{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to ToolBoxV2 \ud83e\uddf0","text":"<p>ToolBoxV2 is a flexible, modular framework designed for creating and managing a wide range of tools, functions, and complete applications. It supports deployment locally, on the web, or as cross-platform desktop/mobile applications.</p> <p>At its core, ToolBoxV2 integrates a Python backend with a Rust server and a Tauri-based UI, offering a powerful and versatile development experience.</p> <ul> <li>Free software: Custom License</li> <li>Officel Web page: https://simplecore.app/</li> <li>GitHub Repository: https://github.com/MarkinHaus/ToolBoxV2</li> </ul>"},{"location":"#key-goals-features","title":"Key Goals &amp; Features","text":"<p>ToolBoxV2 aims to simplify the development and usage of digital tools by:</p> <ul> <li>\ud83d\udd0c Modularity: Build applications from reusable Python modules (<code>mods</code>) and utilities (<code>utils</code>).</li> <li>\u2699\ufe0f Automation: Facilitate automation of tasks through CLI interactions and programmable APIs.</li> <li>\ud83c\udf10 Cross-Platform Interfaces:<ul> <li>Develop Desktop Applications using Tauri (Rust + Web UI).</li> <li>Create Web Applications with the <code>tbjs</code> frontend framework.</li> <li>Interact via a robust Command Line Interface (CLI).</li> </ul> </li> <li>\ud83d\ude80 Performance &amp; Safety: Leverage Rust for backend server components (Actix) and Python for scripting and application logic.</li> <li>\ud83e\udde9 Extensibility: Easily create and integrate new functions, tools, or full mini-applications.</li> <li>System Independence: Strives to make applications and tools runnable across different operating systems.</li> <li>Unified Development: Provides a cohesive environment for Python, Rust, and web technologies.</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<ul> <li> <p>Installation:     For detailed instructions on how to install the core Python library or set up the full-stack development environment, please see the Installation Guide.     <pre><code># Quick install for the Python package\npip install ToolBoxV2\n</code></pre></p> </li> <li> <p>Developer Guide:     To learn how to create modules, use the <code>App</code> class, and interact with the CLI, explore the full Developer Documentation. </p> </li> <li> <p>Explore the Code:     Dive into the GitHub Repository to see the project structure and contribute.</p> </li> </ul>"},{"location":"#example-use-cases","title":"Example Use Cases","text":"<p>ToolBoxV2 can be used for: *   Personal productivity tools (calendars, note-takers). *   Development utilities and automation scripts. *   Custom internal business applications. *   Interactive data processing and visualization tools. *   And much more!</p>"},{"location":"#account-management","title":"Account Management","text":"<p>For detailed information on how to manage user accounts, please see the Account Management documentation.</p>"},{"location":"#p2p-p2p_rpc_protocolmd","title":"p2p p2p_rpc_protocol.md","text":""},{"location":"#credits","title":"Credits","text":"<p>This package was created with inspiration from project structures like those generated by Cookiecutter and templates such as giswqs/pypackage.</p>"},{"location":"#the-stack-stackmd","title":"The stack stack.md","text":"<p>\u00a9 2022\u20132025 Markin Hausmanns \u2013 All rights reserved.</p>"},{"location":"account_management/","title":"Account Management","text":"<p>This document provides a guide to managing user accounts in ToolBoxV2 through the command-line interface (CLI). These commands are available through the <code>helper</code> module.</p>"},{"location":"account_management/#initial-system-setup","title":"Initial System Setup","text":"<p>Before any other account management commands can be used, the system must be initialized. This is done with the <code>init_system</code> command, which creates the first administrative user.</p>"},{"location":"account_management/#init_system","title":"<code>init_system</code>","text":"<p>This command will launch an interactive prompt to guide you through creating the first user account. This user will have the highest level of permissions.</p> <p>Usage:</p> <pre><code>tb -c helper init_system\n</code></pre> <p>The system will prompt you for a username and an email address. Upon successful creation, a new cryptographic key pair will be generated for the user, which will be used for authentication.</p>"},{"location":"account_management/#user-management","title":"User Management","text":"<p>These commands allow you to create, delete, and list users.</p>"},{"location":"account_management/#create-user","title":"<code>create-user</code>","text":"<p>Creates a new user.</p> <p>Usage:</p> <pre><code>tb -c helper create-user &lt;username&gt; &lt;email&gt;\n</code></pre> <ul> <li><code>&lt;username&gt;</code>: The desired username for the new user.</li> <li><code>&lt;email&gt;</code>: The email address for the new user.</li> </ul>"},{"location":"account_management/#delete-user","title":"<code>delete-user</code>","text":"<p>Deletes a user and all associated data, including their cryptographic keys.</p> <p>Usage:</p> <pre><code>tb -c helper delete-user &lt;username&gt;\n</code></pre> <ul> <li><code>&lt;username&gt;</code>: The username of the user to delete.</li> </ul>"},{"location":"account_management/#list-users","title":"<code>list-users</code>","text":"<p>Displays a list of all registered users, including their username, email, and permission level.</p> <p>Usage:</p> <pre><code>tb -c helper list-users\n</code></pre>"},{"location":"account_management/#device-and-access-management","title":"Device and Access Management","text":"<p>These commands are used to manage how users can access their accounts.</p>"},{"location":"account_management/#create-invitation","title":"<code>create-invitation</code>","text":"<p>Generates a one-time invitation code that allows a user to link a new device to their account.</p> <p>Usage:</p> <pre><code>tb -c helper create-invitation &lt;username&gt;\n</code></pre> <ul> <li><code>&lt;username&gt;</code>: The username of the user for whom to create the invitation.</li> </ul>"},{"location":"account_management/#send-magic-link","title":"<code>send-magic-link</code>","text":"<p>Sends a magic login link to the user's registered email address. This link can be used to log in without a password or key.</p> <p>Usage:</p> <pre><code>tb -c helper send-magic-link &lt;username&gt;\n</code></pre> <ul> <li><code>&lt;username&gt;</code>: The username of the user to whom the magic link should be sent.</li> </ul>"},{"location":"agent/","title":"FlowAgent &amp; FlowAgentBuilder Guide","text":""},{"location":"agent/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Architecture Overview</li> <li>Core Concepts<ul> <li>LLM Reasoner: The Strategic Core</li> <li>Unified Context Management</li> <li>Advanced Variable System</li> </ul> </li> <li>FlowAgent API</li> <li>FlowAgentBuilder API</li> <li>Quick Start Guide</li> <li>Configuration Management</li> <li>Persona &amp; Response Formatting</li> <li>Tool Integration<ul> <li>Custom &amp; MCP Tools</li> </ul> </li> <li>Variable System In-Depth</li> <li>Context &amp; Session Management</li> <li>Advanced Usage<ul> <li>Checkpoint &amp; Resume</li> <li>Performance Monitoring</li> </ul> </li> <li>Production Deployment</li> <li>Best Practices</li> </ol>"},{"location":"agent/#1-architecture-overview","title":"1. Architecture Overview","text":"<p>The FlowAgent system has evolved into a hierarchical, reasoning-driven architecture. The central component is the <code>LLMReasonerNode</code>, which acts as the strategic core. It analyzes requests, creates execution outlines, and delegates tasks to specialized sub-systems.</p> <p>This design moves from a linear pipeline to an intelligent, adaptive loop controlled by the reasoner.</p> <pre><code>                                      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                                      \u2502    FlowAgentBuilder    \u2502\n                                      \u2502 (Configuration Engine) \u2502\n                                      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                  \u2502 (Builds)\n                                                  \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                                    FlowAgent                                      \u2502\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502 \u2502                              LLMReasonerNode                                  \u2502 \u2502\n\u2502 \u2502                           (The Strategic Core)                                \u2502 \u2502\n\u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502\n\u2502 \u2502 \u2502 Outline Engine \u2502 \u2502 Meta-Tool Caller \u2502 \u2502 Context Manager\u2502 \u2502 Auto-Recovery  \u2502 \u2502 \u2502\n\u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                      \u2502 (Delegates to Sub-Systems)                 \u2502\n\u2502          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                \u2502\n\u2502          \u25bc                           \u25bc                           \u25bc                \u2502\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502 \u2502   LLMToolNode    \u2502      \u2502   TaskPlanner    \u2502      \u2502    Response Generation   \u2502  \u2502\n\u2502 \u2502 (Simple Tool Use)\u2502      \u2502  (Complex Plans) \u2502      \u2502 (Formatting &amp; Synthesis) \u2502  \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                     \u25bc                                             \u2502\n\u2502                           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                    \u2502\n\u2502                           \u2502   TaskExecutor   \u2502                                    \u2502\n\u2502                           \u2502(Parallel Execution)\u2502                                  \u2502\n\u2502                           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"agent/#2-core-concepts","title":"2. Core Concepts","text":""},{"location":"agent/#llm-reasoner-the-strategic-core","title":"LLM Reasoner: The Strategic Core","text":"<p>The <code>LLMReasonerNode</code> is the brain of the agent. Instead of following a fixed path, it performs these steps in a loop:</p> <ol> <li>Outline Creation: For any given query, it first generates a high-level strategic outline (e.g., \"Step 1: Research data\", \"Step 2: Analyze findings\", \"Final Step: Synthesize response\").</li> <li>Task Stack Management: It maintains an internal to-do list (<code>internal_task_stack</code>) based on the current outline step.</li> <li>Meta-Tool Execution: In each loop, it decides which \"meta-tool\" to use to make progress on its current task. These are not external tools but internal functions that control the agent's sub-systems:<ul> <li><code>internal_reasoning</code>: For thinking and analyzing the situation.</li> <li><code>delegate_to_llm_tool_node</code>: For simple, self-contained tasks that require external tools (e.g., a web search).</li> <li><code>create_and_execute_plan</code>: For complex, multi-step projects that require the full <code>TaskPlanner</code> and <code>TaskExecutor</code>.</li> <li><code>read_from_variables</code>/<code>write_to_variables</code>: To interact with the stateful <code>VariableManager</code>.</li> <li><code>direct_response</code>: To provide the final answer when the outline is complete.</li> </ul> </li> <li>Auto-Recovery: It includes mechanisms to detect infinite loops and automatically attempt recovery, for example, by forcing an advance to the next outline step.</li> </ol>"},{"location":"agent/#unified-context-management","title":"Unified Context Management","text":"<p>The new <code>UnifiedContextManager</code> provides a single, authoritative source for all contextual information. It integrates:</p> <ul> <li>Chat History: Persistent, session-aware conversation history via <code>ChatSession</code>.</li> <li>Variable System: Access to all data in the <code>VariableManager</code>, including task results and world model facts.</li> <li>Execution State: Real-time information about active, completed, and failed tasks.</li> <li>Intelligent Caching: Reduces redundant context processing for better performance.</li> </ul> <p>This eliminates the need for individual nodes to aggregate context manually, leading to a more streamlined and reliable system.</p>"},{"location":"agent/#advanced-variable-system","title":"Advanced Variable System","text":"<p>The <code>VariableManager</code> is a powerful state management system with the following features:</p> <ul> <li>Scoped Variables: Organizes data into logical scopes like <code>world</code>, <code>results</code>, <code>user</code>, and <code>system</code>.</li> <li>Dot-Notation Access: Access nested data in dictionaries and lists easily (e.g., <code>{{ results.task-123.data.some_key }}</code>).</li> <li>Multiple Syntaxes: Use <code>{{ variable.path }}</code>, <code>{variable}</code>, or <code>$variable</code> for flexible text formatting.</li> <li>Dynamic Suggestions: The system can suggest relevant variables to the LLM based on the current query.</li> <li>LLM-Friendly Documentation: Can generate a comprehensive list of all available variables for the LLM to reference.</li> </ul>"},{"location":"agent/#3-flowagent-api","title":"3. FlowAgent API","text":""},{"location":"agent/#basic-usage","title":"Basic Usage","text":"<pre><code># Simple query execution\nagent = await FlowAgentBuilder().with_assistant_persona().build()\nresponse = await agent.a_run(\"Your query here\")\n\n# With session management\nresponse = await agent.a_run(\n    query=\"Follow up question\",\n    session_id=\"user_123\",\n    user_id=\"john_doe\"\n)\n\n# Using variables\nagent.set_variable(\"user.name\", \"John\")\nagent.set_variable(\"project.name\", \"FlowAgent Demo\")\nresponse = await agent.a_run(\"Hello {{ user.name }}! How is {{ project.name }} going?\")\n</code></pre>"},{"location":"agent/#advanced-features","title":"Advanced Features","text":"<pre><code># Format-specific responses\nagent.set_response_format(\n    response_format=\"with-tables\",\n    text_length=\"detailed-indepth\",\n    custom_instructions=\"Focus on actionable insights\"\n)\nresponse_with_format = await agent.a_run_with_format(\n    query=\"Analyze sales data for Q3\",\n    response_format=\"with-tables\"\n)\n\n\n# Checkpoint management\nawait agent.pause()  # Creates and saves a checkpoint\nawait agent.resume() # Resumes from the paused state\n\n# Performance and status monitoring\nsummary = await agent.get_task_execution_summary()\nreasoning = await agent.explain_reasoning_process()\nstatus = agent.status(pretty_print=True)\n\n# Context Management\nawait agent.save_context_to_session(\"user_123\")\ncontext_stats = agent.get_context_statistics()\n\n# Lifecycle\nawait agent.close() # Saves a final checkpoint and shuts down gracefully\n</code></pre>"},{"location":"agent/#4-flowagentbuilder-api","title":"4. FlowAgentBuilder API","text":"<p>The <code>FlowAgentBuilder</code> is now a fluent, production-focused builder that relies on a structured <code>AgentConfig</code> model.</p>"},{"location":"agent/#builder-components","title":"Builder Components","text":"<ul> <li>Configuration Management: <code>load_config()</code>, <code>save_config()</code>, <code>validate_config()</code>.</li> <li>Fluent API: A chainable interface for programmatic configuration.</li> <li>Integration Systems: Built-in support for MCP, A2A, and OpenTelemetry.</li> </ul>"},{"location":"agent/#fluent-api-example","title":"Fluent API Example","text":"<pre><code>builder = (FlowAgentBuilder()\n    .with_name(\"MyProductionAgent\")\n    .with_models(\"openrouter/anthropic/claude-3-haiku\", \"openrouter/openai/gpt-4o\")\n    .with_system_message(\"You are a helpful production assistant.\")\n    .with_developer_persona()\n    .enable_mcp_server(port=8001)\n    .enable_a2a_server(port=5001)\n    .enable_telemetry(service_name=\"prod-agent\", console_export=True)\n    .with_checkpointing(interval_seconds=600)\n    .with_custom_variables({\"env\": \"production\"})\n    .verbose(True)\n)\n\n# Validate before building\nissues = builder.validate_config()\nif not issues[\"errors\"]:\n    agent = await builder.build()\n</code></pre>"},{"location":"agent/#5-quick-start-guide","title":"5. Quick Start Guide","text":""},{"location":"agent/#1-basic-agent-creation","title":"1. Basic Agent Creation","text":"<pre><code>import asyncio\nfrom builder import FlowAgentBuilder\n\nasync def basic_example():\n    # Create a simple assistant agent using a pre-built factory method\n    agent = await (FlowAgentBuilder\n                  .create_general_assistant(\"MyAssistant\")\n                  .build())\n\n    # Use the agent\n    response = await agent.a_run(\"Hello! Can you help me write a Python function?\")\n    print(response)\n\n    await agent.close()\n\n# Run the example\nasyncio.run(basic_example())\n</code></pre>"},{"location":"agent/#2-pre-built-agent-types","title":"2. Pre-built Agent Types","text":"<p>The builder provides factory methods for common agent types, which configure the name, persona, and integrations.</p> <pre><code># Developer agent with code focus\ndeveloper = await FlowAgentBuilder.create_developer_agent(\"CodeHelper\").build()\n\n# Data analyst agent with visualization focus\nanalyst = await FlowAgentBuilder.create_analyst_agent(\"DataHelper\").build()\n\n# Creative assistant for content generation\ncreative = await FlowAgentBuilder.create_creative_agent(\"ContentCreator\").build()\n\n# Executive assistant for strategic tasks\nexecutive = await FlowAgentBuilder.create_executive_agent(\"StrategyHelper\").build()\n\n# General assistant with full capabilities\nassistant = await FlowAgentBuilder.create_general_assistant(\"GeneralHelper\").build()\n</code></pre>"},{"location":"agent/#3-custom-tool-integration","title":"3. Custom Tool Integration","text":"<pre><code>async def custom_tool_example():\n    # Define a custom tool\n    def get_server_time() -&gt; str:\n        \"\"\"Returns the current server time in ISO format.\"\"\"\n        from datetime import datetime\n        return datetime.now().isoformat()\n\n    # Build agent with the tool\n    agent = await (FlowAgentBuilder()\n                  .with_name(\"CustomToolAgent\")\n                  .with_assistant_persona()\n                  .add_tool(get_server_time, \"get_server_time\")\n                  .build())\n\n    # Use the tool through natural language\n    response = await agent.a_run(\"What is the current server time?\")\n    print(response)\n\n    await agent.close()\n\nasyncio.run(custom_tool_example())\n</code></pre>"},{"location":"agent/#6-configuration-management","title":"6. Configuration Management","text":"<p>Configuration is managed through the <code>AgentConfig</code> Pydantic model, which can be loaded from or saved to YAML/JSON files.</p>"},{"location":"agent/#1-configuration-structure-agent_configyaml","title":"1. Configuration Structure (<code>agent_config.yaml</code>)","text":"<pre><code>name: \"ProductionAgent\"\ndescription: \"Production-ready agent with full capabilities\"\nversion: \"2.0.0\"\n\n# LLM Configuration\nfast_llm_model: \"openrouter/anthropic/claude-3-haiku\"\ncomplex_llm_model: \"openrouter/openai/gpt-4o\"\ntemperature: 0.7\nmax_tokens_output: 2048\napi_key_env_var: \"OPENROUTER_API_KEY\"\n\n# Features\nmcp:\n  enabled: true\n  host: \"0.0.0.0\"\n  port: 8000\n  config_path: \"mcp_tools.json\"\n\na2a:\n  enabled: true\n  host: \"0.0.0.0\"\n  port: 5000\n  agent_name: \"ProductionAgent\"\n\ntelemetry:\n  enabled: true\n  service_name: \"production_agent\"\n  console_export: true\n\ncheckpoint:\n  enabled: true\n  interval_seconds: 300\n  checkpoint_dir: \"./checkpoints\"\n\n# Persona and Variables\nactive_persona: \"developer\"\npersona_profiles:\n  developer:\n    name: \"Senior Developer\"\n    style: \"technical\"\n    # ... more persona settings\ncustom_variables:\n  environment: \"production\"```\n\n### 2. Loading and Saving\n\n```python\n# Load from a configuration file\nbuilder = FlowAgentBuilder.from_config_file(\"agent_config.yaml\")\nagent = await builder.build()\n\n# Save the current builder configuration to a file\nbuilder.save_config(\"my_agent_config.yaml\", format=\"yaml\")\n</code></pre>"},{"location":"agent/#3-configuration-validation","title":"3. Configuration Validation","text":"<p>It's best practice to validate the configuration before building the agent.</p> <pre><code>builder = FlowAgentBuilder.from_config_file(\"config.yaml\")\n\n# Validate configuration\nissues = builder.validate_config()\n\nif issues[\"errors\"]:\n    print(\"Configuration errors:\", issues[\"errors\"])\nelif issues[\"warnings\"]:\n    print(\"Configuration warnings:\", issues[\"warnings\"])\nelse:\n    agent = await builder.build()\n</code></pre>"},{"location":"agent/#7-persona-response-formatting","title":"7. Persona &amp; Response Formatting","text":"<p>The persona system is now deeply integrated with response formatting to control the agent's output structure and style.</p>"},{"location":"agent/#1-persona-and-format-structure","title":"1. Persona and Format Structure","text":"<p>The <code>PersonaConfig</code> now includes an optional <code>FormatConfig</code> to define the desired output structure.</p> <pre><code>@dataclass\nclass FormatConfig:\n    response_format: ResponseFormat = ResponseFormat.FREI_TEXT\n    text_length: TextLength = TextLength.CHAT_CONVERSATION\n    # ... more settings\n\n@dataclass\nclass PersonaConfig:\n    name: str\n    style: str = \"professional\"\n    # ... other traits\n    format_config: Optional[FormatConfig] = None\n</code></pre>"},{"location":"agent/#2-pre-built-personas","title":"2. Pre-built Personas","text":"<p>The builder includes methods that set up personas with appropriate default formats.</p> <pre><code># Developer Persona -&gt; Defaults to 'code-structure' format\nbuilder.with_developer_persona()\n\n# Analyst Persona -&gt; Defaults to 'with-tables' format\nbuilder.with_analyst_persona()\n</code></pre>"},{"location":"agent/#3-dynamic-response-formatting","title":"3. Dynamic Response Formatting","text":"<p>You can override the default persona format at runtime for a specific query.</p> <pre><code># Set a specific response format for the next call\nagent.set_response_format(\n    response_format=\"with-tables\",      # Use tables for data\n    text_length=\"detailed-indepth\",     # Comprehensive responses\n    custom_instructions=\"Include confidence scores\"\n)\nresponse = await agent.a_run(\"Analyze this data: [1,2,3,4,5]\")\n\n# Or use the convenient run_with_format method\nresponse_md = await agent.a_run_with_format(\n    query=\"Explain this concept\",\n    response_format=\"md-text\",\n    text_length=\"detailed-indepth\"\n)\n\n# Get available formats\nformats = agent.get_available_formats()\nprint(\"Available formats:\", formats[\"formats\"])\n</code></pre>"},{"location":"agent/#8-tool-integration","title":"8. Tool Integration","text":""},{"location":"agent/#custom-mcp-tools","title":"Custom &amp; MCP Tools","text":"<p>The system seamlessly integrates custom Python functions and tools loaded from MCP (Model Context Protocol) servers. The <code>FlowAgentBuilder</code> now features a robust MCP loader that automatically manages server processes and creates tool wrappers.</p>"},{"location":"agent/#1-custom-functions","title":"1. Custom Functions","text":"<pre><code>def get_current_time():\n    \"\"\"Returns the current timestamp.\"\"\"\n    from datetime import datetime\n    return datetime.now().isoformat()\n\n# Add a custom tool to the agent\nbuilder = FlowAgentBuilder().add_tool(get_current_time, \"current_time\")\n</code></pre>"},{"location":"agent/#2-module-integration","title":"2. Module Integration","text":"<pre><code>import math\n\n# Add all public functions from the math module with a prefix\nbuilder.add_tools_from_module(module=math, prefix=\"math_\")\n</code></pre>"},{"location":"agent/#3-mcp-integration-via-mcp_serversjson","title":"3. MCP Integration (via <code>mcp_servers.json</code>)","text":"<p>The builder can launch and integrate with MCP servers defined in a configuration file. It will automatically manage the server lifecycle and extract all its capabilities (tools, resources, prompts).</p> <p><code>mcp_servers.json</code>: <pre><code>{\n  \"mcpServers\": {\n    \"filesystem\": {\n      \"command\": \"python\",\n      \"args\": [\"-m\", \"mcp_server_filesystem\"],\n      \"env\": { \"FILESYSTEM_ROOT\": \"/home/user/documents\" }\n    },\n    \"sequential_thinking\": {\n        \"command\": \"npx\",\n        \"args\": [\"-y\", \"@modelcontextprotocol/server-sequential-thinking\"]\n    }\n  }\n}\n</code></pre></p> <p>Loading in the builder: <pre><code>agent = await (FlowAgentBuilder()\n              .with_name(\"MCPAgent\")\n              .load_mcp_tools_from_config(\"mcp_servers.json\")\n              .build())\n\n# The agent can now use tools like 'filesystem_read_file' or 'sequential_thinking_prompt_...'\nresponse = await agent.a_run(\"Read the file 'report.txt' from my documents.\")\n</code></pre></p>"},{"location":"agent/#9-variable-system-in-depth","title":"9. Variable System In-Depth","text":"<p>The <code>VariableManager</code> provides a powerful way to manage state and create dynamic content.</p>"},{"location":"agent/#1-variable-scopes","title":"1. Variable Scopes","text":"<ul> <li><code>world</code>: Stores facts the agent has learned.</li> <li><code>results</code>: Holds the output of every executed task (e.g., <code>results.task-123.data</code>).</li> <li><code>user</code>: Contains information about the current user and session.</li> <li><code>system</code>: Provides system-level information like timestamps.</li> <li>Custom Scopes: You can register your own scopes for better organization.</li> </ul>"},{"location":"agent/#2-variable-usage-in-prompts","title":"2. Variable Usage in Prompts","text":"<p>You can reference variables in prompts, system messages, and tool arguments using multiple syntaxes.</p> <pre><code># Double brace syntax (recommended for paths)\nresponse = await agent.a_run(\"User: {{ user.name }}, Project: {{ project.details.name }}\")\n\n# Single brace syntax (for simple, top-level variables)\nresponse = await agent.a_run(\"Welcome {user_name}!\")\n\n# Dollar syntax\nresponse = await agent.a_run(\"Current time is $system_timestamp\")\n</code></pre>"},{"location":"agent/#3-variable-management-api","title":"3. Variable Management API","text":"<pre><code># Set a nested variable\nagent.set_variable(\"project.details.version\", \"3.0\")\n\n# Get variable documentation for the LLM\ndocs = agent.get_variable_documentation()\nprint(docs)\n\n# Get available variables as a dictionary\navailable_vars = agent.get_available_variables()\n</code></pre>"},{"location":"agent/#10-context-session-management","title":"10. Context &amp; Session Management","text":"<p>Context is now handled centrally by the <code>UnifiedContextManager</code>, ensuring consistency across the agent.</p>"},{"location":"agent/#1-session-initialization","title":"1. Session Initialization","text":"<p>Sessions are automatically created and managed. You just need to provide a <code>session_id</code>.</p> <pre><code># This will create or load the session for 'user_123'\nawait agent.a_run(\"My first question\", session_id=\"user_123\")\n\n# The agent now has context from the first question\nawait agent.a_run(\"Follow-up question based on my first one\", session_id=\"user_123\")\n</code></pre>"},{"location":"agent/#2-unified-context","title":"2. Unified Context","text":"<p>The context provided to the LLM reasoner is a rich, unified view of: *   Recent conversation history. *   The current execution state (active and completed tasks). *   Available results from the variable system. *   Relevant facts from the world model.</p>"},{"location":"agent/#3-context-api","title":"3. Context API","text":"<pre><code># Initialize a session explicitly (optional)\nawait agent.initialize_session_context(session_id=\"user_456\", max_history=300)\n\n# Get a snapshot of the current unified context\ncontext_data = await agent.get_context(session_id=\"user_456\", format_for_llm=False)\n\n# Save a snapshot of the context to the persistent session history\nawait agent.save_context_to_session(\"user_456\")\n\n# Get context statistics\nstats = agent.get_context_statistics()\n</code></pre>"},{"location":"agent/#11-advanced-usage","title":"11. Advanced Usage","text":""},{"location":"agent/#checkpoint-resume","title":"Checkpoint &amp; Resume","text":"<p>The agent can automatically save its state and be restored later, making long-running tasks more reliable.</p> <pre><code># Enable checkpointing in the builder\nbuilder.with_checkpointing(enabled=True, interval_seconds=300)\n\n# Manually pause the agent (this also saves a checkpoint)\nawait agent.pause()\n\n# Later, you can resume\nresumed_agent = await FlowAgentBuilder.from_config_file(\"config.yaml\").build()\nawait resumed_agent.load_latest_checkpoint()\nawait resumed_agent.resume()\n</code></pre>"},{"location":"agent/#performance-monitoring","title":"Performance Monitoring","text":"<p>The agent exposes detailed status and performance metrics.</p> <pre><code># Enable telemetry for distributed tracing (e.g., with Jaeger)\nbuilder.enable_telemetry(service_name=\"my_agent\", endpoint=\"http://localhost:14268/api/traces\")\n\n# Get a comprehensive status report\nagent.status(pretty_print=True)\n\n# Get a summary of the reasoning and execution process\nreasoning_explanation = await agent.explain_reasoning_process()\nprint(reasoning_explanation)\n\n# Get detailed statistics from the task executor\nif hasattr(agent.task_flow, 'executor_node'):\n    stats = agent.task_flow.executor_node.get_execution_statistics()\n    print(\"Execution stats:\", stats)\n</code></pre>"},{"location":"agent/#12-production-deployment","title":"12. Production Deployment","text":""},{"location":"agent/#1-production-configuration","title":"1. Production Configuration","text":"<p>Use a dedicated YAML configuration file for production environments to manage settings without code changes. Disable verbose logging.</p> <pre><code># production_agent.py\nimport asyncio\nfrom builder import FlowAgentBuilder\n\nasync def main():\n    agent = await (FlowAgentBuilder\n                  .from_config_file(\"production_config.yaml\")\n                  .verbose(False)\n                  .build())\n\n    try:\n        await agent.start_servers() # Starts MCP/A2A if enabled\n        print(f\"Production agent '{agent.amd.name}' is ready.\")\n        # Keep the agent running\n        while True:\n            await asyncio.sleep(3600)\n    finally:\n        await agent.close()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"agent/#2-docker-deployment","title":"2. Docker Deployment","text":"<pre><code># Dockerfile\nFROM python:3.11-slim\n\nWORKDIR /app\n\n# Install dependencies\nRUN apt-get update &amp;&amp; apt-get install -y nodejs npm &amp;&amp; rm -rf /var/lib/apt/lists/*\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\n\n# Copy application\nCOPY . .\n\n# Expose ports for MCP and A2A\nEXPOSE 8000 5000\n\n# Run the agent\nCMD [\"python\", \"production_agent.py\"]\n</code></pre>"},{"location":"agent/#3-health-monitoring","title":"3. Health Monitoring","text":"<p>Implement a health check endpoint to monitor the agent's status in production.</p> <pre><code>async def health_check(agent: FlowAgent):\n    status = agent.status()\n    is_healthy = status[\"runtime_status\"][\"status\"] in [\"idle\", \"running\"]\n    return {\n        \"status\": \"healthy\" if is_healthy else \"unhealthy\",\n        \"agent_status\": status[\"runtime_status\"][\"status\"],\n        \"total_cost\": status[\"performance\"][\"total_cost\"],\n        \"active_tasks\": status[\"task_execution\"][\"active_tasks\"]\n    }\n</code></pre>"},{"location":"agent/#13-best-practices","title":"13. Best Practices","text":"<ul> <li>Use Configuration Files: Manage agent settings in YAML files (<code>from_config_file</code>) instead of hard-coding them in the builder for better maintainability.</li> <li>Validate Configuration: Always run <code>builder.validate_config()</code> before <code>build()</code> to catch issues early.</li> <li>Leverage Pre-built Personas: Start with pre-built personas (<code>.with_developer_persona()</code>) and customize from there.</li> <li>Use Sessions: Pass a unique <code>session_id</code> to <code>a_run()</code> for each user or conversation to maintain context.</li> <li>Manage Resources: Use <code>await agent.close()</code> for a graceful shutdown, which saves a final checkpoint and cleans up server processes.</li> <li>Enable Checkpointing: For any long-running or critical tasks, enable checkpointing to ensure reliability.</li> <li>Monitor Performance: Regularly check <code>agent.status()</code> and enable telemetry in production to monitor costs and performance.</li> <li>Secure API Keys: Always load API keys from environment variables (<code>.with_api_config(api_key_env_var=...)</code>) and never hard-code them.</li> </ul>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#v001-date","title":"v0.0.1 - Date","text":"<p>Improvement:</p> <ul> <li>TBD</li> </ul> <p>New Features:</p> <ul> <li>TBD</li> </ul>"},{"location":"clis/","title":"CLIS","text":"<p>Of course. Here are three rich helper guides and usage examples for your enhanced CLI applications, formatted in Markdown.</p>"},{"location":"clis/#p2p-tunnel-manager-tmc_p2p_clipy-user-guide","title":"\ud83d\ude80 P2P Tunnel Manager (<code>tmc_p2p_cli.py</code>) - User Guide","text":"<p>This utility provides a robust command-line interface to manage instances of the P2P tunneling application. It creates isolated environments for each peer and relay, making it easy to configure, run, and debug complex network setups.</p>"},{"location":"clis/#quickstart","title":"Quickstart","text":"<ol> <li> <p>Build the application: <pre><code>tb p2p build\n</code></pre></p> </li> <li> <p>Start a Relay Server: <pre><code>tb p2p start-relay main-relay --password \"a-secure-password\"\n</code></pre></p> </li> <li> <p>Start Peers:</p> <ul> <li>Provider (exposes a local service):     <pre><code>tb p2p start-peer api-provider --peer-id service-A \\\n  --relay-addr 127.0.0.1:9000 --relay-pass \"a-secure-password\" \\\n  --forward 127.0.0.1:3000\n</code></pre></li> <li>Consumer (accesses the provider's service):     <pre><code>tb p2p start-peer api-consumer --target service-A \\\n  --relay-addr 127.0.0.1:9000 --relay-pass \"a-secure-password\" \\\n  --listen 127.0.0.1:8000\n</code></pre></li> </ul> </li> <li> <p>Check Status &amp; Logs: <pre><code>tb p2p status\ntb p2p logs api-provider\n</code></pre></p> </li> <li> <p>Stop Instances: <pre><code># Stop one instance\ntb p2p stop api-consumer\n\n# Stop all instances\ntb p2p stop\n</code></pre></p> </li> </ol>"},{"location":"clis/#blob-db-cluster-manager-db_clipy-user-guide","title":"\ud83d\ude80 Blob DB Cluster Manager (<code>db_cli.py</code>) - User Guide","text":"<p>This CLI is a powerful tool for managing a distributed cluster of <code>r_blob_db</code> instances. It handles configuration, state, and provides commands for starting, stopping, and health-checking the entire cluster or individual nodes.</p>"},{"location":"clis/#quickstart_1","title":"Quickstart","text":"<ol> <li> <p>Build the application: <pre><code>tb db build\n</code></pre></p> </li> <li> <p>Initialize the Cluster: The first time you run a command, a <code>cluster_config.json</code> is created with a default two-node setup. You can customize this file.</p> </li> <li> <p>Start the Cluster: <pre><code># Starts all instances defined in cluster_config.json\ntb db start\n</code></pre></p> </li> <li> <p>Check Status &amp; Health: <pre><code>tb db status\ntb db health\n</code></pre></p> </li> <li> <p>Stop the Cluster: <pre><code># Stop a single instance\ntb db stop --instance-id instance-01\n\n# Stop all instances\ntb db stop\n</code></pre></p> </li> </ol>"},{"location":"clis/#example-2-performing-a-rolling-update-on-the-live-cluster","title":"Example 2: Performing a Rolling Update on the Live Cluster","text":"<p>Scenario: You've developed <code>v1.1.0</code> of <code>r_blob_db</code> and need to update your running <code>v1.0.0</code> cluster without any downtime. The rolling update process updates one node at a time, ensuring the cluster remains available.</p> <ol> <li> <p>Check Current Cluster Health:     Before starting, ensure all nodes are healthy.     <pre><code>tb db health\n</code></pre> You should see all instances report <code>\u2705 OK</code>.</p> </li> <li> <p>Build the New Version:     Compile the new version of your application. The manager will automatically find the new binary.     <pre><code># Assuming your code is updated to v1.1.0\ntb db build\n</code></pre></p> </li> <li> <p>Initiate the Rolling Update:     Execute the <code>update</code> command, specifying the new version string.     <pre><code>tb db update --version \"v1.1.0\"\n</code></pre></p> </li> <li> <p>Monitor the Process:     The CLI will provide detailed, real-time feedback:     <pre><code>--- Starting Rolling Update to Version v1.1.0 ---\n\n[1/2] Updating instance 'instance-01'...\n\u23f9\ufe0f  Instance 'instance-01' stopped.\n\ud83d\ude80 Starting instance 'instance-01' on port 3001...\n\u2705 Instance 'instance-01' started successfully. (PID: 12346)\n...\n\u29d6 Waiting for 'instance-01' to become healthy...\n\u2705 Instance 'instance-01' is healthy with new version.\n\n[2/2] Updating instance 'instance-02'...\n...\n--- Rolling Update Complete ---\n</code></pre></p> </li> <li> <p>Verify the Update:     Run the health check again. All instances should now report <code>OK</code> and show <code>server_version: v1.1.0</code>.     <pre><code>tb db health\n</code></pre></p> </li> </ol>"},{"location":"clis/#api-server-manager-api_managerpy-user-guide","title":"\ud83d\ude80 API Server Manager (<code>api_manager.py</code>) - User Guide","text":"<p>This manager is designed for high-availability web services. Its standout feature is the ability to perform zero-downtime updates on POSIX systems (Linux/macOS) by passing the active network socket from the old process to the new one, ensuring no client requests are dropped during the update.</p>"},{"location":"clis/#quickstart_2","title":"Quickstart","text":"<ol> <li> <p>Build the application: <pre><code># Assuming the CLI entrypoint is mapped to `tb`\ntb api build\n</code></pre></p> </li> <li> <p>Start the Server:</p> <ul> <li>On Linux/macOS (with Zero-Downtime enabled): <pre><code>tb api start --posix-zdt\n</code></pre></li> <li>On Windows (uses graceful restart): <pre><code>tb api start\n</code></pre></li> </ul> </li> <li> <p>Check Status: <pre><code>tb api status\n</code></pre></p> </li> <li> <p>Update the Server: <pre><code># First, build the new version\ntb api build\n\n# Then, run the update\ntb api update --version \"v1.2.0\" --posix-zdt\n</code></pre></p> </li> <li> <p>Stop the Server: <pre><code>tb api stop\n</code></pre></p> </li> </ol>"},{"location":"clis/#example-3-zero-downtime-deployment-on-a-linux-server","title":"Example 3: Zero-Downtime Deployment on a Linux Server","text":"<p>Scenario: Your API server is handling live traffic. You need to deploy a critical security patch (<code>v1.0.1</code>) without interrupting any ongoing client connections.</p> <ol> <li> <p>Check Initial State:     Ensure the server is running correctly. The <code>--posix-zdt</code> flag confirms that the manager is aware of the socket file descriptor.     <pre><code>tb api status --posix-zdt\n</code></pre> Output: <pre><code>--- Server Status ---\n  \u2705 RUNNING\n    PID:        11223\n    Version:    v1.0.0\n    Executable: /path/to/project/src-core/simple-core-server\n    Listening FD: 4 (POSIX ZDT Active)\n</code></pre></p> </li> <li> <p>Build the New Version:     Compile the patched version of the code.     <pre><code>tb api build\n</code></pre></p> </li> <li> <p>Execute the Zero-Downtime Update:     Run the <code>update</code> command with the <code>--posix-zdt</code> flag.     <pre><code>tb api update --version \"v1.0.1\" --posix-zdt\n</code></pre></p> </li> <li> <p>Observe the Magic:     The manager performs the following sequence seamlessly:</p> <ul> <li>It finds the persistent socket file descriptor (<code>FD: 4</code>).</li> <li>It starts the new server process (<code>v1.0.1</code>), passing it ownership of the active socket. The new server begins accepting new connections on the same port immediately.</li> <li>Once the new server is running, the manager sends a <code>SIGTERM</code> signal to the old process (<code>v1.0.0</code>).</li> <li>The old process stops accepting new connections but finishes handling any in-flight requests before shutting down.</li> <li>The state file is updated with the new PID and version.</li> </ul> <p>Terminal Output: <pre><code>--- [POSIX] Starting Zero-Downtime Update to v1.0.1 ---\n\u2705 New server started (PID: 11255).\n\u23f9\ufe0f  Process 11223 stopped.\n--- Update Complete. New PID: 11255 ---\n</code></pre></p> </li> <li> <p>Final Verification:     Check the status again. The server is still <code>RUNNING</code>, but now with the new PID and version. No client would have noticed the switch.     <pre><code>tb api status --posix-zdt\n</code></pre></p> </li> </ol> <p>and wit h the same focus new the last ui update + use real Posix by global fag: import contextlib</p>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p> <p>You can contribute in many ways:</p>"},{"location":"contributing/#types-of-contributions","title":"Types of Contributions","text":""},{"location":"contributing/#report-bugs","title":"Report Bugs","text":"<p>Report bugs at https://github.com/MarkinHaus/ToolBoxV2/issues.</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul>"},{"location":"contributing/#fix-bugs","title":"Fix Bugs","text":"<p>Look through the GitHub issues for bugs. Anything tagged with <code>bug</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#implement-features","title":"Implement Features","text":"<p>Look through the GitHub issues for features. Anything tagged with <code>enhancement</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#write-documentation","title":"Write Documentation","text":"<p>ToolBox could always use more documentation, whether as part of the official ToolBox docs, in docstrings, or even on the web in blog posts, articles, and such.</p>"},{"location":"contributing/#submit-feedback","title":"Submit Feedback","text":"<p>The best way to send feedback is to file an issue at https://github.com/MarkinHaus/ToolBoxV2/issues.</p> <p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to implement.</li> <li>Remember that this is a volunteer-driven project, and that contributions are welcome :)</li> </ul>"},{"location":"contributing/#get-started","title":"Get Started!","text":"<p>Ready to contribute? Here's how to set up ToolBoxV2 for local development.</p> <ol> <li> <p>Fork the ToolBoxV2 repo on GitHub.</p> </li> <li> <p>Clone your fork locally:</p> </li> </ol> <pre><code>$ git clone git@github.com:MarkinHaus/ToolBoxV2.git\n</code></pre> <ol> <li>Install your local copy into a virtualenv. Assuming you have    virtualenvwrapper installed, this is how you set up your fork for    local development:</li> </ol> <pre><code>$ mkvirtualenv ToolBoxV2\n$ cd ToolBoxV2/\n$ python setup.py develop\n</code></pre> <ol> <li>Create a branch for local development:</li> </ol> <pre><code>$ git checkout -b name-of-your-bugfix-or-feature\n</code></pre> <p>Now you can make your changes locally.</p> <ol> <li>When you're done making changes, check that your changes pass flake8    and the tests, including testing other Python versions with tox:</li> </ol> <pre><code>$ flake8 ToolBoxV2 tests\n$ python setup.py test or pytest\n$ tox\n</code></pre> <p>To get flake8 and tox, just pip install them into your virtualenv.</p> <ol> <li>Commit your changes and push your branch to GitHub:</li> </ol> <pre><code>$ git add .\n$ git commit -m \"Your detailed description of your changes.\"\n$ git push origin name-of-your-bugfix-or-feature\n</code></pre> <ol> <li>Submit a pull request through the GitHub website.</li> </ol>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>Before you submit a pull request, check that it meets these guidelines:</p> <ol> <li>The pull request should include tests.</li> <li>If the pull request adds functionality, the docs should be updated.    Put your new functionality into a function with a docstring, and add    the feature to the list in README.rst.</li> <li>The pull request should work for Python 3.5, 3.6, 3.7 and 3.8, and    for PyPy. Check https://github.com/MarkinHaus/ToolBoxV2/pull_requests and make sure that the tests pass for all    supported Python versions.</li> </ol>"},{"location":"db_usage_guide/","title":"ToolBoxV2 Database (DB) Module Guide","text":"<p>This guide provides a comprehensive overview of how to use the ToolBoxV2 <code>DB</code> module. It is designed for both human developers and AI agents to understand how to perform persistent key-value storage within the framework.</p>"},{"location":"db_usage_guide/#1-core-concepts","title":"1. Core Concepts","text":"<p>The <code>DB</code> module acts as a standardized abstraction layer for various key-value storage backends. This design allows you to write your application logic once, using a consistent API (<code>get</code>, <code>set</code>, <code>delete</code>, etc.), while the underlying storage engine can be swapped out with minimal configuration changes.</p>"},{"location":"db_usage_guide/#key-features","title":"Key Features:","text":"<ul> <li>Unified API: A simple, consistent set of functions for all database operations.</li> <li>Multiple Backends (Modes): Supports different storage mechanisms, from simple local files to distributed blobs and Redis caches.</li> <li>Automatic Encoding: Data is automatically handled, allowing you to work with standard Python types (strings, dicts, lists) without manual serialization.</li> <li>Environment-Driven Configuration: Database modes and credentials can be configured via environment variables, allowing for easy switching between development, testing, and production setups.</li> </ul>"},{"location":"db_usage_guide/#database-modes","title":"Database Modes","text":"<p>The module can operate in several modes. The default mode is <code>CLUSTER_BLOB</code>, which is the recommended, most robust option for production environments within the ToolBoxV2 ecosystem.</p> <ul> <li><code>CLUSTER_BLOB</code> (CB): The default and recommended mode. It uses the <code>BlobDB</code> backend, which stores data as encrypted blobs in the configured root storage. This is ideal for user-specific, secure, and distributed data storage.</li> <li><code>LOCAL_DICT</code> (LC): Uses <code>MiniDictDB</code>. A simple, file-based dictionary stored locally. It's excellent for local development, testing, or storing non-critical application state.</li> <li><code>LOCAL_REDIS</code> (LR): Connects to a local Redis instance. Use this for high-performance caching or when you need the advanced data structures offered by Redis.</li> <li><code>REMOTE_REDIS</code> (RR): Connects to a remote Redis server. Suitable for shared state and caching in a distributed environment.</li> </ul>"},{"location":"db_usage_guide/#2-basic-usage","title":"2. Basic Usage","text":"<p>To use the DB module, you first need to get a handle to it from the main <code>app</code> instance. All interactions then happen through this instance.</p> <pre><code># Assuming 'app' is your ToolBoxV2 App instance\ndb = app.get_mod(\"DB\")\n\n# Or, if you have a specific instance of the DB module\ndb_spec = app.get_mod(\"DB\", spec=\"MySpecialDB\")\n</code></pre>"},{"location":"db_usage_guide/#storing-data-set","title":"Storing Data (<code>set</code>)","text":"<p>The <code>set</code> function stores a value associated with a key. It overwrites any existing value.</p> <pre><code># Store a simple string\ndb.set(\"user:123:name\", \"Alice\")\n\n# Store a dictionary (will be automatically JSON-serialized)\nuser_profile = {\"email\": \"alice@example.com\", \"level\": 10}\ndb.set(\"user:123:profile\", user_profile)\n\n# Store a list\ndb.set(\"user:123:roles\", [\"admin\", \"editor\"])\n</code></pre>"},{"location":"db_usage_guide/#retrieving-data-get","title":"Retrieving Data (<code>get</code>)","text":"<p>The <code>get</code> function retrieves a value by its key. The data is returned as a <code>Result</code> object.</p> <pre><code>result = db.get(\"user:123:name\")\n\nif result.is_ok():\n    user_name = result.get() # .get() extracts the data from the Result\n    print(f\"User name: {user_name}\") # Output: User name: Alice\n\nprofile_result = db.get(\"user:123:profile\")\nif profile_result.is_ok():\n    # The DB module automatically deserializes the JSON string back into a dict\n    profile_data = profile_result.get()\n    print(f\"User email: {profile_data['email']}\") # Output: User email: alice@example.com\n</code></pre>"},{"location":"db_usage_guide/#special-get-queries-all-and-all-k","title":"Special <code>get</code> Queries: <code>all</code> and <code>all-k</code>","text":"<p>The <code>get</code> method supports special query strings to retrieve all keys or all key-value pairs from the database.</p> <ul> <li><code>get('all-k')</code>: Returns a list of all keys in the database.</li> <li><code>get('all')</code>: Returns a list of all key-value pairs (as tuples) in the database.</li> </ul> <p>Example:</p> <pre><code># Get all keys\nall_keys_result = db.get(\"all-k\")\nif all_keys_result.is_ok():\n    keys = all_keys_result.get()\n    print(f\"All keys in the database: {keys}\")\n    # Output: All keys in the database: [\\'user:123:name\\', \\'user:123:profile\\', \\'user:123:logs\\']\n\n# Get all items (key-value pairs)\nall_items_result = db.get(\"all\")\nif all_items_result.is_ok():\n    items = all_items_result.get()\n    print(f\"All items: {items}\")\n    # Output: All items: [(\\'user:123:name\\', \\'Alice\\'), (\\'user:123:profile\\', {\\'email\\': \\'alice@example.com\\', \\'level\\': 10}), ...]\n</code></pre>"},{"location":"db_usage_guide/#checking-for-existence-if_exist","title":"Checking for Existence (<code>if_exist</code>)","text":"<p>To check if a key exists without retrieving its value, use <code>if_exist</code>.</p> <pre><code>if db.if_exist(\"user:123:name\").get():\n    print(\"User 123 exists!\")\nelse:\n    print(\"User 123 not found.\")\n</code></pre>"},{"location":"db_usage_guide/#deleting-data-delete","title":"Deleting Data (<code>delete</code>)","text":"<pre><code># Delete a single key\ndelete_result = db.delete(\"user:123:roles\")\nif delete_result.is_ok():\n    print(\"Roles deleted.\")\n\n# Delete multiple keys using a matching prefix (supported in Redis/Dict modes)\n# This would delete all keys starting with \"user:123:\"\ndb.delete(\"user:123:\", matching=True)\n</code></pre>"},{"location":"db_usage_guide/#appending-to-a-list-append_on_set","title":"Appending to a List (<code>append_on_set</code>)","text":"<p>This function is useful for adding items to a key that stores a list. If the key doesn't exist, it's created as a new list.</p> <pre><code># Assuming \"user:123:logs\" doesn't exist yet\ndb.append_on_set(\"user:123:logs\", \"User logged in.\")\n\n# Append another log\ndb.append_on_set(\"user:123:logs\", \"User updated profile.\")\n\n# Retrieve the list\nlogs_result = db.get(\"user:123:logs\")\n# logs_result.get() will be [\"User logged in.\", \"User updated profile.\"]\n</code></pre>"},{"location":"db_usage_guide/#3-configuration-and-mode-switching","title":"3. Configuration and Mode Switching","text":"<p>While the default mode is <code>CLUSTER_BLOB</code>, you can change it for development or other specific needs.</p>"},{"location":"db_usage_guide/#configuration-via-environment-variables","title":"Configuration via Environment Variables","text":"<p>The easiest way to configure the DB module is through environment variables in your <code>.env</code> file. The module will read these on startup.</p> Mode <code>DB_MODE_KEY</code> Required Environment Variables Cluster Blob <code>CB</code> (None - Uses application's internal blob storage and encryption) Local Dictionary <code>LC</code> (None - Uses local file storage) Local Redis <code>LR</code> <code>DB_CONNECTION_URI</code> (e.g., <code>redis://localhost:6379</code>) Remote Redis <code>RR</code> <code>DB_CONNECTION_URI</code> or <code>DB_USERNAME</code> &amp; <code>DB_PASSWORD</code> <p>Example <code>.env</code> file for using Local Redis: <pre><code>DB_MODE_KEY=LR\nDB_CONNECTION_URI=redis://localhost:6379\n</code></pre></p>"},{"location":"db_usage_guide/#switching-modes-programmatically","title":"Switching Modes Programmatically","text":"<p>You can switch the database mode at runtime, which is useful for testing or dynamic configuration.</p> <pre><code>from toolboxv2.mods.DB.types import DatabaseModes\n\ndb = app.get_mod(\"DB\")\n\n# Switch to Local Dictionary mode\nresult = db.edit_programmable(mode=DatabaseModes.LC)\n\nif result.is_ok():\n    print(\"Successfully switched DB mode to LOCAL_DICT\")\n\n# The module will automatically close the old connection \n# and initialize the new one.\n</code></pre> <p>This guide covers the primary functionalities of the ToolBoxV2 <code>DB</code> module. By leveraging its abstraction and flexible configuration, you can build robust applications with persistent data storage tailored to your specific needs.</p>"},{"location":"faq/","title":"FAQ","text":""},{"location":"faq/#gei-isaa-redy-in-conda-with-cuda-conda-install-pytorch-torchvision-torchaudio-pytorch-cuda124-c-pytorch-c-nvidia","title":"Gei isaa redy in conda with cuda  # conda install pytorch torchvision torchaudio pytorch-cuda=12.4 -c pytorch -c nvidia","text":""},{"location":"faq/#errors","title":"Errors :","text":""},{"location":"faq/#modulenotfounderror-no-module-named-_cffi_backend-fix-pip-vvv-install-upgrade-force-reinstall-cffi","title":"ModuleNotFoundError: No module named '_cffi_backend' fix -&gt; pip -vvv install --upgrade --force-reinstall cffi","text":""},{"location":"faq/#extraes-langchain-experimental-astor-pyaudio-pebble-transformers-litellm-nltk-gpt4all-speechrecognition-chromadb-pydub-duckduckgo-search-langchain-groq-beautifulsoup4-langchain-huggingface-langchain-langchain-chroma-langchain-ollama-tiktoken","title":"extraes : langchain-experimental astor PyAudio Pebble transformers litellm nltk gpt4all SpeechRecognition chromadb pydub duckduckgo-search langchain-groq beautifulsoup4 langchain-huggingface langchain  langchain-chroma langchain-ollama tiktoken","text":""},{"location":"installation/","title":"ToolBoxV2: Installation Guide","text":"<p>This guide provides instructions for installing ToolBoxV2, whether you need just the core Python library or the full-stack application including the Rust server and Tauri/Web frontend.</p>"},{"location":"installation/#1-installing-the-core-python-library","title":"1. Installing the Core Python Library","text":"<p>This method is suitable if you primarily need to use ToolBoxV2 as a Python library within your own projects or want to develop Python-based modules for it.</p>"},{"location":"installation/#option-a-stable-release-from-pypi-recommended","title":"Option A: Stable Release from PyPI (Recommended)","text":"<p>This is the preferred method for installing the latest stable release of the ToolBoxV2 Python package.</p> <ol> <li> <p>Ensure you have Python and pip:     If you don't have Python and pip installed, this Python installation guide can help. We recommend Python 3.10 or newer.</p> </li> <li> <p>Install ToolBoxV2:     Open your terminal or command prompt and run:     <pre><code>pip install ToolBoxV2\n</code></pre> Consider using a virtual environment to manage project dependencies: <pre><code># Create a virtual environment (optional but recommended)\npython -m venv .venv\n# Activate it (Windows)\n# .venv\\Scripts\\activate\n# Activate it (macOS/Linux)\n# source .venv/bin/activate\n\npip install ToolBoxV2\n</code></pre></p> </li> </ol>"},{"location":"installation/#option-b-from-source-latest-development-version","title":"Option B: From Source (Latest Development Version)","text":"<p>This method allows you to get the very latest code from the GitHub repository, which might include new features or changes not yet in a stable release.</p> <ol> <li> <p>Clone the Repository: <pre><code>git clone https://github.com/MarkinHaus/ToolBoxV2.git\ncd ToolBoxV2\n</code></pre></p> </li> <li> <p>Install in Editable Mode:     This installs the package from your local clone, and any changes you make to the source code will be immediately reflected in your environment.</p> <ul> <li>Using pip: <pre><code># Recommended: Activate a virtual environment first\npip install -e .\n</code></pre></li> <li>Using <code>uv</code> (a fast Python package installer and resolver): <pre><code># Recommended: Activate a virtual environment first\nuv pip install -e .\n</code></pre></li> <li>Using the provided script (sets up environment):     This script creates a virtual environment and installs dependencies.     <pre><code>chmod +x install_python_env.sh\n./install_python_env.sh\n</code></pre></li> </ul> </li> </ol>"},{"location":"installation/#option-c-directly-from-github-with-pip","title":"Option C: Directly from GitHub with pip","text":"<p>You can also install directly from the GitHub repository without cloning it first: <pre><code>pip install git+https://github.com/MarkinHaus/ToolBoxV2.git\n</code></pre></p>"},{"location":"installation/#2-installing-the-full-stack-desktopweb-application","title":"2. Installing the Full Stack Desktop/Web Application","text":"<p>This setup is for developers who want to run or develop the complete ToolBoxV2 application, including the Python backend, Rust server (Actix), and the Tauri-based desktop application or <code>tbjs</code> web frontend.</p>"},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<p>Ensure you have the following installed on your system:</p> <ul> <li>Python: Version 3.10 or higher.</li> <li>Rust and Cargo: Install from rust-lang.org.</li> <li>Node.js and npm/pnpm: Install from nodejs.org. We recommend <code>pnpm</code> for managing Node.js dependencies in this project.<ul> <li>Install <code>pnpm</code> globally: <code>npm install -g pnpm</code></li> </ul> </li> <li>Tauri CLI: Install using Cargo: <code>cargo install tauri-cli</code></li> </ul> <p>Ensure the virtual environment created by the script (or one you created manually) is activated for the subsequent steps.</p> <ol> <li>Install Node.js Dependencies and Build Rust Components:     From the root of the <code>ToolBoxV2</code> directory:     <pre><code>pnpm install  # Installs Node.js dependencies for tbjs and Tauri frontend\n</code></pre>     The Rust backend (<code>src-core/</code>) and Tauri components are typically built as part of the <code>pnpm</code> scripts defined in <code>package.json</code>. If you need to build the Rust core manually:     <pre><code># (Usually not needed if using pnpm scripts)\n# cargo build --release --manifest-path src-core/Cargo.toml\n</code></pre> the build step is Usually handled by the api flow</li> </ol>"},{"location":"installation/#running-the-application-in-cli","title":"Running the Application in CLI","text":"<ul> <li>Row python runner tb <pre><code>tb -c {MOD_NAME} {FUCTION_NAME} {AGRGS} --kwargs name:value\n</code></pre></li> <li>or run in ipython <pre><code>tb --ipy\n</code></pre></li> </ul>"},{"location":"installation/#running-the-application-in-server-mode-for-web-and-desktop","title":"Running the Application in Server mode for web and Desktop","text":"<p>Refer to the scripts in the <code>package.json</code> file for various ways to run and build the application. Common commands include:</p> <ul> <li> <p>Web Development Mode (tbjs frontend with hot-reloading): <pre><code>pnpm dev\n# or live\n</code></pre>     This typically starts the Rust server and the web frontend development server.</p> </li> <li> <p>Tauri Desktop Application (Development Mode): <pre><code>pnpm tauri dev\n</code></pre>     This will build and run the Tauri desktop application with hot-reloading for the frontend.</p> </li> <li> <p>Build Tauri Desktop Application (Production): <pre><code>pnpm tauri build # Or a custom script like `pnpm tauriB` if defined\n</code></pre>     This creates a distributable binary of the desktop application.</p> </li> </ul> <p>For more specific build and run commands, please consult the <code>scripts</code> section in the <code>package.json</code> file located in the <code>ToolBoxV2</code> repository root or use the CLI help: <pre><code>    tb --help\n    # or\n    python -m toolboxv2 --help\n</code></pre></p>"},{"location":"installation/#developing-tip-use-to-activate-all-hooks","title":"developing tip use to activate all hooks","text":"<pre><code>    bash .github/hooks/setup_hooks.sh\n</code></pre>"},{"location":"installation/#auto-version-commit-hook-add-to-the-commit-msg-and-for-auto-summary","title":"auto version commit hook add &lt;#&gt; to the commit msg and  for auto summary","text":""},{"location":"installation/#auto-tagging-of-version-dev-alpha-or-release-tagging-syntax-in-commit-msg","title":"auto tagging of version dev, alpha or release tagging syntax in commit msg <ul> <li>[t:d] for dev</li> <li>[t:a] for alpha and</li> <li>[t:r] for release</li> </ul> <p>all with auto versioning</p>","text":""},{"location":"installation/#pre-commit-hook","title":"pre-commit hook","text":"<p>runs Ruff Bandit Safety versions and on  in the commit msg auto summary of the changes crates an report in local-reports"},{"location":"installation/#_1","title":"????????? <p><pre><code>INSTALLER_URL=\"https://raw.githubusercontent.com/MarkinHaus/ToolBoxV2/refs/heads/master/installer.sh\"; (echo \"Fetching installer script...\" &amp;&amp; curl -sSL -o installer.sh \"$INSTALLER_URL\" &amp;&amp; echo \"Creating default 'init.config'...\" &amp;&amp; cat &lt;&lt;EOL &gt; init.config &amp;&amp; echo \"# ToolBoxV2 Installer Configuration\" &amp;&amp; echo \"# File will be located at: $(pwd)/init.config\" &amp;&amp; echo \"# Modify values below as needed before proceeding.\" &amp;&amp; echo \"# The installer (installer.sh) will use these if this file exists and no arguments are provided to it.\" &amp;&amp; echo \"# --- Example values (uncomment and change if needed): ---\" &amp;&amp; echo \"# TB_VERSION=latest\" &amp;&amp; echo \"# INSTALL_SOURCE=pip\" &amp;&amp; echo \"# PKG_MANAGER=pip\" &amp;&amp; echo \"# PYTHON_VERSION_TARGET=3.11\" &amp;&amp; echo \"# ISAA_EXTRA=false\" &amp;&amp; echo \"# DEV_EXTRA=false\" &amp;&amp; echo \"# INSTALL_LOCATION_TYPE=apps_folder\" &amp;&amp; EOL &amp;&amp; INIT_CONFIG_PATH=\"$(pwd)/init.config\" &amp;&amp; echo -e \"\\n\\033[0;32m\ud83d\udcc4 Default 'init.config' created at:\\033[0m \\033[1;33m$INIT_CONFIG_PATH\\033[0m\" &amp;&amp; echo -e \"   You can review or modify it now in another terminal if you wish.\" &amp;&amp; echo -e \"   The main script (installer.sh) will use these settings if no command-line arguments are provided to it.\" &amp;&amp; read -p \"\u23f3 Press [Enter] to make the installer executable and run it...\" REPLY &amp;&amp; chmod +x installer.sh &amp;&amp; echo \"\ud83d\ude80 Running installer...\" &amp;&amp; ./installer.sh) || echo -e \"\\033[0;31m\u274c An error occurred during the setup process. Please check messages above.\\033[0m\"\n</code></pre> onliner installer</p>","text":""},{"location":"isaa/","title":"ISAA (Intelligent System Agent Architecture) Documentation","text":""},{"location":"isaa/#1-overview","title":"1. Overview","text":"<p>The ISAA (Intelligent System Agent Architecture) module is a sophisticated framework for building, configuring, and orchestrating advanced AI agents. At its core, ISAA now leverages the powerful <code>FlowAgent</code>, a next-generation agent designed for complex reasoning, dynamic planning, and robust tool use.</p> <p>The module provides a high-level API to manage the lifecycle of these agents, from creation and configuration to execution and state management. It is built for asynchronous operations, ensuring high performance in complex, multi-agent workflows.</p> <p>Key Features:</p> <ul> <li>Advanced Agent Core: Powered by the new FlowAgent, which features an outline-driven reasoning loop, sub-system orchestration, and auto-recovery.</li> <li>Builder-Centric Configuration: Uses the <code>FlowAgentBuilder</code> for a fluent, declarative, and serializable approach to agent setup.</li> <li>Stateful Code &amp; File Execution: Each agent is equipped with a <code>ToolsInterface</code>, providing a sandboxed environment for code execution, file system operations, and web browsing.</li> <li>Semantic Memory: Integrates with <code>AISemanticMemory</code> for long-term, persistent knowledge storage and retrieval.</li> <li>Unified Tool System: Seamlessly integrates custom functions, core ISAA utilities, and agent-specific <code>ToolsInterface</code> capabilities.</li> <li>Asynchronous by Design: All primary operations are <code>async</code>, making the system scalable and efficient.</li> </ul>"},{"location":"isaa/#2-core-concepts","title":"2. Core Concepts","text":""},{"location":"isaa/#21-flowagent","title":"2.1. <code>FlowAgent</code>","text":"<p>The <code>FlowAgent</code> is the heart of the ISAA module. It's a highly advanced agent capable of autonomous reasoning and complex task execution.</p> <p>For a comprehensive guide on the internal architecture, capabilities, and API of the <code>FlowAgent</code> itself, please refer to the FlowAgent Documentation.</p> <p>Key characteristics relevant to ISAA include:</p> <ul> <li>Reasoning Core: Makes strategic decisions instead of following rigid plans.</li> <li>Unified Context: Manages conversation history, task status, and variables through a <code>UnifiedContextManager</code>.</li> <li>Dynamic Tool Use: Intelligently analyzes and selects tools based on the immediate context.</li> <li>State Management: Utilizes a powerful, scoped <code>VariableManager</code> to maintain state during execution.</li> </ul>"},{"location":"isaa/#22-flowagentbuilder","title":"2.2. <code>FlowAgentBuilder</code>","text":"<p>The <code>FlowAgentBuilder</code> is the exclusive method for configuring and creating <code>FlowAgent</code> instances. It provides a fluent API that promotes clear and maintainable agent definitions.</p> <ul> <li>Configuration as Code: Define every aspect of an agent\u2014models, persona, tools, and features\u2014programmatically.</li> <li>Serializable Config: The builder's state is backed by a Pydantic model (<code>AgentConfig</code>), allowing any agent's configuration to be saved to and loaded from a JSON or YAML file.</li> <li>Centralized Setup: ISAA uses the builder to inject core tools and system-wide configurations automatically.</li> </ul>"},{"location":"isaa/#23-toolsinterface","title":"2.3. <code>ToolsInterface</code>","text":"<p>Replacing the previous <code>Pipeline</code> system, the <code>ToolsInterface</code> is a stateful execution environment that is directly tied to an agent instance. It provides a powerful set of tools for interacting with the outside world.</p> <ul> <li>Agent-Specific Environment: Each agent gets its own sandboxed <code>ToolsInterface</code> to manage files, execute code, and maintain state without interfering with other agents.</li> <li>Rich Toolset: Provides tools for file I/O (<code>read_file</code>, <code>write_file</code>, <code>list_directory</code>), multi-language code execution (<code>execute_python</code>), and web browsing.</li> <li>Automatic Integration: When an agent is created via <code>isaa.get_agent_builder()</code>, the relevant tools from its <code>ToolsInterface</code> are automatically added to the agent's capabilities.</li> </ul>"},{"location":"isaa/#24-aisemanticmemory","title":"2.4. <code>AISemanticMemory</code>","text":"<p><code>AISemanticMemory</code> serves as the long-term memory for the entire system. Agents can query this memory to retrieve past knowledge or save new information for future use.</p>"},{"location":"isaa/#3-initialization-and-configuration-tools-class","title":"3. Initialization and Configuration (<code>Tools</code> Class)","text":"<p>The <code>Tools</code> class is the main entry point for using the ISAA module.</p> <pre><code>from toolboxv2 import get_app\nfrom toolboxv2.mods.isaa.module import Tools\n\n# Get the application instance\napp = get_app(\"my_application\")\nisaa = app.get_mod(\"isaa\") # Assumes ISAA is registered with the app\n\n# Initialize ISAA (loads configs, sets up defaults)\nasync def initialize_isaa():\n    await isaa.init_isaa()\n    print(\"ISAA initialized.\")\n\n# asyncio.run(initialize_isaa())\n</code></pre>"},{"location":"isaa/#isaaon_exit","title":"<code>isaa.on_exit()</code>","text":"<p>This method ensures that all agent configurations and other states are saved gracefully when the application shuts down.</p>"},{"location":"isaa/#4-agent-management","title":"4. Agent Management","text":"<p>All agent management is now fully asynchronous and builder-oriented.</p>"},{"location":"isaa/#41-getting-an-agent-builder-get_agent_builder","title":"4.1. Getting an Agent Builder (<code>get_agent_builder</code>)","text":"<p>This is the starting point for creating any new agent. It returns a <code>FlowAgentBuilder</code> pre-configured with ISAA's core tools.</p> <pre><code>async def manage_agent_builder():\n    # Get a builder for an agent named \"coder_agent\"\n    coder_builder = isaa.get_agent_builder(\"coder_agent\")\n\n    # Further configure the builder\n    coder_builder.with_models(\n        fast_llm_model=\"openrouter/anthropic/claude-3-haiku\",\n        complex_llm_model=\"openrouter/openai/gpt-4o\"\n    )\n    coder_builder.with_system_message(\"You are a master Python programmer.\")\n\n    return coder_builder\n</code></pre>"},{"location":"isaa/#42-registering-an-agent-async-register_agent","title":"4.2. Registering an Agent (<code>async register_agent</code>)","text":"<p>Once a builder is configured, you register its configuration with ISAA. This saves the agent's definition and makes it available for use.</p> <pre><code>async def register_my_agent():\n    builder = isaa.get_agent_builder(\"my_query_agent\")\n    builder.with_system_message(\"You answer questions based on internal memory.\")\n\n    await isaa.register_agent(builder)\n    print(\"Agent 'my_query_agent' configuration registered.\")\n</code></pre>"},{"location":"isaa/#43-retrieving-an-agent-instance-async-get_agent","title":"4.3. Retrieving an Agent Instance (<code>async get_agent</code>)","text":"<p>This method builds (or retrieves from a cache) a fully operational <code>FlowAgent</code> instance from a registered configuration.</p> <pre><code>async def retrieve_and_use_agent():\n    # This will build the agent if it's the first time it's requested\n    my_agent = await isaa.get_agent(\"my_query_agent\")\n\n    response = await my_agent.a_run(\"What is the capital of France?\")\n    print(response)\n</code></pre>"},{"location":"isaa/#5-running-agents-and-tasks","title":"5. Running Agents and Tasks","text":""},{"location":"isaa/#51-running-an-agent-async-run_agent","title":"5.1. Running an Agent (<code>async run_agent</code>)","text":"<p>The primary method for interacting with a registered agent by name.</p> <pre><code>async def run_specific_agent():\n    # Register a simple agent if it doesn't exist\n    if \"responder\" not in isaa.config.get(\"agents-name-list\", []):\n        builder = isaa.get_agent_builder(\"responder\")\n        await isaa.register_agent(builder)\n\n    # Use a session_id for conversations with persistent history\n    session_id = \"user123_chat\"\n    response1 = await isaa.run_agent(\"responder\", \"My favorite color is blue.\", session_id=session_id)\n    response2 = await isaa.run_agent(\"responder\", \"What is my favorite color?\", session_id=session_id)\n    print(f\"Agent remembers: {response2}\")\n</code></pre>"},{"location":"isaa/#52-structured-output-async-format_class","title":"5.2. Structured Output (<code>async format_class</code>)","text":"<p>Leverage an agent's reasoning to structure output according to a Pydantic model.</p> <pre><code>from pydantic import BaseModel, Field\nfrom typing import List\n\nclass UserProfile(BaseModel):\n    name: str = Field(description=\"The user's full name.\")\n    age: int = Field(description=\"The user's age.\")\n    interests: List[str] = Field(description=\"A list of the user's interests.\")\n\nasync def get_structured_info():\n    profile_dict = await isaa.format_class(\n        UserProfile,\n        \"The user is Alice Smith. She is 30 years old and enjoys hiking and photography.\"\n    )\n    if profile_dict:\n        profile = UserProfile(**profile_dict)\n        print(f\"Parsed User: {profile.name}, Interests: {profile.interests}\")\n</code></pre>"},{"location":"isaa/#6-code-execution-with-toolsinterface","title":"6. Code Execution with <code>ToolsInterface</code>","text":"<p>The <code>ToolsInterface</code> provides a powerful, stateful environment for each agent to execute code, manage files, and interact with the web. You do not interact with the <code>ToolsInterface</code> directly. Instead, you instruct the agent to use the tools that ISAA has automatically provided from the interface.</p> <p>The agent's reasoner is aware of these tools and will use them when a task requires it.</p> <p>Example: Instructing an agent to use its file and code tools. <pre><code>async def execute_code_task():\n    # 1. Get a builder for a coding agent. ISAA will automatically add\n    #    code and file tools from the ToolsInterface.\n    coder_builder = isaa.get_agent_builder(\"PyCoder\")\n    coder_builder.with_system_message(\n        \"You are a Python coding assistant. You write and execute Python code to solve problems.\"\n    )\n    await isaa.register_agent(coder_builder)\n\n    # 2. Get the agent instance\n    coder_agent = await isaa.get_agent(\"PyCoder\")\n\n    # 3. Give the agent a multi-step task involving file I/O and code execution\n    task_prompt = (\n        \"First, create a Python script named 'hello.py' that prints 'Hello from ISAA!'. \"\n        \"Then, execute that script and show me the output.\"\n    )\n\n    # The agent's reasoner will create an outline:\n    # - Step 1: Use the `createScript` tool to write the file.\n    # - Step 2: Use the `runScript` tool to execute it.\n    # - Step 3: Return the captured output.\n    response = await coder_agent.a_run(task_prompt)\n    print(\"--- Agent Response ---\")\n    print(response)\n</code></pre></p>"},{"location":"isaa/#7-semantic-memory-aisemanticmemory","title":"7. Semantic Memory (<code>AISemanticMemory</code>)","text":"<p>Agents can interact with the shared semantic memory through the tools provided by ISAA.</p> <pre><code>async def use_semantic_memory():\n    # Get a general-purpose agent\n    agent = await isaa.get_agent(\"self\")\n\n    # Instruct the agent to save information\n    await agent.a_run(\"Please remember that the project codename is 'Orion'.\", session_id=\"project_orion\")\n\n    # Later, in the same or a different session, instruct it to retrieve the information\n    response = await agent.a_run(\"What is the project codename?\", session_id=\"project_orion\")\n\n    print(response) # The agent will use its `memorySearch` tool to find the answer.\n</code></pre>"},{"location":"isaa/#8-tool-integration","title":"8. Tool Integration","text":"<p>The <code>FlowAgentBuilder</code> is the central point for tool management. ISAA's <code>get_agent_builder</code> method automatically equips new builders with a powerful set of default tools.</p>"},{"location":"isaa/#default-isaa-tools","title":"Default ISAA Tools","text":"<ul> <li>Core Tools: <code>searchWeb</code>, <code>shell</code>.</li> <li>Memory Tools: <code>memorySearch</code>, <code>saveDataToMemory</code>.</li> <li>Scripting Tools: <code>createScript</code>, <code>runScript</code>, <code>listScripts</code>, <code>deleteScript</code>.</li> <li><code>ToolsInterface</code> Tools: A suite of tools for file management (<code>write_file</code>, <code>read_file</code>, <code>list_directory</code>), code execution (<code>execute_python</code>), and more, tailored to the agent's purpose.</li> </ul>"},{"location":"isaa/#adding-your-own-tools","title":"Adding Your Own Tools","text":"<p>You can easily add your own custom functions to any agent builder. <pre><code># 1. Define your custom async function\nasync def get_database_user_count() -&gt; int:\n    \"\"\"Returns the current number of users in the database.\"\"\"\n    # In a real scenario, this would connect to a database\n    return 1337\n\n# 2. Get a builder and add your tool\nmy_builder = isaa.get_agent_builder(\"db_agent\")\nmy_builder.add_tool(\n    get_database_user_count,\n    name=\"getUserCount\",\n    description=\"Fetches the total number of users from the main database.\"\n)\n\n# 3. Register and use the agent\nawait isaa.register_agent(my_builder)\ndb_agent = await isaa.get_agent(\"db_agent\")\nresponse = await db_agent.a_run(\"How many users are in the system?\")\nprint(response)\n</code></pre></p>"},{"location":"isaa/#9-example-usage-flow","title":"9. Example Usage Flow","text":"<p>This example demonstrates a complete workflow: creating an agent, giving it a complex task that requires file I/O and code execution, and getting the final result.</p> <pre><code>import asyncio\nfrom toolboxv2 import get_app\nfrom toolboxv2.mods.isaa.module import Tools\n\n# --- Setup ---\napp = get_app(\"isaa_demo_app\")\nisaa = app.get_mod(\"isaa\")\n\nasync def main_demo():\n    # 1. Initialize ISAA\n    await isaa.init_isaa()\n    print(\"ISAA Initialized.\")\n\n    # 2. Get a builder for a \"DataProcessor\" agent.\n    #    ISAA will automatically add file and code execution tools.\n    data_builder = isaa.get_agent_builder(\"DataProcessor\")\n    data_builder.with_system_message(\n        \"You are a data processing specialist. You write Python scripts to \"\n        \"manipulate data, save it to files, and read it back.\"\n    )\n    data_builder.with_models(\n        fast_llm_model=\"openrouter/anthropic/claude-3-haiku\",\n        complex_llm_model=\"openrouter/openai/gpt-4o\"\n    )\n\n    # 3. Register the agent's configuration\n    await isaa.register_agent(data_builder)\n    print(\"DataProcessor agent registered.\")\n\n    # 4. Get the agent instance\n    data_agent = await isaa.get_agent(\"DataProcessor\")\n\n    # 5. Define a multi-step task for the agent\n    user_task = (\n        \"I need you to perform a data processing task. Here are the steps:\\n\"\n        \"1. Create a Python script called 'process.py'.\\n\"\n        \"2. The script should create a list of numbers from 1 to 10 and calculate their sum.\\n\"\n        \"3. It must then write the result to a file named 'result.txt' in the format: 'The sum is: [sum]'.\\n\"\n        \"4. After creating the script, execute it.\\n\"\n        \"5. Finally, read the content of 'result.txt' and tell me what it says.\"\n    )\n\n    print(f\"\\n--- Running Agent for Task ---\\n{user_task}\\n\")\n\n    # 6. Run the agent\n    # The agent will use its internal reasoner to create an outline and use its\n    # `createScript`, `runScript`, and `read_file` tools to complete the task.\n    final_response = await data_agent.a_run(user_task, session_id=\"data_processing_task_01\")\n\n    print(\"\\n--- Final Agent Response ---\")\n    print(final_response)\n\n    # 7. Check the agent's status\n    print(\"\\n--- Agent Status ---\")\n    data_agent.status(pretty_print=True)\n\n    await data_agent.close()\n\n# --- Run the Demo ---\nasyncio.run(main_demo())\n</code></pre>"},{"location":"isaa/#10-important-notes","title":"10. Important Notes","text":"<ul> <li>Asynchronous First: The entire ISAA module is built around <code>asyncio</code>. Ensure your code is running in an async context.</li> <li>Configuration is Key: An agent's performance is highly dependent on its configuration, especially its system message, persona, and the tools it has access to.</li> <li>Security: Be extremely cautious when using tools that can execute code (<code>execute_python</code>) or shell commands (<code>shell</code>). The default <code>ToolsInterface</code> is sandboxed to a specific directory, but care should always be taken. Avoid exposing these agents to untrusted inputs.</li> <li>State and Sessions: Use <code>session_id</code> to maintain distinct conversational contexts for different users or tasks. The agent's memory and state are tied to this ID.</li> </ul>"},{"location":"isaa/#overview","title":"Overview","text":"<p>The Chain system provides a powerful way to orchestrate multiple ISAA agents in complex workflows. Chains allow you to create sophisticated AI pipelines with sequential execution, parallel processing, conditional branching, error handling, and automatic data formatting between agents.</p>"},{"location":"isaa/#core-concepts","title":"Core Concepts","text":""},{"location":"isaa/#1-basic-chain-operations","title":"1. Basic Chain Operations","text":"<p>The chain system uses intuitive operators to define workflows:</p> <ul> <li><code>&gt;&gt;</code> : Sequential execution (pipe operator)</li> <li><code>+</code> or <code>&amp;</code> : Parallel execution</li> <li><code>%</code> : Conditional branching</li> <li><code>|</code> : Error handling (try/catch)</li> <li><code>-</code> : Data extraction and formatting</li> </ul>"},{"location":"isaa/#2-chain-components","title":"2. Chain Components","text":""},{"location":"isaa/#cf-chain-format","title":"CF (Chain Format)","text":"<p>Handles data transformation and extraction between agents using Pydantic models.</p> <pre><code>from pydantic import BaseModel\n\nclass UserProfile(BaseModel):\n    name: str\n    age: int\n    interests: list[str]\n\n# Create a formatter\nprofile_format = CF(UserProfile)\n</code></pre>"},{"location":"isaa/#is-conditional-check","title":"IS (Conditional Check)","text":"<p>Creates conditional logic based on data values.</p> <pre><code># Check if age is over 18\nadult_check = IS(\"age\", 18)\n</code></pre>"},{"location":"isaa/#basic-usage","title":"Basic Usage","text":""},{"location":"isaa/#1-setting-up-agents-for-chaining","title":"1. Setting Up Agents for Chaining","text":"<pre><code>import asyncio\nfrom toolboxv2 import get_app\n\n# Initialize ISAA\napp = get_app(\"chain_demo\")\nisaa = app.get_mod(\"isaa\")\nawait isaa.init_isaa()\n\n# Create specialized agents\nasync def setup_agents():\n    # Data extractor agent\n    extractor_builder = isaa.get_agent_builder(\"data_extractor\")\n    extractor_builder.with_system_message(\n        \"You extract structured information from text. Always provide complete, accurate data.\"\n    )\n    await isaa.register_agent(extractor_builder)\n\n    # Analyzer agent\n    analyzer_builder = isaa.get_agent_builder(\"analyzer\")\n    analyzer_builder.with_system_message(\n        \"You analyze data and provide insights and recommendations.\"\n    )\n    await isaa.register_agent(analyzer_builder)\n\n    # Report generator\n    reporter_builder = isaa.get_agent_builder(\"reporter\")\n    reporter_builder.with_system_message(\n        \"You create detailed reports from analysis data.\"\n    )\n    await isaa.register_agent(reporter_builder)\n\nawait setup_agents()\n</code></pre>"},{"location":"isaa/#2-simple-sequential-chain","title":"2. Simple Sequential Chain","text":"<pre><code>async def simple_sequential_chain():\n    # Get agent instances\n    extractor = await isaa.get_agent(\"data_extractor\")\n    analyzer = await isaa.get_agent(\"analyzer\")\n    reporter = await isaa.get_agent(\"reporter\")\n\n    # Create a sequential chain\n    chain = extractor &gt;&gt; analyzer &gt;&gt; reporter\n\n    # Execute the chain\n    user_text = \"John Smith is 25 years old and loves hiking, photography, and cooking.\"\n    result = await chain.a_run(user_text)\n\n    print(\"Final Report:\", result)\n\n# Run the chain\nawait simple_sequential_chain()\n</code></pre>"},{"location":"isaa/#advanced-chain-features","title":"Advanced Chain Features","text":""},{"location":"isaa/#1-data-formatting-with-cf","title":"1. Data Formatting with CF","text":"<pre><code>from pydantic import BaseModel\nfrom typing import List\n\nclass PersonData(BaseModel):\n    name: str\n    age: int\n    interests: List[str]\n    location: str = \"Unknown\"\n\nclass Analysis(BaseModel):\n    profile_summary: str\n    recommendations: List[str]\n    risk_score: int\n\nasync def formatted_chain():\n    extractor = await isaa.get_agent(\"data_extractor\")\n    analyzer = await isaa.get_agent(\"analyzer\")\n\n    # Chain with structured data formatting\n    chain = (\n        extractor &gt;&gt;\n        CF(PersonData) &gt;&gt;\n        analyzer &gt;&gt;\n        CF(Analysis)\n    )\n\n    user_input = \"Sarah Johnson, 28, lives in Seattle. Enjoys rock climbing, programming, and yoga.\"\n\n    result = await chain.a_run(user_input)\n    print(\"Structured Result:\", result)\n\nawait formatted_chain()\n</code></pre>"},{"location":"isaa/#2-data-extraction-with-key-selection","title":"2. Data Extraction with Key Selection","text":"<pre><code>async def extraction_chain():\n    extractor = await isaa.get_agent(\"data_extractor\")\n    analyzer = await isaa.get_agent(\"analyzer\")\n\n    # Extract specific fields using the - operator\n    chain = (\n        extractor &gt;&gt;\n        CF(PersonData) - \"interests\" &gt;&gt;  # Extract only interests\n        analyzer\n    )\n\n    # Extract multiple fields\n    multi_extract_chain = (\n        extractor &gt;&gt;\n        CF(PersonData) - (\"name\", \"age\") &gt;&gt;  # Extract name and age\n        analyzer\n    )\n\n    # Extract all fields\n    all_extract_chain = (\n        extractor &gt;&gt;\n        CF(PersonData) - \"*\" &gt;&gt;  # Extract everything\n        analyzer\n    )\n\n    user_input = \"Mike loves surfing and coding. He's 30 years old.\"\n\n    result1 = await chain.a_run(user_input)\n    result2 = await multi_extract_chain.a_run(user_input)\n    result3 = await all_extract_chain.a_run(user_input)\n\n    print(\"Interests only:\", result1)\n    print(\"Name and age:\", result2)\n    print(\"All data:\", result3)\n\nawait extraction_chain()\n</code></pre>"},{"location":"isaa/#3-parallel-processing","title":"3. Parallel Processing","text":"<pre><code>async def parallel_chain():\n    analyzer = await isaa.get_agent(\"analyzer\")\n    reporter = await isaa.get_agent(\"reporter\")\n\n    # Create a specialized summarizer\n    summarizer_builder = isaa.get_agent_builder(\"summarizer\")\n    summarizer_builder.with_system_message(\"You create concise summaries.\")\n    await isaa.register_agent(summarizer_builder)\n\n    summarizer = await isaa.get_agent(\"summarizer\")\n\n    # Parallel execution using + operator\n    parallel_chain = analyzer + reporter + summarizer\n\n    # Sequential then parallel\n    extractor = await isaa.get_agent(\"data_extractor\")\n    complex_chain = extractor &gt;&gt; (analyzer + reporter)\n\n    data = \"Complex project data with multiple stakeholders and requirements...\"\n\n    # This will run analyzer, reporter, and summarizer simultaneously\n    parallel_result = await parallel_chain.a_run(data)\n    print(\"Parallel Results:\", parallel_result)\n\n    # This will run extractor first, then analyzer and reporter in parallel\n    complex_result = await complex_chain.a_run(data)\n    print(\"Complex Chain Result:\", complex_result)\n\nawait parallel_chain()\n</code></pre>"},{"location":"isaa/#4-auto-parallel-processing","title":"4. Auto-Parallel Processing","text":"<pre><code>class TaskList(BaseModel):\n    tasks: List[str]\n    priority: str\n\nasync def auto_parallel_chain():\n    extractor = await isaa.get_agent(\"data_extractor\")\n    analyzer = await isaa.get_agent(\"analyzer\")\n\n    # Auto-parallel: Process each task in the list simultaneously\n    chain = (\n        extractor &gt;&gt;\n        CF(TaskList) - \"tasks[n]\" &gt;&gt;  # [n] creates auto-parallel\n        analyzer\n    )\n\n    input_text = \"\"\"\n    I have these tasks to analyze:\n    - Review quarterly reports\n    - Plan next sprint\n    - Update documentation\n    - Conduct team interviews\n    \"\"\"\n\n    # The analyzer will process each task in parallel automatically\n    results = await chain.a_run(input_text)\n    print(\"Auto-parallel Results:\", results)\n\nawait auto_parallel_chain()\n</code></pre>"},{"location":"isaa/#5-conditional-chains","title":"5. Conditional Chains","text":"<pre><code>async def conditional_chain():\n    extractor = await isaa.get_agent(\"data_extractor\")\n    analyzer = await isaa.get_agent(\"analyzer\")\n    reporter = await isaa.get_agent(\"reporter\")\n\n    # Create a simple approval agent\n    approver_builder = isaa.get_agent_builder(\"approver\")\n    approver_builder.with_system_message(\n        \"You approve or reject based on criteria. Return 'approved' or 'rejected'.\"\n    )\n    await isaa.register_agent(approver_builder)\n    approver = await isaa.get_agent(\"approver\")\n\n    # Conditional chain: different paths based on approval\n    chain = (\n        extractor &gt;&gt;\n        approver &gt;&gt;\n        IS(\"status\", \"approved\") &gt;&gt; reporter %  # If approved, generate report\n        analyzer  # If not approved, send to analyzer for revision\n    )\n\n    approved_request = \"This is a well-structured, reasonable business proposal.\"\n    rejected_request = \"This request lacks proper documentation and justification.\"\n\n    result1 = await chain.a_run(approved_request)  # Goes to reporter\n    result2 = await chain.a_run(rejected_request)  # Goes to analyzer\n\n    print(\"Approved path result:\", result1)\n    print(\"Rejected path result:\", result2)\n\nawait conditional_chain()\n</code></pre>"},{"location":"isaa/#6-error-handling-chains","title":"6. Error Handling Chains","text":"<pre><code>async def error_handling_chain():\n    # Create a potentially failing agent\n    risky_builder = isaa.get_agent_builder(\"risky_processor\")\n    risky_builder.with_system_message(\n        \"You process data but sometimes fail. Randomly throw errors for demonstration.\"\n    )\n    await isaa.register_agent(risky_builder)\n\n    risky_agent = await isaa.get_agent(\"risky_processor\")\n    safe_agent = await isaa.get_agent(\"analyzer\")  # Fallback\n\n    # Error handling chain using | operator\n    chain = risky_agent | safe_agent\n\n    # If risky_agent fails, safe_agent will handle it\n    try:\n        result = await chain.a_run(\"Process this potentially problematic data\")\n        print(\"Chain completed:\", result)\n    except Exception as e:\n        print(\"Chain failed despite fallback:\", e)\n\nawait error_handling_chain()\n</code></pre>"},{"location":"isaa/#complex-workflow-examples","title":"Complex Workflow Examples","text":""},{"location":"isaa/#1-multi-stage-document-processing","title":"1. Multi-Stage Document Processing","text":"<pre><code>class DocumentMetadata(BaseModel):\n    title: str\n    author: str\n    document_type: str\n    complexity_score: int\n\nclass ProcessingResult(BaseModel):\n    summary: str\n    key_points: List[str]\n    action_items: List[str]\n\nasync def document_processing_workflow():\n    # Set up specialized agents\n    metadata_extractor = await isaa.get_agent(\"data_extractor\")\n    content_analyzer = await isaa.get_agent(\"analyzer\")\n    summarizer = await isaa.get_agent(\"summarizer\")\n    action_extractor = await isaa.get_agent(\"reporter\")\n\n    # Complex multi-path workflow\n    workflow = (\n        metadata_extractor &gt;&gt;\n        CF(DocumentMetadata) &gt;&gt;\n        # Branch based on complexity\n        (IS(\"complexity_score\", \"high\") &gt;&gt;\n         (content_analyzer + summarizer) &gt;&gt;  # Parallel processing for complex docs\n         action_extractor) %\n        (summarizer &gt;&gt; action_extractor) &gt;&gt;  # Simple path for easy docs\n        CF(ProcessingResult)\n    )\n\n    complex_doc = \"\"\"\n    Title: Advanced AI Architecture Proposal\n    Author: Dr. Sarah Chen\n    Type: Technical Specification\n\n    This document outlines a comprehensive approach to implementing\n    next-generation AI systems with distributed processing capabilities...\n    [Complex technical content continues...]\n    \"\"\"\n\n    simple_doc = \"\"\"\n    Title: Meeting Notes\n    Author: John Smith\n    Type: Meeting Minutes\n\n    Brief discussion about quarterly goals and upcoming deadlines.\n    \"\"\"\n\n    complex_result = await workflow.a_run(complex_doc)\n    simple_result = await workflow.a_run(simple_doc)\n\n    print(\"Complex Document Result:\", complex_result)\n    print(\"Simple Document Result:\", simple_result)\n\nawait document_processing_workflow()\n</code></pre>"},{"location":"isaa/#2-customer-service-chain","title":"2. Customer Service Chain","text":"<pre><code>class CustomerInquiry(BaseModel):\n    customer_id: str\n    inquiry_type: str\n    priority: str\n    issue_description: str\n\nclass ServiceResponse(BaseModel):\n    response_text: str\n    escalation_needed: bool\n    follow_up_required: bool\n    estimated_resolution_time: str\n\nasync def customer_service_chain():\n    # Specialized customer service agents\n    classifier = await isaa.get_agent(\"data_extractor\")  # Classifies inquiries\n    support_agent = await isaa.get_agent(\"analyzer\")     # Handles standard issues\n    specialist = await isaa.get_agent(\"reporter\")        # Handles complex issues\n\n    # Customer service workflow\n    service_chain = (\n        classifier &gt;&gt;\n        CF(CustomerInquiry) &gt;&gt;\n        # Route based on priority\n        (IS(\"priority\", \"high\") &gt;&gt; specialist) %      # High priority to specialist\n        (IS(\"priority\", \"medium\") &gt;&gt; support_agent) %  # Medium to support\n        support_agent &gt;&gt;                               # Low to standard support\n        CF(ServiceResponse) |\n        # Fallback for any errors\n        \"I apologize, but I'm unable to process your request right now. Please contact our support team directly.\"\n    )\n\n    high_priority = \"\"\"\n    Customer ID: CUST001\n    Issue: Critical system outage affecting production\n    Priority: HIGH\n    Description: Our entire payment system is down, affecting thousands of transactions.\n    \"\"\"\n\n    low_priority = \"\"\"\n    Customer ID: CUST002\n    Issue: Question about account settings\n    Priority: LOW\n    Description: How do I change my email preferences?\n    \"\"\"\n\n    high_result = await service_chain.a_run(high_priority)\n    low_result = await service_chain.a_run(low_priority)\n\n    print(\"High Priority Response:\", high_result)\n    print(\"Low Priority Response:\", low_result)\n\nawait customer_service_chain()\n</code></pre>"},{"location":"isaa/#chain-visualization-and-debugging","title":"Chain Visualization and Debugging","text":""},{"location":"isaa/#1-visualize-chain-structure","title":"1. Visualize Chain Structure","text":"<pre><code>async def visualize_chain():\n    extractor = await isaa.get_agent(\"data_extractor\")\n    analyzer = await isaa.get_agent(\"analyzer\")\n    reporter = await isaa.get_agent(\"reporter\")\n\n    # Create a complex chain\n    complex_chain = (\n        extractor &gt;&gt;\n        CF(PersonData) - \"interests[n]\" &gt;&gt;  # Auto-parallel\n        (analyzer + reporter) &gt;&gt;            # Parallel processing\n        CF(Analysis) |                      # Error handling\n        \"Fallback response\"\n    )\n\n    # Visualize the chain structure\n    complex_chain.print_graph()\n\nawait visualize_chain()\n</code></pre>"},{"location":"isaa/#2-progress-tracking","title":"2. Progress Tracking","text":"<pre><code>from toolboxv2.mods.isaa.base.Agent.types import ProgressEvent\n\nclass ChainProgressTracker:\n    def __init__(self):\n        self.events = []\n\n    async def emit_event(self, event: ProgressEvent):\n        self.events.append(event)\n        print(f\"[{event.event_type}] {event.node_name}: {event.status}\")\n\nasync def tracked_chain():\n    extractor = await isaa.get_agent(\"data_extractor\")\n    analyzer = await isaa.get_agent(\"analyzer\")\n\n    chain = extractor &gt;&gt; analyzer\n\n    # Set up progress tracking\n    tracker = ChainProgressTracker()\n    chain.set_progress_callback(tracker)\n\n    result = await chain.a_run(\"Process this data with tracking\")\n\n    print(\"\\nProgress Events:\")\n    for event in tracker.events:\n        print(f\"  {event.timestamp}: {event.event_type} - {event.node_name}\")\n\nawait tracked_chain()\n</code></pre>"},{"location":"isaa/#best-practices","title":"Best Practices","text":""},{"location":"isaa/#1-agent-specialization","title":"1. Agent Specialization","text":"<pre><code>async def specialized_agents_example():\n    # Create highly specialized agents for better chain performance\n\n    # JSON extractor\n    json_extractor_builder = isaa.get_agent_builder(\"json_extractor\")\n    json_extractor_builder.with_system_message(\n        \"You extract data and return it in valid JSON format. Always use proper JSON syntax.\"\n    )\n    await isaa.register_agent(json_extractor_builder)\n\n    # Validator agent\n    validator_builder = isaa.get_agent_builder(\"validator\")\n    validator_builder.with_system_message(\n        \"You validate data for completeness and accuracy. Return 'valid' or 'invalid' with reasons.\"\n    )\n    await isaa.register_agent(validator_builder)\n\n    # Clean chain with specialized agents\n    extraction_chain = (\n        await isaa.get_agent(\"json_extractor\") &gt;&gt;\n        CF(PersonData) &gt;&gt;\n        await isaa.get_agent(\"validator\") &gt;&gt;\n        await isaa.get_agent(\"analyzer\")\n    )\n\n    return extraction_chain\n</code></pre>"},{"location":"isaa/#2-error-recovery-patterns","title":"2. Error Recovery Patterns","text":"<pre><code>async def robust_chain_pattern():\n    primary_agent = await isaa.get_agent(\"analyzer\")\n    backup_agent = await isaa.get_agent(\"data_extractor\")\n\n    # Multi-layer error recovery\n    robust_chain = (\n        primary_agent |                    # Try primary\n        (backup_agent &gt;&gt; primary_agent) |  # Try backup + primary\n        \"Unable to process request\"        # Final fallback\n    )\n\n    return robust_chain\n</code></pre>"},{"location":"isaa/#3-performance-optimization","title":"3. Performance Optimization","text":"<pre><code>async def optimized_chain():\n    # Use parallel processing for independent operations\n    extractor = await isaa.get_agent(\"data_extractor\")\n    analyzer1 = await isaa.get_agent(\"analyzer\")\n    analyzer2 = await isaa.get_agent(\"reporter\")  # Different analysis\n\n    # Optimize: parallel analysis, then combine\n    optimized = (\n        extractor &gt;&gt;\n        CF(PersonData) &gt;&gt;\n        (analyzer1 + analyzer2) &gt;&gt;  # Parallel analysis\n        await isaa.get_agent(\"summarizer\")  # Combine results\n    )\n\n    return optimized\n</code></pre>"},{"location":"isaa/#direckt-call-support","title":"Direckt call Support","text":"<ul> <li>chain(...) \u2192 ruft sofort run</li> <li>await chain(...) \u2192 ruft automatisch a_run</li> </ul>"},{"location":"isaa/#chain-operators-reference","title":"Chain Operators Reference","text":"Operator Purpose Example <code>&gt;&gt;</code> Sequential execution <code>agent1 &gt;&gt; agent2</code> <code>+</code> Parallel execution <code>agent1 + agent2</code> <code>&amp;</code> Parallel execution (alias) <code>agent1 &amp; agent2</code> <code>%</code> False branch in conditional <code>condition &gt;&gt; true_branch % false_branch</code> <code>\\|</code> Error handling fallback <code>risky_agent \\| safe_agent</code> <code>-</code> Data extraction <code>CF(Model) - \"field\"</code>"},{"location":"isaa/#cf-chain-format-reference","title":"CF (Chain Format) Reference","text":"Pattern Purpose Example <code>CF(Model)</code> Format to Pydantic model <code>CF(UserProfile)</code> <code>CF(Model) - \"field\"</code> Extract single field <code>CF(User) - \"name\"</code> <code>CF(Model) - (\"f1\", \"f2\")</code> Extract multiple fields <code>CF(User) - (\"name\", \"age\")</code> <code>CF(Model) - \"*\"</code> Extract all fields <code>CF(User) - \"*\"</code> <code>CF(Model) - \"field[n]\"</code> Auto-parallel extraction <code>CF(Tasks) - \"tasks[n]\"</code> <p>This documentation provides comprehensive guidance for using the ISAA Chain system to create sophisticated AI agent workflows with powerful orchestration capabilities.</p>"},{"location":"module_creation_guide/","title":"ToolBoxV2 Module Creation Guide","text":"<p>This guide provides a comprehensive overview of how to create, structure, and integrate new modules within the ToolBoxV2 framework. It is intended for both human developers and AI agents.</p>"},{"location":"module_creation_guide/#1-core-concepts","title":"1. Core Concepts","text":"<p>A ToolBoxV2 module is a self-contained unit of functionality that plugs into the main application. It can expose functions to the system, provide API endpoints, and render user interfaces.</p>"},{"location":"module_creation_guide/#key-components-of-a-module","title":"Key Components of a Module:","text":"<ul> <li>Module File: A Python file (e.g., <code>MyModule.py</code>) located in the <code>toolboxv2/mods/</code> directory.</li> <li><code>get_app</code> and <code>export</code>: The entry point for connecting your module to the ToolBoxV2 application instance.</li> <li><code>@export</code> Decorator: The primary mechanism for registering functions and defining their behavior (e.g., as API endpoints, lifecycle hooks, etc.).</li> <li><code>Tools</code> Class (Optional but Recommended): A class that inherits from <code>MainTool</code> to organize your module's logic, state, and lifecycle methods (<code>on_start</code>, <code>on_exit</code>).</li> <li><code>RequestData</code> and <code>Result</code> Objects: Standardized Pydantic models for handling incoming requests and formatting outgoing responses, ensuring consistency across the framework.</li> </ul>"},{"location":"module_creation_guide/#2-module-structure-a-boilerplate","title":"2. Module Structure: A Boilerplate","text":"<p>Here is a standard boilerplate for a new module file (e.g., <code>toolboxv2/mods/MyNewModule.py</code>):</p> <pre><code># toolboxv2/mods/MyNewModule.py\n\nfrom toolboxv2 import App, Result, RequestData, get_app, MainTool\nfrom typing import Dict, Optional\n\n# -- Constants ---\nMOD_NAME = \"MyNewModule\"\nVERSION = \"1.0.0\"\n\n# -- Module Export ---\n# This makes the @export decorator available for this module.\nexport = get_app(f\"mods.{MOD_NAME}\").tb\n\n# -- Main Logic Class (Recommended) ---\nclass Tools(MainTool):\n    def __init__(self, app: App):\n        self.app = app\n        self.name = MOD_NAME\n        self.version = VERSION\n        # You can define CLI tools here if needed\n        self.tools = {\n            \"all\": [[\"show_version\", \"Displays the module version\"]],\n            \"name\": self.name,\n            \"show_version\": self.show_version,\n        }\n        super().__init__(\n            load=self.on_start, # Corresponds to @export(initial=True)\n            v=self.version,\n            tool=self.tools,\n            name=self.name,\n            on_exit=self.on_exit # Corresponds to @export(exit_f=True)\n        )\n\n    def on_start(self):\n        \"\"\"Called when the module is loaded.\"\"\"\n        self.app.logger.info(f\"{self.name} v{self.version} initialized.\")\n        # Example: Registering a UI component with another module\n        self.app.run_any((\"CloudM\", \"add_ui\"),\n                         name=self.name,\n                         title=self.name,\n                         path=f\"/api/{self.name}/ui\",\n                         description=\"A description of my module's UI.\",\n                         auth=True\n                         )\n\n    def on_exit(self):\n        \"\"\"Called when the application is shutting down.\"\"\"\n        self.app.logger.info(f\"Closing {self.name}. Goodbye!\")\n\n    def show_version(self):\n        return self.version\n\n# -- API Endpoints &amp; Functions ---\n\n@export(mod_name=MOD_NAME, name=\"ui\", api=True, api_methods=[\"GET\"])\nasync def get_main_ui(self) -&gt; Result:\n    \"\"\"Serves the main HTML UI for the module.\"\"\"\n    # The 'self' here will be the instance of the Tools class\n    html_content = \"&lt;h1&gt;Welcome to MyNewModule!&lt;/h1&gt;\"\n    return Result.html(data=html_content)\n\n@export(mod_name=MOD_NAME, name=\"get_data\", api=True, request_as_kwarg=True)\nasync def get_some_data(self, request: RequestData) -&gt; Result:\n    \"\"\"An example API endpoint to fetch data.\"\"\"\n    user = await self.app.run_any((\"WidgetsProvider\", \"get_user_from_request\"), request=request)\n    user_name = user.name if user else \"Guest\"\n    return Result.json(data={\"message\": f\"Hello, {user_name}!\", \"module\": self.name})\n</code></pre>"},{"location":"module_creation_guide/#3-the-export-decorator","title":"3. The <code>@export</code> Decorator","text":"<p>The <code>@export</code> decorator is the most critical part of creating a module. It tells ToolBoxV2 how to treat your function. Here are the key parameters:</p> <ul> <li><code>mod_name</code> (str): Required. The name of your module. Must match <code>MOD_NAME</code>.</li> <li><code>name</code> (str): The name to expose the function under. If omitted, the Python function name is used.</li> <li><code>api</code> (bool): If <code>True</code>, the function becomes an HTTP API endpoint accessible at <code>/api/MOD_NAME/function_name</code>.</li> <li><code>api_methods</code> (List[str]): A list of allowed HTTP methods (e.g., <code>[\"GET\", \"POST\"]</code>).</li> <li><code>request_as_kwarg</code> (bool): If <code>True</code>, the <code>RequestData</code> object will be passed as a keyword argument to your function.</li> <li><code>initial</code> (bool): If <code>True</code>, the function is an initialization hook and runs when the module is first loaded.</li> <li><code>exit_f</code> (bool): If <code>True</code>, the function is a cleanup hook and runs when the application exits.</li> <li><code>row</code> (bool): If <code>True</code>, the function's raw return value is sent as the response body, bypassing the <code>Result</code> object wrapper. Useful for serving files or raw text.</li> <li><code>level</code> (int): An integer indicating the privilege level required to execute the function.</li> </ul>"},{"location":"module_creation_guide/#4-handling-requests-and-responses","title":"4. Handling Requests and Responses","text":""},{"location":"module_creation_guide/#the-requestdata-object","title":"The <code>RequestData</code> Object","text":"<p>When a function is an API endpoint (<code>api=True</code>) and uses <code>request_as_kwarg=True</code>, it receives a <code>RequestData</code> object. This object contains all the information about the incoming HTTP request:</p> <ul> <li><code>request.method</code>: The HTTP method (e.g., 'GET', 'POST').</li> <li><code>request.path</code>: The request path.</li> <li><code>request.headers</code>: A Pydantic model of the request headers.</li> <li><code>request.query_params</code>: A dictionary of URL query parameters.</li> <li><code>request.form_data</code>: A dictionary of data from a submitted form.</li> <li><code>request.session</code>: A Pydantic model containing user session information, if the user is authenticated.</li> </ul>"},{"location":"module_creation_guide/#the-result-object","title":"The <code>Result</code> Object","text":"<p>API functions should almost always return a <code>Result</code> object. This standardizes responses and error handling.</p> <p>Success Responses:</p> <ul> <li><code>Result.ok(data, info)</code>: A generic success response.</li> <li><code>Result.json(data, info)</code>: For JSON API responses. Sets the <code>Content-Type</code> header to <code>application/json</code>.</li> <li><code>Result.html(data, info)</code>: For serving HTML content.</li> <li><code>Result.file(data, filename)</code>: For sending files to the user for download.</li> <li><code>Result.sse(stream_generator)</code>: For Server-Sent Events (event streaming).</li> </ul> <p>Error Responses:</p> <ul> <li><code>Result.default_user_error(info, exec_code)</code>: For client-side errors (e.g., bad input). Typically returns a 4xx status code.</li> <li><code>Result.default_internal_error(info, exec_code)</code>: For server-side errors. Typically returns a 5xx status code.</li> </ul>"},{"location":"module_creation_guide/#5-frontend-integration-with-tbjs","title":"5. Frontend Integration with <code>tbjs</code>","text":"<p>Modules often have a corresponding frontend component. The <code>tbjs</code> framework is designed to interact seamlessly with ToolBoxV2 modules.</p>"},{"location":"module_creation_guide/#making-api-calls-from-the-frontend","title":"Making API Calls from the Frontend","text":"<p>Use the <code>TB.api.request</code> function in your JavaScript to call your module's backend functions.</p> <pre><code>// In your frontend JavaScript file\n\nasync function fetchDataFromMyModule() {\n    try {\n        // Calls the 'get_data' function in the 'MyNewModule' module\n        const response = await TB.api.request('MyNewModule', 'get_data');\n\n        if (response.error === \"none\") {\n            const data = response.get(); // Helper to get response.result.data\n            console.log(\"Data from backend:\", data.message);\n            document.getElementById('my-element').innerText = data.message;\n        } else {\n            TB.ui.Toast.showError(`Error: ${response.info.help_text}`);\n        }\n    } catch (error) {\n        TB.logger.error(\"Network or API request failed\", error);\n        TB.ui.Toast.showError(\"Failed to connect to the server.\");\n    }\n}\n</code></pre>"},{"location":"module_creation_guide/#serving-a-ui","title":"Serving a UI","text":"<p>Your module can serve its entire UI as an HTML string from an API endpoint. This is a common pattern for \"widgets\" or self-contained applications.</p> <ol> <li> <p>Backend (<code>MyNewModule.py</code>): Create an endpoint that returns HTML.</p> <pre><code>@export(mod_name=MOD_NAME, name=\"ui\", api=True)\nasync def get_main_ui(self) -&gt; Result:\n    html_content = \"\"\"\n        &lt;div&gt;\n            &lt;h1&gt;My Module's UI&lt;/h1&gt;\n            &lt;button id=\"my-button\"&gt;Fetch Data&lt;/button&gt;\n            &lt;p id=\"my-element\"&gt;&lt;/p&gt;\n            &lt;script unSave=\"true\"&gt;\n                document.getElementById('my-button').addEventListener('click', async () =&gt; {\n                    const response = await TB.api.request('MyNewModule', 'get_data');\n                    if (response.get()) {\n                        document.getElementById('my-element').innerText = response.get().message;\n                    }\n                });\n            &lt;/script&gt;\n        &lt;/div&gt;\n    \"\"\"\n    return Result.html(data=html_content)\n</code></pre> </li> <li> <p>Integration (<code>on_start</code>): In your module's <code>on_start</code> method, register this UI with the <code>CloudM</code> module so it appears in the main application menu.</p> <pre><code>def on_start(self):\n    self.app.run_any((\"CloudM\", \"add_ui\"),\n                     name=self.name,\n                     title=\"My Awesome Module\",\n                     path=f\"/api/{self.name}/ui\",\n                     description=\"This is a module I built.\",\n                     auth=True # Requires user to be logged in\n                     )\n</code></pre> </li> </ol>"},{"location":"module_creation_guide/#6-inter-module-communication","title":"6. Inter-Module Communication","text":"<p>Modules can call functions in other modules using <code>app.run_any()</code>.</p> <pre><code># In MyNewModule.py\n\n@export(mod_name=MOD_NAME, name=\"process_and_store\", api=True, request_as_kwarg=True)\nasync def process_and_store(self, request: RequestData) -&gt; Result:\n    # 1. Get the user from the request using the WidgetsProvider module\n    user = await self.app.run_any((\"WidgetsProvider\", \"get_user_from_request\"), request=request)\n    if not user:\n        return Result.default_user_error(\"Authentication required.\")\n\n    # 2. Use the ISAA module to analyze some text\n    analysis = await self.app.run_any((\"isaa\", \"mini_task_completion\"),\n                                     mini_task=\"Summarize this text.\",\n                                     user_task=\"ToolBoxV2 is a modular framework...\")\n\n    # 3. Save the result to the user's file storage using FileWidget\n    storage = await self.app.run_any((\"FileWidget\", \"get_blob_storage\"), request=request)\n    # ... (code to save 'analysis' to blob storage) ...\n\n    return Result.ok(info=\"Data processed and saved.\")\n</code></pre> <p>This pattern allows for powerful, decoupled architectures where modules specialize in one area (AI, files, UI) and collaborate to build complex applications.</p>"},{"location":"p2p_rpc_protocol/","title":"P2P RPC Protocol Specification","text":"<p>This document defines the JSON-based Remote Procedure Call (RPC) protocol used for secure communication over the ToolBoxV2 P2P network.</p>"},{"location":"p2p_rpc_protocol/#overview","title":"Overview","text":"<p>The protocol is designed to be simple, extensible, and secure. All messages are JSON objects, which are then serialized into a string, encoded to UTF-8 bytes, and then E2E encrypted by the <code>tcm</code> peer before being sent over the P2P data channel.</p>"},{"location":"p2p_rpc_protocol/#message-structure","title":"Message Structure","text":"<p>There are two main types of messages: Request and Response.</p>"},{"location":"p2p_rpc_protocol/#request-message","title":"Request Message","text":"<p>A message sent from a Consumer to a Provider to execute a function.</p> <pre><code>{\n  \"type\": \"request\",\n  \"call_id\": \"unique-string-identifier-123\",\n  \"module\": \"MyModule\",\n  \"function\": \"my_function_name\",\n  \"args\": [\"positional_arg1\", 42],\n  \"kwargs\": {\n    \"keyword_arg1\": \"value1\",\n    \"optional_arg\": true\n  }\n}\n</code></pre> <p>Fields:</p> <ul> <li><code>type</code> (string, required): Must be <code>\"request\"</code>.</li> <li><code>call_id</code> (string, required): A unique identifier (e.g., a UUID) generated by the Consumer. This ID is used to correlate a Response with its original Request.</li> <li><code>module</code> (string, required): The name of the ToolBoxV2 module to be called (e.g., <code>\"CloudM\"</code>).</li> <li><code>function</code> (string, required): The name of the function to execute within the specified module.</li> <li><code>args</code> (array, optional): A list of positional arguments for the function. Defaults to <code>[]</code> if not provided.</li> <li><code>kwargs</code> (object, optional): A dictionary of keyword arguments for the function. Defaults to <code>{}</code> if not provided.</li> </ul>"},{"location":"p2p_rpc_protocol/#response-message","title":"Response Message","text":"<p>A message sent from a Provider back to the Consumer after a function has been executed.</p>"},{"location":"p2p_rpc_protocol/#success-response","title":"Success Response","text":"<pre><code>{\n  \"type\": \"response\",\n  \"call_id\": \"unique-string-identifier-123\",\n  \"result\": {\n    \"status\": \"ok\",\n    \"data\": { \"some_key\": \"some_value\" }\n  },\n  \"error\": null\n}\n</code></pre>"},{"location":"p2p_rpc_protocol/#error-response","title":"Error Response","text":"<pre><code>{\n  \"type\": \"response\",\n  \"call_id\": \"unique-string-identifier-123\",\n  \"result\": null,\n  \"error\": {\n    \"code\": 500,\n    \"message\": \"An internal error occurred.\",\n    \"details\": \"Traceback...\"\n  }\n}\n</code></pre> <p>Fields:</p> <ul> <li><code>type</code> (string, required): Must be <code>\"response\"</code>.</li> <li><code>call_id</code> (string, required): The <code>call_id</code> from the original Request message.</li> <li><code>result</code> (any, nullable): The data returned by the successful execution of the function. This should be JSON-serializable. It is <code>null</code> if an error occurred.</li> <li><code>error</code> (object, nullable): An object describing the error if the function execution failed. It is <code>null</code> on success.<ul> <li><code>code</code> (integer): An error code (e.g., 403 for Forbidden, 404 for Not Found, 500 for Internal Server Error).</li> <li><code>message</code> (string): A human-readable error message.</li> <li><code>details</code> (string, optional): Additional details, such as a traceback.</li> </ul> </li> </ul>"},{"location":"stack/","title":"Stack","text":""},{"location":"stack/#stack-dokumentation","title":"Stack-Dokumentation:","text":"<p>Diese Dokumentation beschreibt die Architektur und den Datenfluss zwischen dem <code>tbjs</code>-Frontend, dem <code>actix_web</code>-Server in Rust und dem <code>toolboxv2</code>-Backend in Python.</p>"},{"location":"stack/#1-architekturubersicht","title":"1. Architektur\u00fcbersicht","text":"<p>Ihr Stack besteht aus drei eng integrierten Schichten, die jeweils spezifische Aufgaben \u00fcbernehmen:</p> <ul> <li>JavaScript (Frontend - <code>tbjs</code>): Eine modulare Framework, die f\u00fcr die Benutzeroberfl\u00e4che und die Client-Logik verantwortlich ist. Sie initiiert die gesamte Kommunikation mit dem Server.</li> <li>Rust (Webserver/Bridge - <code>actix_web</code>): Dient als hochperformante und sichere Br\u00fccke. Er nimmt HTTP-Anfragen vom Client entgegen, verwaltet Benutzersitzungen und leitet Anfragen sicher an das Python-Backend weiter. Er ist die zentrale Schnittstelle, die die Typensicherheit von Rust mit der Flexibilit\u00e4t von Python verbindet.</li> <li>Python (Anwendungslogik - <code>toolboxv2</code>): Das \"Gehirn\" der Anwendung. Hier wird die gesamte Gesch\u00e4ftslogik ausgef\u00fchrt, von der Datenverarbeitung \u00fcber die Authentifizierung bis hin zur Dateiverwaltung. Die modulare Struktur erm\u00f6glicht eine einfache Erweiterung.</li> </ul> <pre><code>sequenceDiagram\n    participant JS (tbjs) as Frontend\n    participant Rust (actix_web) as Webserver/Bridge\n    participant Python (toolboxv2) as Anwendungslogik\n\n    JS (tbjs)-&gt;&gt;+Rust (actix_web): HTTP Request (/api, /sse)\n    Rust (actix_web)-&gt;&gt;+Python (toolboxv2): F\u00fchrt Funktion \u00fcber ToolboxClient aus\n    Python (toolboxv2)--&gt;&gt;-Rust (actix_web): Gibt Result-Objekt zur\u00fcck\n    Rust (actix_web)--&gt;&gt;-JS (tbjs): Sendet HTTP-Antwort\n</code></pre>"},{"location":"stack/#2-detaillierter-requestresponse-lebenszyklus-http","title":"2. Detaillierter Request/Response-Lebenszyklus (HTTP)","text":"<p>Ein typischer API-Aufruf, wie z. B. das Hochladen einer Datei, durchl\u00e4uft die folgenden Phasen:</p>"},{"location":"stack/#phase-1-anfrage-vom-client-zum-server","title":"Phase 1: Anfrage vom Client zum Server","text":"<ol> <li> <p>JavaScript (<code>tbjs</code>):</p> <ul> <li>Initiierung: Eine Benutzeraktion (z. B. das Ausw\u00e4hlen einer Datei) l\u00f6st einen Aufruf von <code>TB.api.request('FileWidget', 'upload', formData, 'POST')</code> aus.</li> <li>Payload-Verarbeitung:<ul> <li>F\u00fcr JSON-Daten wird ein JavaScript-Objekt in einen JSON-String umgewandelt.</li> <li>F\u00fcr Datei-Uploads wird ein <code>FormData</code>-Objekt erstellt. Der Browser setzt automatisch den korrekten <code>Content-Type: multipart/form-data</code> Header, inklusive des <code>boundary</code>.</li> </ul> </li> <li>Versand: Ein <code>fetch</code>-Request wird an den Rust-Server gesendet (z. B. an <code>/api/FileWidget/upload</code>). Der <code>Authorization: Bearer &lt;token&gt;</code> Header wird automatisch angef\u00fcgt, falls ein Token im <code>TB.state</code> vorhanden ist.</li> </ul> </li> <li> <p>Rust (<code>actix_web</code>):</p> <ul> <li>Routing &amp; Middleware: <code>actix_web</code> leitet die Anfrage an den <code>api_handler</code>. Middleware wie <code>SessionMiddleware</code> und <code>Logger</code> werden ausgef\u00fchrt.</li> <li>Sitzungsvalidierung: Der Handler pr\u00fcft, ob das aufgerufene Modul (<code>FileWidget</code>) gesch\u00fctzt ist. Falls ja, wird die Sitzung validiert. Ist die Sitzung ung\u00fcltig, wird ein <code>401 Unauthorized</code> zur\u00fcckgegeben.</li> <li>Payload-Parsing: Der Handler inspiziert den <code>Content-Type</code> Header:<ul> <li><code>application/json</code>: Der Body wird als JSON deserialisiert.</li> <li><code>multipart/form-data</code>: Der <code>api_handler</code> parst den multipart-Stream. Textfelder werden als normale Key-Value-Paare extrahiert. Dateien werden vollst\u00e4ndig in den Speicher gelesen und ihr Inhalt wird Base64-kodiert. Das Ergebnis ist eine <code>HashMap</code>, die eine Struktur wie <code>{ \"file\": { \"filename\": \"...\", \"content_base64\": \"...\" } }</code> enth\u00e4lt.</li> </ul> </li> <li>Python-Aufruf: Der Handler ruft die <code>run_function</code> des globalen <code>ToolboxClient</code> auf. Modulname, Funktionsname und die aufbereiteten <code>kwargs</code> (inklusive der geparsten Payload und Request-Metadaten) werden \u00fcbergeben.</li> </ul> </li> <li> <p>Python (<code>toolboxv2</code>):</p> <ul> <li>Instanz-Management (in Rust): Der <code>ToolboxClient</code> w\u00e4hlt eine verf\u00fcgbare Python-Instanz aus dem Pool aus (oder erstellt eine neue) und stellt sicher, dass das <code>FileWidget</code>-Modul geladen ist.</li> <li>Daten\u00fcbergabe (<code>pyo3</code>): Die <code>serde_json::Value</code> aus Rust wird mithilfe von <code>pyo3</code> in Python-Typen (z. B. <code>dict</code>, <code>list</code>, <code>str</code>) umgewandelt.</li> <li>Ausf\u00fchrung: Die <code>handle_upload</code>-Funktion im <code>FileWidget</code>-Modul wird ausgef\u00fchrt. Sie erh\u00e4lt die <code>form_data</code> als Python-<code>dict</code> und kann direkt auf den Base64-kodierten Inhalt der Datei zugreifen, ihn dekodieren und verarbeiten (z. B. Chunks zusammenf\u00fcgen und im <code>BlobStorage</code> speichern).</li> </ul> </li> </ol>"},{"location":"stack/#phase-2-antwort-vom-server-zum-client","title":"Phase 2: Antwort vom Server zum Client","text":"<ol> <li> <p>Python (<code>toolboxv2</code>):</p> <ul> <li>Ergebnis-Kapselung: Die Python-Funktion schlie\u00dft ihre Arbeit ab und gibt das Ergebnis in einem <code>Result.ok(...)</code> oder <code>Result.default_user_error(...)</code> Objekt zur\u00fcck. Dies standardisiert die Antwortstruktur.</li> </ul> </li> <li> <p>Rust (<code>actix_web</code>):</p> <ul> <li>Datenr\u00fcckgabe (<code>pyo3</code>): Das Python-<code>Result</code>-Objekt wird von der <code>py_to_value</code>-Funktion in eine <code>serde_json::Value</code> f\u00fcr Rust umgewandelt.</li> <li>Antwort-Verarbeitung: Der <code>api_handler</code> empf\u00e4ngt diese <code>serde_json::Value</code> und parst sie in die Rust-Struktur <code>ApiResult</code>. Die Hilfsfunktion <code>parse_response</code> analysiert dieses Objekt:<ul> <li>Sie pr\u00fcft das Feld <code>data_type</code> (z. B. <code>json</code>, <code>html</code>, <code>binary</code>).</li> <li>Sie erstellt die entsprechende <code>HttpResponse</code> mit dem korrekten <code>Content-Type</code> und Body.</li> </ul> </li> </ul> </li> <li> <p>JavaScript (<code>tbjs</code>):</p> <ul> <li>Empfang: Das <code>Promise</code> des <code>fetch</code>-Aufrufs in <code>TB.api.request</code> wird aufgel\u00f6st.</li> <li>Antwort-Wrapper: Die Funktion <code>wrapApiResponse</code> stellt sicher, dass die empfangenen Daten (auch bei Fehlern) konsistent als <code>tbjs</code>-<code>Result</code>-Objekt formatiert sind.</li> <li>UI-Update: Die Anwendungslogik verarbeitet das <code>Result</code>-Objekt und aktualisiert die Benutzeroberfl\u00e4che (z. B. durch Anzeigen einer Erfolgsmeldung oder das Neuladen der Dateiliste).</li> </ul> </li> </ol>"},{"location":"stack/#3-streaming-architektur-server-sent-events-sse","title":"3. Streaming-Architektur (Server-Sent Events - SSE)","text":"<p>Der SSE-Mechanismus folgt einem \u00e4hnlichen, aber auf Streaming ausgerichteten Pfad:</p> <ol> <li>JavaScript (<code>tbjs</code>): <code>TB.sse.connect('/sse/UltimateTTT/open_game_stream?game_id=...')</code> \u00f6ffnet eine persistente HTTP-GET-Verbindung.</li> <li>Rust (<code>actix_web</code>): Der <code>sse_handler</code> empf\u00e4ngt die Anfrage, validiert die Session und ruft <code>client.stream_sse_events(...)</code> auf.</li> <li>Rust-Python-Bridge:<ul> <li>Diese Funktion ruft die Python-Generatorfunktion \u00fcber <code>stream_generator</code> auf.</li> <li>Sie startet eine <code>tokio::task</code>, die in der Python-Funktion auf Ergebnisse wartet.</li> <li>Die <code>yield</code>-Anweisungen der Python-Generatorfunktion senden Daten zur\u00fcck an Rust.</li> </ul> </li> <li>Rust (<code>actix_web</code>): Der <code>sse_handler</code> empf\u00e4ngt die Daten-Chunks vom Python-Generator, formatiert jeden Chunk als SSE-Nachricht (<code>data: ...\\n\\n</code>) und streamt sie sofort an den Client. Ein Heartbeat wird ebenfalls gesendet, um die Verbindung offen zu halten.</li> <li>JavaScript (<code>tbjs</code>): Der <code>EventSource</code>-Listener in <code>TB.sse</code> empf\u00e4ngt die Nachrichten und l\u00f6st entsprechende Events im <code>TB.events</code>-Bus aus, was zu UI-Updates f\u00fchrt.</li> </ol>"},{"location":"stack/#konzept-websocket-implementierung","title":"Konzept: WebSocket-Implementierung","text":"<p>Die Hinzuf\u00fcgung von WebSockets erm\u00f6glicht eine echte bidirektionale Echtzeitkommunikation, die ideal f\u00fcr interaktive Features wie Chats oder Live-Kollaboration ist. Hier ist ein Entwurf, wie dies in Ihren Stack integriert werden kann.</p>"},{"location":"stack/#1-motivation","title":"1. Motivation","text":"<ul> <li>Bidirektionale Kommunikation: Im Gegensatz zu SSE, bei dem nur der Server senden kann, erm\u00f6glichen WebSockets die Kommunikation in beide Richtungen \u00fcber eine einzige Verbindung.</li> <li>Geringere Latenz: Ideal f\u00fcr Anwendungen, die schnelle, wiederholte Interaktionen erfordern (z. B. Multiplayer-Spiele), da der Overhead von HTTP-Anfragen entf\u00e4llt.</li> </ul>"},{"location":"stack/#2-vorgeschlagene-architekturanpassungen","title":"2. Vorgeschlagene Architekturanpassungen","text":"<pre><code>sequenceDiagram\n    participant JS (TB.ws) as Frontend\n    participant Rust (actix-web-actors) as WebSocket Actor\n    participant Python (toolboxv2) as Anwendungslogik\n\n    JS (TB.ws)-&gt;&gt;+Rust (actix-web-actors): WebSocket-Verbindung aufbauen (/ws/...)\n    Rust (actix-web-actors)-&gt;&gt;+Python (toolboxv2): on_connect-Handler aufrufen (via ToolboxClient)\n    Python (toolboxv2)--&gt;&gt;-Rust (actix-web-actors): (Optional) Best\u00e4tigung/Initialdaten\n    Rust (actix-web-actors)--&gt;&gt;-JS (TB.ws): Verbindung ge\u00f6ffnet\n\n    loop Nachrichtenfluss\n        JS (TB.ws)-&gt;&gt;Rust (actix-web-actors): Nachricht senden (z.B. JSON)\n        Rust (actix-web-actors)-&gt;&gt;Python (toolboxv2): on_message-Handler mit Daten aufrufen\n        Python (toolboxv2)--&gt;&gt;Rust (actix-web-actors): (Optional) Direkte Antwort zur\u00fcckgeben\n\n        Python (toolboxv2)-)!-Rust (actix-web-actors): Proaktive Nachricht an Client senden (Push)\n        Rust (actix-web-actors)--&gt;&gt;JS (TB.ws): Nachricht an Client weiterleiten\n    end\n\n    JS (TB.ws)-xRust (actix-web-actors): Verbindung trennen\n    Rust (actix-web-actors)-xPython (toolboxv2): on_disconnect-Handler aufrufen\n</code></pre>"},{"location":"tbjs/","title":"TBjs","text":""},{"location":"tbjs/#tbjs-framework-comprehensive-guide-documentation","title":"tbjs Framework: Comprehensive Guide &amp; Documentation","text":"<p>Table of Contents</p> <ol> <li>Introduction<ul> <li>Key Design Principles &amp; Features</li> </ul> </li> <li>Getting Started<ul> <li>Prerequisites</li> <li>Installation</li> <li>HTML Setup</li> <li>Application Initialization (<code>TB.init</code>)</li> </ul> </li> <li>Core Modules (<code>TB.*</code>)<ul> <li><code>TB.config</code>: Configuration Management</li> <li><code>TB.logger</code>: Logging Utility</li> <li><code>TB.state</code>: Global State Management</li> <li><code>TB.events</code>: Event Bus / Pub/Sub</li> <li><code>TB.env</code>: Environment Detection</li> <li><code>TB.api</code>: Backend Communication</li> <li><code>TB.router</code>: SPA Routing</li> <li><code>TB.crypto</code>: Cryptographic Utilities</li> <li><code>TB.user</code>: User Session &amp; Authentication</li> <li><code>TB.sse</code>: Server-Sent Events</li> <li><code>TB.sw</code>: Service Worker Management</li> <li><code>TB.utils</code>: General Utilities</li> <li><code>TB.graphics</code>: 3D Graphics (THREE.js)</li> </ul> </li> <li>UI System (<code>TB.ui.*</code>)<ul> <li><code>TB.ui.theme</code>: Theming (Light/Dark Mode, Backgrounds)</li> <li><code>TB.ui.htmxIntegration</code>: HTMX Event Handling</li> <li><code>TB.ui.processDynamicContent</code>: Handling New DOM Content</li> <li>UI Components:<ul> <li><code>TB.ui.Modal</code></li> <li><code>TB.ui.Toast</code></li> <li><code>TB.ui.Loader</code></li> <li><code>TB.ui.Button</code></li> <li><code>TB.ui.DarkModeToggle</code></li> <li><code>TB.ui.CookieBanner</code></li> <li><code>TB.ui.MarkdownRenderer</code></li> <li><code>TB.ui.NavMenu</code></li> <li><code>TB.ui.AutocompleteWidget</code></li> </ul> </li> </ul> </li> <li>Styling with Tailwind CSS<ul> <li>Prefixing and CSS Variables</li> <li>Using <code>tbjs</code> Tailwind Config in Your Project</li> </ul> </li> <li>Advanced Topics<ul> <li>Tauri Integration</li> <li>Working with 3D Graphics</li> </ul> </li> <li>Example: Login Flow Walkthrough</li> <li>Building <code>tbjs</code> (For Developers)</li> </ol>"},{"location":"tbjs/#1-introduction","title":"1. Introduction","text":"<p><code>tbjs</code> is a modular frontend framework designed for building modern web applications, with special consideration for integration with Tauri for desktop applications and tools like HTMX and Three.js. It provides a comprehensive set of tools for managing configuration, state, API communication, routing, UI components, user authentication, and more.</p> <p>Key Design Principles &amp; Features:</p> <ul> <li>Modularity: Clear separation of concerns into <code>core</code> and <code>ui</code> modules. You can use only the parts you need.</li> <li>Event-Driven: Facilitates decoupled communication between modules via an event bus.</li> <li>Configuration-Centric: Application behavior is heavily influenced by a central configuration object.</li> <li>State Management: Centralized application state with optional persistence.</li> <li>SPA Router: Handles client-side navigation and view loading.</li> <li>API Abstraction: Simplifies backend communication, supporting both HTTP and Tauri <code>invoke</code> calls.</li> <li>UI System: Includes theme management (light/dark mode), dynamic backgrounds, and reusable UI components.</li> <li>3D Graphics Integration: Built-in support for THREE.js for dynamic backgrounds or scenes, managed by <code>TB.graphics</code>.</li> <li>User Authentication: Robust support for various authentication flows, including device key (asymmetric crypto) and WebAuthn (passkeys).</li> <li>HTMX Friendly: Designed to work seamlessly alongside HTMX for enhancing HTML with dynamic behaviors.</li> <li>Tauri-Aware: Core functionalities can adapt to run optimally in a Tauri environment.</li> <li>Modern Tooling: Built with Webpack, Babel, PostCSS, and Tailwind CSS.</li> </ul>"},{"location":"tbjs/#2-getting-started","title":"2. Getting Started","text":""},{"location":"tbjs/#prerequisites","title":"Prerequisites","text":"<p>Before using <code>tbjs</code>, ensure you have the following (or plan to include them if using related features):</p> <ol> <li>HTMX (Recommended): <code>tbjs</code> integrates well with HTMX for server-rendered partials and dynamic updates.     <pre><code>&lt;script defer src=\"https://unpkg.com/htmx.org@2.0.2/dist/htmx.min.js\"&gt;&lt;/script&gt;\n</code></pre></li> <li>Three.js (Optional, if using <code>TB.graphics</code>):     <pre><code>&lt;script defer src=\"https://cdnjs.cloudflare.com/ajax/libs/three.js/0.153.0/three.min.js\"&gt;&lt;/script&gt;\n</code></pre></li> <li> <p>Marked &amp; Highlight.js (Optional, if using <code>TB.ui.MarkdownRenderer</code>): For rendering Markdown to HTML with syntax highlighting.     <pre><code>&lt;script defer src=\"https://cdn.jsdelivr.net/npm/marked/marked.min.js\"&gt;&lt;/script&gt;\n&lt;script defer src=\"https://cdn.jsdelivr.net/npm/marked-highlight/lib/index.umd.min.js\"&gt;&lt;/script&gt;\n&lt;script defer src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js\"&gt;&lt;/script&gt;\n&lt;link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css\"&gt;\n</code></pre> Ensure <code>window.marked</code>, <code>window.markedHighlight</code>, and <code>window.hljs</code> are available before <code>TB.ui.MarkdownRenderer</code> is used.</p> </li> <li> <p>Material Symbols (Optional, used by some default UI components):     <pre><code>&lt;link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200\" /&gt;\n</code></pre></p> </li> </ol>"},{"location":"tbjs/#installation","title":"Installation","text":"<ol> <li> <p>Add <code>tbjs</code> to your project:     If <code>tbjs</code> were published to npm:     <pre><code>npm install tbjs\n# or\nyarn add tbjs\n</code></pre>     Since it's often used locally or as part of a larger monorepo, you'd typically:</p> <ul> <li>Build <code>tbjs</code> from source (see Building <code>tbjs</code>) to get <code>dist/tbjs.js</code> and <code>dist/tbjs.css</code>.</li> <li>Or, if integrating into a build system, import directly from its source path (e.g., <code>import TB from 'path/to/tbjs/src/index.js';</code>).</li> </ul> </li> <li> <p>Include files in your HTML (if using pre-built dist files): <pre><code>&lt;link rel=\"stylesheet\" href=\"path/to/your/tbjs/dist/tbjs.css\"&gt;\n&lt;!-- Load tbjs.js as a module or a global script depending on its build --&gt;\n&lt;script defer type=\"module\" src=\"path/to/your/tbjs/dist/tbjs.js\"&gt;&lt;/script&gt; &lt;!-- If ES Module build --&gt;\n&lt;!-- &lt;script defer src=\"path/to/your/tbjs/dist/tbjs.js\"&gt;&lt;/script&gt; --&gt; &lt;!-- If UMD build --&gt;\n</code></pre></p> </li> <li> <p>Peer Dependencies (Reminder):     Ensure you have <code>htmx.org</code> and <code>three</code> installed/included if you plan to use features that depend on them.     <pre><code>npm install htmx.org three # Or yarn add\n</code></pre></p> </li> </ol>"},{"location":"tbjs/#3-core-modules-tb","title":"3. Core Modules (<code>TB.*</code>)","text":""},{"location":"tbjs/#tbconfig-configuration-management","title":"<code>TB.config</code>: Configuration Management","text":"<p>Manages application-wide settings. It's initialized by <code>TB.init()</code> with default values merged with your provided configuration.</p> <ul> <li>Initialization: <code>TB.config.init(userAppConfig)</code> is called by <code>TB.init</code>.<ul> <li><code>userAppConfig</code> options:<ul> <li><code>appRootId</code> (string): ID of the main DOM element for router views. Default: <code>app-root</code>.</li> <li><code>baseApiUrl</code> (string): Base URL for API calls. Default: <code>/api</code>. Normalized to be absolute (e.g., <code>/api</code> becomes <code>window.location.origin/api</code>).</li> <li><code>baseFileUrl</code> (string): Base URL for fetching static HTML files for routing. Default: <code>window.location.origin</code>. Normalized to end with <code>/</code> if it has a path, and ensures it doesn't include file names.</li> <li><code>initialState</code> (object): Initial state for <code>TB.state</code>.</li> <li><code>themeSettings</code> (object): See <code>TB.ui.theme</code> section.</li> <li><code>routes</code> (array): Predefined routes for <code>TB.router</code> (currently for reference/future use).</li> <li><code>logLevel</code> (string): <code>debug</code>, <code>info</code>, <code>warn</code>, <code>error</code>, <code>none</code>. Default: <code>info</code>.</li> <li><code>isProduction</code> (boolean): Inferred based on hostname (<code>localhost</code>, <code>127.0.0.1</code>) if not explicitly set.</li> <li><code>serviceWorker</code> (object): <code>{ enabled: boolean, url: string, scope: string }</code>.</li> </ul> </li> </ul> </li> <li>Getting Configuration: <pre><code>const apiUrl = TB.config.get('baseApiUrl');\nconst logLevel = TB.config.get('logLevel');\nconst themePref = TB.config.get('themeSettings.defaultPreference'); // Dot notation for nested\nconst allConfig = TB.config.getAll(); // Returns a copy of the entire config\n</code></pre></li> <li>Setting Configuration (dynamically, use with caution after init): <pre><code>TB.config.set('myCustomSetting', 'someValue');\nTB.config.set('featureFlags.newFeature', true);\n</code></pre></li> </ul>"},{"location":"tbjs/#tblogger-logging-utility","title":"<code>TB.logger</code>: Logging Utility","text":"<p>Provides leveled, prefixed, and timestamped logging to the console.</p> <ul> <li>Initialization: <code>TB.logger.init({ logLevel: '...' })</code> is called by <code>TB.init</code> based on <code>TB.config</code>.</li> <li>Setting Log Level: <pre><code>TB.logger.setLevel('debug'); // 'debug', 'info', 'warn', 'error', 'none'\n</code></pre></li> <li>Logging Messages: <pre><code>TB.logger.debug('Detailed debug message:', { data: 123 });\nTB.logger.info('Informational message.'); // Alias: TB.logger.log()\nTB.logger.warn('Potential issue warning.');\nTB.logger.error('An error occurred:', new Error('Something went wrong'));\n</code></pre>     Output includes a timestamp, <code>[tbjs]</code>, and the log level (e.g., <code>[DEBUG]</code>).</li> </ul>"},{"location":"tbjs/#tbstate-global-state-management","title":"<code>TB.state</code>: Global State Management","text":"<p>A simple key-value store for global application state with optional persistence to <code>localStorage</code>.</p> <ul> <li>Initialization: <code>TB.state.init(initialState)</code> is called by <code>TB.init</code> with <code>TB.config.get('initialState')</code>. Loads any persisted state.</li> <li>Getting State: <pre><code>const username = TB.state.get('user.username'); // Dot notation for nested\nconst allState = TB.state.get(); // Returns a copy of the entire state\n</code></pre></li> <li>Setting State: <pre><code>// Set a simple value\nTB.state.set('ui.darkMode', true);\n\n// Set a nested value, creating intermediate objects if they don't exist\nTB.state.set('user.profile.avatarUrl', '/path/to/avatar.png');\n\n// Persist the top-level key 'user' to localStorage\nTB.state.set('user.isLoggedIn', true, { persist: true });\n// Any change under 'user' (e.g., 'user.settings.notifications') will now persist 'user'.\n</code></pre><ul> <li>Emits <code>state:changed</code> event with <code>{ key, value, fullState }</code>.</li> <li>Emits specific event like <code>state:changed:user:profile:avatarUrl</code> with the <code>value</code>.</li> </ul> </li> <li>Deleting State: <pre><code>TB.state.delete('user.profile.temporaryToken');\nTB.state.delete('featureFlags.oldFlag', { persist: true }); // Will update persisted 'featureFlags'\n</code></pre></li> <li>Legacy \"Var\" Methods (for simple key-value persistence, prefer structured state with <code>persist</code> option):<ul> <li><code>TB.state.initVar('myVar', 'defaultValue')</code>: Sets if not already defined, persists.</li> <li><code>TB.state.delVar('myVar')</code>: Deletes and updates persisted state.</li> <li><code>TB.state.getVar('myVar')</code>: Gets value.</li> <li><code>TB.state.setVar('myVar', 'newValue')</code>: Sets value, persists.</li> </ul> </li> </ul>"},{"location":"tbjs/#tbevents-event-bus-pubsub","title":"<code>TB.events</code>: Event Bus / Pub/Sub","text":"<p>Allows modules to communicate without direct dependencies.</p> <ul> <li>Subscribing to Events: <pre><code>function handleThemeChange(eventData) {\n    console.log('Theme changed to:', eventData.mode);\n}\nTB.events.on('theme:changed', handleThemeChange);\n\n// Subscribe only once\nTB.events.once('app:firstLogin', (userData) =&gt; { /* ... */ });\n</code></pre></li> <li>Unsubscribing from Events: <pre><code>TB.events.off('theme:changed', handleThemeChange);\n</code></pre></li> <li>Emitting Events: <pre><code>TB.events.emit('user:loggedIn', { userId: 123, username: 'testuser' });\n</code></pre>     If a listener throws an error, <code>TB.logger.error</code> is called, and other listeners still execute.</li> <li>Common Framework Events: <code>tbjs:initialized</code>, <code>state:changed</code>, <code>router:navigationSuccess</code>, <code>theme:changed</code>, <code>api:networkError</code>, <code>graphics:initialized</code>, <code>user:loggedOut</code>, etc.</li> </ul>"},{"location":"tbjs/#tbenv-environment-detection","title":"<code>TB.env</code>: Environment Detection","text":"<p>Provides information about the runtime environment.</p> <ul> <li>Initialization: <code>TB.env.detect()</code> is called by <code>TB.init</code>.</li> <li>Checking Environment: <pre><code>if (TB.env.isTauri()) {\n    console.log('Running in Tauri environment.');\n} else if (TB.env.isWeb()) {\n    console.log('Running in a web browser.');\n}\nif (TB.env.isMobile()) { // Currently implies Tauri mobile if detected\n    console.log('Running on a mobile platform (Tauri).');\n}\n</code></pre></li> </ul>"},{"location":"tbjs/#tbapi-backend-communication","title":"<code>TB.api</code>: Backend Communication","text":"<p>Handles all HTTP and Tauri <code>invoke</code> calls, standardizing responses.</p> <ul> <li>Core <code>Result</code> Object: All <code>TB.api</code> methods (and Tauri invokes) aim to return or be wrapped into a <code>Result</code> object:     <pre><code>// Structure of a Result object (simplified)\n// const result = {\n//   origin: Array&lt;string&gt;,    // e.g., ['http'], ['tauri']\n//   error: string,           // From TB.ToolBoxError (e.g., 'none', 'InternalError')\n//   result: {                // Instance of ToolBoxResult\n//     data_to: string,       // From TB.ToolBoxInterfaces (e.g., 'API', 'NATIVE')\n//     data_info: string|null,// Additional info\n//     data: any              // The actual payload\n//   },\n//   info: {                  // Instance of ToolBoxInfo\n//     exec_code: number,     // HTTP status or custom code (0 for success)\n//     help_text: string      // Descriptive message\n//   },\n//   get: function() { return this.result.data; }, // Helper to get payload\n//   log: function() { /* console logs details */ },\n//   html: function() { /* returns an HTML representation for debugging */ }\n// };\n</code></pre></li> <li> <p><code>TB.api.request(moduleName, functionName, payload, method, useTauri, isSpecialAuthRoute)</code>:     The primary method for making backend requests.</p> <ul> <li><code>moduleName</code> (string): Backend module/class OR full path (e.g., <code>/validateSession</code>).</li> <li><code>functionName</code> (string|object): Backend function/method OR query params object if <code>moduleName</code> is a full path (for GET/DELETE).</li> <li><code>payload</code> (object|string|null): Data to send. Object for JSON POST/PUT; string can be form-urlencoded or query params.</li> <li><code>method</code> (string): HTTP method (<code>GET</code>, <code>POST</code>, etc.). Default: <code>POST</code>.</li> <li><code>useTauri</code> (string): <code>auto</code> (default), <code>force</code> (Tauri only), <code>never</code> (HTTP only).</li> <li><code>isSpecialAuthRoute</code> (boolean): If <code>true</code>, influences token handling (rarely needed).</li> </ul> <p>URL Construction (HTTP): *   Standard: <code>baseApiUrl/moduleName/functionName</code> *   Full path: <code>baseApiUrl</code> + <code>moduleName</code> (where <code>moduleName</code> starts with <code>/</code>, e.g., <code>/custom/endpoint</code>)</p> <p><pre><code>// POST request (HTTP or Tauri if available and 'auto')\nconst userData = { name: 'John Doe', email: 'john@example.com' };\nlet response = await TB.api.request('UserModule', 'createUser', userData); // Defaults to POST\n\nif (response.error === TB.ToolBoxError.none) {\n    console.log('User created:', response.get());\n} else {\n    TB.logger.error('Failed to create user:', response.info.help_text);\n}\n\n// GET request with query parameters from an object\nresponse = await TB.api.request('ProductModule', 'getProduct', { id: 123 }, 'GET');\n// URL: /api/ProductModule/getProduct?id=123\n\n// Full path GET (functionName is query params object)\nresponse = await TB.api.request('/custom/data', { type: 'summary' }, null, 'GET');\n// URL: /api/custom/data?type=summary (if baseApiUrl is /api)\n</code></pre> *   <code>TB.api.fetchHtml(path)</code>: Fetches HTML content, typically for router views. Path is relative to <code>baseFileUrl</code>. <pre><code>const htmlResult = await TB.api.fetchHtml('/about.html'); // Fetches /web/pages/about.html\nif (!htmlResult.startsWith('HTTP error!')) { /* ... */ }\n</code></pre> *   <code>TB.api.AuthHttpPostData(username)</code>: Specific method for validating a session. Calls <code>/validateSession</code>. *   <code>TB.api.logoutServer()</code>: Notifies the backend to invalidate the current user's session token (calls <code>/web/logoutS</code>). *   Events: *   <code>api:networkError</code>: Emitted on fetch network failures. Payload: <code>{ url, error }</code>.</p> </li> </ul>"},{"location":"tbjs/#tbrouter-spa-routing","title":"<code>TB.router</code>: SPA Routing","text":"<p>Manages client-side navigation and view rendering.</p> <ul> <li>Initialization: <code>TB.router.init(rootElement, predefinedRoutes)</code> called by <code>TB.init</code>.<ul> <li><code>rootElement</code>: The DOM element where views will be rendered (from <code>TB.config.appRootId</code>).</li> <li>Automatically navigates to the initial URL (or <code>/index.html</code>).</li> </ul> </li> <li>Navigating: <pre><code>// Navigate to a new path, updating browser history\nTB.router.navigateTo('/products/123'); // Fetches baseFileUrl + /products/123.html\n\n// Navigate and replace current history entry\nTB.router.navigateTo('/profile/settings', true);\n</code></pre><ul> <li>Fetches HTML from <code>TB.config.get('baseFileUrl') + path + '.html'</code> (by default, unless path includes an extension).</li> <li>Handles script loading within new views (external once, inline executed, <code>unsave</code> attribute for fresh execution, <code>global=\"true\"</code> for potential preservation).</li> <li>Updates <code>appRootElement.innerHTML</code> with fetched content.</li> <li>Calls <code>TB.ui.processDynamicContent()</code> on the new content.</li> <li>Handles 404 errors by trying to navigate to <code>/web/assets/404.html</code>.</li> <li>Handles 401 errors by trying to navigate to <code>/web/assets/401.html</code>.</li> </ul> </li> <li>Getting Current Path: <code>TB.router.getCurrentPath()</code></li> <li>Cache Management:<ul> <li><code>TB.router.clearCache(path)</code>: Clears HTML cache for a specific path or all if <code>path</code> is omitted (uses <code>sessionStorage</code> if <code>USE_SESSION_CACHE</code> is true in router.js).</li> <li><code>scriptCache</code> (Set of script <code>src</code> URLs) prevents re-fetching external scripts.</li> </ul> </li> <li>Events:<ul> <li><code>router:beforeNavigation</code>: <code>{ from, to }</code></li> <li><code>router:navigationSuccess</code>: <code>{ path, contentSource }</code> ('cache' or 'fetched')</li> <li><code>router:navigationError</code>: <code>{ path, error }</code></li> <li><code>router:contentProcessed</code>: <code>{ path, element }</code></li> </ul> </li> </ul>"},{"location":"tbjs/#tbcrypto-cryptographic-utilities","title":"<code>TB.crypto</code>: Cryptographic Utilities","text":"<p>Provides functions for various cryptographic operations, including WebAuthn. Relies on browser's Web Crypto API.</p> <ul> <li>Key Management &amp; Signing:<ul> <li><code>TB.crypto.generateAsymmetricKeys()</code>: Generates RSA-OAEP key pair (PEM &amp; Base64).</li> <li><code>TB.crypto.decryptAsymmetric(encryptedBase64Data, privateKeyBase64, convertHex = false)</code>: Decrypts RSA-OAEP encrypted data.</li> <li><code>TB.crypto.signMessage(privateKeyBase64, message)</code>: Signs a message using RSA-PSS.</li> <li><code>TB.crypto.storePrivateKey(privateKeyBase64, username)</code>: Stores private key in <code>localStorage</code>.</li> <li><code>TB.crypto.retrievePrivateKey(username)</code>: Retrieves private key.</li> </ul> </li> <li>Symmetric Encryption/Decryption:<ul> <li><code>TB.crypto.generateSymmetricKey()</code>: Generates an AES-GCM key (Base64 of raw key).</li> <li><code>TB.crypto.decryptSymmetric(encryptedDataB64, password)</code>: Decrypts AES-GCM data (assumes IV is prepended to ciphertext, password used for key derivation via PBKDF2).</li> </ul> </li> <li>WebAuthn (Passkeys):<ul> <li>The Relying Party ID (<code>rpId</code>) is determined from <code>window.location.hostname</code> (or \"localhost\").</li> <li><code>TB.crypto.registerWebAuthnCredential(registrationData, singData)</code>:<ul> <li><code>registrationData</code>: <code>{ challenge, userId, username }</code> from server.</li> <li><code>singData</code>: Additional data (e.g., session token) to associate.</li> <li>Calls <code>navigator.credentials.create()</code>. Returns payload for server verification.</li> </ul> </li> <li><code>TB.crypto.authorizeWebAuthnCredential(rawIdAsBase64, challenge, username)</code>:<ul> <li><code>rawIdAsBase64</code>, <code>challenge</code>, <code>username</code> from server.</li> <li>Calls <code>navigator.credentials.get()</code>. Returns assertion payload for server verification.</li> </ul> </li> </ul> </li> <li>Data Conversions: <code>arrayBufferToBase64</code>, <code>base64ToArrayBuffer</code>, <code>strToBase64</code>, etc.</li> </ul>"},{"location":"tbjs/#tbuser-user-session-authentication","title":"<code>TB.user</code>: User Session &amp; Authentication","text":"<p>Manages user state, authentication flows, and user-specific data. User state is stored under <code>TB.state.get('user')</code>.</p> <ul> <li>Initialization: <code>TB.user.init(forceServerFetch = false)</code>:<ul> <li>Called by <code>TB.init</code>. Loads session, validates with backend, synchronizes user data.</li> </ul> </li> <li>Authentication State: <code>TB.user.isAuthenticated()</code>, <code>TB.user.getUsername()</code>, <code>TB.user.getToken()</code>, etc.</li> <li>Login Methods:<ul> <li><code>async TB.user.signup(username, email, initiationKey, registerAsPersona = false)</code>: Initiates user creation.</li> <li><code>async TB.user.loginWithDeviceKey(username)</code>: Login using locally stored asymmetric key.</li> <li><code>async TB.user.loginWithWebAuthn(username)</code>: Login using WebAuthn (passkey).</li> <li><code>async TB.user.requestMagicLink(username)</code>: Requests a magic link email.</li> <li><code>async TB.user.registerDeviceWithInvitation(username, invitationKey)</code>: Registers a new device.</li> <li><code>async TB.user.registerWebAuthnForCurrentUser(username)</code>: Adds a WebAuthn credential for an authenticated user.</li> </ul> </li> <li>Session Management:<ul> <li><code>async TB.user.checkSessionValidity()</code>: Validates current token with server.</li> <li><code>async TB.user.logout(notifyServer = true)</code>: Clears local session, notifies server.</li> </ul> </li> <li>User-Specific Data: <code>TB.user.getUserData(key)</code>, <code>TB.user.setUserData(keyOrObject, value, syncToServer = false)</code>, <code>async TB.user.syncUserData()</code>, <code>async TB.user.fetchUserData()</code>.</li> <li>Events: <code>user:stateChanged</code>, <code>user:loggedOut</code>.</li> </ul>"},{"location":"tbjs/#tbsse-server-sent-events","title":"<code>TB.sse</code>: Server-Sent Events","text":"<p>Manages connections to Server-Sent Event streams.</p> <ul> <li>Connecting: <code>TB.sse.connect(url, options = {})</code><ul> <li><code>options</code>: <code>{ onOpen, onError, onMessage, listeners: { eventName: handler }, eventSourceOptions }</code>. <pre><code>TB.sse.connect('/api/sse/updates', {\n    listeners: {\n        'user-update': (data) =&gt; TB.state.set('user.profile', data),\n        'new-notification': (data) =&gt; TB.ui.Toast.showInfo(data.message)\n    }\n});\n</code></pre></li> </ul> </li> <li>Disconnecting: <code>TB.sse.disconnect(url)</code>, <code>TB.sse.disconnectAll()</code></li> <li>Getting Connection: <code>TB.sse.getConnection(url)</code></li> <li>Events Emitted: <code>sse:open:&lt;url&gt;</code>, <code>sse:error:&lt;url&gt;</code>, <code>sse:event:&lt;url&gt;:&lt;eventName&gt;</code>, etc.</li> </ul>"},{"location":"tbjs/#tbsw-service-worker-management","title":"<code>TB.sw</code>: Service Worker Management","text":"<p>Handles registration and communication with your application's service worker.</p> <ul> <li>Configuration (<code>TB.config.get('serviceWorker')</code>): <code>enabled</code>, <code>url</code>, <code>scope</code>.</li> <li>Registration: Called automatically by <code>TB.init</code> if enabled. Manual: <code>await TB.sw.register()</code>.</li> <li>Unregistration: <code>await TB.sw.unregister()</code></li> <li>Sending Messages: <code>await TB.sw.sendMessage({ type: 'GET_VERSION' })</code></li> <li>Events Emitted: <code>sw:updateAvailable</code>, <code>sw:contentCached</code>.     <pre><code>TB.events.on('sw:updateAvailable', ({ registration }) =&gt; {\n    if (confirm('New version available. Reload?')) {\n        registration.waiting.postMessage({ type: 'SKIP_WAITING' });\n        // Listen for controllerchange to reload\n        navigator.serviceWorker.addEventListener('controllerchange', () =&gt; window.location.reload());\n    }\n});\n</code></pre></li> </ul>"},{"location":"tbjs/#tbutils-general-utilities","title":"<code>TB.utils</code>: General Utilities","text":"<p>A collection of helper functions.</p> <ul> <li><code>TB.utils.autocomplete(inputElement, arrayOrFunctionSource)</code>: Basic autocomplete (prefer <code>TB.ui.AutocompleteWidget</code>).</li> <li><code>TB.utils.debounce(func, delay)</code></li> <li><code>TB.utils.throttle(func, limit)</code></li> <li><code>TB.utils.uniqueId(prefix = 'id-')</code></li> <li><code>TB.utils.deepClone(obj)</code></li> <li><code>TB.utils.cleanUrl(url)</code>: Basic URL cleaning.</li> </ul>"},{"location":"tbjs/#tbgraphics-3d-graphics-threejs","title":"<code>TB.graphics</code>: 3D Graphics (THREE.js)","text":"<p>Manages a THREE.js scene, typically for background effects.</p> <ul> <li>Initialization: <code>TB.graphics.init(canvasContainerSelector, options = {})</code><ul> <li><code>canvasContainerSelector</code>: CSS selector for the DOM element (e.g., <code>'#threeDScene'</code>).</li> <li><code>options</code>: <code>{ cameraY, cameraZ, sierpinskiDepth, loaderHideDelay }</code>.</li> <li>Typically called if <code>themeSettings.background.type</code> is <code>'3d'</code>.</li> </ul> </li> <li>Control Methods:<ul> <li><code>TB.graphics.dispose()</code>, <code>TB.graphics.pause()</code>, <code>TB.graphics.resume()</code>.</li> <li><code>TB.graphics.updateTheme(themeMode)</code>: Called by <code>TB.ui.theme</code>.</li> <li><code>TB.graphics.setSierpinskiDepth(newDepth)</code>.</li> <li><code>TB.graphics.setAnimationSpeed(x, y, z, factor)</code>.</li> <li><code>TB.graphics.adjustCameraZoom(delta)</code>, <code>TB.graphics.setCameraZoom(absoluteZoomValue)</code>.</li> </ul> </li> <li>Programmed Animation Sequences:<ul> <li><code>TB.graphics.playAnimationSequence(sequenceString, onCompleteCallback, baseSpeedOverride, speedFactorOverride)</code><ul> <li><code>sequenceString</code>: e.g., <code>\"R1+32:P2-14\"</code> (Type, Repeat, Direction, Speed, Complexity).</li> </ul> </li> <li><code>TB.graphics.stopAnimationSequence()</code>.</li> </ul> </li> <li>Events: <code>graphics:initialized</code>, <code>graphics:disposed</code>.</li> </ul>"},{"location":"tbjs/#4-ui-system-tbui","title":"4. UI System (<code>TB.ui.*</code>)","text":""},{"location":"tbjs/#tbuitheme-theming","title":"<code>TB.ui.theme</code>: Theming","text":"<p>Manages light/dark mode and application background.</p> <ul> <li>Initialization: <code>TB.ui.theme.init(themeSettings)</code> called by <code>TB.init</code>.<ul> <li><code>themeSettings</code>: <code>{ defaultPreference ('light'|'dark'|'system'), background: { type, light, dark, placeholder } }</code>.</li> <li><code>background.type</code>: <code>'3d'</code>, <code>'image'</code>, <code>'color'</code>, <code>'none'</code>.</li> <li><code>background.light/dark</code>: <code>{ color: string, image: string|null }</code>.</li> <li><code>background.placeholder</code>: <code>{ image_light, image_dark, displayUntil3DReady }</code>.</li> </ul> </li> <li>Interacting with Theme:<ul> <li><code>TB.ui.theme.setPreference('dark')</code>, <code>TB.ui.theme.togglePreference()</code>.</li> <li><code>TB.ui.theme.getCurrentMode()</code> ('light' or 'dark').</li> <li><code>TB.ui.theme.getPreference()</code> ('light', 'dark', or 'system').</li> </ul> </li> <li>Background Management:<ul> <li>Uses <code>#appBackgroundContainer</code> for image/color and <code>#threeDScene</code> for 3D.</li> </ul> </li> <li>Events: <code>theme:changed</code> (payload: <code>{ mode: 'light' | 'dark' }</code>).</li> </ul>"},{"location":"tbjs/#tbuihtmxintegration-htmx-event-handling","title":"<code>TB.ui.htmxIntegration</code>: HTMX Event Handling","text":"<p>Listens to HTMX events to integrate <code>tbjs</code> functionalities.</p> <ul> <li>Initialization: <code>TB.ui.htmxIntegration.init()</code> is called by <code>TB.init</code>.</li> <li><code>htmx:afterSwap</code>: Calls <code>TB.ui.processDynamicContent</code> on the new HTMX target element.</li> <li><code>htmx:afterRequest</code>:<ul> <li>Inspects XHR response. If JSON, wraps in <code>TB.api.Result</code>, shows toasts for errors.</li> <li>Handles <code>REMOTE</code> render commands.</li> <li>Emits <code>htmx:jsonResponse</code>.</li> </ul> </li> </ul>"},{"location":"tbjs/#tbuiprocessdynamiccontentparentelement-options","title":"<code>TB.ui.processDynamicContent(parentElement, options = {})</code>","text":"<p>Initializes <code>tbjs</code> features/components within newly added DOM content.</p> <ul> <li><code>parentElement</code>: The container of the new content.</li> <li><code>options</code>: <code>{ addScripts (default true), scriptCache }</code>.</li> <li>Actions: Calls <code>window.htmx.process()</code>, handles scripts, calls <code>TB.ui.MarkdownRenderer.renderAllIn()</code>, initializes data-attribute driven components like <code>AutocompleteWidget</code>.</li> </ul>"},{"location":"tbjs/#ui-components","title":"UI Components","text":""},{"location":"tbjs/#tbuimodal","title":"<code>TB.ui.Modal</code>","text":"<p>Displays modal dialogs.</p> <ul> <li>Static Usage: <code>TB.ui.Modal.show({ title, content, maxWidth, buttons, onOpen, onClose, ... })</code><ul> <li><code>buttons</code>: <code>[{ text, action: (modalInstance) =&gt; {}, variant, className }]</code></li> </ul> </li> <li>Styling: Uses Tailwind CSS, \"milk glass\" effect.</li> <li> <p>Events: <code>modal:shown</code>, <code>modal:closed</code>.</p> </li> <li> <p>Static Usage: `TB.ui.Modal.confirm({         title,         content,         confirmButtonText = 'OK',         cancelButtonText = 'Cancel',         confirmButtonVariant = 'primary',         cancelButtonVariant = 'secondary',         confirmButtonClass = '',         cancelButtonClass = '',         hideCancelButton = false,         resolveOnClose = false,         ...extraModalOptions // Collects any other options passed to confirm</p> </li> </ul>"},{"location":"tbjs/#tbuitoast","title":"<code>TB.ui.Toast</code>","text":"<p>Displays \"speech balloon\" style toast notifications.</p> <ul> <li>Static Usage:<ul> <li><code>TB.ui.Toast.showInfo(message, options)</code></li> <li><code>TB.ui.Toast.showSuccess(message, options)</code></li> <li><code>TB.ui.Toast.showWarning(message, options)</code></li> <li><code>TB.ui.Toast.showError(message, options)</code></li> </ul> </li> <li>Options: <code>{ title, duration, position, actions, icon, closable, showDotOnHide, dotDuration }</code>.</li> <li>Events: <code>toast:shown</code>, <code>toast:hidden</code>.</li> </ul>"},{"location":"tbjs/#tbuiloader","title":"<code>TB.ui.Loader</code>","text":"<p>Displays a loading indicator.</p> <ul> <li>Static Usage (Global Page Loader):<ul> <li><code>const loaderElement = TB.ui.Loader.show('Processing...');</code></li> <li><code>TB.ui.Loader.hide(loaderElement);</code> (or <code>TB.ui.Loader.hide()</code> for default).</li> </ul> </li> <li>Options: <code>{ text, fullscreen, customSpinnerHtml }</code>.</li> </ul>"},{"location":"tbjs/#tbuibutton","title":"<code>TB.ui.Button</code>","text":"<p>Creates styled button elements programmatically.</p> <ul> <li>Static Usage: <code>const myButtonElement = TB.ui.Button.create(text, onClickCallback, options)</code></li> <li>Options: <code>{ variant, size, iconLeft, iconRight, type, disabled, isLoading, ... }</code>.</li> <li>Instance Methods: <code>setLoading(true)</code>, <code>setDisabled(true)</code>.</li> </ul>"},{"location":"tbjs/#tbuidarkmodetoggle","title":"<code>TB.ui.DarkModeToggle</code>","text":"<p>UI component for switching themes, syncing with <code>TB.ui.theme</code>.</p> <ul> <li>HTML (Example): <pre><code>&lt;div id=\"darkModeToggleContainer\"&gt;\n    &lt;label for=\"darkModeSwitch\"&gt;&lt;span class=\"tb-toggle-icon material-symbols-outlined\"&gt;light_mode&lt;/span&gt;&lt;/label&gt;\n    &lt;input type=\"checkbox\" id=\"darkModeSwitch\" class=\"tb-sr-only\"&gt;\n&lt;/div&gt;\n</code></pre></li> <li>Initialization: <code>TB.ui.DarkModeToggle.init({ containerSelector, iconSelector, checkboxSelector, ... })</code>. Default init uses common selectors.</li> <li>Updates icon and checkbox based on <code>theme:changed</code> event.</li> </ul>"},{"location":"tbjs/#tbuicookiebanner","title":"<code>TB.ui.CookieBanner</code>","text":"<p>Displays a cookie consent banner and settings modal.</p> <ul> <li>Static Usage: <code>TB.ui.CookieBanner.show({ title, message, termsLink, onConsent, ... })</code></li> <li><code>onConsent</code> callback receives <code>{ essential, preferences, analytics, source }</code>.</li> <li>Methods: <code>CookieBanner.getConsent()</code>, <code>CookieBanner.clearConsent()</code>.</li> <li>Events: <code>cookieConsent:updated</code>, <code>cookieBanner:shown</code>/<code>hidden</code>.</li> </ul>"},{"location":"tbjs/#tbuimarkdownrenderer","title":"<code>TB.ui.MarkdownRenderer</code>","text":"<p>Renders Markdown to HTML, with optional <code>highlight.js</code> syntax highlighting.</p> <ul> <li>Dependencies: <code>marked</code>, <code>highlight.js</code>, <code>marked-highlight</code> (global or loaded).</li> <li>Methods:<ul> <li><code>TB.ui.MarkdownRenderer.render(markdownString)</code></li> <li><code>TB.ui.MarkdownRenderer.renderAllIn(parentElement)</code> (for elements with <code>.markdown</code> class)</li> <li><code>TB.ui.MarkdownRenderer.renderElement(element)</code></li> </ul> </li> <li>Adds Tailwind Prose classes (<code>prose dark:prose-invert</code>) for styling.</li> </ul>"},{"location":"tbjs/#tbuinavmenu","title":"<code>TB.ui.NavMenu</code>","text":"<p>A slide-in (or modal-style) navigation menu.</p> <ul> <li>HTML Trigger (Example): <pre><code>&lt;div id=\"Nav-Main\"&gt; &lt;!-- Menu is appended here --&gt;\n    &lt;div id=\"links\"&gt;&lt;span class=\"material-symbols-outlined\"&gt;menu&lt;/span&gt;&lt;/div&gt;\n&lt;/div&gt;\n</code></pre></li> <li>Initialization: <code>TB.ui.NavMenu.init({ triggerSelector, menuContentHtml, ... })</code>.</li> <li>Events: <code>navMenu:opened</code>, <code>navMenu:closed</code>.</li> </ul>"},{"location":"tbjs/#tbuiautocompletewidget","title":"<code>TB.ui.AutocompleteWidget</code>","text":"<p>Provides autocomplete suggestions for input fields.</p> <ul> <li>HTML (Declarative): <pre><code>&lt;input type=\"text\" data-tb-autocomplete data-tb-autocomplete-source='[\"Apple\", \"Banana\"]'&gt;\n&lt;!-- Or data-tb-autocomplete-source=\"myGlobalFunctionName\" --&gt;\n</code></pre></li> <li>Initialization:<ul> <li>Automatic: <code>TB.ui.AutocompleteWidget.initAll()</code> (called by <code>processDynamicContent</code>).</li> <li>Manual: <code>new TB.ui.AutocompleteWidget(inputEl, { source, minLength, onSelect, ... })</code>.</li> </ul> </li> <li>Features: Keyboard navigation, ARIA attributes.</li> </ul>"},{"location":"tbjs/#5-styling-with-tailwind-css","title":"5. Styling with Tailwind CSS","text":"<p><code>tbjs</code> components are primarily styled using Tailwind CSS utility classes.</p>"},{"location":"tbjs/#prefixing-and-css-variables","title":"Prefixing and CSS Variables","text":"<ul> <li>Prefix: <code>tbjs</code>'s internal Tailwind configuration uses a <code>tb-</code> prefix (e.g., <code>tb-bg-primary-500</code>, <code>tb-text-lg</code>). This is crucial to avoid conflicts if your main application also uses Tailwind without a prefix or with a different one.</li> <li>Main CSS (<code>tbjs.css</code> or <code>tbjs-main.css</code>):<ul> <li>Imports Tailwind utilities generated with the <code>tb-</code> prefix.</li> <li>Defines CSS custom properties (variables) for theming (e.g., <code>--tb-color-primary-500</code>, <code>--theme-bg</code>, <code>--glass-bg</code>). These are used by the prefixed Tailwind classes.</li> <li>Includes light and dark theme definitions typically applied to <code>body[data-theme=\"dark\"]</code> or <code>body.dark-mode</code>.</li> <li>Provides base styles and some component-specific styles hard to achieve with utilities alone (e.g., toast speech balloon tail).</li> </ul> </li> <li>Customization:<ul> <li>Applications can override the CSS variables defined in <code>tbjs.css</code> in their own stylesheets to customize the look and feel.</li> <li>For deeper Tailwind customization (new colors, variants specific to <code>tbjs</code>), you would edit <code>tbjs/tailwind.config.js</code> and rebuild <code>tbjs</code>.</li> </ul> </li> </ul>"},{"location":"tbjs/#using-tbjs-tailwind-config-in-your-project","title":"Using <code>tbjs</code> Tailwind Config in Your Project","text":"<p>If your project also uses Tailwind CSS, you have a few options:</p> <ol> <li> <p>Separate Builds (Recommended for Isolation):</p> <ul> <li>Build <code>tbjs.css</code> using its own Tailwind configuration (with the <code>tb-</code> prefix).</li> <li>Build your application's CSS using its Tailwind configuration.</li> <li>Include both CSS files in your HTML. The <code>tb-</code> prefix prevents most conflicts.</li> </ul> </li> <li> <p>Merging Configurations (Advanced):     If you want a single Tailwind build process, you might try to merge configurations. This can be complex due to prefixing and potential conflicts.</p> <ul> <li>You would need to ensure your main <code>tailwind.config.js</code> includes the <code>content</code> paths for <code>tbjs</code> source files.</li> <li>You'd also need to decide how to handle the <code>tb-</code> prefix. If your app doesn't use a prefix, <code>tbjs</code> components might not be styled correctly unless you manually adapt their classes or adjust the <code>tbjs</code> source.</li> <li>A simpler merge might involve including <code>tbjs</code>'s Tailwind plugin or preset if it were structured that way, but this is not the default.</li> </ul> <p>Example (Conceptual - requires careful setup): <pre><code>// your-app/tailwind.config.js\n// const tbjsTailwindConfig = require('path/to/tbjs/tailwind.config.js'); // If CJS\n\nexport default {\n  content: [\n    './src/**/*.{html,js,svelte,vue,jsx,tsx}', // Your app's content\n    './node_modules/tbjs/src/**/*.{html,js}', // Or path to tbjs source\n  ],\n  // If your app uses a prefix, it might conflict or work alongside tb-\n  // prefix: 'app-',\n  theme: {\n    extend: {\n      // You might try to extend with tbjs colors if they are defined without prefix in its config\n      // This part is tricky due to the 'tb-' prefix baked into tbjs's own build\n    },\n  },\n  plugins: [],\n};\n</code></pre> Generally, keeping <code>tbjs.css</code> separate with its <code>tb-</code> prefix is the most straightforward way to avoid styling conflicts.</p> </li> </ol>"},{"location":"tbjs/#6-advanced-topics","title":"6. Advanced Topics","text":""},{"location":"tbjs/#tauri-integration","title":"Tauri Integration","text":"<ul> <li>Environment Check: Use <code>TB.env.isTauri()</code> to execute Tauri-specific code.</li> <li>API Calls: <code>TB.api.request()</code> automatically uses <code>window.__TAURI__.invoke</code> if <code>useTauri</code> is <code>'auto'</code> (default) or <code>'force'</code> and the environment is Tauri.<ul> <li>The Tauri command invoked is typically <code>moduleName.functionName</code> (e.g., <code>MyRustModule.my_function</code>). <pre><code>if (TB.env.isTauri()) {\n    const result = await TB.api.request('my_rust_command', 'sub_command_or_payload_key', { data: 'payload' });\n    // Effective Tauri invoke: window.__TAURI__.invoke('my_rust_command.sub_command_or_payload_key', { data: 'payload' });\n}\n</code></pre></li> </ul> </li> <li>Platform-Specific Features: The <code>initializeApp</code> function shows a pattern for loading Tauri-specific listeners or UI adjustments.</li> </ul>"},{"location":"tbjs/#working-with-3d-graphics","title":"Working with 3D Graphics","text":"<ul> <li>The <code>TB.graphics</code> module manages a THREE.js scene, typically for background effects.</li> <li>Integration with Theme: If <code>themeSettings.background.type</code> is <code>'3d'</code>, <code>TB.ui.theme</code> will initialize <code>TB.graphics</code> (targeting <code>#threeDScene</code>) and call <code>TB.graphics.updateTheme()</code> on light/dark mode changes.</li> <li>Manual Control: <pre><code>TB.graphics.setSierpinskiDepth(3);\nTB.graphics.playAnimationSequence(\"R2+52:P1-31\", () =&gt; console.log(\"3D Animation done!\"));\n// Mouse/touch drag for interaction is usually enabled by default.\n</code></pre></li> </ul>"},{"location":"tbjs/#7-example-login-flow-walkthrough","title":"7. Example: Login Flow Walkthrough","text":"<p>This conceptual example (based on a typical <code>login.js</code> implementation with <code>tbjs</code>) demonstrates how various modules work together:</p> <ol> <li> <p>Initialization (e.g., in a <code>setupLogin</code> function called when the login page loads):</p> <ul> <li>Wait for <code>tbjs:initialized</code> or check <code>TB.isInitialized</code>.</li> <li>Optionally, play an initial graphics animation: <code>TB.graphics.playAnimationSequence(\"Z0+12\")</code>.</li> <li>Check session validity: <code>TB.user.checkSessionValidity()</code>. If valid, show a toast and offer navigation to a dashboard.</li> </ul> </li> <li> <p>Form Submission (e.g., on login button click):</p> <ul> <li>Prevent default form submission.</li> <li>Get username from input. Validate locally (show info/toast on error).</li> <li>Play a \"login attempt\" graphics animation: <code>TB.graphics.playAnimationSequence(\"R1+11:P1-11\")</code>.</li> <li>Show a global loader: <code>TB.ui.Loader.show('Attempting login...')</code>.</li> <li>Authentication Logic (Conditional):<ul> <li>If user opts for WebAuthn/Passkey: <code>await TB.user.loginWithWebAuthn(username)</code>.</li> <li>Else (e.g., device key): <code>await TB.user.loginWithDeviceKey(username)</code>.<ul> <li>If <code>loginWithDeviceKey</code> fails due to no key: Show a sticky error toast with actions:<ul> <li>\"Try Passkey/WebAuthn\": Calls <code>TB.user.loginWithWebAuthn()</code>.</li> <li>\"Register with Invitation\": Prompts for key, calls <code>TB.user.registerDeviceWithInvitation()</code>.</li> <li>\"Send Magic Link\": Calls <code>TB.user.requestMagicLink()</code>.</li> <li>Each action would have its own loader management and graphics animations.</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> <li> <p>Result Handling:</p> <ul> <li>Based on <code>result.success</code> from <code>TB.user</code> login methods:<ul> <li>Success:<ul> <li>Show success toast: <code>TB.ui.Toast.showSuccess('Login successful!')</code>.</li> <li>Play success animation: <code>TB.graphics.playAnimationSequence(\"Z1+32:R0+50\")</code>.</li> <li>Navigate: <code>TB.router.navigateTo('/dashboard')</code>.</li> </ul> </li> <li>Failure:<ul> <li>Show error toast: <code>TB.ui.Toast.showError(result.message)</code>.</li> <li>Play failure animation: <code>TB.graphics.playAnimationSequence(\"P2-42\")</code>.</li> </ul> </li> </ul> </li> <li>Use <code>TB.logger</code> for detailed console logging throughout the process.</li> <li>Hide loader (<code>TB.ui.Loader.hide()</code>) and stop animations (<code>TB.graphics.stopAnimationSequence()</code>) in a <code>finally</code> block or after completion.</li> </ul> </li> </ol> <p>This flow showcases: *   Event-driven UI: Graphics and toasts respond to login states. *   Module Orchestration: <code>TB.user</code>, <code>TB.graphics</code>, <code>TB.ui.Toast</code>, <code>TB.ui.Loader</code>, <code>TB.router</code>, <code>TB.logger</code> working in concert. *   User Feedback: Clear messages and visual cues for different scenarios.</p>"},{"location":"tbjs/#8-building-tbjs-for-developers","title":"8. Building <code>tbjs</code> (For Developers)","text":"<p>If you are modifying the <code>tbjs</code> framework itself or need to build it from source:</p> <ol> <li>Prerequisites:<ul> <li>Node.js and npm (or yarn) installed.</li> </ul> </li> <li>Install Dependencies:     Navigate to the <code>tbjs</code> root directory in your terminal and run:     <pre><code>npm install\n# or\n# yarn install\n</code></pre></li> <li>Build Scripts (examples from a typical <code>package.json</code>):<ul> <li>Production Build: <pre><code>npm run build\n</code></pre>     This usually creates optimized, minified files in a <code>dist/</code> directory (e.g., <code>dist/tbjs.js</code> and <code>dist/tbjs.css</code>). The build process uses Webpack, configured in <code>webpack.config.js</code>.</li> <li>Development Watch Mode: <pre><code>npm run watch\n# or npm run dev\n</code></pre>     This watches source files for changes and automatically rebuilds, often in a non-minified format for easier debugging.</li> <li>Linting: <pre><code>npm run lint\n</code></pre>     Checks the JavaScript code for style consistency and potential errors using a linter like ESLint.</li> </ul> </li> </ol>"},{"location":"toolboxv2/","title":"toolboxv2 API Reference","text":"<p>This section provides an API reference for key components directly available from the <code>toolboxv2</code> package.</p>"},{"location":"toolboxv2/#core-application-tooling","title":"Core Application &amp; Tooling","text":""},{"location":"toolboxv2/#toolboxv2.AppType","title":"<code>toolboxv2.AppType</code>","text":"Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>class AppType:\n    prefix: str\n    id: str\n    globals: dict[str, Any] = {\"root\": dict, }\n    locals: dict[str, Any] = {\"user\": {'app': \"self\"}, }\n\n    local_test: bool = False\n    start_dir: str\n    data_dir: str\n    config_dir: str\n    info_dir: str\n    is_server:bool = False\n\n    logger: logging.Logger\n    logging_filename: str\n\n    api_allowed_mods_list: list[str] = []\n\n    version: str\n    loop: asyncio.AbstractEventLoop\n\n    keys: dict[str, str] = {\n        \"MACRO\": \"macro~~~~:\",\n        \"MACRO_C\": \"m_color~~:\",\n        \"HELPER\": \"helper~~~:\",\n        \"debug\": \"debug~~~~:\",\n        \"id\": \"name-spa~:\",\n        \"st-load\": \"mute~load:\",\n        \"comm-his\": \"comm-his~:\",\n        \"develop-mode\": \"dev~mode~:\",\n        \"provider::\": \"provider::\",\n    }\n\n    defaults: dict[str, (bool or dict or dict[str, dict[str, str]] or str or list[str] or list[list]) | None] = {\n        \"MACRO\": list[str],\n        \"MACRO_C\": dict,\n        \"HELPER\": dict,\n        \"debug\": str,\n        \"id\": str,\n        \"st-load\": False,\n        \"comm-his\": list[list],\n        \"develop-mode\": bool,\n    }\n\n    cluster_manager: ClusterManager\n    root_blob_storage: BlobStorage\n    config_fh: FileHandler\n    _debug: bool\n    flows: dict[str, Callable]\n    dev_modi: bool\n    functions: dict[str, Any]\n    modules: dict[str, Any]\n\n    interface_type: ToolBoxInterfaces\n    REFIX: str\n\n    alive: bool\n    called_exit: tuple[bool, float]\n    args_sto: AppArgs\n    system_flag = None\n    session = None\n    appdata = None\n    exit_tasks = []\n\n    enable_profiling: bool = False\n    sto = None\n\n    websocket_handlers: dict[str, dict[str, Callable]] = {}\n    _rust_ws_bridge: Any = None\n\n    def __init__(self, prefix: None | str= None, args: AppArgs | None = None):\n        self.args_sto = args\n        self.prefix = prefix\n        \"\"\"proxi attr\"\"\"\n\n    def start_server(self):\n        from toolboxv2.utils.system.api import manage_server\n        if self.is_server:\n            return\n        manage_server(\"start\")\n        self.is_server = False\n\n    @staticmethod\n    def exit_main(*args, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    @staticmethod\n    async def hide_console(*args, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    @staticmethod\n    async def show_console(*args, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    @staticmethod\n    async def disconnect(*args, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    def set_logger(self, debug=False):\n        \"\"\"proxi attr\"\"\"\n\n    @property\n    def debug(self):\n        \"\"\"proxi attr\"\"\"\n        return self._debug\n\n    def debug_rains(self, e):\n        \"\"\"proxi attr\"\"\"\n\n    def set_flows(self, r):\n        \"\"\"proxi attr\"\"\"\n\n    def run_flows(self, name, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    def rrun_flows(self, name, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    def idle(self):\n        import time\n        self.print(\"idle\")\n        try:\n            while self.alive:\n                time.sleep(1)\n        except KeyboardInterrupt:\n            pass\n        self.print(\"idle done\")\n\n    async def a_idle(self):\n        self.print(\"a idle\")\n        try:\n            if hasattr(self, 'daemon_app'):\n                self.print(\"serving daemon\")\n                await self.daemon_app.connect(self)\n            else:\n                self.print(\"serving default\")\n                while self.alive:\n                    await asyncio.sleep(1)\n        except KeyboardInterrupt:\n            pass\n        self.print(\"a idle done\")\n\n    @debug.setter\n    def debug(self, value):\n        \"\"\"proxi attr\"\"\"\n\n    def _coppy_mod(self, content, new_mod_dir, mod_name, file_type='py'):\n        \"\"\"proxi attr\"\"\"\n\n    def _pre_lib_mod(self, mod_name, path_to=\"./runtime\", file_type='py'):\n        \"\"\"proxi attr\"\"\"\n\n    def _copy_load(self, mod_name, file_type='py', **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    def inplace_load_instance(self, mod_name, loc=\"toolboxv2.mods.\", spec='app', save=True):\n        \"\"\"proxi attr\"\"\"\n\n    def save_instance(self, instance, modular_id, spec='app', instance_type=\"file/application\", tools_class=None):\n        \"\"\"proxi attr\"\"\"\n\n    def save_initialized_module(self, tools_class, spec):\n        \"\"\"proxi attr\"\"\"\n\n    def mod_online(self, mod_name, installed=False):\n        \"\"\"proxi attr\"\"\"\n\n    def _get_function(self,\n                      name: Enum or None,\n                      state: bool = True,\n                      specification: str = \"app\",\n                      metadata=False, as_str: tuple or None = None, r=0):\n        \"\"\"proxi attr\"\"\"\n\n    def save_exit(self):\n        \"\"\"proxi attr\"\"\"\n\n    def load_mod(self, mod_name: str, mlm='I', **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    async def init_module(self, modular):\n        return await self.load_mod(modular)\n\n    async def load_all_mods_in_file(self, working_dir=\"mods\"):\n        \"\"\"proxi attr\"\"\"\n\n    def get_all_mods(self, working_dir=\"mods\", path_to=\"./runtime\"):\n        \"\"\"proxi attr\"\"\"\n\n    def remove_all_modules(self, delete=False):\n        for mod in list(self.functions.keys()):\n            self.logger.info(f\"closing: {mod}\")\n            self.remove_mod(mod, delete=delete)\n\n    async def a_remove_all_modules(self, delete=False):\n        for mod in list(self.functions.keys()):\n            self.logger.info(f\"closing: {mod}\")\n            await self.a_remove_mod(mod, delete=delete)\n\n    def print_ok(self):\n        \"\"\"proxi attr\"\"\"\n        self.logger.info(\"OK\")\n\n    def reload_mod(self, mod_name, spec='app', is_file=True, loc=\"toolboxv2.mods.\"):\n        \"\"\"proxi attr\"\"\"\n\n    def watch_mod(self, mod_name, spec='app', loc=\"toolboxv2.mods.\", use_thread=True, path_name=None):\n        \"\"\"proxi attr\"\"\"\n\n    def remove_mod(self, mod_name, spec='app', delete=True):\n        \"\"\"proxi attr\"\"\"\n\n    async def a_remove_mod(self, mod_name, spec='app', delete=True):\n        \"\"\"proxi attr\"\"\"\n\n    def exit(self):\n        \"\"\"proxi attr\"\"\"\n\n    def web_context(self) -&gt; str:\n        \"\"\"returns the build index ( toolbox web component )\"\"\"\n\n    async def a_exit(self):\n        \"\"\"proxi attr\"\"\"\n\n    def save_load(self, modname, spec='app'):\n        \"\"\"proxi attr\"\"\"\n\n    def get_function(self, name: Enum or tuple, **kwargs):\n        \"\"\"\n        Kwargs for _get_function\n            metadata:: return the registered function dictionary\n                stateless: (function_data, None), 0\n                stateful: (function_data, higher_order_function), 0\n            state::boolean\n                specification::str default app\n        \"\"\"\n\n    def run_a_from_sync(self, function, *args):\n        \"\"\"\n        run a async fuction\n        \"\"\"\n\n    def run_bg_task_advanced(self, task, *args, **kwargs):\n        \"\"\"\n        proxi attr\n        \"\"\"\n\n    def wait_for_bg_tasks(self, timeout=None):\n        \"\"\"\n        proxi attr\n        \"\"\"\n\n    def run_bg_task(self, task):\n        \"\"\"\n                run a async fuction\n                \"\"\"\n    def run_function(self, mod_function_name: Enum or tuple,\n                     tb_run_function_with_state=True,\n                     tb_run_with_specification='app',\n                     args_=None,\n                     kwargs_=None,\n                     *args,\n                     **kwargs) -&gt; Result:\n\n        \"\"\"proxi attr\"\"\"\n\n    async def a_run_function(self, mod_function_name: Enum or tuple,\n                             tb_run_function_with_state=True,\n                             tb_run_with_specification='app',\n                             args_=None,\n                             kwargs_=None,\n                             *args,\n                             **kwargs) -&gt; Result:\n\n        \"\"\"proxi attr\"\"\"\n\n    def fuction_runner(self, function, function_data: dict, args: list, kwargs: dict, t0=.0):\n        \"\"\"\n        parameters = function_data.get('params')\n        modular_name = function_data.get('module_name')\n        function_name = function_data.get('func_name')\n        mod_function_name = f\"{modular_name}.{function_name}\"\n\n        proxi attr\n        \"\"\"\n\n    async def a_fuction_runner(self, function, function_data: dict, args: list, kwargs: dict):\n        \"\"\"\n        parameters = function_data.get('params')\n        modular_name = function_data.get('module_name')\n        function_name = function_data.get('func_name')\n        mod_function_name = f\"{modular_name}.{function_name}\"\n\n        proxi attr\n        \"\"\"\n\n    async def run_http(self, mod_function_name: Enum or str or tuple, function_name=None, method=\"GET\",\n                       args_=None,\n                       kwargs_=None,\n                       *args, **kwargs):\n        \"\"\"run a function remote via http / https\"\"\"\n\n    def run_any(self, mod_function_name: Enum or str or tuple, backwords_compability_variabel_string_holder=None,\n                get_results=False, tb_run_function_with_state=True, tb_run_with_specification='app', args_=None,\n                kwargs_=None,\n                *args, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    async def a_run_any(self, mod_function_name: Enum or str or tuple,\n                        backwords_compability_variabel_string_holder=None,\n                        get_results=False, tb_run_function_with_state=True, tb_run_with_specification='app', args_=None,\n                        kwargs_=None,\n                        *args, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    def get_mod(self, name, spec='app') -&gt; ModuleType or MainToolType:\n        \"\"\"proxi attr\"\"\"\n\n    @staticmethod\n    def print(text, *args, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    @staticmethod\n    def sprint(text, *args, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    # ----------------------------------------------------------------\n    # Decorators for the toolbox\n\n    def _register_function(self, module_name, func_name, data):\n        \"\"\"proxi attr\"\"\"\n\n    def _create_decorator(self, type_: str,\n                          name: str = \"\",\n                          mod_name: str = \"\",\n                          level: int = -1,\n                          restrict_in_virtual_mode: bool = False,\n                          api: bool = False,\n                          helper: str = \"\",\n                          version: str or None = None,\n                          initial=False,\n                          exit_f=False,\n                          test=True,\n                          samples=None,\n                          state=None,\n                          pre_compute=None,\n                          post_compute=None,\n                          memory_cache=False,\n                          file_cache=False,\n                          row=False,\n                          request_as_kwarg=False,\n                          memory_cache_max_size=100,\n                          memory_cache_ttl=300,\n                          websocket_handler: str | None = None,):\n        \"\"\"proxi attr\"\"\"\n\n        # data = {\n        #     \"type\": type_,\n        #     \"module_name\": module_name,\n        #     \"func_name\": func_name,\n        #     \"level\": level,\n        #     \"restrict_in_virtual_mode\": restrict_in_virtual_mode,\n        #     \"func\": func,\n        #     \"api\": api,\n        #     \"helper\": helper,\n        #     \"version\": version,\n        #     \"initial\": initial,\n        #     \"exit_f\": exit_f,\n        #     \"__module__\": func.__module__,\n        #     \"signature\": sig,\n        #     \"params\": params,\n        #     \"state\": (\n        #         False if len(params) == 0 else params[0] in ['self', 'state', 'app']) if state is None else state,\n        #     \"do_test\": test,\n        #     \"samples\": samples,\n        #     \"request_as_kwarg\": request_as_kwarg,\n\n    def tb(self, name=None,\n           mod_name: str = \"\",\n           helper: str = \"\",\n           version: str or None = None,\n           test: bool = True,\n           restrict_in_virtual_mode: bool = False,\n           api: bool = False,\n           initial: bool = False,\n           exit_f: bool = False,\n           test_only: bool = False,\n           memory_cache: bool = False,\n           file_cache: bool = False,\n           row=False,\n           request_as_kwarg: bool = False,\n           state: bool or None = None,\n           level: int = 0,\n           memory_cache_max_size: int = 100,\n           memory_cache_ttl: int = 300,\n           samples: list or dict or None = None,\n           interface: ToolBoxInterfaces or None or str = None,\n           pre_compute=None,\n           post_compute=None,\n           api_methods=None,\n           websocket_handler: str | None = None,\n           ):\n        \"\"\"\n    A decorator for registering and configuring functions within a module.\n\n    This decorator is used to wrap functions with additional functionality such as caching, API conversion, and lifecycle management (initialization and exit). It also handles the registration of the function in the module's function registry.\n\n    Args:\n        name (str, optional): The name to register the function under. Defaults to the function's own name.\n        mod_name (str, optional): The name of the module the function belongs to.\n        helper (str, optional): A helper string providing additional information about the function.\n        version (str or None, optional): The version of the function or module.\n        test (bool, optional): Flag to indicate if the function is for testing purposes.\n        restrict_in_virtual_mode (bool, optional): Flag to restrict the function in virtual mode.\n        api (bool, optional): Flag to indicate if the function is part of an API.\n        initial (bool, optional): Flag to indicate if the function should be executed at initialization.\n        exit_f (bool, optional): Flag to indicate if the function should be executed at exit.\n        test_only (bool, optional): Flag to indicate if the function should only be used for testing.\n        memory_cache (bool, optional): Flag to enable memory caching for the function.\n        request_as_kwarg (bool, optional): Flag to get request if the fuction is calld from api.\n        file_cache (bool, optional): Flag to enable file caching for the function.\n        row (bool, optional): rather to auto wrap the result in Result type default False means no row data aka result type\n        state (bool or None, optional): Flag to indicate if the function maintains state.\n        level (int, optional): The level of the function, used for prioritization or categorization.\n        memory_cache_max_size (int, optional): Maximum size of the memory cache.\n        memory_cache_ttl (int, optional): Time-to-live for the memory cache entries.\n        samples (list or dict or None, optional): Samples or examples of function usage.\n        interface (str, optional): The interface type for the function.\n        pre_compute (callable, optional): A function to be called before the main function.\n        post_compute (callable, optional): A function to be called after the main function.\n        api_methods (list[str], optional): default [\"AUTO\"] (GET if not params, POST if params) , GET, POST, PUT or DELETE.\n\n    Returns:\n        function: The decorated function with additional processing and registration capabilities.\n    \"\"\"\n        if interface is None:\n            interface = \"tb\"\n        if test_only and 'test' not in self.id:\n            return lambda *args, **kwargs: args\n        return self._create_decorator(interface,\n                                      name,\n                                      mod_name,\n                                      level=level,\n                                      restrict_in_virtual_mode=restrict_in_virtual_mode,\n                                      helper=helper,\n                                      api=api,\n                                      version=version,\n                                      initial=initial,\n                                      exit_f=exit_f,\n                                      test=test,\n                                      samples=samples,\n                                      state=state,\n                                      pre_compute=pre_compute,\n                                      post_compute=post_compute,\n                                      memory_cache=memory_cache,\n                                      file_cache=file_cache,\n                                      row=row,\n                                      request_as_kwarg=request_as_kwarg,\n                                      memory_cache_max_size=memory_cache_max_size,\n                                      memory_cache_ttl=memory_cache_ttl)\n\n    def print_functions(self, name=None):\n\n\n        if not self.functions:\n            print(\"Nothing to see\")\n            return\n\n        def helper(_functions):\n            for func_name, data in _functions.items():\n                if not isinstance(data, dict):\n                    continue\n\n                func_type = data.get('type', 'Unknown')\n                func_level = 'r' if data['level'] == -1 else data['level']\n                api_status = 'Api' if data.get('api', False) else 'Non-Api'\n\n                print(f\"  Function: {func_name}{data.get('signature', '()')}; \"\n                      f\"Type: {func_type}, Level: {func_level}, {api_status}\")\n\n        if name is not None:\n            functions = self.functions.get(name)\n            if functions is not None:\n                print(f\"\\nModule: {name}; Type: {functions.get('app_instance_type', 'Unknown')}\")\n                helper(functions)\n                return\n        for module, functions in self.functions.items():\n            print(f\"\\nModule: {module}; Type: {functions.get('app_instance_type', 'Unknown')}\")\n            helper(functions)\n\n    def save_autocompletion_dict(self):\n        \"\"\"proxi attr\"\"\"\n\n    def get_autocompletion_dict(self):\n        \"\"\"proxi attr\"\"\"\n\n    def get_username(self, get_input=False, default=\"loot\") -&gt; str:\n        \"\"\"proxi attr\"\"\"\n\n    def save_registry_as_enums(self, directory: str, filename: str):\n        \"\"\"proxi attr\"\"\"\n\n    async def execute_all_functions_(self, m_query='', f_query=''):\n        print(\"Executing all functions\")\n        from ..extras import generate_test_cases\n        all_data = {\n            \"modular_run\": 0,\n            \"modular_fatal_error\": 0,\n            \"errors\": 0,\n            \"modular_sug\": 0,\n            \"coverage\": [],\n            \"total_coverage\": {},\n        }\n        items = list(self.functions.items()).copy()\n        for module_name, functions in items:\n            infos = {\n                \"functions_run\": 0,\n                \"functions_fatal_error\": 0,\n                \"error\": 0,\n                \"functions_sug\": 0,\n                'calls': {},\n                'callse': {},\n                \"coverage\": [0, 0],\n            }\n            all_data['modular_run'] += 1\n            if not module_name.startswith(m_query):\n                all_data['modular_sug'] += 1\n                continue\n\n            with Spinner(message=f\"In {module_name}| \"):\n                f_items = list(functions.items()).copy()\n                for function_name, function_data in f_items:\n                    if not isinstance(function_data, dict):\n                        continue\n                    if not function_name.startswith(f_query):\n                        continue\n                    test: list = function_data.get('do_test')\n                    # print(test, module_name, function_name, function_data)\n                    infos[\"coverage\"][0] += 1\n                    if test is False:\n                        continue\n\n                    with Spinner(message=f\"\\t\\t\\t\\t\\t\\tfuction {function_name}...\"):\n                        params: list = function_data.get('params')\n                        sig: signature = function_data.get('signature')\n                        state: bool = function_data.get('state')\n                        samples: bool = function_data.get('samples')\n\n                        test_kwargs_list = [{}]\n\n                        if params is not None:\n                            test_kwargs_list = samples if samples is not None else generate_test_cases(sig=sig)\n                            # print(test_kwargs)\n                            # print(test_kwargs[0])\n                            # test_kwargs = test_kwargs_list[0]\n                        # print(module_name, function_name, test_kwargs_list)\n                        infos[\"coverage\"][1] += 1\n                        for test_kwargs in test_kwargs_list:\n                            try:\n                                # print(f\"test Running {state=} |{module_name}.{function_name}\")\n                                result = await self.a_run_function((module_name, function_name),\n                                                                   tb_run_function_with_state=state,\n                                                                   **test_kwargs)\n                                if not isinstance(result, Result):\n                                    result = Result.ok(result)\n                                if result.info.exec_code == 0:\n                                    infos['calls'][function_name] = [test_kwargs, str(result)]\n                                    infos['functions_sug'] += 1\n                                else:\n                                    infos['functions_sug'] += 1\n                                    infos['error'] += 1\n                                    infos['callse'][function_name] = [test_kwargs, str(result)]\n                            except Exception as e:\n                                infos['functions_fatal_error'] += 1\n                                infos['callse'][function_name] = [test_kwargs, str(e)]\n                            finally:\n                                infos['functions_run'] += 1\n\n                if infos['functions_run'] == infos['functions_sug']:\n                    all_data['modular_sug'] += 1\n                else:\n                    all_data['modular_fatal_error'] += 1\n                if infos['error'] &gt; 0:\n                    all_data['errors'] += infos['error']\n\n                all_data[module_name] = infos\n                if infos['coverage'][0] == 0:\n                    c = 0\n                else:\n                    c = infos['coverage'][1] / infos['coverage'][0]\n                all_data[\"coverage\"].append(f\"{module_name}:{c:.2f}\\n\")\n        total_coverage = sum([float(t.split(\":\")[-1]) for t in all_data[\"coverage\"]]) / len(all_data[\"coverage\"])\n        print(\n            f\"\\n{all_data['modular_run']=}\\n{all_data['modular_sug']=}\\n{all_data['modular_fatal_error']=}\\n{total_coverage=}\")\n        d = analyze_data(all_data)\n        return Result.ok(data=all_data, data_info=d)\n\n    @staticmethod\n    def calculate_complexity(filename_or_code):\n        from radon.complexity import cc_rank, cc_visit\n        if os.path.exists(filename_or_code):\n            with open(filename_or_code) as file:\n                code = file.read()\n        else:\n            code = filename_or_code\n\n        # Calculate and print Cyclomatic Complexity\n        complexity_results = cc_visit(code)\n        i = -1\n        avg_complexity = 0\n        for block in complexity_results:\n            complexity = block.complexity\n            i += 1\n            print(f\"block: {block.name} {i} Class/Fuction/Methode : {block.letter}\")\n            print(f\"    fullname: {block.fullname}\")\n            print(f\"    Cyclomatic Complexity: {complexity}\")\n            # Optional: Get complexity rank\n            avg_complexity += complexity\n            rank = cc_rank(complexity)\n            print(f\"    Complexity Rank: {rank}\")\n            # print(f\"    lineno: {block.lineno}\")\n            print(f\"    endline: {block.endline}\")\n            print(f\"    col_offset: {block.col_offset}\\n\")\n        if i &lt;= 0:\n            i += 2\n        avg_complexity = avg_complexity / i\n        print(f\"\\nAVG Complexity: {avg_complexity:.2f}\")\n        print(f\"Total Rank: {cc_rank(int(avg_complexity + i // 10))}\")\n\n    async def execute_function_test(self, module_name: str, function_name: str,\n                                    function_data: dict, test_kwargs: dict,\n                                    profiler: cProfile.Profile) -&gt; tuple[bool, str, dict, float]:\n        start_time = time.time()\n        with profile_section(profiler, hasattr(self, 'enable_profiling') and self.enable_profiling):\n            try:\n                result = await self.a_run_function(\n                    (module_name, function_name),\n                    tb_run_function_with_state=function_data.get('state'),\n                    **test_kwargs\n                )\n\n                if not isinstance(result, Result):\n                    result = Result.ok(result)\n\n                success = result.info.exec_code == 0\n                execution_time = time.time() - start_time\n                return success, str(result), test_kwargs, execution_time\n            except Exception as e:\n                execution_time = time.time() - start_time\n                return False, str(e), test_kwargs, execution_time\n\n    async def process_function(self, module_name: str, function_name: str,\n                               function_data: dict, profiler: cProfile.Profile) -&gt; tuple[str, ModuleInfo]:\n        start_time = time.time()\n        info = ModuleInfo()\n\n        with profile_section(profiler, hasattr(self, 'enable_profiling') and self.enable_profiling):\n            if not isinstance(function_data, dict):\n                return function_name, info\n\n            test = function_data.get('do_test')\n            info.coverage[0] += 1\n\n            if test is False:\n                return function_name, info\n\n            params = function_data.get('params')\n            sig = function_data.get('signature')\n            samples = function_data.get('samples')\n\n            test_kwargs_list = [{}] if params is None else (\n                samples if samples is not None else generate_test_cases(sig=sig)\n            )\n\n            info.coverage[1] += 1\n\n            # Create tasks for all test cases\n            tasks = [\n                self.execute_function_test(module_name, function_name, function_data, test_kwargs, profiler)\n                for test_kwargs in test_kwargs_list\n            ]\n\n            # Execute all tests concurrently\n            results = await asyncio.gather(*tasks)\n\n            total_execution_time = 0\n            for success, result_str, test_kwargs, execution_time in results:\n                info.functions_run += 1\n                total_execution_time += execution_time\n\n                if success:\n                    info.functions_sug += 1\n                    info.calls[function_name] = [test_kwargs, result_str]\n                else:\n                    info.functions_sug += 1\n                    info.error += 1\n                    info.callse[function_name] = [test_kwargs, result_str]\n\n            info.execution_time = time.time() - start_time\n            return function_name, info\n\n    async def process_module(self, module_name: str, functions: dict,\n                             f_query: str, profiler: cProfile.Profile) -&gt; tuple[str, ModuleInfo]:\n        start_time = time.time()\n\n        with profile_section(profiler, hasattr(self, 'enable_profiling') and self.enable_profiling):\n            async with asyncio.Semaphore(mp.cpu_count()):\n                tasks = [\n                    self.process_function(module_name, fname, fdata, profiler)\n                    for fname, fdata in functions.items()\n                    if fname.startswith(f_query)\n                ]\n\n                if not tasks:\n                    return module_name, ModuleInfo()\n\n                results = await asyncio.gather(*tasks)\n\n                # Combine results from all functions in the module\n                combined_info = ModuleInfo()\n                total_execution_time = 0\n\n                for _, info in results:\n                    combined_info.functions_run += info.functions_run\n                    combined_info.functions_fatal_error += info.functions_fatal_error\n                    combined_info.error += info.error\n                    combined_info.functions_sug += info.functions_sug\n                    combined_info.calls.update(info.calls)\n                    combined_info.callse.update(info.callse)\n                    combined_info.coverage[0] += info.coverage[0]\n                    combined_info.coverage[1] += info.coverage[1]\n                    total_execution_time += info.execution_time\n\n                combined_info.execution_time = time.time() - start_time\n                return module_name, combined_info\n\n    async def execute_all_functions(self, m_query='', f_query='', enable_profiling=True):\n        \"\"\"\n        Execute all functions with parallel processing and optional profiling.\n\n        Args:\n            m_query (str): Module name query filter\n            f_query (str): Function name query filter\n            enable_profiling (bool): Enable detailed profiling information\n        \"\"\"\n        print(\"Executing all functions in parallel\" + (\" with profiling\" if enable_profiling else \"\"))\n\n        start_time = time.time()\n        stats = ExecutionStats()\n        items = list(self.functions.items()).copy()\n\n        # Set up profiling\n        self.enable_profiling = enable_profiling\n        profiler = cProfile.Profile()\n\n        with profile_section(profiler, enable_profiling):\n            # Filter modules based on query\n            filtered_modules = [\n                (mname, mfuncs) for mname, mfuncs in items\n                if mname.startswith(m_query)\n            ]\n\n            stats.modular_run = len(filtered_modules)\n\n            # Process all modules concurrently\n            async with asyncio.Semaphore(mp.cpu_count()):\n                tasks = [\n                    self.process_module(mname, mfuncs, f_query, profiler)\n                    for mname, mfuncs in filtered_modules\n                ]\n\n                results = await asyncio.gather(*tasks)\n\n            # Combine results and calculate statistics\n            for module_name, info in results:\n                if info.functions_run == info.functions_sug:\n                    stats.modular_sug += 1\n                else:\n                    stats.modular_fatal_error += 1\n\n                stats.errors += info.error\n\n                # Calculate coverage\n                coverage = (info.coverage[1] / info.coverage[0]) if info.coverage[0] &gt; 0 else 0\n                stats.coverage.append(f\"{module_name}:{coverage:.2f}\\n\")\n\n                # Store module info\n                stats.__dict__[module_name] = info\n\n            # Calculate total coverage\n            total_coverage = (\n                sum(float(t.split(\":\")[-1]) for t in stats.coverage) / len(stats.coverage)\n                if stats.coverage else 0\n            )\n\n            stats.total_execution_time = time.time() - start_time\n\n            # Generate profiling stats if enabled\n            if enable_profiling:\n                s = io.StringIO()\n                ps = pstats.Stats(profiler, stream=s).sort_stats('cumulative')\n                ps.print_stats()\n                stats.profiling_data = {\n                    'detailed_stats': s.getvalue(),\n                    'total_time': stats.total_execution_time,\n                    'function_count': stats.modular_run,\n                    'successful_functions': stats.modular_sug\n                }\n\n            print(\n                f\"\\n{stats.modular_run=}\"\n                f\"\\n{stats.modular_sug=}\"\n                f\"\\n{stats.modular_fatal_error=}\"\n                f\"\\n{total_coverage=}\"\n                f\"\\nTotal execution time: {stats.total_execution_time:.2f}s\"\n            )\n\n            if enable_profiling:\n                print(\"\\nProfiling Summary:\")\n                print(f\"{'=' * 50}\")\n                print(\"Top 10 time-consuming functions:\")\n                ps.print_stats(10)\n\n            analyzed_data = analyze_data(stats.__dict__)\n            return Result.ok(data=stats.__dict__, data_info=analyzed_data)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.debug","title":"<code>debug</code>  <code>property</code> <code>writable</code>","text":"<p>proxi attr</p>"},{"location":"toolboxv2/#toolboxv2.AppType.prefix","title":"<code>prefix = prefix</code>  <code>instance-attribute</code>","text":"<p>proxi attr</p>"},{"location":"toolboxv2/#toolboxv2.AppType.a_exit","title":"<code>a_exit()</code>  <code>async</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>async def a_exit(self):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.a_fuction_runner","title":"<code>a_fuction_runner(function, function_data, args, kwargs)</code>  <code>async</code>","text":"<p>parameters = function_data.get('params') modular_name = function_data.get('module_name') function_name = function_data.get('func_name') mod_function_name = f\"{modular_name}.{function_name}\"</p> <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>async def a_fuction_runner(self, function, function_data: dict, args: list, kwargs: dict):\n    \"\"\"\n    parameters = function_data.get('params')\n    modular_name = function_data.get('module_name')\n    function_name = function_data.get('func_name')\n    mod_function_name = f\"{modular_name}.{function_name}\"\n\n    proxi attr\n    \"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.a_remove_mod","title":"<code>a_remove_mod(mod_name, spec='app', delete=True)</code>  <code>async</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>async def a_remove_mod(self, mod_name, spec='app', delete=True):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.a_run_any","title":"<code>a_run_any(mod_function_name, backwords_compability_variabel_string_holder=None, get_results=False, tb_run_function_with_state=True, tb_run_with_specification='app', args_=None, kwargs_=None, *args, **kwargs)</code>  <code>async</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>async def a_run_any(self, mod_function_name: Enum or str or tuple,\n                    backwords_compability_variabel_string_holder=None,\n                    get_results=False, tb_run_function_with_state=True, tb_run_with_specification='app', args_=None,\n                    kwargs_=None,\n                    *args, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.a_run_function","title":"<code>a_run_function(mod_function_name, tb_run_function_with_state=True, tb_run_with_specification='app', args_=None, kwargs_=None, *args, **kwargs)</code>  <code>async</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>async def a_run_function(self, mod_function_name: Enum or tuple,\n                         tb_run_function_with_state=True,\n                         tb_run_with_specification='app',\n                         args_=None,\n                         kwargs_=None,\n                         *args,\n                         **kwargs) -&gt; Result:\n\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.debug_rains","title":"<code>debug_rains(e)</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def debug_rains(self, e):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.disconnect","title":"<code>disconnect(*args, **kwargs)</code>  <code>async</code> <code>staticmethod</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@staticmethod\nasync def disconnect(*args, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.execute_all_functions","title":"<code>execute_all_functions(m_query='', f_query='', enable_profiling=True)</code>  <code>async</code>","text":"<p>Execute all functions with parallel processing and optional profiling.</p> <p>Parameters:</p> Name Type Description Default <code>m_query</code> <code>str</code> <p>Module name query filter</p> <code>''</code> <code>f_query</code> <code>str</code> <p>Function name query filter</p> <code>''</code> <code>enable_profiling</code> <code>bool</code> <p>Enable detailed profiling information</p> <code>True</code> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>async def execute_all_functions(self, m_query='', f_query='', enable_profiling=True):\n    \"\"\"\n    Execute all functions with parallel processing and optional profiling.\n\n    Args:\n        m_query (str): Module name query filter\n        f_query (str): Function name query filter\n        enable_profiling (bool): Enable detailed profiling information\n    \"\"\"\n    print(\"Executing all functions in parallel\" + (\" with profiling\" if enable_profiling else \"\"))\n\n    start_time = time.time()\n    stats = ExecutionStats()\n    items = list(self.functions.items()).copy()\n\n    # Set up profiling\n    self.enable_profiling = enable_profiling\n    profiler = cProfile.Profile()\n\n    with profile_section(profiler, enable_profiling):\n        # Filter modules based on query\n        filtered_modules = [\n            (mname, mfuncs) for mname, mfuncs in items\n            if mname.startswith(m_query)\n        ]\n\n        stats.modular_run = len(filtered_modules)\n\n        # Process all modules concurrently\n        async with asyncio.Semaphore(mp.cpu_count()):\n            tasks = [\n                self.process_module(mname, mfuncs, f_query, profiler)\n                for mname, mfuncs in filtered_modules\n            ]\n\n            results = await asyncio.gather(*tasks)\n\n        # Combine results and calculate statistics\n        for module_name, info in results:\n            if info.functions_run == info.functions_sug:\n                stats.modular_sug += 1\n            else:\n                stats.modular_fatal_error += 1\n\n            stats.errors += info.error\n\n            # Calculate coverage\n            coverage = (info.coverage[1] / info.coverage[0]) if info.coverage[0] &gt; 0 else 0\n            stats.coverage.append(f\"{module_name}:{coverage:.2f}\\n\")\n\n            # Store module info\n            stats.__dict__[module_name] = info\n\n        # Calculate total coverage\n        total_coverage = (\n            sum(float(t.split(\":\")[-1]) for t in stats.coverage) / len(stats.coverage)\n            if stats.coverage else 0\n        )\n\n        stats.total_execution_time = time.time() - start_time\n\n        # Generate profiling stats if enabled\n        if enable_profiling:\n            s = io.StringIO()\n            ps = pstats.Stats(profiler, stream=s).sort_stats('cumulative')\n            ps.print_stats()\n            stats.profiling_data = {\n                'detailed_stats': s.getvalue(),\n                'total_time': stats.total_execution_time,\n                'function_count': stats.modular_run,\n                'successful_functions': stats.modular_sug\n            }\n\n        print(\n            f\"\\n{stats.modular_run=}\"\n            f\"\\n{stats.modular_sug=}\"\n            f\"\\n{stats.modular_fatal_error=}\"\n            f\"\\n{total_coverage=}\"\n            f\"\\nTotal execution time: {stats.total_execution_time:.2f}s\"\n        )\n\n        if enable_profiling:\n            print(\"\\nProfiling Summary:\")\n            print(f\"{'=' * 50}\")\n            print(\"Top 10 time-consuming functions:\")\n            ps.print_stats(10)\n\n        analyzed_data = analyze_data(stats.__dict__)\n        return Result.ok(data=stats.__dict__, data_info=analyzed_data)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.exit","title":"<code>exit()</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def exit(self):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.exit_main","title":"<code>exit_main(*args, **kwargs)</code>  <code>staticmethod</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@staticmethod\ndef exit_main(*args, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.fuction_runner","title":"<code>fuction_runner(function, function_data, args, kwargs, t0=0.0)</code>","text":"<p>parameters = function_data.get('params') modular_name = function_data.get('module_name') function_name = function_data.get('func_name') mod_function_name = f\"{modular_name}.{function_name}\"</p> <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def fuction_runner(self, function, function_data: dict, args: list, kwargs: dict, t0=.0):\n    \"\"\"\n    parameters = function_data.get('params')\n    modular_name = function_data.get('module_name')\n    function_name = function_data.get('func_name')\n    mod_function_name = f\"{modular_name}.{function_name}\"\n\n    proxi attr\n    \"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.get_all_mods","title":"<code>get_all_mods(working_dir='mods', path_to='./runtime')</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def get_all_mods(self, working_dir=\"mods\", path_to=\"./runtime\"):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.get_autocompletion_dict","title":"<code>get_autocompletion_dict()</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def get_autocompletion_dict(self):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.get_function","title":"<code>get_function(name, **kwargs)</code>","text":"<p>Kwargs for _get_function     metadata:: return the registered function dictionary         stateless: (function_data, None), 0         stateful: (function_data, higher_order_function), 0     state::boolean         specification::str default app</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def get_function(self, name: Enum or tuple, **kwargs):\n    \"\"\"\n    Kwargs for _get_function\n        metadata:: return the registered function dictionary\n            stateless: (function_data, None), 0\n            stateful: (function_data, higher_order_function), 0\n        state::boolean\n            specification::str default app\n    \"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.get_mod","title":"<code>get_mod(name, spec='app')</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def get_mod(self, name, spec='app') -&gt; ModuleType or MainToolType:\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.get_username","title":"<code>get_username(get_input=False, default='loot')</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def get_username(self, get_input=False, default=\"loot\") -&gt; str:\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.hide_console","title":"<code>hide_console(*args, **kwargs)</code>  <code>async</code> <code>staticmethod</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@staticmethod\nasync def hide_console(*args, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.inplace_load_instance","title":"<code>inplace_load_instance(mod_name, loc='toolboxv2.mods.', spec='app', save=True)</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def inplace_load_instance(self, mod_name, loc=\"toolboxv2.mods.\", spec='app', save=True):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.load_all_mods_in_file","title":"<code>load_all_mods_in_file(working_dir='mods')</code>  <code>async</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>async def load_all_mods_in_file(self, working_dir=\"mods\"):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.load_mod","title":"<code>load_mod(mod_name, mlm='I', **kwargs)</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def load_mod(self, mod_name: str, mlm='I', **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.mod_online","title":"<code>mod_online(mod_name, installed=False)</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def mod_online(self, mod_name, installed=False):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.print","title":"<code>print(text, *args, **kwargs)</code>  <code>staticmethod</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@staticmethod\ndef print(text, *args, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.print_ok","title":"<code>print_ok()</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def print_ok(self):\n    \"\"\"proxi attr\"\"\"\n    self.logger.info(\"OK\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.reload_mod","title":"<code>reload_mod(mod_name, spec='app', is_file=True, loc='toolboxv2.mods.')</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def reload_mod(self, mod_name, spec='app', is_file=True, loc=\"toolboxv2.mods.\"):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.remove_mod","title":"<code>remove_mod(mod_name, spec='app', delete=True)</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def remove_mod(self, mod_name, spec='app', delete=True):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.rrun_flows","title":"<code>rrun_flows(name, **kwargs)</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def rrun_flows(self, name, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.run_a_from_sync","title":"<code>run_a_from_sync(function, *args)</code>","text":"<p>run a async fuction</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def run_a_from_sync(self, function, *args):\n    \"\"\"\n    run a async fuction\n    \"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.run_any","title":"<code>run_any(mod_function_name, backwords_compability_variabel_string_holder=None, get_results=False, tb_run_function_with_state=True, tb_run_with_specification='app', args_=None, kwargs_=None, *args, **kwargs)</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def run_any(self, mod_function_name: Enum or str or tuple, backwords_compability_variabel_string_holder=None,\n            get_results=False, tb_run_function_with_state=True, tb_run_with_specification='app', args_=None,\n            kwargs_=None,\n            *args, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.run_bg_task","title":"<code>run_bg_task(task)</code>","text":"<p>run a async fuction</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def run_bg_task(self, task):\n    \"\"\"\n            run a async fuction\n            \"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.run_bg_task_advanced","title":"<code>run_bg_task_advanced(task, *args, **kwargs)</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def run_bg_task_advanced(self, task, *args, **kwargs):\n    \"\"\"\n    proxi attr\n    \"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.run_flows","title":"<code>run_flows(name, **kwargs)</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def run_flows(self, name, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.run_function","title":"<code>run_function(mod_function_name, tb_run_function_with_state=True, tb_run_with_specification='app', args_=None, kwargs_=None, *args, **kwargs)</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def run_function(self, mod_function_name: Enum or tuple,\n                 tb_run_function_with_state=True,\n                 tb_run_with_specification='app',\n                 args_=None,\n                 kwargs_=None,\n                 *args,\n                 **kwargs) -&gt; Result:\n\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.run_http","title":"<code>run_http(mod_function_name, function_name=None, method='GET', args_=None, kwargs_=None, *args, **kwargs)</code>  <code>async</code>","text":"<p>run a function remote via http / https</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>async def run_http(self, mod_function_name: Enum or str or tuple, function_name=None, method=\"GET\",\n                   args_=None,\n                   kwargs_=None,\n                   *args, **kwargs):\n    \"\"\"run a function remote via http / https\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.save_autocompletion_dict","title":"<code>save_autocompletion_dict()</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def save_autocompletion_dict(self):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.save_exit","title":"<code>save_exit()</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def save_exit(self):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.save_initialized_module","title":"<code>save_initialized_module(tools_class, spec)</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def save_initialized_module(self, tools_class, spec):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.save_instance","title":"<code>save_instance(instance, modular_id, spec='app', instance_type='file/application', tools_class=None)</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def save_instance(self, instance, modular_id, spec='app', instance_type=\"file/application\", tools_class=None):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.save_load","title":"<code>save_load(modname, spec='app')</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def save_load(self, modname, spec='app'):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.save_registry_as_enums","title":"<code>save_registry_as_enums(directory, filename)</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def save_registry_as_enums(self, directory: str, filename: str):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.set_flows","title":"<code>set_flows(r)</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def set_flows(self, r):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.set_logger","title":"<code>set_logger(debug=False)</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def set_logger(self, debug=False):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.show_console","title":"<code>show_console(*args, **kwargs)</code>  <code>async</code> <code>staticmethod</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@staticmethod\nasync def show_console(*args, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.sprint","title":"<code>sprint(text, *args, **kwargs)</code>  <code>staticmethod</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@staticmethod\ndef sprint(text, *args, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.tb","title":"<code>tb(name=None, mod_name='', helper='', version=None, test=True, restrict_in_virtual_mode=False, api=False, initial=False, exit_f=False, test_only=False, memory_cache=False, file_cache=False, row=False, request_as_kwarg=False, state=None, level=0, memory_cache_max_size=100, memory_cache_ttl=300, samples=None, interface=None, pre_compute=None, post_compute=None, api_methods=None, websocket_handler=None)</code>","text":"<p>A decorator for registering and configuring functions within a module.</p> <p>This decorator is used to wrap functions with additional functionality such as caching, API conversion, and lifecycle management (initialization and exit). It also handles the registration of the function in the module's function registry.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name to register the function under. Defaults to the function's own name.</p> <code>None</code> <code>mod_name</code> <code>str</code> <p>The name of the module the function belongs to.</p> <code>''</code> <code>helper</code> <code>str</code> <p>A helper string providing additional information about the function.</p> <code>''</code> <code>version</code> <code>str or None</code> <p>The version of the function or module.</p> <code>None</code> <code>test</code> <code>bool</code> <p>Flag to indicate if the function is for testing purposes.</p> <code>True</code> <code>restrict_in_virtual_mode</code> <code>bool</code> <p>Flag to restrict the function in virtual mode.</p> <code>False</code> <code>api</code> <code>bool</code> <p>Flag to indicate if the function is part of an API.</p> <code>False</code> <code>initial</code> <code>bool</code> <p>Flag to indicate if the function should be executed at initialization.</p> <code>False</code> <code>exit_f</code> <code>bool</code> <p>Flag to indicate if the function should be executed at exit.</p> <code>False</code> <code>test_only</code> <code>bool</code> <p>Flag to indicate if the function should only be used for testing.</p> <code>False</code> <code>memory_cache</code> <code>bool</code> <p>Flag to enable memory caching for the function.</p> <code>False</code> <code>request_as_kwarg</code> <code>bool</code> <p>Flag to get request if the fuction is calld from api.</p> <code>False</code> <code>file_cache</code> <code>bool</code> <p>Flag to enable file caching for the function.</p> <code>False</code> <code>row</code> <code>bool</code> <p>rather to auto wrap the result in Result type default False means no row data aka result type</p> <code>False</code> <code>state</code> <code>bool or None</code> <p>Flag to indicate if the function maintains state.</p> <code>None</code> <code>level</code> <code>int</code> <p>The level of the function, used for prioritization or categorization.</p> <code>0</code> <code>memory_cache_max_size</code> <code>int</code> <p>Maximum size of the memory cache.</p> <code>100</code> <code>memory_cache_ttl</code> <code>int</code> <p>Time-to-live for the memory cache entries.</p> <code>300</code> <code>samples</code> <code>list or dict or None</code> <p>Samples or examples of function usage.</p> <code>None</code> <code>interface</code> <code>str</code> <p>The interface type for the function.</p> <code>None</code> <code>pre_compute</code> <code>callable</code> <p>A function to be called before the main function.</p> <code>None</code> <code>post_compute</code> <code>callable</code> <p>A function to be called after the main function.</p> <code>None</code> <code>api_methods</code> <code>list[str]</code> <p>default [\"AUTO\"] (GET if not params, POST if params) , GET, POST, PUT or DELETE.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>function</code> <p>The decorated function with additional processing and registration capabilities.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def tb(self, name=None,\n       mod_name: str = \"\",\n       helper: str = \"\",\n       version: str or None = None,\n       test: bool = True,\n       restrict_in_virtual_mode: bool = False,\n       api: bool = False,\n       initial: bool = False,\n       exit_f: bool = False,\n       test_only: bool = False,\n       memory_cache: bool = False,\n       file_cache: bool = False,\n       row=False,\n       request_as_kwarg: bool = False,\n       state: bool or None = None,\n       level: int = 0,\n       memory_cache_max_size: int = 100,\n       memory_cache_ttl: int = 300,\n       samples: list or dict or None = None,\n       interface: ToolBoxInterfaces or None or str = None,\n       pre_compute=None,\n       post_compute=None,\n       api_methods=None,\n       websocket_handler: str | None = None,\n       ):\n    \"\"\"\nA decorator for registering and configuring functions within a module.\n\nThis decorator is used to wrap functions with additional functionality such as caching, API conversion, and lifecycle management (initialization and exit). It also handles the registration of the function in the module's function registry.\n\nArgs:\n    name (str, optional): The name to register the function under. Defaults to the function's own name.\n    mod_name (str, optional): The name of the module the function belongs to.\n    helper (str, optional): A helper string providing additional information about the function.\n    version (str or None, optional): The version of the function or module.\n    test (bool, optional): Flag to indicate if the function is for testing purposes.\n    restrict_in_virtual_mode (bool, optional): Flag to restrict the function in virtual mode.\n    api (bool, optional): Flag to indicate if the function is part of an API.\n    initial (bool, optional): Flag to indicate if the function should be executed at initialization.\n    exit_f (bool, optional): Flag to indicate if the function should be executed at exit.\n    test_only (bool, optional): Flag to indicate if the function should only be used for testing.\n    memory_cache (bool, optional): Flag to enable memory caching for the function.\n    request_as_kwarg (bool, optional): Flag to get request if the fuction is calld from api.\n    file_cache (bool, optional): Flag to enable file caching for the function.\n    row (bool, optional): rather to auto wrap the result in Result type default False means no row data aka result type\n    state (bool or None, optional): Flag to indicate if the function maintains state.\n    level (int, optional): The level of the function, used for prioritization or categorization.\n    memory_cache_max_size (int, optional): Maximum size of the memory cache.\n    memory_cache_ttl (int, optional): Time-to-live for the memory cache entries.\n    samples (list or dict or None, optional): Samples or examples of function usage.\n    interface (str, optional): The interface type for the function.\n    pre_compute (callable, optional): A function to be called before the main function.\n    post_compute (callable, optional): A function to be called after the main function.\n    api_methods (list[str], optional): default [\"AUTO\"] (GET if not params, POST if params) , GET, POST, PUT or DELETE.\n\nReturns:\n    function: The decorated function with additional processing and registration capabilities.\n\"\"\"\n    if interface is None:\n        interface = \"tb\"\n    if test_only and 'test' not in self.id:\n        return lambda *args, **kwargs: args\n    return self._create_decorator(interface,\n                                  name,\n                                  mod_name,\n                                  level=level,\n                                  restrict_in_virtual_mode=restrict_in_virtual_mode,\n                                  helper=helper,\n                                  api=api,\n                                  version=version,\n                                  initial=initial,\n                                  exit_f=exit_f,\n                                  test=test,\n                                  samples=samples,\n                                  state=state,\n                                  pre_compute=pre_compute,\n                                  post_compute=post_compute,\n                                  memory_cache=memory_cache,\n                                  file_cache=file_cache,\n                                  row=row,\n                                  request_as_kwarg=request_as_kwarg,\n                                  memory_cache_max_size=memory_cache_max_size,\n                                  memory_cache_ttl=memory_cache_ttl)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.wait_for_bg_tasks","title":"<code>wait_for_bg_tasks(timeout=None)</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def wait_for_bg_tasks(self, timeout=None):\n    \"\"\"\n    proxi attr\n    \"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.watch_mod","title":"<code>watch_mod(mod_name, spec='app', loc='toolboxv2.mods.', use_thread=True, path_name=None)</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def watch_mod(self, mod_name, spec='app', loc=\"toolboxv2.mods.\", use_thread=True, path_name=None):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.AppType.web_context","title":"<code>web_context()</code>","text":"<p>returns the build index ( toolbox web component )</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def web_context(self) -&gt; str:\n    \"\"\"returns the build index ( toolbox web component )\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.MainTool","title":"<code>toolboxv2.MainTool</code>","text":"Source code in <code>toolboxv2/utils/system/main_tool.py</code> <pre><code>class MainTool:\n    toolID: str = \"\"\n    # app = None\n    interface = None\n    spec = \"app\"\n    name = \"\"\n    color = \"Bold\"\n    stuf = False\n\n    def __init__(self, *args, **kwargs):\n        \"\"\"\n        Standard constructor used for arguments pass\n        Do not override. Use __ainit__ instead\n        \"\"\"\n        self.__storedargs = args, kwargs\n        self.tools = kwargs.get(\"tool\", {})\n        self.logger = kwargs.get(\"logs\", get_logger())\n        self.color = kwargs.get(\"color\", \"WHITE\")\n        self.todo = kwargs.get(\"load\", kwargs.get(\"on_start\", lambda: None))\n        if \"on_exit\" in kwargs and isinstance(kwargs.get(\"on_exit\"), Callable):\n            self.on_exit =self.app.tb(\n                mod_name=self.name,\n                name=kwargs.get(\"on_exit\").__name__,\n                version=self.version if hasattr(self, 'version') else \"0.0.0\",\n            )(kwargs.get(\"on_exit\"))\n        self.async_initialized = False\n        if self.todo:\n            try:\n                if inspect.iscoroutinefunction(self.todo):\n                    pass\n                else:\n                    self.todo()\n                get_logger().info(f\"{self.name} on load suspended\")\n            except Exception as e:\n                get_logger().error(f\"Error loading mod {self.name} {e}\")\n                if self.app.debug:\n                    import traceback\n                    traceback.print_exc()\n        else:\n            get_logger().info(f\"{self.name} no load require\")\n\n    async def __ainit__(self, *args, **kwargs):\n        self.version = kwargs[\"v\"]\n        self.tools = kwargs.get(\"tool\", {})\n        self.name = kwargs[\"name\"]\n        self.logger = kwargs.get(\"logs\", get_logger())\n        self.color = kwargs.get(\"color\", \"WHITE\")\n        self.todo = kwargs.get(\"load\", kwargs.get(\"on_start\"))\n        if not hasattr(self, 'config'):\n            self.config = {}\n        self.user = None\n        self.description = \"A toolbox mod\" if kwargs.get(\"description\") is None else kwargs.get(\"description\")\n        if MainTool.interface is None:\n            MainTool.interface = self.app.interface_type\n        # Result.default(self.app.interface)\n\n        if self.todo:\n            try:\n                if inspect.iscoroutinefunction(self.todo):\n                    await self.todo()\n                else:\n                    pass\n                await asyncio.sleep(0.1)\n                get_logger().info(f\"{self.name} on load suspended\")\n            except Exception as e:\n                get_logger().error(f\"Error loading mod {self.name} {e}\")\n                if self.app.debug:\n                    import traceback\n                    traceback.print_exc()\n        else:\n            get_logger().info(f\"{self.name} no load require\")\n        self.app.print(f\"TOOL : {self.spec}.{self.name} online\")\n\n\n\n    @property\n    def app(self):\n        return get_app(\n            from_=f\"{self.spec}.{self.name}|{self.toolID if self.toolID else '*' + MainTool.toolID} {self.interface if self.interface else MainTool.interface}\")\n\n    @app.setter\n    def app(self, v):\n        raise PermissionError(f\"You cannot set the App Instance! {v=}\")\n\n    @staticmethod\n    def return_result(error: ToolBoxError = ToolBoxError.none,\n                      exec_code: int = 0,\n                      help_text: str = \"\",\n                      data_info=None,\n                      data=None,\n                      data_to=None):\n\n        if data_to is None:\n            data_to = MainTool.interface if MainTool.interface is not None else ToolBoxInterfaces.cli\n\n        if data is None:\n            data = {}\n\n        if data_info is None:\n            data_info = {}\n\n        return Result(\n            error,\n            ToolBoxResult(data_info=data_info, data=data, data_to=data_to),\n            ToolBoxInfo(exec_code=exec_code, help_text=help_text)\n        )\n\n    def print(self, message, end=\"\\n\", **kwargs):\n        if self.stuf:\n            return\n\n        self.app.print(Style.style_dic[self.color] + self.name + Style.style_dic[\"END\"] + \":\", message, end=end,\n                       **kwargs)\n\n    def add_str_to_config(self, command):\n        if len(command) != 2:\n            self.logger.error('Invalid command must be key value')\n            return False\n        self.config[command[0]] = command[1]\n\n    def webInstall(self, user_instance, construct_render) -&gt; str:\n        \"\"\"\"Returns a web installer for the given user instance and construct render template\"\"\"\n\n    def get_version(self) -&gt; str:\n        \"\"\"\"Returns the version\"\"\"\n        return self.version\n\n    async def get_user(self, username: str) -&gt; Result:\n        return await self.app.a_run_any(CLOUDM_AUTHMANAGER.GET_USER_BY_NAME, username=username, get_results=True)\n\n    async def __initobj(self):\n        \"\"\"Crutch used for __await__ after spawning\"\"\"\n        assert not self.async_initialized\n        self.async_initialized = True\n        # pass the parameters to __ainit__ that passed to __init__\n        await self.__ainit__(*self.__storedargs[0], **self.__storedargs[1])\n        return self\n\n    def __await__(self):\n        return self.__initobj().__await__()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.MainTool.__init__","title":"<code>__init__(*args, **kwargs)</code>","text":"<p>Standard constructor used for arguments pass Do not override. Use ainit instead</p> Source code in <code>toolboxv2/utils/system/main_tool.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"\n    Standard constructor used for arguments pass\n    Do not override. Use __ainit__ instead\n    \"\"\"\n    self.__storedargs = args, kwargs\n    self.tools = kwargs.get(\"tool\", {})\n    self.logger = kwargs.get(\"logs\", get_logger())\n    self.color = kwargs.get(\"color\", \"WHITE\")\n    self.todo = kwargs.get(\"load\", kwargs.get(\"on_start\", lambda: None))\n    if \"on_exit\" in kwargs and isinstance(kwargs.get(\"on_exit\"), Callable):\n        self.on_exit =self.app.tb(\n            mod_name=self.name,\n            name=kwargs.get(\"on_exit\").__name__,\n            version=self.version if hasattr(self, 'version') else \"0.0.0\",\n        )(kwargs.get(\"on_exit\"))\n    self.async_initialized = False\n    if self.todo:\n        try:\n            if inspect.iscoroutinefunction(self.todo):\n                pass\n            else:\n                self.todo()\n            get_logger().info(f\"{self.name} on load suspended\")\n        except Exception as e:\n            get_logger().error(f\"Error loading mod {self.name} {e}\")\n            if self.app.debug:\n                import traceback\n                traceback.print_exc()\n    else:\n        get_logger().info(f\"{self.name} no load require\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.MainTool.__initobj","title":"<code>__initobj()</code>  <code>async</code>","text":"<p>Crutch used for await after spawning</p> Source code in <code>toolboxv2/utils/system/main_tool.py</code> <pre><code>async def __initobj(self):\n    \"\"\"Crutch used for __await__ after spawning\"\"\"\n    assert not self.async_initialized\n    self.async_initialized = True\n    # pass the parameters to __ainit__ that passed to __init__\n    await self.__ainit__(*self.__storedargs[0], **self.__storedargs[1])\n    return self\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.MainTool.get_version","title":"<code>get_version()</code>","text":"<p>\"Returns the version</p> Source code in <code>toolboxv2/utils/system/main_tool.py</code> <pre><code>def get_version(self) -&gt; str:\n    \"\"\"\"Returns the version\"\"\"\n    return self.version\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.MainTool.webInstall","title":"<code>webInstall(user_instance, construct_render)</code>","text":"<p>\"Returns a web installer for the given user instance and construct render template</p> Source code in <code>toolboxv2/utils/system/main_tool.py</code> <pre><code>def webInstall(self, user_instance, construct_render) -&gt; str:\n    \"\"\"\"Returns a web installer for the given user instance and construct render template\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.get_app","title":"<code>toolboxv2.get_app(from_=None, name=None, args=AppArgs().default(), app_con=None, sync=False)</code>","text":"Source code in <code>toolboxv2/utils/system/getting_and_closing_app.py</code> <pre><code>def get_app(from_=None, name=None, args=AppArgs().default(), app_con=None, sync=False) -&gt; AppType:\n    global registered_apps\n    # name = None\n    # print(f\"get app requested from: {from_} withe name: {name}\")\n    logger = get_logger()\n    logger.info(Style.GREYBG(f\"get app requested from: {from_}\"))\n    if registered_apps[0] is not None:\n        return registered_apps[0]\n\n    if app_con is None:\n        from ... import App\n        app_con = App\n    app = app_con(name, args=args) if name else app_con()\n    logger.info(Style.Bold(f\"App instance, returned ID: {app.id}\"))\n\n    registered_apps[0] = app\n    return app\n</code></pre>"},{"location":"toolboxv2/#system-utilities-configuration","title":"System Utilities &amp; Configuration","text":""},{"location":"toolboxv2/#toolboxv2.FileHandler","title":"<code>toolboxv2.FileHandler</code>","text":"<p>               Bases: <code>Code</code></p> Source code in <code>toolboxv2/utils/system/file_handler.py</code> <pre><code>class FileHandler(Code):\n\n    def __init__(self, filename, name='mainTool', keys=None, defaults=None):\n        if defaults is None:\n            defaults = {}\n        if keys is None:\n            keys = {}\n        assert filename.endswith(\".config\") or filename.endswith(\".data\"), \\\n            f\"filename must end with .config or .data {filename=}\"\n        self.file_handler_save = {}\n        self.file_handler_load = {}\n        self.file_handler_key_mapper = {}\n        self.file_handler_filename = filename\n        self.file_handler_storage = None\n        self.file_handler_max_loaded_index_ = 0\n        self.file_handler_file_prefix = (f\".{filename.split('.')[1]}/\"\n                                         f\"{name.replace('.', '-')}/\")\n        # self.load_file_handler()\n        self.set_defaults_keys_file_handler(keys, defaults)\n\n    def _open_file_handler(self, mode: str, rdu):\n        logger = get_logger()\n        logger.info(Style.Bold(Style.YELLOW(f\"Opening file in mode : {mode}\")))\n        if self.file_handler_storage:\n            self.file_handler_storage.close()\n            self.file_handler_storage = None\n        try:\n            self.file_handler_storage = open(self.file_handler_file_prefix + self.file_handler_filename, mode)\n            self.file_handler_max_loaded_index_ += 1\n        except FileNotFoundError:\n            if self.file_handler_max_loaded_index_ == 2:\n                os.makedirs(self.file_handler_file_prefix, exist_ok=True)\n            if self.file_handler_max_loaded_index_ == 3:\n                os.makedirs(\".config/mainTool\", exist_ok=True)\n            if self.file_handler_max_loaded_index_ &gt;= 5:\n                print(Style.RED(f\"pleas create this file to prosed : {self.file_handler_file_prefix}\"\n                                f\"{self.file_handler_filename}\"))\n                logger.critical(f\"{self.file_handler_file_prefix} {self.file_handler_filename} FileNotFoundError cannot\"\n                                f\" be Created\")\n                exit(0)\n            self.file_handler_max_loaded_index_ += 1\n            logger.info(Style.YELLOW(f\"Try Creating File: {self.file_handler_file_prefix}{self.file_handler_filename}\"))\n\n            if not os.path.exists(f\"{self.file_handler_file_prefix}\"):\n                os.makedirs(f\"{self.file_handler_file_prefix}\")\n\n            with open(self.file_handler_file_prefix + self.file_handler_filename, 'a'):\n                logger.info(Style.GREEN(\"File created successfully\"))\n                self.file_handler_max_loaded_index_ = -1\n            rdu()\n        except OSError and PermissionError as e:\n            raise e\n\n    def open_s_file_handler(self):\n        self._open_file_handler('w+', self.open_s_file_handler)\n        return self\n\n    def open_l_file_handler(self):\n        self._open_file_handler('r+', self.open_l_file_handler)\n        return self\n\n    def save_file_handler(self):\n        get_logger().info(\n            Style.BLUE(\n                f\"init Saving (S) {self.file_handler_filename} \"\n            )\n        )\n        if self.file_handler_storage:\n            get_logger().warning(\n                f\"WARNING file is already open (S): {self.file_handler_filename} {self.file_handler_storage}\")\n\n        self.open_s_file_handler()\n\n        get_logger().info(\n            Style.BLUE(\n                f\"Elements to save : ({len(self.file_handler_save.keys())})\"\n            )\n        )\n\n        self.file_handler_storage.write(json.dumps(self.file_handler_save))\n\n        self.file_handler_storage.close()\n        self.file_handler_storage = None\n\n        get_logger().info(\n            Style.BLUE(\n                f\"closing file : {self.file_handler_filename} \"\n            )\n        )\n\n        return self\n\n    def add_to_save_file_handler(self, key: str, value: str):\n        if len(key) != 10:\n            get_logger(). \\\n                warning(\n                Style.YELLOW(\n                    'WARNING: key length is not 10 characters'\n                )\n            )\n            return False\n        if key not in self.file_handler_load:\n            if key in self.file_handler_key_mapper:\n                key = self.file_handler_key_mapper[key]\n\n        self.file_handler_load[key] = value\n        self.file_handler_save[key] = self.encode_code(value)\n        return True\n\n    def remove_key_file_handler(self, key: str):\n        if key == 'Pka7237327':\n            print(\"Cant remove Root Key\")\n            return\n        if key in self.file_handler_load:\n            del self.file_handler_load[key]\n        if key in self.file_handler_save:\n            del self.file_handler_save[key]\n\n    def load_file_handler(self):\n        get_logger().info(\n            Style.BLUE(\n                f\"loading {self.file_handler_filename} \"\n            )\n        )\n        if self.file_handler_storage:\n            get_logger().warning(\n                Style.YELLOW(\n                    f\"WARNING file is already open (L) {self.file_handler_filename}\"\n                )\n            )\n        self.open_l_file_handler()\n\n        try:\n\n            self.file_handler_save = json.load(self.file_handler_storage)\n            for key, line in self.file_handler_save.items():\n                self.file_handler_load[key] = self.decode_code(line)\n\n        except json.decoder.JSONDecodeError and Exception:\n\n            for line in self.file_handler_storage:\n                line = line[:-1]\n                heda = line[:10]\n                self.file_handler_save[heda] = line[10:]\n                enc = self.decode_code(line[10:])\n                self.file_handler_load[heda] = enc\n\n            self.file_handler_save = {}\n\n        self.file_handler_storage.close()\n        self.file_handler_storage = None\n\n        return self\n\n    def get_file_handler(self, obj: str, default=None) -&gt; str or None:\n        logger = get_logger()\n        if obj not in self.file_handler_load:\n            if obj in self.file_handler_key_mapper:\n                obj = self.file_handler_key_mapper[obj]\n        logger.info(Style.ITALIC(Style.GREY(f\"Collecting data from storage key : {obj}\")))\n        self.file_handler_max_loaded_index_ = -1\n        for objects in self.file_handler_load.items():\n            self.file_handler_max_loaded_index_ += 1\n            if obj == objects[0]:\n\n                try:\n                    if len(objects[1]) &gt; 0:\n                        return ast.literal_eval(objects[1]) if isinstance(objects[1], str) else objects[1]\n                    logger.warning(\n                        Style.YELLOW(\n                            f\"No data  {obj}  ; {self.file_handler_filename}\"\n                        )\n                    )\n                except ValueError:\n                    logger.error(f\"ValueError Loading {obj} ; {self.file_handler_filename}\")\n                except SyntaxError:\n                    if isinstance(objects[1], str):\n                        return objects[1]\n                    logger.warning(\n                        Style.YELLOW(\n                            f\"Possible SyntaxError Loading {obj} ; {self.file_handler_filename}\"\n                            f\" {len(objects[1])} {type(objects[1])}\"\n                        )\n                    )\n                    return objects[1]\n                except NameError:\n                    return str(objects[1])\n\n        if obj in list(self.file_handler_save.keys()):\n            r = self.decode_code(self.file_handler_save[obj])\n            logger.info(f\"returning Default for {obj}\")\n            return r\n\n        if default is None:\n            default = self.file_handler_load.get(obj)\n\n        logger.info(\"no data found\")\n        return default\n\n    def set_defaults_keys_file_handler(self, keys: dict, defaults: dict):\n        list_keys = iter(list(keys.keys()))\n        df_keys = defaults.keys()\n        for key in list_keys:\n            self.file_handler_key_mapper[key] = keys[key]\n            self.file_handler_key_mapper[keys[key]] = key\n            if key in df_keys:\n                self.file_handler_load[keys[key]] = str(defaults[key])\n                self.file_handler_save[keys[key]] = self.encode_code(defaults[key])\n            else:\n                self.file_handler_load[keys[key]] = \"None\"\n\n    def delete_file(self):\n        os.remove(self.file_handler_file_prefix + self.file_handler_filename)\n        get_logger().warning(Style.GREEN(f\"File deleted {self.file_handler_file_prefix + self.file_handler_filename}\"))\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils","title":"<code>toolboxv2.utils</code>","text":""},{"location":"toolboxv2/#toolboxv2.utils.App","title":"<code>App</code>","text":"Source code in <code>toolboxv2/utils/toolbox.py</code> <pre><code>class App(AppType, metaclass=Singleton):\n\n    def __init__(self, prefix: str = \"\", args=AppArgs().default()):\n        super().__init__(prefix, args)\n        self._web_context = None\n        t0 = time.perf_counter()\n        abspath = os.path.abspath(__file__)\n        self.system_flag = system()  # Linux: Linux Mac: Darwin Windows: Windows\n\n        self.appdata = os.getenv('APPDATA') if os.name == 'nt' else os.getenv('XDG_CONFIG_HOME') or os.path.expanduser(\n                '~/.config') if os.name == 'posix' else None\n\n        if self.system_flag == \"Darwin\" or self.system_flag == \"Linux\":\n            dir_name = os.path.dirname(abspath).replace(\"/utils\", \"\")\n        else:\n            dir_name = os.path.dirname(abspath).replace(\"\\\\utils\", \"\")\n\n        self.start_dir = str(dir_name)\n\n        self.bg_tasks = []\n\n        lapp = dir_name + '\\\\.data\\\\'\n\n        if not prefix:\n            if not os.path.exists(f\"{lapp}last-app-prefix.txt\"):\n                os.makedirs(lapp, exist_ok=True)\n                open(f\"{lapp}last-app-prefix.txt\", \"a\").close()\n            with open(f\"{lapp}last-app-prefix.txt\") as prefix_file:\n                cont = prefix_file.read()\n                if cont:\n                    prefix = cont.rstrip()\n        else:\n            if not os.path.exists(f\"{lapp}last-app-prefix.txt\"):\n                os.makedirs(lapp, exist_ok=True)\n                open(f\"{lapp}last-app-prefix.txt\", \"a\").close()\n            with open(f\"{lapp}last-app-prefix.txt\", \"w\") as prefix_file:\n                prefix_file.write(prefix)\n\n        self.prefix = prefix\n\n        node_ = node()\n\n        if 'localhost' in node_ and (host := os.getenv('HOSTNAME', 'localhost')) != 'localhost':\n            node_ = node_.replace('localhost', host)\n        self.id = prefix + '-' + node_\n        self.globals = {\n            \"root\": {**globals()},\n        }\n        self.locals = {\n            \"user\": {'app': self, **locals()},\n        }\n\n        identification = self.id\n        collective_identification = self.id\n        if \"test\" in prefix:\n            if self.system_flag == \"Darwin\" or self.system_flag == \"Linux\":\n                start_dir = self.start_dir.replace(\"ToolBoxV2/toolboxv2\", \"toolboxv2\")\n            else:\n                start_dir = self.start_dir.replace(\"ToolBoxV2\\\\toolboxv2\", \"toolboxv2\")\n            self.data_dir = start_dir + '\\\\.data\\\\' + \"test\"\n            self.config_dir = start_dir + '\\\\.config\\\\' + \"test\"\n            self.info_dir = start_dir + '\\\\.info\\\\' + \"test\"\n        elif identification.startswith('collective-'):\n            collective_identification = identification.split('-')[1]\n            self.data_dir = self.start_dir + '\\\\.data\\\\' + collective_identification\n            self.config_dir = self.start_dir + '\\\\.config\\\\' + collective_identification\n            self.info_dir = self.start_dir + '\\\\.info\\\\' + collective_identification\n            self.id = collective_identification\n        else:\n            self.data_dir = self.start_dir + '\\\\.data\\\\' + identification\n            self.config_dir = self.start_dir + '\\\\.config\\\\' + identification\n            self.info_dir = self.start_dir + '\\\\.info\\\\' + identification\n\n        if self.appdata is None:\n            self.appdata = self.data_dir\n        else:\n            self.appdata += \"/ToolBoxV2\"\n\n        if not os.path.exists(self.appdata):\n            os.makedirs(self.appdata, exist_ok=True)\n        if not os.path.exists(self.data_dir):\n            os.makedirs(self.data_dir, exist_ok=True)\n        if not os.path.exists(self.config_dir):\n            os.makedirs(self.config_dir, exist_ok=True)\n        if not os.path.exists(self.info_dir):\n            os.makedirs(self.info_dir, exist_ok=True)\n\n        print(f\"Starting ToolBox as {prefix} from :\", Style.Bold(Style.CYAN(f\"{os.getcwd()}\")))\n\n        logger_info_str, self.logger, self.logging_filename = self.set_logger(args.debug)\n\n        print(\"Logger \" + logger_info_str)\n        print(\"================================\")\n        self.logger.info(\"Logger initialized\")\n        get_logger().info(Style.GREEN(\"Starting Application instance\"))\n        if args.init and args.init is not None and self.start_dir not in sys.path:\n            sys.path.append(self.start_dir)\n\n        __version__ = get_version_from_pyproject()\n        self.version = __version__\n\n        self.keys = {\n            \"MACRO\": \"macro~~~~:\",\n            \"MACRO_C\": \"m_color~~:\",\n            \"HELPER\": \"helper~~~:\",\n            \"debug\": \"debug~~~~:\",\n            \"id\": \"name-spa~:\",\n            \"st-load\": \"mute~load:\",\n            \"comm-his\": \"comm-his~:\",\n            \"develop-mode\": \"dev~mode~:\",\n            \"provider::\": \"provider::\",\n        }\n\n        defaults = {\n            \"MACRO\": ['Exit'],\n            \"MACRO_C\": {},\n            \"HELPER\": {},\n            \"debug\": args.debug,\n            \"id\": self.id,\n            \"st-load\": False,\n            \"comm-his\": [[]],\n            \"develop-mode\": False,\n        }\n        self.config_fh = FileHandler(collective_identification + \".config\", keys=self.keys, defaults=defaults)\n        self.config_fh.load_file_handler()\n        self._debug = args.debug\n        self.flows = {}\n        self.dev_modi = self.config_fh.get_file_handler(self.keys[\"develop-mode\"])\n        if self.config_fh.get_file_handler(\"provider::\") is None:\n            self.config_fh.add_to_save_file_handler(\"provider::\", \"http://localhost:\" + str(\n                self.args_sto.port) if os.environ.get(\"HOSTNAME\",\"localhost\") == \"localhost\" else \"https://simplecore.app\")\n        self.functions = {}\n        self.modules = {}\n\n        self.interface_type = ToolBoxInterfaces.native\n        self.PREFIX = Style.CYAN(f\"~{node()}@&gt;\")\n        self.alive = True\n        self.called_exit = False, time.time()\n\n        self.print(f\"Infos:\\n  {'Name':&lt;8} -&gt; {node()}\\n  {'ID':&lt;8} -&gt; {self.id}\\n  {'Version':&lt;8} -&gt; {self.version}\\n\")\n\n        self.logger.info(\n            Style.GREEN(\n                f\"Finish init up in {time.perf_counter() - t0:.2f}s\"\n            )\n        )\n\n        self.args_sto = args\n        self.loop = None\n\n        from .system.session import Session\n        self.session: Session = Session(self.get_username())\n        if len(sys.argv) &gt; 2 and sys.argv[1] == \"db\":\n            return\n        from .system.db_cli_manager import ClusterManager, get_executable_path\n        self.cluster_manager = ClusterManager()\n        online_list, server_list = self.cluster_manager.status_all(silent=True)\n        if not server_list:\n            self.cluster_manager.start_all(get_executable_path(), self.version)\n            _, server_list = self.cluster_manager.status_all()\n        from .extras.blobs import BlobStorage\n        self.root_blob_storage = BlobStorage(servers=server_list, storage_directory=self.data_dir+ '\\\\blob_cache\\\\')\n        # self._start_event_loop()\n\n    def _start_event_loop(self):\n        \"\"\"Starts the asyncio event loop in a separate thread.\"\"\"\n        if self.loop is None:\n            self.loop = asyncio.new_event_loop()\n            self.loop_thread = threading.Thread(target=self.loop.run_forever, daemon=True)\n            self.loop_thread.start()\n\n    def get_username(self, get_input=False, default=\"loot\") -&gt; str:\n        user_name = self.config_fh.get_file_handler(\"ac_user:::\")\n        if get_input and user_name is None:\n            user_name = input(\"Input your username: \")\n            self.config_fh.add_to_save_file_handler(\"ac_user:::\", user_name)\n        if user_name is None:\n            user_name = default\n            self.config_fh.add_to_save_file_handler(\"ac_user:::\", user_name)\n        return user_name\n\n    def set_username(self, username):\n        return self.config_fh.add_to_save_file_handler(\"ac_user:::\", username)\n\n    @staticmethod\n    def exit_main(*args, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    @staticmethod\n    def hide_console(*args, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    @staticmethod\n    def show_console(*args, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    @staticmethod\n    def disconnect(*args, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    def set_logger(self, debug=False):\n        if \"test\" in self.prefix and not debug:\n            logger, logging_filename = setup_logging(logging.NOTSET, name=\"toolbox-test\", interminal=True,\n                                                     file_level=logging.NOTSET, app_name=self.id)\n            logger_info_str = \"in Test Mode\"\n        elif \"live\" in self.prefix and not debug:\n            logger, logging_filename = setup_logging(logging.DEBUG, name=\"toolbox-live\", interminal=False,\n                                                     file_level=logging.WARNING, app_name=self.id)\n            logger_info_str = \"in Live Mode\"\n            # setup_logging(logging.WARNING, name=\"toolbox-live\", is_online=True\n            #              , online_level=logging.WARNING).info(\"Logger initialized\")\n        elif \"debug\" in self.prefix or self.prefix.endswith(\"D\"):\n            self.prefix = self.prefix.replace(\"-debug\", '').replace(\"debug\", '')\n            logger, logging_filename = setup_logging(logging.DEBUG, name=\"toolbox-debug\", interminal=True,\n                                                     file_level=logging.WARNING, app_name=self.id)\n            logger_info_str = \"in debug Mode\"\n            self.debug = True\n        elif debug:\n            logger, logging_filename = setup_logging(logging.DEBUG, name=f\"toolbox-{self.prefix}-debug\",\n                                                     interminal=True,\n                                                     file_level=logging.DEBUG, app_name=self.id)\n            logger_info_str = \"in args debug Mode\"\n        else:\n            logger, logging_filename = setup_logging(logging.ERROR, name=f\"toolbox-{self.prefix}\", app_name=self.id)\n            logger_info_str = \"in Default\"\n\n        return logger_info_str, logger, logging_filename\n\n    @property\n    def debug(self):\n        return self._debug\n\n    @debug.setter\n    def debug(self, value):\n        if not isinstance(value, bool):\n            self.logger.debug(f\"Value must be an boolean. is : {value} type of {type(value)}\")\n            raise ValueError(\"Value must be an boolean.\")\n\n        # self.logger.info(f\"Setting debug {value}\")\n        self._debug = value\n\n    def debug_rains(self, e):\n        if self.debug:\n            import traceback\n            x = \"=\"*5\n            x += \" DEBUG \"\n            x += \"=\"*5\n            self.print(x)\n            self.print(traceback.format_exc())\n            self.print(x)\n            raise e\n        else:\n            self.logger.error(f\"Error: {e}\")\n            import traceback\n            x = \"=\"*5\n            x += \" DEBUG \"\n            x += \"=\"*5\n            self.print(x)\n            self.print(traceback.format_exc())\n            self.print(x)\n\n    def set_flows(self, r):\n        self.flows = r\n\n    async def run_flows(self, name, **kwargs):\n        from ..flows import flows_dict as flows_dict_func\n        if name not in self.flows:\n            self.flows = {**self.flows, **flows_dict_func(s=name, remote=True)}\n        if name in self.flows:\n            if asyncio.iscoroutinefunction(self.flows[name]):\n                return await self.flows[name](get_app(from_=\"runner\"), self.args_sto, **kwargs)\n            else:\n                return self.flows[name](get_app(from_=\"runner\"), self.args_sto, **kwargs)\n        else:\n            print(\"Flow not found, active flows:\", len(self.flows.keys()))\n\n    def _coppy_mod(self, content, new_mod_dir, mod_name, file_type='py'):\n\n        mode = 'xb'\n        self.logger.info(f\" coppy mod {mod_name} to {new_mod_dir} size : {sys.getsizeof(content) / 8388608:.3f} mb\")\n\n        if not os.path.exists(new_mod_dir):\n            os.makedirs(new_mod_dir)\n            with open(f\"{new_mod_dir}/__init__.py\", \"w\") as nmd:\n                nmd.write(f\"__version__ = '{self.version}'\")\n\n        if os.path.exists(f\"{new_mod_dir}/{mod_name}.{file_type}\"):\n            mode = False\n\n            with open(f\"{new_mod_dir}/{mod_name}.{file_type}\", 'rb') as d:\n                runtime_mod = d.read()  # Testing version but not efficient\n\n            if len(content) != len(runtime_mod):\n                mode = 'wb'\n\n        if mode:\n            with open(f\"{new_mod_dir}/{mod_name}.{file_type}\", mode) as f:\n                f.write(content)\n\n    def _pre_lib_mod(self, mod_name, path_to=\"./runtime\", file_type='py'):\n        working_dir = self.id.replace(\".\", \"_\")\n        lib_mod_dir = f\"toolboxv2.runtime.{working_dir}.mod_lib.\"\n\n        self.logger.info(f\"pre_lib_mod {mod_name} from {lib_mod_dir}\")\n\n        postfix = \"_dev\" if self.dev_modi else \"\"\n        mod_file_dir = f\"./mods{postfix}/{mod_name}.{file_type}\"\n        new_mod_dir = f\"{path_to}/{working_dir}/mod_lib\"\n        with open(mod_file_dir, \"rb\") as c:\n            content = c.read()\n        self._coppy_mod(content, new_mod_dir, mod_name, file_type=file_type)\n        return lib_mod_dir\n\n    def _copy_load(self, mod_name, file_type='py', **kwargs):\n        loc = self._pre_lib_mod(mod_name, file_type)\n        return self.inplace_load_instance(mod_name, loc=loc, **kwargs)\n\n    def helper_install_pip_module(self, module_name):\n        if 'main' in self.id:\n            return\n        self.print(f\"Installing {module_name} GREEDY\")\n        os.system(f\"{sys.executable} -m pip install {module_name}\")\n\n    def python_module_import_classifier(self, mod_name, error_message):\n\n        if error_message.startswith(\"No module named 'toolboxv2.utils\"):\n            return Result.default_internal_error(f\"404 {error_message.split('utils')[1]} not found\")\n        if error_message.startswith(\"No module named 'toolboxv2.mods\"):\n            if mod_name.startswith('.'):\n                return\n            return self.run_a_from_sync(self.a_run_any, (\"CloudM\", \"install\"), module_name=mod_name)\n        if error_message.startswith(\"No module named '\"):\n            pip_requ = error_message.split(\"'\")[1].replace(\"'\", \"\").strip()\n            # if 'y' in input(f\"\\t\\t\\tAuto install {pip_requ} Y/n\").lower:\n            return self.helper_install_pip_module(pip_requ)\n            # return Result.default_internal_error(f\"404 {pip_requ} not found\")\n\n    def inplace_load_instance(self, mod_name, loc=\"toolboxv2.mods.\", spec='app', save=True, mfo=None):\n        if self.dev_modi and loc == \"toolboxv2.mods.\":\n            loc = \"toolboxv2.mods_dev.\"\n        if spec=='app' and self.mod_online(mod_name):\n            self.logger.info(f\"Reloading mod from : {loc + mod_name}\")\n            self.remove_mod(mod_name, spec=spec, delete=False)\n\n        if (os.path.exists(self.start_dir + '/mods/' + mod_name) or os.path.exists(\n            self.start_dir + '/mods/' + mod_name + '.py')) and (\n            os.path.isdir(self.start_dir + '/mods/' + mod_name) or os.path.isfile(\n            self.start_dir + '/mods/' + mod_name + '.py')):\n            try:\n                if mfo is None:\n                    modular_file_object = import_module(loc + mod_name)\n                else:\n                    modular_file_object = mfo\n                self.modules[mod_name] = modular_file_object\n            except ModuleNotFoundError as e:\n                self.logger.error(Style.RED(f\"module {loc + mod_name} not found is type sensitive {e}\"))\n                self.print(Style.RED(f\"module {loc + mod_name} not found is type sensitive {e}\"))\n                if self.debug or self.args_sto.sysPrint:\n                    self.python_module_import_classifier(mod_name, str(e))\n                self.debug_rains(e)\n                return None\n        else:\n            self.print(f\"module {loc + mod_name} is not valid\")\n            return None\n        if hasattr(modular_file_object, \"Tools\"):\n            tools_class = modular_file_object.Tools\n        else:\n            if hasattr(modular_file_object, \"name\"):\n                tools_class = modular_file_object\n                modular_file_object = import_module(loc + mod_name)\n            else:\n                tools_class = None\n\n        modular_id = None\n        instance = modular_file_object\n        app_instance_type = \"file/application\"\n\n        if tools_class is None:\n            modular_id = modular_file_object.Name if hasattr(modular_file_object, \"Name\") else mod_name\n\n        if tools_class is None and modular_id is None:\n            modular_id = str(modular_file_object.__name__)\n            self.logger.warning(f\"Unknown instance loaded {mod_name}\")\n            return modular_file_object\n\n        if tools_class is not None:\n            tools_class = self.save_initialized_module(tools_class, spec)\n            modular_id = tools_class.name\n            app_instance_type = \"functions/class\"\n        else:\n            instance.spec = spec\n        # if private:\n        #     self.functions[modular_id][f\"{spec}_private\"] = private\n\n        if not save:\n            return instance if tools_class is None else tools_class\n\n        return self.save_instance(instance, modular_id, spec, app_instance_type, tools_class=tools_class)\n\n    def save_instance(self, instance, modular_id, spec='app', instance_type=\"file/application\", tools_class=None):\n\n        if modular_id in self.functions and tools_class is None:\n            if self.functions[modular_id].get(f\"{spec}_instance\", None) is None:\n                self.functions[modular_id][f\"{spec}_instance\"] = instance\n                self.functions[modular_id][f\"{spec}_instance_type\"] = instance_type\n            else:\n                self.print(\"Firest instance stays use new spec to get new instance\")\n                if modular_id in self.functions and self.functions[modular_id].get(f\"{spec}_instance\", None) is not None:\n                    return self.functions[modular_id][f\"{spec}_instance\"]\n                else:\n                    raise ImportError(f\"Module already known {modular_id} and not avalabel reload using other spec then {spec}\")\n\n        elif tools_class is not None:\n            if modular_id not in self.functions:\n                self.functions[modular_id] = {}\n            self.functions[modular_id][f\"{spec}_instance\"] = tools_class\n            self.functions[modular_id][f\"{spec}_instance_type\"] = instance_type\n\n            try:\n                if not hasattr(tools_class, 'tools'):\n                    tools_class.tools = {\"Version\": tools_class.get_version, 'name': tools_class.name}\n                for function_name in list(tools_class.tools.keys()):\n                    t_function_name = function_name.lower()\n                    if t_function_name != \"all\" and t_function_name != \"name\":\n                        self.tb(function_name, mod_name=modular_id)(tools_class.tools.get(function_name))\n                self.functions[modular_id][f\"{spec}_instance_type\"] += \"/BC\"\n                if hasattr(tools_class, 'on_exit'):\n                    if \"on_exit\" in self.functions[modular_id]:\n                        self.functions[modular_id][\"on_exit\"].append(tools_class.on_exit)\n                    else:\n                        self.functions[modular_id][\"on_exit\"] = [tools_class.on_exit]\n            except Exception as e:\n                self.logger.error(f\"Starting Module {modular_id} compatibility failed with : {e}\")\n                pass\n        elif modular_id not in self.functions and tools_class is None:\n            self.functions[modular_id] = {}\n            self.functions[modular_id][f\"{spec}_instance\"] = instance\n            self.functions[modular_id][f\"{spec}_instance_type\"] = instance_type\n\n        else:\n            raise ImportError(f\"Modular {modular_id} is not a valid mod\")\n        on_start = self.functions[modular_id].get(\"on_start\")\n        if on_start is not None:\n            i = 1\n            for f in on_start:\n                try:\n                    f_, e = self.get_function((modular_id, f), state=True, specification=spec)\n                    if e == 0:\n                        self.logger.info(Style.GREY(f\"Running On start {f} {i}/{len(on_start)}\"))\n                        if asyncio.iscoroutinefunction(f_):\n                            self.print(f\"Async on start is only in Tool claas supported for {modular_id}.{f}\" if tools_class is None else f\"initialization starting soon for {modular_id}.{f}\")\n                            self.run_bg_task_advanced(f_)\n                        else:\n                            o = f_()\n                            if o is not None:\n                                self.print(f\"Function {modular_id} On start result: {o}\")\n                    else:\n                        self.logger.warning(f\"starting function not found {e}\")\n                except Exception as e:\n                    self.logger.debug(Style.YELLOW(\n                        Style.Bold(f\"modular:{modular_id}.{f} on_start error {i}/{len(on_start)} -&gt; {e}\")))\n                    self.debug_rains(e)\n                finally:\n                    i += 1\n        return instance if tools_class is None else tools_class\n\n    def save_initialized_module(self, tools_class, spec):\n        tools_class.spec = spec\n        live_tools_class = tools_class(app=self)\n        return live_tools_class\n\n    def mod_online(self, mod_name, installed=False):\n        if installed and mod_name not in self.functions:\n            self.save_load(mod_name)\n        return mod_name in self.functions\n\n    def _get_function(self,\n                      name: Enum or None,\n                      state: bool = True,\n                      specification: str = \"app\",\n                      metadata=False, as_str: tuple or None = None, r=0, **kwargs):\n\n        if as_str is None and isinstance(name, Enum):\n            modular_id = str(name.NAME.value)\n            function_id = str(name.value)\n        elif as_str is None and isinstance(name, list):\n            modular_id, function_id = name[0], name[1]\n        else:\n            modular_id, function_id = as_str\n\n        self.logger.info(f\"getting function : {specification}.{modular_id}.{function_id}\")\n\n        if modular_id not in self.functions:\n            if r == 0:\n                self.save_load(modular_id, spec=specification)\n                return self.get_function(name=(modular_id, function_id),\n                                         state=state,\n                                         specification=specification,\n                                         metadata=metadata,\n                                         r=1)\n            self.logger.warning(f\"function modular not found {modular_id} 404\")\n            return \"404\", 404\n\n        if function_id not in self.functions[modular_id]:\n            self.logger.warning(f\"function data not found {modular_id}.{function_id} 404\")\n            return \"404\", 404\n\n        function_data = self.functions[modular_id][function_id]\n\n        if isinstance(function_data, list):\n            print(f\"functions {function_id} : {function_data}\")\n            function_data = self.functions[modular_id][function_data[kwargs.get('i', -1)]]\n            print(f\"functions {modular_id} : {function_data}\")\n        function = function_data.get(\"func\")\n        params = function_data.get(\"params\")\n\n        state_ = function_data.get(\"state\")\n        if state_ is not None and state != state_:\n            state = state_\n\n        if function is None:\n            self.logger.warning(\"No function found\")\n            return \"404\", 404\n\n        if params is None:\n            self.logger.warning(\"No function (params) found\")\n            return \"404\", 301\n\n        if metadata and not state:\n            self.logger.info(\"returning metadata stateless\")\n            return (function_data, function), 0\n\n        if not state:  # mens a stateless function\n            self.logger.info(\"returning stateless function\")\n            return function, 0\n\n        instance = self.functions[modular_id].get(f\"{specification}_instance\")\n\n        # instance_type = self.functions[modular_id].get(f\"{specification}_instance_type\", \"functions/class\")\n\n        if params[0] == 'app':\n            instance = get_app(from_=f\"fuction {specification}.{modular_id}.{function_id}\")\n\n        if instance is None and self.alive:\n            self.inplace_load_instance(modular_id, spec=specification)\n            instance = self.functions[modular_id].get(f\"{specification}_instance\")\n\n        if instance is None:\n            self.logger.warning(\"No live Instance found\")\n            return \"404\", 400\n\n        # if instance_type.endswith(\"/BC\"):  # for backwards compatibility  functions/class/BC old modules\n        #     # returning as stateless\n        #     # return \"422\", -1\n        #     self.logger.info(\n        #         f\"returning stateless function, cant find tools class for state handling found {instance_type}\")\n        #     if metadata:\n        #         self.logger.info(f\"returning metadata stateless\")\n        #         return (function_data, function), 0\n        #     return function, 0\n\n        self.logger.info(\"wrapping in higher_order_function\")\n\n        self.logger.info(f\"returned fuction {specification}.{modular_id}.{function_id}\")\n        higher_order_function = partial(function, instance)\n\n        if metadata:\n            self.logger.info(\"returning metadata stateful\")\n            return (function_data, higher_order_function), 0\n\n        self.logger.info(\"returning stateful function\")\n        return higher_order_function, 0\n\n    def save_exit(self):\n        self.logger.info(f\"save exiting saving data to {self.config_fh.file_handler_filename} states of {self.debug=}\")\n        self.config_fh.add_to_save_file_handler(self.keys[\"debug\"], str(self.debug))\n\n    def init_mod(self, mod_name, spec='app'):\n        \"\"\"\n        Initializes a module in a thread-safe manner by submitting the\n        asynchronous initialization to the running event loop.\n        \"\"\"\n        if '.' in mod_name:\n            mod_name = mod_name.split('.')[0]\n        self.run_bg_task(self.a_init_mod, mod_name, spec)\n        # loop = self.loop_gard()\n        # if loop:\n        #     # Create a future to get the result from the coroutine\n        #     future: Future = asyncio.run_coroutine_threadsafe(\n        #         self.a_init_mod(mod_name, spec), loop\n        #     )\n        #     # Block until the result is available\n        #     return future.result()\n        # else:\n        #     raise ValueError(\"Event loop is not running\")\n        #     # return self.loop_gard().run_until_complete(self.a_init_mod(mod_name, spec))\n\n    def run_bg_task(self, task: Callable, *args, **kwargs) -&gt; asyncio.Task | None:\n        \"\"\"\n        Runs a coroutine in the background without blocking the caller.\n\n        This is the primary method for \"fire-and-forget\" async tasks. It schedules\n        the coroutine to run on the application's main event loop.\n\n        Args:\n            task: The coroutine function to run.\n            *args: Arguments to pass to the coroutine function.\n            **kwargs: Keyword arguments to pass to the coroutine function.\n\n        Returns:\n            An asyncio.Task object representing the scheduled task, or None if\n            the task could not be scheduled.\n        \"\"\"\n        if not callable(task):\n            self.logger.warning(\"Task passed to run_bg_task is not callable!\")\n            return None\n\n        if not asyncio.iscoroutinefunction(task) and not asyncio.iscoroutine(task):\n            self.logger.warning(f\"Task '{getattr(task, '__name__', 'unknown')}' is not a coroutine. \"\n                                f\"Use run_bg_task_advanced for synchronous functions.\")\n            # Fallback to advanced runner for convenience\n            self.run_bg_task_advanced(task, *args, **kwargs)\n            return None\n\n        try:\n            loop = self.loop_gard()\n            if not loop.is_running():\n                # If the main loop isn't running, we can't create a task on it.\n                # This scenario is handled by run_bg_task_advanced.\n                self.logger.info(\"Main event loop not running. Delegating to advanced background runner.\")\n                return self.run_bg_task_advanced(task, *args, **kwargs)\n\n            # Create the coroutine if it's a function\n            coro = task(*args, **kwargs) if asyncio.iscoroutinefunction(task) else task\n\n            # Create a task on the running event loop\n            bg_task = loop.create_task(coro)\n\n            # Add a callback to log exceptions from the background task\n            def _log_exception(the_task: asyncio.Task):\n                if not the_task.cancelled() and the_task.exception():\n                    self.logger.error(f\"Exception in background task '{the_task.get_name()}':\",\n                                      exc_info=the_task.exception())\n\n            bg_task.add_done_callback(_log_exception)\n            self.bg_tasks.append(bg_task)\n            return bg_task\n\n        except Exception as e:\n            self.logger.error(f\"Failed to schedule background task: {e}\", exc_info=True)\n            return None\n\n    def run_bg_task_advanced(self, task: Callable, *args, **kwargs) -&gt; threading.Thread:\n        \"\"\"\n        Runs a task in a separate, dedicated background thread with its own event loop.\n\n        This is ideal for:\n        1. Running an async task from a synchronous context.\n        2. Launching a long-running, independent operation that should not\n           interfere with the main application's event loop.\n\n        Args:\n            task: The function to run (can be sync or async).\n            *args: Arguments for the task.\n            **kwargs: Keyword arguments for the task.\n\n        Returns:\n            The threading.Thread object managing the background execution.\n        \"\"\"\n        if not callable(task):\n            self.logger.warning(\"Task for run_bg_task_advanced is not callable!\")\n            return None\n\n        def thread_target():\n            # Each thread gets its own event loop.\n            loop = asyncio.new_event_loop()\n            asyncio.set_event_loop(loop)\n\n            try:\n                # Prepare the coroutine we need to run\n                if asyncio.iscoroutinefunction(task):\n                    coro = task(*args, **kwargs)\n                elif asyncio.iscoroutine(task):\n                    # It's already a coroutine object\n                    coro = task\n                else:\n                    # It's a synchronous function, run it in an executor\n                    # to avoid blocking the new event loop.\n                    coro = loop.run_in_executor(None, lambda: task(*args, **kwargs))\n\n                # Run the coroutine to completion\n                result = loop.run_until_complete(coro)\n                self.logger.debug(f\"Advanced background task '{getattr(task, '__name__', 'unknown')}' completed.\")\n                if result is not None:\n                    self.logger.debug(f\"Task result: {str(result)[:100]}\")\n\n            except Exception as e:\n                self.logger.error(f\"Error in advanced background task '{getattr(task, '__name__', 'unknown')}':\",\n                                  exc_info=e)\n            finally:\n                # Cleanly shut down the event loop in this thread.\n                try:\n                    all_tasks = asyncio.all_tasks(loop=loop)\n                    if all_tasks:\n                        for t in all_tasks:\n                            t.cancel()\n                        loop.run_until_complete(asyncio.gather(*all_tasks, return_exceptions=True))\n                finally:\n                    loop.close()\n                    asyncio.set_event_loop(None)\n\n        # Create, start, and return the thread.\n        # It's a daemon thread so it won't prevent the main app from exiting.\n        t = threading.Thread(target=thread_target, daemon=True, name=f\"BGTask-{getattr(task, '__name__', 'unknown')}\")\n        self.bg_tasks.append(t)\n        t.start()\n        return t\n\n    # Helper method to wait for background tasks to complete (optional)\n    def wait_for_bg_tasks(self, timeout=None):\n        \"\"\"\n        Wait for all background tasks to complete.\n\n        Args:\n            timeout: Maximum time to wait (in seconds) for all tasks to complete.\n                     None means wait indefinitely.\n\n        Returns:\n            bool: True if all tasks completed, False if timeout occurred\n        \"\"\"\n        active_tasks = [t for t in self.bg_tasks if t.is_alive()]\n\n        for task in active_tasks:\n            task.join(timeout=timeout)\n            if task.is_alive():\n                return False\n\n        return True\n\n    def __call__(self, *args, **kwargs):\n        return self.run(*args, **kwargs)\n\n    def run(self, *args, request=None, running_function_coro=None, **kwargs):\n        \"\"\"\n        Run a function with support for SSE streaming in both\n        threaded and non-threaded contexts.\n        \"\"\"\n        if running_function_coro is None:\n            mn, fn = args[0]\n            if self.functions.get(mn, {}).get(fn, {}).get('request_as_kwarg', False):\n                kwargs[\"request\"] = RequestData.from_dict(request)\n                if 'data' in kwargs and 'data' not in self.functions.get(mn, {}).get(fn, {}).get('params', []):\n                    kwargs[\"request\"].data = kwargs[\"request\"].body = kwargs['data']\n                    del kwargs['data']\n                if 'form_data' in kwargs and 'form_data' not in self.functions.get(mn, {}).get(fn, {}).get('params',\n                                                                                                           []):\n                    kwargs[\"request\"].form_data = kwargs[\"request\"].body = kwargs['form_data']\n                    del kwargs['form_data']\n\n        # Create the coroutine\n        coro = running_function_coro or self.a_run_any(*args, **kwargs)\n\n        # Get or create an event loop\n        try:\n            loop = asyncio.get_event_loop()\n            is_running = loop.is_running()\n        except RuntimeError:\n            loop = asyncio.new_event_loop()\n            asyncio.set_event_loop(loop)\n            is_running = False\n\n        # If the loop is already running, run in a separate thread\n        if is_running:\n            # Create thread pool executor as needed\n            if not hasattr(self.__class__, '_executor'):\n                self.__class__._executor = ThreadPoolExecutor(max_workers=4)\n\n            def run_in_new_thread():\n                # Set up a new loop in this thread\n                new_loop = asyncio.new_event_loop()\n                asyncio.set_event_loop(new_loop)\n\n                try:\n                    # Run the coroutine\n                    return new_loop.run_until_complete(coro)\n                finally:\n                    new_loop.close()\n\n            # Run in thread and get result\n            thread_result = self.__class__._executor.submit(run_in_new_thread).result()\n\n            # Handle streaming results from thread\n            if isinstance(thread_result, dict) and thread_result.get(\"is_stream\"):\n                # Create a new SSE stream in the main thread\n                async def stream_from_function():\n                    # Re-run the function with direct async access\n                    stream_result = await self.a_run_any(*args, **kwargs)\n\n                    if (isinstance(stream_result, Result) and\n                        getattr(stream_result.result, 'data_type', None) == \"stream\"):\n                        # Get and forward data from the original generator\n                        original_gen = stream_result.result.data.get(\"generator\")\n                        if inspect.isasyncgen(original_gen):\n                            async for item in original_gen:\n                                yield item\n\n                # Return a new streaming Result\n                return Result.stream(\n                    stream_generator=stream_from_function(),\n                    headers=thread_result.get(\"headers\", {})\n                )\n\n            result = thread_result\n        else:\n            # Direct execution when loop is not running\n            result = loop.run_until_complete(coro)\n\n        # Process the final result\n        if isinstance(result, Result):\n            if 'debug' in self.id:\n                result.print()\n            if getattr(result.result, 'data_type', None) == \"stream\":\n                return result\n            return result.to_api_result().model_dump(mode='json')\n\n        return result\n\n    def loop_gard(self):\n        if self.loop is None:\n            self._start_event_loop()\n            self.loop = asyncio.get_event_loop()\n        if self.loop.is_closed():\n            self.loop = asyncio.get_event_loop()\n        return self.loop\n\n    async def a_init_mod(self, mod_name, spec='app'):\n        mod = self.save_load(mod_name, spec=spec)\n        if hasattr(mod, \"__initobj\") and not mod.async_initialized:\n            await mod\n        return mod\n\n\n    def load_mod(self, mod_name: str, mlm='I', **kwargs):\n\n        action_list_helper = ['I (inplace load dill on error python)',\n                              # 'C (coppy py file to runtime dir)',\n                              # 'S (save py file to dill)',\n                              # 'CS (coppy and save py file)',\n                              # 'D (development mode, inplace load py file)'\n                              ]\n        action_list = {\"I\": lambda: self.inplace_load_instance(mod_name, **kwargs),\n                       \"C\": lambda: self._copy_load(mod_name, **kwargs)\n                       }\n\n        try:\n            if mlm in action_list:\n\n                return action_list.get(mlm)()\n            else:\n                self.logger.critical(\n                    f\"config mlm must be {' or '.join(action_list_helper)} is {mlm=}\")\n                raise ValueError(f\"config mlm must be {' or '.join(action_list_helper)} is {mlm=}\")\n        except ValueError as e:\n            self.logger.warning(Style.YELLOW(f\"Error Loading Module '{mod_name}', with error :{e}\"))\n            self.debug_rains(e)\n        except ImportError as e:\n            self.logger.error(Style.YELLOW(f\"Error Loading Module '{mod_name}', with error :{e}\"))\n            self.debug_rains(e)\n        except Exception as e:\n            self.logger.critical(Style.RED(f\"Error Loading Module '{mod_name}', with critical error :{e}\"))\n            print(Style.RED(f\"Error Loading Module '{mod_name}'\"))\n            self.debug_rains(e)\n\n        return Result.default_internal_error(info=\"info's in logs.\")\n\n    async def load_all_mods_in_file(self, working_dir=\"mods\"):\n        print(f\"LOADING ALL MODS FROM FOLDER : {working_dir}\")\n        t0 = time.perf_counter()\n        # Get the list of all modules\n        module_list = self.get_all_mods(working_dir)\n        open_modules = self.functions.keys()\n        start_len = len(open_modules)\n\n        for om in open_modules:\n            if om in module_list:\n                module_list.remove(om)\n\n        tasks: set[Task] = set()\n\n        _ = {tasks.add(asyncio.create_task(asyncio.to_thread(self.save_load, mod, 'app'))) for mod in module_list}\n        for t in asyncio.as_completed(tasks):\n            try:\n                result = await t\n                if hasattr(result, 'Name'):\n                    print('Opened :', result.Name)\n                elif hasattr(result, 'name'):\n                    if hasattr(result, 'async_initialized'):\n                        if not result.async_initialized:\n                            async def _():\n                                try:\n                                    if asyncio.iscoroutine(result):\n                                        await result\n                                    if hasattr(result, 'Name'):\n                                        print('Opened :', result.Name)\n                                    elif hasattr(result, 'name'):\n                                        print('Opened :', result.name)\n                                except Exception as e:\n                                    self.debug_rains(e)\n                                    if hasattr(result, 'Name'):\n                                        print('Error opening :', result.Name)\n                                    elif hasattr(result, 'name'):\n                                        print('Error opening :', result.name)\n                            asyncio.create_task(_())\n                        else:\n                            print('Opened :', result.name)\n                else:\n                    print('Opened :', result)\n            except Exception as e:\n                self.logger.error(Style.RED(f\"An Error occurred while opening all modules error: {str(e)}\"))\n                self.debug_rains(e)\n        opened = len(self.functions.keys()) - start_len\n\n        self.logger.info(f\"Opened {opened} modules in {time.perf_counter() - t0:.2f}s\")\n        return f\"Opened {opened} modules in {time.perf_counter() - t0:.2f}s\"\n\n    def get_all_mods(self, working_dir=\"mods\", path_to=\"./runtime\", use_wd=True):\n        self.logger.info(f\"collating all mods in working directory {working_dir}\")\n\n        pr = \"_dev\" if self.dev_modi else \"\"\n        if working_dir == \"mods\" and use_wd:\n            working_dir = f\"{self.start_dir}/mods{pr}\"\n        elif use_wd:\n            pass\n        else:\n            w_dir = self.id.replace(\".\", \"_\")\n            working_dir = f\"{path_to}/{w_dir}/mod_lib{pr}/\"\n        res = os.listdir(working_dir)\n\n        self.logger.info(f\"found : {len(res)} files\")\n\n        def do_helper(_mod):\n            if \"mainTool\" in _mod:\n                return False\n            # if not _mod.endswith(\".py\"):\n            #     return False\n            if _mod.startswith(\"__\"):\n                return False\n            if _mod.startswith(\".\"):\n                return False\n            return not _mod.startswith(\"test_\")\n\n        def r_endings(word: str):\n            if word.endswith(\".py\"):\n                return word[:-3]\n            return word\n\n        mods_list = list(map(r_endings, filter(do_helper, res)))\n\n        self.logger.info(f\"found : {len(mods_list)} Modules\")\n        return mods_list\n\n    def remove_all_modules(self, delete=False):\n        for mod in list(self.functions.keys()):\n            self.logger.info(f\"closing: {mod}\")\n            self.remove_mod(mod, delete=delete)\n\n    def remove_mod(self, mod_name, spec='app', delete=True):\n        if mod_name not in self.functions:\n            self.logger.info(f\"mod not active {mod_name}\")\n            return\n\n        on_exit = self.functions[mod_name].get(\"on_exit\")\n        self.logger.info(f\"closing: {on_exit}\")\n        def helper():\n            if f\"{spec}_instance\" in self.functions[mod_name]:\n                del self.functions[mod_name][f\"{spec}_instance\"]\n            if f\"{spec}_instance_type\" in self.functions[mod_name]:\n                del self.functions[mod_name][f\"{spec}_instance_type\"]\n\n        if on_exit is None and self.functions[mod_name].get(f\"{spec}_instance_type\", \"\").endswith(\"/BC\"):\n            instance = self.functions[mod_name].get(f\"{spec}_instance\", None)\n            if instance is not None and hasattr(instance, 'on_exit'):\n                if asyncio.iscoroutinefunction(instance.on_exit):\n                    self.exit_tasks.append(instance.on_exit)\n                else:\n                    instance.on_exit()\n\n        if on_exit is None and delete:\n            self.functions[mod_name] = {}\n            del self.functions[mod_name]\n            return\n        if on_exit is None:\n            helper()\n            return\n\n        i = 1\n\n        for j, f in enumerate(on_exit):\n            try:\n                f_, e = self.get_function((mod_name, f), state=True, specification=spec, i=j)\n                if e == 0:\n                    self.logger.info(Style.GREY(f\"Running On exit {f} {i}/{len(on_exit)}\"))\n                    if asyncio.iscoroutinefunction(f_):\n                        self.exit_tasks.append(f_)\n                        o = None\n                    else:\n                        o = f_()\n                    if o is not None:\n                        self.print(f\"Function On Exit result: {o}\")\n                else:\n                    self.logger.warning(\"closing function not found\")\n            except Exception as e:\n                self.logger.debug(\n                    Style.YELLOW(Style.Bold(f\"modular:{mod_name}.{f} on_exit error {i}/{len(on_exit)} -&gt; {e}\")))\n\n                self.debug_rains(e)\n            finally:\n                i += 1\n\n        helper()\n\n        if delete:\n            self.functions[mod_name] = {}\n            del self.functions[mod_name]\n\n    async def a_remove_all_modules(self, delete=False):\n        for mod in list(self.functions.keys()):\n            self.logger.info(f\"closing: {mod}\")\n            await self.a_remove_mod(mod, delete=delete)\n\n    async def a_remove_mod(self, mod_name, spec='app', delete=True):\n        if mod_name not in self.functions:\n            self.logger.info(f\"mod not active {mod_name}\")\n            return\n        on_exit = self.functions[mod_name].get(\"on_exit\")\n        self.logger.info(f\"closing: {on_exit}\")\n        def helper():\n            if f\"{spec}_instance\" in self.functions[mod_name]:\n                del self.functions[mod_name][f\"{spec}_instance\"]\n            if f\"{spec}_instance_type\" in self.functions[mod_name]:\n                del self.functions[mod_name][f\"{spec}_instance_type\"]\n\n        if on_exit is None and self.functions[mod_name].get(f\"{spec}_instance_type\", \"\").endswith(\"/BC\"):\n            instance = self.functions[mod_name].get(f\"{spec}_instance\", None)\n            if instance is not None and hasattr(instance, 'on_exit'):\n                if asyncio.iscoroutinefunction(instance.on_exit):\n                    await instance.on_exit()\n                else:\n                    instance.on_exit()\n\n        if on_exit is None and delete:\n            self.functions[mod_name] = {}\n            del self.functions[mod_name]\n            return\n        if on_exit is None:\n            helper()\n            return\n\n        i = 1\n        for f in on_exit:\n            try:\n                e = 1\n                if isinstance(f, str):\n                    f_, e = self.get_function((mod_name, f), state=True, specification=spec)\n                elif isinstance(f, Callable):\n                    f_, e, f  = f, 0, f.__name__\n                if e == 0:\n                    self.logger.info(Style.GREY(f\"Running On exit {f} {i}/{len(on_exit)}\"))\n                    if asyncio.iscoroutinefunction(f_):\n                        o = await f_()\n                    else:\n                        o = f_()\n                    if o is not None:\n                        self.print(f\"Function On Exit result: {o}\")\n                else:\n                    self.logger.warning(\"closing function not found\")\n            except Exception as e:\n                self.logger.debug(\n                    Style.YELLOW(Style.Bold(f\"modular:{mod_name}.{f} on_exit error {i}/{len(on_exit)} -&gt; {e}\")))\n                self.debug_rains(e)\n            finally:\n                i += 1\n\n        helper()\n\n        if delete:\n            self.functions[mod_name] = {}\n            del self.functions[mod_name]\n\n    def exit(self, remove_all=True):\n        if not self.alive:\n            return\n        if self.args_sto.debug:\n            self.hide_console()\n        self.disconnect()\n        if remove_all:\n            self.remove_all_modules()\n        self.logger.info(\"Exiting ToolBox interface\")\n        self.alive = False\n        self.called_exit = True, time.time()\n        self.save_exit()\n        if hasattr(self, 'root_blob_storage') and self.root_blob_storage:\n            self.root_blob_storage.exit()\n        try:\n            self.config_fh.save_file_handler()\n        except SystemExit:\n            print(\"If u ar testing this is fine else ...\")\n\n        if hasattr(self, 'daemon_app'):\n            import threading\n\n            for thread in threading.enumerate()[::-1]:\n                if thread.name == \"MainThread\":\n                    continue\n                try:\n                    with Spinner(f\"closing Thread {thread.name:^50}|\", symbols=\"s\", count_down=True,\n                                 time_in_s=0.751 if not self.debug else 0.6):\n                        thread.join(timeout=0.751 if not self.debug else 0.6)\n                except TimeoutError as e:\n                    self.logger.error(f\"Timeout error on exit {thread.name} {str(e)}\")\n                    print(str(e), f\"Timeout {thread.name}\")\n                except KeyboardInterrupt:\n                    print(\"Unsave Exit\")\n                    break\n        if hasattr(self, 'loop') and self.loop is not None:\n            with Spinner(\"closing Event loop:\", symbols=\"+\"):\n                self.loop.stop()\n\n    async def a_exit(self):\n        await self.a_remove_all_modules(delete=True)\n        results = await asyncio.gather(\n            *[asyncio.create_task(f()) for f in self.exit_tasks if asyncio.iscoroutinefunction(f)])\n        for result in results:\n            self.print(f\"Function On Exit result: {result}\")\n        self.exit(remove_all=False)\n\n    def save_load(self, modname, spec='app'):\n        self.logger.debug(f\"Save load module {modname}\")\n        if not modname:\n            self.logger.warning(\"no filename specified\")\n            return False\n        try:\n            return self.load_mod(modname, spec=spec)\n        except ModuleNotFoundError as e:\n            self.logger.error(Style.RED(f\"Module {modname} not found\"))\n            self.debug_rains(e)\n\n        return False\n\n    def get_function(self, name: Enum or tuple, **kwargs):\n        \"\"\"\n        Kwargs for _get_function\n            metadata:: return the registered function dictionary\n                stateless: (function_data, None), 0\n                stateful: (function_data, higher_order_function), 0\n            state::boolean\n                specification::str default app\n        \"\"\"\n        if isinstance(name, tuple):\n            return self._get_function(None, as_str=name, **kwargs)\n        else:\n            return self._get_function(name, **kwargs)\n\n    async def a_run_function(self, mod_function_name: Enum or tuple,\n                             tb_run_function_with_state=True,\n                             tb_run_with_specification='app',\n                             args_=None,\n                             kwargs_=None,\n                             *args,\n                             **kwargs) -&gt; Result:\n\n        if kwargs_ is not None and not kwargs:\n            kwargs = kwargs_\n        if args_ is not None and not args:\n            args = args_\n        if isinstance(mod_function_name, tuple):\n            modular_name, function_name = mod_function_name\n        elif isinstance(mod_function_name, list):\n            modular_name, function_name = mod_function_name[0], mod_function_name[1]\n        elif isinstance(mod_function_name, Enum):\n            modular_name, function_name = mod_function_name.__class__.NAME.value, mod_function_name.value\n        else:\n            raise TypeError(\"Unknown function type\")\n\n        if tb_run_with_specification == 'ws_internal':\n            modular_name = modular_name.split('/')[0]\n            if not self.mod_online(modular_name, installed=True):\n                self.get_mod(modular_name)\n            handler_id, event_name = mod_function_name\n            if handler_id in self.websocket_handlers and event_name in self.websocket_handlers[handler_id]:\n                handler_func = self.websocket_handlers[handler_id][event_name]\n                try:\n                    # F\u00fchre den asynchronen Handler aus\n                    if inspect.iscoroutinefunction(handler_func):\n                        await handler_func(self, **kwargs)\n                    else:\n                        handler_func(self, **kwargs)  # F\u00fcr synchrone Handler\n                    return Result.ok(info=f\"WS handler '{event_name}' executed.\")\n                except Exception as e:\n                    self.logger.error(f\"Error in WebSocket handler '{handler_id}/{event_name}': {e}\", exc_info=True)\n                    return Result.default_internal_error(info=str(e))\n            else:\n                # Kein Handler registriert, aber das ist kein Fehler (z.B. on_connect ist optional)\n                return Result.ok(info=f\"No WS handler for '{event_name}'.\")\n\n        if not self.mod_online(modular_name, installed=True):\n            self.get_mod(modular_name)\n\n        function_data, error_code = self.get_function(mod_function_name, state=tb_run_function_with_state,\n                                                      metadata=True, specification=tb_run_with_specification)\n        self.logger.info(f\"Received fuction : {mod_function_name}, with execode: {error_code}\")\n        if error_code == 404:\n            mod = self.get_mod(modular_name)\n            if hasattr(mod, \"async_initialized\") and not mod.async_initialized:\n                await mod\n            function_data, error_code = self.get_function(mod_function_name, state=tb_run_function_with_state,\n                                                          metadata=True, specification=tb_run_with_specification)\n\n        if error_code == 404:\n            self.logger.warning(Style.RED(\"Function Not Found\"))\n            return (Result.default_user_error(interface=self.interface_type,\n                                              exec_code=404,\n                                              info=\"function not found function is not decorated\").\n                    set_origin(mod_function_name))\n\n        if error_code == 300:\n            return Result.default_internal_error(interface=self.interface_type,\n                                                 info=f\"module {modular_name}\"\n                                                      f\" has no state (instance)\").set_origin(mod_function_name)\n\n        if error_code != 0:\n            return Result.default_internal_error(interface=self.interface_type,\n                                                 exec_code=error_code,\n                                                 info=f\"Internal error\"\n                                                      f\" {modular_name}.\"\n                                                      f\"{function_name}\").set_origin(mod_function_name)\n\n        if not tb_run_function_with_state:\n            function_data, _ = function_data\n            function = function_data.get('func')\n        else:\n            function_data, function = function_data\n\n        if not function:\n            self.logger.warning(Style.RED(f\"Function {function_name} not found\"))\n            return Result.default_internal_error(interface=self.interface_type,\n                                                 exec_code=404,\n                                                 info=\"function not found function\").set_origin(mod_function_name)\n\n        self.logger.info(\"Profiling function\")\n        t0 = time.perf_counter()\n        if asyncio.iscoroutinefunction(function):\n            return await self.a_fuction_runner(function, function_data, args, kwargs, t0)\n        else:\n            return self.fuction_runner(function, function_data, args, kwargs, t0)\n\n\n    def run_function(self, mod_function_name: Enum or tuple,\n                     tb_run_function_with_state=True,\n                     tb_run_with_specification='app',\n                     args_=None,\n                     kwargs_=None,\n                     *args,\n                     **kwargs) -&gt; Result:\n\n        if kwargs_ is not None and not kwargs:\n            kwargs = kwargs_\n        if args_ is not None and not args:\n            args = args_\n        if isinstance(mod_function_name, tuple):\n            modular_name, function_name = mod_function_name\n        elif isinstance(mod_function_name, list):\n            modular_name, function_name = mod_function_name[0], mod_function_name[1]\n        elif isinstance(mod_function_name, Enum):\n            modular_name, function_name = mod_function_name.__class__.NAME.value, mod_function_name.value\n        else:\n            raise TypeError(\"Unknown function type\")\n\n        if not self.mod_online(modular_name, installed=True):\n            self.get_mod(modular_name)\n\n        if tb_run_with_specification == 'ws_internal':\n            handler_id, event_name = mod_function_name\n            if handler_id in self.websocket_handlers and event_name in self.websocket_handlers[handler_id]:\n                handler_func = self.websocket_handlers[handler_id][event_name]\n                try:\n                    # F\u00fchre den asynchronen Handler aus\n                    if inspect.iscoroutinefunction(handler_func):\n                        return self.loop.run_until_complete(handler_func(self, **kwargs))\n                    else:\n                        handler_func(self, **kwargs)  # F\u00fcr synchrone Handler\n                    return Result.ok(info=f\"WS handler '{event_name}' executed.\")\n                except Exception as e:\n                    self.logger.error(f\"Error in WebSocket handler '{handler_id}/{event_name}': {e}\", exc_info=True)\n                    return Result.default_internal_error(info=str(e))\n            else:\n                # Kein Handler registriert, aber das ist kein Fehler (z.B. on_connect ist optional)\n                return Result.ok(info=f\"No WS handler for '{event_name}'.\")\n\n        function_data, error_code = self.get_function(mod_function_name, state=tb_run_function_with_state,\n                                                      metadata=True, specification=tb_run_with_specification)\n        self.logger.info(f\"Received fuction : {mod_function_name}, with execode: {error_code}\")\n        if error_code == 1 or error_code == 3 or error_code == 400:\n            self.get_mod(modular_name)\n            function_data, error_code = self.get_function(mod_function_name, state=tb_run_function_with_state,\n                                                          metadata=True, specification=tb_run_with_specification)\n\n        if error_code == 2:\n            self.logger.warning(Style.RED(\"Function Not Found\"))\n            return (Result.default_user_error(interface=self.interface_type,\n                                              exec_code=404,\n                                              info=\"function not found function is not decorated\").\n                    set_origin(mod_function_name))\n\n        if error_code == -1:\n            return Result.default_internal_error(interface=self.interface_type,\n                                                 info=f\"module {modular_name}\"\n                                                      f\" has no state (instance)\").set_origin(mod_function_name)\n\n        if error_code != 0:\n            return Result.default_internal_error(interface=self.interface_type,\n                                                 exec_code=error_code,\n                                                 info=f\"Internal error\"\n                                                      f\" {modular_name}.\"\n                                                      f\"{function_name}\").set_origin(mod_function_name)\n\n        if not tb_run_function_with_state:\n            function_data, _ = function_data\n            function = function_data.get('func')\n        else:\n            function_data, function = function_data\n\n        if not function:\n            self.logger.warning(Style.RED(f\"Function {function_name} not found\"))\n            return Result.default_internal_error(interface=self.interface_type,\n                                                 exec_code=404,\n                                                 info=\"function not found function\").set_origin(mod_function_name)\n\n        self.logger.info(\"Profiling function\")\n        t0 = time.perf_counter()\n        if asyncio.iscoroutinefunction(function):\n            raise ValueError(f\"Fuction {function_name} is Async use a_run_any\")\n        else:\n            return self.fuction_runner(function, function_data, args, kwargs, t0)\n\n    def run_a_from_sync(self, function, *args, **kwargs):\n        # Initialize self.loop if not already set.\n        if self.loop is None:\n            try:\n                self.loop = asyncio.get_running_loop()\n            except RuntimeError:\n                self.loop = asyncio.new_event_loop()\n\n        # If the loop is running, offload the coroutine to a new thread.\n        if self.loop.is_running():\n            result_future = Future()\n\n            def run_in_new_loop():\n                new_loop = asyncio.new_event_loop()\n                asyncio.set_event_loop(new_loop)\n                try:\n                    result = new_loop.run_until_complete(function(*args, **kwargs))\n                    result_future.set_result(result)\n                except Exception as e:\n                    result_future.set_exception(e)\n                finally:\n                    new_loop.close()\n\n            thread = threading.Thread(target=run_in_new_loop)\n            thread.start()\n            thread.join()  # Block until the thread completes.\n            return result_future.result()\n        else:\n            # If the loop is not running, schedule and run the coroutine directly.\n            future = self.loop.create_task(function(*args, **kwargs))\n            return self.loop.run_until_complete(future)\n\n    def fuction_runner(self, function, function_data: dict, args: list, kwargs: dict, t0=.0):\n\n        parameters = function_data.get('params')\n        modular_name = function_data.get('module_name')\n        function_name = function_data.get('func_name')\n        row = function_data.get('row')\n        mod_function_name = f\"{modular_name}.{function_name}\"\n\n        if_self_state = 1 if 'self' in parameters else 0\n\n        try:\n            if len(parameters) == 0:\n                res = function()\n            elif len(parameters) == len(args) + if_self_state:\n                res = function(*args)\n            elif len(parameters) == len(kwargs.keys()) + if_self_state:\n                res = function(**kwargs)\n            else:\n                res = function(*args, **kwargs)\n            self.logger.info(f\"Execution done in {time.perf_counter()-t0:.4f}\")\n            if isinstance(res, Result):\n                formatted_result = res\n                if formatted_result.origin is None:\n                    formatted_result.set_origin(mod_function_name)\n            elif isinstance(res, ApiResult):\n                formatted_result = res\n                if formatted_result.origin is None:\n                    formatted_result.as_result().set_origin(mod_function_name).to_api_result()\n            elif row:\n                formatted_result = res\n            else:\n                # Wrap the result in a Result object\n                formatted_result = Result.ok(\n                    interface=self.interface_type,\n                    data_info=\"Auto generated result\",\n                    data=res,\n                    info=\"Function executed successfully\"\n                ).set_origin(mod_function_name)\n            if not row:\n                self.logger.info(\n                    f\"Function Exec code: {formatted_result.info.exec_code} Info's: {formatted_result.info.help_text}\")\n            else:\n                self.logger.info(\n                    f\"Function Exec data: {formatted_result}\")\n        except Exception as e:\n            self.logger.error(\n                Style.YELLOW(Style.Bold(\n                    f\"! Function ERROR: in {modular_name}.{function_name}\")))\n            # Wrap the exception in a Result object\n            formatted_result = Result.default_internal_error(info=str(e)).set_origin(mod_function_name)\n            # res = formatted_result\n            self.logger.error(\n                f\"Function {modular_name}.{function_name}\"\n                f\" executed wit an error {str(e)}, {type(e)}\")\n            self.debug_rains(e)\n            self.print(f\"! Function ERROR: in {modular_name}.{function_name} \")\n\n\n\n        else:\n            self.print_ok()\n\n            self.logger.info(\n                f\"Function {modular_name}.{function_name}\"\n                f\" executed successfully\")\n\n        return formatted_result\n\n    async def a_fuction_runner(self, function, function_data: dict, args: list, kwargs: dict, t0=.0):\n\n        parameters = function_data.get('params')\n        modular_name = function_data.get('module_name')\n        function_name = function_data.get('func_name')\n        row = function_data.get('row')\n        mod_function_name = f\"{modular_name}.{function_name}\"\n\n        if_self_state = 1 if 'self' in parameters else 0\n\n        try:\n            if len(parameters) == 0:\n                res = await function()\n            elif len(parameters) == len(args) + if_self_state:\n                res = await function(*args)\n            elif len(parameters) == len(kwargs.keys()) + if_self_state:\n                res = await function(**kwargs)\n            else:\n                res = await function(*args, **kwargs)\n            self.logger.info(f\"Execution done in {time.perf_counter()-t0:.4f}\")\n            if isinstance(res, Result):\n                formatted_result = res\n                if formatted_result.origin is None:\n                    formatted_result.set_origin(mod_function_name)\n            elif isinstance(res, ApiResult):\n                formatted_result = res\n                if formatted_result.origin is None:\n                    formatted_result.as_result().set_origin(mod_function_name).to_api_result()\n            elif row:\n                formatted_result = res\n            else:\n                # Wrap the result in a Result object\n                formatted_result = Result.ok(\n                    interface=self.interface_type,\n                    data_info=\"Auto generated result\",\n                    data=res,\n                    info=\"Function executed successfully\"\n                ).set_origin(mod_function_name)\n            if not row:\n                self.logger.info(\n                    f\"Function Exec code: {formatted_result.info.exec_code} Info's: {formatted_result.info.help_text}\")\n            else:\n                self.logger.info(\n                    f\"Function Exec data: {formatted_result}\")\n        except Exception as e:\n            self.logger.error(\n                Style.YELLOW(Style.Bold(\n                    f\"! Function ERROR: in {modular_name}.{function_name}\")))\n            # Wrap the exception in a Result object\n            formatted_result = Result.default_internal_error(info=str(e)).set_origin(mod_function_name)\n            # res = formatted_result\n            self.logger.error(\n                f\"Function {modular_name}.{function_name}\"\n                f\" executed wit an error {str(e)}, {type(e)}\")\n            self.debug_rains(e)\n\n        else:\n            self.print_ok()\n\n            self.logger.info(\n                f\"Function {modular_name}.{function_name}\"\n                f\" executed successfully\")\n\n        return formatted_result\n\n    async def run_http(self, mod_function_name: Enum or str or tuple, function_name=None,\n                       args_=None,\n                       kwargs_=None, method=\"GET\",\n                       *args, **kwargs):\n        if kwargs_ is not None and not kwargs:\n            kwargs = kwargs_\n        if args_ is not None and not args:\n            args = args_\n\n        modular_name = mod_function_name\n        function_name = function_name\n\n        if isinstance(mod_function_name, str) and isinstance(function_name, str):\n            mod_function_name = (mod_function_name, function_name)\n\n        if isinstance(mod_function_name, tuple):\n            modular_name, function_name = mod_function_name\n        elif isinstance(mod_function_name, list):\n            modular_name, function_name = mod_function_name[0], mod_function_name[1]\n        elif isinstance(mod_function_name, Enum):\n            modular_name, function_name = mod_function_name.__class__.NAME.value, mod_function_name.value\n\n        self.logger.info(f\"getting function : {modular_name}.{function_name} from http {self.session.base}\")\n        r = await self.session.fetch(f\"/api/{modular_name}/{function_name}{'?' + args_ if args_ is not None else ''}\",\n                                     data=kwargs, method=method)\n        try:\n            if not r:\n                print(\"\u00a7 Session server Offline!\", self.session.base)\n                return Result.default_internal_error(info=\"Session fetch failed\").as_dict()\n\n            content_type = r.headers.get('Content-Type', '').lower()\n\n            if 'application/json' in content_type:\n                try:\n                    return r.json()\n                except Exception as e:\n                    print(f\"\u26a0 JSON decode error: {e}\")\n                    # Fallback to text if JSON decoding fails\n                    text = r.text\n            else:\n                text = r.text\n\n            if isinstance(text, Callable):\n                if asyncio.iscoroutinefunction(text):\n                    text = await text()\n                else:\n                    text = text()\n\n            # Attempt YAML\n            if 'yaml' in content_type or text.strip().startswith('---'):\n                try:\n                    import yaml\n                    return yaml.safe_load(text)\n                except Exception as e:\n                    print(f\"\u26a0 YAML decode error: {e}\")\n\n            # Attempt XML\n            if 'xml' in content_type or text.strip().startswith('&lt;?xml'):\n                try:\n                    import xmltodict\n                    return xmltodict.parse(text)\n                except Exception as e:\n                    print(f\"\u26a0 XML decode error: {e}\")\n\n            # Fallback: return plain text\n            return Result.default_internal_error(data={'raw_text': text, 'content_type': content_type}).as_dict()\n\n        except Exception as e:\n            print(\"\u274c Fatal error during API call:\", e)\n            self.debug_rains(e)\n            return Result.default_internal_error(str(e)).as_dict()\n\n    def run_local(self, *args, **kwargs):\n        return self.run_any(*args, **kwargs)\n\n    async def a_run_local(self, *args, **kwargs):\n        return await self.a_run_any(*args, **kwargs)\n\n    def run_any(self, mod_function_name: Enum or str or tuple, backwords_compability_variabel_string_holder=None,\n                get_results=False, tb_run_function_with_state=True, tb_run_with_specification='app', args_=None,\n                kwargs_=None,\n                *args, **kwargs):\n\n        # if self.debug:\n        #     self.logger.info(f'Called from: {getouterframes(currentframe(), 2)}')\n\n        if kwargs_ is not None and not kwargs:\n            kwargs = kwargs_\n        if args_ is not None and not args:\n            args = args_\n\n        if isinstance(mod_function_name, str) and backwords_compability_variabel_string_holder is None:\n            backwords_compability_variabel_string_holder = mod_function_name.split('.')[-1]\n            mod_function_name = mod_function_name.replace(f\".{backwords_compability_variabel_string_holder}\", \"\")\n\n        if isinstance(mod_function_name, str) and isinstance(backwords_compability_variabel_string_holder, str):\n            mod_function_name = (mod_function_name, backwords_compability_variabel_string_holder)\n\n        res: Result = self.run_function(mod_function_name,\n                                        tb_run_function_with_state=tb_run_function_with_state,\n                                        tb_run_with_specification=tb_run_with_specification,\n                                        args_=args, kwargs_=kwargs).as_result()\n        if isinstance(res, ApiResult):\n            res = res.as_result()\n\n        if isinstance(res, Result) and res.bg_task is not None:\n            self.run_bg_task(res.bg_task)\n\n        if self.debug:\n            res.log(show_data=False)\n\n        if not get_results and isinstance(res, Result):\n            return res.get()\n\n        if get_results and not isinstance(res, Result):\n            return Result.ok(data=res)\n\n        return res\n\n    async def a_run_any(self, mod_function_name: Enum or str or tuple,\n                        backwords_compability_variabel_string_holder=None,\n                        get_results=False, tb_run_function_with_state=True, tb_run_with_specification='app', args_=None,\n                        kwargs_=None,\n                        *args, **kwargs):\n\n        # if self.debug:\n        #     self.logger.info(f'Called from: {getouterframes(currentframe(), 2)}')\n\n        if kwargs_ is not None and not kwargs:\n            kwargs = kwargs_\n        if args_ is not None and not args:\n            args = args_\n\n        if isinstance(mod_function_name, str) and backwords_compability_variabel_string_holder is None:\n            backwords_compability_variabel_string_holder = mod_function_name.split('.')[-1]\n            mod_function_name = mod_function_name.replace(f\".{backwords_compability_variabel_string_holder}\", \"\")\n\n        if isinstance(mod_function_name, str) and isinstance(backwords_compability_variabel_string_holder, str):\n            mod_function_name = (mod_function_name, backwords_compability_variabel_string_holder)\n\n        res: Result = await self.a_run_function(mod_function_name,\n                                                tb_run_function_with_state=tb_run_function_with_state,\n                                                tb_run_with_specification=tb_run_with_specification,\n                                                args_=args, kwargs_=kwargs)\n        if isinstance(res, ApiResult):\n            res = res.as_result()\n\n        if isinstance(res, Result) and res.bg_task is not None:\n            self.run_bg_task(res.bg_task)\n\n        if self.debug:\n            res.print()\n            res.log(show_data=False) if isinstance(res, Result) else self.logger.debug(res)\n        if not get_results and isinstance(res, Result):\n            return res.get()\n\n        if get_results and not isinstance(res, Result):\n            return Result.ok(data=res)\n\n        return res\n\n\n    def web_context(self):\n        if self._web_context is None:\n            try:\n                self._web_context = open(\"./dist/helper.html\", encoding=\"utf-8\").read()\n            except Exception as e:\n                self.logger.error(f\"Could not load web context: {e}\")\n                self._web_context = \"&lt;div&gt;&lt;h1&gt;Web Context not found&lt;/h1&gt;&lt;/div&gt;\"\n        return self._web_context\n\n    def get_mod(self, name, spec='app') -&gt; ModuleType or MainToolType:\n        if spec != \"app\":\n            self.print(f\"Getting Module {name} spec: {spec}\")\n        if name not in self.functions:\n            mod = self.save_load(name, spec=spec)\n            if mod is False or (isinstance(mod, Result) and mod.is_error()):\n                self.logger.warning(f\"Could not find {name} in {list(self.functions.keys())}\")\n                raise ValueError(f\"Could not find {name} in {list(self.functions.keys())} pleas install the module, or its posibly broken use --debug for infos\")\n        # private = self.functions[name].get(f\"{spec}_private\")\n        # if private is not None:\n        #     if private and spec != 'app':\n        #         raise ValueError(\"Module is private\")\n        if name not in self.functions:\n            self.logger.warning(f\"Module '{name}' is not found\")\n            return None\n        instance = self.functions[name].get(f\"{spec}_instance\")\n        if instance is None:\n            return self.load_mod(name, spec=spec)\n        return self.functions[name].get(f\"{spec}_instance\")\n\n    def print(self, text=\"\", *args, **kwargs):\n        # self.logger.info(f\"Output : {text}\")\n        if 'live' in self.id:\n            return\n\n        flush = kwargs.pop('flush', True)\n        if self.sprint(None):\n            print(Style.CYAN(f\"System${self.id}:\"), end=\" \", flush=flush)\n        print(text, *args, **kwargs, flush=flush)\n\n    def sprint(self, text=\"\", *args, **kwargs):\n        if text is None:\n            return True\n        if 'live' in self.id:\n            return\n        flush = kwargs.pop('flush', True)\n        # self.logger.info(f\"Output : {text}\")\n        print(Style.CYAN(f\"System${self.id}:\"), end=\" \", flush=flush)\n        if isinstance(text, str) and kwargs == {} and text:\n            stram_print(text + ' '.join(args))\n            print()\n        else:\n            print(text, *args, **kwargs, flush=flush)\n\n    # ----------------------------------------------------------------\n    # Decorators for the toolbox\n\n    def reload_mod(self, mod_name, spec='app', is_file=True, loc=\"toolboxv2.mods.\"):\n        self.remove_mod(mod_name, delete=True)\n        if mod_name not in self.modules:\n            self.logger.warning(f\"Module '{mod_name}' is not found\")\n            return\n        if hasattr(self.modules[mod_name], 'reload_save') and self.modules[mod_name].reload_save:\n            def reexecute_module_code(x):\n                return x\n        else:\n            def reexecute_module_code(module_name):\n                if isinstance(module_name, str):\n                    module = import_module(module_name)\n                else:\n                    module = module_name\n                # Get the source code of the module\n                try:\n                    source = inspect.getsource(module)\n                except Exception:\n                    # print(f\"No source for {str(module_name).split('from')[0]}: {e}\")\n                    return module\n                # Compile the source code\n                try:\n                    code = compile(source, module.__file__, 'exec')\n                    # Execute the code in the module's namespace\n                    exec(code, module.__dict__)\n                except Exception:\n                    # print(f\"No source for {str(module_name).split('from')[0]}: {e}\")\n                    pass\n                return module\n\n        if not is_file:\n            mods = self.get_all_mods(\"./mods/\" + mod_name)\n            def recursive_reload(package_name):\n                package = import_module(package_name)\n\n                # First, reload all submodules\n                if hasattr(package, '__path__'):\n                    for _finder, name, _ispkg in pkgutil.walk_packages(package.__path__, package.__name__ + \".\"):\n                        try:\n                            mod = import_module(name)\n                            reexecute_module_code(mod)\n                            reload(mod)\n                        except Exception as e:\n                            print(f\"Error reloading module {name}: {e}\")\n                            break\n\n                # Finally, reload the package itself\n                reexecute_module_code(package)\n                reload(package)\n\n            for mod in mods:\n                if mod.endswith(\".txt\") or mod.endswith(\".yaml\"):\n                    continue\n                try:\n                    recursive_reload(loc + mod_name + '.' + mod)\n                    self.print(f\"Reloaded {mod_name}.{mod}\")\n                except ImportError:\n                    self.print(f\"Could not load {mod_name}.{mod}\")\n        reexecute_module_code(self.modules[mod_name])\n        if mod_name in self.functions:\n            if \"on_exit\" in self.functions[mod_name]:\n                self.functions[mod_name][\"on_exit\"] = []\n            if \"on_start\" in self.functions[mod_name]:\n                self.functions[mod_name][\"on_start\"] = []\n        self.inplace_load_instance(mod_name, spec=spec, mfo=reload(self.modules[mod_name]) if mod_name in self.modules else None)\n\n    def watch_mod(self, mod_name, spec='app', loc=\"toolboxv2.mods.\", use_thread=True, path_name=None, on_reload=None):\n        if path_name is None:\n            path_name = mod_name\n        is_file = os.path.isfile(self.start_dir + '/mods/' + path_name + '.py')\n        import watchfiles\n        def helper():\n            paths = f'mods/{path_name}' + ('.py' if is_file else '')\n            self.logger.info(f'Watching Path: {paths}')\n            try:\n                for changes in watchfiles.watch(paths):\n                    if not changes:\n                        continue\n                    self.reload_mod(mod_name, spec, is_file, loc)\n                    if on_reload:\n                        on_reload()\n            except FileNotFoundError:\n                self.logger.warning(f\"Path {paths} not found\")\n\n        if not use_thread:\n            helper()\n        else:\n            threading.Thread(target=helper, daemon=True).start()\n\n    def _register_function(self, module_name, func_name, data):\n        if module_name not in self.functions:\n            self.functions[module_name] = {}\n        if func_name in self.functions[module_name]:\n            self.print(f\"Overriding function {func_name} from {module_name}\", end=\"\\r\")\n            self.functions[module_name][func_name] = data\n        else:\n            self.functions[module_name][func_name] = data\n\n    def _create_decorator(self, type_: str,\n                          name: str = \"\",\n                          mod_name: str = \"\",\n                          level: int = -1,\n                          restrict_in_virtual_mode: bool = False,\n                          api: bool = False,\n                          helper: str = \"\",\n                          version: str or None = None,\n                          initial: bool=False,\n                          exit_f: bool=False,\n                          test: bool=True,\n                          samples:list[dict[str, Any]] | None=None,\n                          state:bool | None=None,\n                          pre_compute:Callable | None=None,\n                          post_compute:Callable[[], Result] | None=None,\n                          api_methods:list[str] | None=None,\n                          memory_cache: bool=False,\n                          file_cache: bool=False,\n                          request_as_kwarg: bool=False,\n                          row: bool=False,\n                          memory_cache_max_size:int=100,\n                          memory_cache_ttl:int=300,\n                          websocket_handler: str | None = None,\n                          ):\n\n        if isinstance(type_, Enum):\n            type_ = type_.value\n\n        if memory_cache and file_cache:\n            raise ValueError(\"Don't use both cash at the same time for the same fuction\")\n\n        use_cache = memory_cache or file_cache\n        cache = {}\n        if file_cache:\n            cache = FileCache(folder=self.data_dir + f'\\\\cache\\\\{mod_name}\\\\',\n                              filename=self.data_dir + f'\\\\cache\\\\{mod_name}\\\\{name}cache.db')\n        if memory_cache:\n            cache = MemoryCache(maxsize=memory_cache_max_size, ttl=memory_cache_ttl)\n\n        version = self.version if version is None else self.version + ':' + version\n\n        def a_additional_process(func):\n\n            async def executor(*args, **kwargs):\n\n                if pre_compute is not None:\n                    args, kwargs = await pre_compute(*args, **kwargs)\n                if asyncio.iscoroutinefunction(func):\n                    result = await func(*args, **kwargs)\n                else:\n                    result = func(*args, **kwargs)\n                if post_compute is not None:\n                    result = await post_compute(result)\n                if row:\n                    return result\n                if not isinstance(result, Result):\n                    result = Result.ok(data=result)\n                if result.origin is None:\n                    result.set_origin((mod_name if mod_name else func.__module__.split('.')[-1]\n                                       , name if name else func.__name__\n                                       , type_))\n                if result.result.data_to == ToolBoxInterfaces.native.name:\n                    result.result.data_to = ToolBoxInterfaces.remote if api else ToolBoxInterfaces.native\n                # Wenden Sie die to_api_result Methode auf das Ergebnis an, falls verf\u00fcgbar\n                if api and hasattr(result, 'to_api_result'):\n                    return result.to_api_result()\n                return result\n\n            @wraps(func)\n            async def wrapper(*args, **kwargs):\n\n                if not use_cache:\n                    return await executor(*args, **kwargs)\n\n                try:\n                    cache_key = (f\"{mod_name if mod_name else func.__module__.split('.')[-1]}\"\n                                 f\"-{func.__name__}-{str(args)},{str(kwargs.items())}\")\n                except ValueError:\n                    cache_key = (f\"{mod_name if mod_name else func.__module__.split('.')[-1]}\"\n                                 f\"-{func.__name__}-{bytes(args)},{str(kwargs.items())}\")\n\n                result = cache.get(cache_key)\n                if result is not None:\n                    return result\n\n                result = await executor(*args, **kwargs)\n\n                cache.set(cache_key, result)\n\n                return result\n\n            return wrapper\n\n        def additional_process(func):\n\n            def executor(*args, **kwargs):\n\n                if pre_compute is not None:\n                    args, kwargs = pre_compute(*args, **kwargs)\n                if asyncio.iscoroutinefunction(func):\n                    result = func(*args, **kwargs)\n                else:\n                    result = func(*args, **kwargs)\n                if post_compute is not None:\n                    result = post_compute(result)\n                if row:\n                    return result\n                if not isinstance(result, Result):\n                    result = Result.ok(data=result)\n                if result.origin is None:\n                    result.set_origin((mod_name if mod_name else func.__module__.split('.')[-1]\n                                       , name if name else func.__name__\n                                       , type_))\n                if result.result.data_to == ToolBoxInterfaces.native.name:\n                    result.result.data_to = ToolBoxInterfaces.remote if api else ToolBoxInterfaces.native\n                # Wenden Sie die to_api_result Methode auf das Ergebnis an, falls verf\u00fcgbar\n                if api and hasattr(result, 'to_api_result'):\n                    return result.to_api_result()\n                return result\n\n            @wraps(func)\n            def wrapper(*args, **kwargs):\n\n                if not use_cache:\n                    return executor(*args, **kwargs)\n\n                try:\n                    cache_key = (f\"{mod_name if mod_name else func.__module__.split('.')[-1]}\"\n                                 f\"-{func.__name__}-{str(args)},{str(kwargs.items())}\")\n                except ValueError:\n                    cache_key = (f\"{mod_name if mod_name else func.__module__.split('.')[-1]}\"\n                                 f\"-{func.__name__}-{bytes(args)},{str(kwargs.items())}\")\n\n                result = cache.get(cache_key)\n                if result is not None:\n                    return result\n\n                result = executor(*args, **kwargs)\n\n                cache.set(cache_key, result)\n\n                return result\n\n            return wrapper\n\n        def decorator(func):\n            sig = signature(func)\n            params = list(sig.parameters)\n            module_name = mod_name if mod_name else func.__module__.split('.')[-1]\n            func_name = name if name else func.__name__\n            if func_name == 'on_start':\n                func_name = 'on_startup'\n            if func_name == 'on_exit':\n                func_name = 'on_close'\n            if api or pre_compute is not None or post_compute is not None or memory_cache or file_cache:\n                if asyncio.iscoroutinefunction(func):\n                    func = a_additional_process(func)\n                else:\n                    func = additional_process(func)\n            if api and str(sig.return_annotation) == 'Result':\n                raise ValueError(f\"Fuction {module_name}.{func_name} registered as \"\n                                 f\"Api fuction but uses {str(sig.return_annotation)}\\n\"\n                                 f\"Please change the sig from ..)-&gt; Result to ..)-&gt; ApiResult\")\n            data = {\n                \"type\": type_,\n                \"module_name\": module_name,\n                \"func_name\": func_name,\n                \"level\": level,\n                \"restrict_in_virtual_mode\": restrict_in_virtual_mode,\n                \"func\": func,\n                \"api\": api,\n                \"helper\": helper,\n                \"version\": version,\n                \"initial\": initial,\n                \"exit_f\": exit_f,\n                \"api_methods\": api_methods if api_methods is not None else [\"AUTO\"],\n                \"__module__\": func.__module__,\n                \"signature\": sig,\n                \"params\": params,\n                \"row\": row,\n                \"state\": (\n                    False if len(params) == 0 else params[0] in ['self', 'state', 'app']) if state is None else state,\n                \"do_test\": test,\n                \"samples\": samples,\n                \"request_as_kwarg\": request_as_kwarg,\n\n            }\n\n            if websocket_handler:\n                # Die dekorierte Funktion sollte ein Dict mit den Handlern zur\u00fcckgeben\n                try:\n                    handler_config = func(self)  # Rufe die Funktion auf, um die Konfiguration zu erhalten\n                    if not isinstance(handler_config, dict):\n                        raise TypeError(\n                            f\"WebSocket handler function '{func.__name__}' must return a dictionary of handlers.\")\n\n                    # Handler-Identifikator, z.B. \"ChatModule/room_chat\"\n                    handler_id = f\"{module_name}/{websocket_handler}\"\n                    self.websocket_handlers[handler_id] = {}\n\n                    for event_name, handler_func in handler_config.items():\n                        if event_name in [\"on_connect\", \"on_message\", \"on_disconnect\"] and callable(handler_func):\n                            self.websocket_handlers[handler_id][event_name] = handler_func\n                        else:\n                            self.logger.warning(f\"Invalid WebSocket handler event '{event_name}' in '{handler_id}'.\")\n\n                    self.logger.info(f\"Registered WebSocket handlers for '{handler_id}'.\")\n\n                except Exception as e:\n                    self.logger.error(f\"Failed to register WebSocket handlers for '{func.__name__}': {e}\",\n                                      exc_info=True)\n            else:\n                self._register_function(module_name, func_name, data)\n\n            if exit_f:\n                if \"on_exit\" not in self.functions[module_name]:\n                    self.functions[module_name][\"on_exit\"] = []\n                self.functions[module_name][\"on_exit\"].append(func_name)\n            if initial:\n                if \"on_start\" not in self.functions[module_name]:\n                    self.functions[module_name][\"on_start\"] = []\n                self.functions[module_name][\"on_start\"].append(func_name)\n\n            return func\n\n        decorator.tb_init = True\n\n        return decorator\n\n    def tb(self, name=None,\n           mod_name: str = \"\",\n           helper: str = \"\",\n           version: str | None = None,\n           test: bool = True,\n           restrict_in_virtual_mode: bool = False,\n           api: bool = False,\n           initial: bool = False,\n           exit_f: bool = False,\n           test_only: bool = False,\n           memory_cache: bool = False,\n           file_cache: bool = False,\n           request_as_kwarg: bool = False,\n           row: bool = False,\n           state: bool | None = None,\n           level: int = -1,\n           memory_cache_max_size: int = 100,\n           memory_cache_ttl: int = 300,\n           samples: list or dict or None = None,\n           interface: ToolBoxInterfaces or None or str = None,\n           pre_compute=None,\n           post_compute=None,\n           api_methods=None,\n           websocket_handler: str | None = None,\n           ):\n        \"\"\"\n    A decorator for registering and configuring functions within a module.\n\n    This decorator is used to wrap functions with additional functionality such as caching, API conversion, and lifecycle management (initialization and exit). It also handles the registration of the function in the module's function registry.\n\n    Args:\n        name (str, optional): The name to register the function under. Defaults to the function's own name.\n        mod_name (str, optional): The name of the module the function belongs to.\n        helper (str, optional): A helper string providing additional information about the function.\n        version (str or None, optional): The version of the function or module.\n        test (bool, optional): Flag to indicate if the function is for testing purposes.\n        restrict_in_virtual_mode (bool, optional): Flag to restrict the function in virtual mode.\n        api (bool, optional): Flag to indicate if the function is part of an API.\n        initial (bool, optional): Flag to indicate if the function should be executed at initialization.\n        exit_f (bool, optional): Flag to indicate if the function should be executed at exit.\n        test_only (bool, optional): Flag to indicate if the function should only be used for testing.\n        memory_cache (bool, optional): Flag to enable memory caching for the function.\n        request_as_kwarg (bool, optional): Flag to get request if the fuction is calld from api.\n        file_cache (bool, optional): Flag to enable file caching for the function.\n        row (bool, optional): rather to auto wrap the result in Result type default False means no row data aka result type\n        state (bool or None, optional): Flag to indicate if the function maintains state.\n        level (int, optional): The level of the function, used for prioritization or categorization.\n        memory_cache_max_size (int, optional): Maximum size of the memory cache.\n        memory_cache_ttl (int, optional): Time-to-live for the memory cache entries.\n        samples (list or dict or None, optional): Samples or examples of function usage.\n        interface (str, optional): The interface type for the function.\n        pre_compute (callable, optional): A function to be called before the main function.\n        post_compute (callable, optional): A function to be called after the main function.\n        api_methods (list[str], optional): default [\"AUTO\"] (GET if not params, POST if params) , GET, POST, PUT or DELETE.\n        websocket_handler (str, optional): The name of the websocket handler to use.\n\n    Returns:\n        function: The decorated function with additional processing and registration capabilities.\n    \"\"\"\n        if interface is None:\n            interface = \"tb\"\n        if test_only and 'test' not in self.id:\n            return lambda *args, **kwargs: args\n        return self._create_decorator(interface,\n                                      name,\n                                      mod_name,\n                                      level=level,\n                                      restrict_in_virtual_mode=restrict_in_virtual_mode,\n                                      helper=helper,\n                                      api=api,\n                                      version=version,\n                                      initial=initial,\n                                      exit_f=exit_f,\n                                      test=test,\n                                      samples=samples,\n                                      state=state,\n                                      pre_compute=pre_compute,\n                                      post_compute=post_compute,\n                                      memory_cache=memory_cache,\n                                      file_cache=file_cache,\n                                      request_as_kwarg=request_as_kwarg,\n                                      row=row,\n                                      api_methods=api_methods,\n                                      memory_cache_max_size=memory_cache_max_size,\n                                      memory_cache_ttl=memory_cache_ttl,\n                                      websocket_handler=websocket_handler,\n                                      )\n\n    def save_autocompletion_dict(self):\n        autocompletion_dict = {}\n        for module_name, _module in self.functions.items():\n            data = {}\n            for function_name, function_data in self.functions[module_name].items():\n                if not isinstance(function_data, dict):\n                    continue\n                data[function_name] = {arg: None for arg in\n                                       function_data.get(\"params\", [])}\n                if len(data[function_name].keys()) == 0:\n                    data[function_name] = None\n            autocompletion_dict[module_name] = data if len(data.keys()) &gt; 0 else None\n        self.config_fh.add_to_save_file_handler(\"auto~~~~~~\", str(autocompletion_dict))\n\n    def get_autocompletion_dict(self):\n        return self.config_fh.get_file_handler(\"auto~~~~~~\")\n\n    def save_registry_as_enums(self, directory: str, filename: str):\n        # Ordner erstellen, falls nicht vorhanden\n        if not os.path.exists(directory):\n            os.makedirs(directory)\n\n        # Dateipfad vorbereiten\n        filepath = os.path.join(directory, filename)\n\n        # Enum-Klassen als Strings generieren\n        enum_classes = [f'\"\"\"Automatic generated by ToolBox v = {self.version}\"\"\"'\n                        f'\\nfrom enum import Enum\\nfrom dataclasses import dataclass'\n                        f'\\n\\n\\n']\n        for module, functions in self.functions.items():\n            if module.startswith(\"APP_INSTANCE\"):\n                continue\n            class_name = module\n            enum_members = \"\\n    \".join(\n                [\n                    f\"{func_name.upper().replace('-', '')}\"\n                    f\" = '{func_name}' \"\n                    f\"# Input: ({fuction_data['params'] if isinstance(fuction_data, dict) else ''}),\"\n                    f\" Output: {fuction_data['signature'].return_annotation if isinstance(fuction_data, dict) else 'None'}\"\n                    for func_name, fuction_data in functions.items()])\n            enum_class = (f'@dataclass\\nclass {class_name.upper().replace(\".\", \"_\").replace(\"-\", \"\")}(Enum):'\n                          f\"\\n    NAME = '{class_name}'\\n    {enum_members}\")\n            enum_classes.append(enum_class)\n\n        # Enums in die Datei schreiben\n        data = \"\\n\\n\\n\".join(enum_classes)\n        if len(data) &lt; 12:\n            raise ValueError(\n                \"Invalid Enums Loosing content pleas delete it ur self in the (utils/system/all_functions_enums.py) or add mor new stuff :}\")\n        with open(filepath, 'w') as file:\n            file.write(data)\n\n        print(Style.Bold(Style.BLUE(f\"Enums gespeichert in {filepath}\")))\n\n\n    # WS logic\n\n    def _set_rust_ws_bridge(self, bridge_object: Any):\n        \"\"\"\n        Diese Methode wird von Rust aufgerufen, um die Kommunikationsbr\u00fccke zu setzen.\n        Sie darf NICHT manuell von Python aus aufgerufen werden.\n        \"\"\"\n        self.print(f\"Rust WebSocket bridge has been set for instance {self.id}.\")\n        self._rust_ws_bridge = bridge_object\n\n    async def ws_send(self, conn_id: str, payload: dict):\n        \"\"\"\n        Sendet eine Nachricht asynchron an eine einzelne WebSocket-Verbindung.\n\n        Args:\n            conn_id: Die eindeutige ID der Zielverbindung.\n            payload: Ein Dictionary, das als JSON gesendet wird.\n        \"\"\"\n        if self._rust_ws_bridge is None:\n            self.logger.error(\"Cannot send WebSocket message: Rust bridge is not initialized.\")\n            return\n\n        try:\n            # Ruft die asynchrone Rust-Methode auf und wartet auf deren Abschluss\n            await self._rust_ws_bridge.send_message(conn_id, json.dumps(payload))\n        except Exception as e:\n            self.logger.error(f\"Failed to send WebSocket message to {conn_id}: {e}\", exc_info=True)\n\n    async def ws_broadcast(self, channel_id: str, payload: dict, source_conn_id: str = \"python_broadcast\"):\n        \"\"\"\n        Sendet eine Nachricht asynchron an alle Clients in einem Kanal/Raum.\n\n        Args:\n            channel_id: Der Kanal, an den gesendet werden soll.\n            payload: Ein Dictionary, das als JSON gesendet wird.\n            source_conn_id (optional): Die ID der urspr\u00fcnglichen Verbindung, um Echos zu vermeiden.\n        \"\"\"\n        if self._rust_ws_bridge is None:\n            self.logger.error(\"Cannot broadcast WebSocket message: Rust bridge is not initialized.\")\n            return\n\n        try:\n            # Ruft die asynchrone Rust-Broadcast-Methode auf\n            await self._rust_ws_bridge.broadcast_message(channel_id, json.dumps(payload), source_conn_id)\n        except Exception as e:\n            self.logger.error(f\"Failed to broadcast WebSocket message to channel {channel_id}: {e}\", exc_info=True)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.App.disconnect","title":"<code>disconnect(*args, **kwargs)</code>  <code>staticmethod</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/toolbox.py</code> <pre><code>@staticmethod\ndef disconnect(*args, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.App.exit_main","title":"<code>exit_main(*args, **kwargs)</code>  <code>staticmethod</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/toolbox.py</code> <pre><code>@staticmethod\ndef exit_main(*args, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.App.get_function","title":"<code>get_function(name, **kwargs)</code>","text":"<p>Kwargs for _get_function     metadata:: return the registered function dictionary         stateless: (function_data, None), 0         stateful: (function_data, higher_order_function), 0     state::boolean         specification::str default app</p> Source code in <code>toolboxv2/utils/toolbox.py</code> <pre><code>def get_function(self, name: Enum or tuple, **kwargs):\n    \"\"\"\n    Kwargs for _get_function\n        metadata:: return the registered function dictionary\n            stateless: (function_data, None), 0\n            stateful: (function_data, higher_order_function), 0\n        state::boolean\n            specification::str default app\n    \"\"\"\n    if isinstance(name, tuple):\n        return self._get_function(None, as_str=name, **kwargs)\n    else:\n        return self._get_function(name, **kwargs)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.App.hide_console","title":"<code>hide_console(*args, **kwargs)</code>  <code>staticmethod</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/toolbox.py</code> <pre><code>@staticmethod\ndef hide_console(*args, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.App.init_mod","title":"<code>init_mod(mod_name, spec='app')</code>","text":"<p>Initializes a module in a thread-safe manner by submitting the asynchronous initialization to the running event loop.</p> Source code in <code>toolboxv2/utils/toolbox.py</code> <pre><code>def init_mod(self, mod_name, spec='app'):\n    \"\"\"\n    Initializes a module in a thread-safe manner by submitting the\n    asynchronous initialization to the running event loop.\n    \"\"\"\n    if '.' in mod_name:\n        mod_name = mod_name.split('.')[0]\n    self.run_bg_task(self.a_init_mod, mod_name, spec)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.App.run","title":"<code>run(*args, request=None, running_function_coro=None, **kwargs)</code>","text":"<p>Run a function with support for SSE streaming in both threaded and non-threaded contexts.</p> Source code in <code>toolboxv2/utils/toolbox.py</code> <pre><code>def run(self, *args, request=None, running_function_coro=None, **kwargs):\n    \"\"\"\n    Run a function with support for SSE streaming in both\n    threaded and non-threaded contexts.\n    \"\"\"\n    if running_function_coro is None:\n        mn, fn = args[0]\n        if self.functions.get(mn, {}).get(fn, {}).get('request_as_kwarg', False):\n            kwargs[\"request\"] = RequestData.from_dict(request)\n            if 'data' in kwargs and 'data' not in self.functions.get(mn, {}).get(fn, {}).get('params', []):\n                kwargs[\"request\"].data = kwargs[\"request\"].body = kwargs['data']\n                del kwargs['data']\n            if 'form_data' in kwargs and 'form_data' not in self.functions.get(mn, {}).get(fn, {}).get('params',\n                                                                                                       []):\n                kwargs[\"request\"].form_data = kwargs[\"request\"].body = kwargs['form_data']\n                del kwargs['form_data']\n\n    # Create the coroutine\n    coro = running_function_coro or self.a_run_any(*args, **kwargs)\n\n    # Get or create an event loop\n    try:\n        loop = asyncio.get_event_loop()\n        is_running = loop.is_running()\n    except RuntimeError:\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n        is_running = False\n\n    # If the loop is already running, run in a separate thread\n    if is_running:\n        # Create thread pool executor as needed\n        if not hasattr(self.__class__, '_executor'):\n            self.__class__._executor = ThreadPoolExecutor(max_workers=4)\n\n        def run_in_new_thread():\n            # Set up a new loop in this thread\n            new_loop = asyncio.new_event_loop()\n            asyncio.set_event_loop(new_loop)\n\n            try:\n                # Run the coroutine\n                return new_loop.run_until_complete(coro)\n            finally:\n                new_loop.close()\n\n        # Run in thread and get result\n        thread_result = self.__class__._executor.submit(run_in_new_thread).result()\n\n        # Handle streaming results from thread\n        if isinstance(thread_result, dict) and thread_result.get(\"is_stream\"):\n            # Create a new SSE stream in the main thread\n            async def stream_from_function():\n                # Re-run the function with direct async access\n                stream_result = await self.a_run_any(*args, **kwargs)\n\n                if (isinstance(stream_result, Result) and\n                    getattr(stream_result.result, 'data_type', None) == \"stream\"):\n                    # Get and forward data from the original generator\n                    original_gen = stream_result.result.data.get(\"generator\")\n                    if inspect.isasyncgen(original_gen):\n                        async for item in original_gen:\n                            yield item\n\n            # Return a new streaming Result\n            return Result.stream(\n                stream_generator=stream_from_function(),\n                headers=thread_result.get(\"headers\", {})\n            )\n\n        result = thread_result\n    else:\n        # Direct execution when loop is not running\n        result = loop.run_until_complete(coro)\n\n    # Process the final result\n    if isinstance(result, Result):\n        if 'debug' in self.id:\n            result.print()\n        if getattr(result.result, 'data_type', None) == \"stream\":\n            return result\n        return result.to_api_result().model_dump(mode='json')\n\n    return result\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.App.run_bg_task","title":"<code>run_bg_task(task, *args, **kwargs)</code>","text":"<p>Runs a coroutine in the background without blocking the caller.</p> <p>This is the primary method for \"fire-and-forget\" async tasks. It schedules the coroutine to run on the application's main event loop.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>Callable</code> <p>The coroutine function to run.</p> required <code>*args</code> <p>Arguments to pass to the coroutine function.</p> <code>()</code> <code>**kwargs</code> <p>Keyword arguments to pass to the coroutine function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Task | None</code> <p>An asyncio.Task object representing the scheduled task, or None if</p> <code>Task | None</code> <p>the task could not be scheduled.</p> Source code in <code>toolboxv2/utils/toolbox.py</code> <pre><code>def run_bg_task(self, task: Callable, *args, **kwargs) -&gt; asyncio.Task | None:\n    \"\"\"\n    Runs a coroutine in the background without blocking the caller.\n\n    This is the primary method for \"fire-and-forget\" async tasks. It schedules\n    the coroutine to run on the application's main event loop.\n\n    Args:\n        task: The coroutine function to run.\n        *args: Arguments to pass to the coroutine function.\n        **kwargs: Keyword arguments to pass to the coroutine function.\n\n    Returns:\n        An asyncio.Task object representing the scheduled task, or None if\n        the task could not be scheduled.\n    \"\"\"\n    if not callable(task):\n        self.logger.warning(\"Task passed to run_bg_task is not callable!\")\n        return None\n\n    if not asyncio.iscoroutinefunction(task) and not asyncio.iscoroutine(task):\n        self.logger.warning(f\"Task '{getattr(task, '__name__', 'unknown')}' is not a coroutine. \"\n                            f\"Use run_bg_task_advanced for synchronous functions.\")\n        # Fallback to advanced runner for convenience\n        self.run_bg_task_advanced(task, *args, **kwargs)\n        return None\n\n    try:\n        loop = self.loop_gard()\n        if not loop.is_running():\n            # If the main loop isn't running, we can't create a task on it.\n            # This scenario is handled by run_bg_task_advanced.\n            self.logger.info(\"Main event loop not running. Delegating to advanced background runner.\")\n            return self.run_bg_task_advanced(task, *args, **kwargs)\n\n        # Create the coroutine if it's a function\n        coro = task(*args, **kwargs) if asyncio.iscoroutinefunction(task) else task\n\n        # Create a task on the running event loop\n        bg_task = loop.create_task(coro)\n\n        # Add a callback to log exceptions from the background task\n        def _log_exception(the_task: asyncio.Task):\n            if not the_task.cancelled() and the_task.exception():\n                self.logger.error(f\"Exception in background task '{the_task.get_name()}':\",\n                                  exc_info=the_task.exception())\n\n        bg_task.add_done_callback(_log_exception)\n        self.bg_tasks.append(bg_task)\n        return bg_task\n\n    except Exception as e:\n        self.logger.error(f\"Failed to schedule background task: {e}\", exc_info=True)\n        return None\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.App.run_bg_task_advanced","title":"<code>run_bg_task_advanced(task, *args, **kwargs)</code>","text":"<p>Runs a task in a separate, dedicated background thread with its own event loop.</p> <p>This is ideal for: 1. Running an async task from a synchronous context. 2. Launching a long-running, independent operation that should not    interfere with the main application's event loop.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>Callable</code> <p>The function to run (can be sync or async).</p> required <code>*args</code> <p>Arguments for the task.</p> <code>()</code> <code>**kwargs</code> <p>Keyword arguments for the task.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Thread</code> <p>The threading.Thread object managing the background execution.</p> Source code in <code>toolboxv2/utils/toolbox.py</code> <pre><code>def run_bg_task_advanced(self, task: Callable, *args, **kwargs) -&gt; threading.Thread:\n    \"\"\"\n    Runs a task in a separate, dedicated background thread with its own event loop.\n\n    This is ideal for:\n    1. Running an async task from a synchronous context.\n    2. Launching a long-running, independent operation that should not\n       interfere with the main application's event loop.\n\n    Args:\n        task: The function to run (can be sync or async).\n        *args: Arguments for the task.\n        **kwargs: Keyword arguments for the task.\n\n    Returns:\n        The threading.Thread object managing the background execution.\n    \"\"\"\n    if not callable(task):\n        self.logger.warning(\"Task for run_bg_task_advanced is not callable!\")\n        return None\n\n    def thread_target():\n        # Each thread gets its own event loop.\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n\n        try:\n            # Prepare the coroutine we need to run\n            if asyncio.iscoroutinefunction(task):\n                coro = task(*args, **kwargs)\n            elif asyncio.iscoroutine(task):\n                # It's already a coroutine object\n                coro = task\n            else:\n                # It's a synchronous function, run it in an executor\n                # to avoid blocking the new event loop.\n                coro = loop.run_in_executor(None, lambda: task(*args, **kwargs))\n\n            # Run the coroutine to completion\n            result = loop.run_until_complete(coro)\n            self.logger.debug(f\"Advanced background task '{getattr(task, '__name__', 'unknown')}' completed.\")\n            if result is not None:\n                self.logger.debug(f\"Task result: {str(result)[:100]}\")\n\n        except Exception as e:\n            self.logger.error(f\"Error in advanced background task '{getattr(task, '__name__', 'unknown')}':\",\n                              exc_info=e)\n        finally:\n            # Cleanly shut down the event loop in this thread.\n            try:\n                all_tasks = asyncio.all_tasks(loop=loop)\n                if all_tasks:\n                    for t in all_tasks:\n                        t.cancel()\n                    loop.run_until_complete(asyncio.gather(*all_tasks, return_exceptions=True))\n            finally:\n                loop.close()\n                asyncio.set_event_loop(None)\n\n    # Create, start, and return the thread.\n    # It's a daemon thread so it won't prevent the main app from exiting.\n    t = threading.Thread(target=thread_target, daemon=True, name=f\"BGTask-{getattr(task, '__name__', 'unknown')}\")\n    self.bg_tasks.append(t)\n    t.start()\n    return t\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.App.show_console","title":"<code>show_console(*args, **kwargs)</code>  <code>staticmethod</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/toolbox.py</code> <pre><code>@staticmethod\ndef show_console(*args, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.App.tb","title":"<code>tb(name=None, mod_name='', helper='', version=None, test=True, restrict_in_virtual_mode=False, api=False, initial=False, exit_f=False, test_only=False, memory_cache=False, file_cache=False, request_as_kwarg=False, row=False, state=None, level=-1, memory_cache_max_size=100, memory_cache_ttl=300, samples=None, interface=None, pre_compute=None, post_compute=None, api_methods=None, websocket_handler=None)</code>","text":"<p>A decorator for registering and configuring functions within a module.</p> <p>This decorator is used to wrap functions with additional functionality such as caching, API conversion, and lifecycle management (initialization and exit). It also handles the registration of the function in the module's function registry.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name to register the function under. Defaults to the function's own name.</p> <code>None</code> <code>mod_name</code> <code>str</code> <p>The name of the module the function belongs to.</p> <code>''</code> <code>helper</code> <code>str</code> <p>A helper string providing additional information about the function.</p> <code>''</code> <code>version</code> <code>str or None</code> <p>The version of the function or module.</p> <code>None</code> <code>test</code> <code>bool</code> <p>Flag to indicate if the function is for testing purposes.</p> <code>True</code> <code>restrict_in_virtual_mode</code> <code>bool</code> <p>Flag to restrict the function in virtual mode.</p> <code>False</code> <code>api</code> <code>bool</code> <p>Flag to indicate if the function is part of an API.</p> <code>False</code> <code>initial</code> <code>bool</code> <p>Flag to indicate if the function should be executed at initialization.</p> <code>False</code> <code>exit_f</code> <code>bool</code> <p>Flag to indicate if the function should be executed at exit.</p> <code>False</code> <code>test_only</code> <code>bool</code> <p>Flag to indicate if the function should only be used for testing.</p> <code>False</code> <code>memory_cache</code> <code>bool</code> <p>Flag to enable memory caching for the function.</p> <code>False</code> <code>request_as_kwarg</code> <code>bool</code> <p>Flag to get request if the fuction is calld from api.</p> <code>False</code> <code>file_cache</code> <code>bool</code> <p>Flag to enable file caching for the function.</p> <code>False</code> <code>row</code> <code>bool</code> <p>rather to auto wrap the result in Result type default False means no row data aka result type</p> <code>False</code> <code>state</code> <code>bool or None</code> <p>Flag to indicate if the function maintains state.</p> <code>None</code> <code>level</code> <code>int</code> <p>The level of the function, used for prioritization or categorization.</p> <code>-1</code> <code>memory_cache_max_size</code> <code>int</code> <p>Maximum size of the memory cache.</p> <code>100</code> <code>memory_cache_ttl</code> <code>int</code> <p>Time-to-live for the memory cache entries.</p> <code>300</code> <code>samples</code> <code>list or dict or None</code> <p>Samples or examples of function usage.</p> <code>None</code> <code>interface</code> <code>str</code> <p>The interface type for the function.</p> <code>None</code> <code>pre_compute</code> <code>callable</code> <p>A function to be called before the main function.</p> <code>None</code> <code>post_compute</code> <code>callable</code> <p>A function to be called after the main function.</p> <code>None</code> <code>api_methods</code> <code>list[str]</code> <p>default [\"AUTO\"] (GET if not params, POST if params) , GET, POST, PUT or DELETE.</p> <code>None</code> <code>websocket_handler</code> <code>str</code> <p>The name of the websocket handler to use.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>function</code> <p>The decorated function with additional processing and registration capabilities.</p> Source code in <code>toolboxv2/utils/toolbox.py</code> <pre><code>def tb(self, name=None,\n       mod_name: str = \"\",\n       helper: str = \"\",\n       version: str | None = None,\n       test: bool = True,\n       restrict_in_virtual_mode: bool = False,\n       api: bool = False,\n       initial: bool = False,\n       exit_f: bool = False,\n       test_only: bool = False,\n       memory_cache: bool = False,\n       file_cache: bool = False,\n       request_as_kwarg: bool = False,\n       row: bool = False,\n       state: bool | None = None,\n       level: int = -1,\n       memory_cache_max_size: int = 100,\n       memory_cache_ttl: int = 300,\n       samples: list or dict or None = None,\n       interface: ToolBoxInterfaces or None or str = None,\n       pre_compute=None,\n       post_compute=None,\n       api_methods=None,\n       websocket_handler: str | None = None,\n       ):\n    \"\"\"\nA decorator for registering and configuring functions within a module.\n\nThis decorator is used to wrap functions with additional functionality such as caching, API conversion, and lifecycle management (initialization and exit). It also handles the registration of the function in the module's function registry.\n\nArgs:\n    name (str, optional): The name to register the function under. Defaults to the function's own name.\n    mod_name (str, optional): The name of the module the function belongs to.\n    helper (str, optional): A helper string providing additional information about the function.\n    version (str or None, optional): The version of the function or module.\n    test (bool, optional): Flag to indicate if the function is for testing purposes.\n    restrict_in_virtual_mode (bool, optional): Flag to restrict the function in virtual mode.\n    api (bool, optional): Flag to indicate if the function is part of an API.\n    initial (bool, optional): Flag to indicate if the function should be executed at initialization.\n    exit_f (bool, optional): Flag to indicate if the function should be executed at exit.\n    test_only (bool, optional): Flag to indicate if the function should only be used for testing.\n    memory_cache (bool, optional): Flag to enable memory caching for the function.\n    request_as_kwarg (bool, optional): Flag to get request if the fuction is calld from api.\n    file_cache (bool, optional): Flag to enable file caching for the function.\n    row (bool, optional): rather to auto wrap the result in Result type default False means no row data aka result type\n    state (bool or None, optional): Flag to indicate if the function maintains state.\n    level (int, optional): The level of the function, used for prioritization or categorization.\n    memory_cache_max_size (int, optional): Maximum size of the memory cache.\n    memory_cache_ttl (int, optional): Time-to-live for the memory cache entries.\n    samples (list or dict or None, optional): Samples or examples of function usage.\n    interface (str, optional): The interface type for the function.\n    pre_compute (callable, optional): A function to be called before the main function.\n    post_compute (callable, optional): A function to be called after the main function.\n    api_methods (list[str], optional): default [\"AUTO\"] (GET if not params, POST if params) , GET, POST, PUT or DELETE.\n    websocket_handler (str, optional): The name of the websocket handler to use.\n\nReturns:\n    function: The decorated function with additional processing and registration capabilities.\n\"\"\"\n    if interface is None:\n        interface = \"tb\"\n    if test_only and 'test' not in self.id:\n        return lambda *args, **kwargs: args\n    return self._create_decorator(interface,\n                                  name,\n                                  mod_name,\n                                  level=level,\n                                  restrict_in_virtual_mode=restrict_in_virtual_mode,\n                                  helper=helper,\n                                  api=api,\n                                  version=version,\n                                  initial=initial,\n                                  exit_f=exit_f,\n                                  test=test,\n                                  samples=samples,\n                                  state=state,\n                                  pre_compute=pre_compute,\n                                  post_compute=post_compute,\n                                  memory_cache=memory_cache,\n                                  file_cache=file_cache,\n                                  request_as_kwarg=request_as_kwarg,\n                                  row=row,\n                                  api_methods=api_methods,\n                                  memory_cache_max_size=memory_cache_max_size,\n                                  memory_cache_ttl=memory_cache_ttl,\n                                  websocket_handler=websocket_handler,\n                                  )\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.App.wait_for_bg_tasks","title":"<code>wait_for_bg_tasks(timeout=None)</code>","text":"<p>Wait for all background tasks to complete.</p> <p>Parameters:</p> Name Type Description Default <code>timeout</code> <p>Maximum time to wait (in seconds) for all tasks to complete.      None means wait indefinitely.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>bool</code> <p>True if all tasks completed, False if timeout occurred</p> Source code in <code>toolboxv2/utils/toolbox.py</code> <pre><code>def wait_for_bg_tasks(self, timeout=None):\n    \"\"\"\n    Wait for all background tasks to complete.\n\n    Args:\n        timeout: Maximum time to wait (in seconds) for all tasks to complete.\n                 None means wait indefinitely.\n\n    Returns:\n        bool: True if all tasks completed, False if timeout occurred\n    \"\"\"\n    active_tasks = [t for t in self.bg_tasks if t.is_alive()]\n\n    for task in active_tasks:\n        task.join(timeout=timeout)\n        if task.is_alive():\n            return False\n\n    return True\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.App.ws_broadcast","title":"<code>ws_broadcast(channel_id, payload, source_conn_id='python_broadcast')</code>  <code>async</code>","text":"<p>Sendet eine Nachricht asynchron an alle Clients in einem Kanal/Raum.</p> <p>Parameters:</p> Name Type Description Default <code>channel_id</code> <code>str</code> <p>Der Kanal, an den gesendet werden soll.</p> required <code>payload</code> <code>dict</code> <p>Ein Dictionary, das als JSON gesendet wird.</p> required <code>source_conn_id</code> <code>optional</code> <p>Die ID der urspr\u00fcnglichen Verbindung, um Echos zu vermeiden.</p> <code>'python_broadcast'</code> Source code in <code>toolboxv2/utils/toolbox.py</code> <pre><code>async def ws_broadcast(self, channel_id: str, payload: dict, source_conn_id: str = \"python_broadcast\"):\n    \"\"\"\n    Sendet eine Nachricht asynchron an alle Clients in einem Kanal/Raum.\n\n    Args:\n        channel_id: Der Kanal, an den gesendet werden soll.\n        payload: Ein Dictionary, das als JSON gesendet wird.\n        source_conn_id (optional): Die ID der urspr\u00fcnglichen Verbindung, um Echos zu vermeiden.\n    \"\"\"\n    if self._rust_ws_bridge is None:\n        self.logger.error(\"Cannot broadcast WebSocket message: Rust bridge is not initialized.\")\n        return\n\n    try:\n        # Ruft die asynchrone Rust-Broadcast-Methode auf\n        await self._rust_ws_bridge.broadcast_message(channel_id, json.dumps(payload), source_conn_id)\n    except Exception as e:\n        self.logger.error(f\"Failed to broadcast WebSocket message to channel {channel_id}: {e}\", exc_info=True)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.App.ws_send","title":"<code>ws_send(conn_id, payload)</code>  <code>async</code>","text":"<p>Sendet eine Nachricht asynchron an eine einzelne WebSocket-Verbindung.</p> <p>Parameters:</p> Name Type Description Default <code>conn_id</code> <code>str</code> <p>Die eindeutige ID der Zielverbindung.</p> required <code>payload</code> <code>dict</code> <p>Ein Dictionary, das als JSON gesendet wird.</p> required Source code in <code>toolboxv2/utils/toolbox.py</code> <pre><code>async def ws_send(self, conn_id: str, payload: dict):\n    \"\"\"\n    Sendet eine Nachricht asynchron an eine einzelne WebSocket-Verbindung.\n\n    Args:\n        conn_id: Die eindeutige ID der Zielverbindung.\n        payload: Ein Dictionary, das als JSON gesendet wird.\n    \"\"\"\n    if self._rust_ws_bridge is None:\n        self.logger.error(\"Cannot send WebSocket message: Rust bridge is not initialized.\")\n        return\n\n    try:\n        # Ruft die asynchrone Rust-Methode auf und wartet auf deren Abschluss\n        await self._rust_ws_bridge.send_message(conn_id, json.dumps(payload))\n    except Exception as e:\n        self.logger.error(f\"Failed to send WebSocket message to {conn_id}: {e}\", exc_info=True)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.Code","title":"<code>Code</code>","text":"Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>class Code:\n\n    @staticmethod\n    def DK():\n        return DEVICE_KEY\n\n    def decode_code(self, encrypted_data, key=None):\n\n        if not isinstance(encrypted_data, str):\n            encrypted_data = str(encrypted_data)\n\n        if key is None:\n            key = DEVICE_KEY()\n\n        return self.decrypt_symmetric(encrypted_data, key)\n\n    def encode_code(self, data, key=None):\n\n        if not isinstance(data, str):\n            data = str(data)\n\n        if key is None:\n            key = DEVICE_KEY()\n\n        return self.encrypt_symmetric(data, key)\n\n    @staticmethod\n    def generate_seed() -&gt; int:\n        \"\"\"\n        Erzeugt eine zuf\u00e4llige Zahl als Seed.\n\n        Returns:\n            int: Eine zuf\u00e4llige Zahl.\n        \"\"\"\n        return random.randint(2 ** 32 - 1, 2 ** 64 - 1)\n\n    @staticmethod\n    def one_way_hash(text: str, salt: str = '', pepper: str = '') -&gt; str:\n        \"\"\"\n        Erzeugt einen Hash eines gegebenen Textes mit Salt, Pepper und optional einem Seed.\n\n        Args:\n            text (str): Der zu hashende Text.\n            salt (str): Der Salt-Wert.\n            pepper (str): Der Pepper-Wert.\n            seed (int, optional): Ein optionaler Seed-Wert. Standardm\u00e4\u00dfig None.\n\n        Returns:\n            str: Der resultierende Hash-Wert.\n        \"\"\"\n        return hashlib.sha256((salt + text + pepper).encode()).hexdigest()\n\n    @staticmethod\n    def generate_symmetric_key(as_str=True) -&gt; str or bytes:\n        \"\"\"\n        Generiert einen Schl\u00fcssel f\u00fcr die symmetrische Verschl\u00fcsselung.\n\n        Returns:\n            str: Der generierte Schl\u00fcssel.\n        \"\"\"\n        key = Fernet.generate_key()\n        if as_str:\n            key = key.decode()\n        return key\n\n    @staticmethod\n    def encrypt_symmetric(text: str or bytes, key: str) -&gt; str:\n        \"\"\"\n        Verschl\u00fcsselt einen Text mit einem gegebenen symmetrischen Schl\u00fcssel.\n\n        Args:\n            text (str): Der zu verschl\u00fcsselnde Text.\n            key (str): Der symmetrische Schl\u00fcssel.\n\n        Returns:\n            str: Der verschl\u00fcsselte Text.\n        \"\"\"\n        if isinstance(text, str):\n            text = text.encode()\n\n        try:\n            fernet = Fernet(key.encode())\n            return fernet.encrypt(text).decode()\n        except Exception as e:\n            get_logger().error(f\"Error encrypt_symmetric #{str(e)}#\")\n            return \"Error encrypt\"\n\n    @staticmethod\n    def decrypt_symmetric(encrypted_text: str, key: str, to_str=True, mute=False) -&gt; str or bytes:\n        \"\"\"\n        Entschl\u00fcsselt einen Text mit einem gegebenen symmetrischen Schl\u00fcssel.\n\n        Args:\n            encrypted_text (str): Der zu entschl\u00fcsselnde Text.\n            key (str): Der symmetrische Schl\u00fcssel.\n            to_str (bool): default true returns str if false returns bytes\n        Returns:\n            str: Der entschl\u00fcsselte Text.\n        \"\"\"\n\n        if isinstance(key, str):\n            key = key.encode()\n\n        #try:\n        fernet = Fernet(key)\n        text_b = fernet.decrypt(encrypted_text)\n        if not to_str:\n            return text_b\n        return text_b.decode()\n        # except Exception as e:\n        #     get_logger().error(f\"Error decrypt_symmetric {e}\")\n        #     if not mute:\n        #         raise e\n        #     if not to_str:\n        #         return f\"Error decoding\".encode()\n        #     return f\"Error decoding\"\n\n    @staticmethod\n    def generate_asymmetric_keys() -&gt; (str, str):\n        \"\"\"\n        Generiert ein Paar von \u00f6ffentlichen und privaten Schl\u00fcsseln f\u00fcr die asymmetrische Verschl\u00fcsselung.\n\n        Args:\n            seed (int, optional): Ein optionaler Seed-Wert. Standardm\u00e4\u00dfig None.\n\n        Returns:\n            (str, str): Ein Tupel aus \u00f6ffentlichem und privatem Schl\u00fcssel.\n        \"\"\"\n        private_key = rsa.generate_private_key(\n            public_exponent=65537,\n            key_size=2048 * 3,\n        )\n        public_key = private_key.public_key()\n\n        # Serialisieren der Schl\u00fcssel\n        pem_private_key = private_key.private_bytes(\n            encoding=serialization.Encoding.PEM,\n            format=serialization.PrivateFormat.PKCS8,\n            encryption_algorithm=serialization.NoEncryption()\n        ).decode()\n\n        pem_public_key = public_key.public_bytes(\n            encoding=serialization.Encoding.PEM,\n            format=serialization.PublicFormat.SubjectPublicKeyInfo\n        ).decode()\n\n        return pem_public_key, pem_private_key\n\n    @staticmethod\n    def save_keys_to_files(public_key: str, private_key: str, directory: str = \"keys\") -&gt; None:\n        \"\"\"\n        Speichert die generierten Schl\u00fcssel in separate Dateien.\n        Der private Schl\u00fcssel wird mit dem Device Key verschl\u00fcsselt.\n\n        Args:\n            public_key (str): Der \u00f6ffentliche Schl\u00fcssel im PEM-Format\n            private_key (str): Der private Schl\u00fcssel im PEM-Format\n            directory (str): Das Verzeichnis, in dem die Schl\u00fcssel gespeichert werden sollen\n        \"\"\"\n        # Erstelle das Verzeichnis, falls es nicht existiert\n        os.makedirs(directory, exist_ok=True)\n\n        # Hole den Device Key\n        device_key = DEVICE_KEY()\n\n        # Verschl\u00fcssele den privaten Schl\u00fcssel mit dem Device Key\n        encrypted_private_key = Code.encrypt_symmetric(private_key, device_key)\n\n        # Speichere den \u00f6ffentlichen Schl\u00fcssel\n        public_key_path = os.path.join(directory, \"public_key.pem\")\n        with open(public_key_path, \"w\") as f:\n            f.write(public_key)\n\n        # Speichere den verschl\u00fcsselten privaten Schl\u00fcssel\n        private_key_path = os.path.join(directory, \"private_key.pem\")\n        with open(private_key_path, \"w\") as f:\n            f.write(encrypted_private_key)\n\n        print(\"Saved keys in \", public_key_path)\n\n    @staticmethod\n    def load_keys_from_files(directory: str = \"keys\") -&gt; (str, str):\n        \"\"\"\n        L\u00e4dt die Schl\u00fcssel aus den Dateien.\n        Der private Schl\u00fcssel wird mit dem Device Key entschl\u00fcsselt.\n\n        Args:\n            directory (str): Das Verzeichnis, aus dem die Schl\u00fcssel geladen werden sollen\n\n        Returns:\n            (str, str): Ein Tupel aus \u00f6ffentlichem und privatem Schl\u00fcssel\n\n        Raises:\n            FileNotFoundError: Wenn die Schl\u00fcsseldateien nicht gefunden werden k\u00f6nnen\n        \"\"\"\n        # Pfade zu den Schl\u00fcsseldateien\n        public_key_path = os.path.join(directory, \"public_key.pem\")\n        private_key_path = os.path.join(directory, \"private_key.pem\")\n\n        # Pr\u00fcfe ob die Dateien existieren\n        if not os.path.exists(public_key_path) or not os.path.exists(private_key_path):\n            return \"\", \"\"\n\n        # Hole den Device Key\n        device_key = DEVICE_KEY()\n\n        # Lade den \u00f6ffentlichen Schl\u00fcssel\n        with open(public_key_path) as f:\n            public_key = f.read()\n\n        # Lade und entschl\u00fcssele den privaten Schl\u00fcssel\n        with open(private_key_path) as f:\n            encrypted_private_key = f.read()\n            private_key = Code.decrypt_symmetric(encrypted_private_key, device_key)\n\n        return public_key, private_key\n\n    @staticmethod\n    def encrypt_asymmetric(text: str, public_key_str: str) -&gt; str:\n        \"\"\"\n        Verschl\u00fcsselt einen Text mit einem gegebenen \u00f6ffentlichen Schl\u00fcssel.\n\n        Args:\n            text (str): Der zu verschl\u00fcsselnde Text.\n            public_key_str (str): Der \u00f6ffentliche Schl\u00fcssel als String oder im pem format.\n\n        Returns:\n            str: Der verschl\u00fcsselte Text.\n        \"\"\"\n        # try:\n        #    public_key: RSAPublicKey = serialization.load_pem_public_key(public_key_str.encode())\n        #  except Exception as e:\n        #     get_logger().error(f\"Error encrypt_asymmetric {e}\")\n        try:\n            public_key: RSAPublicKey = serialization.load_pem_public_key(public_key_str.encode())\n            encrypted = public_key.encrypt(\n                text.encode(),\n                padding.OAEP(\n                    mgf=padding.MGF1(algorithm=hashes.SHA512()),\n                    algorithm=hashes.SHA512(),\n                    label=None\n                )\n            )\n            return encrypted.hex()\n        except Exception as e:\n            get_logger().error(f\"Error encrypt_asymmetric {e}\")\n            return \"Invalid\"\n\n    @staticmethod\n    def decrypt_asymmetric(encrypted_text_hex: str, private_key_str: str) -&gt; str:\n        \"\"\"\n        Entschl\u00fcsselt einen Text mit einem gegebenen privaten Schl\u00fcssel.\n\n        Args:\n            encrypted_text_hex (str): Der verschl\u00fcsselte Text als Hex-String.\n            private_key_str (str): Der private Schl\u00fcssel als String.\n\n        Returns:\n            str: Der entschl\u00fcsselte Text.\n        \"\"\"\n        try:\n            private_key = serialization.load_pem_private_key(private_key_str.encode(), password=None)\n            decrypted = private_key.decrypt(\n                bytes.fromhex(encrypted_text_hex),\n                padding.OAEP(\n                    mgf=padding.MGF1(algorithm=hashes.SHA512()),\n                    algorithm=hashes.SHA512(),\n                    label=None\n                )\n            )\n            return decrypted.decode()\n\n        except Exception as e:\n            get_logger().error(f\"Error decrypt_asymmetric {e}\")\n        return \"Invalid\"\n\n    @staticmethod\n    def verify_signature(signature: str or bytes, message: str or bytes, public_key_str: str,\n                         salt_length=padding.PSS.MAX_LENGTH) -&gt; bool:\n        if isinstance(signature, str):\n            signature = signature.encode()\n        if isinstance(message, str):\n            message = message.encode()\n        try:\n            public_key: RSAPublicKey = serialization.load_pem_public_key(public_key_str.encode())\n            public_key.verify(\n                signature=signature,\n                data=message,\n                padding=padding.PSS(\n                    mgf=padding.MGF1(hashes.SHA512()),\n                    salt_length=salt_length\n                ),\n                algorithm=hashes.SHA512()\n            )\n            return True\n        except:\n            pass\n        return False\n\n    @staticmethod\n    def verify_signature_web_algo(signature: str or bytes, message: str or bytes, public_key_str: str,\n                                  algo: int = -512) -&gt; bool:\n        signature_algorithm = ECDSA(hashes.SHA512())\n        if algo != -512:\n            signature_algorithm = ECDSA(hashes.SHA256())\n\n        if isinstance(signature, str):\n            signature = signature.encode()\n        if isinstance(message, str):\n            message = message.encode()\n        try:\n            public_key = serialization.load_pem_public_key(public_key_str.encode())\n            public_key.verify(\n                signature=signature,\n                data=message,\n                # padding=padding.PSS(\n                #    mgf=padding.MGF1(hashes.SHA512()),\n                #    salt_length=padding.PSS.MAX_LENGTH\n                # ),\n                signature_algorithm=signature_algorithm\n            )\n            return True\n        except:\n            pass\n        return False\n\n    @staticmethod\n    def create_signature(message: str, private_key_str: str, salt_length=padding.PSS.MAX_LENGTH,\n                         row=False) -&gt; str or bytes:\n        try:\n            private_key = serialization.load_pem_private_key(private_key_str.encode(), password=None)\n            signature = private_key.sign(\n                message.encode(),\n                padding.PSS(\n                    mgf=padding.MGF1(hashes.SHA512()),\n                    salt_length=salt_length\n                ),\n                hashes.SHA512()\n            )\n            if row:\n                return signature\n            return base64.b64encode(signature).decode()\n        except Exception as e:\n            get_logger().error(f\"Error create_signature {e}\")\n            print(e)\n        return \"Invalid Key\"\n\n    @staticmethod\n    def pem_to_public_key(pem_key: str):\n        \"\"\"\n        Konvertiert einen PEM-kodierten \u00f6ffentlichen Schl\u00fcssel in ein PublicKey-Objekt.\n\n        Args:\n            pem_key (str): Der PEM-kodierte \u00f6ffentliche Schl\u00fcssel.\n\n        Returns:\n            PublicKey: Das PublicKey-Objekt.\n        \"\"\"\n        public_key = serialization.load_pem_public_key(pem_key.encode())\n        return public_key\n\n    @staticmethod\n    def public_key_to_pem(public_key: RSAPublicKey):\n        \"\"\"\n        Konvertiert ein PublicKey-Objekt in einen PEM-kodierten String.\n\n        Args:\n            public_key (PublicKey): Das PublicKey-Objekt.\n\n        Returns:\n            str: Der PEM-kodierte \u00f6ffentliche Schl\u00fcssel.\n        \"\"\"\n        pem = public_key.public_bytes(\n            encoding=serialization.Encoding.PEM,\n            format=serialization.PublicFormat.SubjectPublicKeyInfo\n        )\n        return pem.decode()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.Code.decrypt_asymmetric","title":"<code>decrypt_asymmetric(encrypted_text_hex, private_key_str)</code>  <code>staticmethod</code>","text":"<p>Entschl\u00fcsselt einen Text mit einem gegebenen privaten Schl\u00fcssel.</p> <p>Parameters:</p> Name Type Description Default <code>encrypted_text_hex</code> <code>str</code> <p>Der verschl\u00fcsselte Text als Hex-String.</p> required <code>private_key_str</code> <code>str</code> <p>Der private Schl\u00fcssel als String.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Der entschl\u00fcsselte Text.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef decrypt_asymmetric(encrypted_text_hex: str, private_key_str: str) -&gt; str:\n    \"\"\"\n    Entschl\u00fcsselt einen Text mit einem gegebenen privaten Schl\u00fcssel.\n\n    Args:\n        encrypted_text_hex (str): Der verschl\u00fcsselte Text als Hex-String.\n        private_key_str (str): Der private Schl\u00fcssel als String.\n\n    Returns:\n        str: Der entschl\u00fcsselte Text.\n    \"\"\"\n    try:\n        private_key = serialization.load_pem_private_key(private_key_str.encode(), password=None)\n        decrypted = private_key.decrypt(\n            bytes.fromhex(encrypted_text_hex),\n            padding.OAEP(\n                mgf=padding.MGF1(algorithm=hashes.SHA512()),\n                algorithm=hashes.SHA512(),\n                label=None\n            )\n        )\n        return decrypted.decode()\n\n    except Exception as e:\n        get_logger().error(f\"Error decrypt_asymmetric {e}\")\n    return \"Invalid\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.Code.decrypt_symmetric","title":"<code>decrypt_symmetric(encrypted_text, key, to_str=True, mute=False)</code>  <code>staticmethod</code>","text":"<p>Entschl\u00fcsselt einen Text mit einem gegebenen symmetrischen Schl\u00fcssel.</p> <p>Parameters:</p> Name Type Description Default <code>encrypted_text</code> <code>str</code> <p>Der zu entschl\u00fcsselnde Text.</p> required <code>key</code> <code>str</code> <p>Der symmetrische Schl\u00fcssel.</p> required <code>to_str</code> <code>bool</code> <p>default true returns str if false returns bytes</p> <code>True</code> <p>Returns:     str: Der entschl\u00fcsselte Text.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef decrypt_symmetric(encrypted_text: str, key: str, to_str=True, mute=False) -&gt; str or bytes:\n    \"\"\"\n    Entschl\u00fcsselt einen Text mit einem gegebenen symmetrischen Schl\u00fcssel.\n\n    Args:\n        encrypted_text (str): Der zu entschl\u00fcsselnde Text.\n        key (str): Der symmetrische Schl\u00fcssel.\n        to_str (bool): default true returns str if false returns bytes\n    Returns:\n        str: Der entschl\u00fcsselte Text.\n    \"\"\"\n\n    if isinstance(key, str):\n        key = key.encode()\n\n    #try:\n    fernet = Fernet(key)\n    text_b = fernet.decrypt(encrypted_text)\n    if not to_str:\n        return text_b\n    return text_b.decode()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.Code.encrypt_asymmetric","title":"<code>encrypt_asymmetric(text, public_key_str)</code>  <code>staticmethod</code>","text":"<p>Verschl\u00fcsselt einen Text mit einem gegebenen \u00f6ffentlichen Schl\u00fcssel.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Der zu verschl\u00fcsselnde Text.</p> required <code>public_key_str</code> <code>str</code> <p>Der \u00f6ffentliche Schl\u00fcssel als String oder im pem format.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Der verschl\u00fcsselte Text.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef encrypt_asymmetric(text: str, public_key_str: str) -&gt; str:\n    \"\"\"\n    Verschl\u00fcsselt einen Text mit einem gegebenen \u00f6ffentlichen Schl\u00fcssel.\n\n    Args:\n        text (str): Der zu verschl\u00fcsselnde Text.\n        public_key_str (str): Der \u00f6ffentliche Schl\u00fcssel als String oder im pem format.\n\n    Returns:\n        str: Der verschl\u00fcsselte Text.\n    \"\"\"\n    # try:\n    #    public_key: RSAPublicKey = serialization.load_pem_public_key(public_key_str.encode())\n    #  except Exception as e:\n    #     get_logger().error(f\"Error encrypt_asymmetric {e}\")\n    try:\n        public_key: RSAPublicKey = serialization.load_pem_public_key(public_key_str.encode())\n        encrypted = public_key.encrypt(\n            text.encode(),\n            padding.OAEP(\n                mgf=padding.MGF1(algorithm=hashes.SHA512()),\n                algorithm=hashes.SHA512(),\n                label=None\n            )\n        )\n        return encrypted.hex()\n    except Exception as e:\n        get_logger().error(f\"Error encrypt_asymmetric {e}\")\n        return \"Invalid\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.Code.encrypt_symmetric","title":"<code>encrypt_symmetric(text, key)</code>  <code>staticmethod</code>","text":"<p>Verschl\u00fcsselt einen Text mit einem gegebenen symmetrischen Schl\u00fcssel.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Der zu verschl\u00fcsselnde Text.</p> required <code>key</code> <code>str</code> <p>Der symmetrische Schl\u00fcssel.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Der verschl\u00fcsselte Text.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef encrypt_symmetric(text: str or bytes, key: str) -&gt; str:\n    \"\"\"\n    Verschl\u00fcsselt einen Text mit einem gegebenen symmetrischen Schl\u00fcssel.\n\n    Args:\n        text (str): Der zu verschl\u00fcsselnde Text.\n        key (str): Der symmetrische Schl\u00fcssel.\n\n    Returns:\n        str: Der verschl\u00fcsselte Text.\n    \"\"\"\n    if isinstance(text, str):\n        text = text.encode()\n\n    try:\n        fernet = Fernet(key.encode())\n        return fernet.encrypt(text).decode()\n    except Exception as e:\n        get_logger().error(f\"Error encrypt_symmetric #{str(e)}#\")\n        return \"Error encrypt\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.Code.generate_asymmetric_keys","title":"<code>generate_asymmetric_keys()</code>  <code>staticmethod</code>","text":"<p>Generiert ein Paar von \u00f6ffentlichen und privaten Schl\u00fcsseln f\u00fcr die asymmetrische Verschl\u00fcsselung.</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>int</code> <p>Ein optionaler Seed-Wert. Standardm\u00e4\u00dfig None.</p> required <p>Returns:</p> Type Description <code>(str, str)</code> <p>Ein Tupel aus \u00f6ffentlichem und privatem Schl\u00fcssel.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef generate_asymmetric_keys() -&gt; (str, str):\n    \"\"\"\n    Generiert ein Paar von \u00f6ffentlichen und privaten Schl\u00fcsseln f\u00fcr die asymmetrische Verschl\u00fcsselung.\n\n    Args:\n        seed (int, optional): Ein optionaler Seed-Wert. Standardm\u00e4\u00dfig None.\n\n    Returns:\n        (str, str): Ein Tupel aus \u00f6ffentlichem und privatem Schl\u00fcssel.\n    \"\"\"\n    private_key = rsa.generate_private_key(\n        public_exponent=65537,\n        key_size=2048 * 3,\n    )\n    public_key = private_key.public_key()\n\n    # Serialisieren der Schl\u00fcssel\n    pem_private_key = private_key.private_bytes(\n        encoding=serialization.Encoding.PEM,\n        format=serialization.PrivateFormat.PKCS8,\n        encryption_algorithm=serialization.NoEncryption()\n    ).decode()\n\n    pem_public_key = public_key.public_bytes(\n        encoding=serialization.Encoding.PEM,\n        format=serialization.PublicFormat.SubjectPublicKeyInfo\n    ).decode()\n\n    return pem_public_key, pem_private_key\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.Code.generate_seed","title":"<code>generate_seed()</code>  <code>staticmethod</code>","text":"<p>Erzeugt eine zuf\u00e4llige Zahl als Seed.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Eine zuf\u00e4llige Zahl.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef generate_seed() -&gt; int:\n    \"\"\"\n    Erzeugt eine zuf\u00e4llige Zahl als Seed.\n\n    Returns:\n        int: Eine zuf\u00e4llige Zahl.\n    \"\"\"\n    return random.randint(2 ** 32 - 1, 2 ** 64 - 1)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.Code.generate_symmetric_key","title":"<code>generate_symmetric_key(as_str=True)</code>  <code>staticmethod</code>","text":"<p>Generiert einen Schl\u00fcssel f\u00fcr die symmetrische Verschl\u00fcsselung.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str or bytes</code> <p>Der generierte Schl\u00fcssel.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef generate_symmetric_key(as_str=True) -&gt; str or bytes:\n    \"\"\"\n    Generiert einen Schl\u00fcssel f\u00fcr die symmetrische Verschl\u00fcsselung.\n\n    Returns:\n        str: Der generierte Schl\u00fcssel.\n    \"\"\"\n    key = Fernet.generate_key()\n    if as_str:\n        key = key.decode()\n    return key\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.Code.load_keys_from_files","title":"<code>load_keys_from_files(directory='keys')</code>  <code>staticmethod</code>","text":"<p>L\u00e4dt die Schl\u00fcssel aus den Dateien. Der private Schl\u00fcssel wird mit dem Device Key entschl\u00fcsselt.</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>str</code> <p>Das Verzeichnis, aus dem die Schl\u00fcssel geladen werden sollen</p> <code>'keys'</code> <p>Returns:</p> Type Description <code>(str, str)</code> <p>Ein Tupel aus \u00f6ffentlichem und privatem Schl\u00fcssel</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>Wenn die Schl\u00fcsseldateien nicht gefunden werden k\u00f6nnen</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef load_keys_from_files(directory: str = \"keys\") -&gt; (str, str):\n    \"\"\"\n    L\u00e4dt die Schl\u00fcssel aus den Dateien.\n    Der private Schl\u00fcssel wird mit dem Device Key entschl\u00fcsselt.\n\n    Args:\n        directory (str): Das Verzeichnis, aus dem die Schl\u00fcssel geladen werden sollen\n\n    Returns:\n        (str, str): Ein Tupel aus \u00f6ffentlichem und privatem Schl\u00fcssel\n\n    Raises:\n        FileNotFoundError: Wenn die Schl\u00fcsseldateien nicht gefunden werden k\u00f6nnen\n    \"\"\"\n    # Pfade zu den Schl\u00fcsseldateien\n    public_key_path = os.path.join(directory, \"public_key.pem\")\n    private_key_path = os.path.join(directory, \"private_key.pem\")\n\n    # Pr\u00fcfe ob die Dateien existieren\n    if not os.path.exists(public_key_path) or not os.path.exists(private_key_path):\n        return \"\", \"\"\n\n    # Hole den Device Key\n    device_key = DEVICE_KEY()\n\n    # Lade den \u00f6ffentlichen Schl\u00fcssel\n    with open(public_key_path) as f:\n        public_key = f.read()\n\n    # Lade und entschl\u00fcssele den privaten Schl\u00fcssel\n    with open(private_key_path) as f:\n        encrypted_private_key = f.read()\n        private_key = Code.decrypt_symmetric(encrypted_private_key, device_key)\n\n    return public_key, private_key\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.Code.one_way_hash","title":"<code>one_way_hash(text, salt='', pepper='')</code>  <code>staticmethod</code>","text":"<p>Erzeugt einen Hash eines gegebenen Textes mit Salt, Pepper und optional einem Seed.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Der zu hashende Text.</p> required <code>salt</code> <code>str</code> <p>Der Salt-Wert.</p> <code>''</code> <code>pepper</code> <code>str</code> <p>Der Pepper-Wert.</p> <code>''</code> <code>seed</code> <code>int</code> <p>Ein optionaler Seed-Wert. Standardm\u00e4\u00dfig None.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Der resultierende Hash-Wert.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef one_way_hash(text: str, salt: str = '', pepper: str = '') -&gt; str:\n    \"\"\"\n    Erzeugt einen Hash eines gegebenen Textes mit Salt, Pepper und optional einem Seed.\n\n    Args:\n        text (str): Der zu hashende Text.\n        salt (str): Der Salt-Wert.\n        pepper (str): Der Pepper-Wert.\n        seed (int, optional): Ein optionaler Seed-Wert. Standardm\u00e4\u00dfig None.\n\n    Returns:\n        str: Der resultierende Hash-Wert.\n    \"\"\"\n    return hashlib.sha256((salt + text + pepper).encode()).hexdigest()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.Code.pem_to_public_key","title":"<code>pem_to_public_key(pem_key)</code>  <code>staticmethod</code>","text":"<p>Konvertiert einen PEM-kodierten \u00f6ffentlichen Schl\u00fcssel in ein PublicKey-Objekt.</p> <p>Parameters:</p> Name Type Description Default <code>pem_key</code> <code>str</code> <p>Der PEM-kodierte \u00f6ffentliche Schl\u00fcssel.</p> required <p>Returns:</p> Name Type Description <code>PublicKey</code> <p>Das PublicKey-Objekt.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef pem_to_public_key(pem_key: str):\n    \"\"\"\n    Konvertiert einen PEM-kodierten \u00f6ffentlichen Schl\u00fcssel in ein PublicKey-Objekt.\n\n    Args:\n        pem_key (str): Der PEM-kodierte \u00f6ffentliche Schl\u00fcssel.\n\n    Returns:\n        PublicKey: Das PublicKey-Objekt.\n    \"\"\"\n    public_key = serialization.load_pem_public_key(pem_key.encode())\n    return public_key\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.Code.public_key_to_pem","title":"<code>public_key_to_pem(public_key)</code>  <code>staticmethod</code>","text":"<p>Konvertiert ein PublicKey-Objekt in einen PEM-kodierten String.</p> <p>Parameters:</p> Name Type Description Default <code>public_key</code> <code>PublicKey</code> <p>Das PublicKey-Objekt.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>Der PEM-kodierte \u00f6ffentliche Schl\u00fcssel.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef public_key_to_pem(public_key: RSAPublicKey):\n    \"\"\"\n    Konvertiert ein PublicKey-Objekt in einen PEM-kodierten String.\n\n    Args:\n        public_key (PublicKey): Das PublicKey-Objekt.\n\n    Returns:\n        str: Der PEM-kodierte \u00f6ffentliche Schl\u00fcssel.\n    \"\"\"\n    pem = public_key.public_bytes(\n        encoding=serialization.Encoding.PEM,\n        format=serialization.PublicFormat.SubjectPublicKeyInfo\n    )\n    return pem.decode()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.Code.save_keys_to_files","title":"<code>save_keys_to_files(public_key, private_key, directory='keys')</code>  <code>staticmethod</code>","text":"<p>Speichert die generierten Schl\u00fcssel in separate Dateien. Der private Schl\u00fcssel wird mit dem Device Key verschl\u00fcsselt.</p> <p>Parameters:</p> Name Type Description Default <code>public_key</code> <code>str</code> <p>Der \u00f6ffentliche Schl\u00fcssel im PEM-Format</p> required <code>private_key</code> <code>str</code> <p>Der private Schl\u00fcssel im PEM-Format</p> required <code>directory</code> <code>str</code> <p>Das Verzeichnis, in dem die Schl\u00fcssel gespeichert werden sollen</p> <code>'keys'</code> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef save_keys_to_files(public_key: str, private_key: str, directory: str = \"keys\") -&gt; None:\n    \"\"\"\n    Speichert die generierten Schl\u00fcssel in separate Dateien.\n    Der private Schl\u00fcssel wird mit dem Device Key verschl\u00fcsselt.\n\n    Args:\n        public_key (str): Der \u00f6ffentliche Schl\u00fcssel im PEM-Format\n        private_key (str): Der private Schl\u00fcssel im PEM-Format\n        directory (str): Das Verzeichnis, in dem die Schl\u00fcssel gespeichert werden sollen\n    \"\"\"\n    # Erstelle das Verzeichnis, falls es nicht existiert\n    os.makedirs(directory, exist_ok=True)\n\n    # Hole den Device Key\n    device_key = DEVICE_KEY()\n\n    # Verschl\u00fcssele den privaten Schl\u00fcssel mit dem Device Key\n    encrypted_private_key = Code.encrypt_symmetric(private_key, device_key)\n\n    # Speichere den \u00f6ffentlichen Schl\u00fcssel\n    public_key_path = os.path.join(directory, \"public_key.pem\")\n    with open(public_key_path, \"w\") as f:\n        f.write(public_key)\n\n    # Speichere den verschl\u00fcsselten privaten Schl\u00fcssel\n    private_key_path = os.path.join(directory, \"private_key.pem\")\n    with open(private_key_path, \"w\") as f:\n        f.write(encrypted_private_key)\n\n    print(\"Saved keys in \", public_key_path)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.MainTool","title":"<code>MainTool</code>","text":"Source code in <code>toolboxv2/utils/system/main_tool.py</code> <pre><code>class MainTool:\n    toolID: str = \"\"\n    # app = None\n    interface = None\n    spec = \"app\"\n    name = \"\"\n    color = \"Bold\"\n    stuf = False\n\n    def __init__(self, *args, **kwargs):\n        \"\"\"\n        Standard constructor used for arguments pass\n        Do not override. Use __ainit__ instead\n        \"\"\"\n        self.__storedargs = args, kwargs\n        self.tools = kwargs.get(\"tool\", {})\n        self.logger = kwargs.get(\"logs\", get_logger())\n        self.color = kwargs.get(\"color\", \"WHITE\")\n        self.todo = kwargs.get(\"load\", kwargs.get(\"on_start\", lambda: None))\n        if \"on_exit\" in kwargs and isinstance(kwargs.get(\"on_exit\"), Callable):\n            self.on_exit =self.app.tb(\n                mod_name=self.name,\n                name=kwargs.get(\"on_exit\").__name__,\n                version=self.version if hasattr(self, 'version') else \"0.0.0\",\n            )(kwargs.get(\"on_exit\"))\n        self.async_initialized = False\n        if self.todo:\n            try:\n                if inspect.iscoroutinefunction(self.todo):\n                    pass\n                else:\n                    self.todo()\n                get_logger().info(f\"{self.name} on load suspended\")\n            except Exception as e:\n                get_logger().error(f\"Error loading mod {self.name} {e}\")\n                if self.app.debug:\n                    import traceback\n                    traceback.print_exc()\n        else:\n            get_logger().info(f\"{self.name} no load require\")\n\n    async def __ainit__(self, *args, **kwargs):\n        self.version = kwargs[\"v\"]\n        self.tools = kwargs.get(\"tool\", {})\n        self.name = kwargs[\"name\"]\n        self.logger = kwargs.get(\"logs\", get_logger())\n        self.color = kwargs.get(\"color\", \"WHITE\")\n        self.todo = kwargs.get(\"load\", kwargs.get(\"on_start\"))\n        if not hasattr(self, 'config'):\n            self.config = {}\n        self.user = None\n        self.description = \"A toolbox mod\" if kwargs.get(\"description\") is None else kwargs.get(\"description\")\n        if MainTool.interface is None:\n            MainTool.interface = self.app.interface_type\n        # Result.default(self.app.interface)\n\n        if self.todo:\n            try:\n                if inspect.iscoroutinefunction(self.todo):\n                    await self.todo()\n                else:\n                    pass\n                await asyncio.sleep(0.1)\n                get_logger().info(f\"{self.name} on load suspended\")\n            except Exception as e:\n                get_logger().error(f\"Error loading mod {self.name} {e}\")\n                if self.app.debug:\n                    import traceback\n                    traceback.print_exc()\n        else:\n            get_logger().info(f\"{self.name} no load require\")\n        self.app.print(f\"TOOL : {self.spec}.{self.name} online\")\n\n\n\n    @property\n    def app(self):\n        return get_app(\n            from_=f\"{self.spec}.{self.name}|{self.toolID if self.toolID else '*' + MainTool.toolID} {self.interface if self.interface else MainTool.interface}\")\n\n    @app.setter\n    def app(self, v):\n        raise PermissionError(f\"You cannot set the App Instance! {v=}\")\n\n    @staticmethod\n    def return_result(error: ToolBoxError = ToolBoxError.none,\n                      exec_code: int = 0,\n                      help_text: str = \"\",\n                      data_info=None,\n                      data=None,\n                      data_to=None):\n\n        if data_to is None:\n            data_to = MainTool.interface if MainTool.interface is not None else ToolBoxInterfaces.cli\n\n        if data is None:\n            data = {}\n\n        if data_info is None:\n            data_info = {}\n\n        return Result(\n            error,\n            ToolBoxResult(data_info=data_info, data=data, data_to=data_to),\n            ToolBoxInfo(exec_code=exec_code, help_text=help_text)\n        )\n\n    def print(self, message, end=\"\\n\", **kwargs):\n        if self.stuf:\n            return\n\n        self.app.print(Style.style_dic[self.color] + self.name + Style.style_dic[\"END\"] + \":\", message, end=end,\n                       **kwargs)\n\n    def add_str_to_config(self, command):\n        if len(command) != 2:\n            self.logger.error('Invalid command must be key value')\n            return False\n        self.config[command[0]] = command[1]\n\n    def webInstall(self, user_instance, construct_render) -&gt; str:\n        \"\"\"\"Returns a web installer for the given user instance and construct render template\"\"\"\n\n    def get_version(self) -&gt; str:\n        \"\"\"\"Returns the version\"\"\"\n        return self.version\n\n    async def get_user(self, username: str) -&gt; Result:\n        return await self.app.a_run_any(CLOUDM_AUTHMANAGER.GET_USER_BY_NAME, username=username, get_results=True)\n\n    async def __initobj(self):\n        \"\"\"Crutch used for __await__ after spawning\"\"\"\n        assert not self.async_initialized\n        self.async_initialized = True\n        # pass the parameters to __ainit__ that passed to __init__\n        await self.__ainit__(*self.__storedargs[0], **self.__storedargs[1])\n        return self\n\n    def __await__(self):\n        return self.__initobj().__await__()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.MainTool.__init__","title":"<code>__init__(*args, **kwargs)</code>","text":"<p>Standard constructor used for arguments pass Do not override. Use ainit instead</p> Source code in <code>toolboxv2/utils/system/main_tool.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"\n    Standard constructor used for arguments pass\n    Do not override. Use __ainit__ instead\n    \"\"\"\n    self.__storedargs = args, kwargs\n    self.tools = kwargs.get(\"tool\", {})\n    self.logger = kwargs.get(\"logs\", get_logger())\n    self.color = kwargs.get(\"color\", \"WHITE\")\n    self.todo = kwargs.get(\"load\", kwargs.get(\"on_start\", lambda: None))\n    if \"on_exit\" in kwargs and isinstance(kwargs.get(\"on_exit\"), Callable):\n        self.on_exit =self.app.tb(\n            mod_name=self.name,\n            name=kwargs.get(\"on_exit\").__name__,\n            version=self.version if hasattr(self, 'version') else \"0.0.0\",\n        )(kwargs.get(\"on_exit\"))\n    self.async_initialized = False\n    if self.todo:\n        try:\n            if inspect.iscoroutinefunction(self.todo):\n                pass\n            else:\n                self.todo()\n            get_logger().info(f\"{self.name} on load suspended\")\n        except Exception as e:\n            get_logger().error(f\"Error loading mod {self.name} {e}\")\n            if self.app.debug:\n                import traceback\n                traceback.print_exc()\n    else:\n        get_logger().info(f\"{self.name} no load require\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.MainTool.__initobj","title":"<code>__initobj()</code>  <code>async</code>","text":"<p>Crutch used for await after spawning</p> Source code in <code>toolboxv2/utils/system/main_tool.py</code> <pre><code>async def __initobj(self):\n    \"\"\"Crutch used for __await__ after spawning\"\"\"\n    assert not self.async_initialized\n    self.async_initialized = True\n    # pass the parameters to __ainit__ that passed to __init__\n    await self.__ainit__(*self.__storedargs[0], **self.__storedargs[1])\n    return self\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.MainTool.get_version","title":"<code>get_version()</code>","text":"<p>\"Returns the version</p> Source code in <code>toolboxv2/utils/system/main_tool.py</code> <pre><code>def get_version(self) -&gt; str:\n    \"\"\"\"Returns the version\"\"\"\n    return self.version\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.MainTool.webInstall","title":"<code>webInstall(user_instance, construct_render)</code>","text":"<p>\"Returns a web installer for the given user instance and construct render template</p> Source code in <code>toolboxv2/utils/system/main_tool.py</code> <pre><code>def webInstall(self, user_instance, construct_render) -&gt; str:\n    \"\"\"\"Returns a web installer for the given user instance and construct render template\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.Result","title":"<code>Result</code>","text":"Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>class Result:\n    _task = None\n    def __init__(self,\n                 error: ToolBoxError,\n                 result: ToolBoxResult,\n                 info: ToolBoxInfo,\n                 origin: Any | None = None,\n                 ):\n        self.error: ToolBoxError = error\n        self.result: ToolBoxResult = result\n        self.info: ToolBoxInfo = info\n        self.origin = origin\n\n    def as_result(self):\n        return self\n\n    def as_dict(self):\n        return {\n            \"error\":self.error.value if isinstance(self.error, Enum) else self.error,\n        \"result\" : {\n            \"data_to\":self.result.data_to.value if isinstance(self.result.data_to, Enum) else self.result.data_to,\n            \"data_info\":self.result.data_info,\n            \"data\":self.result.data,\n            \"data_type\":self.result.data_type\n        } if self.result else None,\n        \"info\" : {\n            \"exec_code\" : self.info.exec_code,  # exec_code umwandel in http resposn codes\n        \"help_text\" : self.info.help_text\n        } if self.info else None,\n        \"origin\" : self.origin\n        }\n\n    def set_origin(self, origin):\n        if self.origin is not None:\n            raise ValueError(\"You cannot Change the origin of a Result!\")\n        self.origin = origin\n        return self\n\n    def set_dir_origin(self, name, extras=\"assets/\"):\n        if self.origin is not None:\n            raise ValueError(\"You cannot Change the origin of a Result!\")\n        self.origin = f\"mods/{name}/{extras}\"\n        return self\n\n    def is_error(self):\n        if _test_is_result(self.result.data):\n            return self.result.data.is_error()\n        if self.error == ToolBoxError.none:\n            return False\n        if self.info.exec_code == 0:\n            return False\n        return self.info.exec_code != 200\n\n    def is_ok(self):\n        return not self.is_error()\n\n    def is_data(self):\n        return self.result.data is not None\n\n    def to_api_result(self):\n        # print(f\" error={self.error}, result= {self.result}, info= {self.info}, origin= {self.origin}\")\n        return ApiResult(\n            error=self.error.value if isinstance(self.error, Enum) else self.error,\n            result=ToolBoxResultBM(\n                data_to=self.result.data_to.value if isinstance(self.result.data_to, Enum) else self.result.data_to,\n                data_info=self.result.data_info,\n                data=self.result.data,\n                data_type=self.result.data_type\n            ) if self.result else None,\n            info=ToolBoxInfoBM(\n                exec_code=self.info.exec_code,  # exec_code umwandel in http resposn codes\n                help_text=self.info.help_text\n            ) if self.info else None,\n            origin=self.origin\n        )\n\n    def task(self, task):\n        self._task = task\n        return self\n\n    @staticmethod\n    def result_from_dict(error: str, result: dict, info: dict, origin: list or None or str):\n        # print(f\" error={self.error}, result= {self.result}, info= {self.info}, origin= {self.origin}\")\n        return ApiResult(\n            error=error if isinstance(error, Enum) else error,\n            result=ToolBoxResultBM(\n                data_to=result.get('data_to') if isinstance(result.get('data_to'), Enum) else result.get('data_to'),\n                data_info=result.get('data_info', '404'),\n                data=result.get('data'),\n                data_type=result.get('data_type', '404'),\n            ) if result else ToolBoxResultBM(\n                data_to=ToolBoxInterfaces.cli.value,\n                data_info='',\n                data='404',\n                data_type='404',\n            ),\n            info=ToolBoxInfoBM(\n                exec_code=info.get('exec_code', 404),\n                help_text=info.get('help_text', '404')\n            ) if info else ToolBoxInfoBM(\n                exec_code=404,\n                help_text='404'\n            ),\n            origin=origin\n        ).as_result()\n\n    @classmethod\n    def stream(cls,\n               stream_generator: Any,  # Renamed from source for clarity\n               content_type: str = \"text/event-stream\",  # Default to SSE\n               headers: dict | None = None,\n               info: str = \"OK\",\n               interface: ToolBoxInterfaces = ToolBoxInterfaces.remote,\n               cleanup_func: Callable[[], None] | Callable[[], T] | Callable[[], AsyncGenerator[T, None]] | None = None):\n        \"\"\"\n        Create a streaming response Result. Handles SSE and other stream types.\n\n        Args:\n            stream_generator: Any stream source (async generator, sync generator, iterable, or single item).\n            content_type: Content-Type header (default: text/event-stream for SSE).\n            headers: Additional HTTP headers for the response.\n            info: Help text for the result.\n            interface: Interface to send data to.\n            cleanup_func: Optional function for cleanup.\n\n        Returns:\n            A Result object configured for streaming.\n        \"\"\"\n        error = ToolBoxError.none\n        info_obj = ToolBoxInfo(exec_code=0, help_text=info)\n\n        final_generator: AsyncGenerator[str, None]\n\n        if content_type == \"text/event-stream\":\n            # For SSE, always use SSEGenerator.create_sse_stream to wrap the source.\n            # SSEGenerator.create_sse_stream handles various types of stream_generator internally.\n            final_generator = SSEGenerator.create_sse_stream(source=stream_generator, cleanup_func=cleanup_func)\n\n            # Standard SSE headers for the HTTP response itself\n            # These will be stored in the Result object. Rust side decides how to use them.\n            standard_sse_headers = {\n                \"Cache-Control\": \"no-cache\",  # SSE specific\n                \"Connection\": \"keep-alive\",  # SSE specific\n                \"X-Accel-Buffering\": \"no\",  # Useful for proxies with SSE\n                # Content-Type is implicitly text/event-stream, will be in streaming_data below\n            }\n            all_response_headers = standard_sse_headers.copy()\n            if headers:\n                all_response_headers.update(headers)\n        else:\n            # For non-SSE streams.\n            # If stream_generator is sync, wrap it to be async.\n            # If already async or single item, it will be handled.\n            # Rust's stream_generator in ToolboxClient seems to handle both sync/async Python generators.\n            # For consistency with how SSEGenerator does it, we can wrap sync ones.\n            if inspect.isgenerator(stream_generator) or \\\n                (not isinstance(stream_generator, str) and hasattr(stream_generator, '__iter__')):\n                final_generator = SSEGenerator.wrap_sync_generator(stream_generator)  # Simple async wrapper\n            elif inspect.isasyncgen(stream_generator):\n                final_generator = stream_generator\n            else:  # Single item or string\n                async def _single_item_gen():\n                    yield stream_generator\n\n                final_generator = _single_item_gen()\n            all_response_headers = headers if headers else {}\n\n        # Prepare streaming data to be stored in the Result object\n        streaming_data = {\n            \"type\": \"stream\",  # Indicator for Rust side\n            \"generator\": final_generator,\n            \"content_type\": content_type,  # Let Rust know the intended content type\n            \"headers\": all_response_headers  # Intended HTTP headers for the overall response\n        }\n\n        result_payload = ToolBoxResult(\n            data_to=interface,\n            data=streaming_data,\n            data_info=\"Streaming response\" if content_type != \"text/event-stream\" else \"SSE Event Stream\",\n            data_type=\"stream\"  # Generic type for Rust to identify it needs to stream from 'generator'\n        )\n\n        return cls(error=error, info=info_obj, result=result_payload)\n\n    @classmethod\n    def sse(cls,\n            stream_generator: Any,\n            info: str = \"OK\",\n            interface: ToolBoxInterfaces = ToolBoxInterfaces.remote,\n            cleanup_func: Callable[[], None] | Callable[[], T] | Callable[[], AsyncGenerator[T, None]] | None = None,\n            # http_headers: Optional[dict] = None # If we want to allow overriding default SSE HTTP headers\n            ):\n        \"\"\"\n        Create an Server-Sent Events (SSE) streaming response Result.\n\n        Args:\n            stream_generator: A source yielding individual data items. This can be an\n                              async generator, sync generator, iterable, or a single item.\n                              Each item will be formatted as an SSE event.\n            info: Optional help text for the Result.\n            interface: Optional ToolBoxInterface to target.\n            cleanup_func: Optional cleanup function to run when the stream ends or is cancelled.\n            #http_headers: Optional dictionary of custom HTTP headers for the SSE response.\n\n        Returns:\n            A Result object configured for SSE streaming.\n        \"\"\"\n        # Result.stream will handle calling SSEGenerator.create_sse_stream\n        # and setting appropriate default headers for SSE when content_type is \"text/event-stream\".\n        return cls.stream(\n            stream_generator=stream_generator,\n            content_type=\"text/event-stream\",\n            # headers=http_headers, # Pass if we add http_headers param\n            info=info,\n            interface=interface,\n            cleanup_func=cleanup_func\n        )\n\n    @classmethod\n    def default(cls, interface=ToolBoxInterfaces.native):\n        error = ToolBoxError.none\n        info = ToolBoxInfo(exec_code=-1, help_text=\"\")\n        result = ToolBoxResult(data_to=interface)\n        return cls(error=error, info=info, result=result)\n\n    @classmethod\n    def json(cls, data, info=\"OK\", interface=ToolBoxInterfaces.remote, exec_code=0, status_code=None):\n        \"\"\"Create a JSON response Result.\"\"\"\n        error = ToolBoxError.none\n        info_obj = ToolBoxInfo(exec_code=status_code or exec_code, help_text=info)\n\n        result = ToolBoxResult(\n            data_to=interface,\n            data=data,\n            data_info=\"JSON response\",\n            data_type=\"json\"\n        )\n\n        return cls(error=error, info=info_obj, result=result)\n\n    @classmethod\n    def text(cls, text_data, content_type=\"text/plain\",exec_code=None,status=200, info=\"OK\", interface=ToolBoxInterfaces.remote, headers=None):\n        \"\"\"Create a text response Result with specific content type.\"\"\"\n        if headers is not None:\n            return cls.html(text_data, status= exec_code or status, info=info, headers=headers)\n        error = ToolBoxError.none\n        info_obj = ToolBoxInfo(exec_code=exec_code or status, help_text=info)\n\n        result = ToolBoxResult(\n            data_to=interface,\n            data=text_data,\n            data_info=\"Text response\",\n            data_type=content_type\n        )\n\n        return cls(error=error, info=info_obj, result=result)\n\n    @classmethod\n    def binary(cls, data, content_type=\"application/octet-stream\", download_name=None, info=\"OK\",\n               interface=ToolBoxInterfaces.remote):\n        \"\"\"Create a binary data response Result.\"\"\"\n        error = ToolBoxError.none\n        info_obj = ToolBoxInfo(exec_code=0, help_text=info)\n\n        # Create a dictionary with binary data and metadata\n        binary_data = {\n            \"data\": data,\n            \"content_type\": content_type,\n            \"filename\": download_name\n        }\n\n        result = ToolBoxResult(\n            data_to=interface,\n            data=binary_data,\n            data_info=f\"Binary response: {download_name}\" if download_name else \"Binary response\",\n            data_type=\"binary\"\n        )\n\n        return cls(error=error, info=info_obj, result=result)\n\n    @classmethod\n    def file(cls, data, filename, content_type=None, info=\"OK\", interface=ToolBoxInterfaces.remote):\n        \"\"\"Create a file download response Result.\n\n        Args:\n            data: File data as bytes or base64 string\n            filename: Name of the file for download\n            content_type: MIME type of the file (auto-detected if None)\n            info: Response info text\n            interface: Target interface\n\n        Returns:\n            Result object configured for file download\n        \"\"\"\n        import base64\n        import mimetypes\n\n        error = ToolBoxError.none\n        info_obj = ToolBoxInfo(exec_code=200, help_text=info)\n\n        # Auto-detect content type if not provided\n        if content_type is None:\n            content_type, _ = mimetypes.guess_type(filename)\n            if content_type is None:\n                content_type = \"application/octet-stream\"\n\n        # Ensure data is base64 encoded string (as expected by Rust server)\n        if isinstance(data, bytes):\n            base64_data = base64.b64encode(data).decode('utf-8')\n        elif isinstance(data, str):\n            # Assume it's already base64 encoded\n            base64_data = data\n        else:\n            raise ValueError(\"File data must be bytes or base64 string\")\n\n        result = ToolBoxResult(\n            data_to=interface,\n            data=base64_data,  # Rust expects base64 string for \"file\" type\n            data_info=f\"File download: {filename}\",\n            data_type=\"file\"\n        )\n\n        return cls(error=error, info=info_obj, result=result)\n\n    @classmethod\n    def redirect(cls, url, status_code=302, info=\"Redirect\", interface=ToolBoxInterfaces.remote):\n        \"\"\"Create a redirect response.\"\"\"\n        error = ToolBoxError.none\n        info_obj = ToolBoxInfo(exec_code=status_code, help_text=info)\n\n        result = ToolBoxResult(\n            data_to=interface,\n            data=url,\n            data_info=\"Redirect response\",\n            data_type=\"redirect\"\n        )\n\n        return cls(error=error, info=info_obj, result=result)\n\n    @classmethod\n    def ok(cls, data=None, data_info=\"\", info=\"OK\", interface=ToolBoxInterfaces.native):\n        error = ToolBoxError.none\n        info = ToolBoxInfo(exec_code=0, help_text=info)\n        result = ToolBoxResult(data_to=interface, data=data, data_info=data_info, data_type=type(data).__name__)\n        return cls(error=error, info=info, result=result)\n\n    @classmethod\n    def html(cls, data=None, data_info=\"\", info=\"OK\", interface=ToolBoxInterfaces.remote, data_type=\"html\",status=200, headers=None, row=False):\n        error = ToolBoxError.none\n        info = ToolBoxInfo(exec_code=status, help_text=info)\n        from ...utils.system.getting_and_closing_app import get_app\n\n        if not row and not '\"&lt;div class=\"main-content\"\"' in data:\n            data = f'&lt;div class=\"main-content frosted-glass\"&gt;{data}&lt;div&gt;'\n        if not row and not get_app().web_context() in data:\n            data = get_app().web_context() + data\n\n        if isinstance(headers, dict):\n            result = ToolBoxResult(data_to=interface, data={'html':data,'headers':headers}, data_info=data_info,\n                                   data_type=\"special_html\")\n        else:\n            result = ToolBoxResult(data_to=interface, data=data, data_info=data_info,\n                                   data_type=data_type if data_type is not None else type(data).__name__)\n        return cls(error=error, info=info, result=result)\n\n    @classmethod\n    def future(cls, data=None, data_info=\"\", info=\"OK\", interface=ToolBoxInterfaces.future):\n        error = ToolBoxError.none\n        info = ToolBoxInfo(exec_code=0, help_text=info)\n        result = ToolBoxResult(data_to=interface, data=data, data_info=data_info, data_type=\"future\")\n        return cls(error=error, info=info, result=result)\n\n    @classmethod\n    def custom_error(cls, data=None, data_info=\"\", info=\"\", exec_code=-1, interface=ToolBoxInterfaces.native):\n        error = ToolBoxError.custom_error\n        info = ToolBoxInfo(exec_code=exec_code, help_text=info)\n        result = ToolBoxResult(data_to=interface, data=data, data_info=data_info, data_type=type(data).__name__)\n        return cls(error=error, info=info, result=result)\n\n    @classmethod\n    def error(cls, data=None, data_info=\"\", info=\"\", exec_code=450, interface=ToolBoxInterfaces.remote):\n        error = ToolBoxError.custom_error\n        info = ToolBoxInfo(exec_code=exec_code, help_text=info)\n        result = ToolBoxResult(data_to=interface, data=data, data_info=data_info, data_type=type(data).__name__)\n        return cls(error=error, info=info, result=result)\n\n    @classmethod\n    def default_user_error(cls, info=\"\", exec_code=-3, interface=ToolBoxInterfaces.native, data=None):\n        error = ToolBoxError.input_error\n        info = ToolBoxInfo(exec_code, info)\n        result = ToolBoxResult(data_to=interface, data=data, data_type=type(data).__name__)\n        return cls(error=error, info=info, result=result)\n\n    @classmethod\n    def default_internal_error(cls, info=\"\", exec_code=-2, interface=ToolBoxInterfaces.native, data=None):\n        error = ToolBoxError.internal_error\n        info = ToolBoxInfo(exec_code, info)\n        result = ToolBoxResult(data_to=interface, data=data, data_type=type(data).__name__)\n        return cls(error=error, info=info, result=result)\n\n    def print(self, show=True, show_data=True, prifix=\"\"):\n        data = '\\n' + f\"{((prifix + f'Data_{self.result.data_type}: ' + str(self.result.data) if self.result.data is not None else 'NO Data') if not isinstance(self.result.data, Result) else self.result.data.print(show=False, show_data=show_data, prifix=prifix + '-')) if show_data else 'Data: private'}\"\n        origin = '\\n' + f\"{prifix + 'Origin: ' + str(self.origin) if self.origin is not None else 'NO Origin'}\"\n        text = (f\"Function Exec code: {self.info.exec_code}\"\n                f\"\\n{prifix}Info's:\"\n                f\" {self.info.help_text} {'&lt;|&gt; ' + str(self.result.data_info) if self.result.data_info is not None else ''}\"\n                f\"{origin}{(data[:100]+'...') if not data.endswith('NO Data') else ''}\\n\")\n        if not show:\n            return text\n        print(\"\\n======== Result ========\\n\" + text + \"------- EndOfD -------\")\n        return self\n\n    def log(self, show_data=True, prifix=\"\"):\n        from toolboxv2 import get_logger\n        get_logger().debug(self.print(show=False, show_data=show_data, prifix=prifix).replace(\"\\n\", \" - \"))\n        return self\n\n    def __str__(self):\n        return self.print(show=False, show_data=True)\n\n    def get(self, key=None, default=None):\n        data = self.result.data\n        if isinstance(data, Result):\n            return data.get(key=key, default=default)\n        if key is not None and isinstance(data, dict):\n            return data.get(key, default)\n        return data if data is not None else default\n\n    async def aget(self, key=None, default=None):\n        if asyncio.isfuture(self.result.data) or asyncio.iscoroutine(self.result.data) or (\n            isinstance(self.result.data_to, Enum) and self.result.data_to.name == ToolBoxInterfaces.future.name):\n            data = await self.result.data\n        else:\n            data = self.get(key=None, default=None)\n        if isinstance(data, Result):\n            return data.get(key=key, default=default)\n        if key is not None and isinstance(data, dict):\n            return data.get(key, default)\n        return data if data is not None else default\n\n    def lazy_return(self, _=0, data=None, **kwargs):\n        flags = ['raise', 'logg', 'user', 'intern']\n        flag = flags[_] if isinstance(_, int) else _\n        if self.info.exec_code == 0:\n            return self if data is None else data if _test_is_result(data) else self.ok(data=data, **kwargs)\n        if flag == 'raise':\n            raise ValueError(self.print(show=False))\n        if flag == 'logg':\n            from .. import get_logger\n            get_logger().error(self.print(show=False))\n\n        if flag == 'user':\n            return self if data is None else data if _test_is_result(data) else self.default_user_error(data=data,\n                                                                                                        **kwargs)\n        if flag == 'intern':\n            return self if data is None else data if _test_is_result(data) else self.default_internal_error(data=data,\n                                                                                                            **kwargs)\n\n        return self if data is None else data if _test_is_result(data) else self.custom_error(data=data, **kwargs)\n\n    @property\n    def bg_task(self):\n        return self._task\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.Result.binary","title":"<code>binary(data, content_type='application/octet-stream', download_name=None, info='OK', interface=ToolBoxInterfaces.remote)</code>  <code>classmethod</code>","text":"<p>Create a binary data response Result.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@classmethod\ndef binary(cls, data, content_type=\"application/octet-stream\", download_name=None, info=\"OK\",\n           interface=ToolBoxInterfaces.remote):\n    \"\"\"Create a binary data response Result.\"\"\"\n    error = ToolBoxError.none\n    info_obj = ToolBoxInfo(exec_code=0, help_text=info)\n\n    # Create a dictionary with binary data and metadata\n    binary_data = {\n        \"data\": data,\n        \"content_type\": content_type,\n        \"filename\": download_name\n    }\n\n    result = ToolBoxResult(\n        data_to=interface,\n        data=binary_data,\n        data_info=f\"Binary response: {download_name}\" if download_name else \"Binary response\",\n        data_type=\"binary\"\n    )\n\n    return cls(error=error, info=info_obj, result=result)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.Result.file","title":"<code>file(data, filename, content_type=None, info='OK', interface=ToolBoxInterfaces.remote)</code>  <code>classmethod</code>","text":"<p>Create a file download response Result.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <p>File data as bytes or base64 string</p> required <code>filename</code> <p>Name of the file for download</p> required <code>content_type</code> <p>MIME type of the file (auto-detected if None)</p> <code>None</code> <code>info</code> <p>Response info text</p> <code>'OK'</code> <code>interface</code> <p>Target interface</p> <code>remote</code> <p>Returns:</p> Type Description <p>Result object configured for file download</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@classmethod\ndef file(cls, data, filename, content_type=None, info=\"OK\", interface=ToolBoxInterfaces.remote):\n    \"\"\"Create a file download response Result.\n\n    Args:\n        data: File data as bytes or base64 string\n        filename: Name of the file for download\n        content_type: MIME type of the file (auto-detected if None)\n        info: Response info text\n        interface: Target interface\n\n    Returns:\n        Result object configured for file download\n    \"\"\"\n    import base64\n    import mimetypes\n\n    error = ToolBoxError.none\n    info_obj = ToolBoxInfo(exec_code=200, help_text=info)\n\n    # Auto-detect content type if not provided\n    if content_type is None:\n        content_type, _ = mimetypes.guess_type(filename)\n        if content_type is None:\n            content_type = \"application/octet-stream\"\n\n    # Ensure data is base64 encoded string (as expected by Rust server)\n    if isinstance(data, bytes):\n        base64_data = base64.b64encode(data).decode('utf-8')\n    elif isinstance(data, str):\n        # Assume it's already base64 encoded\n        base64_data = data\n    else:\n        raise ValueError(\"File data must be bytes or base64 string\")\n\n    result = ToolBoxResult(\n        data_to=interface,\n        data=base64_data,  # Rust expects base64 string for \"file\" type\n        data_info=f\"File download: {filename}\",\n        data_type=\"file\"\n    )\n\n    return cls(error=error, info=info_obj, result=result)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.Result.json","title":"<code>json(data, info='OK', interface=ToolBoxInterfaces.remote, exec_code=0, status_code=None)</code>  <code>classmethod</code>","text":"<p>Create a JSON response Result.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@classmethod\ndef json(cls, data, info=\"OK\", interface=ToolBoxInterfaces.remote, exec_code=0, status_code=None):\n    \"\"\"Create a JSON response Result.\"\"\"\n    error = ToolBoxError.none\n    info_obj = ToolBoxInfo(exec_code=status_code or exec_code, help_text=info)\n\n    result = ToolBoxResult(\n        data_to=interface,\n        data=data,\n        data_info=\"JSON response\",\n        data_type=\"json\"\n    )\n\n    return cls(error=error, info=info_obj, result=result)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.Result.redirect","title":"<code>redirect(url, status_code=302, info='Redirect', interface=ToolBoxInterfaces.remote)</code>  <code>classmethod</code>","text":"<p>Create a redirect response.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@classmethod\ndef redirect(cls, url, status_code=302, info=\"Redirect\", interface=ToolBoxInterfaces.remote):\n    \"\"\"Create a redirect response.\"\"\"\n    error = ToolBoxError.none\n    info_obj = ToolBoxInfo(exec_code=status_code, help_text=info)\n\n    result = ToolBoxResult(\n        data_to=interface,\n        data=url,\n        data_info=\"Redirect response\",\n        data_type=\"redirect\"\n    )\n\n    return cls(error=error, info=info_obj, result=result)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.Result.sse","title":"<code>sse(stream_generator, info='OK', interface=ToolBoxInterfaces.remote, cleanup_func=None)</code>  <code>classmethod</code>","text":"<p>Create an Server-Sent Events (SSE) streaming response Result.</p> <p>Parameters:</p> Name Type Description Default <code>stream_generator</code> <code>Any</code> <p>A source yielding individual data items. This can be an               async generator, sync generator, iterable, or a single item.               Each item will be formatted as an SSE event.</p> required <code>info</code> <code>str</code> <p>Optional help text for the Result.</p> <code>'OK'</code> <code>interface</code> <code>ToolBoxInterfaces</code> <p>Optional ToolBoxInterface to target.</p> <code>remote</code> <code>cleanup_func</code> <code>Callable[[], None] | Callable[[], T] | Callable[[], AsyncGenerator[T, None]] | None</code> <p>Optional cleanup function to run when the stream ends or is cancelled.</p> <code>None</code> <code>#http_headers</code> <p>Optional dictionary of custom HTTP headers for the SSE response.</p> required <p>Returns:</p> Type Description <p>A Result object configured for SSE streaming.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@classmethod\ndef sse(cls,\n        stream_generator: Any,\n        info: str = \"OK\",\n        interface: ToolBoxInterfaces = ToolBoxInterfaces.remote,\n        cleanup_func: Callable[[], None] | Callable[[], T] | Callable[[], AsyncGenerator[T, None]] | None = None,\n        # http_headers: Optional[dict] = None # If we want to allow overriding default SSE HTTP headers\n        ):\n    \"\"\"\n    Create an Server-Sent Events (SSE) streaming response Result.\n\n    Args:\n        stream_generator: A source yielding individual data items. This can be an\n                          async generator, sync generator, iterable, or a single item.\n                          Each item will be formatted as an SSE event.\n        info: Optional help text for the Result.\n        interface: Optional ToolBoxInterface to target.\n        cleanup_func: Optional cleanup function to run when the stream ends or is cancelled.\n        #http_headers: Optional dictionary of custom HTTP headers for the SSE response.\n\n    Returns:\n        A Result object configured for SSE streaming.\n    \"\"\"\n    # Result.stream will handle calling SSEGenerator.create_sse_stream\n    # and setting appropriate default headers for SSE when content_type is \"text/event-stream\".\n    return cls.stream(\n        stream_generator=stream_generator,\n        content_type=\"text/event-stream\",\n        # headers=http_headers, # Pass if we add http_headers param\n        info=info,\n        interface=interface,\n        cleanup_func=cleanup_func\n    )\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.Result.stream","title":"<code>stream(stream_generator, content_type='text/event-stream', headers=None, info='OK', interface=ToolBoxInterfaces.remote, cleanup_func=None)</code>  <code>classmethod</code>","text":"<p>Create a streaming response Result. Handles SSE and other stream types.</p> <p>Parameters:</p> Name Type Description Default <code>stream_generator</code> <code>Any</code> <p>Any stream source (async generator, sync generator, iterable, or single item).</p> required <code>content_type</code> <code>str</code> <p>Content-Type header (default: text/event-stream for SSE).</p> <code>'text/event-stream'</code> <code>headers</code> <code>dict | None</code> <p>Additional HTTP headers for the response.</p> <code>None</code> <code>info</code> <code>str</code> <p>Help text for the result.</p> <code>'OK'</code> <code>interface</code> <code>ToolBoxInterfaces</code> <p>Interface to send data to.</p> <code>remote</code> <code>cleanup_func</code> <code>Callable[[], None] | Callable[[], T] | Callable[[], AsyncGenerator[T, None]] | None</code> <p>Optional function for cleanup.</p> <code>None</code> <p>Returns:</p> Type Description <p>A Result object configured for streaming.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@classmethod\ndef stream(cls,\n           stream_generator: Any,  # Renamed from source for clarity\n           content_type: str = \"text/event-stream\",  # Default to SSE\n           headers: dict | None = None,\n           info: str = \"OK\",\n           interface: ToolBoxInterfaces = ToolBoxInterfaces.remote,\n           cleanup_func: Callable[[], None] | Callable[[], T] | Callable[[], AsyncGenerator[T, None]] | None = None):\n    \"\"\"\n    Create a streaming response Result. Handles SSE and other stream types.\n\n    Args:\n        stream_generator: Any stream source (async generator, sync generator, iterable, or single item).\n        content_type: Content-Type header (default: text/event-stream for SSE).\n        headers: Additional HTTP headers for the response.\n        info: Help text for the result.\n        interface: Interface to send data to.\n        cleanup_func: Optional function for cleanup.\n\n    Returns:\n        A Result object configured for streaming.\n    \"\"\"\n    error = ToolBoxError.none\n    info_obj = ToolBoxInfo(exec_code=0, help_text=info)\n\n    final_generator: AsyncGenerator[str, None]\n\n    if content_type == \"text/event-stream\":\n        # For SSE, always use SSEGenerator.create_sse_stream to wrap the source.\n        # SSEGenerator.create_sse_stream handles various types of stream_generator internally.\n        final_generator = SSEGenerator.create_sse_stream(source=stream_generator, cleanup_func=cleanup_func)\n\n        # Standard SSE headers for the HTTP response itself\n        # These will be stored in the Result object. Rust side decides how to use them.\n        standard_sse_headers = {\n            \"Cache-Control\": \"no-cache\",  # SSE specific\n            \"Connection\": \"keep-alive\",  # SSE specific\n            \"X-Accel-Buffering\": \"no\",  # Useful for proxies with SSE\n            # Content-Type is implicitly text/event-stream, will be in streaming_data below\n        }\n        all_response_headers = standard_sse_headers.copy()\n        if headers:\n            all_response_headers.update(headers)\n    else:\n        # For non-SSE streams.\n        # If stream_generator is sync, wrap it to be async.\n        # If already async or single item, it will be handled.\n        # Rust's stream_generator in ToolboxClient seems to handle both sync/async Python generators.\n        # For consistency with how SSEGenerator does it, we can wrap sync ones.\n        if inspect.isgenerator(stream_generator) or \\\n            (not isinstance(stream_generator, str) and hasattr(stream_generator, '__iter__')):\n            final_generator = SSEGenerator.wrap_sync_generator(stream_generator)  # Simple async wrapper\n        elif inspect.isasyncgen(stream_generator):\n            final_generator = stream_generator\n        else:  # Single item or string\n            async def _single_item_gen():\n                yield stream_generator\n\n            final_generator = _single_item_gen()\n        all_response_headers = headers if headers else {}\n\n    # Prepare streaming data to be stored in the Result object\n    streaming_data = {\n        \"type\": \"stream\",  # Indicator for Rust side\n        \"generator\": final_generator,\n        \"content_type\": content_type,  # Let Rust know the intended content type\n        \"headers\": all_response_headers  # Intended HTTP headers for the overall response\n    }\n\n    result_payload = ToolBoxResult(\n        data_to=interface,\n        data=streaming_data,\n        data_info=\"Streaming response\" if content_type != \"text/event-stream\" else \"SSE Event Stream\",\n        data_type=\"stream\"  # Generic type for Rust to identify it needs to stream from 'generator'\n    )\n\n    return cls(error=error, info=info_obj, result=result_payload)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.Result.text","title":"<code>text(text_data, content_type='text/plain', exec_code=None, status=200, info='OK', interface=ToolBoxInterfaces.remote, headers=None)</code>  <code>classmethod</code>","text":"<p>Create a text response Result with specific content type.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@classmethod\ndef text(cls, text_data, content_type=\"text/plain\",exec_code=None,status=200, info=\"OK\", interface=ToolBoxInterfaces.remote, headers=None):\n    \"\"\"Create a text response Result with specific content type.\"\"\"\n    if headers is not None:\n        return cls.html(text_data, status= exec_code or status, info=info, headers=headers)\n    error = ToolBoxError.none\n    info_obj = ToolBoxInfo(exec_code=exec_code or status, help_text=info)\n\n    result = ToolBoxResult(\n        data_to=interface,\n        data=text_data,\n        data_info=\"Text response\",\n        data_type=content_type\n    )\n\n    return cls(error=error, info=info_obj, result=result)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.Singleton","title":"<code>Singleton</code>","text":"<p>Singleton metaclass for ensuring only one instance of a class.</p> Source code in <code>toolboxv2/utils/singelton_class.py</code> <pre><code>class Singleton(type):\n    \"\"\"\n    Singleton metaclass for ensuring only one instance of a class.\n    \"\"\"\n\n    _instances = {}\n    _kwargs = {}\n    _args = {}\n\n    def __call__(cls, *args, **kwargs):\n        if cls not in cls._instances:\n            cls._instances[cls] = super().__call__(*args, **kwargs)\n            cls._args[cls] = args\n            cls._kwargs[cls] = kwargs\n        return cls._instances[cls]\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.Spinner","title":"<code>Spinner</code>","text":"<p>Enhanced Spinner with tqdm-like line rendering.</p> Source code in <code>toolboxv2/utils/extras/Style.py</code> <pre><code>class Spinner:\n    \"\"\"\n    Enhanced Spinner with tqdm-like line rendering.\n    \"\"\"\n    SYMBOL_SETS = {\n        \"c\": [\"\u25d0\", \"\u25d3\", \"\u25d1\", \"\u25d2\"],\n        \"b\": [\"\u2581\", \"\u2583\", \"\u2584\", \"\u2585\", \"\u2586\", \"\u2587\", \"\u2588\", \"\u2587\", \"\u2586\", \"\u2585\", \"\u2584\", \"\u2583\"],\n        \"d\": [\"\u28fe\", \"\u28fd\", \"\u28fb\", \"\u28bf\", \"\u287f\", \"\u28df\", \"\u28ef\", \"\u28f7\"],\n        \"w\": [\"\ud83c\udf0d\", \"\ud83c\udf0e\", \"\ud83c\udf0f\"],\n        \"s\": [\"\ud83c\udf00   \", \" \ud83c\udf00  \", \"  \ud83c\udf00 \", \"   \ud83c\udf00\", \"  \ud83c\udf00 \", \" \ud83c\udf00  \"],\n        \"+\": [\"+\", \"x\"],\n        \"t\": [\"\u2736\", \"\u2738\", \"\u2739\", \"\u273a\", \"\u2739\", \"\u2737\"]\n    }\n\n    def __init__(\n        self,\n        message: str = \"Loading...\",\n        delay: float = 0.1,\n        symbols=None,\n        count_down: bool = False,\n        time_in_s: float = 0\n    ):\n        \"\"\"Initialize spinner with flexible configuration.\"\"\"\n        # Resolve symbol set.\n        if isinstance(symbols, str):\n            symbols = self.SYMBOL_SETS.get(symbols, None)\n\n        # Default symbols if not provided.\n        if symbols is None:\n            symbols = [\"\u280b\", \"\u2819\", \"\u2839\", \"\u2838\", \"\u283c\", \"\u2834\", \"\u2826\", \"\u2827\", \"\u2807\", \"\u280f\"]\n\n        # Test mode symbol set.\n        if 'unittest' in sys.argv[0]:\n            symbols = ['#', '=', '-']\n\n        self.spinner = itertools.cycle(symbols)\n        self.delay = delay\n        self.message = message\n        self.running = False\n        self.spinner_thread = None\n        self.max_t = time_in_s\n        self.contd = count_down\n\n        # Rendering management.\n        self._is_primary = False\n        self._start_time = 0\n\n        # Central manager.\n        self.manager = SpinnerManager()\n\n    def _generate_render_line(self):\n        \"\"\"Generate the primary render line.\"\"\"\n        current_time = time.time()\n        if self.contd:\n            remaining = max(0, self.max_t - (current_time - self._start_time))\n            time_display = f\"{remaining:.2f}\"\n        else:\n            time_display = f\"{current_time - self._start_time:.2f}\"\n\n        symbol = next(self.spinner)\n        return f\"{symbol} {self.message} | {time_display}\"\n\n    def _generate_secondary_info(self):\n        \"\"\"Generate secondary spinner info for additional spinners.\"\"\"\n        return f\"{self.message}\"\n\n    def __enter__(self):\n        \"\"\"Start the spinner.\"\"\"\n        self.running = True\n        self._start_time = time.time()\n        self.manager.register_spinner(self)\n        return self\n\n    def __exit__(self, exc_type, exc_value, exc_traceback):\n        \"\"\"Stop the spinner.\"\"\"\n        self.running = False\n        self.manager.unregister_spinner(self)\n        # Clear the spinner's line if it was the primary spinner.\n        if self._is_primary:\n            sys.stdout.write(\"\\r\\033[K\")\n            sys.stdout.flush()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.Spinner.__enter__","title":"<code>__enter__()</code>","text":"<p>Start the spinner.</p> Source code in <code>toolboxv2/utils/extras/Style.py</code> <pre><code>def __enter__(self):\n    \"\"\"Start the spinner.\"\"\"\n    self.running = True\n    self._start_time = time.time()\n    self.manager.register_spinner(self)\n    return self\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.Spinner.__exit__","title":"<code>__exit__(exc_type, exc_value, exc_traceback)</code>","text":"<p>Stop the spinner.</p> Source code in <code>toolboxv2/utils/extras/Style.py</code> <pre><code>def __exit__(self, exc_type, exc_value, exc_traceback):\n    \"\"\"Stop the spinner.\"\"\"\n    self.running = False\n    self.manager.unregister_spinner(self)\n    # Clear the spinner's line if it was the primary spinner.\n    if self._is_primary:\n        sys.stdout.write(\"\\r\\033[K\")\n        sys.stdout.flush()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.Spinner.__init__","title":"<code>__init__(message='Loading...', delay=0.1, symbols=None, count_down=False, time_in_s=0)</code>","text":"<p>Initialize spinner with flexible configuration.</p> Source code in <code>toolboxv2/utils/extras/Style.py</code> <pre><code>def __init__(\n    self,\n    message: str = \"Loading...\",\n    delay: float = 0.1,\n    symbols=None,\n    count_down: bool = False,\n    time_in_s: float = 0\n):\n    \"\"\"Initialize spinner with flexible configuration.\"\"\"\n    # Resolve symbol set.\n    if isinstance(symbols, str):\n        symbols = self.SYMBOL_SETS.get(symbols, None)\n\n    # Default symbols if not provided.\n    if symbols is None:\n        symbols = [\"\u280b\", \"\u2819\", \"\u2839\", \"\u2838\", \"\u283c\", \"\u2834\", \"\u2826\", \"\u2827\", \"\u2807\", \"\u280f\"]\n\n    # Test mode symbol set.\n    if 'unittest' in sys.argv[0]:\n        symbols = ['#', '=', '-']\n\n    self.spinner = itertools.cycle(symbols)\n    self.delay = delay\n    self.message = message\n    self.running = False\n    self.spinner_thread = None\n    self.max_t = time_in_s\n    self.contd = count_down\n\n    # Rendering management.\n    self._is_primary = False\n    self._start_time = 0\n\n    # Central manager.\n    self.manager = SpinnerManager()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.TBEF","title":"<code>TBEF</code>","text":"<p>Automatic generated by ToolBox v = 0.1.22</p>"},{"location":"toolboxv2/#toolboxv2.utils.daemon","title":"<code>daemon</code>","text":""},{"location":"toolboxv2/#toolboxv2.utils.daemon.DaemonUtil","title":"<code>DaemonUtil</code>","text":"Source code in <code>toolboxv2/utils/daemon/daemon_util.py</code> <pre><code>class DaemonUtil:\n\n    def __init__(self, *args, **kwargs):\n        \"\"\"\n        Standard constructor used for arguments pass\n        Do not override. Use __ainit__ instead\n        \"\"\"\n        self.server = None\n        self.alive = False\n        self.__storedargs = args, kwargs\n        self.async_initialized = False\n\n    async def __initobj(self):\n        \"\"\"Crutch used for __await__ after spawning\"\"\"\n        assert not self.async_initialized\n        self.async_initialized = True\n        # pass the parameters to __ainit__ that passed to __init__\n        await self.__ainit__(*self.__storedargs[0], **self.__storedargs[1])\n        return self\n\n    def __await__(self):\n        return self.__initobj().__await__()\n\n    async def __ainit__(self, class_instance: Any, host='0.0.0.0', port=6587, t=False,\n                        app: (App or AppType) | None = None,\n                        peer=False, name='daemonApp-server', on_register=None, on_client_exit=None, on_server_exit=None,\n                        unix_socket=False, test_override=False):\n        from toolboxv2.mods.SocketManager import SocketType\n        self.class_instance = class_instance\n        self.server = None\n        self.port = port\n        self.host = host\n        self.alive = False\n        self.test_override = test_override\n        self._name = name\n        if on_register is None:\n            def on_register(*args):\n                return None\n        self._on_register = on_register\n        if on_client_exit is None:\n            def on_client_exit(*args):\n                return None\n        self.on_client_exit = on_client_exit\n        if on_server_exit is None:\n            def on_server_exit():\n                return None\n        self.on_server_exit = on_server_exit\n        self.unix_socket = unix_socket\n        self.online = None\n        connection_type = SocketType.server\n        if peer:\n            connection_type = SocketType.peer\n\n        await self.start_server(connection_type)\n        app = app if app is not None else get_app(from_=f\"DaemonUtil.{self._name}\")\n        self.online = await asyncio.to_thread(self.connect, app)\n        if t:\n            await self.online\n\n    async def start_server(self, connection_type=None):\n        \"\"\"Start the server using app and the socket manager\"\"\"\n        from toolboxv2.mods.SocketManager import SocketType\n        if connection_type is None:\n            connection_type = SocketType.server\n        app = get_app(from_=\"Starting.Daemon\")\n        print(app.mod_online(\"SocketManager\"), \"SocketManager\")\n        if not app.mod_online(\"SocketManager\"):\n            await app.load_mod(\"SocketManager\")\n        server_result = await app.a_run_any(SOCKETMANAGER.CREATE_SOCKET,\n                                            get_results=True,\n                                            name=self._name,\n                                            host=self.host,\n                                            port=self.port,\n                                            type_id=connection_type,\n                                            max_connections=-1,\n                                            return_full_object=True,\n                                            test_override=self.test_override,\n                                            unix_file=self.unix_socket)\n        if server_result.is_error():\n            raise Exception(f\"Server error: {server_result.print(False)}\")\n        if not server_result.is_data():\n            raise Exception(f\"Server error: {server_result.print(False)}\")\n        self.alive = True\n        self.server = server_result\n        # 'socket': socket,\n        # 'receiver_socket': r_socket,\n        # 'host': host,\n        # 'port': port,\n        # 'p2p-port': endpoint_port,\n        # 'sender': send,\n        # 'receiver_queue': receiver_queue,\n        # 'connection_error': connection_error,\n        # 'receiver_thread': s_thread,\n        # 'keepalive_thread': keep_alive_thread,\n        # 'running_dict': running_dict,\n        # 'client_to_receiver_thread': to_receive,\n        # 'client_receiver_threads': threeds,\n\n    async def send(self, data: dict or bytes or str, identifier: tuple[str, int] or str = \"main\"):\n        result = await self.server.aget()\n        sender = result.get('sender')\n        await sender(data, identifier)\n        return \"Data Transmitted\"\n\n    @staticmethod\n    async def runner_co(fuction, *args, **kwargs):\n        if asyncio.iscoroutinefunction(fuction):\n            return await fuction(*args, **kwargs)\n        return fuction(*args, **kwargs)\n\n    async def connect(self, app):\n        result = await self.server.aget()\n        if not isinstance(result, dict) or result.get('connection_error') != 0:\n            raise Exception(f\"Server error: {result}\")\n        self.server = Result.ok(result)\n        receiver_queue: queue.Queue = self.server.get('receiver_queue')\n        client_to_receiver_thread = self.server.get('client_to_receiver_thread')\n        running_dict = self.server.get('running_dict')\n        sender = self.server.get('sender')\n        known_clients = {}\n        valid_clients = {}\n        app.print(f\"Starting Demon {self._name}\")\n\n        while self.alive:\n\n            if not receiver_queue.empty():\n                data = receiver_queue.get()\n                if not data:\n                    continue\n                if 'identifier' not in data:\n                    continue\n\n                identifier = data.get('identifier', 'unknown')\n                try:\n                    if identifier == \"new_con\":\n                        client, address = data.get('data')\n                        get_logger().info(f\"New connection: {address}\")\n                        known_clients[str(address)] = client\n                        await client_to_receiver_thread(client, str(address))\n\n                        await self.runner_co(self._on_register, identifier, address)\n                        identifier = str(address)\n                        # await sender({'ok': 0}, identifier)\n\n                    print(\"Receiver queue\", identifier, identifier in known_clients, identifier in valid_clients)\n                    # validation\n                    if identifier in known_clients:\n                        get_logger().info(identifier)\n                        if identifier.startswith(\"('127.0.0.1'\"):\n                            valid_clients[identifier] = known_clients[identifier]\n                            await self.runner_co(self._on_register, identifier, data)\n                        elif data.get(\"claim\", False):\n                            do = app.run_any((\"CloudM.UserInstances\", \"validate_ws_id\"),\n                                             ws_id=data.get(\"claim\"))[0]\n                            get_logger().info(do)\n                            if do:\n                                valid_clients[identifier] = known_clients[identifier]\n                                await self.runner_co(self._on_register, identifier, data)\n                        elif data.get(\"key\", False) == os.getenv(\"TB_R_KEY\"):\n                            valid_clients[identifier] = known_clients[identifier]\n                            await self.runner_co(self._on_register, identifier, data)\n                        else:\n                            get_logger().warning(f\"Validating Failed: {identifier}\")\n                            # sender({'Validating Failed': -1}, eval(identifier))\n                        get_logger().info(f\"Validating New: {identifier}\")\n                        del known_clients[identifier]\n\n                    elif identifier in valid_clients:\n                        get_logger().info(f\"New valid Request: {identifier}\")\n                        name = data.get('name')\n                        args = data.get('args')\n                        kwargs = data.get('kwargs')\n\n                        get_logger().info(f\"Request data: {name=}{args=}{kwargs=}{identifier=}\")\n\n                        if name == 'exit_main':\n                            self.alive = False\n                            break\n\n                        if name == 'show_console':\n                            show_console(True)\n                            await sender({'ok': 0}, identifier)\n                            continue\n\n                        if name == 'hide_console':\n                            show_console(False)\n                            await sender({'ok': 0}, identifier)\n                            continue\n\n                        if name == 'rrun_flow':\n                            show_console(True)\n                            runnner = self.class_instance.run_flow\n                            threading.Thread(target=runnner, args=args, kwargs=kwargs, daemon=True).start()\n                            await sender({'ok': 0}, identifier)\n                            show_console(False)\n                            continue\n\n                        async def _helper_runner():\n                            try:\n                                attr_f = getattr(self.class_instance, name)\n\n                                if asyncio.iscoroutinefunction(attr_f):\n                                    res = await attr_f(*args, **kwargs)\n                                else:\n                                    res = attr_f(*args, **kwargs)\n\n                                if res is None:\n                                    res = {'data': res}\n                                elif isinstance(res, Result):\n                                    if asyncio.iscoroutine(res.get()) or isinstance(res.get(), asyncio.Task):\n                                        res_ = await res.aget()\n                                        res.result.data = res_\n                                    res = json.loads(res.to_api_result().json())\n                                elif isinstance(res, bytes | dict):\n                                    pass\n                                else:\n                                    res = {'data': 'unsupported type', 'type': str(type(res))}\n\n                                get_logger().info(f\"sending response {res} {type(res)}\")\n\n                                await sender(res, identifier)\n                            except Exception as e:\n                                await sender({\"data\": str(e)}, identifier)\n\n                        await _helper_runner()\n                    else:\n                        print(\"Unknown connection data:\", data)\n\n                except Exception as e:\n                    get_logger().warning(Style.RED(f\"An error occurred on {identifier} {str(e)}\"))\n                    if identifier != \"unknown\":\n                        running_dict[\"receive\"][str(identifier)] = False\n                        await self.runner_co(self.on_client_exit,  identifier)\n            await asyncio.sleep(0.1)\n        running_dict[\"server_receiver\"] = False\n        for x in running_dict[\"receive\"]:\n            running_dict[\"receive\"][x] = False\n        running_dict[\"keep_alive_var\"] = False\n        await self.runner_co(self.on_server_exit)\n        app.print(f\"Closing Demon {self._name}\")\n        return Result.ok()\n\n    async def a_exit(self):\n        result = await self.server.aget()\n        await result.get(\"close\")()\n        self.alive = False\n        if asyncio.iscoroutine(self.online):\n            await self.online\n        print(\"Connection result :\", result.get(\"host\"), result.get(\"port\"),\n              \"total connections:\", result.get(\"connections\"))\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.daemon.DaemonUtil.__init__","title":"<code>__init__(*args, **kwargs)</code>","text":"<p>Standard constructor used for arguments pass Do not override. Use ainit instead</p> Source code in <code>toolboxv2/utils/daemon/daemon_util.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"\n    Standard constructor used for arguments pass\n    Do not override. Use __ainit__ instead\n    \"\"\"\n    self.server = None\n    self.alive = False\n    self.__storedargs = args, kwargs\n    self.async_initialized = False\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.daemon.DaemonUtil.__initobj","title":"<code>__initobj()</code>  <code>async</code>","text":"<p>Crutch used for await after spawning</p> Source code in <code>toolboxv2/utils/daemon/daemon_util.py</code> <pre><code>async def __initobj(self):\n    \"\"\"Crutch used for __await__ after spawning\"\"\"\n    assert not self.async_initialized\n    self.async_initialized = True\n    # pass the parameters to __ainit__ that passed to __init__\n    await self.__ainit__(*self.__storedargs[0], **self.__storedargs[1])\n    return self\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.daemon.DaemonUtil.start_server","title":"<code>start_server(connection_type=None)</code>  <code>async</code>","text":"<p>Start the server using app and the socket manager</p> Source code in <code>toolboxv2/utils/daemon/daemon_util.py</code> <pre><code>async def start_server(self, connection_type=None):\n    \"\"\"Start the server using app and the socket manager\"\"\"\n    from toolboxv2.mods.SocketManager import SocketType\n    if connection_type is None:\n        connection_type = SocketType.server\n    app = get_app(from_=\"Starting.Daemon\")\n    print(app.mod_online(\"SocketManager\"), \"SocketManager\")\n    if not app.mod_online(\"SocketManager\"):\n        await app.load_mod(\"SocketManager\")\n    server_result = await app.a_run_any(SOCKETMANAGER.CREATE_SOCKET,\n                                        get_results=True,\n                                        name=self._name,\n                                        host=self.host,\n                                        port=self.port,\n                                        type_id=connection_type,\n                                        max_connections=-1,\n                                        return_full_object=True,\n                                        test_override=self.test_override,\n                                        unix_file=self.unix_socket)\n    if server_result.is_error():\n        raise Exception(f\"Server error: {server_result.print(False)}\")\n    if not server_result.is_data():\n        raise Exception(f\"Server error: {server_result.print(False)}\")\n    self.alive = True\n    self.server = server_result\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.daemon.daemon_util","title":"<code>daemon_util</code>","text":""},{"location":"toolboxv2/#toolboxv2.utils.daemon.daemon_util.DaemonUtil","title":"<code>DaemonUtil</code>","text":"Source code in <code>toolboxv2/utils/daemon/daemon_util.py</code> <pre><code>class DaemonUtil:\n\n    def __init__(self, *args, **kwargs):\n        \"\"\"\n        Standard constructor used for arguments pass\n        Do not override. Use __ainit__ instead\n        \"\"\"\n        self.server = None\n        self.alive = False\n        self.__storedargs = args, kwargs\n        self.async_initialized = False\n\n    async def __initobj(self):\n        \"\"\"Crutch used for __await__ after spawning\"\"\"\n        assert not self.async_initialized\n        self.async_initialized = True\n        # pass the parameters to __ainit__ that passed to __init__\n        await self.__ainit__(*self.__storedargs[0], **self.__storedargs[1])\n        return self\n\n    def __await__(self):\n        return self.__initobj().__await__()\n\n    async def __ainit__(self, class_instance: Any, host='0.0.0.0', port=6587, t=False,\n                        app: (App or AppType) | None = None,\n                        peer=False, name='daemonApp-server', on_register=None, on_client_exit=None, on_server_exit=None,\n                        unix_socket=False, test_override=False):\n        from toolboxv2.mods.SocketManager import SocketType\n        self.class_instance = class_instance\n        self.server = None\n        self.port = port\n        self.host = host\n        self.alive = False\n        self.test_override = test_override\n        self._name = name\n        if on_register is None:\n            def on_register(*args):\n                return None\n        self._on_register = on_register\n        if on_client_exit is None:\n            def on_client_exit(*args):\n                return None\n        self.on_client_exit = on_client_exit\n        if on_server_exit is None:\n            def on_server_exit():\n                return None\n        self.on_server_exit = on_server_exit\n        self.unix_socket = unix_socket\n        self.online = None\n        connection_type = SocketType.server\n        if peer:\n            connection_type = SocketType.peer\n\n        await self.start_server(connection_type)\n        app = app if app is not None else get_app(from_=f\"DaemonUtil.{self._name}\")\n        self.online = await asyncio.to_thread(self.connect, app)\n        if t:\n            await self.online\n\n    async def start_server(self, connection_type=None):\n        \"\"\"Start the server using app and the socket manager\"\"\"\n        from toolboxv2.mods.SocketManager import SocketType\n        if connection_type is None:\n            connection_type = SocketType.server\n        app = get_app(from_=\"Starting.Daemon\")\n        print(app.mod_online(\"SocketManager\"), \"SocketManager\")\n        if not app.mod_online(\"SocketManager\"):\n            await app.load_mod(\"SocketManager\")\n        server_result = await app.a_run_any(SOCKETMANAGER.CREATE_SOCKET,\n                                            get_results=True,\n                                            name=self._name,\n                                            host=self.host,\n                                            port=self.port,\n                                            type_id=connection_type,\n                                            max_connections=-1,\n                                            return_full_object=True,\n                                            test_override=self.test_override,\n                                            unix_file=self.unix_socket)\n        if server_result.is_error():\n            raise Exception(f\"Server error: {server_result.print(False)}\")\n        if not server_result.is_data():\n            raise Exception(f\"Server error: {server_result.print(False)}\")\n        self.alive = True\n        self.server = server_result\n        # 'socket': socket,\n        # 'receiver_socket': r_socket,\n        # 'host': host,\n        # 'port': port,\n        # 'p2p-port': endpoint_port,\n        # 'sender': send,\n        # 'receiver_queue': receiver_queue,\n        # 'connection_error': connection_error,\n        # 'receiver_thread': s_thread,\n        # 'keepalive_thread': keep_alive_thread,\n        # 'running_dict': running_dict,\n        # 'client_to_receiver_thread': to_receive,\n        # 'client_receiver_threads': threeds,\n\n    async def send(self, data: dict or bytes or str, identifier: tuple[str, int] or str = \"main\"):\n        result = await self.server.aget()\n        sender = result.get('sender')\n        await sender(data, identifier)\n        return \"Data Transmitted\"\n\n    @staticmethod\n    async def runner_co(fuction, *args, **kwargs):\n        if asyncio.iscoroutinefunction(fuction):\n            return await fuction(*args, **kwargs)\n        return fuction(*args, **kwargs)\n\n    async def connect(self, app):\n        result = await self.server.aget()\n        if not isinstance(result, dict) or result.get('connection_error') != 0:\n            raise Exception(f\"Server error: {result}\")\n        self.server = Result.ok(result)\n        receiver_queue: queue.Queue = self.server.get('receiver_queue')\n        client_to_receiver_thread = self.server.get('client_to_receiver_thread')\n        running_dict = self.server.get('running_dict')\n        sender = self.server.get('sender')\n        known_clients = {}\n        valid_clients = {}\n        app.print(f\"Starting Demon {self._name}\")\n\n        while self.alive:\n\n            if not receiver_queue.empty():\n                data = receiver_queue.get()\n                if not data:\n                    continue\n                if 'identifier' not in data:\n                    continue\n\n                identifier = data.get('identifier', 'unknown')\n                try:\n                    if identifier == \"new_con\":\n                        client, address = data.get('data')\n                        get_logger().info(f\"New connection: {address}\")\n                        known_clients[str(address)] = client\n                        await client_to_receiver_thread(client, str(address))\n\n                        await self.runner_co(self._on_register, identifier, address)\n                        identifier = str(address)\n                        # await sender({'ok': 0}, identifier)\n\n                    print(\"Receiver queue\", identifier, identifier in known_clients, identifier in valid_clients)\n                    # validation\n                    if identifier in known_clients:\n                        get_logger().info(identifier)\n                        if identifier.startswith(\"('127.0.0.1'\"):\n                            valid_clients[identifier] = known_clients[identifier]\n                            await self.runner_co(self._on_register, identifier, data)\n                        elif data.get(\"claim\", False):\n                            do = app.run_any((\"CloudM.UserInstances\", \"validate_ws_id\"),\n                                             ws_id=data.get(\"claim\"))[0]\n                            get_logger().info(do)\n                            if do:\n                                valid_clients[identifier] = known_clients[identifier]\n                                await self.runner_co(self._on_register, identifier, data)\n                        elif data.get(\"key\", False) == os.getenv(\"TB_R_KEY\"):\n                            valid_clients[identifier] = known_clients[identifier]\n                            await self.runner_co(self._on_register, identifier, data)\n                        else:\n                            get_logger().warning(f\"Validating Failed: {identifier}\")\n                            # sender({'Validating Failed': -1}, eval(identifier))\n                        get_logger().info(f\"Validating New: {identifier}\")\n                        del known_clients[identifier]\n\n                    elif identifier in valid_clients:\n                        get_logger().info(f\"New valid Request: {identifier}\")\n                        name = data.get('name')\n                        args = data.get('args')\n                        kwargs = data.get('kwargs')\n\n                        get_logger().info(f\"Request data: {name=}{args=}{kwargs=}{identifier=}\")\n\n                        if name == 'exit_main':\n                            self.alive = False\n                            break\n\n                        if name == 'show_console':\n                            show_console(True)\n                            await sender({'ok': 0}, identifier)\n                            continue\n\n                        if name == 'hide_console':\n                            show_console(False)\n                            await sender({'ok': 0}, identifier)\n                            continue\n\n                        if name == 'rrun_flow':\n                            show_console(True)\n                            runnner = self.class_instance.run_flow\n                            threading.Thread(target=runnner, args=args, kwargs=kwargs, daemon=True).start()\n                            await sender({'ok': 0}, identifier)\n                            show_console(False)\n                            continue\n\n                        async def _helper_runner():\n                            try:\n                                attr_f = getattr(self.class_instance, name)\n\n                                if asyncio.iscoroutinefunction(attr_f):\n                                    res = await attr_f(*args, **kwargs)\n                                else:\n                                    res = attr_f(*args, **kwargs)\n\n                                if res is None:\n                                    res = {'data': res}\n                                elif isinstance(res, Result):\n                                    if asyncio.iscoroutine(res.get()) or isinstance(res.get(), asyncio.Task):\n                                        res_ = await res.aget()\n                                        res.result.data = res_\n                                    res = json.loads(res.to_api_result().json())\n                                elif isinstance(res, bytes | dict):\n                                    pass\n                                else:\n                                    res = {'data': 'unsupported type', 'type': str(type(res))}\n\n                                get_logger().info(f\"sending response {res} {type(res)}\")\n\n                                await sender(res, identifier)\n                            except Exception as e:\n                                await sender({\"data\": str(e)}, identifier)\n\n                        await _helper_runner()\n                    else:\n                        print(\"Unknown connection data:\", data)\n\n                except Exception as e:\n                    get_logger().warning(Style.RED(f\"An error occurred on {identifier} {str(e)}\"))\n                    if identifier != \"unknown\":\n                        running_dict[\"receive\"][str(identifier)] = False\n                        await self.runner_co(self.on_client_exit,  identifier)\n            await asyncio.sleep(0.1)\n        running_dict[\"server_receiver\"] = False\n        for x in running_dict[\"receive\"]:\n            running_dict[\"receive\"][x] = False\n        running_dict[\"keep_alive_var\"] = False\n        await self.runner_co(self.on_server_exit)\n        app.print(f\"Closing Demon {self._name}\")\n        return Result.ok()\n\n    async def a_exit(self):\n        result = await self.server.aget()\n        await result.get(\"close\")()\n        self.alive = False\n        if asyncio.iscoroutine(self.online):\n            await self.online\n        print(\"Connection result :\", result.get(\"host\"), result.get(\"port\"),\n              \"total connections:\", result.get(\"connections\"))\n</code></pre> <code>__init__(*args, **kwargs)</code> \u00b6 <p>Standard constructor used for arguments pass Do not override. Use ainit instead</p> Source code in <code>toolboxv2/utils/daemon/daemon_util.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"\n    Standard constructor used for arguments pass\n    Do not override. Use __ainit__ instead\n    \"\"\"\n    self.server = None\n    self.alive = False\n    self.__storedargs = args, kwargs\n    self.async_initialized = False\n</code></pre> <code>__initobj()</code> <code>async</code> \u00b6 <p>Crutch used for await after spawning</p> Source code in <code>toolboxv2/utils/daemon/daemon_util.py</code> <pre><code>async def __initobj(self):\n    \"\"\"Crutch used for __await__ after spawning\"\"\"\n    assert not self.async_initialized\n    self.async_initialized = True\n    # pass the parameters to __ainit__ that passed to __init__\n    await self.__ainit__(*self.__storedargs[0], **self.__storedargs[1])\n    return self\n</code></pre> <code>start_server(connection_type=None)</code> <code>async</code> \u00b6 <p>Start the server using app and the socket manager</p> Source code in <code>toolboxv2/utils/daemon/daemon_util.py</code> <pre><code>async def start_server(self, connection_type=None):\n    \"\"\"Start the server using app and the socket manager\"\"\"\n    from toolboxv2.mods.SocketManager import SocketType\n    if connection_type is None:\n        connection_type = SocketType.server\n    app = get_app(from_=\"Starting.Daemon\")\n    print(app.mod_online(\"SocketManager\"), \"SocketManager\")\n    if not app.mod_online(\"SocketManager\"):\n        await app.load_mod(\"SocketManager\")\n    server_result = await app.a_run_any(SOCKETMANAGER.CREATE_SOCKET,\n                                        get_results=True,\n                                        name=self._name,\n                                        host=self.host,\n                                        port=self.port,\n                                        type_id=connection_type,\n                                        max_connections=-1,\n                                        return_full_object=True,\n                                        test_override=self.test_override,\n                                        unix_file=self.unix_socket)\n    if server_result.is_error():\n        raise Exception(f\"Server error: {server_result.print(False)}\")\n    if not server_result.is_data():\n        raise Exception(f\"Server error: {server_result.print(False)}\")\n    self.alive = True\n    self.server = server_result\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.extras","title":"<code>extras</code>","text":""},{"location":"toolboxv2/#toolboxv2.utils.extras.BaseWidget","title":"<code>BaseWidget</code>","text":"Source code in <code>toolboxv2/utils/extras/base_widget.py</code> <pre><code>class BaseWidget:\n    def __init__(self, name: str):\n        self.name = name\n        self.openWidgetsIDs = {}\n        self.onReload = []\n        self.iframes = {}\n\n    def register(self, app, fuction, version=None, name=\"get_widget\", level=1, **kwargs):\n        if version is None:\n            version = app.version\n        app.tb(mod_name=self.name, version=version, request_as_kwarg=True, level=level, api=True, name=name, **kwargs)(\n            fuction)\n\n    def modify_iterator(self, iterator, replace):\n        \"\"\"\n        ['a', 'b'] -&gt; [{replace[0]: 'a',..., replace[len(replace)-1]: 'a'},\n        {replace[0]: 'b',..., replace[len(replace)-1]: 'b'}, ]\n        \"\"\"\n\n        for item in iterator:\n            modified_item = {replace[i]: (self.name if replace[i] == \"name\" else '') + item for i in\n                             range(len(replace))}\n            yield modified_item\n\n    def register2reload(self, *functions):\n        for fuction in functions:\n            def x(r):\n                return fuction(request=r)\n            self.onReload.append(x)\n\n    def reload_guard(self, function):\n        c = None\n        if len(self.onReload) == 0:\n            c = function()\n        return c\n\n    async def oa_reload_guard(self, function):\n        c = None\n        if len(self.onReload) == 0:\n            c = await function() if asyncio.iscoroutinefunction(function) else function()\n        return c\n\n    @staticmethod\n    def get_a_group(asset_name, template=None, file_path=None, a_kwargs=None):\n        if a_kwargs is None:\n            raise ValueError(\"a_kwargs must be specified\")\n        return [{'name': asset_name,\n                 'file_path': file_path,\n                 'kwargs': a_kwargs\n                 } if file_path is not None else {'name': asset_name,\n                                                  'template': template,\n                                                  'kwargs': a_kwargs\n                                                  }]\n\n    def group_generator(self, asset_name: str, iterator: iter, template=None, file_path=None, a_kwargs=None):\n        groups = []\n        work_kwargs = a_kwargs\n        for _i, data in enumerate(iterator):\n            if isinstance(data, dict):\n                work_kwargs = {**a_kwargs, **data}\n            groups.append(self.get_a_group(asset_name, template=template, file_path=file_path, a_kwargs=work_kwargs))\n        return groups\n\n    def asset_loder(self, app, name, asset_id, file_path=None, template=None, iterator=None, **kwargs):\n        a_kwargs = {**{\n            'root': f\"/api/{self.name}\",\n            'WidgetID': asset_id},\n                    **kwargs}\n        asset_name = f\"{name}-{asset_id}\"\n        if iterator is None:\n            group = self.get_a_group(asset_name,\n                                     template=template,\n                                     file_path=file_path,\n                                     a_kwargs=a_kwargs)\n        else:\n            group = self.group_generator(asset_name,\n                                         iterator=iterator,\n                                         template=template,\n                                         file_path=file_path,\n                                         a_kwargs=a_kwargs)\n\n        asset = app.run_any(MINIMALHTML.ADD_COLLECTION_TO_GROUP,\n                            group_name=self.name,\n                            collection={'name': f\"{asset_name}\",\n                                        'group': group},\n                            get_results=True)\n        if asset.is_error():\n            app.run_any(MINIMALHTML.ADD_GROUP, command=self.name)\n            asset = app.run_any(MINIMALHTML.ADD_COLLECTION_TO_GROUP,\n                                group_name=self.name,\n                                collection={'name': f\"{self.name}-{asset_name}\",\n                                            'group': group},\n                                get_results=True)\n        return asset\n\n    def generate_html(self, app, name=\"MainWidget\", asset_id=str(uuid.uuid4())[:4]):\n        return app.run_any(MINIMALHTML.GENERATE_HTML,\n                           group_name=self.name,\n                           collection_name=f\"{name}-{asset_id}\")\n\n    def load_widget(self, app, request, name=\"MainWidget\", asset_id=str(uuid.uuid4())[:4]):\n        app.run_any(MINIMALHTML.ADD_GROUP, command=self.name)\n        self.reload(request)\n        html_widget = self.generate_html(app, name, asset_id)\n        return html_widget[0]['html_element']\n\n    @staticmethod\n    async def get_user_from_request(app, request):\n        from toolboxv2.mods.CloudM import User\n        if request is None:\n            return User()\n        return await get_current_user_from_request(app, request)\n\n    @staticmethod\n    def get_s_id(request):\n        from ..system.types import Result\n        if request is None:\n            return Result.default_internal_error(\"No request specified\")\n        return Result.ok(request.session.get('ID', ''))\n\n    def reload(self, request):\n        [_(request) for _ in self.onReload]\n\n    async def oa_reload(self, request):\n        [_(request) if not asyncio.iscoroutinefunction(_) else await _(request) for _ in self.onReload]\n\n    async def get_widget(self, request, **kwargs):\n        raise NotImplementedError\n\n    def hash_wrapper(self, _id, _salt=''):\n        from ..security.cryp import Code\n        return Code.one_way_hash(text=_id, salt=_salt, pepper=self.name)\n\n    def register_iframe(self, iframe_id: str, src: str, width: str = \"100%\", height: str = \"500px\", **kwargs):\n        \"\"\"\n        Registriert einen iframe mit gegebener ID und Quelle\n\n        Args:\n            iframe_id: Eindeutige ID f\u00fcr den iframe\n            src: URL oder Pfad zur Quelle des iframes\n            width: Breite des iframes (default: \"100%\")\n            height: H\u00f6he des iframes (default: \"500px\")\n            **kwargs: Weitere iframe-Attribute\n        \"\"\"\n        iframe_config = {\n            'src': src,\n            'width': width,\n            'height': height,\n            **kwargs\n        }\n        self.iframes[iframe_id] = iframe_config\n\n    def create_iframe_asset(self, app, iframe_id: str, asset_id: str = None):\n        \"\"\"\n        Erstellt ein Asset f\u00fcr einen registrierten iframe\n\n        Args:\n            app: App-Instanz\n            iframe_id: ID des registrierten iframes\n            asset_id: Optional, spezifische Asset-ID\n        \"\"\"\n        if iframe_id not in self.iframes:\n            raise ValueError(f\"iframe mit ID {iframe_id} nicht registriert\")\n\n        if asset_id is None:\n            asset_id = str(uuid.uuid4())[:4]\n\n        iframe_config = self.iframes[iframe_id]\n        iframe_template = \"\"\"\n        &lt;iframe id=\"{iframe_id}\"\n                src=\"{src}\"\n                width=\"{width}\"\n                height=\"{height}\"\n                frameborder=\"0\"\n                {additional_attrs}&gt;&lt;/iframe&gt;\n        \"\"\".strip()\n\n        # Filtere bekannte Attribute heraus und erstelle String f\u00fcr zus\u00e4tzliche Attribute\n        known_attrs = {'src', 'width', 'height'}\n        additional_attrs = ' '.join(\n            f'{k}=\"{v}\"' for k, v in iframe_config.items()\n            if k not in known_attrs\n        )\n\n        iframe_html = iframe_template.format(\n            iframe_id=iframe_id,\n            src=iframe_config['src'],\n            width=iframe_config['width'],\n            height=iframe_config['height'],\n            additional_attrs=additional_attrs\n        )\n\n        return self.asset_loder(\n            app=app,\n            name=f\"iframe-{iframe_id}\",\n            asset_id=asset_id,\n            template=iframe_html\n        )\n\n    def load_iframe(self, app, iframe_id: str, asset_id: str = None):\n        \"\"\"\n        L\u00e4dt einen registrierten iframe und gibt das HTML-Element zur\u00fcck\n\n        Args:\n            app: App-Instanz\n            iframe_id: ID des registrierten iframes\n            asset_id: Optional, spezifische Asset-ID\n        \"\"\"\n        self.create_iframe_asset(app, iframe_id, asset_id)\n        return self.generate_html(app, f\"iframe-{iframe_id}\", asset_id)[0]['html_element']\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.extras.BaseWidget.create_iframe_asset","title":"<code>create_iframe_asset(app, iframe_id, asset_id=None)</code>","text":"<p>Erstellt ein Asset f\u00fcr einen registrierten iframe</p> <p>Parameters:</p> Name Type Description Default <code>app</code> <p>App-Instanz</p> required <code>iframe_id</code> <code>str</code> <p>ID des registrierten iframes</p> required <code>asset_id</code> <code>str</code> <p>Optional, spezifische Asset-ID</p> <code>None</code> Source code in <code>toolboxv2/utils/extras/base_widget.py</code> <pre><code>def create_iframe_asset(self, app, iframe_id: str, asset_id: str = None):\n    \"\"\"\n    Erstellt ein Asset f\u00fcr einen registrierten iframe\n\n    Args:\n        app: App-Instanz\n        iframe_id: ID des registrierten iframes\n        asset_id: Optional, spezifische Asset-ID\n    \"\"\"\n    if iframe_id not in self.iframes:\n        raise ValueError(f\"iframe mit ID {iframe_id} nicht registriert\")\n\n    if asset_id is None:\n        asset_id = str(uuid.uuid4())[:4]\n\n    iframe_config = self.iframes[iframe_id]\n    iframe_template = \"\"\"\n    &lt;iframe id=\"{iframe_id}\"\n            src=\"{src}\"\n            width=\"{width}\"\n            height=\"{height}\"\n            frameborder=\"0\"\n            {additional_attrs}&gt;&lt;/iframe&gt;\n    \"\"\".strip()\n\n    # Filtere bekannte Attribute heraus und erstelle String f\u00fcr zus\u00e4tzliche Attribute\n    known_attrs = {'src', 'width', 'height'}\n    additional_attrs = ' '.join(\n        f'{k}=\"{v}\"' for k, v in iframe_config.items()\n        if k not in known_attrs\n    )\n\n    iframe_html = iframe_template.format(\n        iframe_id=iframe_id,\n        src=iframe_config['src'],\n        width=iframe_config['width'],\n        height=iframe_config['height'],\n        additional_attrs=additional_attrs\n    )\n\n    return self.asset_loder(\n        app=app,\n        name=f\"iframe-{iframe_id}\",\n        asset_id=asset_id,\n        template=iframe_html\n    )\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.extras.BaseWidget.load_iframe","title":"<code>load_iframe(app, iframe_id, asset_id=None)</code>","text":"<p>L\u00e4dt einen registrierten iframe und gibt das HTML-Element zur\u00fcck</p> <p>Parameters:</p> Name Type Description Default <code>app</code> <p>App-Instanz</p> required <code>iframe_id</code> <code>str</code> <p>ID des registrierten iframes</p> required <code>asset_id</code> <code>str</code> <p>Optional, spezifische Asset-ID</p> <code>None</code> Source code in <code>toolboxv2/utils/extras/base_widget.py</code> <pre><code>def load_iframe(self, app, iframe_id: str, asset_id: str = None):\n    \"\"\"\n    L\u00e4dt einen registrierten iframe und gibt das HTML-Element zur\u00fcck\n\n    Args:\n        app: App-Instanz\n        iframe_id: ID des registrierten iframes\n        asset_id: Optional, spezifische Asset-ID\n    \"\"\"\n    self.create_iframe_asset(app, iframe_id, asset_id)\n    return self.generate_html(app, f\"iframe-{iframe_id}\", asset_id)[0]['html_element']\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.extras.BaseWidget.modify_iterator","title":"<code>modify_iterator(iterator, replace)</code>","text":"<p>['a', 'b'] -&gt; [{replace[0]: 'a',..., replace[len(replace)-1]: 'a'}, {replace[0]: 'b',..., replace[len(replace)-1]: 'b'}, ]</p> Source code in <code>toolboxv2/utils/extras/base_widget.py</code> <pre><code>def modify_iterator(self, iterator, replace):\n    \"\"\"\n    ['a', 'b'] -&gt; [{replace[0]: 'a',..., replace[len(replace)-1]: 'a'},\n    {replace[0]: 'b',..., replace[len(replace)-1]: 'b'}, ]\n    \"\"\"\n\n    for item in iterator:\n        modified_item = {replace[i]: (self.name if replace[i] == \"name\" else '') + item for i in\n                         range(len(replace))}\n        yield modified_item\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.extras.BaseWidget.register_iframe","title":"<code>register_iframe(iframe_id, src, width='100%', height='500px', **kwargs)</code>","text":"<p>Registriert einen iframe mit gegebener ID und Quelle</p> <p>Parameters:</p> Name Type Description Default <code>iframe_id</code> <code>str</code> <p>Eindeutige ID f\u00fcr den iframe</p> required <code>src</code> <code>str</code> <p>URL oder Pfad zur Quelle des iframes</p> required <code>width</code> <code>str</code> <p>Breite des iframes (default: \"100%\")</p> <code>'100%'</code> <code>height</code> <code>str</code> <p>H\u00f6he des iframes (default: \"500px\")</p> <code>'500px'</code> <code>**kwargs</code> <p>Weitere iframe-Attribute</p> <code>{}</code> Source code in <code>toolboxv2/utils/extras/base_widget.py</code> <pre><code>def register_iframe(self, iframe_id: str, src: str, width: str = \"100%\", height: str = \"500px\", **kwargs):\n    \"\"\"\n    Registriert einen iframe mit gegebener ID und Quelle\n\n    Args:\n        iframe_id: Eindeutige ID f\u00fcr den iframe\n        src: URL oder Pfad zur Quelle des iframes\n        width: Breite des iframes (default: \"100%\")\n        height: H\u00f6he des iframes (default: \"500px\")\n        **kwargs: Weitere iframe-Attribute\n    \"\"\"\n    iframe_config = {\n        'src': src,\n        'width': width,\n        'height': height,\n        **kwargs\n    }\n    self.iframes[iframe_id] = iframe_config\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.extras.Style","title":"<code>Style</code>","text":""},{"location":"toolboxv2/#toolboxv2.utils.extras.Style.Spinner","title":"<code>Spinner</code>","text":"<p>Enhanced Spinner with tqdm-like line rendering.</p> Source code in <code>toolboxv2/utils/extras/Style.py</code> <pre><code>class Spinner:\n    \"\"\"\n    Enhanced Spinner with tqdm-like line rendering.\n    \"\"\"\n    SYMBOL_SETS = {\n        \"c\": [\"\u25d0\", \"\u25d3\", \"\u25d1\", \"\u25d2\"],\n        \"b\": [\"\u2581\", \"\u2583\", \"\u2584\", \"\u2585\", \"\u2586\", \"\u2587\", \"\u2588\", \"\u2587\", \"\u2586\", \"\u2585\", \"\u2584\", \"\u2583\"],\n        \"d\": [\"\u28fe\", \"\u28fd\", \"\u28fb\", \"\u28bf\", \"\u287f\", \"\u28df\", \"\u28ef\", \"\u28f7\"],\n        \"w\": [\"\ud83c\udf0d\", \"\ud83c\udf0e\", \"\ud83c\udf0f\"],\n        \"s\": [\"\ud83c\udf00   \", \" \ud83c\udf00  \", \"  \ud83c\udf00 \", \"   \ud83c\udf00\", \"  \ud83c\udf00 \", \" \ud83c\udf00  \"],\n        \"+\": [\"+\", \"x\"],\n        \"t\": [\"\u2736\", \"\u2738\", \"\u2739\", \"\u273a\", \"\u2739\", \"\u2737\"]\n    }\n\n    def __init__(\n        self,\n        message: str = \"Loading...\",\n        delay: float = 0.1,\n        symbols=None,\n        count_down: bool = False,\n        time_in_s: float = 0\n    ):\n        \"\"\"Initialize spinner with flexible configuration.\"\"\"\n        # Resolve symbol set.\n        if isinstance(symbols, str):\n            symbols = self.SYMBOL_SETS.get(symbols, None)\n\n        # Default symbols if not provided.\n        if symbols is None:\n            symbols = [\"\u280b\", \"\u2819\", \"\u2839\", \"\u2838\", \"\u283c\", \"\u2834\", \"\u2826\", \"\u2827\", \"\u2807\", \"\u280f\"]\n\n        # Test mode symbol set.\n        if 'unittest' in sys.argv[0]:\n            symbols = ['#', '=', '-']\n\n        self.spinner = itertools.cycle(symbols)\n        self.delay = delay\n        self.message = message\n        self.running = False\n        self.spinner_thread = None\n        self.max_t = time_in_s\n        self.contd = count_down\n\n        # Rendering management.\n        self._is_primary = False\n        self._start_time = 0\n\n        # Central manager.\n        self.manager = SpinnerManager()\n\n    def _generate_render_line(self):\n        \"\"\"Generate the primary render line.\"\"\"\n        current_time = time.time()\n        if self.contd:\n            remaining = max(0, self.max_t - (current_time - self._start_time))\n            time_display = f\"{remaining:.2f}\"\n        else:\n            time_display = f\"{current_time - self._start_time:.2f}\"\n\n        symbol = next(self.spinner)\n        return f\"{symbol} {self.message} | {time_display}\"\n\n    def _generate_secondary_info(self):\n        \"\"\"Generate secondary spinner info for additional spinners.\"\"\"\n        return f\"{self.message}\"\n\n    def __enter__(self):\n        \"\"\"Start the spinner.\"\"\"\n        self.running = True\n        self._start_time = time.time()\n        self.manager.register_spinner(self)\n        return self\n\n    def __exit__(self, exc_type, exc_value, exc_traceback):\n        \"\"\"Stop the spinner.\"\"\"\n        self.running = False\n        self.manager.unregister_spinner(self)\n        # Clear the spinner's line if it was the primary spinner.\n        if self._is_primary:\n            sys.stdout.write(\"\\r\\033[K\")\n            sys.stdout.flush()\n</code></pre> <code>__enter__()</code> \u00b6 <p>Start the spinner.</p> Source code in <code>toolboxv2/utils/extras/Style.py</code> <pre><code>def __enter__(self):\n    \"\"\"Start the spinner.\"\"\"\n    self.running = True\n    self._start_time = time.time()\n    self.manager.register_spinner(self)\n    return self\n</code></pre> <code>__exit__(exc_type, exc_value, exc_traceback)</code> \u00b6 <p>Stop the spinner.</p> Source code in <code>toolboxv2/utils/extras/Style.py</code> <pre><code>def __exit__(self, exc_type, exc_value, exc_traceback):\n    \"\"\"Stop the spinner.\"\"\"\n    self.running = False\n    self.manager.unregister_spinner(self)\n    # Clear the spinner's line if it was the primary spinner.\n    if self._is_primary:\n        sys.stdout.write(\"\\r\\033[K\")\n        sys.stdout.flush()\n</code></pre> <code>__init__(message='Loading...', delay=0.1, symbols=None, count_down=False, time_in_s=0)</code> \u00b6 <p>Initialize spinner with flexible configuration.</p> Source code in <code>toolboxv2/utils/extras/Style.py</code> <pre><code>def __init__(\n    self,\n    message: str = \"Loading...\",\n    delay: float = 0.1,\n    symbols=None,\n    count_down: bool = False,\n    time_in_s: float = 0\n):\n    \"\"\"Initialize spinner with flexible configuration.\"\"\"\n    # Resolve symbol set.\n    if isinstance(symbols, str):\n        symbols = self.SYMBOL_SETS.get(symbols, None)\n\n    # Default symbols if not provided.\n    if symbols is None:\n        symbols = [\"\u280b\", \"\u2819\", \"\u2839\", \"\u2838\", \"\u283c\", \"\u2834\", \"\u2826\", \"\u2827\", \"\u2807\", \"\u280f\"]\n\n    # Test mode symbol set.\n    if 'unittest' in sys.argv[0]:\n        symbols = ['#', '=', '-']\n\n    self.spinner = itertools.cycle(symbols)\n    self.delay = delay\n    self.message = message\n    self.running = False\n    self.spinner_thread = None\n    self.max_t = time_in_s\n    self.contd = count_down\n\n    # Rendering management.\n    self._is_primary = False\n    self._start_time = 0\n\n    # Central manager.\n    self.manager = SpinnerManager()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.extras.Style.SpinnerManager","title":"<code>SpinnerManager</code>","text":"<p>Manages multiple spinners to ensure tqdm-like line rendering. Automatically captures SIGINT (Ctrl+C) to stop all spinners.</p> Source code in <code>toolboxv2/utils/extras/Style.py</code> <pre><code>class SpinnerManager(metaclass=Singleton):\n    \"\"\"\n    Manages multiple spinners to ensure tqdm-like line rendering.\n    Automatically captures SIGINT (Ctrl+C) to stop all spinners.\n    \"\"\"\n    _instance = None\n\n    def __new__(cls):\n        if not cls._instance:\n            cls._instance = super().__new__(cls)\n            cls._instance._init_manager()\n        return cls._instance\n\n    def _init_manager(self):\n        \"\"\"Initialize spinner management resources and register SIGINT handler.\"\"\"\n        self._spinners = []\n        self._lock = threading.Lock()\n        self._render_thread = None\n        self._should_run = False\n        try:\n            signal.signal(signal.SIGINT, self._signal_handler)\n        except ValueError:\n            print(\"Spinner Manager not in the min Thread no signal possible\")\n            pass\n\n    def _signal_handler(self, signum, frame):\n        \"\"\"Handle SIGINT by stopping all spinners gracefully.\"\"\"\n        with self._lock:\n            for spinner in self._spinners:\n                spinner.running = False\n            self._spinners.clear()\n        self._should_run = False\n        sys.stdout.write(\"\\r\\033[K\")  # Clear the spinner's line.\n        sys.stdout.flush()\n        sys.exit(0)\n\n    def register_spinner(self, spinner):\n        \"\"\"Register a new spinner.\"\"\"\n        with self._lock:\n            # First spinner defines the rendering line.\n            if not self._spinners:\n                spinner._is_primary = True\n            self._spinners.append(spinner)\n            # Start rendering if not already running.\n            if not self._should_run:\n                self._should_run = True\n                self._render_thread = threading.Thread(\n                    target=self._render_loop,\n                    daemon=True\n                )\n                self._render_thread.start()\n\n    def unregister_spinner(self, spinner):\n        \"\"\"Unregister a completed spinner.\"\"\"\n        with self._lock:\n            if spinner in self._spinners:\n                self._spinners.remove(spinner)\n\n    def _render_loop(self):\n        \"\"\"Continuous rendering loop for all active spinners.\"\"\"\n        while self._should_run:\n            if not self._spinners:\n                self._should_run = False\n                break\n\n            with self._lock:\n                # Find primary spinner (first registered).\n                primary_spinner = next((s for s in self._spinners if s._is_primary), None)\n\n                if primary_spinner and primary_spinner.running:\n                    # Render in the same line.\n                    render_line = primary_spinner._generate_render_line()\n\n                    # Append additional spinner info if multiple exist.\n                    if len(self._spinners) &gt; 1:\n                        secondary_info = \" | \".join(\n                            s._generate_secondary_info()\n                            for s in self._spinners\n                            if s is not primary_spinner and s.running\n                        )\n                        render_line += f\" [{secondary_info}]\"\n\n                    # Clear line and write.\n                    try:\n                        sys.stdout.write(\"\\r\" + render_line + \"\\033[K\")\n                        sys.stdout.flush()\n                    except Exception:\n                        self._should_run = False\n\n            time.sleep(0.1)  # Render interval.\n</code></pre> <code>register_spinner(spinner)</code> \u00b6 <p>Register a new spinner.</p> Source code in <code>toolboxv2/utils/extras/Style.py</code> <pre><code>def register_spinner(self, spinner):\n    \"\"\"Register a new spinner.\"\"\"\n    with self._lock:\n        # First spinner defines the rendering line.\n        if not self._spinners:\n            spinner._is_primary = True\n        self._spinners.append(spinner)\n        # Start rendering if not already running.\n        if not self._should_run:\n            self._should_run = True\n            self._render_thread = threading.Thread(\n                target=self._render_loop,\n                daemon=True\n            )\n            self._render_thread.start()\n</code></pre> <code>unregister_spinner(spinner)</code> \u00b6 <p>Unregister a completed spinner.</p> Source code in <code>toolboxv2/utils/extras/Style.py</code> <pre><code>def unregister_spinner(self, spinner):\n    \"\"\"Unregister a completed spinner.\"\"\"\n    with self._lock:\n        if spinner in self._spinners:\n            self._spinners.remove(spinner)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.extras.base_widget","title":"<code>base_widget</code>","text":""},{"location":"toolboxv2/#toolboxv2.utils.extras.base_widget.BaseWidget","title":"<code>BaseWidget</code>","text":"Source code in <code>toolboxv2/utils/extras/base_widget.py</code> <pre><code>class BaseWidget:\n    def __init__(self, name: str):\n        self.name = name\n        self.openWidgetsIDs = {}\n        self.onReload = []\n        self.iframes = {}\n\n    def register(self, app, fuction, version=None, name=\"get_widget\", level=1, **kwargs):\n        if version is None:\n            version = app.version\n        app.tb(mod_name=self.name, version=version, request_as_kwarg=True, level=level, api=True, name=name, **kwargs)(\n            fuction)\n\n    def modify_iterator(self, iterator, replace):\n        \"\"\"\n        ['a', 'b'] -&gt; [{replace[0]: 'a',..., replace[len(replace)-1]: 'a'},\n        {replace[0]: 'b',..., replace[len(replace)-1]: 'b'}, ]\n        \"\"\"\n\n        for item in iterator:\n            modified_item = {replace[i]: (self.name if replace[i] == \"name\" else '') + item for i in\n                             range(len(replace))}\n            yield modified_item\n\n    def register2reload(self, *functions):\n        for fuction in functions:\n            def x(r):\n                return fuction(request=r)\n            self.onReload.append(x)\n\n    def reload_guard(self, function):\n        c = None\n        if len(self.onReload) == 0:\n            c = function()\n        return c\n\n    async def oa_reload_guard(self, function):\n        c = None\n        if len(self.onReload) == 0:\n            c = await function() if asyncio.iscoroutinefunction(function) else function()\n        return c\n\n    @staticmethod\n    def get_a_group(asset_name, template=None, file_path=None, a_kwargs=None):\n        if a_kwargs is None:\n            raise ValueError(\"a_kwargs must be specified\")\n        return [{'name': asset_name,\n                 'file_path': file_path,\n                 'kwargs': a_kwargs\n                 } if file_path is not None else {'name': asset_name,\n                                                  'template': template,\n                                                  'kwargs': a_kwargs\n                                                  }]\n\n    def group_generator(self, asset_name: str, iterator: iter, template=None, file_path=None, a_kwargs=None):\n        groups = []\n        work_kwargs = a_kwargs\n        for _i, data in enumerate(iterator):\n            if isinstance(data, dict):\n                work_kwargs = {**a_kwargs, **data}\n            groups.append(self.get_a_group(asset_name, template=template, file_path=file_path, a_kwargs=work_kwargs))\n        return groups\n\n    def asset_loder(self, app, name, asset_id, file_path=None, template=None, iterator=None, **kwargs):\n        a_kwargs = {**{\n            'root': f\"/api/{self.name}\",\n            'WidgetID': asset_id},\n                    **kwargs}\n        asset_name = f\"{name}-{asset_id}\"\n        if iterator is None:\n            group = self.get_a_group(asset_name,\n                                     template=template,\n                                     file_path=file_path,\n                                     a_kwargs=a_kwargs)\n        else:\n            group = self.group_generator(asset_name,\n                                         iterator=iterator,\n                                         template=template,\n                                         file_path=file_path,\n                                         a_kwargs=a_kwargs)\n\n        asset = app.run_any(MINIMALHTML.ADD_COLLECTION_TO_GROUP,\n                            group_name=self.name,\n                            collection={'name': f\"{asset_name}\",\n                                        'group': group},\n                            get_results=True)\n        if asset.is_error():\n            app.run_any(MINIMALHTML.ADD_GROUP, command=self.name)\n            asset = app.run_any(MINIMALHTML.ADD_COLLECTION_TO_GROUP,\n                                group_name=self.name,\n                                collection={'name': f\"{self.name}-{asset_name}\",\n                                            'group': group},\n                                get_results=True)\n        return asset\n\n    def generate_html(self, app, name=\"MainWidget\", asset_id=str(uuid.uuid4())[:4]):\n        return app.run_any(MINIMALHTML.GENERATE_HTML,\n                           group_name=self.name,\n                           collection_name=f\"{name}-{asset_id}\")\n\n    def load_widget(self, app, request, name=\"MainWidget\", asset_id=str(uuid.uuid4())[:4]):\n        app.run_any(MINIMALHTML.ADD_GROUP, command=self.name)\n        self.reload(request)\n        html_widget = self.generate_html(app, name, asset_id)\n        return html_widget[0]['html_element']\n\n    @staticmethod\n    async def get_user_from_request(app, request):\n        from toolboxv2.mods.CloudM import User\n        if request is None:\n            return User()\n        return await get_current_user_from_request(app, request)\n\n    @staticmethod\n    def get_s_id(request):\n        from ..system.types import Result\n        if request is None:\n            return Result.default_internal_error(\"No request specified\")\n        return Result.ok(request.session.get('ID', ''))\n\n    def reload(self, request):\n        [_(request) for _ in self.onReload]\n\n    async def oa_reload(self, request):\n        [_(request) if not asyncio.iscoroutinefunction(_) else await _(request) for _ in self.onReload]\n\n    async def get_widget(self, request, **kwargs):\n        raise NotImplementedError\n\n    def hash_wrapper(self, _id, _salt=''):\n        from ..security.cryp import Code\n        return Code.one_way_hash(text=_id, salt=_salt, pepper=self.name)\n\n    def register_iframe(self, iframe_id: str, src: str, width: str = \"100%\", height: str = \"500px\", **kwargs):\n        \"\"\"\n        Registriert einen iframe mit gegebener ID und Quelle\n\n        Args:\n            iframe_id: Eindeutige ID f\u00fcr den iframe\n            src: URL oder Pfad zur Quelle des iframes\n            width: Breite des iframes (default: \"100%\")\n            height: H\u00f6he des iframes (default: \"500px\")\n            **kwargs: Weitere iframe-Attribute\n        \"\"\"\n        iframe_config = {\n            'src': src,\n            'width': width,\n            'height': height,\n            **kwargs\n        }\n        self.iframes[iframe_id] = iframe_config\n\n    def create_iframe_asset(self, app, iframe_id: str, asset_id: str = None):\n        \"\"\"\n        Erstellt ein Asset f\u00fcr einen registrierten iframe\n\n        Args:\n            app: App-Instanz\n            iframe_id: ID des registrierten iframes\n            asset_id: Optional, spezifische Asset-ID\n        \"\"\"\n        if iframe_id not in self.iframes:\n            raise ValueError(f\"iframe mit ID {iframe_id} nicht registriert\")\n\n        if asset_id is None:\n            asset_id = str(uuid.uuid4())[:4]\n\n        iframe_config = self.iframes[iframe_id]\n        iframe_template = \"\"\"\n        &lt;iframe id=\"{iframe_id}\"\n                src=\"{src}\"\n                width=\"{width}\"\n                height=\"{height}\"\n                frameborder=\"0\"\n                {additional_attrs}&gt;&lt;/iframe&gt;\n        \"\"\".strip()\n\n        # Filtere bekannte Attribute heraus und erstelle String f\u00fcr zus\u00e4tzliche Attribute\n        known_attrs = {'src', 'width', 'height'}\n        additional_attrs = ' '.join(\n            f'{k}=\"{v}\"' for k, v in iframe_config.items()\n            if k not in known_attrs\n        )\n\n        iframe_html = iframe_template.format(\n            iframe_id=iframe_id,\n            src=iframe_config['src'],\n            width=iframe_config['width'],\n            height=iframe_config['height'],\n            additional_attrs=additional_attrs\n        )\n\n        return self.asset_loder(\n            app=app,\n            name=f\"iframe-{iframe_id}\",\n            asset_id=asset_id,\n            template=iframe_html\n        )\n\n    def load_iframe(self, app, iframe_id: str, asset_id: str = None):\n        \"\"\"\n        L\u00e4dt einen registrierten iframe und gibt das HTML-Element zur\u00fcck\n\n        Args:\n            app: App-Instanz\n            iframe_id: ID des registrierten iframes\n            asset_id: Optional, spezifische Asset-ID\n        \"\"\"\n        self.create_iframe_asset(app, iframe_id, asset_id)\n        return self.generate_html(app, f\"iframe-{iframe_id}\", asset_id)[0]['html_element']\n</code></pre> <code>create_iframe_asset(app, iframe_id, asset_id=None)</code> \u00b6 <p>Erstellt ein Asset f\u00fcr einen registrierten iframe</p> <p>Parameters:</p> Name Type Description Default <code>app</code> <p>App-Instanz</p> required <code>iframe_id</code> <code>str</code> <p>ID des registrierten iframes</p> required <code>asset_id</code> <code>str</code> <p>Optional, spezifische Asset-ID</p> <code>None</code> Source code in <code>toolboxv2/utils/extras/base_widget.py</code> <pre><code>def create_iframe_asset(self, app, iframe_id: str, asset_id: str = None):\n    \"\"\"\n    Erstellt ein Asset f\u00fcr einen registrierten iframe\n\n    Args:\n        app: App-Instanz\n        iframe_id: ID des registrierten iframes\n        asset_id: Optional, spezifische Asset-ID\n    \"\"\"\n    if iframe_id not in self.iframes:\n        raise ValueError(f\"iframe mit ID {iframe_id} nicht registriert\")\n\n    if asset_id is None:\n        asset_id = str(uuid.uuid4())[:4]\n\n    iframe_config = self.iframes[iframe_id]\n    iframe_template = \"\"\"\n    &lt;iframe id=\"{iframe_id}\"\n            src=\"{src}\"\n            width=\"{width}\"\n            height=\"{height}\"\n            frameborder=\"0\"\n            {additional_attrs}&gt;&lt;/iframe&gt;\n    \"\"\".strip()\n\n    # Filtere bekannte Attribute heraus und erstelle String f\u00fcr zus\u00e4tzliche Attribute\n    known_attrs = {'src', 'width', 'height'}\n    additional_attrs = ' '.join(\n        f'{k}=\"{v}\"' for k, v in iframe_config.items()\n        if k not in known_attrs\n    )\n\n    iframe_html = iframe_template.format(\n        iframe_id=iframe_id,\n        src=iframe_config['src'],\n        width=iframe_config['width'],\n        height=iframe_config['height'],\n        additional_attrs=additional_attrs\n    )\n\n    return self.asset_loder(\n        app=app,\n        name=f\"iframe-{iframe_id}\",\n        asset_id=asset_id,\n        template=iframe_html\n    )\n</code></pre> <code>load_iframe(app, iframe_id, asset_id=None)</code> \u00b6 <p>L\u00e4dt einen registrierten iframe und gibt das HTML-Element zur\u00fcck</p> <p>Parameters:</p> Name Type Description Default <code>app</code> <p>App-Instanz</p> required <code>iframe_id</code> <code>str</code> <p>ID des registrierten iframes</p> required <code>asset_id</code> <code>str</code> <p>Optional, spezifische Asset-ID</p> <code>None</code> Source code in <code>toolboxv2/utils/extras/base_widget.py</code> <pre><code>def load_iframe(self, app, iframe_id: str, asset_id: str = None):\n    \"\"\"\n    L\u00e4dt einen registrierten iframe und gibt das HTML-Element zur\u00fcck\n\n    Args:\n        app: App-Instanz\n        iframe_id: ID des registrierten iframes\n        asset_id: Optional, spezifische Asset-ID\n    \"\"\"\n    self.create_iframe_asset(app, iframe_id, asset_id)\n    return self.generate_html(app, f\"iframe-{iframe_id}\", asset_id)[0]['html_element']\n</code></pre> <code>modify_iterator(iterator, replace)</code> \u00b6 <p>['a', 'b'] -&gt; [{replace[0]: 'a',..., replace[len(replace)-1]: 'a'}, {replace[0]: 'b',..., replace[len(replace)-1]: 'b'}, ]</p> Source code in <code>toolboxv2/utils/extras/base_widget.py</code> <pre><code>def modify_iterator(self, iterator, replace):\n    \"\"\"\n    ['a', 'b'] -&gt; [{replace[0]: 'a',..., replace[len(replace)-1]: 'a'},\n    {replace[0]: 'b',..., replace[len(replace)-1]: 'b'}, ]\n    \"\"\"\n\n    for item in iterator:\n        modified_item = {replace[i]: (self.name if replace[i] == \"name\" else '') + item for i in\n                         range(len(replace))}\n        yield modified_item\n</code></pre> <code>register_iframe(iframe_id, src, width='100%', height='500px', **kwargs)</code> \u00b6 <p>Registriert einen iframe mit gegebener ID und Quelle</p> <p>Parameters:</p> Name Type Description Default <code>iframe_id</code> <code>str</code> <p>Eindeutige ID f\u00fcr den iframe</p> required <code>src</code> <code>str</code> <p>URL oder Pfad zur Quelle des iframes</p> required <code>width</code> <code>str</code> <p>Breite des iframes (default: \"100%\")</p> <code>'100%'</code> <code>height</code> <code>str</code> <p>H\u00f6he des iframes (default: \"500px\")</p> <code>'500px'</code> <code>**kwargs</code> <p>Weitere iframe-Attribute</p> <code>{}</code> Source code in <code>toolboxv2/utils/extras/base_widget.py</code> <pre><code>def register_iframe(self, iframe_id: str, src: str, width: str = \"100%\", height: str = \"500px\", **kwargs):\n    \"\"\"\n    Registriert einen iframe mit gegebener ID und Quelle\n\n    Args:\n        iframe_id: Eindeutige ID f\u00fcr den iframe\n        src: URL oder Pfad zur Quelle des iframes\n        width: Breite des iframes (default: \"100%\")\n        height: H\u00f6he des iframes (default: \"500px\")\n        **kwargs: Weitere iframe-Attribute\n    \"\"\"\n    iframe_config = {\n        'src': src,\n        'width': width,\n        'height': height,\n        **kwargs\n    }\n    self.iframes[iframe_id] = iframe_config\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.extras.blobs","title":"<code>blobs</code>","text":""},{"location":"toolboxv2/#toolboxv2.utils.extras.blobs.BlobFile","title":"<code>BlobFile</code>","text":"Source code in <code>toolboxv2/utils/extras/blobs.py</code> <pre><code>class BlobFile(io.IOBase):\n    def __init__(self, filename: str, mode: str = 'r', storage: BlobStorage = None, key: str = None,\n                 servers: list[str] = None):\n        if not isinstance(filename, str) or not filename:\n            raise ValueError(\"Filename must be a non-empty string.\")\n        if not filename.startswith('/'): filename = '/' + filename\n        self.filename = filename.lstrip('/\\\\')\n        self.blob_id, self.folder, self.datei = self._path_splitter(self.filename)\n        self.mode = mode\n\n        if storage is None:\n            # In a real app, dependency injection or a global factory would be better\n            # but this provides a fallback for simple scripts.\n            if not servers:\n                from toolboxv2 import get_app\n                storage = get_app(from_=\"BlobStorage\").root_blob_storage\n            else:\n                storage = BlobStorage(servers=servers)\n\n        self.storage = storage\n        self.data_buffer = b\"\"\n        self.key = key\n        if key:\n            try:\n                assert Code.decrypt_symmetric(Code.encrypt_symmetric(b\"test\", key), key, to_str=False) == b\"test\"\n            except Exception:\n                raise ValueError(\"Invalid symmetric key provided.\")\n\n    @staticmethod\n    def _path_splitter(filename):\n        parts = Path(filename).parts\n        if not parts: raise ValueError(\"Filename cannot be empty.\")\n        blob_id = parts[0]\n        if len(parts) == 1: raise ValueError(\"Filename must include a path within the blob, e.g., 'blob_id/file.txt'\")\n        datei = parts[-1]\n        folder = '|'.join(parts[1:-1])\n        return blob_id, folder, datei\n\n    def create(self):\n        self.storage.create_blob(pickle.dumps({}), self.blob_id)\n        return self\n\n    def __enter__(self):\n        try:\n            raw_blob_data = self.storage.read_blob(self.blob_id)\n            if raw_blob_data != b'' and (not raw_blob_data or raw_blob_data is None):\n                raw_blob_data = b\"\"\n            blob_content = pickle.loads(raw_blob_data)\n        except (requests.exceptions.HTTPError, EOFError, pickle.UnpicklingError, ConnectionError) as e:\n            if isinstance(e, requests.exceptions.HTTPError) and e.response.status_code == 404:\n                blob_content = {}  # Blob doesn't exist yet, treat as empty\n            elif isinstance(e, EOFError | pickle.UnpicklingError):\n                blob_content = {}  # Blob is empty or corrupt, treat as empty for writing\n            else:\n                self.storage.create_blob(blob_id=self.blob_id, data=pickle.dumps({}))\n                blob_content = {}\n\n        if 'r' in self.mode:\n            path_key = self.folder if self.folder else self.datei\n            if self.folder:\n                file_data = blob_content.get(self.folder, {}).get(self.datei)\n            else:\n                file_data = blob_content.get(self.datei)\n\n            if file_data:\n                self.data_buffer = file_data\n                if self.key:\n                    self.data_buffer = Code.decrypt_symmetric(self.data_buffer, self.key, to_str=False)\n        return self\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        if 'w' in self.mode:\n            final_data = self.data_buffer\n            if self.key:\n                final_data = Code.encrypt_symmetric(final_data, self.key)\n\n            try:\n                raw_blob_data = self.storage.read_blob(self.blob_id)\n                blob_content = pickle.loads(raw_blob_data)\n            except Exception:\n                blob_content = {}\n\n            # Safely navigate and create path\n            current_level = blob_content\n            if self.folder:\n                if self.folder not in current_level:\n                    current_level[self.folder] = {}\n                current_level = current_level[self.folder]\n\n            current_level[self.datei] = final_data\n            self.storage.update_blob(self.blob_id, pickle.dumps(blob_content))\n\n\n\n\n    def exists(self) -&gt; bool:\n        \"\"\"\n        Checks if the specific file path exists within the blob without reading its content.\n        This is an efficient, read-only operation.\n\n        Returns:\n            bool: True if the file exists within the blob, False otherwise.\n        \"\"\"\n        try:\n            # Fetch the raw blob data. This leverages the local cache if available.\n            raw_blob_data = self.storage.read_blob(self.blob_id)\n            # Unpickle the directory structure.\n            if raw_blob_data:\n                blob_content = pickle.loads(raw_blob_data)\n            else:\n                return False\n        except (requests.exceptions.HTTPError, EOFError, pickle.UnpicklingError, ConnectionError):\n            # If the blob itself doesn't exist, is empty, or can't be reached,\n            # then the file within it cannot exist.\n            return False\n\n        # Navigate the dictionary to check for the file's existence.\n        current_level = blob_content\n        if self.folder:\n            if self.folder not in current_level:\n                return False\n            current_level = current_level[self.folder]\n\n        return self.datei in current_level\n\n    def clear(self):\n        self.data_buffer = b''\n\n    def write(self, data):\n        if 'w' not in self.mode: raise OSError(\"File not opened in write mode.\")\n        if isinstance(data, str):\n            self.data_buffer += data.encode()\n        elif isinstance(data, bytes):\n            self.data_buffer += data\n        else:\n            raise TypeError(\"write() argument must be str or bytes\")\n\n    def read(self):\n        if 'r' not in self.mode: raise OSError(\"File not opened in read mode.\")\n        return self.data_buffer\n\n    def read_json(self):\n        if 'r' not in self.mode: raise ValueError(\"File not opened in read mode.\")\n        if self.data_buffer == b\"\": return {}\n        return json.loads(self.data_buffer.decode())\n\n    def write_json(self, data):\n        if 'w' not in self.mode: raise ValueError(\"File not opened in write mode.\")\n        self.data_buffer += json.dumps(data).encode()\n\n    def read_pickle(self):\n        if 'r' not in self.mode: raise ValueError(\"File not opened in read mode.\")\n        if self.data_buffer == b\"\": return {}\n        return pickle.loads(self.data_buffer)\n\n    def write_pickle(self, data):\n        if 'w' not in self.mode: raise ValueError(\"File not opened in write mode.\")\n        self.data_buffer += pickle.dumps(data)\n\n    def read_yaml(self):\n        if 'r' not in self.mode: raise ValueError(\"File not opened in read mode.\")\n        if self.data_buffer == b\"\": return {}\n        return yaml.safe_load(self.data_buffer)\n\n    def write_yaml(self, data):\n        if 'w' not in self.mode: raise ValueError(\"File not opened in write mode.\")\n        yaml.dump(data, self)\n</code></pre> <code>exists()</code> \u00b6 <p>Checks if the specific file path exists within the blob without reading its content. This is an efficient, read-only operation.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the file exists within the blob, False otherwise.</p> Source code in <code>toolboxv2/utils/extras/blobs.py</code> <pre><code>def exists(self) -&gt; bool:\n    \"\"\"\n    Checks if the specific file path exists within the blob without reading its content.\n    This is an efficient, read-only operation.\n\n    Returns:\n        bool: True if the file exists within the blob, False otherwise.\n    \"\"\"\n    try:\n        # Fetch the raw blob data. This leverages the local cache if available.\n        raw_blob_data = self.storage.read_blob(self.blob_id)\n        # Unpickle the directory structure.\n        if raw_blob_data:\n            blob_content = pickle.loads(raw_blob_data)\n        else:\n            return False\n    except (requests.exceptions.HTTPError, EOFError, pickle.UnpicklingError, ConnectionError):\n        # If the blob itself doesn't exist, is empty, or can't be reached,\n        # then the file within it cannot exist.\n        return False\n\n    # Navigate the dictionary to check for the file's existence.\n    current_level = blob_content\n    if self.folder:\n        if self.folder not in current_level:\n            return False\n        current_level = current_level[self.folder]\n\n    return self.datei in current_level\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.extras.blobs.BlobStorage","title":"<code>BlobStorage</code>","text":"<p>A production-ready client for the distributed blob storage server. It handles communication with a list of server instances, manages a local cache, and implements backoff/retry logic for resilience.</p> Source code in <code>toolboxv2/utils/extras/blobs.py</code> <pre><code>class BlobStorage:\n    \"\"\"\n    A production-ready client for the distributed blob storage server.\n    It handles communication with a list of server instances, manages a local cache,\n    and implements backoff/retry logic for resilience.\n    \"\"\"\n\n    def __init__(self, servers: list[str], storage_directory: str = './.data/blob_cache'):\n\n\n        self.servers = servers\n        self.session = requests.Session()\n        self.storage_directory = storage_directory\n        self.blob_ids = []\n        os.makedirs(storage_directory, exist_ok=True)\n\n        # Initialize the consistent hash ring\n        self.hash_ring = ConsistentHashRing()\n        for server in self.servers:\n            self.hash_ring.add_node(server)\n\n    def _make_request(self, method, endpoint, blob_id: str = None, max_retries=2, **kwargs):\n        \"\"\"\n        Makes a resilient HTTP request to the server cluster.\n        - If a blob_id is provided, it uses the consistent hash ring to find the\n          primary server and subsequent backup servers in a predictable order.\n        - If no blob_id is given (e.g., for broadcast actions), it tries servers randomly.\n        - Implements exponential backoff on server errors.\n        \"\"\"\n        if not self.servers:\n            res = requests.Response()\n            res.status_code = 503\n            res.reason = \"No servers available\"\n            return res\n\n        if blob_id:\n            # Get the ordered list of servers for this specific blob\n            preferred_servers = self.hash_ring.get_nodes_for_key(blob_id)\n        else:\n            # For non-specific requests, shuffle all servers\n            preferred_servers = random.sample(self.servers, len(self.servers))\n\n        last_error = None\n        for attempt in range(max_retries):\n            for server in preferred_servers:\n                url = f\"{server.rstrip('/')}{endpoint}\"\n                try:\n                    # In a targeted request, print which server we are trying\n                    response = self.session.request(method, url, timeout=10, **kwargs)\n\n                    if 500 &lt;= response.status_code &lt; 600:\n                        get_logger().warning(f\"Warning: Server {server} returned status {response.status_code}. Retrying...\")\n                        continue\n                    response.raise_for_status()\n                    return response\n                except requests.exceptions.RequestException as e:\n                    last_error = e\n                    get_logger().warning(f\"Warning: Could not connect to server {server}: {e}. Trying next server.\")\n\n            if attempt &lt; max_retries - 1:\n                wait_time = 2 ** (attempt*0.1)\n                get_logger().warning(f\"Warning: All preferred servers failed. Retrying in {wait_time} seconds...\")\n                time.sleep(wait_time)\n                if len(preferred_servers) == 1 and len(self.servers) &gt; 1:\n                    preferred_servers = random.sample(self.servers, len(self.servers))\n\n        raise ConnectionError(f\"Failed to execute request after {max_retries} attempts. Last error: {last_error}\")\n\n\n    def create_blob(self, data: bytes, blob_id=None) -&gt; str:\n        \"\"\"\n        Creates a new blob. The blob_id is calculated client-side by hashing\n        the content, and the data is sent to the correct server determined\n        by the consistent hash ring. This uses a PUT request, making creation\n        idempotent.\n        \"\"\"\n        # The blob ID is the hash of its content, ensuring content-addressable storage.\n        if not blob_id:\n            blob_id = hashlib.sha256(data).hexdigest()\n\n        # Use PUT, as we now know the blob's final ID/URL.\n        # Pass blob_id to _make_request so it uses the hash ring.\n        print(f\"Creating blob {blob_id} on {self._make_request('PUT', f'/blob/{blob_id}',blob_id=blob_id, data=data).status_code}\")\n        # blob_id = response.text\n        self._save_blob_to_cache(blob_id, data)\n        return blob_id\n\n    def read_blob(self, blob_id: str) -&gt; bytes:\n        cached_data = self._load_blob_from_cache(blob_id)\n        if cached_data is not None:\n            return cached_data\n\n        get_logger().info(f\"Info: Blob '{blob_id}' not in cache, fetching from network.\")\n        # Pass blob_id to _make_request to target the correct server(s).\n        response = self._make_request('GET', f'/blob/{blob_id}', blob_id=blob_id)\n\n        blob_data = response.content\n        self._save_blob_to_cache(blob_id, blob_data)\n        return blob_data\n\n    def update_blob(self, blob_id: str, data: bytes):\n        # Pass blob_id to _make_request to target the correct server(s).\n        response = self._make_request('PUT', f'/blob/{blob_id}', blob_id=blob_id, data=data)\n        self._save_blob_to_cache(blob_id, data)\n        return response\n\n    def delete_blob(self, blob_id: str):\n        # Pass blob_id to _make_request to target the correct server(s).\n        self._make_request('DELETE', f'/blob/{blob_id}', blob_id=blob_id)\n        cache_file = self._get_blob_cache_filename(blob_id)\n        if os.path.exists(cache_file):\n            os.remove(cache_file)\n\n    # NOTE: share_blobs and recover_blob are coordination endpoints. They do not\n    # act on a single blob, so they will continue to use the non-targeted (random)\n    # request mode to contact any available server to act as a coordinator.\n    def share_blobs(self, blob_ids: list[str]):\n        get_logger().info(f\"Info: Instructing a server to share blobs for recovery: {blob_ids}\")\n        payload = {\"blob_ids\": blob_ids}\n        # No blob_id passed, will try any server as a coordinator.\n        self._make_request('POST', '/share', json=payload)\n        get_logger().info(\"Info: Sharing command sent successfully.\")\n\n    def recover_blob(self, lost_blob_id: str) -&gt; bytes:\n        get_logger().info(f\"Info: Attempting to recover '{lost_blob_id}' from the cluster.\")\n        payload = {\"blob_id\": lost_blob_id}\n        # No blob_id passed, recovery can be initiated by any server.\n        response = self._make_request('POST', '/recover', json=payload)\n\n        recovered_data = response.content\n        get_logger().info(f\"Info: Successfully recovered blob '{lost_blob_id}'.\")\n        self._save_blob_to_cache(lost_blob_id, recovered_data)\n        return recovered_data\n\n    def _get_blob_cache_filename(self, blob_id: str) -&gt; str:\n        return os.path.join(self.storage_directory, blob_id + '.blobcache')\n\n    def _save_blob_to_cache(self, blob_id: str, data: bytes):\n        if not data or data is None:\n            return\n        if blob_id not in self.blob_ids:\n            self.blob_ids.append(blob_id)\n        with open(self._get_blob_cache_filename(blob_id), 'wb') as f:\n            f.write(data)\n\n    def _load_blob_from_cache(self, blob_id: str) -&gt; bytes | None:\n        cache_file = self._get_blob_cache_filename(blob_id)\n        if not os.path.exists(cache_file):\n            return None\n        with open(cache_file, 'rb') as f:\n            return f.read()\n\n    def exit(self):\n        if len(self.blob_ids) &lt; 5:\n            return\n        for _i in range(len(self.servers)//2+1):\n            self.share_blobs(self.blob_ids)\n</code></pre> <code>create_blob(data, blob_id=None)</code> \u00b6 <p>Creates a new blob. The blob_id is calculated client-side by hashing the content, and the data is sent to the correct server determined by the consistent hash ring. This uses a PUT request, making creation idempotent.</p> Source code in <code>toolboxv2/utils/extras/blobs.py</code> <pre><code>def create_blob(self, data: bytes, blob_id=None) -&gt; str:\n    \"\"\"\n    Creates a new blob. The blob_id is calculated client-side by hashing\n    the content, and the data is sent to the correct server determined\n    by the consistent hash ring. This uses a PUT request, making creation\n    idempotent.\n    \"\"\"\n    # The blob ID is the hash of its content, ensuring content-addressable storage.\n    if not blob_id:\n        blob_id = hashlib.sha256(data).hexdigest()\n\n    # Use PUT, as we now know the blob's final ID/URL.\n    # Pass blob_id to _make_request so it uses the hash ring.\n    print(f\"Creating blob {blob_id} on {self._make_request('PUT', f'/blob/{blob_id}',blob_id=blob_id, data=data).status_code}\")\n    # blob_id = response.text\n    self._save_blob_to_cache(blob_id, data)\n    return blob_id\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.extras.blobs.ConsistentHashRing","title":"<code>ConsistentHashRing</code>","text":"<p>A consistent hash ring implementation to map keys (blob_ids) to nodes (servers). It uses virtual nodes (replicas) to ensure a more uniform distribution of keys.</p> Source code in <code>toolboxv2/utils/extras/blobs.py</code> <pre><code>class ConsistentHashRing:\n    \"\"\"\n    A consistent hash ring implementation to map keys (blob_ids) to nodes (servers).\n    It uses virtual nodes (replicas) to ensure a more uniform distribution of keys.\n    \"\"\"\n    def __init__(self, replicas=100):\n        \"\"\"\n        :param replicas: The number of virtual nodes for each physical node.\n                         Higher values lead to more balanced distribution.\n        \"\"\"\n        self.replicas = replicas\n        self._keys = []  # Sorted list of hash values (the ring)\n        self._nodes = {} # Maps hash values to physical node URLs\n\n    def _hash(self, key: str) -&gt; int:\n        \"\"\"Hashes a key to an integer using md5 for speed and distribution.\"\"\"\n        return int(hashlib.md5(key.encode('utf-8')).hexdigest(), 16)\n\n    def add_node(self, node: str):\n        \"\"\"Adds a physical node to the hash ring.\"\"\"\n        for i in range(self.replicas):\n            vnode_key = f\"{node}:{i}\"\n            h = self._hash(vnode_key)\n            bisect.insort(self._keys, h)\n            self._nodes[h] = node\n\n    def get_nodes_for_key(self, key: str) -&gt; list[str]:\n        \"\"\"\n        Returns an ordered list of nodes responsible for the given key.\n        The first node in the list is the primary, the rest are failover candidates\n        in preferential order.\n        \"\"\"\n        if not self._nodes:\n            return []\n\n        h = self._hash(key)\n        start_idx = bisect.bisect_left(self._keys, h)\n\n        # Collect unique physical nodes by iterating around the ring\n        found_nodes = []\n        for i in range(len(self._keys)):\n            idx = (start_idx + i) % len(self._keys)\n            node_hash = self._keys[idx]\n            physical_node = self._nodes[node_hash]\n            if physical_node not in found_nodes:\n                found_nodes.append(physical_node)\n            # Stop when we have found all unique physical nodes\n            if len(found_nodes) == len(set(self._nodes.values())):\n                break\n        return found_nodes\n</code></pre> <code>__init__(replicas=100)</code> \u00b6 <p>:param replicas: The number of virtual nodes for each physical node.                  Higher values lead to more balanced distribution.</p> Source code in <code>toolboxv2/utils/extras/blobs.py</code> <pre><code>def __init__(self, replicas=100):\n    \"\"\"\n    :param replicas: The number of virtual nodes for each physical node.\n                     Higher values lead to more balanced distribution.\n    \"\"\"\n    self.replicas = replicas\n    self._keys = []  # Sorted list of hash values (the ring)\n    self._nodes = {} # Maps hash values to physical node URLs\n</code></pre> <code>add_node(node)</code> \u00b6 <p>Adds a physical node to the hash ring.</p> Source code in <code>toolboxv2/utils/extras/blobs.py</code> <pre><code>def add_node(self, node: str):\n    \"\"\"Adds a physical node to the hash ring.\"\"\"\n    for i in range(self.replicas):\n        vnode_key = f\"{node}:{i}\"\n        h = self._hash(vnode_key)\n        bisect.insort(self._keys, h)\n        self._nodes[h] = node\n</code></pre> <code>get_nodes_for_key(key)</code> \u00b6 <p>Returns an ordered list of nodes responsible for the given key. The first node in the list is the primary, the rest are failover candidates in preferential order.</p> Source code in <code>toolboxv2/utils/extras/blobs.py</code> <pre><code>def get_nodes_for_key(self, key: str) -&gt; list[str]:\n    \"\"\"\n    Returns an ordered list of nodes responsible for the given key.\n    The first node in the list is the primary, the rest are failover candidates\n    in preferential order.\n    \"\"\"\n    if not self._nodes:\n        return []\n\n    h = self._hash(key)\n    start_idx = bisect.bisect_left(self._keys, h)\n\n    # Collect unique physical nodes by iterating around the ring\n    found_nodes = []\n    for i in range(len(self._keys)):\n        idx = (start_idx + i) % len(self._keys)\n        node_hash = self._keys[idx]\n        physical_node = self._nodes[node_hash]\n        if physical_node not in found_nodes:\n            found_nodes.append(physical_node)\n        # Stop when we have found all unique physical nodes\n        if len(found_nodes) == len(set(self._nodes.values())):\n            break\n    return found_nodes\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.extras.gist_control","title":"<code>gist_control</code>","text":""},{"location":"toolboxv2/#toolboxv2.utils.extras.gist_control.GistLoader","title":"<code>GistLoader</code>","text":"Source code in <code>toolboxv2/utils/extras/gist_control.py</code> <pre><code>class GistLoader:\n    def __init__(self, gist_url):\n        self.gist_url = gist_url\n        self.module_code = None\n\n    def load_module(self, module_name):\n        \"\"\"L\u00e4dt das Modul mit dem gegebenen Namen.\"\"\"\n        if self.module_code is None:\n            self.module_code = self._fetch_gist_content()\n\n        # Erstelle ein neues Modul\n        module = importlib.util.module_from_spec(self.get_spec(module_name))\n        exec(self.module_code, module.__dict__)\n        return module\n\n    def get_spec(self, module_name):\n        \"\"\"Gibt die Modul-Specifikation zur\u00fcck.\"\"\"\n        return ModuleSpec(module_name, self)\n\n    def get_filename(self, module_name):\n        return f\"&lt;gist:{self.gist_url}&gt;\"\n\n    def _fetch_gist_content(self):\n        \"\"\"L\u00e4dt den Inhalt des Gists von der GitHub API herunter.\"\"\"\n        gist_id = self.gist_url.split('/')[-1]\n        api_url = f\"https://api.github.com/gists/{gist_id}\"\n\n        response = requests.get(api_url)\n\n        if response.status_code == 200:\n            gist_data = response.json()\n            first_file = next(iter(gist_data['files'].values()))\n            return first_file['content']\n        else:\n            raise Exception(f\"Failed to fetch gist: {response.status_code}\")\n</code></pre> <code>get_spec(module_name)</code> \u00b6 <p>Gibt die Modul-Specifikation zur\u00fcck.</p> Source code in <code>toolboxv2/utils/extras/gist_control.py</code> <pre><code>def get_spec(self, module_name):\n    \"\"\"Gibt die Modul-Specifikation zur\u00fcck.\"\"\"\n    return ModuleSpec(module_name, self)\n</code></pre> <code>load_module(module_name)</code> \u00b6 <p>L\u00e4dt das Modul mit dem gegebenen Namen.</p> Source code in <code>toolboxv2/utils/extras/gist_control.py</code> <pre><code>def load_module(self, module_name):\n    \"\"\"L\u00e4dt das Modul mit dem gegebenen Namen.\"\"\"\n    if self.module_code is None:\n        self.module_code = self._fetch_gist_content()\n\n    # Erstelle ein neues Modul\n    module = importlib.util.module_from_spec(self.get_spec(module_name))\n    exec(self.module_code, module.__dict__)\n    return module\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.extras.helper_test_functions","title":"<code>helper_test_functions</code>","text":""},{"location":"toolboxv2/#toolboxv2.utils.extras.helper_test_functions.generate_edge_value","title":"<code>generate_edge_value(param_type)</code>","text":"<p>Generiert Edge-Case-Werte basierend auf dem Parametertyp.</p> Source code in <code>toolboxv2/utils/extras/helper_test_functions.py</code> <pre><code>def generate_edge_value(param_type: Any) -&gt; Any:\n    \"\"\"\n    Generiert Edge-Case-Werte basierend auf dem Parametertyp.\n    \"\"\"\n    if param_type in [int, float]:\n        return -999  # Beispiel f\u00fcr negative Zahlen\n    elif param_type == str:\n        return \"test \" * 100  # Lange zuf\u00e4llige Strings\n    # F\u00fcgen Sie hier weitere Bedingungen f\u00fcr andere Datentypen hinzu\n    return None\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.extras.helper_test_functions.generate_normal_value","title":"<code>generate_normal_value(param_type)</code>","text":"<p>Generiert normale Werte basierend auf dem Parametertyp.</p> Source code in <code>toolboxv2/utils/extras/helper_test_functions.py</code> <pre><code>def generate_normal_value(param_type: Any) -&gt; Any:\n    \"\"\"\n    Generiert normale Werte basierend auf dem Parametertyp.\n    \"\"\"\n    from toolboxv2 import RequestData\n    if param_type in [int, float]:\n        return random.randint(0, 100)  # Zuf\u00e4llige normale Zahlen\n    elif param_type == str:\n        return \"test\" # Zuf\u00e4lliges Wort\n    elif param_type == RequestData:\n        return RequestData.moc()\n    # F\u00fcgen Sie hier weitere Bedingungen f\u00fcr andere Datentypen hinzu\n    return None\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.extras.keword_matcher","title":"<code>keword_matcher</code>","text":""},{"location":"toolboxv2/#toolboxv2.utils.extras.keword_matcher.calculate_keyword_score","title":"<code>calculate_keyword_score(text, keywords)</code>","text":"<p>Berechnet den Keyword-Score basierend auf der H\u00e4ufigkeit der Keywords im Text. Case-insensitive und optimiert f\u00fcr Geschwindigkeit.</p> <p>:param text: Eingabetext als String :param keywords: Set von Keywords :return: Gesamt-Score als Integer</p> Source code in <code>toolboxv2/utils/extras/keword_matcher.py</code> <pre><code>def calculate_keyword_score(text: str, keywords: set[str]) -&gt; int:\n    \"\"\"\n    Berechnet den Keyword-Score basierend auf der H\u00e4ufigkeit der Keywords im Text.\n    Case-insensitive und optimiert f\u00fcr Geschwindigkeit.\n\n    :param text: Eingabetext als String\n    :param keywords: Set von Keywords\n    :return: Gesamt-Score als Integer\n    \"\"\"\n    # Vorverarbeitung der Keywords\n    keyword_pattern = re.compile(\n        r'\\b(' + '|'.join(re.escape(k.lower()) for k in keywords) + r')\\b',\n        flags=re.IGNORECASE\n    )\n\n    # Erstelle Frequenz-W\u00f6rterbuch\n    freq_dict = defaultdict(int)\n\n    # Finde alle \u00dcbereinstimmungen\n    matches = keyword_pattern.findall(text.lower())\n\n    # Z\u00e4hle die Treffer\n    for match in matches:\n        freq_dict[match.lower()] += 1\n\n    # Berechne Gesamt-Score\n    total_score = sum(freq_dict.values())\n\n    return total_score\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.extras.keword_matcher.calculate_weighted_score","title":"<code>calculate_weighted_score(text, keyword_weights)</code>","text":"<p>Berechnet gewichteten Score mit unterschiedlichen Gewichten pro Keyword</p> <p>:param text: Eingabetext :param keyword_weights: Dictionary mit {Keyword: Gewicht} :return: Gewichteter Gesamt-Score</p> Source code in <code>toolboxv2/utils/extras/keword_matcher.py</code> <pre><code>def calculate_weighted_score(text: str, keyword_weights: dict or list) -&gt; float:\n    \"\"\"\n    Berechnet gewichteten Score mit unterschiedlichen Gewichten pro Keyword\n\n    :param text: Eingabetext\n    :param keyword_weights: Dictionary mit {Keyword: Gewicht}\n    :return: Gewichteter Gesamt-Score\n    \"\"\"\n    total = 0.0\n    text_lower = text.lower()\n\n    if isinstance(keyword_weights, list):\n        keyword_weights = {k:v for k, v in keyword_weights}\n\n    for keyword, weight in keyword_weights.items():\n        count = len(re.findall(r'\\b' + re.escape(keyword.lower()) + r'\\b', text_lower))\n        total += count * weight\n\n    return round(total, 2)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.extras.keword_matcher.extract_keywords","title":"<code>extract_keywords(text, max_len=-1, min_word_length=3, with_weights=False, remove_stopwords=True, stopwords=True)</code>","text":"<p>Extrahiert Keywords mit optionaler Frequenzgewichtung</p> <p>:param text: Eingabetext :param max_len: Maximale Anzahl Keywords (-1 = alle) :param min_word_length: Minimale Wortl\u00e4nge :param with_weights: Gibt Wort+Frequenz zur\u00fcck wenn True :param remove_stopwords: Filtert deutsche Stopw\u00f6rter :param german_stopwords: Verwendet deutsche Standard-Stopw\u00f6rter :return: Keywords oder (Keyword, H\u00e4ufigkeit) Paare</p> Source code in <code>toolboxv2/utils/extras/keword_matcher.py</code> <pre><code>def extract_keywords(\n    text: str,\n    max_len: int = -1,\n    min_word_length: int = 3,\n    with_weights: bool = False,\n    remove_stopwords: bool = True,\n    stopwords: bool = True\n) -&gt; list[str] | list[tuple[str, int]]:\n    \"\"\"\n    Extrahiert Keywords mit optionaler Frequenzgewichtung\n\n    :param text: Eingabetext\n    :param max_len: Maximale Anzahl Keywords (-1 = alle)\n    :param min_word_length: Minimale Wortl\u00e4nge\n    :param with_weights: Gibt Wort+Frequenz zur\u00fcck wenn True\n    :param remove_stopwords: Filtert deutsche Stopw\u00f6rter\n    :param german_stopwords: Verwendet deutsche Standard-Stopw\u00f6rter\n    :return: Keywords oder (Keyword, H\u00e4ufigkeit) Paare\n    \"\"\"\n\n    # Deutsche Basis-Stopw\u00f6rter\n    DEFAULT_STOPWORDS = STOPWORDS if stopwords else set()\n\n    # Text vorverarbeiten\n    words = re.findall(r'\\b\\w+\\b', text.lower())\n\n    # Worte filtern\n    filtered_words = [\n        word for word in words\n        if len(word) &gt; min_word_length\n           and (not remove_stopwords or word not in DEFAULT_STOPWORDS)\n    ]\n\n    # Frequenzanalyse\n    word_counts = defaultdict(int)\n    for word in filtered_words:\n        word_counts[word] += 1\n\n    # Sortierung: Zuerst H\u00e4ufigkeit, dann alphabetisch\n    sorted_words = sorted(\n        word_counts.items(),\n        key=lambda x: (-x[1], x[0])\n    )\n\n    # L\u00e4ngenbegrenzung\n    if max_len == -1:\n        max_len = None\n    result = sorted_words[:max_len]\n\n    return result if with_weights else [word for word, _ in result]\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.extras.reqbuilder","title":"<code>reqbuilder</code>","text":""},{"location":"toolboxv2/#toolboxv2.utils.extras.reqbuilder.generate_requirements","title":"<code>generate_requirements(folder, output_file)</code>","text":"<p>Generates requirements.txt for the specified folder using pipreqs.</p> Source code in <code>toolboxv2/utils/extras/reqbuilder.py</code> <pre><code>def generate_requirements(folder: str, output_file: str):\n    \"\"\"Generates requirements.txt for the specified folder using pipreqs.\"\"\"\n    print(folder, output_file, os.path.abspath(os.curdir))\n    try:\n        from pipreqs.pipreqs import get_all_imports\n    except ImportError:\n        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"pipreqs\"], check=True)\n    from pipreqs.pipreqs import get_all_imports\n    imports = set(get_all_imports(os.path.abspath(folder)))\n    imports.remove('toolboxv2') if 'toolboxv2' in imports else None\n    with open(os.path.abspath(output_file), \"w\") as f:\n        f.write(\"\\n\".join(imports))\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.extras.reqbuilder.run_pipeline","title":"<code>run_pipeline(base_dir)</code>","text":"<p>Runs the entire pipeline to generate requirements files.</p> Source code in <code>toolboxv2/utils/extras/reqbuilder.py</code> <pre><code>def run_pipeline(base_dir: str):\n    \"\"\"Runs the entire pipeline to generate requirements files.\"\"\"\n    toolbox_path = os.path.join(base_dir, \"toolboxv2\")\n    utils_path = os.path.join(toolbox_path, \"utils\")\n    mini_req_file = os.path.join(base_dir, \"requirements_mini.txt\")\n    extras_req_file = os.path.join(base_dir, \"requirements_tests.txt\")\n\n    # Step 1: Generate minimal requirements\n    print(\"Step 1/2: \")\n    generate_requirements(utils_path, mini_req_file)\n\n    # Step 2: Generate extended requirements\n    print(\"Step 2/2: \")\n    extras_path = os.path.join(toolbox_path, \"tests\")\n    generate_requirements(extras_path, extras_req_file)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.proxy","title":"<code>proxy</code>","text":""},{"location":"toolboxv2/#toolboxv2.utils.proxy.ProxyUtil","title":"<code>ProxyUtil</code>","text":"Source code in <code>toolboxv2/utils/proxy/prox_util.py</code> <pre><code>class ProxyUtil:\n    def __init__(self, *args, **kwargs):\n        \"\"\"\n        Standard constructor used for arguments pass\n        Do not override. Use __ainit__ instead\n        \"\"\"\n        self.__storedargs = args, kwargs\n        self.async_initialized = False\n\n    async def __initobj(self):\n        \"\"\"Crutch used for __await__ after spawning\"\"\"\n        # assert not self.async_initialized\n        self.async_initialized = True\n        # pass the parameters to __ainit__ that passed to __init__\n        await self.__ainit__(*self.__storedargs[0], **self.__storedargs[1])\n        return self\n\n    def __await__(self):\n        return self.__initobj().__await__()\n\n    async def __ainit__(self, class_instance: Any, host='0.0.0.0', port=6587, timeout=6,\n                        app: (App or AppType) | None = None,\n                        remote_functions=None, peer=False, name='ProxyApp-client', do_connect=True, unix_socket=False,\n                        test_override=False):\n        self.class_instance = class_instance\n        self.client = None\n        self.test_override = test_override\n        self.port = port\n        self.host = host\n        self.timeout = timeout\n        if app is None:\n            app = get_app(\"ProxyUtil\")\n        self.app = app\n        self._name = name\n        self.unix_socket = unix_socket\n        if remote_functions is None:\n            remote_functions = [\"run_any\", \"a_run_any\", \"remove_mod\", \"save_load\", \"exit_main\", \"show_console\", \"hide_console\",\n                                \"rrun_flow\",\n                                \"get_autocompletion_dict\",\n                                \"exit_main\", \"watch_mod\"]\n        self.remote_functions = remote_functions\n\n        from toolboxv2.mods.SocketManager import SocketType\n        self.connection_type = SocketType.client\n        if peer:\n            self.connection_type = SocketType.peer\n        if do_connect:\n            await self.connect()\n\n    async def connect(self):\n        client_result = await self.app.a_run_local(SOCKETMANAGER.CREATE_SOCKET,\n                                           get_results=True,\n                                           name=self._name,\n                                           host=self.host,\n                                           port=self.port,\n                                           type_id=self.connection_type,\n                                           max_connections=-1,\n                                           return_full_object=True,\n                                           test_override=self.test_override,\n                                           unix_file=self.unix_socket)\n\n        if client_result.is_error():\n            raise Exception(f\"Client {self._name} error: {client_result.print(False)}\")\n        if not client_result.is_data():\n            raise Exception(f\"Client {self._name} error: {client_result.print(False)}\")\n        # 'socket': socket,\n        # 'receiver_socket': r_socket,\n        # 'host': host,\n        # 'port': port,\n        # 'p2p-port': endpoint_port,\n        # 'sender': send,\n        # 'receiver_queue': receiver_queue,\n        # 'connection_error': connection_error,\n        # 'receiver_thread': s_thread,\n        # 'keepalive_thread': keep_alive_thread,\n        # 'running_dict': running_dict,\n        # 'client_to_receiver_thread': to_receive,\n        # 'client_receiver_threads': threeds,\n        result = await client_result.aget()\n        if result is None or result.get('connection_error') != 0:\n            raise Exception(f\"Client {self._name} error: {client_result.print(False)}\")\n        self.client = Result.ok(result)\n\n    async def disconnect(self):\n        time.sleep(1)\n        close = self.client.get(\"close\")\n        await close()\n        self.client = None\n\n    async def reconnect(self):\n        if self.client is not None:\n            await self.disconnect()\n        await self.connect()\n\n    async def verify(self, message=b\"verify\"):\n        await asyncio.sleep(1)\n        # self.client.get('sender')({'keepalive': 0})\n        await self.client.get('sender')(message)\n\n    def __getattr__(self, name):\n\n        # print(f\"ProxyApp: {name}, {self.client is None}\")\n        if name == \"on_exit\":\n            return self.disconnect\n        if name == \"rc\":\n            return self.reconnect\n\n        if name == \"r\":\n            try:\n                return self.client.get('receiver_queue').get(timeout=self.timeout)\n            except:\n                return \"No data\"\n\n        app_attr = getattr(self.class_instance, name)\n\n        async def method(*args, **kwargs):\n            # if name == 'run_any':\n            #     print(\"method\", name, kwargs.get('get_results', False), args[0])\n            if self.client is None:\n                await self.reconnect()\n            if kwargs.get('spec', '-') == 'app':\n                if asyncio.iscoroutinefunction(app_attr):\n                    return await app_attr(*args, **kwargs)\n                return app_attr(*args, **kwargs)\n            try:\n                if name in self.remote_functions:\n                    if (name == 'run_any' or name == 'a_run_any') and not kwargs.get('get_results', False):\n                        if asyncio.iscoroutinefunction(app_attr):\n                            return await app_attr(*args, **kwargs)\n                        return app_attr(*args, **kwargs)\n                    if (name == 'run_any' or name == 'a_run_any') and kwargs.get('get_results', False):\n                        if isinstance(args[0], Enum):\n                            args = (args[0].__class__.NAME.value, args[0].value), args[1:]\n                    self.app.sprint(f\"Calling method {name}, {args=}, {kwargs}=\")\n                    await self.client.get('sender')({'name': name, 'args': args, 'kwargs': kwargs})\n                    while Spinner(\"Waiting for result\"):\n                        try:\n                            data = self.client.get('receiver_queue').get(timeout=self.timeout)\n                            if isinstance(data, dict) and 'identifier' in data:\n                                del data[\"identifier\"]\n                            if 'error' in data and 'origin' in data and 'result' in data and 'info' in data:\n                                data = ApiResult(**data).as_result()\n                            return data\n                        except:\n                            print(\"No data look later with class_instance.r\")\n                            return Result.default_internal_error(\"No data received from Demon.\"\n                                                                 \" uns class_instance.r to get data later\")\n            except:\n                if self.client.get('socket') is None:\n                    self.client = None\n            return app_attr(*args, **kwargs)\n\n        if callable(app_attr) and name in self.remote_functions and self.client is not None:\n            return method\n        return app_attr\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.proxy.ProxyUtil.__init__","title":"<code>__init__(*args, **kwargs)</code>","text":"<p>Standard constructor used for arguments pass Do not override. Use ainit instead</p> Source code in <code>toolboxv2/utils/proxy/prox_util.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"\n    Standard constructor used for arguments pass\n    Do not override. Use __ainit__ instead\n    \"\"\"\n    self.__storedargs = args, kwargs\n    self.async_initialized = False\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.proxy.ProxyUtil.__initobj","title":"<code>__initobj()</code>  <code>async</code>","text":"<p>Crutch used for await after spawning</p> Source code in <code>toolboxv2/utils/proxy/prox_util.py</code> <pre><code>async def __initobj(self):\n    \"\"\"Crutch used for __await__ after spawning\"\"\"\n    # assert not self.async_initialized\n    self.async_initialized = True\n    # pass the parameters to __ainit__ that passed to __init__\n    await self.__ainit__(*self.__storedargs[0], **self.__storedargs[1])\n    return self\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.proxy.prox_util","title":"<code>prox_util</code>","text":""},{"location":"toolboxv2/#toolboxv2.utils.proxy.prox_util.ProxyUtil","title":"<code>ProxyUtil</code>","text":"Source code in <code>toolboxv2/utils/proxy/prox_util.py</code> <pre><code>class ProxyUtil:\n    def __init__(self, *args, **kwargs):\n        \"\"\"\n        Standard constructor used for arguments pass\n        Do not override. Use __ainit__ instead\n        \"\"\"\n        self.__storedargs = args, kwargs\n        self.async_initialized = False\n\n    async def __initobj(self):\n        \"\"\"Crutch used for __await__ after spawning\"\"\"\n        # assert not self.async_initialized\n        self.async_initialized = True\n        # pass the parameters to __ainit__ that passed to __init__\n        await self.__ainit__(*self.__storedargs[0], **self.__storedargs[1])\n        return self\n\n    def __await__(self):\n        return self.__initobj().__await__()\n\n    async def __ainit__(self, class_instance: Any, host='0.0.0.0', port=6587, timeout=6,\n                        app: (App or AppType) | None = None,\n                        remote_functions=None, peer=False, name='ProxyApp-client', do_connect=True, unix_socket=False,\n                        test_override=False):\n        self.class_instance = class_instance\n        self.client = None\n        self.test_override = test_override\n        self.port = port\n        self.host = host\n        self.timeout = timeout\n        if app is None:\n            app = get_app(\"ProxyUtil\")\n        self.app = app\n        self._name = name\n        self.unix_socket = unix_socket\n        if remote_functions is None:\n            remote_functions = [\"run_any\", \"a_run_any\", \"remove_mod\", \"save_load\", \"exit_main\", \"show_console\", \"hide_console\",\n                                \"rrun_flow\",\n                                \"get_autocompletion_dict\",\n                                \"exit_main\", \"watch_mod\"]\n        self.remote_functions = remote_functions\n\n        from toolboxv2.mods.SocketManager import SocketType\n        self.connection_type = SocketType.client\n        if peer:\n            self.connection_type = SocketType.peer\n        if do_connect:\n            await self.connect()\n\n    async def connect(self):\n        client_result = await self.app.a_run_local(SOCKETMANAGER.CREATE_SOCKET,\n                                           get_results=True,\n                                           name=self._name,\n                                           host=self.host,\n                                           port=self.port,\n                                           type_id=self.connection_type,\n                                           max_connections=-1,\n                                           return_full_object=True,\n                                           test_override=self.test_override,\n                                           unix_file=self.unix_socket)\n\n        if client_result.is_error():\n            raise Exception(f\"Client {self._name} error: {client_result.print(False)}\")\n        if not client_result.is_data():\n            raise Exception(f\"Client {self._name} error: {client_result.print(False)}\")\n        # 'socket': socket,\n        # 'receiver_socket': r_socket,\n        # 'host': host,\n        # 'port': port,\n        # 'p2p-port': endpoint_port,\n        # 'sender': send,\n        # 'receiver_queue': receiver_queue,\n        # 'connection_error': connection_error,\n        # 'receiver_thread': s_thread,\n        # 'keepalive_thread': keep_alive_thread,\n        # 'running_dict': running_dict,\n        # 'client_to_receiver_thread': to_receive,\n        # 'client_receiver_threads': threeds,\n        result = await client_result.aget()\n        if result is None or result.get('connection_error') != 0:\n            raise Exception(f\"Client {self._name} error: {client_result.print(False)}\")\n        self.client = Result.ok(result)\n\n    async def disconnect(self):\n        time.sleep(1)\n        close = self.client.get(\"close\")\n        await close()\n        self.client = None\n\n    async def reconnect(self):\n        if self.client is not None:\n            await self.disconnect()\n        await self.connect()\n\n    async def verify(self, message=b\"verify\"):\n        await asyncio.sleep(1)\n        # self.client.get('sender')({'keepalive': 0})\n        await self.client.get('sender')(message)\n\n    def __getattr__(self, name):\n\n        # print(f\"ProxyApp: {name}, {self.client is None}\")\n        if name == \"on_exit\":\n            return self.disconnect\n        if name == \"rc\":\n            return self.reconnect\n\n        if name == \"r\":\n            try:\n                return self.client.get('receiver_queue').get(timeout=self.timeout)\n            except:\n                return \"No data\"\n\n        app_attr = getattr(self.class_instance, name)\n\n        async def method(*args, **kwargs):\n            # if name == 'run_any':\n            #     print(\"method\", name, kwargs.get('get_results', False), args[0])\n            if self.client is None:\n                await self.reconnect()\n            if kwargs.get('spec', '-') == 'app':\n                if asyncio.iscoroutinefunction(app_attr):\n                    return await app_attr(*args, **kwargs)\n                return app_attr(*args, **kwargs)\n            try:\n                if name in self.remote_functions:\n                    if (name == 'run_any' or name == 'a_run_any') and not kwargs.get('get_results', False):\n                        if asyncio.iscoroutinefunction(app_attr):\n                            return await app_attr(*args, **kwargs)\n                        return app_attr(*args, **kwargs)\n                    if (name == 'run_any' or name == 'a_run_any') and kwargs.get('get_results', False):\n                        if isinstance(args[0], Enum):\n                            args = (args[0].__class__.NAME.value, args[0].value), args[1:]\n                    self.app.sprint(f\"Calling method {name}, {args=}, {kwargs}=\")\n                    await self.client.get('sender')({'name': name, 'args': args, 'kwargs': kwargs})\n                    while Spinner(\"Waiting for result\"):\n                        try:\n                            data = self.client.get('receiver_queue').get(timeout=self.timeout)\n                            if isinstance(data, dict) and 'identifier' in data:\n                                del data[\"identifier\"]\n                            if 'error' in data and 'origin' in data and 'result' in data and 'info' in data:\n                                data = ApiResult(**data).as_result()\n                            return data\n                        except:\n                            print(\"No data look later with class_instance.r\")\n                            return Result.default_internal_error(\"No data received from Demon.\"\n                                                                 \" uns class_instance.r to get data later\")\n            except:\n                if self.client.get('socket') is None:\n                    self.client = None\n            return app_attr(*args, **kwargs)\n\n        if callable(app_attr) and name in self.remote_functions and self.client is not None:\n            return method\n        return app_attr\n</code></pre> <code>__init__(*args, **kwargs)</code> \u00b6 <p>Standard constructor used for arguments pass Do not override. Use ainit instead</p> Source code in <code>toolboxv2/utils/proxy/prox_util.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"\n    Standard constructor used for arguments pass\n    Do not override. Use __ainit__ instead\n    \"\"\"\n    self.__storedargs = args, kwargs\n    self.async_initialized = False\n</code></pre> <code>__initobj()</code> <code>async</code> \u00b6 <p>Crutch used for await after spawning</p> Source code in <code>toolboxv2/utils/proxy/prox_util.py</code> <pre><code>async def __initobj(self):\n    \"\"\"Crutch used for __await__ after spawning\"\"\"\n    # assert not self.async_initialized\n    self.async_initialized = True\n    # pass the parameters to __ainit__ that passed to __init__\n    await self.__ainit__(*self.__storedargs[0], **self.__storedargs[1])\n    return self\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.security","title":"<code>security</code>","text":""},{"location":"toolboxv2/#toolboxv2.utils.security.Code","title":"<code>Code</code>","text":"Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>class Code:\n\n    @staticmethod\n    def DK():\n        return DEVICE_KEY\n\n    def decode_code(self, encrypted_data, key=None):\n\n        if not isinstance(encrypted_data, str):\n            encrypted_data = str(encrypted_data)\n\n        if key is None:\n            key = DEVICE_KEY()\n\n        return self.decrypt_symmetric(encrypted_data, key)\n\n    def encode_code(self, data, key=None):\n\n        if not isinstance(data, str):\n            data = str(data)\n\n        if key is None:\n            key = DEVICE_KEY()\n\n        return self.encrypt_symmetric(data, key)\n\n    @staticmethod\n    def generate_seed() -&gt; int:\n        \"\"\"\n        Erzeugt eine zuf\u00e4llige Zahl als Seed.\n\n        Returns:\n            int: Eine zuf\u00e4llige Zahl.\n        \"\"\"\n        return random.randint(2 ** 32 - 1, 2 ** 64 - 1)\n\n    @staticmethod\n    def one_way_hash(text: str, salt: str = '', pepper: str = '') -&gt; str:\n        \"\"\"\n        Erzeugt einen Hash eines gegebenen Textes mit Salt, Pepper und optional einem Seed.\n\n        Args:\n            text (str): Der zu hashende Text.\n            salt (str): Der Salt-Wert.\n            pepper (str): Der Pepper-Wert.\n            seed (int, optional): Ein optionaler Seed-Wert. Standardm\u00e4\u00dfig None.\n\n        Returns:\n            str: Der resultierende Hash-Wert.\n        \"\"\"\n        return hashlib.sha256((salt + text + pepper).encode()).hexdigest()\n\n    @staticmethod\n    def generate_symmetric_key(as_str=True) -&gt; str or bytes:\n        \"\"\"\n        Generiert einen Schl\u00fcssel f\u00fcr die symmetrische Verschl\u00fcsselung.\n\n        Returns:\n            str: Der generierte Schl\u00fcssel.\n        \"\"\"\n        key = Fernet.generate_key()\n        if as_str:\n            key = key.decode()\n        return key\n\n    @staticmethod\n    def encrypt_symmetric(text: str or bytes, key: str) -&gt; str:\n        \"\"\"\n        Verschl\u00fcsselt einen Text mit einem gegebenen symmetrischen Schl\u00fcssel.\n\n        Args:\n            text (str): Der zu verschl\u00fcsselnde Text.\n            key (str): Der symmetrische Schl\u00fcssel.\n\n        Returns:\n            str: Der verschl\u00fcsselte Text.\n        \"\"\"\n        if isinstance(text, str):\n            text = text.encode()\n\n        try:\n            fernet = Fernet(key.encode())\n            return fernet.encrypt(text).decode()\n        except Exception as e:\n            get_logger().error(f\"Error encrypt_symmetric #{str(e)}#\")\n            return \"Error encrypt\"\n\n    @staticmethod\n    def decrypt_symmetric(encrypted_text: str, key: str, to_str=True, mute=False) -&gt; str or bytes:\n        \"\"\"\n        Entschl\u00fcsselt einen Text mit einem gegebenen symmetrischen Schl\u00fcssel.\n\n        Args:\n            encrypted_text (str): Der zu entschl\u00fcsselnde Text.\n            key (str): Der symmetrische Schl\u00fcssel.\n            to_str (bool): default true returns str if false returns bytes\n        Returns:\n            str: Der entschl\u00fcsselte Text.\n        \"\"\"\n\n        if isinstance(key, str):\n            key = key.encode()\n\n        #try:\n        fernet = Fernet(key)\n        text_b = fernet.decrypt(encrypted_text)\n        if not to_str:\n            return text_b\n        return text_b.decode()\n        # except Exception as e:\n        #     get_logger().error(f\"Error decrypt_symmetric {e}\")\n        #     if not mute:\n        #         raise e\n        #     if not to_str:\n        #         return f\"Error decoding\".encode()\n        #     return f\"Error decoding\"\n\n    @staticmethod\n    def generate_asymmetric_keys() -&gt; (str, str):\n        \"\"\"\n        Generiert ein Paar von \u00f6ffentlichen und privaten Schl\u00fcsseln f\u00fcr die asymmetrische Verschl\u00fcsselung.\n\n        Args:\n            seed (int, optional): Ein optionaler Seed-Wert. Standardm\u00e4\u00dfig None.\n\n        Returns:\n            (str, str): Ein Tupel aus \u00f6ffentlichem und privatem Schl\u00fcssel.\n        \"\"\"\n        private_key = rsa.generate_private_key(\n            public_exponent=65537,\n            key_size=2048 * 3,\n        )\n        public_key = private_key.public_key()\n\n        # Serialisieren der Schl\u00fcssel\n        pem_private_key = private_key.private_bytes(\n            encoding=serialization.Encoding.PEM,\n            format=serialization.PrivateFormat.PKCS8,\n            encryption_algorithm=serialization.NoEncryption()\n        ).decode()\n\n        pem_public_key = public_key.public_bytes(\n            encoding=serialization.Encoding.PEM,\n            format=serialization.PublicFormat.SubjectPublicKeyInfo\n        ).decode()\n\n        return pem_public_key, pem_private_key\n\n    @staticmethod\n    def save_keys_to_files(public_key: str, private_key: str, directory: str = \"keys\") -&gt; None:\n        \"\"\"\n        Speichert die generierten Schl\u00fcssel in separate Dateien.\n        Der private Schl\u00fcssel wird mit dem Device Key verschl\u00fcsselt.\n\n        Args:\n            public_key (str): Der \u00f6ffentliche Schl\u00fcssel im PEM-Format\n            private_key (str): Der private Schl\u00fcssel im PEM-Format\n            directory (str): Das Verzeichnis, in dem die Schl\u00fcssel gespeichert werden sollen\n        \"\"\"\n        # Erstelle das Verzeichnis, falls es nicht existiert\n        os.makedirs(directory, exist_ok=True)\n\n        # Hole den Device Key\n        device_key = DEVICE_KEY()\n\n        # Verschl\u00fcssele den privaten Schl\u00fcssel mit dem Device Key\n        encrypted_private_key = Code.encrypt_symmetric(private_key, device_key)\n\n        # Speichere den \u00f6ffentlichen Schl\u00fcssel\n        public_key_path = os.path.join(directory, \"public_key.pem\")\n        with open(public_key_path, \"w\") as f:\n            f.write(public_key)\n\n        # Speichere den verschl\u00fcsselten privaten Schl\u00fcssel\n        private_key_path = os.path.join(directory, \"private_key.pem\")\n        with open(private_key_path, \"w\") as f:\n            f.write(encrypted_private_key)\n\n        print(\"Saved keys in \", public_key_path)\n\n    @staticmethod\n    def load_keys_from_files(directory: str = \"keys\") -&gt; (str, str):\n        \"\"\"\n        L\u00e4dt die Schl\u00fcssel aus den Dateien.\n        Der private Schl\u00fcssel wird mit dem Device Key entschl\u00fcsselt.\n\n        Args:\n            directory (str): Das Verzeichnis, aus dem die Schl\u00fcssel geladen werden sollen\n\n        Returns:\n            (str, str): Ein Tupel aus \u00f6ffentlichem und privatem Schl\u00fcssel\n\n        Raises:\n            FileNotFoundError: Wenn die Schl\u00fcsseldateien nicht gefunden werden k\u00f6nnen\n        \"\"\"\n        # Pfade zu den Schl\u00fcsseldateien\n        public_key_path = os.path.join(directory, \"public_key.pem\")\n        private_key_path = os.path.join(directory, \"private_key.pem\")\n\n        # Pr\u00fcfe ob die Dateien existieren\n        if not os.path.exists(public_key_path) or not os.path.exists(private_key_path):\n            return \"\", \"\"\n\n        # Hole den Device Key\n        device_key = DEVICE_KEY()\n\n        # Lade den \u00f6ffentlichen Schl\u00fcssel\n        with open(public_key_path) as f:\n            public_key = f.read()\n\n        # Lade und entschl\u00fcssele den privaten Schl\u00fcssel\n        with open(private_key_path) as f:\n            encrypted_private_key = f.read()\n            private_key = Code.decrypt_symmetric(encrypted_private_key, device_key)\n\n        return public_key, private_key\n\n    @staticmethod\n    def encrypt_asymmetric(text: str, public_key_str: str) -&gt; str:\n        \"\"\"\n        Verschl\u00fcsselt einen Text mit einem gegebenen \u00f6ffentlichen Schl\u00fcssel.\n\n        Args:\n            text (str): Der zu verschl\u00fcsselnde Text.\n            public_key_str (str): Der \u00f6ffentliche Schl\u00fcssel als String oder im pem format.\n\n        Returns:\n            str: Der verschl\u00fcsselte Text.\n        \"\"\"\n        # try:\n        #    public_key: RSAPublicKey = serialization.load_pem_public_key(public_key_str.encode())\n        #  except Exception as e:\n        #     get_logger().error(f\"Error encrypt_asymmetric {e}\")\n        try:\n            public_key: RSAPublicKey = serialization.load_pem_public_key(public_key_str.encode())\n            encrypted = public_key.encrypt(\n                text.encode(),\n                padding.OAEP(\n                    mgf=padding.MGF1(algorithm=hashes.SHA512()),\n                    algorithm=hashes.SHA512(),\n                    label=None\n                )\n            )\n            return encrypted.hex()\n        except Exception as e:\n            get_logger().error(f\"Error encrypt_asymmetric {e}\")\n            return \"Invalid\"\n\n    @staticmethod\n    def decrypt_asymmetric(encrypted_text_hex: str, private_key_str: str) -&gt; str:\n        \"\"\"\n        Entschl\u00fcsselt einen Text mit einem gegebenen privaten Schl\u00fcssel.\n\n        Args:\n            encrypted_text_hex (str): Der verschl\u00fcsselte Text als Hex-String.\n            private_key_str (str): Der private Schl\u00fcssel als String.\n\n        Returns:\n            str: Der entschl\u00fcsselte Text.\n        \"\"\"\n        try:\n            private_key = serialization.load_pem_private_key(private_key_str.encode(), password=None)\n            decrypted = private_key.decrypt(\n                bytes.fromhex(encrypted_text_hex),\n                padding.OAEP(\n                    mgf=padding.MGF1(algorithm=hashes.SHA512()),\n                    algorithm=hashes.SHA512(),\n                    label=None\n                )\n            )\n            return decrypted.decode()\n\n        except Exception as e:\n            get_logger().error(f\"Error decrypt_asymmetric {e}\")\n        return \"Invalid\"\n\n    @staticmethod\n    def verify_signature(signature: str or bytes, message: str or bytes, public_key_str: str,\n                         salt_length=padding.PSS.MAX_LENGTH) -&gt; bool:\n        if isinstance(signature, str):\n            signature = signature.encode()\n        if isinstance(message, str):\n            message = message.encode()\n        try:\n            public_key: RSAPublicKey = serialization.load_pem_public_key(public_key_str.encode())\n            public_key.verify(\n                signature=signature,\n                data=message,\n                padding=padding.PSS(\n                    mgf=padding.MGF1(hashes.SHA512()),\n                    salt_length=salt_length\n                ),\n                algorithm=hashes.SHA512()\n            )\n            return True\n        except:\n            pass\n        return False\n\n    @staticmethod\n    def verify_signature_web_algo(signature: str or bytes, message: str or bytes, public_key_str: str,\n                                  algo: int = -512) -&gt; bool:\n        signature_algorithm = ECDSA(hashes.SHA512())\n        if algo != -512:\n            signature_algorithm = ECDSA(hashes.SHA256())\n\n        if isinstance(signature, str):\n            signature = signature.encode()\n        if isinstance(message, str):\n            message = message.encode()\n        try:\n            public_key = serialization.load_pem_public_key(public_key_str.encode())\n            public_key.verify(\n                signature=signature,\n                data=message,\n                # padding=padding.PSS(\n                #    mgf=padding.MGF1(hashes.SHA512()),\n                #    salt_length=padding.PSS.MAX_LENGTH\n                # ),\n                signature_algorithm=signature_algorithm\n            )\n            return True\n        except:\n            pass\n        return False\n\n    @staticmethod\n    def create_signature(message: str, private_key_str: str, salt_length=padding.PSS.MAX_LENGTH,\n                         row=False) -&gt; str or bytes:\n        try:\n            private_key = serialization.load_pem_private_key(private_key_str.encode(), password=None)\n            signature = private_key.sign(\n                message.encode(),\n                padding.PSS(\n                    mgf=padding.MGF1(hashes.SHA512()),\n                    salt_length=salt_length\n                ),\n                hashes.SHA512()\n            )\n            if row:\n                return signature\n            return base64.b64encode(signature).decode()\n        except Exception as e:\n            get_logger().error(f\"Error create_signature {e}\")\n            print(e)\n        return \"Invalid Key\"\n\n    @staticmethod\n    def pem_to_public_key(pem_key: str):\n        \"\"\"\n        Konvertiert einen PEM-kodierten \u00f6ffentlichen Schl\u00fcssel in ein PublicKey-Objekt.\n\n        Args:\n            pem_key (str): Der PEM-kodierte \u00f6ffentliche Schl\u00fcssel.\n\n        Returns:\n            PublicKey: Das PublicKey-Objekt.\n        \"\"\"\n        public_key = serialization.load_pem_public_key(pem_key.encode())\n        return public_key\n\n    @staticmethod\n    def public_key_to_pem(public_key: RSAPublicKey):\n        \"\"\"\n        Konvertiert ein PublicKey-Objekt in einen PEM-kodierten String.\n\n        Args:\n            public_key (PublicKey): Das PublicKey-Objekt.\n\n        Returns:\n            str: Der PEM-kodierte \u00f6ffentliche Schl\u00fcssel.\n        \"\"\"\n        pem = public_key.public_bytes(\n            encoding=serialization.Encoding.PEM,\n            format=serialization.PublicFormat.SubjectPublicKeyInfo\n        )\n        return pem.decode()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.security.Code.decrypt_asymmetric","title":"<code>decrypt_asymmetric(encrypted_text_hex, private_key_str)</code>  <code>staticmethod</code>","text":"<p>Entschl\u00fcsselt einen Text mit einem gegebenen privaten Schl\u00fcssel.</p> <p>Parameters:</p> Name Type Description Default <code>encrypted_text_hex</code> <code>str</code> <p>Der verschl\u00fcsselte Text als Hex-String.</p> required <code>private_key_str</code> <code>str</code> <p>Der private Schl\u00fcssel als String.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Der entschl\u00fcsselte Text.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef decrypt_asymmetric(encrypted_text_hex: str, private_key_str: str) -&gt; str:\n    \"\"\"\n    Entschl\u00fcsselt einen Text mit einem gegebenen privaten Schl\u00fcssel.\n\n    Args:\n        encrypted_text_hex (str): Der verschl\u00fcsselte Text als Hex-String.\n        private_key_str (str): Der private Schl\u00fcssel als String.\n\n    Returns:\n        str: Der entschl\u00fcsselte Text.\n    \"\"\"\n    try:\n        private_key = serialization.load_pem_private_key(private_key_str.encode(), password=None)\n        decrypted = private_key.decrypt(\n            bytes.fromhex(encrypted_text_hex),\n            padding.OAEP(\n                mgf=padding.MGF1(algorithm=hashes.SHA512()),\n                algorithm=hashes.SHA512(),\n                label=None\n            )\n        )\n        return decrypted.decode()\n\n    except Exception as e:\n        get_logger().error(f\"Error decrypt_asymmetric {e}\")\n    return \"Invalid\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.security.Code.decrypt_symmetric","title":"<code>decrypt_symmetric(encrypted_text, key, to_str=True, mute=False)</code>  <code>staticmethod</code>","text":"<p>Entschl\u00fcsselt einen Text mit einem gegebenen symmetrischen Schl\u00fcssel.</p> <p>Parameters:</p> Name Type Description Default <code>encrypted_text</code> <code>str</code> <p>Der zu entschl\u00fcsselnde Text.</p> required <code>key</code> <code>str</code> <p>Der symmetrische Schl\u00fcssel.</p> required <code>to_str</code> <code>bool</code> <p>default true returns str if false returns bytes</p> <code>True</code> <p>Returns:     str: Der entschl\u00fcsselte Text.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef decrypt_symmetric(encrypted_text: str, key: str, to_str=True, mute=False) -&gt; str or bytes:\n    \"\"\"\n    Entschl\u00fcsselt einen Text mit einem gegebenen symmetrischen Schl\u00fcssel.\n\n    Args:\n        encrypted_text (str): Der zu entschl\u00fcsselnde Text.\n        key (str): Der symmetrische Schl\u00fcssel.\n        to_str (bool): default true returns str if false returns bytes\n    Returns:\n        str: Der entschl\u00fcsselte Text.\n    \"\"\"\n\n    if isinstance(key, str):\n        key = key.encode()\n\n    #try:\n    fernet = Fernet(key)\n    text_b = fernet.decrypt(encrypted_text)\n    if not to_str:\n        return text_b\n    return text_b.decode()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.security.Code.encrypt_asymmetric","title":"<code>encrypt_asymmetric(text, public_key_str)</code>  <code>staticmethod</code>","text":"<p>Verschl\u00fcsselt einen Text mit einem gegebenen \u00f6ffentlichen Schl\u00fcssel.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Der zu verschl\u00fcsselnde Text.</p> required <code>public_key_str</code> <code>str</code> <p>Der \u00f6ffentliche Schl\u00fcssel als String oder im pem format.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Der verschl\u00fcsselte Text.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef encrypt_asymmetric(text: str, public_key_str: str) -&gt; str:\n    \"\"\"\n    Verschl\u00fcsselt einen Text mit einem gegebenen \u00f6ffentlichen Schl\u00fcssel.\n\n    Args:\n        text (str): Der zu verschl\u00fcsselnde Text.\n        public_key_str (str): Der \u00f6ffentliche Schl\u00fcssel als String oder im pem format.\n\n    Returns:\n        str: Der verschl\u00fcsselte Text.\n    \"\"\"\n    # try:\n    #    public_key: RSAPublicKey = serialization.load_pem_public_key(public_key_str.encode())\n    #  except Exception as e:\n    #     get_logger().error(f\"Error encrypt_asymmetric {e}\")\n    try:\n        public_key: RSAPublicKey = serialization.load_pem_public_key(public_key_str.encode())\n        encrypted = public_key.encrypt(\n            text.encode(),\n            padding.OAEP(\n                mgf=padding.MGF1(algorithm=hashes.SHA512()),\n                algorithm=hashes.SHA512(),\n                label=None\n            )\n        )\n        return encrypted.hex()\n    except Exception as e:\n        get_logger().error(f\"Error encrypt_asymmetric {e}\")\n        return \"Invalid\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.security.Code.encrypt_symmetric","title":"<code>encrypt_symmetric(text, key)</code>  <code>staticmethod</code>","text":"<p>Verschl\u00fcsselt einen Text mit einem gegebenen symmetrischen Schl\u00fcssel.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Der zu verschl\u00fcsselnde Text.</p> required <code>key</code> <code>str</code> <p>Der symmetrische Schl\u00fcssel.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Der verschl\u00fcsselte Text.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef encrypt_symmetric(text: str or bytes, key: str) -&gt; str:\n    \"\"\"\n    Verschl\u00fcsselt einen Text mit einem gegebenen symmetrischen Schl\u00fcssel.\n\n    Args:\n        text (str): Der zu verschl\u00fcsselnde Text.\n        key (str): Der symmetrische Schl\u00fcssel.\n\n    Returns:\n        str: Der verschl\u00fcsselte Text.\n    \"\"\"\n    if isinstance(text, str):\n        text = text.encode()\n\n    try:\n        fernet = Fernet(key.encode())\n        return fernet.encrypt(text).decode()\n    except Exception as e:\n        get_logger().error(f\"Error encrypt_symmetric #{str(e)}#\")\n        return \"Error encrypt\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.security.Code.generate_asymmetric_keys","title":"<code>generate_asymmetric_keys()</code>  <code>staticmethod</code>","text":"<p>Generiert ein Paar von \u00f6ffentlichen und privaten Schl\u00fcsseln f\u00fcr die asymmetrische Verschl\u00fcsselung.</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>int</code> <p>Ein optionaler Seed-Wert. Standardm\u00e4\u00dfig None.</p> required <p>Returns:</p> Type Description <code>(str, str)</code> <p>Ein Tupel aus \u00f6ffentlichem und privatem Schl\u00fcssel.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef generate_asymmetric_keys() -&gt; (str, str):\n    \"\"\"\n    Generiert ein Paar von \u00f6ffentlichen und privaten Schl\u00fcsseln f\u00fcr die asymmetrische Verschl\u00fcsselung.\n\n    Args:\n        seed (int, optional): Ein optionaler Seed-Wert. Standardm\u00e4\u00dfig None.\n\n    Returns:\n        (str, str): Ein Tupel aus \u00f6ffentlichem und privatem Schl\u00fcssel.\n    \"\"\"\n    private_key = rsa.generate_private_key(\n        public_exponent=65537,\n        key_size=2048 * 3,\n    )\n    public_key = private_key.public_key()\n\n    # Serialisieren der Schl\u00fcssel\n    pem_private_key = private_key.private_bytes(\n        encoding=serialization.Encoding.PEM,\n        format=serialization.PrivateFormat.PKCS8,\n        encryption_algorithm=serialization.NoEncryption()\n    ).decode()\n\n    pem_public_key = public_key.public_bytes(\n        encoding=serialization.Encoding.PEM,\n        format=serialization.PublicFormat.SubjectPublicKeyInfo\n    ).decode()\n\n    return pem_public_key, pem_private_key\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.security.Code.generate_seed","title":"<code>generate_seed()</code>  <code>staticmethod</code>","text":"<p>Erzeugt eine zuf\u00e4llige Zahl als Seed.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Eine zuf\u00e4llige Zahl.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef generate_seed() -&gt; int:\n    \"\"\"\n    Erzeugt eine zuf\u00e4llige Zahl als Seed.\n\n    Returns:\n        int: Eine zuf\u00e4llige Zahl.\n    \"\"\"\n    return random.randint(2 ** 32 - 1, 2 ** 64 - 1)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.security.Code.generate_symmetric_key","title":"<code>generate_symmetric_key(as_str=True)</code>  <code>staticmethod</code>","text":"<p>Generiert einen Schl\u00fcssel f\u00fcr die symmetrische Verschl\u00fcsselung.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str or bytes</code> <p>Der generierte Schl\u00fcssel.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef generate_symmetric_key(as_str=True) -&gt; str or bytes:\n    \"\"\"\n    Generiert einen Schl\u00fcssel f\u00fcr die symmetrische Verschl\u00fcsselung.\n\n    Returns:\n        str: Der generierte Schl\u00fcssel.\n    \"\"\"\n    key = Fernet.generate_key()\n    if as_str:\n        key = key.decode()\n    return key\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.security.Code.load_keys_from_files","title":"<code>load_keys_from_files(directory='keys')</code>  <code>staticmethod</code>","text":"<p>L\u00e4dt die Schl\u00fcssel aus den Dateien. Der private Schl\u00fcssel wird mit dem Device Key entschl\u00fcsselt.</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>str</code> <p>Das Verzeichnis, aus dem die Schl\u00fcssel geladen werden sollen</p> <code>'keys'</code> <p>Returns:</p> Type Description <code>(str, str)</code> <p>Ein Tupel aus \u00f6ffentlichem und privatem Schl\u00fcssel</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>Wenn die Schl\u00fcsseldateien nicht gefunden werden k\u00f6nnen</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef load_keys_from_files(directory: str = \"keys\") -&gt; (str, str):\n    \"\"\"\n    L\u00e4dt die Schl\u00fcssel aus den Dateien.\n    Der private Schl\u00fcssel wird mit dem Device Key entschl\u00fcsselt.\n\n    Args:\n        directory (str): Das Verzeichnis, aus dem die Schl\u00fcssel geladen werden sollen\n\n    Returns:\n        (str, str): Ein Tupel aus \u00f6ffentlichem und privatem Schl\u00fcssel\n\n    Raises:\n        FileNotFoundError: Wenn die Schl\u00fcsseldateien nicht gefunden werden k\u00f6nnen\n    \"\"\"\n    # Pfade zu den Schl\u00fcsseldateien\n    public_key_path = os.path.join(directory, \"public_key.pem\")\n    private_key_path = os.path.join(directory, \"private_key.pem\")\n\n    # Pr\u00fcfe ob die Dateien existieren\n    if not os.path.exists(public_key_path) or not os.path.exists(private_key_path):\n        return \"\", \"\"\n\n    # Hole den Device Key\n    device_key = DEVICE_KEY()\n\n    # Lade den \u00f6ffentlichen Schl\u00fcssel\n    with open(public_key_path) as f:\n        public_key = f.read()\n\n    # Lade und entschl\u00fcssele den privaten Schl\u00fcssel\n    with open(private_key_path) as f:\n        encrypted_private_key = f.read()\n        private_key = Code.decrypt_symmetric(encrypted_private_key, device_key)\n\n    return public_key, private_key\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.security.Code.one_way_hash","title":"<code>one_way_hash(text, salt='', pepper='')</code>  <code>staticmethod</code>","text":"<p>Erzeugt einen Hash eines gegebenen Textes mit Salt, Pepper und optional einem Seed.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Der zu hashende Text.</p> required <code>salt</code> <code>str</code> <p>Der Salt-Wert.</p> <code>''</code> <code>pepper</code> <code>str</code> <p>Der Pepper-Wert.</p> <code>''</code> <code>seed</code> <code>int</code> <p>Ein optionaler Seed-Wert. Standardm\u00e4\u00dfig None.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Der resultierende Hash-Wert.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef one_way_hash(text: str, salt: str = '', pepper: str = '') -&gt; str:\n    \"\"\"\n    Erzeugt einen Hash eines gegebenen Textes mit Salt, Pepper und optional einem Seed.\n\n    Args:\n        text (str): Der zu hashende Text.\n        salt (str): Der Salt-Wert.\n        pepper (str): Der Pepper-Wert.\n        seed (int, optional): Ein optionaler Seed-Wert. Standardm\u00e4\u00dfig None.\n\n    Returns:\n        str: Der resultierende Hash-Wert.\n    \"\"\"\n    return hashlib.sha256((salt + text + pepper).encode()).hexdigest()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.security.Code.pem_to_public_key","title":"<code>pem_to_public_key(pem_key)</code>  <code>staticmethod</code>","text":"<p>Konvertiert einen PEM-kodierten \u00f6ffentlichen Schl\u00fcssel in ein PublicKey-Objekt.</p> <p>Parameters:</p> Name Type Description Default <code>pem_key</code> <code>str</code> <p>Der PEM-kodierte \u00f6ffentliche Schl\u00fcssel.</p> required <p>Returns:</p> Name Type Description <code>PublicKey</code> <p>Das PublicKey-Objekt.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef pem_to_public_key(pem_key: str):\n    \"\"\"\n    Konvertiert einen PEM-kodierten \u00f6ffentlichen Schl\u00fcssel in ein PublicKey-Objekt.\n\n    Args:\n        pem_key (str): Der PEM-kodierte \u00f6ffentliche Schl\u00fcssel.\n\n    Returns:\n        PublicKey: Das PublicKey-Objekt.\n    \"\"\"\n    public_key = serialization.load_pem_public_key(pem_key.encode())\n    return public_key\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.security.Code.public_key_to_pem","title":"<code>public_key_to_pem(public_key)</code>  <code>staticmethod</code>","text":"<p>Konvertiert ein PublicKey-Objekt in einen PEM-kodierten String.</p> <p>Parameters:</p> Name Type Description Default <code>public_key</code> <code>PublicKey</code> <p>Das PublicKey-Objekt.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>Der PEM-kodierte \u00f6ffentliche Schl\u00fcssel.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef public_key_to_pem(public_key: RSAPublicKey):\n    \"\"\"\n    Konvertiert ein PublicKey-Objekt in einen PEM-kodierten String.\n\n    Args:\n        public_key (PublicKey): Das PublicKey-Objekt.\n\n    Returns:\n        str: Der PEM-kodierte \u00f6ffentliche Schl\u00fcssel.\n    \"\"\"\n    pem = public_key.public_bytes(\n        encoding=serialization.Encoding.PEM,\n        format=serialization.PublicFormat.SubjectPublicKeyInfo\n    )\n    return pem.decode()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.security.Code.save_keys_to_files","title":"<code>save_keys_to_files(public_key, private_key, directory='keys')</code>  <code>staticmethod</code>","text":"<p>Speichert die generierten Schl\u00fcssel in separate Dateien. Der private Schl\u00fcssel wird mit dem Device Key verschl\u00fcsselt.</p> <p>Parameters:</p> Name Type Description Default <code>public_key</code> <code>str</code> <p>Der \u00f6ffentliche Schl\u00fcssel im PEM-Format</p> required <code>private_key</code> <code>str</code> <p>Der private Schl\u00fcssel im PEM-Format</p> required <code>directory</code> <code>str</code> <p>Das Verzeichnis, in dem die Schl\u00fcssel gespeichert werden sollen</p> <code>'keys'</code> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef save_keys_to_files(public_key: str, private_key: str, directory: str = \"keys\") -&gt; None:\n    \"\"\"\n    Speichert die generierten Schl\u00fcssel in separate Dateien.\n    Der private Schl\u00fcssel wird mit dem Device Key verschl\u00fcsselt.\n\n    Args:\n        public_key (str): Der \u00f6ffentliche Schl\u00fcssel im PEM-Format\n        private_key (str): Der private Schl\u00fcssel im PEM-Format\n        directory (str): Das Verzeichnis, in dem die Schl\u00fcssel gespeichert werden sollen\n    \"\"\"\n    # Erstelle das Verzeichnis, falls es nicht existiert\n    os.makedirs(directory, exist_ok=True)\n\n    # Hole den Device Key\n    device_key = DEVICE_KEY()\n\n    # Verschl\u00fcssele den privaten Schl\u00fcssel mit dem Device Key\n    encrypted_private_key = Code.encrypt_symmetric(private_key, device_key)\n\n    # Speichere den \u00f6ffentlichen Schl\u00fcssel\n    public_key_path = os.path.join(directory, \"public_key.pem\")\n    with open(public_key_path, \"w\") as f:\n        f.write(public_key)\n\n    # Speichere den verschl\u00fcsselten privaten Schl\u00fcssel\n    private_key_path = os.path.join(directory, \"private_key.pem\")\n    with open(private_key_path, \"w\") as f:\n        f.write(encrypted_private_key)\n\n    print(\"Saved keys in \", public_key_path)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.security.cryp","title":"<code>cryp</code>","text":""},{"location":"toolboxv2/#toolboxv2.utils.security.cryp.Code","title":"<code>Code</code>","text":"Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>class Code:\n\n    @staticmethod\n    def DK():\n        return DEVICE_KEY\n\n    def decode_code(self, encrypted_data, key=None):\n\n        if not isinstance(encrypted_data, str):\n            encrypted_data = str(encrypted_data)\n\n        if key is None:\n            key = DEVICE_KEY()\n\n        return self.decrypt_symmetric(encrypted_data, key)\n\n    def encode_code(self, data, key=None):\n\n        if not isinstance(data, str):\n            data = str(data)\n\n        if key is None:\n            key = DEVICE_KEY()\n\n        return self.encrypt_symmetric(data, key)\n\n    @staticmethod\n    def generate_seed() -&gt; int:\n        \"\"\"\n        Erzeugt eine zuf\u00e4llige Zahl als Seed.\n\n        Returns:\n            int: Eine zuf\u00e4llige Zahl.\n        \"\"\"\n        return random.randint(2 ** 32 - 1, 2 ** 64 - 1)\n\n    @staticmethod\n    def one_way_hash(text: str, salt: str = '', pepper: str = '') -&gt; str:\n        \"\"\"\n        Erzeugt einen Hash eines gegebenen Textes mit Salt, Pepper und optional einem Seed.\n\n        Args:\n            text (str): Der zu hashende Text.\n            salt (str): Der Salt-Wert.\n            pepper (str): Der Pepper-Wert.\n            seed (int, optional): Ein optionaler Seed-Wert. Standardm\u00e4\u00dfig None.\n\n        Returns:\n            str: Der resultierende Hash-Wert.\n        \"\"\"\n        return hashlib.sha256((salt + text + pepper).encode()).hexdigest()\n\n    @staticmethod\n    def generate_symmetric_key(as_str=True) -&gt; str or bytes:\n        \"\"\"\n        Generiert einen Schl\u00fcssel f\u00fcr die symmetrische Verschl\u00fcsselung.\n\n        Returns:\n            str: Der generierte Schl\u00fcssel.\n        \"\"\"\n        key = Fernet.generate_key()\n        if as_str:\n            key = key.decode()\n        return key\n\n    @staticmethod\n    def encrypt_symmetric(text: str or bytes, key: str) -&gt; str:\n        \"\"\"\n        Verschl\u00fcsselt einen Text mit einem gegebenen symmetrischen Schl\u00fcssel.\n\n        Args:\n            text (str): Der zu verschl\u00fcsselnde Text.\n            key (str): Der symmetrische Schl\u00fcssel.\n\n        Returns:\n            str: Der verschl\u00fcsselte Text.\n        \"\"\"\n        if isinstance(text, str):\n            text = text.encode()\n\n        try:\n            fernet = Fernet(key.encode())\n            return fernet.encrypt(text).decode()\n        except Exception as e:\n            get_logger().error(f\"Error encrypt_symmetric #{str(e)}#\")\n            return \"Error encrypt\"\n\n    @staticmethod\n    def decrypt_symmetric(encrypted_text: str, key: str, to_str=True, mute=False) -&gt; str or bytes:\n        \"\"\"\n        Entschl\u00fcsselt einen Text mit einem gegebenen symmetrischen Schl\u00fcssel.\n\n        Args:\n            encrypted_text (str): Der zu entschl\u00fcsselnde Text.\n            key (str): Der symmetrische Schl\u00fcssel.\n            to_str (bool): default true returns str if false returns bytes\n        Returns:\n            str: Der entschl\u00fcsselte Text.\n        \"\"\"\n\n        if isinstance(key, str):\n            key = key.encode()\n\n        #try:\n        fernet = Fernet(key)\n        text_b = fernet.decrypt(encrypted_text)\n        if not to_str:\n            return text_b\n        return text_b.decode()\n        # except Exception as e:\n        #     get_logger().error(f\"Error decrypt_symmetric {e}\")\n        #     if not mute:\n        #         raise e\n        #     if not to_str:\n        #         return f\"Error decoding\".encode()\n        #     return f\"Error decoding\"\n\n    @staticmethod\n    def generate_asymmetric_keys() -&gt; (str, str):\n        \"\"\"\n        Generiert ein Paar von \u00f6ffentlichen und privaten Schl\u00fcsseln f\u00fcr die asymmetrische Verschl\u00fcsselung.\n\n        Args:\n            seed (int, optional): Ein optionaler Seed-Wert. Standardm\u00e4\u00dfig None.\n\n        Returns:\n            (str, str): Ein Tupel aus \u00f6ffentlichem und privatem Schl\u00fcssel.\n        \"\"\"\n        private_key = rsa.generate_private_key(\n            public_exponent=65537,\n            key_size=2048 * 3,\n        )\n        public_key = private_key.public_key()\n\n        # Serialisieren der Schl\u00fcssel\n        pem_private_key = private_key.private_bytes(\n            encoding=serialization.Encoding.PEM,\n            format=serialization.PrivateFormat.PKCS8,\n            encryption_algorithm=serialization.NoEncryption()\n        ).decode()\n\n        pem_public_key = public_key.public_bytes(\n            encoding=serialization.Encoding.PEM,\n            format=serialization.PublicFormat.SubjectPublicKeyInfo\n        ).decode()\n\n        return pem_public_key, pem_private_key\n\n    @staticmethod\n    def save_keys_to_files(public_key: str, private_key: str, directory: str = \"keys\") -&gt; None:\n        \"\"\"\n        Speichert die generierten Schl\u00fcssel in separate Dateien.\n        Der private Schl\u00fcssel wird mit dem Device Key verschl\u00fcsselt.\n\n        Args:\n            public_key (str): Der \u00f6ffentliche Schl\u00fcssel im PEM-Format\n            private_key (str): Der private Schl\u00fcssel im PEM-Format\n            directory (str): Das Verzeichnis, in dem die Schl\u00fcssel gespeichert werden sollen\n        \"\"\"\n        # Erstelle das Verzeichnis, falls es nicht existiert\n        os.makedirs(directory, exist_ok=True)\n\n        # Hole den Device Key\n        device_key = DEVICE_KEY()\n\n        # Verschl\u00fcssele den privaten Schl\u00fcssel mit dem Device Key\n        encrypted_private_key = Code.encrypt_symmetric(private_key, device_key)\n\n        # Speichere den \u00f6ffentlichen Schl\u00fcssel\n        public_key_path = os.path.join(directory, \"public_key.pem\")\n        with open(public_key_path, \"w\") as f:\n            f.write(public_key)\n\n        # Speichere den verschl\u00fcsselten privaten Schl\u00fcssel\n        private_key_path = os.path.join(directory, \"private_key.pem\")\n        with open(private_key_path, \"w\") as f:\n            f.write(encrypted_private_key)\n\n        print(\"Saved keys in \", public_key_path)\n\n    @staticmethod\n    def load_keys_from_files(directory: str = \"keys\") -&gt; (str, str):\n        \"\"\"\n        L\u00e4dt die Schl\u00fcssel aus den Dateien.\n        Der private Schl\u00fcssel wird mit dem Device Key entschl\u00fcsselt.\n\n        Args:\n            directory (str): Das Verzeichnis, aus dem die Schl\u00fcssel geladen werden sollen\n\n        Returns:\n            (str, str): Ein Tupel aus \u00f6ffentlichem und privatem Schl\u00fcssel\n\n        Raises:\n            FileNotFoundError: Wenn die Schl\u00fcsseldateien nicht gefunden werden k\u00f6nnen\n        \"\"\"\n        # Pfade zu den Schl\u00fcsseldateien\n        public_key_path = os.path.join(directory, \"public_key.pem\")\n        private_key_path = os.path.join(directory, \"private_key.pem\")\n\n        # Pr\u00fcfe ob die Dateien existieren\n        if not os.path.exists(public_key_path) or not os.path.exists(private_key_path):\n            return \"\", \"\"\n\n        # Hole den Device Key\n        device_key = DEVICE_KEY()\n\n        # Lade den \u00f6ffentlichen Schl\u00fcssel\n        with open(public_key_path) as f:\n            public_key = f.read()\n\n        # Lade und entschl\u00fcssele den privaten Schl\u00fcssel\n        with open(private_key_path) as f:\n            encrypted_private_key = f.read()\n            private_key = Code.decrypt_symmetric(encrypted_private_key, device_key)\n\n        return public_key, private_key\n\n    @staticmethod\n    def encrypt_asymmetric(text: str, public_key_str: str) -&gt; str:\n        \"\"\"\n        Verschl\u00fcsselt einen Text mit einem gegebenen \u00f6ffentlichen Schl\u00fcssel.\n\n        Args:\n            text (str): Der zu verschl\u00fcsselnde Text.\n            public_key_str (str): Der \u00f6ffentliche Schl\u00fcssel als String oder im pem format.\n\n        Returns:\n            str: Der verschl\u00fcsselte Text.\n        \"\"\"\n        # try:\n        #    public_key: RSAPublicKey = serialization.load_pem_public_key(public_key_str.encode())\n        #  except Exception as e:\n        #     get_logger().error(f\"Error encrypt_asymmetric {e}\")\n        try:\n            public_key: RSAPublicKey = serialization.load_pem_public_key(public_key_str.encode())\n            encrypted = public_key.encrypt(\n                text.encode(),\n                padding.OAEP(\n                    mgf=padding.MGF1(algorithm=hashes.SHA512()),\n                    algorithm=hashes.SHA512(),\n                    label=None\n                )\n            )\n            return encrypted.hex()\n        except Exception as e:\n            get_logger().error(f\"Error encrypt_asymmetric {e}\")\n            return \"Invalid\"\n\n    @staticmethod\n    def decrypt_asymmetric(encrypted_text_hex: str, private_key_str: str) -&gt; str:\n        \"\"\"\n        Entschl\u00fcsselt einen Text mit einem gegebenen privaten Schl\u00fcssel.\n\n        Args:\n            encrypted_text_hex (str): Der verschl\u00fcsselte Text als Hex-String.\n            private_key_str (str): Der private Schl\u00fcssel als String.\n\n        Returns:\n            str: Der entschl\u00fcsselte Text.\n        \"\"\"\n        try:\n            private_key = serialization.load_pem_private_key(private_key_str.encode(), password=None)\n            decrypted = private_key.decrypt(\n                bytes.fromhex(encrypted_text_hex),\n                padding.OAEP(\n                    mgf=padding.MGF1(algorithm=hashes.SHA512()),\n                    algorithm=hashes.SHA512(),\n                    label=None\n                )\n            )\n            return decrypted.decode()\n\n        except Exception as e:\n            get_logger().error(f\"Error decrypt_asymmetric {e}\")\n        return \"Invalid\"\n\n    @staticmethod\n    def verify_signature(signature: str or bytes, message: str or bytes, public_key_str: str,\n                         salt_length=padding.PSS.MAX_LENGTH) -&gt; bool:\n        if isinstance(signature, str):\n            signature = signature.encode()\n        if isinstance(message, str):\n            message = message.encode()\n        try:\n            public_key: RSAPublicKey = serialization.load_pem_public_key(public_key_str.encode())\n            public_key.verify(\n                signature=signature,\n                data=message,\n                padding=padding.PSS(\n                    mgf=padding.MGF1(hashes.SHA512()),\n                    salt_length=salt_length\n                ),\n                algorithm=hashes.SHA512()\n            )\n            return True\n        except:\n            pass\n        return False\n\n    @staticmethod\n    def verify_signature_web_algo(signature: str or bytes, message: str or bytes, public_key_str: str,\n                                  algo: int = -512) -&gt; bool:\n        signature_algorithm = ECDSA(hashes.SHA512())\n        if algo != -512:\n            signature_algorithm = ECDSA(hashes.SHA256())\n\n        if isinstance(signature, str):\n            signature = signature.encode()\n        if isinstance(message, str):\n            message = message.encode()\n        try:\n            public_key = serialization.load_pem_public_key(public_key_str.encode())\n            public_key.verify(\n                signature=signature,\n                data=message,\n                # padding=padding.PSS(\n                #    mgf=padding.MGF1(hashes.SHA512()),\n                #    salt_length=padding.PSS.MAX_LENGTH\n                # ),\n                signature_algorithm=signature_algorithm\n            )\n            return True\n        except:\n            pass\n        return False\n\n    @staticmethod\n    def create_signature(message: str, private_key_str: str, salt_length=padding.PSS.MAX_LENGTH,\n                         row=False) -&gt; str or bytes:\n        try:\n            private_key = serialization.load_pem_private_key(private_key_str.encode(), password=None)\n            signature = private_key.sign(\n                message.encode(),\n                padding.PSS(\n                    mgf=padding.MGF1(hashes.SHA512()),\n                    salt_length=salt_length\n                ),\n                hashes.SHA512()\n            )\n            if row:\n                return signature\n            return base64.b64encode(signature).decode()\n        except Exception as e:\n            get_logger().error(f\"Error create_signature {e}\")\n            print(e)\n        return \"Invalid Key\"\n\n    @staticmethod\n    def pem_to_public_key(pem_key: str):\n        \"\"\"\n        Konvertiert einen PEM-kodierten \u00f6ffentlichen Schl\u00fcssel in ein PublicKey-Objekt.\n\n        Args:\n            pem_key (str): Der PEM-kodierte \u00f6ffentliche Schl\u00fcssel.\n\n        Returns:\n            PublicKey: Das PublicKey-Objekt.\n        \"\"\"\n        public_key = serialization.load_pem_public_key(pem_key.encode())\n        return public_key\n\n    @staticmethod\n    def public_key_to_pem(public_key: RSAPublicKey):\n        \"\"\"\n        Konvertiert ein PublicKey-Objekt in einen PEM-kodierten String.\n\n        Args:\n            public_key (PublicKey): Das PublicKey-Objekt.\n\n        Returns:\n            str: Der PEM-kodierte \u00f6ffentliche Schl\u00fcssel.\n        \"\"\"\n        pem = public_key.public_bytes(\n            encoding=serialization.Encoding.PEM,\n            format=serialization.PublicFormat.SubjectPublicKeyInfo\n        )\n        return pem.decode()\n</code></pre> <code>decrypt_asymmetric(encrypted_text_hex, private_key_str)</code> <code>staticmethod</code> \u00b6 <p>Entschl\u00fcsselt einen Text mit einem gegebenen privaten Schl\u00fcssel.</p> <p>Parameters:</p> Name Type Description Default <code>encrypted_text_hex</code> <code>str</code> <p>Der verschl\u00fcsselte Text als Hex-String.</p> required <code>private_key_str</code> <code>str</code> <p>Der private Schl\u00fcssel als String.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Der entschl\u00fcsselte Text.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef decrypt_asymmetric(encrypted_text_hex: str, private_key_str: str) -&gt; str:\n    \"\"\"\n    Entschl\u00fcsselt einen Text mit einem gegebenen privaten Schl\u00fcssel.\n\n    Args:\n        encrypted_text_hex (str): Der verschl\u00fcsselte Text als Hex-String.\n        private_key_str (str): Der private Schl\u00fcssel als String.\n\n    Returns:\n        str: Der entschl\u00fcsselte Text.\n    \"\"\"\n    try:\n        private_key = serialization.load_pem_private_key(private_key_str.encode(), password=None)\n        decrypted = private_key.decrypt(\n            bytes.fromhex(encrypted_text_hex),\n            padding.OAEP(\n                mgf=padding.MGF1(algorithm=hashes.SHA512()),\n                algorithm=hashes.SHA512(),\n                label=None\n            )\n        )\n        return decrypted.decode()\n\n    except Exception as e:\n        get_logger().error(f\"Error decrypt_asymmetric {e}\")\n    return \"Invalid\"\n</code></pre> <code>decrypt_symmetric(encrypted_text, key, to_str=True, mute=False)</code> <code>staticmethod</code> \u00b6 <p>Entschl\u00fcsselt einen Text mit einem gegebenen symmetrischen Schl\u00fcssel.</p> <p>Parameters:</p> Name Type Description Default <code>encrypted_text</code> <code>str</code> <p>Der zu entschl\u00fcsselnde Text.</p> required <code>key</code> <code>str</code> <p>Der symmetrische Schl\u00fcssel.</p> required <code>to_str</code> <code>bool</code> <p>default true returns str if false returns bytes</p> <code>True</code> <p>Returns:     str: Der entschl\u00fcsselte Text.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef decrypt_symmetric(encrypted_text: str, key: str, to_str=True, mute=False) -&gt; str or bytes:\n    \"\"\"\n    Entschl\u00fcsselt einen Text mit einem gegebenen symmetrischen Schl\u00fcssel.\n\n    Args:\n        encrypted_text (str): Der zu entschl\u00fcsselnde Text.\n        key (str): Der symmetrische Schl\u00fcssel.\n        to_str (bool): default true returns str if false returns bytes\n    Returns:\n        str: Der entschl\u00fcsselte Text.\n    \"\"\"\n\n    if isinstance(key, str):\n        key = key.encode()\n\n    #try:\n    fernet = Fernet(key)\n    text_b = fernet.decrypt(encrypted_text)\n    if not to_str:\n        return text_b\n    return text_b.decode()\n</code></pre> <code>encrypt_asymmetric(text, public_key_str)</code> <code>staticmethod</code> \u00b6 <p>Verschl\u00fcsselt einen Text mit einem gegebenen \u00f6ffentlichen Schl\u00fcssel.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Der zu verschl\u00fcsselnde Text.</p> required <code>public_key_str</code> <code>str</code> <p>Der \u00f6ffentliche Schl\u00fcssel als String oder im pem format.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Der verschl\u00fcsselte Text.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef encrypt_asymmetric(text: str, public_key_str: str) -&gt; str:\n    \"\"\"\n    Verschl\u00fcsselt einen Text mit einem gegebenen \u00f6ffentlichen Schl\u00fcssel.\n\n    Args:\n        text (str): Der zu verschl\u00fcsselnde Text.\n        public_key_str (str): Der \u00f6ffentliche Schl\u00fcssel als String oder im pem format.\n\n    Returns:\n        str: Der verschl\u00fcsselte Text.\n    \"\"\"\n    # try:\n    #    public_key: RSAPublicKey = serialization.load_pem_public_key(public_key_str.encode())\n    #  except Exception as e:\n    #     get_logger().error(f\"Error encrypt_asymmetric {e}\")\n    try:\n        public_key: RSAPublicKey = serialization.load_pem_public_key(public_key_str.encode())\n        encrypted = public_key.encrypt(\n            text.encode(),\n            padding.OAEP(\n                mgf=padding.MGF1(algorithm=hashes.SHA512()),\n                algorithm=hashes.SHA512(),\n                label=None\n            )\n        )\n        return encrypted.hex()\n    except Exception as e:\n        get_logger().error(f\"Error encrypt_asymmetric {e}\")\n        return \"Invalid\"\n</code></pre> <code>encrypt_symmetric(text, key)</code> <code>staticmethod</code> \u00b6 <p>Verschl\u00fcsselt einen Text mit einem gegebenen symmetrischen Schl\u00fcssel.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Der zu verschl\u00fcsselnde Text.</p> required <code>key</code> <code>str</code> <p>Der symmetrische Schl\u00fcssel.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Der verschl\u00fcsselte Text.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef encrypt_symmetric(text: str or bytes, key: str) -&gt; str:\n    \"\"\"\n    Verschl\u00fcsselt einen Text mit einem gegebenen symmetrischen Schl\u00fcssel.\n\n    Args:\n        text (str): Der zu verschl\u00fcsselnde Text.\n        key (str): Der symmetrische Schl\u00fcssel.\n\n    Returns:\n        str: Der verschl\u00fcsselte Text.\n    \"\"\"\n    if isinstance(text, str):\n        text = text.encode()\n\n    try:\n        fernet = Fernet(key.encode())\n        return fernet.encrypt(text).decode()\n    except Exception as e:\n        get_logger().error(f\"Error encrypt_symmetric #{str(e)}#\")\n        return \"Error encrypt\"\n</code></pre> <code>generate_asymmetric_keys()</code> <code>staticmethod</code> \u00b6 <p>Generiert ein Paar von \u00f6ffentlichen und privaten Schl\u00fcsseln f\u00fcr die asymmetrische Verschl\u00fcsselung.</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>int</code> <p>Ein optionaler Seed-Wert. Standardm\u00e4\u00dfig None.</p> required <p>Returns:</p> Type Description <code>(str, str)</code> <p>Ein Tupel aus \u00f6ffentlichem und privatem Schl\u00fcssel.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef generate_asymmetric_keys() -&gt; (str, str):\n    \"\"\"\n    Generiert ein Paar von \u00f6ffentlichen und privaten Schl\u00fcsseln f\u00fcr die asymmetrische Verschl\u00fcsselung.\n\n    Args:\n        seed (int, optional): Ein optionaler Seed-Wert. Standardm\u00e4\u00dfig None.\n\n    Returns:\n        (str, str): Ein Tupel aus \u00f6ffentlichem und privatem Schl\u00fcssel.\n    \"\"\"\n    private_key = rsa.generate_private_key(\n        public_exponent=65537,\n        key_size=2048 * 3,\n    )\n    public_key = private_key.public_key()\n\n    # Serialisieren der Schl\u00fcssel\n    pem_private_key = private_key.private_bytes(\n        encoding=serialization.Encoding.PEM,\n        format=serialization.PrivateFormat.PKCS8,\n        encryption_algorithm=serialization.NoEncryption()\n    ).decode()\n\n    pem_public_key = public_key.public_bytes(\n        encoding=serialization.Encoding.PEM,\n        format=serialization.PublicFormat.SubjectPublicKeyInfo\n    ).decode()\n\n    return pem_public_key, pem_private_key\n</code></pre> <code>generate_seed()</code> <code>staticmethod</code> \u00b6 <p>Erzeugt eine zuf\u00e4llige Zahl als Seed.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Eine zuf\u00e4llige Zahl.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef generate_seed() -&gt; int:\n    \"\"\"\n    Erzeugt eine zuf\u00e4llige Zahl als Seed.\n\n    Returns:\n        int: Eine zuf\u00e4llige Zahl.\n    \"\"\"\n    return random.randint(2 ** 32 - 1, 2 ** 64 - 1)\n</code></pre> <code>generate_symmetric_key(as_str=True)</code> <code>staticmethod</code> \u00b6 <p>Generiert einen Schl\u00fcssel f\u00fcr die symmetrische Verschl\u00fcsselung.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str or bytes</code> <p>Der generierte Schl\u00fcssel.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef generate_symmetric_key(as_str=True) -&gt; str or bytes:\n    \"\"\"\n    Generiert einen Schl\u00fcssel f\u00fcr die symmetrische Verschl\u00fcsselung.\n\n    Returns:\n        str: Der generierte Schl\u00fcssel.\n    \"\"\"\n    key = Fernet.generate_key()\n    if as_str:\n        key = key.decode()\n    return key\n</code></pre> <code>load_keys_from_files(directory='keys')</code> <code>staticmethod</code> \u00b6 <p>L\u00e4dt die Schl\u00fcssel aus den Dateien. Der private Schl\u00fcssel wird mit dem Device Key entschl\u00fcsselt.</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>str</code> <p>Das Verzeichnis, aus dem die Schl\u00fcssel geladen werden sollen</p> <code>'keys'</code> <p>Returns:</p> Type Description <code>(str, str)</code> <p>Ein Tupel aus \u00f6ffentlichem und privatem Schl\u00fcssel</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>Wenn die Schl\u00fcsseldateien nicht gefunden werden k\u00f6nnen</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef load_keys_from_files(directory: str = \"keys\") -&gt; (str, str):\n    \"\"\"\n    L\u00e4dt die Schl\u00fcssel aus den Dateien.\n    Der private Schl\u00fcssel wird mit dem Device Key entschl\u00fcsselt.\n\n    Args:\n        directory (str): Das Verzeichnis, aus dem die Schl\u00fcssel geladen werden sollen\n\n    Returns:\n        (str, str): Ein Tupel aus \u00f6ffentlichem und privatem Schl\u00fcssel\n\n    Raises:\n        FileNotFoundError: Wenn die Schl\u00fcsseldateien nicht gefunden werden k\u00f6nnen\n    \"\"\"\n    # Pfade zu den Schl\u00fcsseldateien\n    public_key_path = os.path.join(directory, \"public_key.pem\")\n    private_key_path = os.path.join(directory, \"private_key.pem\")\n\n    # Pr\u00fcfe ob die Dateien existieren\n    if not os.path.exists(public_key_path) or not os.path.exists(private_key_path):\n        return \"\", \"\"\n\n    # Hole den Device Key\n    device_key = DEVICE_KEY()\n\n    # Lade den \u00f6ffentlichen Schl\u00fcssel\n    with open(public_key_path) as f:\n        public_key = f.read()\n\n    # Lade und entschl\u00fcssele den privaten Schl\u00fcssel\n    with open(private_key_path) as f:\n        encrypted_private_key = f.read()\n        private_key = Code.decrypt_symmetric(encrypted_private_key, device_key)\n\n    return public_key, private_key\n</code></pre> <code>one_way_hash(text, salt='', pepper='')</code> <code>staticmethod</code> \u00b6 <p>Erzeugt einen Hash eines gegebenen Textes mit Salt, Pepper und optional einem Seed.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Der zu hashende Text.</p> required <code>salt</code> <code>str</code> <p>Der Salt-Wert.</p> <code>''</code> <code>pepper</code> <code>str</code> <p>Der Pepper-Wert.</p> <code>''</code> <code>seed</code> <code>int</code> <p>Ein optionaler Seed-Wert. Standardm\u00e4\u00dfig None.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Der resultierende Hash-Wert.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef one_way_hash(text: str, salt: str = '', pepper: str = '') -&gt; str:\n    \"\"\"\n    Erzeugt einen Hash eines gegebenen Textes mit Salt, Pepper und optional einem Seed.\n\n    Args:\n        text (str): Der zu hashende Text.\n        salt (str): Der Salt-Wert.\n        pepper (str): Der Pepper-Wert.\n        seed (int, optional): Ein optionaler Seed-Wert. Standardm\u00e4\u00dfig None.\n\n    Returns:\n        str: Der resultierende Hash-Wert.\n    \"\"\"\n    return hashlib.sha256((salt + text + pepper).encode()).hexdigest()\n</code></pre> <code>pem_to_public_key(pem_key)</code> <code>staticmethod</code> \u00b6 <p>Konvertiert einen PEM-kodierten \u00f6ffentlichen Schl\u00fcssel in ein PublicKey-Objekt.</p> <p>Parameters:</p> Name Type Description Default <code>pem_key</code> <code>str</code> <p>Der PEM-kodierte \u00f6ffentliche Schl\u00fcssel.</p> required <p>Returns:</p> Name Type Description <code>PublicKey</code> <p>Das PublicKey-Objekt.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef pem_to_public_key(pem_key: str):\n    \"\"\"\n    Konvertiert einen PEM-kodierten \u00f6ffentlichen Schl\u00fcssel in ein PublicKey-Objekt.\n\n    Args:\n        pem_key (str): Der PEM-kodierte \u00f6ffentliche Schl\u00fcssel.\n\n    Returns:\n        PublicKey: Das PublicKey-Objekt.\n    \"\"\"\n    public_key = serialization.load_pem_public_key(pem_key.encode())\n    return public_key\n</code></pre> <code>public_key_to_pem(public_key)</code> <code>staticmethod</code> \u00b6 <p>Konvertiert ein PublicKey-Objekt in einen PEM-kodierten String.</p> <p>Parameters:</p> Name Type Description Default <code>public_key</code> <code>PublicKey</code> <p>Das PublicKey-Objekt.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>Der PEM-kodierte \u00f6ffentliche Schl\u00fcssel.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef public_key_to_pem(public_key: RSAPublicKey):\n    \"\"\"\n    Konvertiert ein PublicKey-Objekt in einen PEM-kodierten String.\n\n    Args:\n        public_key (PublicKey): Das PublicKey-Objekt.\n\n    Returns:\n        str: Der PEM-kodierte \u00f6ffentliche Schl\u00fcssel.\n    \"\"\"\n    pem = public_key.public_bytes(\n        encoding=serialization.Encoding.PEM,\n        format=serialization.PublicFormat.SubjectPublicKeyInfo\n    )\n    return pem.decode()\n</code></pre> <code>save_keys_to_files(public_key, private_key, directory='keys')</code> <code>staticmethod</code> \u00b6 <p>Speichert die generierten Schl\u00fcssel in separate Dateien. Der private Schl\u00fcssel wird mit dem Device Key verschl\u00fcsselt.</p> <p>Parameters:</p> Name Type Description Default <code>public_key</code> <code>str</code> <p>Der \u00f6ffentliche Schl\u00fcssel im PEM-Format</p> required <code>private_key</code> <code>str</code> <p>Der private Schl\u00fcssel im PEM-Format</p> required <code>directory</code> <code>str</code> <p>Das Verzeichnis, in dem die Schl\u00fcssel gespeichert werden sollen</p> <code>'keys'</code> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef save_keys_to_files(public_key: str, private_key: str, directory: str = \"keys\") -&gt; None:\n    \"\"\"\n    Speichert die generierten Schl\u00fcssel in separate Dateien.\n    Der private Schl\u00fcssel wird mit dem Device Key verschl\u00fcsselt.\n\n    Args:\n        public_key (str): Der \u00f6ffentliche Schl\u00fcssel im PEM-Format\n        private_key (str): Der private Schl\u00fcssel im PEM-Format\n        directory (str): Das Verzeichnis, in dem die Schl\u00fcssel gespeichert werden sollen\n    \"\"\"\n    # Erstelle das Verzeichnis, falls es nicht existiert\n    os.makedirs(directory, exist_ok=True)\n\n    # Hole den Device Key\n    device_key = DEVICE_KEY()\n\n    # Verschl\u00fcssele den privaten Schl\u00fcssel mit dem Device Key\n    encrypted_private_key = Code.encrypt_symmetric(private_key, device_key)\n\n    # Speichere den \u00f6ffentlichen Schl\u00fcssel\n    public_key_path = os.path.join(directory, \"public_key.pem\")\n    with open(public_key_path, \"w\") as f:\n        f.write(public_key)\n\n    # Speichere den verschl\u00fcsselten privaten Schl\u00fcssel\n    private_key_path = os.path.join(directory, \"private_key.pem\")\n    with open(private_key_path, \"w\") as f:\n        f.write(encrypted_private_key)\n\n    print(\"Saved keys in \", public_key_path)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.singelton_class","title":"<code>singelton_class</code>","text":""},{"location":"toolboxv2/#toolboxv2.utils.singelton_class.Singleton","title":"<code>Singleton</code>","text":"<p>Singleton metaclass for ensuring only one instance of a class.</p> Source code in <code>toolboxv2/utils/singelton_class.py</code> <pre><code>class Singleton(type):\n    \"\"\"\n    Singleton metaclass for ensuring only one instance of a class.\n    \"\"\"\n\n    _instances = {}\n    _kwargs = {}\n    _args = {}\n\n    def __call__(cls, *args, **kwargs):\n        if cls not in cls._instances:\n            cls._instances[cls] = super().__call__(*args, **kwargs)\n            cls._args[cls] = args\n            cls._kwargs[cls] = kwargs\n        return cls._instances[cls]\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system","title":"<code>system</code>","text":""},{"location":"toolboxv2/#toolboxv2.utils.system.AppType","title":"<code>AppType</code>","text":"Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>class AppType:\n    prefix: str\n    id: str\n    globals: dict[str, Any] = {\"root\": dict, }\n    locals: dict[str, Any] = {\"user\": {'app': \"self\"}, }\n\n    local_test: bool = False\n    start_dir: str\n    data_dir: str\n    config_dir: str\n    info_dir: str\n    is_server:bool = False\n\n    logger: logging.Logger\n    logging_filename: str\n\n    api_allowed_mods_list: list[str] = []\n\n    version: str\n    loop: asyncio.AbstractEventLoop\n\n    keys: dict[str, str] = {\n        \"MACRO\": \"macro~~~~:\",\n        \"MACRO_C\": \"m_color~~:\",\n        \"HELPER\": \"helper~~~:\",\n        \"debug\": \"debug~~~~:\",\n        \"id\": \"name-spa~:\",\n        \"st-load\": \"mute~load:\",\n        \"comm-his\": \"comm-his~:\",\n        \"develop-mode\": \"dev~mode~:\",\n        \"provider::\": \"provider::\",\n    }\n\n    defaults: dict[str, (bool or dict or dict[str, dict[str, str]] or str or list[str] or list[list]) | None] = {\n        \"MACRO\": list[str],\n        \"MACRO_C\": dict,\n        \"HELPER\": dict,\n        \"debug\": str,\n        \"id\": str,\n        \"st-load\": False,\n        \"comm-his\": list[list],\n        \"develop-mode\": bool,\n    }\n\n    cluster_manager: ClusterManager\n    root_blob_storage: BlobStorage\n    config_fh: FileHandler\n    _debug: bool\n    flows: dict[str, Callable]\n    dev_modi: bool\n    functions: dict[str, Any]\n    modules: dict[str, Any]\n\n    interface_type: ToolBoxInterfaces\n    REFIX: str\n\n    alive: bool\n    called_exit: tuple[bool, float]\n    args_sto: AppArgs\n    system_flag = None\n    session = None\n    appdata = None\n    exit_tasks = []\n\n    enable_profiling: bool = False\n    sto = None\n\n    websocket_handlers: dict[str, dict[str, Callable]] = {}\n    _rust_ws_bridge: Any = None\n\n    def __init__(self, prefix: None | str= None, args: AppArgs | None = None):\n        self.args_sto = args\n        self.prefix = prefix\n        \"\"\"proxi attr\"\"\"\n\n    def start_server(self):\n        from toolboxv2.utils.system.api import manage_server\n        if self.is_server:\n            return\n        manage_server(\"start\")\n        self.is_server = False\n\n    @staticmethod\n    def exit_main(*args, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    @staticmethod\n    async def hide_console(*args, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    @staticmethod\n    async def show_console(*args, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    @staticmethod\n    async def disconnect(*args, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    def set_logger(self, debug=False):\n        \"\"\"proxi attr\"\"\"\n\n    @property\n    def debug(self):\n        \"\"\"proxi attr\"\"\"\n        return self._debug\n\n    def debug_rains(self, e):\n        \"\"\"proxi attr\"\"\"\n\n    def set_flows(self, r):\n        \"\"\"proxi attr\"\"\"\n\n    def run_flows(self, name, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    def rrun_flows(self, name, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    def idle(self):\n        import time\n        self.print(\"idle\")\n        try:\n            while self.alive:\n                time.sleep(1)\n        except KeyboardInterrupt:\n            pass\n        self.print(\"idle done\")\n\n    async def a_idle(self):\n        self.print(\"a idle\")\n        try:\n            if hasattr(self, 'daemon_app'):\n                self.print(\"serving daemon\")\n                await self.daemon_app.connect(self)\n            else:\n                self.print(\"serving default\")\n                while self.alive:\n                    await asyncio.sleep(1)\n        except KeyboardInterrupt:\n            pass\n        self.print(\"a idle done\")\n\n    @debug.setter\n    def debug(self, value):\n        \"\"\"proxi attr\"\"\"\n\n    def _coppy_mod(self, content, new_mod_dir, mod_name, file_type='py'):\n        \"\"\"proxi attr\"\"\"\n\n    def _pre_lib_mod(self, mod_name, path_to=\"./runtime\", file_type='py'):\n        \"\"\"proxi attr\"\"\"\n\n    def _copy_load(self, mod_name, file_type='py', **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    def inplace_load_instance(self, mod_name, loc=\"toolboxv2.mods.\", spec='app', save=True):\n        \"\"\"proxi attr\"\"\"\n\n    def save_instance(self, instance, modular_id, spec='app', instance_type=\"file/application\", tools_class=None):\n        \"\"\"proxi attr\"\"\"\n\n    def save_initialized_module(self, tools_class, spec):\n        \"\"\"proxi attr\"\"\"\n\n    def mod_online(self, mod_name, installed=False):\n        \"\"\"proxi attr\"\"\"\n\n    def _get_function(self,\n                      name: Enum or None,\n                      state: bool = True,\n                      specification: str = \"app\",\n                      metadata=False, as_str: tuple or None = None, r=0):\n        \"\"\"proxi attr\"\"\"\n\n    def save_exit(self):\n        \"\"\"proxi attr\"\"\"\n\n    def load_mod(self, mod_name: str, mlm='I', **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    async def init_module(self, modular):\n        return await self.load_mod(modular)\n\n    async def load_all_mods_in_file(self, working_dir=\"mods\"):\n        \"\"\"proxi attr\"\"\"\n\n    def get_all_mods(self, working_dir=\"mods\", path_to=\"./runtime\"):\n        \"\"\"proxi attr\"\"\"\n\n    def remove_all_modules(self, delete=False):\n        for mod in list(self.functions.keys()):\n            self.logger.info(f\"closing: {mod}\")\n            self.remove_mod(mod, delete=delete)\n\n    async def a_remove_all_modules(self, delete=False):\n        for mod in list(self.functions.keys()):\n            self.logger.info(f\"closing: {mod}\")\n            await self.a_remove_mod(mod, delete=delete)\n\n    def print_ok(self):\n        \"\"\"proxi attr\"\"\"\n        self.logger.info(\"OK\")\n\n    def reload_mod(self, mod_name, spec='app', is_file=True, loc=\"toolboxv2.mods.\"):\n        \"\"\"proxi attr\"\"\"\n\n    def watch_mod(self, mod_name, spec='app', loc=\"toolboxv2.mods.\", use_thread=True, path_name=None):\n        \"\"\"proxi attr\"\"\"\n\n    def remove_mod(self, mod_name, spec='app', delete=True):\n        \"\"\"proxi attr\"\"\"\n\n    async def a_remove_mod(self, mod_name, spec='app', delete=True):\n        \"\"\"proxi attr\"\"\"\n\n    def exit(self):\n        \"\"\"proxi attr\"\"\"\n\n    def web_context(self) -&gt; str:\n        \"\"\"returns the build index ( toolbox web component )\"\"\"\n\n    async def a_exit(self):\n        \"\"\"proxi attr\"\"\"\n\n    def save_load(self, modname, spec='app'):\n        \"\"\"proxi attr\"\"\"\n\n    def get_function(self, name: Enum or tuple, **kwargs):\n        \"\"\"\n        Kwargs for _get_function\n            metadata:: return the registered function dictionary\n                stateless: (function_data, None), 0\n                stateful: (function_data, higher_order_function), 0\n            state::boolean\n                specification::str default app\n        \"\"\"\n\n    def run_a_from_sync(self, function, *args):\n        \"\"\"\n        run a async fuction\n        \"\"\"\n\n    def run_bg_task_advanced(self, task, *args, **kwargs):\n        \"\"\"\n        proxi attr\n        \"\"\"\n\n    def wait_for_bg_tasks(self, timeout=None):\n        \"\"\"\n        proxi attr\n        \"\"\"\n\n    def run_bg_task(self, task):\n        \"\"\"\n                run a async fuction\n                \"\"\"\n    def run_function(self, mod_function_name: Enum or tuple,\n                     tb_run_function_with_state=True,\n                     tb_run_with_specification='app',\n                     args_=None,\n                     kwargs_=None,\n                     *args,\n                     **kwargs) -&gt; Result:\n\n        \"\"\"proxi attr\"\"\"\n\n    async def a_run_function(self, mod_function_name: Enum or tuple,\n                             tb_run_function_with_state=True,\n                             tb_run_with_specification='app',\n                             args_=None,\n                             kwargs_=None,\n                             *args,\n                             **kwargs) -&gt; Result:\n\n        \"\"\"proxi attr\"\"\"\n\n    def fuction_runner(self, function, function_data: dict, args: list, kwargs: dict, t0=.0):\n        \"\"\"\n        parameters = function_data.get('params')\n        modular_name = function_data.get('module_name')\n        function_name = function_data.get('func_name')\n        mod_function_name = f\"{modular_name}.{function_name}\"\n\n        proxi attr\n        \"\"\"\n\n    async def a_fuction_runner(self, function, function_data: dict, args: list, kwargs: dict):\n        \"\"\"\n        parameters = function_data.get('params')\n        modular_name = function_data.get('module_name')\n        function_name = function_data.get('func_name')\n        mod_function_name = f\"{modular_name}.{function_name}\"\n\n        proxi attr\n        \"\"\"\n\n    async def run_http(self, mod_function_name: Enum or str or tuple, function_name=None, method=\"GET\",\n                       args_=None,\n                       kwargs_=None,\n                       *args, **kwargs):\n        \"\"\"run a function remote via http / https\"\"\"\n\n    def run_any(self, mod_function_name: Enum or str or tuple, backwords_compability_variabel_string_holder=None,\n                get_results=False, tb_run_function_with_state=True, tb_run_with_specification='app', args_=None,\n                kwargs_=None,\n                *args, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    async def a_run_any(self, mod_function_name: Enum or str or tuple,\n                        backwords_compability_variabel_string_holder=None,\n                        get_results=False, tb_run_function_with_state=True, tb_run_with_specification='app', args_=None,\n                        kwargs_=None,\n                        *args, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    def get_mod(self, name, spec='app') -&gt; ModuleType or MainToolType:\n        \"\"\"proxi attr\"\"\"\n\n    @staticmethod\n    def print(text, *args, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    @staticmethod\n    def sprint(text, *args, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    # ----------------------------------------------------------------\n    # Decorators for the toolbox\n\n    def _register_function(self, module_name, func_name, data):\n        \"\"\"proxi attr\"\"\"\n\n    def _create_decorator(self, type_: str,\n                          name: str = \"\",\n                          mod_name: str = \"\",\n                          level: int = -1,\n                          restrict_in_virtual_mode: bool = False,\n                          api: bool = False,\n                          helper: str = \"\",\n                          version: str or None = None,\n                          initial=False,\n                          exit_f=False,\n                          test=True,\n                          samples=None,\n                          state=None,\n                          pre_compute=None,\n                          post_compute=None,\n                          memory_cache=False,\n                          file_cache=False,\n                          row=False,\n                          request_as_kwarg=False,\n                          memory_cache_max_size=100,\n                          memory_cache_ttl=300,\n                          websocket_handler: str | None = None,):\n        \"\"\"proxi attr\"\"\"\n\n        # data = {\n        #     \"type\": type_,\n        #     \"module_name\": module_name,\n        #     \"func_name\": func_name,\n        #     \"level\": level,\n        #     \"restrict_in_virtual_mode\": restrict_in_virtual_mode,\n        #     \"func\": func,\n        #     \"api\": api,\n        #     \"helper\": helper,\n        #     \"version\": version,\n        #     \"initial\": initial,\n        #     \"exit_f\": exit_f,\n        #     \"__module__\": func.__module__,\n        #     \"signature\": sig,\n        #     \"params\": params,\n        #     \"state\": (\n        #         False if len(params) == 0 else params[0] in ['self', 'state', 'app']) if state is None else state,\n        #     \"do_test\": test,\n        #     \"samples\": samples,\n        #     \"request_as_kwarg\": request_as_kwarg,\n\n    def tb(self, name=None,\n           mod_name: str = \"\",\n           helper: str = \"\",\n           version: str or None = None,\n           test: bool = True,\n           restrict_in_virtual_mode: bool = False,\n           api: bool = False,\n           initial: bool = False,\n           exit_f: bool = False,\n           test_only: bool = False,\n           memory_cache: bool = False,\n           file_cache: bool = False,\n           row=False,\n           request_as_kwarg: bool = False,\n           state: bool or None = None,\n           level: int = 0,\n           memory_cache_max_size: int = 100,\n           memory_cache_ttl: int = 300,\n           samples: list or dict or None = None,\n           interface: ToolBoxInterfaces or None or str = None,\n           pre_compute=None,\n           post_compute=None,\n           api_methods=None,\n           websocket_handler: str | None = None,\n           ):\n        \"\"\"\n    A decorator for registering and configuring functions within a module.\n\n    This decorator is used to wrap functions with additional functionality such as caching, API conversion, and lifecycle management (initialization and exit). It also handles the registration of the function in the module's function registry.\n\n    Args:\n        name (str, optional): The name to register the function under. Defaults to the function's own name.\n        mod_name (str, optional): The name of the module the function belongs to.\n        helper (str, optional): A helper string providing additional information about the function.\n        version (str or None, optional): The version of the function or module.\n        test (bool, optional): Flag to indicate if the function is for testing purposes.\n        restrict_in_virtual_mode (bool, optional): Flag to restrict the function in virtual mode.\n        api (bool, optional): Flag to indicate if the function is part of an API.\n        initial (bool, optional): Flag to indicate if the function should be executed at initialization.\n        exit_f (bool, optional): Flag to indicate if the function should be executed at exit.\n        test_only (bool, optional): Flag to indicate if the function should only be used for testing.\n        memory_cache (bool, optional): Flag to enable memory caching for the function.\n        request_as_kwarg (bool, optional): Flag to get request if the fuction is calld from api.\n        file_cache (bool, optional): Flag to enable file caching for the function.\n        row (bool, optional): rather to auto wrap the result in Result type default False means no row data aka result type\n        state (bool or None, optional): Flag to indicate if the function maintains state.\n        level (int, optional): The level of the function, used for prioritization or categorization.\n        memory_cache_max_size (int, optional): Maximum size of the memory cache.\n        memory_cache_ttl (int, optional): Time-to-live for the memory cache entries.\n        samples (list or dict or None, optional): Samples or examples of function usage.\n        interface (str, optional): The interface type for the function.\n        pre_compute (callable, optional): A function to be called before the main function.\n        post_compute (callable, optional): A function to be called after the main function.\n        api_methods (list[str], optional): default [\"AUTO\"] (GET if not params, POST if params) , GET, POST, PUT or DELETE.\n\n    Returns:\n        function: The decorated function with additional processing and registration capabilities.\n    \"\"\"\n        if interface is None:\n            interface = \"tb\"\n        if test_only and 'test' not in self.id:\n            return lambda *args, **kwargs: args\n        return self._create_decorator(interface,\n                                      name,\n                                      mod_name,\n                                      level=level,\n                                      restrict_in_virtual_mode=restrict_in_virtual_mode,\n                                      helper=helper,\n                                      api=api,\n                                      version=version,\n                                      initial=initial,\n                                      exit_f=exit_f,\n                                      test=test,\n                                      samples=samples,\n                                      state=state,\n                                      pre_compute=pre_compute,\n                                      post_compute=post_compute,\n                                      memory_cache=memory_cache,\n                                      file_cache=file_cache,\n                                      row=row,\n                                      request_as_kwarg=request_as_kwarg,\n                                      memory_cache_max_size=memory_cache_max_size,\n                                      memory_cache_ttl=memory_cache_ttl)\n\n    def print_functions(self, name=None):\n\n\n        if not self.functions:\n            print(\"Nothing to see\")\n            return\n\n        def helper(_functions):\n            for func_name, data in _functions.items():\n                if not isinstance(data, dict):\n                    continue\n\n                func_type = data.get('type', 'Unknown')\n                func_level = 'r' if data['level'] == -1 else data['level']\n                api_status = 'Api' if data.get('api', False) else 'Non-Api'\n\n                print(f\"  Function: {func_name}{data.get('signature', '()')}; \"\n                      f\"Type: {func_type}, Level: {func_level}, {api_status}\")\n\n        if name is not None:\n            functions = self.functions.get(name)\n            if functions is not None:\n                print(f\"\\nModule: {name}; Type: {functions.get('app_instance_type', 'Unknown')}\")\n                helper(functions)\n                return\n        for module, functions in self.functions.items():\n            print(f\"\\nModule: {module}; Type: {functions.get('app_instance_type', 'Unknown')}\")\n            helper(functions)\n\n    def save_autocompletion_dict(self):\n        \"\"\"proxi attr\"\"\"\n\n    def get_autocompletion_dict(self):\n        \"\"\"proxi attr\"\"\"\n\n    def get_username(self, get_input=False, default=\"loot\") -&gt; str:\n        \"\"\"proxi attr\"\"\"\n\n    def save_registry_as_enums(self, directory: str, filename: str):\n        \"\"\"proxi attr\"\"\"\n\n    async def execute_all_functions_(self, m_query='', f_query=''):\n        print(\"Executing all functions\")\n        from ..extras import generate_test_cases\n        all_data = {\n            \"modular_run\": 0,\n            \"modular_fatal_error\": 0,\n            \"errors\": 0,\n            \"modular_sug\": 0,\n            \"coverage\": [],\n            \"total_coverage\": {},\n        }\n        items = list(self.functions.items()).copy()\n        for module_name, functions in items:\n            infos = {\n                \"functions_run\": 0,\n                \"functions_fatal_error\": 0,\n                \"error\": 0,\n                \"functions_sug\": 0,\n                'calls': {},\n                'callse': {},\n                \"coverage\": [0, 0],\n            }\n            all_data['modular_run'] += 1\n            if not module_name.startswith(m_query):\n                all_data['modular_sug'] += 1\n                continue\n\n            with Spinner(message=f\"In {module_name}| \"):\n                f_items = list(functions.items()).copy()\n                for function_name, function_data in f_items:\n                    if not isinstance(function_data, dict):\n                        continue\n                    if not function_name.startswith(f_query):\n                        continue\n                    test: list = function_data.get('do_test')\n                    # print(test, module_name, function_name, function_data)\n                    infos[\"coverage\"][0] += 1\n                    if test is False:\n                        continue\n\n                    with Spinner(message=f\"\\t\\t\\t\\t\\t\\tfuction {function_name}...\"):\n                        params: list = function_data.get('params')\n                        sig: signature = function_data.get('signature')\n                        state: bool = function_data.get('state')\n                        samples: bool = function_data.get('samples')\n\n                        test_kwargs_list = [{}]\n\n                        if params is not None:\n                            test_kwargs_list = samples if samples is not None else generate_test_cases(sig=sig)\n                            # print(test_kwargs)\n                            # print(test_kwargs[0])\n                            # test_kwargs = test_kwargs_list[0]\n                        # print(module_name, function_name, test_kwargs_list)\n                        infos[\"coverage\"][1] += 1\n                        for test_kwargs in test_kwargs_list:\n                            try:\n                                # print(f\"test Running {state=} |{module_name}.{function_name}\")\n                                result = await self.a_run_function((module_name, function_name),\n                                                                   tb_run_function_with_state=state,\n                                                                   **test_kwargs)\n                                if not isinstance(result, Result):\n                                    result = Result.ok(result)\n                                if result.info.exec_code == 0:\n                                    infos['calls'][function_name] = [test_kwargs, str(result)]\n                                    infos['functions_sug'] += 1\n                                else:\n                                    infos['functions_sug'] += 1\n                                    infos['error'] += 1\n                                    infos['callse'][function_name] = [test_kwargs, str(result)]\n                            except Exception as e:\n                                infos['functions_fatal_error'] += 1\n                                infos['callse'][function_name] = [test_kwargs, str(e)]\n                            finally:\n                                infos['functions_run'] += 1\n\n                if infos['functions_run'] == infos['functions_sug']:\n                    all_data['modular_sug'] += 1\n                else:\n                    all_data['modular_fatal_error'] += 1\n                if infos['error'] &gt; 0:\n                    all_data['errors'] += infos['error']\n\n                all_data[module_name] = infos\n                if infos['coverage'][0] == 0:\n                    c = 0\n                else:\n                    c = infos['coverage'][1] / infos['coverage'][0]\n                all_data[\"coverage\"].append(f\"{module_name}:{c:.2f}\\n\")\n        total_coverage = sum([float(t.split(\":\")[-1]) for t in all_data[\"coverage\"]]) / len(all_data[\"coverage\"])\n        print(\n            f\"\\n{all_data['modular_run']=}\\n{all_data['modular_sug']=}\\n{all_data['modular_fatal_error']=}\\n{total_coverage=}\")\n        d = analyze_data(all_data)\n        return Result.ok(data=all_data, data_info=d)\n\n    @staticmethod\n    def calculate_complexity(filename_or_code):\n        from radon.complexity import cc_rank, cc_visit\n        if os.path.exists(filename_or_code):\n            with open(filename_or_code) as file:\n                code = file.read()\n        else:\n            code = filename_or_code\n\n        # Calculate and print Cyclomatic Complexity\n        complexity_results = cc_visit(code)\n        i = -1\n        avg_complexity = 0\n        for block in complexity_results:\n            complexity = block.complexity\n            i += 1\n            print(f\"block: {block.name} {i} Class/Fuction/Methode : {block.letter}\")\n            print(f\"    fullname: {block.fullname}\")\n            print(f\"    Cyclomatic Complexity: {complexity}\")\n            # Optional: Get complexity rank\n            avg_complexity += complexity\n            rank = cc_rank(complexity)\n            print(f\"    Complexity Rank: {rank}\")\n            # print(f\"    lineno: {block.lineno}\")\n            print(f\"    endline: {block.endline}\")\n            print(f\"    col_offset: {block.col_offset}\\n\")\n        if i &lt;= 0:\n            i += 2\n        avg_complexity = avg_complexity / i\n        print(f\"\\nAVG Complexity: {avg_complexity:.2f}\")\n        print(f\"Total Rank: {cc_rank(int(avg_complexity + i // 10))}\")\n\n    async def execute_function_test(self, module_name: str, function_name: str,\n                                    function_data: dict, test_kwargs: dict,\n                                    profiler: cProfile.Profile) -&gt; tuple[bool, str, dict, float]:\n        start_time = time.time()\n        with profile_section(profiler, hasattr(self, 'enable_profiling') and self.enable_profiling):\n            try:\n                result = await self.a_run_function(\n                    (module_name, function_name),\n                    tb_run_function_with_state=function_data.get('state'),\n                    **test_kwargs\n                )\n\n                if not isinstance(result, Result):\n                    result = Result.ok(result)\n\n                success = result.info.exec_code == 0\n                execution_time = time.time() - start_time\n                return success, str(result), test_kwargs, execution_time\n            except Exception as e:\n                execution_time = time.time() - start_time\n                return False, str(e), test_kwargs, execution_time\n\n    async def process_function(self, module_name: str, function_name: str,\n                               function_data: dict, profiler: cProfile.Profile) -&gt; tuple[str, ModuleInfo]:\n        start_time = time.time()\n        info = ModuleInfo()\n\n        with profile_section(profiler, hasattr(self, 'enable_profiling') and self.enable_profiling):\n            if not isinstance(function_data, dict):\n                return function_name, info\n\n            test = function_data.get('do_test')\n            info.coverage[0] += 1\n\n            if test is False:\n                return function_name, info\n\n            params = function_data.get('params')\n            sig = function_data.get('signature')\n            samples = function_data.get('samples')\n\n            test_kwargs_list = [{}] if params is None else (\n                samples if samples is not None else generate_test_cases(sig=sig)\n            )\n\n            info.coverage[1] += 1\n\n            # Create tasks for all test cases\n            tasks = [\n                self.execute_function_test(module_name, function_name, function_data, test_kwargs, profiler)\n                for test_kwargs in test_kwargs_list\n            ]\n\n            # Execute all tests concurrently\n            results = await asyncio.gather(*tasks)\n\n            total_execution_time = 0\n            for success, result_str, test_kwargs, execution_time in results:\n                info.functions_run += 1\n                total_execution_time += execution_time\n\n                if success:\n                    info.functions_sug += 1\n                    info.calls[function_name] = [test_kwargs, result_str]\n                else:\n                    info.functions_sug += 1\n                    info.error += 1\n                    info.callse[function_name] = [test_kwargs, result_str]\n\n            info.execution_time = time.time() - start_time\n            return function_name, info\n\n    async def process_module(self, module_name: str, functions: dict,\n                             f_query: str, profiler: cProfile.Profile) -&gt; tuple[str, ModuleInfo]:\n        start_time = time.time()\n\n        with profile_section(profiler, hasattr(self, 'enable_profiling') and self.enable_profiling):\n            async with asyncio.Semaphore(mp.cpu_count()):\n                tasks = [\n                    self.process_function(module_name, fname, fdata, profiler)\n                    for fname, fdata in functions.items()\n                    if fname.startswith(f_query)\n                ]\n\n                if not tasks:\n                    return module_name, ModuleInfo()\n\n                results = await asyncio.gather(*tasks)\n\n                # Combine results from all functions in the module\n                combined_info = ModuleInfo()\n                total_execution_time = 0\n\n                for _, info in results:\n                    combined_info.functions_run += info.functions_run\n                    combined_info.functions_fatal_error += info.functions_fatal_error\n                    combined_info.error += info.error\n                    combined_info.functions_sug += info.functions_sug\n                    combined_info.calls.update(info.calls)\n                    combined_info.callse.update(info.callse)\n                    combined_info.coverage[0] += info.coverage[0]\n                    combined_info.coverage[1] += info.coverage[1]\n                    total_execution_time += info.execution_time\n\n                combined_info.execution_time = time.time() - start_time\n                return module_name, combined_info\n\n    async def execute_all_functions(self, m_query='', f_query='', enable_profiling=True):\n        \"\"\"\n        Execute all functions with parallel processing and optional profiling.\n\n        Args:\n            m_query (str): Module name query filter\n            f_query (str): Function name query filter\n            enable_profiling (bool): Enable detailed profiling information\n        \"\"\"\n        print(\"Executing all functions in parallel\" + (\" with profiling\" if enable_profiling else \"\"))\n\n        start_time = time.time()\n        stats = ExecutionStats()\n        items = list(self.functions.items()).copy()\n\n        # Set up profiling\n        self.enable_profiling = enable_profiling\n        profiler = cProfile.Profile()\n\n        with profile_section(profiler, enable_profiling):\n            # Filter modules based on query\n            filtered_modules = [\n                (mname, mfuncs) for mname, mfuncs in items\n                if mname.startswith(m_query)\n            ]\n\n            stats.modular_run = len(filtered_modules)\n\n            # Process all modules concurrently\n            async with asyncio.Semaphore(mp.cpu_count()):\n                tasks = [\n                    self.process_module(mname, mfuncs, f_query, profiler)\n                    for mname, mfuncs in filtered_modules\n                ]\n\n                results = await asyncio.gather(*tasks)\n\n            # Combine results and calculate statistics\n            for module_name, info in results:\n                if info.functions_run == info.functions_sug:\n                    stats.modular_sug += 1\n                else:\n                    stats.modular_fatal_error += 1\n\n                stats.errors += info.error\n\n                # Calculate coverage\n                coverage = (info.coverage[1] / info.coverage[0]) if info.coverage[0] &gt; 0 else 0\n                stats.coverage.append(f\"{module_name}:{coverage:.2f}\\n\")\n\n                # Store module info\n                stats.__dict__[module_name] = info\n\n            # Calculate total coverage\n            total_coverage = (\n                sum(float(t.split(\":\")[-1]) for t in stats.coverage) / len(stats.coverage)\n                if stats.coverage else 0\n            )\n\n            stats.total_execution_time = time.time() - start_time\n\n            # Generate profiling stats if enabled\n            if enable_profiling:\n                s = io.StringIO()\n                ps = pstats.Stats(profiler, stream=s).sort_stats('cumulative')\n                ps.print_stats()\n                stats.profiling_data = {\n                    'detailed_stats': s.getvalue(),\n                    'total_time': stats.total_execution_time,\n                    'function_count': stats.modular_run,\n                    'successful_functions': stats.modular_sug\n                }\n\n            print(\n                f\"\\n{stats.modular_run=}\"\n                f\"\\n{stats.modular_sug=}\"\n                f\"\\n{stats.modular_fatal_error=}\"\n                f\"\\n{total_coverage=}\"\n                f\"\\nTotal execution time: {stats.total_execution_time:.2f}s\"\n            )\n\n            if enable_profiling:\n                print(\"\\nProfiling Summary:\")\n                print(f\"{'=' * 50}\")\n                print(\"Top 10 time-consuming functions:\")\n                ps.print_stats(10)\n\n            analyzed_data = analyze_data(stats.__dict__)\n            return Result.ok(data=stats.__dict__, data_info=analyzed_data)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.debug","title":"<code>debug</code>  <code>property</code> <code>writable</code>","text":"<p>proxi attr</p>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.prefix","title":"<code>prefix = prefix</code>  <code>instance-attribute</code>","text":"<p>proxi attr</p>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.a_exit","title":"<code>a_exit()</code>  <code>async</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>async def a_exit(self):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.a_fuction_runner","title":"<code>a_fuction_runner(function, function_data, args, kwargs)</code>  <code>async</code>","text":"<p>parameters = function_data.get('params') modular_name = function_data.get('module_name') function_name = function_data.get('func_name') mod_function_name = f\"{modular_name}.{function_name}\"</p> <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>async def a_fuction_runner(self, function, function_data: dict, args: list, kwargs: dict):\n    \"\"\"\n    parameters = function_data.get('params')\n    modular_name = function_data.get('module_name')\n    function_name = function_data.get('func_name')\n    mod_function_name = f\"{modular_name}.{function_name}\"\n\n    proxi attr\n    \"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.a_remove_mod","title":"<code>a_remove_mod(mod_name, spec='app', delete=True)</code>  <code>async</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>async def a_remove_mod(self, mod_name, spec='app', delete=True):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.a_run_any","title":"<code>a_run_any(mod_function_name, backwords_compability_variabel_string_holder=None, get_results=False, tb_run_function_with_state=True, tb_run_with_specification='app', args_=None, kwargs_=None, *args, **kwargs)</code>  <code>async</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>async def a_run_any(self, mod_function_name: Enum or str or tuple,\n                    backwords_compability_variabel_string_holder=None,\n                    get_results=False, tb_run_function_with_state=True, tb_run_with_specification='app', args_=None,\n                    kwargs_=None,\n                    *args, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.a_run_function","title":"<code>a_run_function(mod_function_name, tb_run_function_with_state=True, tb_run_with_specification='app', args_=None, kwargs_=None, *args, **kwargs)</code>  <code>async</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>async def a_run_function(self, mod_function_name: Enum or tuple,\n                         tb_run_function_with_state=True,\n                         tb_run_with_specification='app',\n                         args_=None,\n                         kwargs_=None,\n                         *args,\n                         **kwargs) -&gt; Result:\n\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.debug_rains","title":"<code>debug_rains(e)</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def debug_rains(self, e):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.disconnect","title":"<code>disconnect(*args, **kwargs)</code>  <code>async</code> <code>staticmethod</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@staticmethod\nasync def disconnect(*args, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.execute_all_functions","title":"<code>execute_all_functions(m_query='', f_query='', enable_profiling=True)</code>  <code>async</code>","text":"<p>Execute all functions with parallel processing and optional profiling.</p> <p>Parameters:</p> Name Type Description Default <code>m_query</code> <code>str</code> <p>Module name query filter</p> <code>''</code> <code>f_query</code> <code>str</code> <p>Function name query filter</p> <code>''</code> <code>enable_profiling</code> <code>bool</code> <p>Enable detailed profiling information</p> <code>True</code> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>async def execute_all_functions(self, m_query='', f_query='', enable_profiling=True):\n    \"\"\"\n    Execute all functions with parallel processing and optional profiling.\n\n    Args:\n        m_query (str): Module name query filter\n        f_query (str): Function name query filter\n        enable_profiling (bool): Enable detailed profiling information\n    \"\"\"\n    print(\"Executing all functions in parallel\" + (\" with profiling\" if enable_profiling else \"\"))\n\n    start_time = time.time()\n    stats = ExecutionStats()\n    items = list(self.functions.items()).copy()\n\n    # Set up profiling\n    self.enable_profiling = enable_profiling\n    profiler = cProfile.Profile()\n\n    with profile_section(profiler, enable_profiling):\n        # Filter modules based on query\n        filtered_modules = [\n            (mname, mfuncs) for mname, mfuncs in items\n            if mname.startswith(m_query)\n        ]\n\n        stats.modular_run = len(filtered_modules)\n\n        # Process all modules concurrently\n        async with asyncio.Semaphore(mp.cpu_count()):\n            tasks = [\n                self.process_module(mname, mfuncs, f_query, profiler)\n                for mname, mfuncs in filtered_modules\n            ]\n\n            results = await asyncio.gather(*tasks)\n\n        # Combine results and calculate statistics\n        for module_name, info in results:\n            if info.functions_run == info.functions_sug:\n                stats.modular_sug += 1\n            else:\n                stats.modular_fatal_error += 1\n\n            stats.errors += info.error\n\n            # Calculate coverage\n            coverage = (info.coverage[1] / info.coverage[0]) if info.coverage[0] &gt; 0 else 0\n            stats.coverage.append(f\"{module_name}:{coverage:.2f}\\n\")\n\n            # Store module info\n            stats.__dict__[module_name] = info\n\n        # Calculate total coverage\n        total_coverage = (\n            sum(float(t.split(\":\")[-1]) for t in stats.coverage) / len(stats.coverage)\n            if stats.coverage else 0\n        )\n\n        stats.total_execution_time = time.time() - start_time\n\n        # Generate profiling stats if enabled\n        if enable_profiling:\n            s = io.StringIO()\n            ps = pstats.Stats(profiler, stream=s).sort_stats('cumulative')\n            ps.print_stats()\n            stats.profiling_data = {\n                'detailed_stats': s.getvalue(),\n                'total_time': stats.total_execution_time,\n                'function_count': stats.modular_run,\n                'successful_functions': stats.modular_sug\n            }\n\n        print(\n            f\"\\n{stats.modular_run=}\"\n            f\"\\n{stats.modular_sug=}\"\n            f\"\\n{stats.modular_fatal_error=}\"\n            f\"\\n{total_coverage=}\"\n            f\"\\nTotal execution time: {stats.total_execution_time:.2f}s\"\n        )\n\n        if enable_profiling:\n            print(\"\\nProfiling Summary:\")\n            print(f\"{'=' * 50}\")\n            print(\"Top 10 time-consuming functions:\")\n            ps.print_stats(10)\n\n        analyzed_data = analyze_data(stats.__dict__)\n        return Result.ok(data=stats.__dict__, data_info=analyzed_data)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.exit","title":"<code>exit()</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def exit(self):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.exit_main","title":"<code>exit_main(*args, **kwargs)</code>  <code>staticmethod</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@staticmethod\ndef exit_main(*args, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.fuction_runner","title":"<code>fuction_runner(function, function_data, args, kwargs, t0=0.0)</code>","text":"<p>parameters = function_data.get('params') modular_name = function_data.get('module_name') function_name = function_data.get('func_name') mod_function_name = f\"{modular_name}.{function_name}\"</p> <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def fuction_runner(self, function, function_data: dict, args: list, kwargs: dict, t0=.0):\n    \"\"\"\n    parameters = function_data.get('params')\n    modular_name = function_data.get('module_name')\n    function_name = function_data.get('func_name')\n    mod_function_name = f\"{modular_name}.{function_name}\"\n\n    proxi attr\n    \"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.get_all_mods","title":"<code>get_all_mods(working_dir='mods', path_to='./runtime')</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def get_all_mods(self, working_dir=\"mods\", path_to=\"./runtime\"):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.get_autocompletion_dict","title":"<code>get_autocompletion_dict()</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def get_autocompletion_dict(self):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.get_function","title":"<code>get_function(name, **kwargs)</code>","text":"<p>Kwargs for _get_function     metadata:: return the registered function dictionary         stateless: (function_data, None), 0         stateful: (function_data, higher_order_function), 0     state::boolean         specification::str default app</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def get_function(self, name: Enum or tuple, **kwargs):\n    \"\"\"\n    Kwargs for _get_function\n        metadata:: return the registered function dictionary\n            stateless: (function_data, None), 0\n            stateful: (function_data, higher_order_function), 0\n        state::boolean\n            specification::str default app\n    \"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.get_mod","title":"<code>get_mod(name, spec='app')</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def get_mod(self, name, spec='app') -&gt; ModuleType or MainToolType:\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.get_username","title":"<code>get_username(get_input=False, default='loot')</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def get_username(self, get_input=False, default=\"loot\") -&gt; str:\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.hide_console","title":"<code>hide_console(*args, **kwargs)</code>  <code>async</code> <code>staticmethod</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@staticmethod\nasync def hide_console(*args, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.inplace_load_instance","title":"<code>inplace_load_instance(mod_name, loc='toolboxv2.mods.', spec='app', save=True)</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def inplace_load_instance(self, mod_name, loc=\"toolboxv2.mods.\", spec='app', save=True):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.load_all_mods_in_file","title":"<code>load_all_mods_in_file(working_dir='mods')</code>  <code>async</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>async def load_all_mods_in_file(self, working_dir=\"mods\"):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.load_mod","title":"<code>load_mod(mod_name, mlm='I', **kwargs)</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def load_mod(self, mod_name: str, mlm='I', **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.mod_online","title":"<code>mod_online(mod_name, installed=False)</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def mod_online(self, mod_name, installed=False):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.print","title":"<code>print(text, *args, **kwargs)</code>  <code>staticmethod</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@staticmethod\ndef print(text, *args, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.print_ok","title":"<code>print_ok()</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def print_ok(self):\n    \"\"\"proxi attr\"\"\"\n    self.logger.info(\"OK\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.reload_mod","title":"<code>reload_mod(mod_name, spec='app', is_file=True, loc='toolboxv2.mods.')</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def reload_mod(self, mod_name, spec='app', is_file=True, loc=\"toolboxv2.mods.\"):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.remove_mod","title":"<code>remove_mod(mod_name, spec='app', delete=True)</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def remove_mod(self, mod_name, spec='app', delete=True):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.rrun_flows","title":"<code>rrun_flows(name, **kwargs)</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def rrun_flows(self, name, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.run_a_from_sync","title":"<code>run_a_from_sync(function, *args)</code>","text":"<p>run a async fuction</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def run_a_from_sync(self, function, *args):\n    \"\"\"\n    run a async fuction\n    \"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.run_any","title":"<code>run_any(mod_function_name, backwords_compability_variabel_string_holder=None, get_results=False, tb_run_function_with_state=True, tb_run_with_specification='app', args_=None, kwargs_=None, *args, **kwargs)</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def run_any(self, mod_function_name: Enum or str or tuple, backwords_compability_variabel_string_holder=None,\n            get_results=False, tb_run_function_with_state=True, tb_run_with_specification='app', args_=None,\n            kwargs_=None,\n            *args, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.run_bg_task","title":"<code>run_bg_task(task)</code>","text":"<p>run a async fuction</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def run_bg_task(self, task):\n    \"\"\"\n            run a async fuction\n            \"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.run_bg_task_advanced","title":"<code>run_bg_task_advanced(task, *args, **kwargs)</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def run_bg_task_advanced(self, task, *args, **kwargs):\n    \"\"\"\n    proxi attr\n    \"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.run_flows","title":"<code>run_flows(name, **kwargs)</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def run_flows(self, name, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.run_function","title":"<code>run_function(mod_function_name, tb_run_function_with_state=True, tb_run_with_specification='app', args_=None, kwargs_=None, *args, **kwargs)</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def run_function(self, mod_function_name: Enum or tuple,\n                 tb_run_function_with_state=True,\n                 tb_run_with_specification='app',\n                 args_=None,\n                 kwargs_=None,\n                 *args,\n                 **kwargs) -&gt; Result:\n\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.run_http","title":"<code>run_http(mod_function_name, function_name=None, method='GET', args_=None, kwargs_=None, *args, **kwargs)</code>  <code>async</code>","text":"<p>run a function remote via http / https</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>async def run_http(self, mod_function_name: Enum or str or tuple, function_name=None, method=\"GET\",\n                   args_=None,\n                   kwargs_=None,\n                   *args, **kwargs):\n    \"\"\"run a function remote via http / https\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.save_autocompletion_dict","title":"<code>save_autocompletion_dict()</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def save_autocompletion_dict(self):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.save_exit","title":"<code>save_exit()</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def save_exit(self):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.save_initialized_module","title":"<code>save_initialized_module(tools_class, spec)</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def save_initialized_module(self, tools_class, spec):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.save_instance","title":"<code>save_instance(instance, modular_id, spec='app', instance_type='file/application', tools_class=None)</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def save_instance(self, instance, modular_id, spec='app', instance_type=\"file/application\", tools_class=None):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.save_load","title":"<code>save_load(modname, spec='app')</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def save_load(self, modname, spec='app'):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.save_registry_as_enums","title":"<code>save_registry_as_enums(directory, filename)</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def save_registry_as_enums(self, directory: str, filename: str):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.set_flows","title":"<code>set_flows(r)</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def set_flows(self, r):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.set_logger","title":"<code>set_logger(debug=False)</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def set_logger(self, debug=False):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.show_console","title":"<code>show_console(*args, **kwargs)</code>  <code>async</code> <code>staticmethod</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@staticmethod\nasync def show_console(*args, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.sprint","title":"<code>sprint(text, *args, **kwargs)</code>  <code>staticmethod</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@staticmethod\ndef sprint(text, *args, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.tb","title":"<code>tb(name=None, mod_name='', helper='', version=None, test=True, restrict_in_virtual_mode=False, api=False, initial=False, exit_f=False, test_only=False, memory_cache=False, file_cache=False, row=False, request_as_kwarg=False, state=None, level=0, memory_cache_max_size=100, memory_cache_ttl=300, samples=None, interface=None, pre_compute=None, post_compute=None, api_methods=None, websocket_handler=None)</code>","text":"<p>A decorator for registering and configuring functions within a module.</p> <p>This decorator is used to wrap functions with additional functionality such as caching, API conversion, and lifecycle management (initialization and exit). It also handles the registration of the function in the module's function registry.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name to register the function under. Defaults to the function's own name.</p> <code>None</code> <code>mod_name</code> <code>str</code> <p>The name of the module the function belongs to.</p> <code>''</code> <code>helper</code> <code>str</code> <p>A helper string providing additional information about the function.</p> <code>''</code> <code>version</code> <code>str or None</code> <p>The version of the function or module.</p> <code>None</code> <code>test</code> <code>bool</code> <p>Flag to indicate if the function is for testing purposes.</p> <code>True</code> <code>restrict_in_virtual_mode</code> <code>bool</code> <p>Flag to restrict the function in virtual mode.</p> <code>False</code> <code>api</code> <code>bool</code> <p>Flag to indicate if the function is part of an API.</p> <code>False</code> <code>initial</code> <code>bool</code> <p>Flag to indicate if the function should be executed at initialization.</p> <code>False</code> <code>exit_f</code> <code>bool</code> <p>Flag to indicate if the function should be executed at exit.</p> <code>False</code> <code>test_only</code> <code>bool</code> <p>Flag to indicate if the function should only be used for testing.</p> <code>False</code> <code>memory_cache</code> <code>bool</code> <p>Flag to enable memory caching for the function.</p> <code>False</code> <code>request_as_kwarg</code> <code>bool</code> <p>Flag to get request if the fuction is calld from api.</p> <code>False</code> <code>file_cache</code> <code>bool</code> <p>Flag to enable file caching for the function.</p> <code>False</code> <code>row</code> <code>bool</code> <p>rather to auto wrap the result in Result type default False means no row data aka result type</p> <code>False</code> <code>state</code> <code>bool or None</code> <p>Flag to indicate if the function maintains state.</p> <code>None</code> <code>level</code> <code>int</code> <p>The level of the function, used for prioritization or categorization.</p> <code>0</code> <code>memory_cache_max_size</code> <code>int</code> <p>Maximum size of the memory cache.</p> <code>100</code> <code>memory_cache_ttl</code> <code>int</code> <p>Time-to-live for the memory cache entries.</p> <code>300</code> <code>samples</code> <code>list or dict or None</code> <p>Samples or examples of function usage.</p> <code>None</code> <code>interface</code> <code>str</code> <p>The interface type for the function.</p> <code>None</code> <code>pre_compute</code> <code>callable</code> <p>A function to be called before the main function.</p> <code>None</code> <code>post_compute</code> <code>callable</code> <p>A function to be called after the main function.</p> <code>None</code> <code>api_methods</code> <code>list[str]</code> <p>default [\"AUTO\"] (GET if not params, POST if params) , GET, POST, PUT or DELETE.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>function</code> <p>The decorated function with additional processing and registration capabilities.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def tb(self, name=None,\n       mod_name: str = \"\",\n       helper: str = \"\",\n       version: str or None = None,\n       test: bool = True,\n       restrict_in_virtual_mode: bool = False,\n       api: bool = False,\n       initial: bool = False,\n       exit_f: bool = False,\n       test_only: bool = False,\n       memory_cache: bool = False,\n       file_cache: bool = False,\n       row=False,\n       request_as_kwarg: bool = False,\n       state: bool or None = None,\n       level: int = 0,\n       memory_cache_max_size: int = 100,\n       memory_cache_ttl: int = 300,\n       samples: list or dict or None = None,\n       interface: ToolBoxInterfaces or None or str = None,\n       pre_compute=None,\n       post_compute=None,\n       api_methods=None,\n       websocket_handler: str | None = None,\n       ):\n    \"\"\"\nA decorator for registering and configuring functions within a module.\n\nThis decorator is used to wrap functions with additional functionality such as caching, API conversion, and lifecycle management (initialization and exit). It also handles the registration of the function in the module's function registry.\n\nArgs:\n    name (str, optional): The name to register the function under. Defaults to the function's own name.\n    mod_name (str, optional): The name of the module the function belongs to.\n    helper (str, optional): A helper string providing additional information about the function.\n    version (str or None, optional): The version of the function or module.\n    test (bool, optional): Flag to indicate if the function is for testing purposes.\n    restrict_in_virtual_mode (bool, optional): Flag to restrict the function in virtual mode.\n    api (bool, optional): Flag to indicate if the function is part of an API.\n    initial (bool, optional): Flag to indicate if the function should be executed at initialization.\n    exit_f (bool, optional): Flag to indicate if the function should be executed at exit.\n    test_only (bool, optional): Flag to indicate if the function should only be used for testing.\n    memory_cache (bool, optional): Flag to enable memory caching for the function.\n    request_as_kwarg (bool, optional): Flag to get request if the fuction is calld from api.\n    file_cache (bool, optional): Flag to enable file caching for the function.\n    row (bool, optional): rather to auto wrap the result in Result type default False means no row data aka result type\n    state (bool or None, optional): Flag to indicate if the function maintains state.\n    level (int, optional): The level of the function, used for prioritization or categorization.\n    memory_cache_max_size (int, optional): Maximum size of the memory cache.\n    memory_cache_ttl (int, optional): Time-to-live for the memory cache entries.\n    samples (list or dict or None, optional): Samples or examples of function usage.\n    interface (str, optional): The interface type for the function.\n    pre_compute (callable, optional): A function to be called before the main function.\n    post_compute (callable, optional): A function to be called after the main function.\n    api_methods (list[str], optional): default [\"AUTO\"] (GET if not params, POST if params) , GET, POST, PUT or DELETE.\n\nReturns:\n    function: The decorated function with additional processing and registration capabilities.\n\"\"\"\n    if interface is None:\n        interface = \"tb\"\n    if test_only and 'test' not in self.id:\n        return lambda *args, **kwargs: args\n    return self._create_decorator(interface,\n                                  name,\n                                  mod_name,\n                                  level=level,\n                                  restrict_in_virtual_mode=restrict_in_virtual_mode,\n                                  helper=helper,\n                                  api=api,\n                                  version=version,\n                                  initial=initial,\n                                  exit_f=exit_f,\n                                  test=test,\n                                  samples=samples,\n                                  state=state,\n                                  pre_compute=pre_compute,\n                                  post_compute=post_compute,\n                                  memory_cache=memory_cache,\n                                  file_cache=file_cache,\n                                  row=row,\n                                  request_as_kwarg=request_as_kwarg,\n                                  memory_cache_max_size=memory_cache_max_size,\n                                  memory_cache_ttl=memory_cache_ttl)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.wait_for_bg_tasks","title":"<code>wait_for_bg_tasks(timeout=None)</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def wait_for_bg_tasks(self, timeout=None):\n    \"\"\"\n    proxi attr\n    \"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.watch_mod","title":"<code>watch_mod(mod_name, spec='app', loc='toolboxv2.mods.', use_thread=True, path_name=None)</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def watch_mod(self, mod_name, spec='app', loc=\"toolboxv2.mods.\", use_thread=True, path_name=None):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.AppType.web_context","title":"<code>web_context()</code>","text":"<p>returns the build index ( toolbox web component )</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def web_context(self) -&gt; str:\n    \"\"\"returns the build index ( toolbox web component )\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.MainTool","title":"<code>MainTool</code>","text":"Source code in <code>toolboxv2/utils/system/main_tool.py</code> <pre><code>class MainTool:\n    toolID: str = \"\"\n    # app = None\n    interface = None\n    spec = \"app\"\n    name = \"\"\n    color = \"Bold\"\n    stuf = False\n\n    def __init__(self, *args, **kwargs):\n        \"\"\"\n        Standard constructor used for arguments pass\n        Do not override. Use __ainit__ instead\n        \"\"\"\n        self.__storedargs = args, kwargs\n        self.tools = kwargs.get(\"tool\", {})\n        self.logger = kwargs.get(\"logs\", get_logger())\n        self.color = kwargs.get(\"color\", \"WHITE\")\n        self.todo = kwargs.get(\"load\", kwargs.get(\"on_start\", lambda: None))\n        if \"on_exit\" in kwargs and isinstance(kwargs.get(\"on_exit\"), Callable):\n            self.on_exit =self.app.tb(\n                mod_name=self.name,\n                name=kwargs.get(\"on_exit\").__name__,\n                version=self.version if hasattr(self, 'version') else \"0.0.0\",\n            )(kwargs.get(\"on_exit\"))\n        self.async_initialized = False\n        if self.todo:\n            try:\n                if inspect.iscoroutinefunction(self.todo):\n                    pass\n                else:\n                    self.todo()\n                get_logger().info(f\"{self.name} on load suspended\")\n            except Exception as e:\n                get_logger().error(f\"Error loading mod {self.name} {e}\")\n                if self.app.debug:\n                    import traceback\n                    traceback.print_exc()\n        else:\n            get_logger().info(f\"{self.name} no load require\")\n\n    async def __ainit__(self, *args, **kwargs):\n        self.version = kwargs[\"v\"]\n        self.tools = kwargs.get(\"tool\", {})\n        self.name = kwargs[\"name\"]\n        self.logger = kwargs.get(\"logs\", get_logger())\n        self.color = kwargs.get(\"color\", \"WHITE\")\n        self.todo = kwargs.get(\"load\", kwargs.get(\"on_start\"))\n        if not hasattr(self, 'config'):\n            self.config = {}\n        self.user = None\n        self.description = \"A toolbox mod\" if kwargs.get(\"description\") is None else kwargs.get(\"description\")\n        if MainTool.interface is None:\n            MainTool.interface = self.app.interface_type\n        # Result.default(self.app.interface)\n\n        if self.todo:\n            try:\n                if inspect.iscoroutinefunction(self.todo):\n                    await self.todo()\n                else:\n                    pass\n                await asyncio.sleep(0.1)\n                get_logger().info(f\"{self.name} on load suspended\")\n            except Exception as e:\n                get_logger().error(f\"Error loading mod {self.name} {e}\")\n                if self.app.debug:\n                    import traceback\n                    traceback.print_exc()\n        else:\n            get_logger().info(f\"{self.name} no load require\")\n        self.app.print(f\"TOOL : {self.spec}.{self.name} online\")\n\n\n\n    @property\n    def app(self):\n        return get_app(\n            from_=f\"{self.spec}.{self.name}|{self.toolID if self.toolID else '*' + MainTool.toolID} {self.interface if self.interface else MainTool.interface}\")\n\n    @app.setter\n    def app(self, v):\n        raise PermissionError(f\"You cannot set the App Instance! {v=}\")\n\n    @staticmethod\n    def return_result(error: ToolBoxError = ToolBoxError.none,\n                      exec_code: int = 0,\n                      help_text: str = \"\",\n                      data_info=None,\n                      data=None,\n                      data_to=None):\n\n        if data_to is None:\n            data_to = MainTool.interface if MainTool.interface is not None else ToolBoxInterfaces.cli\n\n        if data is None:\n            data = {}\n\n        if data_info is None:\n            data_info = {}\n\n        return Result(\n            error,\n            ToolBoxResult(data_info=data_info, data=data, data_to=data_to),\n            ToolBoxInfo(exec_code=exec_code, help_text=help_text)\n        )\n\n    def print(self, message, end=\"\\n\", **kwargs):\n        if self.stuf:\n            return\n\n        self.app.print(Style.style_dic[self.color] + self.name + Style.style_dic[\"END\"] + \":\", message, end=end,\n                       **kwargs)\n\n    def add_str_to_config(self, command):\n        if len(command) != 2:\n            self.logger.error('Invalid command must be key value')\n            return False\n        self.config[command[0]] = command[1]\n\n    def webInstall(self, user_instance, construct_render) -&gt; str:\n        \"\"\"\"Returns a web installer for the given user instance and construct render template\"\"\"\n\n    def get_version(self) -&gt; str:\n        \"\"\"\"Returns the version\"\"\"\n        return self.version\n\n    async def get_user(self, username: str) -&gt; Result:\n        return await self.app.a_run_any(CLOUDM_AUTHMANAGER.GET_USER_BY_NAME, username=username, get_results=True)\n\n    async def __initobj(self):\n        \"\"\"Crutch used for __await__ after spawning\"\"\"\n        assert not self.async_initialized\n        self.async_initialized = True\n        # pass the parameters to __ainit__ that passed to __init__\n        await self.__ainit__(*self.__storedargs[0], **self.__storedargs[1])\n        return self\n\n    def __await__(self):\n        return self.__initobj().__await__()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.MainTool.__init__","title":"<code>__init__(*args, **kwargs)</code>","text":"<p>Standard constructor used for arguments pass Do not override. Use ainit instead</p> Source code in <code>toolboxv2/utils/system/main_tool.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"\n    Standard constructor used for arguments pass\n    Do not override. Use __ainit__ instead\n    \"\"\"\n    self.__storedargs = args, kwargs\n    self.tools = kwargs.get(\"tool\", {})\n    self.logger = kwargs.get(\"logs\", get_logger())\n    self.color = kwargs.get(\"color\", \"WHITE\")\n    self.todo = kwargs.get(\"load\", kwargs.get(\"on_start\", lambda: None))\n    if \"on_exit\" in kwargs and isinstance(kwargs.get(\"on_exit\"), Callable):\n        self.on_exit =self.app.tb(\n            mod_name=self.name,\n            name=kwargs.get(\"on_exit\").__name__,\n            version=self.version if hasattr(self, 'version') else \"0.0.0\",\n        )(kwargs.get(\"on_exit\"))\n    self.async_initialized = False\n    if self.todo:\n        try:\n            if inspect.iscoroutinefunction(self.todo):\n                pass\n            else:\n                self.todo()\n            get_logger().info(f\"{self.name} on load suspended\")\n        except Exception as e:\n            get_logger().error(f\"Error loading mod {self.name} {e}\")\n            if self.app.debug:\n                import traceback\n                traceback.print_exc()\n    else:\n        get_logger().info(f\"{self.name} no load require\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.MainTool.__initobj","title":"<code>__initobj()</code>  <code>async</code>","text":"<p>Crutch used for await after spawning</p> Source code in <code>toolboxv2/utils/system/main_tool.py</code> <pre><code>async def __initobj(self):\n    \"\"\"Crutch used for __await__ after spawning\"\"\"\n    assert not self.async_initialized\n    self.async_initialized = True\n    # pass the parameters to __ainit__ that passed to __init__\n    await self.__ainit__(*self.__storedargs[0], **self.__storedargs[1])\n    return self\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.MainTool.get_version","title":"<code>get_version()</code>","text":"<p>\"Returns the version</p> Source code in <code>toolboxv2/utils/system/main_tool.py</code> <pre><code>def get_version(self) -&gt; str:\n    \"\"\"\"Returns the version\"\"\"\n    return self.version\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.MainTool.webInstall","title":"<code>webInstall(user_instance, construct_render)</code>","text":"<p>\"Returns a web installer for the given user instance and construct render template</p> Source code in <code>toolboxv2/utils/system/main_tool.py</code> <pre><code>def webInstall(self, user_instance, construct_render) -&gt; str:\n    \"\"\"\"Returns a web installer for the given user instance and construct render template\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.MainToolType","title":"<code>MainToolType</code>","text":"Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>class MainToolType:\n    toolID: str\n    app: A\n    interface: ToolBoxInterfaces\n    spec: str\n\n    version: str\n    tools: dict  # legacy\n    name: str\n    logger: logging\n    color: str\n    todo: Callable\n    _on_exit: Callable\n    stuf: bool\n    config: dict\n    user: U | None\n    description: str\n\n    @staticmethod\n    def return_result(error: ToolBoxError = ToolBoxError.none,\n                      exec_code: int = 0,\n                      help_text: str = \"\",\n                      data_info=None,\n                      data=None,\n                      data_to=None) -&gt; Result:\n        \"\"\"proxi attr\"\"\"\n\n    def load(self):\n        \"\"\"proxi attr\"\"\"\n\n    def print(self, message, end=\"\\n\", **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    def add_str_to_config(self, command):\n        if len(command) != 2:\n            self.logger.error('Invalid command must be key value')\n            return False\n        self.config[command[0]] = command[1]\n\n    def webInstall(self, user_instance, construct_render) -&gt; str:\n        \"\"\"\"Returns a web installer for the given user instance and construct render template\"\"\"\n\n    async def get_user(self, username: str) -&gt; Result:\n        return self.app.a_run_any(CLOUDM_AUTHMANAGER.GET_USER_BY_NAME, username=username, get_results=True)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.MainToolType.load","title":"<code>load()</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def load(self):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.MainToolType.print","title":"<code>print(message, end='\\n', **kwargs)</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def print(self, message, end=\"\\n\", **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.MainToolType.return_result","title":"<code>return_result(error=ToolBoxError.none, exec_code=0, help_text='', data_info=None, data=None, data_to=None)</code>  <code>staticmethod</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@staticmethod\ndef return_result(error: ToolBoxError = ToolBoxError.none,\n                  exec_code: int = 0,\n                  help_text: str = \"\",\n                  data_info=None,\n                  data=None,\n                  data_to=None) -&gt; Result:\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.MainToolType.webInstall","title":"<code>webInstall(user_instance, construct_render)</code>","text":"<p>\"Returns a web installer for the given user instance and construct render template</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def webInstall(self, user_instance, construct_render) -&gt; str:\n    \"\"\"\"Returns a web installer for the given user instance and construct render template\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.Result","title":"<code>Result</code>","text":"Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>class Result:\n    _task = None\n    def __init__(self,\n                 error: ToolBoxError,\n                 result: ToolBoxResult,\n                 info: ToolBoxInfo,\n                 origin: Any | None = None,\n                 ):\n        self.error: ToolBoxError = error\n        self.result: ToolBoxResult = result\n        self.info: ToolBoxInfo = info\n        self.origin = origin\n\n    def as_result(self):\n        return self\n\n    def as_dict(self):\n        return {\n            \"error\":self.error.value if isinstance(self.error, Enum) else self.error,\n        \"result\" : {\n            \"data_to\":self.result.data_to.value if isinstance(self.result.data_to, Enum) else self.result.data_to,\n            \"data_info\":self.result.data_info,\n            \"data\":self.result.data,\n            \"data_type\":self.result.data_type\n        } if self.result else None,\n        \"info\" : {\n            \"exec_code\" : self.info.exec_code,  # exec_code umwandel in http resposn codes\n        \"help_text\" : self.info.help_text\n        } if self.info else None,\n        \"origin\" : self.origin\n        }\n\n    def set_origin(self, origin):\n        if self.origin is not None:\n            raise ValueError(\"You cannot Change the origin of a Result!\")\n        self.origin = origin\n        return self\n\n    def set_dir_origin(self, name, extras=\"assets/\"):\n        if self.origin is not None:\n            raise ValueError(\"You cannot Change the origin of a Result!\")\n        self.origin = f\"mods/{name}/{extras}\"\n        return self\n\n    def is_error(self):\n        if _test_is_result(self.result.data):\n            return self.result.data.is_error()\n        if self.error == ToolBoxError.none:\n            return False\n        if self.info.exec_code == 0:\n            return False\n        return self.info.exec_code != 200\n\n    def is_ok(self):\n        return not self.is_error()\n\n    def is_data(self):\n        return self.result.data is not None\n\n    def to_api_result(self):\n        # print(f\" error={self.error}, result= {self.result}, info= {self.info}, origin= {self.origin}\")\n        return ApiResult(\n            error=self.error.value if isinstance(self.error, Enum) else self.error,\n            result=ToolBoxResultBM(\n                data_to=self.result.data_to.value if isinstance(self.result.data_to, Enum) else self.result.data_to,\n                data_info=self.result.data_info,\n                data=self.result.data,\n                data_type=self.result.data_type\n            ) if self.result else None,\n            info=ToolBoxInfoBM(\n                exec_code=self.info.exec_code,  # exec_code umwandel in http resposn codes\n                help_text=self.info.help_text\n            ) if self.info else None,\n            origin=self.origin\n        )\n\n    def task(self, task):\n        self._task = task\n        return self\n\n    @staticmethod\n    def result_from_dict(error: str, result: dict, info: dict, origin: list or None or str):\n        # print(f\" error={self.error}, result= {self.result}, info= {self.info}, origin= {self.origin}\")\n        return ApiResult(\n            error=error if isinstance(error, Enum) else error,\n            result=ToolBoxResultBM(\n                data_to=result.get('data_to') if isinstance(result.get('data_to'), Enum) else result.get('data_to'),\n                data_info=result.get('data_info', '404'),\n                data=result.get('data'),\n                data_type=result.get('data_type', '404'),\n            ) if result else ToolBoxResultBM(\n                data_to=ToolBoxInterfaces.cli.value,\n                data_info='',\n                data='404',\n                data_type='404',\n            ),\n            info=ToolBoxInfoBM(\n                exec_code=info.get('exec_code', 404),\n                help_text=info.get('help_text', '404')\n            ) if info else ToolBoxInfoBM(\n                exec_code=404,\n                help_text='404'\n            ),\n            origin=origin\n        ).as_result()\n\n    @classmethod\n    def stream(cls,\n               stream_generator: Any,  # Renamed from source for clarity\n               content_type: str = \"text/event-stream\",  # Default to SSE\n               headers: dict | None = None,\n               info: str = \"OK\",\n               interface: ToolBoxInterfaces = ToolBoxInterfaces.remote,\n               cleanup_func: Callable[[], None] | Callable[[], T] | Callable[[], AsyncGenerator[T, None]] | None = None):\n        \"\"\"\n        Create a streaming response Result. Handles SSE and other stream types.\n\n        Args:\n            stream_generator: Any stream source (async generator, sync generator, iterable, or single item).\n            content_type: Content-Type header (default: text/event-stream for SSE).\n            headers: Additional HTTP headers for the response.\n            info: Help text for the result.\n            interface: Interface to send data to.\n            cleanup_func: Optional function for cleanup.\n\n        Returns:\n            A Result object configured for streaming.\n        \"\"\"\n        error = ToolBoxError.none\n        info_obj = ToolBoxInfo(exec_code=0, help_text=info)\n\n        final_generator: AsyncGenerator[str, None]\n\n        if content_type == \"text/event-stream\":\n            # For SSE, always use SSEGenerator.create_sse_stream to wrap the source.\n            # SSEGenerator.create_sse_stream handles various types of stream_generator internally.\n            final_generator = SSEGenerator.create_sse_stream(source=stream_generator, cleanup_func=cleanup_func)\n\n            # Standard SSE headers for the HTTP response itself\n            # These will be stored in the Result object. Rust side decides how to use them.\n            standard_sse_headers = {\n                \"Cache-Control\": \"no-cache\",  # SSE specific\n                \"Connection\": \"keep-alive\",  # SSE specific\n                \"X-Accel-Buffering\": \"no\",  # Useful for proxies with SSE\n                # Content-Type is implicitly text/event-stream, will be in streaming_data below\n            }\n            all_response_headers = standard_sse_headers.copy()\n            if headers:\n                all_response_headers.update(headers)\n        else:\n            # For non-SSE streams.\n            # If stream_generator is sync, wrap it to be async.\n            # If already async or single item, it will be handled.\n            # Rust's stream_generator in ToolboxClient seems to handle both sync/async Python generators.\n            # For consistency with how SSEGenerator does it, we can wrap sync ones.\n            if inspect.isgenerator(stream_generator) or \\\n                (not isinstance(stream_generator, str) and hasattr(stream_generator, '__iter__')):\n                final_generator = SSEGenerator.wrap_sync_generator(stream_generator)  # Simple async wrapper\n            elif inspect.isasyncgen(stream_generator):\n                final_generator = stream_generator\n            else:  # Single item or string\n                async def _single_item_gen():\n                    yield stream_generator\n\n                final_generator = _single_item_gen()\n            all_response_headers = headers if headers else {}\n\n        # Prepare streaming data to be stored in the Result object\n        streaming_data = {\n            \"type\": \"stream\",  # Indicator for Rust side\n            \"generator\": final_generator,\n            \"content_type\": content_type,  # Let Rust know the intended content type\n            \"headers\": all_response_headers  # Intended HTTP headers for the overall response\n        }\n\n        result_payload = ToolBoxResult(\n            data_to=interface,\n            data=streaming_data,\n            data_info=\"Streaming response\" if content_type != \"text/event-stream\" else \"SSE Event Stream\",\n            data_type=\"stream\"  # Generic type for Rust to identify it needs to stream from 'generator'\n        )\n\n        return cls(error=error, info=info_obj, result=result_payload)\n\n    @classmethod\n    def sse(cls,\n            stream_generator: Any,\n            info: str = \"OK\",\n            interface: ToolBoxInterfaces = ToolBoxInterfaces.remote,\n            cleanup_func: Callable[[], None] | Callable[[], T] | Callable[[], AsyncGenerator[T, None]] | None = None,\n            # http_headers: Optional[dict] = None # If we want to allow overriding default SSE HTTP headers\n            ):\n        \"\"\"\n        Create an Server-Sent Events (SSE) streaming response Result.\n\n        Args:\n            stream_generator: A source yielding individual data items. This can be an\n                              async generator, sync generator, iterable, or a single item.\n                              Each item will be formatted as an SSE event.\n            info: Optional help text for the Result.\n            interface: Optional ToolBoxInterface to target.\n            cleanup_func: Optional cleanup function to run when the stream ends or is cancelled.\n            #http_headers: Optional dictionary of custom HTTP headers for the SSE response.\n\n        Returns:\n            A Result object configured for SSE streaming.\n        \"\"\"\n        # Result.stream will handle calling SSEGenerator.create_sse_stream\n        # and setting appropriate default headers for SSE when content_type is \"text/event-stream\".\n        return cls.stream(\n            stream_generator=stream_generator,\n            content_type=\"text/event-stream\",\n            # headers=http_headers, # Pass if we add http_headers param\n            info=info,\n            interface=interface,\n            cleanup_func=cleanup_func\n        )\n\n    @classmethod\n    def default(cls, interface=ToolBoxInterfaces.native):\n        error = ToolBoxError.none\n        info = ToolBoxInfo(exec_code=-1, help_text=\"\")\n        result = ToolBoxResult(data_to=interface)\n        return cls(error=error, info=info, result=result)\n\n    @classmethod\n    def json(cls, data, info=\"OK\", interface=ToolBoxInterfaces.remote, exec_code=0, status_code=None):\n        \"\"\"Create a JSON response Result.\"\"\"\n        error = ToolBoxError.none\n        info_obj = ToolBoxInfo(exec_code=status_code or exec_code, help_text=info)\n\n        result = ToolBoxResult(\n            data_to=interface,\n            data=data,\n            data_info=\"JSON response\",\n            data_type=\"json\"\n        )\n\n        return cls(error=error, info=info_obj, result=result)\n\n    @classmethod\n    def text(cls, text_data, content_type=\"text/plain\",exec_code=None,status=200, info=\"OK\", interface=ToolBoxInterfaces.remote, headers=None):\n        \"\"\"Create a text response Result with specific content type.\"\"\"\n        if headers is not None:\n            return cls.html(text_data, status= exec_code or status, info=info, headers=headers)\n        error = ToolBoxError.none\n        info_obj = ToolBoxInfo(exec_code=exec_code or status, help_text=info)\n\n        result = ToolBoxResult(\n            data_to=interface,\n            data=text_data,\n            data_info=\"Text response\",\n            data_type=content_type\n        )\n\n        return cls(error=error, info=info_obj, result=result)\n\n    @classmethod\n    def binary(cls, data, content_type=\"application/octet-stream\", download_name=None, info=\"OK\",\n               interface=ToolBoxInterfaces.remote):\n        \"\"\"Create a binary data response Result.\"\"\"\n        error = ToolBoxError.none\n        info_obj = ToolBoxInfo(exec_code=0, help_text=info)\n\n        # Create a dictionary with binary data and metadata\n        binary_data = {\n            \"data\": data,\n            \"content_type\": content_type,\n            \"filename\": download_name\n        }\n\n        result = ToolBoxResult(\n            data_to=interface,\n            data=binary_data,\n            data_info=f\"Binary response: {download_name}\" if download_name else \"Binary response\",\n            data_type=\"binary\"\n        )\n\n        return cls(error=error, info=info_obj, result=result)\n\n    @classmethod\n    def file(cls, data, filename, content_type=None, info=\"OK\", interface=ToolBoxInterfaces.remote):\n        \"\"\"Create a file download response Result.\n\n        Args:\n            data: File data as bytes or base64 string\n            filename: Name of the file for download\n            content_type: MIME type of the file (auto-detected if None)\n            info: Response info text\n            interface: Target interface\n\n        Returns:\n            Result object configured for file download\n        \"\"\"\n        import base64\n        import mimetypes\n\n        error = ToolBoxError.none\n        info_obj = ToolBoxInfo(exec_code=200, help_text=info)\n\n        # Auto-detect content type if not provided\n        if content_type is None:\n            content_type, _ = mimetypes.guess_type(filename)\n            if content_type is None:\n                content_type = \"application/octet-stream\"\n\n        # Ensure data is base64 encoded string (as expected by Rust server)\n        if isinstance(data, bytes):\n            base64_data = base64.b64encode(data).decode('utf-8')\n        elif isinstance(data, str):\n            # Assume it's already base64 encoded\n            base64_data = data\n        else:\n            raise ValueError(\"File data must be bytes or base64 string\")\n\n        result = ToolBoxResult(\n            data_to=interface,\n            data=base64_data,  # Rust expects base64 string for \"file\" type\n            data_info=f\"File download: {filename}\",\n            data_type=\"file\"\n        )\n\n        return cls(error=error, info=info_obj, result=result)\n\n    @classmethod\n    def redirect(cls, url, status_code=302, info=\"Redirect\", interface=ToolBoxInterfaces.remote):\n        \"\"\"Create a redirect response.\"\"\"\n        error = ToolBoxError.none\n        info_obj = ToolBoxInfo(exec_code=status_code, help_text=info)\n\n        result = ToolBoxResult(\n            data_to=interface,\n            data=url,\n            data_info=\"Redirect response\",\n            data_type=\"redirect\"\n        )\n\n        return cls(error=error, info=info_obj, result=result)\n\n    @classmethod\n    def ok(cls, data=None, data_info=\"\", info=\"OK\", interface=ToolBoxInterfaces.native):\n        error = ToolBoxError.none\n        info = ToolBoxInfo(exec_code=0, help_text=info)\n        result = ToolBoxResult(data_to=interface, data=data, data_info=data_info, data_type=type(data).__name__)\n        return cls(error=error, info=info, result=result)\n\n    @classmethod\n    def html(cls, data=None, data_info=\"\", info=\"OK\", interface=ToolBoxInterfaces.remote, data_type=\"html\",status=200, headers=None, row=False):\n        error = ToolBoxError.none\n        info = ToolBoxInfo(exec_code=status, help_text=info)\n        from ...utils.system.getting_and_closing_app import get_app\n\n        if not row and not '\"&lt;div class=\"main-content\"\"' in data:\n            data = f'&lt;div class=\"main-content frosted-glass\"&gt;{data}&lt;div&gt;'\n        if not row and not get_app().web_context() in data:\n            data = get_app().web_context() + data\n\n        if isinstance(headers, dict):\n            result = ToolBoxResult(data_to=interface, data={'html':data,'headers':headers}, data_info=data_info,\n                                   data_type=\"special_html\")\n        else:\n            result = ToolBoxResult(data_to=interface, data=data, data_info=data_info,\n                                   data_type=data_type if data_type is not None else type(data).__name__)\n        return cls(error=error, info=info, result=result)\n\n    @classmethod\n    def future(cls, data=None, data_info=\"\", info=\"OK\", interface=ToolBoxInterfaces.future):\n        error = ToolBoxError.none\n        info = ToolBoxInfo(exec_code=0, help_text=info)\n        result = ToolBoxResult(data_to=interface, data=data, data_info=data_info, data_type=\"future\")\n        return cls(error=error, info=info, result=result)\n\n    @classmethod\n    def custom_error(cls, data=None, data_info=\"\", info=\"\", exec_code=-1, interface=ToolBoxInterfaces.native):\n        error = ToolBoxError.custom_error\n        info = ToolBoxInfo(exec_code=exec_code, help_text=info)\n        result = ToolBoxResult(data_to=interface, data=data, data_info=data_info, data_type=type(data).__name__)\n        return cls(error=error, info=info, result=result)\n\n    @classmethod\n    def error(cls, data=None, data_info=\"\", info=\"\", exec_code=450, interface=ToolBoxInterfaces.remote):\n        error = ToolBoxError.custom_error\n        info = ToolBoxInfo(exec_code=exec_code, help_text=info)\n        result = ToolBoxResult(data_to=interface, data=data, data_info=data_info, data_type=type(data).__name__)\n        return cls(error=error, info=info, result=result)\n\n    @classmethod\n    def default_user_error(cls, info=\"\", exec_code=-3, interface=ToolBoxInterfaces.native, data=None):\n        error = ToolBoxError.input_error\n        info = ToolBoxInfo(exec_code, info)\n        result = ToolBoxResult(data_to=interface, data=data, data_type=type(data).__name__)\n        return cls(error=error, info=info, result=result)\n\n    @classmethod\n    def default_internal_error(cls, info=\"\", exec_code=-2, interface=ToolBoxInterfaces.native, data=None):\n        error = ToolBoxError.internal_error\n        info = ToolBoxInfo(exec_code, info)\n        result = ToolBoxResult(data_to=interface, data=data, data_type=type(data).__name__)\n        return cls(error=error, info=info, result=result)\n\n    def print(self, show=True, show_data=True, prifix=\"\"):\n        data = '\\n' + f\"{((prifix + f'Data_{self.result.data_type}: ' + str(self.result.data) if self.result.data is not None else 'NO Data') if not isinstance(self.result.data, Result) else self.result.data.print(show=False, show_data=show_data, prifix=prifix + '-')) if show_data else 'Data: private'}\"\n        origin = '\\n' + f\"{prifix + 'Origin: ' + str(self.origin) if self.origin is not None else 'NO Origin'}\"\n        text = (f\"Function Exec code: {self.info.exec_code}\"\n                f\"\\n{prifix}Info's:\"\n                f\" {self.info.help_text} {'&lt;|&gt; ' + str(self.result.data_info) if self.result.data_info is not None else ''}\"\n                f\"{origin}{(data[:100]+'...') if not data.endswith('NO Data') else ''}\\n\")\n        if not show:\n            return text\n        print(\"\\n======== Result ========\\n\" + text + \"------- EndOfD -------\")\n        return self\n\n    def log(self, show_data=True, prifix=\"\"):\n        from toolboxv2 import get_logger\n        get_logger().debug(self.print(show=False, show_data=show_data, prifix=prifix).replace(\"\\n\", \" - \"))\n        return self\n\n    def __str__(self):\n        return self.print(show=False, show_data=True)\n\n    def get(self, key=None, default=None):\n        data = self.result.data\n        if isinstance(data, Result):\n            return data.get(key=key, default=default)\n        if key is not None and isinstance(data, dict):\n            return data.get(key, default)\n        return data if data is not None else default\n\n    async def aget(self, key=None, default=None):\n        if asyncio.isfuture(self.result.data) or asyncio.iscoroutine(self.result.data) or (\n            isinstance(self.result.data_to, Enum) and self.result.data_to.name == ToolBoxInterfaces.future.name):\n            data = await self.result.data\n        else:\n            data = self.get(key=None, default=None)\n        if isinstance(data, Result):\n            return data.get(key=key, default=default)\n        if key is not None and isinstance(data, dict):\n            return data.get(key, default)\n        return data if data is not None else default\n\n    def lazy_return(self, _=0, data=None, **kwargs):\n        flags = ['raise', 'logg', 'user', 'intern']\n        flag = flags[_] if isinstance(_, int) else _\n        if self.info.exec_code == 0:\n            return self if data is None else data if _test_is_result(data) else self.ok(data=data, **kwargs)\n        if flag == 'raise':\n            raise ValueError(self.print(show=False))\n        if flag == 'logg':\n            from .. import get_logger\n            get_logger().error(self.print(show=False))\n\n        if flag == 'user':\n            return self if data is None else data if _test_is_result(data) else self.default_user_error(data=data,\n                                                                                                        **kwargs)\n        if flag == 'intern':\n            return self if data is None else data if _test_is_result(data) else self.default_internal_error(data=data,\n                                                                                                            **kwargs)\n\n        return self if data is None else data if _test_is_result(data) else self.custom_error(data=data, **kwargs)\n\n    @property\n    def bg_task(self):\n        return self._task\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.Result.binary","title":"<code>binary(data, content_type='application/octet-stream', download_name=None, info='OK', interface=ToolBoxInterfaces.remote)</code>  <code>classmethod</code>","text":"<p>Create a binary data response Result.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@classmethod\ndef binary(cls, data, content_type=\"application/octet-stream\", download_name=None, info=\"OK\",\n           interface=ToolBoxInterfaces.remote):\n    \"\"\"Create a binary data response Result.\"\"\"\n    error = ToolBoxError.none\n    info_obj = ToolBoxInfo(exec_code=0, help_text=info)\n\n    # Create a dictionary with binary data and metadata\n    binary_data = {\n        \"data\": data,\n        \"content_type\": content_type,\n        \"filename\": download_name\n    }\n\n    result = ToolBoxResult(\n        data_to=interface,\n        data=binary_data,\n        data_info=f\"Binary response: {download_name}\" if download_name else \"Binary response\",\n        data_type=\"binary\"\n    )\n\n    return cls(error=error, info=info_obj, result=result)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.Result.file","title":"<code>file(data, filename, content_type=None, info='OK', interface=ToolBoxInterfaces.remote)</code>  <code>classmethod</code>","text":"<p>Create a file download response Result.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <p>File data as bytes or base64 string</p> required <code>filename</code> <p>Name of the file for download</p> required <code>content_type</code> <p>MIME type of the file (auto-detected if None)</p> <code>None</code> <code>info</code> <p>Response info text</p> <code>'OK'</code> <code>interface</code> <p>Target interface</p> <code>remote</code> <p>Returns:</p> Type Description <p>Result object configured for file download</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@classmethod\ndef file(cls, data, filename, content_type=None, info=\"OK\", interface=ToolBoxInterfaces.remote):\n    \"\"\"Create a file download response Result.\n\n    Args:\n        data: File data as bytes or base64 string\n        filename: Name of the file for download\n        content_type: MIME type of the file (auto-detected if None)\n        info: Response info text\n        interface: Target interface\n\n    Returns:\n        Result object configured for file download\n    \"\"\"\n    import base64\n    import mimetypes\n\n    error = ToolBoxError.none\n    info_obj = ToolBoxInfo(exec_code=200, help_text=info)\n\n    # Auto-detect content type if not provided\n    if content_type is None:\n        content_type, _ = mimetypes.guess_type(filename)\n        if content_type is None:\n            content_type = \"application/octet-stream\"\n\n    # Ensure data is base64 encoded string (as expected by Rust server)\n    if isinstance(data, bytes):\n        base64_data = base64.b64encode(data).decode('utf-8')\n    elif isinstance(data, str):\n        # Assume it's already base64 encoded\n        base64_data = data\n    else:\n        raise ValueError(\"File data must be bytes or base64 string\")\n\n    result = ToolBoxResult(\n        data_to=interface,\n        data=base64_data,  # Rust expects base64 string for \"file\" type\n        data_info=f\"File download: {filename}\",\n        data_type=\"file\"\n    )\n\n    return cls(error=error, info=info_obj, result=result)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.Result.json","title":"<code>json(data, info='OK', interface=ToolBoxInterfaces.remote, exec_code=0, status_code=None)</code>  <code>classmethod</code>","text":"<p>Create a JSON response Result.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@classmethod\ndef json(cls, data, info=\"OK\", interface=ToolBoxInterfaces.remote, exec_code=0, status_code=None):\n    \"\"\"Create a JSON response Result.\"\"\"\n    error = ToolBoxError.none\n    info_obj = ToolBoxInfo(exec_code=status_code or exec_code, help_text=info)\n\n    result = ToolBoxResult(\n        data_to=interface,\n        data=data,\n        data_info=\"JSON response\",\n        data_type=\"json\"\n    )\n\n    return cls(error=error, info=info_obj, result=result)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.Result.redirect","title":"<code>redirect(url, status_code=302, info='Redirect', interface=ToolBoxInterfaces.remote)</code>  <code>classmethod</code>","text":"<p>Create a redirect response.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@classmethod\ndef redirect(cls, url, status_code=302, info=\"Redirect\", interface=ToolBoxInterfaces.remote):\n    \"\"\"Create a redirect response.\"\"\"\n    error = ToolBoxError.none\n    info_obj = ToolBoxInfo(exec_code=status_code, help_text=info)\n\n    result = ToolBoxResult(\n        data_to=interface,\n        data=url,\n        data_info=\"Redirect response\",\n        data_type=\"redirect\"\n    )\n\n    return cls(error=error, info=info_obj, result=result)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.Result.sse","title":"<code>sse(stream_generator, info='OK', interface=ToolBoxInterfaces.remote, cleanup_func=None)</code>  <code>classmethod</code>","text":"<p>Create an Server-Sent Events (SSE) streaming response Result.</p> <p>Parameters:</p> Name Type Description Default <code>stream_generator</code> <code>Any</code> <p>A source yielding individual data items. This can be an               async generator, sync generator, iterable, or a single item.               Each item will be formatted as an SSE event.</p> required <code>info</code> <code>str</code> <p>Optional help text for the Result.</p> <code>'OK'</code> <code>interface</code> <code>ToolBoxInterfaces</code> <p>Optional ToolBoxInterface to target.</p> <code>remote</code> <code>cleanup_func</code> <code>Callable[[], None] | Callable[[], T] | Callable[[], AsyncGenerator[T, None]] | None</code> <p>Optional cleanup function to run when the stream ends or is cancelled.</p> <code>None</code> <code>#http_headers</code> <p>Optional dictionary of custom HTTP headers for the SSE response.</p> required <p>Returns:</p> Type Description <p>A Result object configured for SSE streaming.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@classmethod\ndef sse(cls,\n        stream_generator: Any,\n        info: str = \"OK\",\n        interface: ToolBoxInterfaces = ToolBoxInterfaces.remote,\n        cleanup_func: Callable[[], None] | Callable[[], T] | Callable[[], AsyncGenerator[T, None]] | None = None,\n        # http_headers: Optional[dict] = None # If we want to allow overriding default SSE HTTP headers\n        ):\n    \"\"\"\n    Create an Server-Sent Events (SSE) streaming response Result.\n\n    Args:\n        stream_generator: A source yielding individual data items. This can be an\n                          async generator, sync generator, iterable, or a single item.\n                          Each item will be formatted as an SSE event.\n        info: Optional help text for the Result.\n        interface: Optional ToolBoxInterface to target.\n        cleanup_func: Optional cleanup function to run when the stream ends or is cancelled.\n        #http_headers: Optional dictionary of custom HTTP headers for the SSE response.\n\n    Returns:\n        A Result object configured for SSE streaming.\n    \"\"\"\n    # Result.stream will handle calling SSEGenerator.create_sse_stream\n    # and setting appropriate default headers for SSE when content_type is \"text/event-stream\".\n    return cls.stream(\n        stream_generator=stream_generator,\n        content_type=\"text/event-stream\",\n        # headers=http_headers, # Pass if we add http_headers param\n        info=info,\n        interface=interface,\n        cleanup_func=cleanup_func\n    )\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.Result.stream","title":"<code>stream(stream_generator, content_type='text/event-stream', headers=None, info='OK', interface=ToolBoxInterfaces.remote, cleanup_func=None)</code>  <code>classmethod</code>","text":"<p>Create a streaming response Result. Handles SSE and other stream types.</p> <p>Parameters:</p> Name Type Description Default <code>stream_generator</code> <code>Any</code> <p>Any stream source (async generator, sync generator, iterable, or single item).</p> required <code>content_type</code> <code>str</code> <p>Content-Type header (default: text/event-stream for SSE).</p> <code>'text/event-stream'</code> <code>headers</code> <code>dict | None</code> <p>Additional HTTP headers for the response.</p> <code>None</code> <code>info</code> <code>str</code> <p>Help text for the result.</p> <code>'OK'</code> <code>interface</code> <code>ToolBoxInterfaces</code> <p>Interface to send data to.</p> <code>remote</code> <code>cleanup_func</code> <code>Callable[[], None] | Callable[[], T] | Callable[[], AsyncGenerator[T, None]] | None</code> <p>Optional function for cleanup.</p> <code>None</code> <p>Returns:</p> Type Description <p>A Result object configured for streaming.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@classmethod\ndef stream(cls,\n           stream_generator: Any,  # Renamed from source for clarity\n           content_type: str = \"text/event-stream\",  # Default to SSE\n           headers: dict | None = None,\n           info: str = \"OK\",\n           interface: ToolBoxInterfaces = ToolBoxInterfaces.remote,\n           cleanup_func: Callable[[], None] | Callable[[], T] | Callable[[], AsyncGenerator[T, None]] | None = None):\n    \"\"\"\n    Create a streaming response Result. Handles SSE and other stream types.\n\n    Args:\n        stream_generator: Any stream source (async generator, sync generator, iterable, or single item).\n        content_type: Content-Type header (default: text/event-stream for SSE).\n        headers: Additional HTTP headers for the response.\n        info: Help text for the result.\n        interface: Interface to send data to.\n        cleanup_func: Optional function for cleanup.\n\n    Returns:\n        A Result object configured for streaming.\n    \"\"\"\n    error = ToolBoxError.none\n    info_obj = ToolBoxInfo(exec_code=0, help_text=info)\n\n    final_generator: AsyncGenerator[str, None]\n\n    if content_type == \"text/event-stream\":\n        # For SSE, always use SSEGenerator.create_sse_stream to wrap the source.\n        # SSEGenerator.create_sse_stream handles various types of stream_generator internally.\n        final_generator = SSEGenerator.create_sse_stream(source=stream_generator, cleanup_func=cleanup_func)\n\n        # Standard SSE headers for the HTTP response itself\n        # These will be stored in the Result object. Rust side decides how to use them.\n        standard_sse_headers = {\n            \"Cache-Control\": \"no-cache\",  # SSE specific\n            \"Connection\": \"keep-alive\",  # SSE specific\n            \"X-Accel-Buffering\": \"no\",  # Useful for proxies with SSE\n            # Content-Type is implicitly text/event-stream, will be in streaming_data below\n        }\n        all_response_headers = standard_sse_headers.copy()\n        if headers:\n            all_response_headers.update(headers)\n    else:\n        # For non-SSE streams.\n        # If stream_generator is sync, wrap it to be async.\n        # If already async or single item, it will be handled.\n        # Rust's stream_generator in ToolboxClient seems to handle both sync/async Python generators.\n        # For consistency with how SSEGenerator does it, we can wrap sync ones.\n        if inspect.isgenerator(stream_generator) or \\\n            (not isinstance(stream_generator, str) and hasattr(stream_generator, '__iter__')):\n            final_generator = SSEGenerator.wrap_sync_generator(stream_generator)  # Simple async wrapper\n        elif inspect.isasyncgen(stream_generator):\n            final_generator = stream_generator\n        else:  # Single item or string\n            async def _single_item_gen():\n                yield stream_generator\n\n            final_generator = _single_item_gen()\n        all_response_headers = headers if headers else {}\n\n    # Prepare streaming data to be stored in the Result object\n    streaming_data = {\n        \"type\": \"stream\",  # Indicator for Rust side\n        \"generator\": final_generator,\n        \"content_type\": content_type,  # Let Rust know the intended content type\n        \"headers\": all_response_headers  # Intended HTTP headers for the overall response\n    }\n\n    result_payload = ToolBoxResult(\n        data_to=interface,\n        data=streaming_data,\n        data_info=\"Streaming response\" if content_type != \"text/event-stream\" else \"SSE Event Stream\",\n        data_type=\"stream\"  # Generic type for Rust to identify it needs to stream from 'generator'\n    )\n\n    return cls(error=error, info=info_obj, result=result_payload)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.Result.text","title":"<code>text(text_data, content_type='text/plain', exec_code=None, status=200, info='OK', interface=ToolBoxInterfaces.remote, headers=None)</code>  <code>classmethod</code>","text":"<p>Create a text response Result with specific content type.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@classmethod\ndef text(cls, text_data, content_type=\"text/plain\",exec_code=None,status=200, info=\"OK\", interface=ToolBoxInterfaces.remote, headers=None):\n    \"\"\"Create a text response Result with specific content type.\"\"\"\n    if headers is not None:\n        return cls.html(text_data, status= exec_code or status, info=info, headers=headers)\n    error = ToolBoxError.none\n    info_obj = ToolBoxInfo(exec_code=exec_code or status, help_text=info)\n\n    result = ToolBoxResult(\n        data_to=interface,\n        data=text_data,\n        data_info=\"Text response\",\n        data_type=content_type\n    )\n\n    return cls(error=error, info=info_obj, result=result)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.all_functions_enums","title":"<code>all_functions_enums</code>","text":"<p>Automatic generated by ToolBox v = 0.1.22</p>"},{"location":"toolboxv2/#toolboxv2.utils.system.api","title":"<code>api</code>","text":""},{"location":"toolboxv2/#toolboxv2.utils.system.api.build_cargo_project","title":"<code>build_cargo_project(debug=False)</code>","text":"<p>Build the Cargo project, optionally in debug mode.</p> Source code in <code>toolboxv2/utils/system/api.py</code> <pre><code>def build_cargo_project(debug=False):\n    \"\"\"Build the Cargo project, optionally in debug mode.\"\"\"\n    mode = \"debug\" if debug else \"release\"\n    args = [\"cargo\", \"build\"]\n    if not debug:\n        args.append(\"--release\")\n\n    print(f\"Building in {mode} mode...\")\n    try:\n        subprocess.run(args, cwd=os.path.join(\".\", \"src-core\"), check=True)\n        exe_path = get_executable_name_with_extension()\n        if exe_path:\n            bin_dir = tb_root_dir / \"bin\"\n            bin_dir.mkdir(exist_ok=True)\n            exe_path = Path(exe_path)\n            try:\n                shutil.copy(exe_path, bin_dir / exe_path.name)\n            except Exception:\n                bin_dir = tb_root_dir / \"ubin\"\n                bin_dir.mkdir(exist_ok=True)\n                (bin_dir / exe_path.name).unlink(missing_ok=True)\n                try:\n                    shutil.copy(exe_path, bin_dir / exe_path.name)\n                except Exception as e:\n                    print(f\"Failed to copy executable: {e}\")\n            print(f\"Copied executable to '{bin_dir.resolve()}'\")\n        return True\n    except subprocess.CalledProcessError as e:\n        print(f\"Cargo build failed: {e}\")\n        return False\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.api.check_cargo_installed","title":"<code>check_cargo_installed()</code>","text":"<p>Check if Cargo (Rust package manager) is installed on the system.</p> Source code in <code>toolboxv2/utils/system/api.py</code> <pre><code>def check_cargo_installed():\n    \"\"\"Check if Cargo (Rust package manager) is installed on the system.\"\"\"\n    try:\n        subprocess.run([\"cargo\", \"--version\"], check=True, capture_output=True)\n        return True\n    except Exception:\n        return False\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.api.cleanup_build_files","title":"<code>cleanup_build_files()</code>","text":"<p>Cleans up build files.</p> Source code in <code>toolboxv2/utils/system/api.py</code> <pre><code>def cleanup_build_files():\n    \"\"\"Cleans up build files.\"\"\"\n    src_core_path = os.path.join(\".\", \"src-core\")\n    target_path = os.path.join(src_core_path, \"target\")\n\n    if os.path.exists(target_path):\n        try:\n            print(f\"Cleaning up build files in {target_path}...\")\n            # First try using cargo clean\n            try:\n                subprocess.run([\"cargo\", \"clean\"], cwd=src_core_path, check=True)\n                print(\"Successfully cleaned up build files with cargo clean\")\n            except subprocess.CalledProcessError:\n                # If cargo clean fails, manually remove directories\n                print(\"Cargo clean failed, manually removing build directories...\")\n                for item in os.listdir(target_path):\n                    item_path = os.path.join(target_path, item)\n                    if os.path.isdir(item_path) and item != \".rustc_info.json\":\n                        shutil.rmtree(item_path)\n                        print(f\"Removed {item_path}\")\n            return True\n        except Exception as e:\n            print(f\"Failed to clean up build files: {e}\")\n            return False\n    else:\n        print(f\"Build directory {target_path} not found\")\n        return True\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.api.detect_os_and_arch","title":"<code>detect_os_and_arch()</code>","text":"<p>Detect the current operating system and architecture.</p> Source code in <code>toolboxv2/utils/system/api.py</code> <pre><code>def detect_os_and_arch():\n    \"\"\"Detect the current operating system and architecture.\"\"\"\n    current_os = platform.system().lower()  # e.g., 'windows', 'linux', 'darwin'\n    machine = platform.machine().lower()  # e.g., 'x86_64', 'amd64'\n    return current_os, machine\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.api.download_executable","title":"<code>download_executable(url, file_name)</code>","text":"<p>Attempt to download the executable from the provided URL.</p> Source code in <code>toolboxv2/utils/system/api.py</code> <pre><code>def download_executable(url, file_name):\n    \"\"\"Attempt to download the executable from the provided URL.\"\"\"\n    try:\n        import requests\n    except ImportError:\n        print(\"The 'requests' library is required. Please install it via pip install requests\")\n        sys.exit(1)\n\n    print(f\"Attempting to download executable from {url}...\")\n    try:\n        response = requests.get(url, stream=True)\n    except Exception as e:\n        print(f\"Download error: {e}\")\n        return None\n\n    if response.status_code == 200:\n        with open(file_name, \"wb\") as f:\n            for chunk in response.iter_content(chunk_size=8192):\n                if chunk:\n                    f.write(chunk)\n        # Make the file executable on non-Windows systems\n        if platform.system().lower() != \"windows\":\n            os.chmod(file_name, 0o755)\n        return file_name\n    else:\n        print(\"Download failed. Status code:\", response.status_code)\n        return None\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.api.find_highest_zip_version","title":"<code>find_highest_zip_version(name_filter, app_version=None, root_dir='mods_sto', version_only=False)</code>","text":"<p>Findet die h\u00f6chste verf\u00fcgbare ZIP-Version in einem Verzeichnis basierend auf einem Namensfilter.</p> <p>Parameters:</p> Name Type Description Default <code>root_dir</code> <code>str</code> <p>Wurzelverzeichnis f\u00fcr die Suche</p> <code>'mods_sto'</code> <code>name_filter</code> <code>str</code> <p>Namensfilter f\u00fcr die ZIP-Dateien</p> required <code>app_version</code> <code>str</code> <p>Aktuelle App-Version f\u00fcr Kompatibilit\u00e4tspr\u00fcfung</p> <code>None</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Pfad zur ZIP-Datei mit der h\u00f6chsten Version oder None wenn keine gefunden</p> Source code in <code>toolboxv2/utils/system/api.py</code> <pre><code>def find_highest_zip_version(name_filter: str, app_version: str = None, root_dir: str = \"mods_sto\", version_only=False) -&gt; str:\n    \"\"\"\n    Findet die h\u00f6chste verf\u00fcgbare ZIP-Version in einem Verzeichnis basierend auf einem Namensfilter.\n\n    Args:\n        root_dir (str): Wurzelverzeichnis f\u00fcr die Suche\n        name_filter (str): Namensfilter f\u00fcr die ZIP-Dateien\n        app_version (str, optional): Aktuelle App-Version f\u00fcr Kompatibilit\u00e4tspr\u00fcfung\n\n    Returns:\n        str: Pfad zur ZIP-Datei mit der h\u00f6chsten Version oder None wenn keine gefunden\n    \"\"\"\n\n    # Kompiliere den Regex-Pattern f\u00fcr die Dateinamen\n    pattern = fr\"{name_filter}&amp;v[0-9.]+\u00a7([0-9.]+)\\.zip$\"\n\n    highest_version = None\n    highest_version_file = None\n\n    # Durchsuche das Verzeichnis\n    root_path = Path(root_dir)\n    for file_path in root_path.rglob(\"*.zip\"):\n        if \"RST$\"+name_filter not in str(file_path):\n            continue\n        match = re.search(pattern, str(file_path).split(\"RST$\")[-1].strip())\n        if match:\n            zip_version = match.group(1)\n\n            # Pr\u00fcfe App-Version Kompatibilit\u00e4t falls angegeben\n            if app_version:\n                file_app_version = re.search(r\"&amp;v([0-9.]+)\u00a7\", str(file_path)).group(1)\n                if version.parse(file_app_version) &gt; version.parse(app_version):\n                    continue\n\n            # Vergleiche Versionen\n            current_version = version.parse(zip_version)\n            if highest_version is None or current_version &gt; highest_version:\n                highest_version = current_version\n                highest_version_file = str(file_path)\n    if version_only:\n        return str(highest_version)\n    return highest_version_file\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.api.find_highest_zip_version_entry","title":"<code>find_highest_zip_version_entry(name, target_app_version=None, filepath='tbState.yaml')</code>","text":"<p>Findet den Eintrag mit der h\u00f6chsten ZIP-Version f\u00fcr einen gegebenen Namen und eine optionale Ziel-App-Version in einer YAML-Datei.</p> <p>:param name: Der Name des gesuchten Eintrags. :param target_app_version: Die Zielversion der App als String (optional). :param filepath: Der Pfad zur YAML-Datei. :return: Den Eintrag mit der h\u00f6chsten ZIP-Version innerhalb der Ziel-App-Version oder None, falls nicht gefunden.</p> Source code in <code>toolboxv2/utils/system/api.py</code> <pre><code>def find_highest_zip_version_entry(name, target_app_version=None, filepath='tbState.yaml'):\n    \"\"\"\n    Findet den Eintrag mit der h\u00f6chsten ZIP-Version f\u00fcr einen gegebenen Namen und eine optionale Ziel-App-Version in einer YAML-Datei.\n\n    :param name: Der Name des gesuchten Eintrags.\n    :param target_app_version: Die Zielversion der App als String (optional).\n    :param filepath: Der Pfad zur YAML-Datei.\n    :return: Den Eintrag mit der h\u00f6chsten ZIP-Version innerhalb der Ziel-App-Version oder None, falls nicht gefunden.\n    \"\"\"\n    import yaml\n    highest_zip_ver = None\n    highest_entry = {}\n\n    with open(filepath) as file:\n        data = yaml.safe_load(file)\n        # print(data)\n        app_ver_h = None\n        for key, value in list(data.get('installable', {}).items())[::-1]:\n            # Pr\u00fcfe, ob der Name im Schl\u00fcssel enthalten ist\n\n            if name in key:\n                v = value['version']\n                if len(v) == 1:\n                    app_ver = v[0].split('v')[-1]\n                    zip_ver = \"0.0.0\"\n                else:\n                    app_ver, zip_ver = v\n                    app_ver = app_ver.split('v')[-1]\n                app_ver = version.parse(app_ver)\n                # Wenn eine Ziel-App-Version angegeben ist, vergleiche sie\n                if target_app_version is None or app_ver == version.parse(target_app_version):\n                    current_zip_ver = version.parse(zip_ver)\n                    # print(current_zip_ver, highest_zip_ver)\n\n                    if highest_zip_ver is None or current_zip_ver &gt; highest_zip_ver:\n                        highest_zip_ver = current_zip_ver\n                        highest_entry = value\n\n                    if app_ver_h is None or app_ver &gt; app_ver_h:\n                        app_ver_h = app_ver\n                        highest_zip_ver = current_zip_ver\n                        highest_entry = value\n    return highest_entry\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.api.get_executable_path","title":"<code>get_executable_path()</code>","text":"<p>Find the release executable in standard locations.</p> Source code in <code>toolboxv2/utils/system/api.py</code> <pre><code>def get_executable_path():\n    \"\"\"Find the release executable in standard locations.\"\"\"\n    # This function is simplified from your example to match this script's scope\n    exe_name = get_executable_name_with_extension()\n    from toolboxv2 import tb_root_dir\n    search_paths = [\n        tb_root_dir / Path(\"bin\") / exe_name,\n        tb_root_dir / Path(\"src-core\") / exe_name,\n        tb_root_dir / exe_name,\n        tb_root_dir / Path(\"src-core\") / \"target\" / \"release\" / exe_name,\n    ]\n    for path in search_paths:\n        print(path)\n        if path.exists() and path.is_file():\n            return path.resolve()\n    return None\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.api.query_executable_url","title":"<code>query_executable_url(current_os, machine)</code>","text":"<p>Query a remote URL for a matching executable based on OS and architecture. The file name is built dynamically based on parameters.</p> Source code in <code>toolboxv2/utils/system/api.py</code> <pre><code>def query_executable_url(current_os, machine):\n    \"\"\"\n    Query a remote URL for a matching executable based on OS and architecture.\n    The file name is built dynamically based on parameters.\n    \"\"\"\n    base_url = \"https://example.com/downloads\"  # Replace with the actual URL\n    # Windows executables have .exe extension\n    if current_os == \"windows\":\n        file_name = f\"server_{current_os}_{machine}.exe\"\n    else:\n        file_name = f\"server_{current_os}_{machine}\"\n    full_url = f\"{base_url}/{file_name}\"\n    return full_url, file_name\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.api.remove_release_executable","title":"<code>remove_release_executable()</code>","text":"<p>Removes the release executable.</p> Source code in <code>toolboxv2/utils/system/api.py</code> <pre><code>def remove_release_executable():\n    \"\"\"Removes the release executable.\"\"\"\n    src_core_path = os.path.join(\".\", \"src-core\")\n    expected_name = \"simple-core-server.exe\" if platform.system().lower() == \"windows\" else \"simple-core-server\"\n\n    # Remove from src-core root\n    direct_path = os.path.join(src_core_path, expected_name)\n    if os.path.exists(direct_path):\n        try:\n            os.remove(direct_path)\n            print(f\"Removed release executable: {direct_path}\")\n        except Exception as e:\n            print(f\"Failed to remove {direct_path}: {e}\")\n\n    # Remove from target/release\n    release_path = os.path.join(src_core_path, \"target\", \"release\", expected_name)\n    if os.path.exists(release_path):\n        try:\n            os.remove(release_path)\n            print(f\"Removed release executable: {release_path}\")\n        except Exception as e:\n            print(f\"Failed to remove {release_path}: {e}\")\n\n    return True\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.api.run_executable","title":"<code>run_executable(file_path)</code>","text":"<p>Run the executable file.</p> Source code in <code>toolboxv2/utils/system/api.py</code> <pre><code>def run_executable(file_path):\n    \"\"\"Run the executable file.\"\"\"\n    try:\n        print(\"Running it.\")\n        subprocess.run([os.path.abspath(file_path)], check=True)\n    except subprocess.CalledProcessError as e:\n        print(f\"Failed to execute {file_path}: {e}\")\n    except KeyboardInterrupt:\n        print(\"Exiting call from:\", file_path)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.api.run_in_debug_mode","title":"<code>run_in_debug_mode()</code>","text":"<p>Run the Cargo project in debug mode.</p> Source code in <code>toolboxv2/utils/system/api.py</code> <pre><code>def run_in_debug_mode():\n    \"\"\"Run the Cargo project in debug mode.\"\"\"\n    src_core_path = os.path.join(\".\", \"src-core\")\n    print(\"Running in debug mode...\")\n    try:\n        subprocess.run([\"cargo\", \"run\"], cwd=src_core_path)\n        return True\n    except subprocess.CalledProcessError as e:\n        print(f\"Debug execution failed: {e}\")\n        return False\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.api.run_with_hot_reload","title":"<code>run_with_hot_reload()</code>","text":"<p>Run the Cargo project with hot reloading.</p> Source code in <code>toolboxv2/utils/system/api.py</code> <pre><code>def run_with_hot_reload():\n    \"\"\"Run the Cargo project with hot reloading.\"\"\"\n    src_core_path = os.path.join(\".\", \"src-core\")\n\n    # Check if cargo-watch is installed\n    try:\n        subprocess.run([\"cargo\", \"watch\", \"--version\"], check=True, capture_output=True)\n    except Exception:\n        print(\"cargo-watch is not installed. Installing now...\")\n        try:\n            subprocess.run([\"cargo\", \"install\", \"cargo-watch\"], check=True)\n        except subprocess.CalledProcessError as e:\n            print(f\"Failed to install cargo-watch: {e}\")\n            print(\"Running without hot reload\")\n            return run_in_debug_mode()\n\n    print(\"Running with hot reload in debug mode...\")\n    try:\n        subprocess.run([\"cargo\", \"watch\", \"-x\", \"run\"], cwd=src_core_path)\n        return True\n    except subprocess.CalledProcessError as e:\n        print(f\"Hot reload execution failed: {e}\")\n        return False\n    except KeyboardInterrupt:\n        print(\"Exiting hot reload: KeyboardInterrupt\")\n        return False\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.api.update_server","title":"<code>update_server(new_executable_path, new_version, use_posix_zdt)</code>","text":"<p>High-level update function, calls platform-specific logic.</p> Source code in <code>toolboxv2/utils/system/api.py</code> <pre><code>def update_server(new_executable_path: str, new_version: str, use_posix_zdt: bool):\n    \"\"\"High-level update function, calls platform-specific logic.\"\"\"\n    # Only use POSIX ZDT if flag is set AND on a non-windows system\n    is_posix = platform.system().lower() != \"windows\"\n    if is_posix and use_posix_zdt:\n        return update_server_posix(new_executable_path, new_version)\n    else:\n        if use_posix_zdt and not is_posix:\n            print(Style.YELLOW(\"Warning: --posix-zdt flag ignored on Windows. Using graceful restart.\"))\n        return update_server_graceful_restart(new_executable_path, new_version)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.conda_runner","title":"<code>conda_runner</code>","text":""},{"location":"toolboxv2/#toolboxv2.utils.system.conda_runner.create_env_registry","title":"<code>create_env_registry(env_name)</code>","text":"<p>Create a JSON registry of all packages installed in the specified conda environment.</p> <p>Args: env_name (str): Name of the conda environment</p> <p>Returns: bool: True if registry creation was successful, False otherwise</p> Source code in <code>toolboxv2/utils/system/conda_runner.py</code> <pre><code>def create_env_registry(env_name: str) -&gt; bool:\n    \"\"\"\n    Create a JSON registry of all packages installed in the specified conda environment.\n\n    Args:\n    env_name (str): Name of the conda environment\n\n    Returns:\n    bool: True if registry creation was successful, False otherwise\n    \"\"\"\n    # Get list of installed packages\n    command = f\"conda list -n {env_name} --json\"\n    success, output = run_command(command, live=False)\n\n    if not success or output is None:\n        print(f\"Failed to get package list for environment {env_name}\")\n        return False\n\n    try:\n        # Parse the JSON output\n        packages = json.loads(output)\n\n        # Create a simplified registry with package names and versions\n        registry = [{\"name\": pkg[\"name\"], \"version\": pkg[\"version\"]} for pkg in packages]\n\n        # Write the registry to a JSON file\n        registry_file = f\"{env_name}_registry.json\"\n        with open(registry_file, 'w') as f:\n            json.dump(registry, f, indent=2)\n\n        print(f\"Registry created successfully: {registry_file}\")\n        return True\n\n    except json.JSONDecodeError:\n        print(f\"Failed to parse package list for environment {env_name}\")\n        return False\n    except OSError:\n        print(f\"Failed to write registry file for environment {env_name}\")\n        return False\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.db_cli_manager","title":"<code>db_cli_manager</code>","text":""},{"location":"toolboxv2/#toolboxv2.utils.system.db_cli_manager.ClusterManager","title":"<code>ClusterManager</code>","text":"<p>Manages a cluster of r_blob_db instances defined in a config file.</p> Source code in <code>toolboxv2/utils/system/db_cli_manager.py</code> <pre><code>class ClusterManager:\n    \"\"\"Manages a cluster of r_blob_db instances defined in a config file.\"\"\"\n\n    def __init__(self, config_path: str = CLUSTER_CONFIG_FILE):\n        self.config_path = Path(config_path)\n        self.instances: dict[str, DBInstanceManager] = self._load_config()\n\n    def _load_config(self) -&gt; dict[str, DBInstanceManager]:\n        \"\"\"Loads and validates the cluster configuration.\"\"\"\n        from toolboxv2 import tb_root_dir\n        if not self.config_path.is_absolute():\n            self.config_path = tb_root_dir / self.config_path\n\n        default_config_dir = (tb_root_dir / \".data/db_data/\").resolve()\n        default_config = {\n            \"instance-01\": {\"port\": 3001, \"data_dir\": str(default_config_dir / \"01\")},\n            \"instance-02\": {\"port\": 3002, \"data_dir\": str(default_config_dir / \"02\")},\n        }\n\n        if not self.config_path.exists():\n            print(Style.YELLOW(f\"Warning: Cluster config '{self.config_path}' not found. Creating a default example.\"))\n\n            with open(self.config_path, 'w') as f:\n                json.dump(default_config, f, indent=4)\n            config_data = default_config\n        else:\n            try:\n                with open(self.config_path) as f:\n                    config_data = json.load(f)\n            except json.JSONDecodeError:\n                print(Style.RED(f\"Error: Cluster config '{self.config_path}' is not valid JSON. using default config.\"))\n                config_data = default_config\n\n        return {id: DBInstanceManager(id, cfg) for id, cfg in config_data.items()}\n\n    def get_instances(self, instance_id: str | None = None) -&gt; list[DBInstanceManager]:\n        \"\"\"Returns a list of instances to operate on.\"\"\"\n        if instance_id:\n            if instance_id not in self.instances:\n                raise ValueError(f\"Instance ID '{instance_id}' not found in '{self.config_path}'.\")\n            return [self.instances[instance_id]]\n        return list(self.instances.values())\n\n    def start_all(self, executable_path: Path, version: str, instance_id: str | None = None):\n        for instance in self.get_instances(instance_id):\n            instance.start(executable_path, version)\n\n    def stop_all(self, instance_id: str | None = None):\n        for instance in self.get_instances(instance_id):\n            instance.stop()\n\n    def status_all(self, instance_id: str | None = None, silent=False):\n        if not silent:\n            header = f\"--- {Style.Bold('Cluster Status')} ---\"\n            print(header)\n            print(\n                f\"{Style.Underline('INSTANCE ID'):&lt;18} {Style.Underline('STATUS'):&lt;20} {Style.Underline('PID'):&lt;8} {Style.Underline('VERSION'):&lt;12} {Style.Underline('PORT')}\")\n\n        services_online = 0\n        server_list = []\n        for instance in self.get_instances(instance_id):\n            pid, version = instance.read_state()\n            is_running = instance.is_running()\n            if is_running:\n                server_list.append(f\"http://{instance.host}:{instance.port}\")\n                services_online += 1\n            if not silent:\n                status_str = \"\u2705 RUNNING\" if is_running else \"\u274c STOPPED\"\n                status_color = Style.GREEN2 if is_running else Style.RED2\n                print(\n                    f\"  {Style.WHITE(instance.id):&lt;16} {status_color(status_str):&lt;20} {Style.GREY(str(pid or 'N/A')):&lt;8} {Style.BLUE2(version or 'N/A'):&lt;12} {Style.YELLOW(str(instance.port))}\"\n                )\n        if not silent:\n            print(\"-\" * len(header))\n        return services_online, server_list\n\n    def health_check_all(self, instance_id: str | None = None):\n        header = f\"--- {Style.Bold('Cluster Health Check')} ---\"\n        print(header)\n        print(\n            f\"{Style.Underline('INSTANCE ID'):&lt;18} {Style.Underline('STATUS'):&lt;22} {Style.Underline('PID'):&lt;8} {Style.Underline('LATENCY'):&lt;12} {Style.Underline('DETAILS')}\")\n\n        for instance in self.get_instances(instance_id):\n            health = instance.get_health()\n            status = health.get('status', 'UNKNOWN')\n            pid = health.get('pid', 'N/A')\n            details = \"\"\n\n            if status == 'OK':\n                status_str, color = \"\u2705 OK\", Style.GREEN2\n                latency = f\"{health['latency_ms']}ms\"\n                details = f\"Blobs: {Style.YELLOW(str(health['blobs_managed']))} | Version: {Style.BLUE2(health['server_version'])}\"\n            elif status == 'STOPPED':\n                status_str, color = \"\u274c STOPPED\", Style.RED2\n                latency = \"N/A\"\n            else:\n                status_str, color = f\"\ud83d\udd25 {status}\", Style.RED\n                latency = \"N/A\"\n                details = Style.GREY(str(health.get('error', 'N/A')))\n\n            print(\n                f\"  {Style.WHITE(instance.id):&lt;16} {color(status_str):&lt;22} {Style.GREY(str(pid)):&lt;8} {Style.GREEN(latency):&lt;12} {details}\")\n        print(\"-\" * len(header))\n\n    def update_all_rolling(self, new_executable_path: Path, new_version: str, instance_id: str | None = None):\n        \"\"\"Performs a zero-downtime rolling update of the cluster.\"\"\"\n        print(f\"--- {Style.Bold(f'Starting Rolling Update to Version {Style.YELLOW(new_version)}')} ---\")\n        instances_to_update = self.get_instances(instance_id)\n        for i, instance in enumerate(instances_to_update):\n            print(\n                f\"\\n{Style.CYAN(f'[{i + 1}/{len(instances_to_update)}] Updating instance')} '{Style.WHITE(instance.id)}'...\")\n\n            if not instance.stop():\n                print(Style.RED2(f\"CRITICAL: Failed to stop old instance '{instance.id}'. Aborting update.\"))\n                return\n\n            if not instance.start(new_executable_path, new_version):\n                print(Style.RED2(f\"CRITICAL: Failed to start new version for '{instance.id}'. Update halted.\"))\n                print(Style.YELLOW(\"The cluster might be in a partially updated state. Please investigate.\"))\n                return\n\n            with Spinner(f\"Waiting for '{instance.id}' to become healthy\", symbols=\"t\") as s:\n                for attempt in range(5):\n                    s.message = f\"Waiting for '{instance.id}' to become healthy (attempt {attempt + 1}/5)\"\n                    time.sleep(2)\n                    health = instance.get_health()\n                    if health.get('status') == 'OK':\n                        print(\n                            f\"\\n{Style.GREEN('\u2705 Instance')} '{instance.id}' {Style.GREEN('is healthy with new version.')}\")\n                        break\n                else:\n                    print(\n                        f\"\\n{Style.RED2('CRITICAL:')} Instance '{instance.id}' did not become healthy after update. Update halted.\")\n                    return\n\n        print(f\"\\n--- {Style.GREEN2('Rolling Update Complete')} ---\")\n</code></pre> <code>get_instances(instance_id=None)</code> \u00b6 <p>Returns a list of instances to operate on.</p> Source code in <code>toolboxv2/utils/system/db_cli_manager.py</code> <pre><code>def get_instances(self, instance_id: str | None = None) -&gt; list[DBInstanceManager]:\n    \"\"\"Returns a list of instances to operate on.\"\"\"\n    if instance_id:\n        if instance_id not in self.instances:\n            raise ValueError(f\"Instance ID '{instance_id}' not found in '{self.config_path}'.\")\n        return [self.instances[instance_id]]\n    return list(self.instances.values())\n</code></pre> <code>update_all_rolling(new_executable_path, new_version, instance_id=None)</code> \u00b6 <p>Performs a zero-downtime rolling update of the cluster.</p> Source code in <code>toolboxv2/utils/system/db_cli_manager.py</code> <pre><code>def update_all_rolling(self, new_executable_path: Path, new_version: str, instance_id: str | None = None):\n    \"\"\"Performs a zero-downtime rolling update of the cluster.\"\"\"\n    print(f\"--- {Style.Bold(f'Starting Rolling Update to Version {Style.YELLOW(new_version)}')} ---\")\n    instances_to_update = self.get_instances(instance_id)\n    for i, instance in enumerate(instances_to_update):\n        print(\n            f\"\\n{Style.CYAN(f'[{i + 1}/{len(instances_to_update)}] Updating instance')} '{Style.WHITE(instance.id)}'...\")\n\n        if not instance.stop():\n            print(Style.RED2(f\"CRITICAL: Failed to stop old instance '{instance.id}'. Aborting update.\"))\n            return\n\n        if not instance.start(new_executable_path, new_version):\n            print(Style.RED2(f\"CRITICAL: Failed to start new version for '{instance.id}'. Update halted.\"))\n            print(Style.YELLOW(\"The cluster might be in a partially updated state. Please investigate.\"))\n            return\n\n        with Spinner(f\"Waiting for '{instance.id}' to become healthy\", symbols=\"t\") as s:\n            for attempt in range(5):\n                s.message = f\"Waiting for '{instance.id}' to become healthy (attempt {attempt + 1}/5)\"\n                time.sleep(2)\n                health = instance.get_health()\n                if health.get('status') == 'OK':\n                    print(\n                        f\"\\n{Style.GREEN('\u2705 Instance')} '{instance.id}' {Style.GREEN('is healthy with new version.')}\")\n                    break\n            else:\n                print(\n                    f\"\\n{Style.RED2('CRITICAL:')} Instance '{instance.id}' did not become healthy after update. Update halted.\")\n                return\n\n    print(f\"\\n--- {Style.GREEN2('Rolling Update Complete')} ---\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.db_cli_manager.DBInstanceManager","title":"<code>DBInstanceManager</code>","text":"<p>Manages a single r_blob_db instance.</p> Source code in <code>toolboxv2/utils/system/db_cli_manager.py</code> <pre><code>class DBInstanceManager:\n    \"\"\"Manages a single r_blob_db instance.\"\"\"\n\n    def __init__(self, instance_id: str, config: dict):\n        self.id = instance_id\n        self.port = config['port']\n        self.host = config.get('host', '127.0.0.1')\n        self.data_dir = Path(config['data_dir'])\n        self.state_file = self.data_dir / \"instance_state.json\"\n        self.log_file = self.data_dir / \"instance.log\"  # Added for better logging info\n\n    def read_state(self) -&gt; tuple[int | None, str | None]:\n        \"\"\"Reads the PID and version from the instance's state file.\"\"\"\n        if not self.state_file.exists():\n            return None, None\n        try:\n            with open(self.state_file) as f:\n                state = json.load(f)\n            return state.get('pid'), state.get('version')\n        except (json.JSONDecodeError, ValueError, FileNotFoundError):\n            return None, None\n\n    def write_state(self, pid: int | None, version: str | None):\n        \"\"\"Writes the PID and version to the state file.\"\"\"\n        self.data_dir.mkdir(parents=True, exist_ok=True)\n        state = {'pid': pid, 'version': version}\n        with open(self.state_file, 'w') as f:\n            json.dump(state, f, indent=4)\n\n    def is_running(self) -&gt; bool:\n        \"\"\"Checks if the process associated with this instance is running.\"\"\"\n        pid, _ = self.read_state()\n        return psutil.pid_exists(pid) if pid else False\n\n    def start(self, executable_path: Path, version: str) -&gt; bool:\n        \"\"\"Starts the instance process and detaches, redirecting output to a log file.\"\"\"\n        if self.is_running():\n            print(Style.YELLOW(f\"Instance '{self.id}' is already running.\"))\n            return True\n\n        print(Style.CYAN(f\"\ud83d\ude80 Starting instance '{self.id}' on port {self.port}...\"))\n        self.data_dir.mkdir(parents=True, exist_ok=True)\n        log_handle = open(self.log_file, 'a')\n\n        env = os.environ.copy()\n        env[\"R_BLOB_DB_CLEAN\"] = os.getenv(\"R_BLOB_DB_CLEAN\", \"false\")\n        env[\"R_BLOB_DB_PORT\"] = str(self.port)\n        env[\"R_BLOB_DB_DATA_DIR\"] = str(self.data_dir.resolve())\n        env[\"RUST_LOG\"] = \"info,tower_http=debug\" # \"error\"\n\n        try:\n            if executable_path is None:\n                raise ValueError(f\"\\n{Style.RED2('\u274c ERROR:')} Executable not found. Build it first.\")\n            with Spinner(f\"Launching process for '{self.id}'\", symbols=\"d\"):\n                process = subprocess.Popen(\n                    [str(executable_path.resolve())],\n                    env=env,\n                    stdout=log_handle,\n                    stderr=log_handle,\n                    creationflags=subprocess.DETACHED_PROCESS if platform.system() == \"Windows\" else 0\n                )\n                time.sleep(1.5)\n\n            if process.poll() is not None:\n                print(f\"\\n{Style.RED2('\u274c ERROR:')} Instance '{self.id}' failed to start. Check logs:\")\n                print(f\"    {Style.GREY(self.log_file)}\")\n                return False\n\n            self.write_state(process.pid, version)\n            print(\n                f\"\\n{Style.GREEN2('\u2705 Instance')} '{Style.Bold(self.id)}' {Style.GREEN2('started successfully.')} {Style.GREY(f'(PID: {process.pid})')}\")\n            print(f\"   {Style.BLUE('Logging to:')} {Style.GREY(self.log_file)}\")\n            return True\n        except Exception as e:\n            print(f\"\\n{Style.RED2('\u274c ERROR:')} Failed to launch instance '{self.id}': {e}\")\n            log_handle.close()\n            return False\n\n    def stop(self, timeout: int = 10) -&gt; bool:\n        \"\"\"Stops the instance process gracefully.\"\"\"\n        if not self.is_running():\n            print(Style.YELLOW(f\"Instance '{self.id}' is not running.\"))\n            self.write_state(None, None)\n            return True\n\n        pid, _ = self.read_state()\n        with Spinner(f\"Stopping '{self.id}' (PID: {pid})\", symbols=\"+\", time_in_s=timeout, count_down=True) as s:\n            try:\n                proc = psutil.Process(pid)\n                proc.terminate()\n                proc.wait(timeout)\n            except psutil.TimeoutExpired:\n                s.message = f\"Force killing '{self.id}'\"\n                proc.kill()\n            except psutil.NoSuchProcess:\n                pass\n            except Exception as e:\n                print(f\"\\n{Style.RED2('\u274c ERROR:')} Failed to stop instance '{self.id}': {e}\")\n                return False\n\n        self.write_state(None, None)\n        print(f\"\\n{Style.VIOLET2('\u23f9\ufe0f  Instance')} '{Style.Bold(self.id)}' {Style.VIOLET2('stopped.')}\")\n        return True\n\n    def get_health(self) -&gt; dict:\n        \"\"\"Performs a health check on the running instance.\"\"\"\n        if not self.is_running():\n            return {'id': self.id, 'status': 'STOPPED', 'error': 'Process not running'}\n\n        pid, version = self.read_state()\n        health_url = f\"http://{self.host}:{self.port}/health\"\n        start_time = time.monotonic()\n        try:\n            response = requests.get(health_url, timeout=2)\n            latency_ms = (time.monotonic() - start_time) * 1000\n            response.raise_for_status()\n            health_data = response.json()\n            health_data.update({\n                'id': self.id, 'pid': pid, 'latency_ms': round(latency_ms),\n                'server_version': health_data.pop('version', 'unknown'),\n                'manager_known_version': version\n            })\n            return health_data\n        except requests.exceptions.RequestException as e:\n            return {'id': self.id, 'status': 'UNREACHABLE', 'pid': pid, 'error': str(e)}\n        except Exception as e:\n            return {'id': self.id, 'status': 'ERROR', 'pid': pid, 'error': f'Failed to parse health response: {e}'}\n</code></pre> <code>get_health()</code> \u00b6 <p>Performs a health check on the running instance.</p> Source code in <code>toolboxv2/utils/system/db_cli_manager.py</code> <pre><code>def get_health(self) -&gt; dict:\n    \"\"\"Performs a health check on the running instance.\"\"\"\n    if not self.is_running():\n        return {'id': self.id, 'status': 'STOPPED', 'error': 'Process not running'}\n\n    pid, version = self.read_state()\n    health_url = f\"http://{self.host}:{self.port}/health\"\n    start_time = time.monotonic()\n    try:\n        response = requests.get(health_url, timeout=2)\n        latency_ms = (time.monotonic() - start_time) * 1000\n        response.raise_for_status()\n        health_data = response.json()\n        health_data.update({\n            'id': self.id, 'pid': pid, 'latency_ms': round(latency_ms),\n            'server_version': health_data.pop('version', 'unknown'),\n            'manager_known_version': version\n        })\n        return health_data\n    except requests.exceptions.RequestException as e:\n        return {'id': self.id, 'status': 'UNREACHABLE', 'pid': pid, 'error': str(e)}\n    except Exception as e:\n        return {'id': self.id, 'status': 'ERROR', 'pid': pid, 'error': f'Failed to parse health response: {e}'}\n</code></pre> <code>is_running()</code> \u00b6 <p>Checks if the process associated with this instance is running.</p> Source code in <code>toolboxv2/utils/system/db_cli_manager.py</code> <pre><code>def is_running(self) -&gt; bool:\n    \"\"\"Checks if the process associated with this instance is running.\"\"\"\n    pid, _ = self.read_state()\n    return psutil.pid_exists(pid) if pid else False\n</code></pre> <code>read_state()</code> \u00b6 <p>Reads the PID and version from the instance's state file.</p> Source code in <code>toolboxv2/utils/system/db_cli_manager.py</code> <pre><code>def read_state(self) -&gt; tuple[int | None, str | None]:\n    \"\"\"Reads the PID and version from the instance's state file.\"\"\"\n    if not self.state_file.exists():\n        return None, None\n    try:\n        with open(self.state_file) as f:\n            state = json.load(f)\n        return state.get('pid'), state.get('version')\n    except (json.JSONDecodeError, ValueError, FileNotFoundError):\n        return None, None\n</code></pre> <code>start(executable_path, version)</code> \u00b6 <p>Starts the instance process and detaches, redirecting output to a log file.</p> Source code in <code>toolboxv2/utils/system/db_cli_manager.py</code> <pre><code>def start(self, executable_path: Path, version: str) -&gt; bool:\n    \"\"\"Starts the instance process and detaches, redirecting output to a log file.\"\"\"\n    if self.is_running():\n        print(Style.YELLOW(f\"Instance '{self.id}' is already running.\"))\n        return True\n\n    print(Style.CYAN(f\"\ud83d\ude80 Starting instance '{self.id}' on port {self.port}...\"))\n    self.data_dir.mkdir(parents=True, exist_ok=True)\n    log_handle = open(self.log_file, 'a')\n\n    env = os.environ.copy()\n    env[\"R_BLOB_DB_CLEAN\"] = os.getenv(\"R_BLOB_DB_CLEAN\", \"false\")\n    env[\"R_BLOB_DB_PORT\"] = str(self.port)\n    env[\"R_BLOB_DB_DATA_DIR\"] = str(self.data_dir.resolve())\n    env[\"RUST_LOG\"] = \"info,tower_http=debug\" # \"error\"\n\n    try:\n        if executable_path is None:\n            raise ValueError(f\"\\n{Style.RED2('\u274c ERROR:')} Executable not found. Build it first.\")\n        with Spinner(f\"Launching process for '{self.id}'\", symbols=\"d\"):\n            process = subprocess.Popen(\n                [str(executable_path.resolve())],\n                env=env,\n                stdout=log_handle,\n                stderr=log_handle,\n                creationflags=subprocess.DETACHED_PROCESS if platform.system() == \"Windows\" else 0\n            )\n            time.sleep(1.5)\n\n        if process.poll() is not None:\n            print(f\"\\n{Style.RED2('\u274c ERROR:')} Instance '{self.id}' failed to start. Check logs:\")\n            print(f\"    {Style.GREY(self.log_file)}\")\n            return False\n\n        self.write_state(process.pid, version)\n        print(\n            f\"\\n{Style.GREEN2('\u2705 Instance')} '{Style.Bold(self.id)}' {Style.GREEN2('started successfully.')} {Style.GREY(f'(PID: {process.pid})')}\")\n        print(f\"   {Style.BLUE('Logging to:')} {Style.GREY(self.log_file)}\")\n        return True\n    except Exception as e:\n        print(f\"\\n{Style.RED2('\u274c ERROR:')} Failed to launch instance '{self.id}': {e}\")\n        log_handle.close()\n        return False\n</code></pre> <code>stop(timeout=10)</code> \u00b6 <p>Stops the instance process gracefully.</p> Source code in <code>toolboxv2/utils/system/db_cli_manager.py</code> <pre><code>def stop(self, timeout: int = 10) -&gt; bool:\n    \"\"\"Stops the instance process gracefully.\"\"\"\n    if not self.is_running():\n        print(Style.YELLOW(f\"Instance '{self.id}' is not running.\"))\n        self.write_state(None, None)\n        return True\n\n    pid, _ = self.read_state()\n    with Spinner(f\"Stopping '{self.id}' (PID: {pid})\", symbols=\"+\", time_in_s=timeout, count_down=True) as s:\n        try:\n            proc = psutil.Process(pid)\n            proc.terminate()\n            proc.wait(timeout)\n        except psutil.TimeoutExpired:\n            s.message = f\"Force killing '{self.id}'\"\n            proc.kill()\n        except psutil.NoSuchProcess:\n            pass\n        except Exception as e:\n            print(f\"\\n{Style.RED2('\u274c ERROR:')} Failed to stop instance '{self.id}': {e}\")\n            return False\n\n    self.write_state(None, None)\n    print(f\"\\n{Style.VIOLET2('\u23f9\ufe0f  Instance')} '{Style.Bold(self.id)}' {Style.VIOLET2('stopped.')}\")\n    return True\n</code></pre> <code>write_state(pid, version)</code> \u00b6 <p>Writes the PID and version to the state file.</p> Source code in <code>toolboxv2/utils/system/db_cli_manager.py</code> <pre><code>def write_state(self, pid: int | None, version: str | None):\n    \"\"\"Writes the PID and version to the state file.\"\"\"\n    self.data_dir.mkdir(parents=True, exist_ok=True)\n    state = {'pid': pid, 'version': version}\n    with open(self.state_file, 'w') as f:\n        json.dump(state, f, indent=4)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.db_cli_manager.cli_db_runner","title":"<code>cli_db_runner()</code>","text":"<p>The main entry point for the CLI application.</p> Source code in <code>toolboxv2/utils/system/db_cli_manager.py</code> <pre><code>def cli_db_runner():\n    \"\"\"The main entry point for the CLI application.\"\"\"\n    parser = argparse.ArgumentParser(\n        description=f\"\ud83d\ude80 {Style.Bold('A manager for r_blob_db instances and clusters.')}\",\n        formatter_class=argparse.RawTextHelpFormatter\n    )\n    subparsers = parser.add_subparsers(dest=\"action\", required=True, help=\"Available actions\")\n\n    # Define common arguments\n    instance_arg = {'name_or_flags': ['--instance-id'], 'type': str,\n                    'help': 'Target a specific instance ID. If omitted, action applies to the whole cluster.',\n                    'default': None}\n    version_arg = {'name_or_flags': ['--version'], 'type': str,\n                   'help': 'Specify a version string for the executable (e.g., \"1.2.0\").', 'default': 'dev'}\n\n    # --- Define Commands ---\n    p_start = subparsers.add_parser('start', help='Start instance(s).')\n    p_start.add_argument(*instance_arg['name_or_flags'],\n                         **{k: v for k, v in instance_arg.items() if k != 'name_or_flags'})\n    p_start.add_argument(*version_arg['name_or_flags'],\n                         **{k: v for k, v in version_arg.items() if k != 'name_or_flags'})\n\n    p_stop = subparsers.add_parser('stop', help='Stop instance(s).')\n    p_stop.add_argument(*instance_arg['name_or_flags'],\n                        **{k: v for k, v in instance_arg.items() if k != 'name_or_flags'})\n\n    p_status = subparsers.add_parser('status', help='Show the running status of instance(s).')\n    p_status.add_argument(*instance_arg['name_or_flags'],\n                          **{k: v for k, v in instance_arg.items() if k != 'name_or_flags'})\n\n    p_health = subparsers.add_parser('health', help='Perform a health check on instance(s).')\n    p_health.add_argument(*instance_arg['name_or_flags'],\n                          **{k: v for k, v in instance_arg.items() if k != 'name_or_flags'})\n\n    p_update = subparsers.add_parser('update', help='Perform a rolling update on the cluster.')\n    p_update.add_argument(*instance_arg['name_or_flags'],\n                          **{k: v for k, v in instance_arg.items() if k != 'name_or_flags'})\n    version_arg_update = {**version_arg, 'required': True}\n    p_update.add_argument(*version_arg_update['name_or_flags'],\n                          **{k: v for k, v in version_arg_update.items() if k != 'name_or_flags'})\n\n    subparsers.add_parser('build', help='Build the Rust executable from source.')\n    subparsers.add_parser('clean', help='Clean the Rust build artifacts.')\n\n    # --- Execute Command ---\n    args = parser.parse_args()\n\n    if args.action == 'build':\n        handle_build()\n        return\n    if args.action == 'clean':\n        handle_clean()\n        return\n\n    manager = ClusterManager()\n\n    if args.action in ['start', 'update']:\n        executable_path = get_executable_path(update=(args.action == 'update'))\n        if not executable_path:\n            print(Style.RED(f\"ERROR: Could not find the {EXECUTABLE_NAME} executable.\"))\n            print(Style.YELLOW(\"Please build it first with: python -m toolboxv2.r_blob_db.db_cli build\"))\n            return\n\n    if args.action == 'start':\n        manager.start_all(executable_path, args.version, args.instance_id)\n    elif args.action == 'stop':\n        manager.stop_all(args.instance_id)\n    elif args.action == 'status':\n        manager.status_all(args.instance_id)\n    elif args.action == 'health':\n        manager.health_check_all(args.instance_id)\n    elif args.action == 'update':\n        manager.update_all_rolling(executable_path, args.version, args.instance_id)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.db_cli_manager.get_executable_path","title":"<code>get_executable_path(base_name=EXECUTABLE_NAME, update=False)</code>","text":"<p>Finds the release executable in standard locations.</p> Source code in <code>toolboxv2/utils/system/db_cli_manager.py</code> <pre><code>def get_executable_path(base_name: str = EXECUTABLE_NAME, update=False) -&gt; Path | None:\n    \"\"\"Finds the release executable in standard locations.\"\"\"\n    name_with_ext = f\"{base_name}.exe\" if platform.system() == \"Windows\" else base_name\n    from toolboxv2 import tb_root_dir\n    search_paths = [\n        tb_root_dir / \"bin\" / name_with_ext,\n        tb_root_dir / \"r_blob_db\" / \"target\" / \"release\" / name_with_ext,\n    ]\n    if update:\n        search_paths = search_paths[::-1]\n    for path in search_paths:\n        if path.is_file():\n            return path.resolve()\n    return None\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.main_tool","title":"<code>main_tool</code>","text":""},{"location":"toolboxv2/#toolboxv2.utils.system.main_tool.MainTool","title":"<code>MainTool</code>","text":"Source code in <code>toolboxv2/utils/system/main_tool.py</code> <pre><code>class MainTool:\n    toolID: str = \"\"\n    # app = None\n    interface = None\n    spec = \"app\"\n    name = \"\"\n    color = \"Bold\"\n    stuf = False\n\n    def __init__(self, *args, **kwargs):\n        \"\"\"\n        Standard constructor used for arguments pass\n        Do not override. Use __ainit__ instead\n        \"\"\"\n        self.__storedargs = args, kwargs\n        self.tools = kwargs.get(\"tool\", {})\n        self.logger = kwargs.get(\"logs\", get_logger())\n        self.color = kwargs.get(\"color\", \"WHITE\")\n        self.todo = kwargs.get(\"load\", kwargs.get(\"on_start\", lambda: None))\n        if \"on_exit\" in kwargs and isinstance(kwargs.get(\"on_exit\"), Callable):\n            self.on_exit =self.app.tb(\n                mod_name=self.name,\n                name=kwargs.get(\"on_exit\").__name__,\n                version=self.version if hasattr(self, 'version') else \"0.0.0\",\n            )(kwargs.get(\"on_exit\"))\n        self.async_initialized = False\n        if self.todo:\n            try:\n                if inspect.iscoroutinefunction(self.todo):\n                    pass\n                else:\n                    self.todo()\n                get_logger().info(f\"{self.name} on load suspended\")\n            except Exception as e:\n                get_logger().error(f\"Error loading mod {self.name} {e}\")\n                if self.app.debug:\n                    import traceback\n                    traceback.print_exc()\n        else:\n            get_logger().info(f\"{self.name} no load require\")\n\n    async def __ainit__(self, *args, **kwargs):\n        self.version = kwargs[\"v\"]\n        self.tools = kwargs.get(\"tool\", {})\n        self.name = kwargs[\"name\"]\n        self.logger = kwargs.get(\"logs\", get_logger())\n        self.color = kwargs.get(\"color\", \"WHITE\")\n        self.todo = kwargs.get(\"load\", kwargs.get(\"on_start\"))\n        if not hasattr(self, 'config'):\n            self.config = {}\n        self.user = None\n        self.description = \"A toolbox mod\" if kwargs.get(\"description\") is None else kwargs.get(\"description\")\n        if MainTool.interface is None:\n            MainTool.interface = self.app.interface_type\n        # Result.default(self.app.interface)\n\n        if self.todo:\n            try:\n                if inspect.iscoroutinefunction(self.todo):\n                    await self.todo()\n                else:\n                    pass\n                await asyncio.sleep(0.1)\n                get_logger().info(f\"{self.name} on load suspended\")\n            except Exception as e:\n                get_logger().error(f\"Error loading mod {self.name} {e}\")\n                if self.app.debug:\n                    import traceback\n                    traceback.print_exc()\n        else:\n            get_logger().info(f\"{self.name} no load require\")\n        self.app.print(f\"TOOL : {self.spec}.{self.name} online\")\n\n\n\n    @property\n    def app(self):\n        return get_app(\n            from_=f\"{self.spec}.{self.name}|{self.toolID if self.toolID else '*' + MainTool.toolID} {self.interface if self.interface else MainTool.interface}\")\n\n    @app.setter\n    def app(self, v):\n        raise PermissionError(f\"You cannot set the App Instance! {v=}\")\n\n    @staticmethod\n    def return_result(error: ToolBoxError = ToolBoxError.none,\n                      exec_code: int = 0,\n                      help_text: str = \"\",\n                      data_info=None,\n                      data=None,\n                      data_to=None):\n\n        if data_to is None:\n            data_to = MainTool.interface if MainTool.interface is not None else ToolBoxInterfaces.cli\n\n        if data is None:\n            data = {}\n\n        if data_info is None:\n            data_info = {}\n\n        return Result(\n            error,\n            ToolBoxResult(data_info=data_info, data=data, data_to=data_to),\n            ToolBoxInfo(exec_code=exec_code, help_text=help_text)\n        )\n\n    def print(self, message, end=\"\\n\", **kwargs):\n        if self.stuf:\n            return\n\n        self.app.print(Style.style_dic[self.color] + self.name + Style.style_dic[\"END\"] + \":\", message, end=end,\n                       **kwargs)\n\n    def add_str_to_config(self, command):\n        if len(command) != 2:\n            self.logger.error('Invalid command must be key value')\n            return False\n        self.config[command[0]] = command[1]\n\n    def webInstall(self, user_instance, construct_render) -&gt; str:\n        \"\"\"\"Returns a web installer for the given user instance and construct render template\"\"\"\n\n    def get_version(self) -&gt; str:\n        \"\"\"\"Returns the version\"\"\"\n        return self.version\n\n    async def get_user(self, username: str) -&gt; Result:\n        return await self.app.a_run_any(CLOUDM_AUTHMANAGER.GET_USER_BY_NAME, username=username, get_results=True)\n\n    async def __initobj(self):\n        \"\"\"Crutch used for __await__ after spawning\"\"\"\n        assert not self.async_initialized\n        self.async_initialized = True\n        # pass the parameters to __ainit__ that passed to __init__\n        await self.__ainit__(*self.__storedargs[0], **self.__storedargs[1])\n        return self\n\n    def __await__(self):\n        return self.__initobj().__await__()\n</code></pre> <code>__init__(*args, **kwargs)</code> \u00b6 <p>Standard constructor used for arguments pass Do not override. Use ainit instead</p> Source code in <code>toolboxv2/utils/system/main_tool.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"\n    Standard constructor used for arguments pass\n    Do not override. Use __ainit__ instead\n    \"\"\"\n    self.__storedargs = args, kwargs\n    self.tools = kwargs.get(\"tool\", {})\n    self.logger = kwargs.get(\"logs\", get_logger())\n    self.color = kwargs.get(\"color\", \"WHITE\")\n    self.todo = kwargs.get(\"load\", kwargs.get(\"on_start\", lambda: None))\n    if \"on_exit\" in kwargs and isinstance(kwargs.get(\"on_exit\"), Callable):\n        self.on_exit =self.app.tb(\n            mod_name=self.name,\n            name=kwargs.get(\"on_exit\").__name__,\n            version=self.version if hasattr(self, 'version') else \"0.0.0\",\n        )(kwargs.get(\"on_exit\"))\n    self.async_initialized = False\n    if self.todo:\n        try:\n            if inspect.iscoroutinefunction(self.todo):\n                pass\n            else:\n                self.todo()\n            get_logger().info(f\"{self.name} on load suspended\")\n        except Exception as e:\n            get_logger().error(f\"Error loading mod {self.name} {e}\")\n            if self.app.debug:\n                import traceback\n                traceback.print_exc()\n    else:\n        get_logger().info(f\"{self.name} no load require\")\n</code></pre> <code>__initobj()</code> <code>async</code> \u00b6 <p>Crutch used for await after spawning</p> Source code in <code>toolboxv2/utils/system/main_tool.py</code> <pre><code>async def __initobj(self):\n    \"\"\"Crutch used for __await__ after spawning\"\"\"\n    assert not self.async_initialized\n    self.async_initialized = True\n    # pass the parameters to __ainit__ that passed to __init__\n    await self.__ainit__(*self.__storedargs[0], **self.__storedargs[1])\n    return self\n</code></pre> <code>get_version()</code> \u00b6 <p>\"Returns the version</p> Source code in <code>toolboxv2/utils/system/main_tool.py</code> <pre><code>def get_version(self) -&gt; str:\n    \"\"\"\"Returns the version\"\"\"\n    return self.version\n</code></pre> <code>webInstall(user_instance, construct_render)</code> \u00b6 <p>\"Returns a web installer for the given user instance and construct render template</p> Source code in <code>toolboxv2/utils/system/main_tool.py</code> <pre><code>def webInstall(self, user_instance, construct_render) -&gt; str:\n    \"\"\"\"Returns a web installer for the given user instance and construct render template\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.main_tool.get_version_from_pyproject","title":"<code>get_version_from_pyproject(pyproject_path='../pyproject.toml')</code>","text":"<p>Reads the version from the pyproject.toml file.</p> Source code in <code>toolboxv2/utils/system/main_tool.py</code> <pre><code>def get_version_from_pyproject(pyproject_path='../pyproject.toml'):\n    \"\"\"Reads the version from the pyproject.toml file.\"\"\"\n    if not os.path.exists(pyproject_path) and pyproject_path=='../pyproject.toml':\n        pyproject_path = 'pyproject.toml'\n    if not os.path.exists(pyproject_path) and pyproject_path=='pyproject.toml':\n        return \"0.1.21\"\n\n    try:\n        import toml\n        # Load the pyproject.toml file\n        with open(pyproject_path) as file:\n            pyproject_data = toml.load(file)\n\n        # Extract the version from the 'project' section\n        version = pyproject_data.get('project', {}).get('version')\n\n        if version is None:\n            raise ValueError(f\"Version not found in {pyproject_path}\")\n\n        return version\n    except Exception as e:\n        print(f\"Error reading version: {e}\")\n        return \"0.0.0\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.state_system","title":"<code>state_system</code>","text":"<p>The Task of the State System is : 1 Kep trak of the current state of the ToolBox and its dependency's 2 tracks the shasum of all mod and runnabael 3 the version of all mod</p> <p>The state : {\"utils\":{\"file_name\": {\"version\":##,\"shasum\"}} ,\"mods\":{\"file_name\": {\"version\":##,\"shasum\":##,\"src-url\":##}} ,\"runnable\":{\"file_name\": {\"version\":##,\"shasum\":##,\"src-url\":##}} ,\"api\":{\"file_name\": {\"version\":##,\"shasum\"}} ,\"app\":{\"file_name\": {\"version\":##,\"shasum\":##,\"src-url\":##}} }</p> <p>trans form state from on to an other.</p>"},{"location":"toolboxv2/#toolboxv2.utils.system.tcm_p2p_cli","title":"<code>tcm_p2p_cli</code>","text":""},{"location":"toolboxv2/#toolboxv2.utils.system.tcm_p2p_cli.InstanceManager","title":"<code>InstanceManager</code>","text":"<p>Manages a single named instance (relay or peer) of the P2P application.</p> Source code in <code>toolboxv2/utils/system/tcm_p2p_cli.py</code> <pre><code>class InstanceManager:\n    \"\"\"Manages a single named instance (relay or peer) of the P2P application.\"\"\"\n\n    def __init__(self, name: str):\n        self.name = name\n        self.instance_dir = INSTANCES_ROOT_DIR / self.name\n        self.state_file = self.instance_dir / \"state.json\"\n        self.config_file = self.instance_dir / \"config.toml\"\n        self.log_file = self.instance_dir / \"instance.log\"\n\n    def read_state(self) -&gt; dict:\n        \"\"\"Reads the instance's state (pid, mode, etc.) from its state file.\"\"\"\n        if not self.state_file.exists():\n            return {}\n        try:\n            with open(self.state_file) as f:\n                return json.load(f)\n        except (json.JSONDecodeError, FileNotFoundError):\n            return {}\n\n    def write_state(self, state_data: dict):\n        \"\"\"Writes the instance's state to its state file.\"\"\"\n        self.instance_dir.mkdir(parents=True, exist_ok=True)\n        with open(self.state_file, 'w') as f:\n            json.dump(state_data, f, indent=2)\n\n    def is_running(self) -&gt; bool:\n        \"\"\"Checks if the process associated with this instance is active.\"\"\"\n        pid = self.read_state().get('pid')\n        return psutil.pid_exists(pid) if pid else False\n\n    def generate_config(self, mode: str, config_data: dict):\n        \"\"\"Generates the config.toml file for this specific instance.\"\"\"\n        content = f'mode = \"{mode}\"\\n\\n'\n\n        if mode == \"relay\":\n            content += \"[relay]\\n\"\n            content += f'bind_address = \"{config_data.get(\"bind_address\", \"0.0.0.0:9000\")}\"\\n'\n            content += f'password = \"{config_data.get(\"password\", \"\")}\"\\n'\n\n        elif mode == \"peer\":\n            content += \"[peer]\\n\"\n            content += f'relay_address = \"{config_data.get(\"relay_address\", \"127.0.0.1:9000\")}\"\\n'\n            content += f'relay_password = \"{config_data.get(\"relay_password\", \"\")}\"\\n'\n            content += f'peer_id = \"{config_data.get(\"peer_id\", \"default-peer\")}\"\\n'\n            content += f'listen_address = \"{config_data.get(\"listen_address\", \"127.0.0.1:8000\")}\"\\n'\n            content += f'forward_to_address = \"{config_data.get(\"forward_to_address\", \"127.0.0.1:3000\")}\"\\n'\n            if config_data.get(\"target_peer_id\"):\n                content += f'target_peer_id = \"{config_data.get(\"target_peer_id\")}\"\\n'\n\n        self.instance_dir.mkdir(parents=True, exist_ok=True)\n        with open(self.config_file, \"w\") as f:\n            f.write(content)\n        print(f\"    {Style.GREEN('Generated config:')} {Style.GREY(str(self.config_file))}\")\n\n    def start(self, executable_path: Path, mode: str, config_data: dict) -&gt; bool:\n        \"\"\"Starts the instance process, detaches it, and logs its state.\"\"\"\n        if self.is_running():\n            print(Style.YELLOW(f\"Instance '{self.name}' is already running.\"))\n            return True\n\n        print(Style.CYAN(f\"\ud83d\ude80 Starting instance '{self.name}'...\"))\n        self.generate_config(mode, config_data)\n        log_handle = open(self.log_file, 'a')\n\n        try:\n            with Spinner(f\"Launching process for '{self.name}'\", symbols=\"d\"):\n                process = subprocess.Popen(\n                    [str(executable_path)],\n                    cwd=str(self.instance_dir),\n                    stdout=log_handle,\n                    stderr=log_handle,\n                    creationflags=subprocess.DETACHED_PROCESS if platform.system() == \"Windows\" else 0\n                )\n                time.sleep(1.5)  # Give it a moment to stabilize or crash\n\n            if process.poll() is not None:\n                print(f\"\\n{Style.RED2('\u274c ERROR:')} Instance '{self.name}' failed to start. Check logs for details:\")\n                print(f\"    {Style.GREY(self.log_file)}\")\n                return False\n\n            state = {'pid': process.pid, 'mode': mode, 'config': config_data}\n            self.write_state(state)\n            print(\n                f\"\\n{Style.GREEN2('\u2705 Instance')} '{Style.Bold(self.name)}' {Style.GREEN2('started successfully.')} {Style.GREY(f'(PID: {process.pid})')}\")\n            print(f\"   {Style.BLUE('Logging to:')} {Style.GREY(self.log_file)}\")\n            return True\n        except Exception as e:\n            print(f\"\\n{Style.RED2('\u274c ERROR:')} Failed to launch instance '{self.name}': {e}\")\n            log_handle.close()\n            return False\n\n    def stop(self, timeout: int = 10) -&gt; bool:\n        \"\"\"Stops the instance process gracefully with a forced kill fallback.\"\"\"\n        if not self.is_running():\n            print(Style.YELLOW(f\"Instance '{self.name}' is not running.\"))\n            self.write_state({})\n            return True\n\n        pid = self.read_state().get('pid')\n        with Spinner(f\"Stopping '{self.name}' (PID: {pid})\", symbols=\"+\", time_in_s=timeout, count_down=True) as s:\n            try:\n                proc = psutil.Process(pid)\n                proc.terminate()\n                proc.wait(timeout)\n            except psutil.TimeoutExpired:\n                s.message = f\"Force killing '{self.name}'\"\n                proc.kill()\n            except psutil.NoSuchProcess:\n                pass\n            except Exception as e:\n                print(f\"\\n{Style.RED2('\u274c ERROR:')} Failed to stop instance '{self.name}': {e}\")\n                return False\n\n        self.write_state({})\n        print(f\"\\n{Style.VIOLET2('\u23f9\ufe0f  Instance')} '{Style.Bold(self.name)}' {Style.VIOLET2('stopped.')}\")\n        return True\n</code></pre> <code>generate_config(mode, config_data)</code> \u00b6 <p>Generates the config.toml file for this specific instance.</p> Source code in <code>toolboxv2/utils/system/tcm_p2p_cli.py</code> <pre><code>def generate_config(self, mode: str, config_data: dict):\n    \"\"\"Generates the config.toml file for this specific instance.\"\"\"\n    content = f'mode = \"{mode}\"\\n\\n'\n\n    if mode == \"relay\":\n        content += \"[relay]\\n\"\n        content += f'bind_address = \"{config_data.get(\"bind_address\", \"0.0.0.0:9000\")}\"\\n'\n        content += f'password = \"{config_data.get(\"password\", \"\")}\"\\n'\n\n    elif mode == \"peer\":\n        content += \"[peer]\\n\"\n        content += f'relay_address = \"{config_data.get(\"relay_address\", \"127.0.0.1:9000\")}\"\\n'\n        content += f'relay_password = \"{config_data.get(\"relay_password\", \"\")}\"\\n'\n        content += f'peer_id = \"{config_data.get(\"peer_id\", \"default-peer\")}\"\\n'\n        content += f'listen_address = \"{config_data.get(\"listen_address\", \"127.0.0.1:8000\")}\"\\n'\n        content += f'forward_to_address = \"{config_data.get(\"forward_to_address\", \"127.0.0.1:3000\")}\"\\n'\n        if config_data.get(\"target_peer_id\"):\n            content += f'target_peer_id = \"{config_data.get(\"target_peer_id\")}\"\\n'\n\n    self.instance_dir.mkdir(parents=True, exist_ok=True)\n    with open(self.config_file, \"w\") as f:\n        f.write(content)\n    print(f\"    {Style.GREEN('Generated config:')} {Style.GREY(str(self.config_file))}\")\n</code></pre> <code>is_running()</code> \u00b6 <p>Checks if the process associated with this instance is active.</p> Source code in <code>toolboxv2/utils/system/tcm_p2p_cli.py</code> <pre><code>def is_running(self) -&gt; bool:\n    \"\"\"Checks if the process associated with this instance is active.\"\"\"\n    pid = self.read_state().get('pid')\n    return psutil.pid_exists(pid) if pid else False\n</code></pre> <code>read_state()</code> \u00b6 <p>Reads the instance's state (pid, mode, etc.) from its state file.</p> Source code in <code>toolboxv2/utils/system/tcm_p2p_cli.py</code> <pre><code>def read_state(self) -&gt; dict:\n    \"\"\"Reads the instance's state (pid, mode, etc.) from its state file.\"\"\"\n    if not self.state_file.exists():\n        return {}\n    try:\n        with open(self.state_file) as f:\n            return json.load(f)\n    except (json.JSONDecodeError, FileNotFoundError):\n        return {}\n</code></pre> <code>start(executable_path, mode, config_data)</code> \u00b6 <p>Starts the instance process, detaches it, and logs its state.</p> Source code in <code>toolboxv2/utils/system/tcm_p2p_cli.py</code> <pre><code>def start(self, executable_path: Path, mode: str, config_data: dict) -&gt; bool:\n    \"\"\"Starts the instance process, detaches it, and logs its state.\"\"\"\n    if self.is_running():\n        print(Style.YELLOW(f\"Instance '{self.name}' is already running.\"))\n        return True\n\n    print(Style.CYAN(f\"\ud83d\ude80 Starting instance '{self.name}'...\"))\n    self.generate_config(mode, config_data)\n    log_handle = open(self.log_file, 'a')\n\n    try:\n        with Spinner(f\"Launching process for '{self.name}'\", symbols=\"d\"):\n            process = subprocess.Popen(\n                [str(executable_path)],\n                cwd=str(self.instance_dir),\n                stdout=log_handle,\n                stderr=log_handle,\n                creationflags=subprocess.DETACHED_PROCESS if platform.system() == \"Windows\" else 0\n            )\n            time.sleep(1.5)  # Give it a moment to stabilize or crash\n\n        if process.poll() is not None:\n            print(f\"\\n{Style.RED2('\u274c ERROR:')} Instance '{self.name}' failed to start. Check logs for details:\")\n            print(f\"    {Style.GREY(self.log_file)}\")\n            return False\n\n        state = {'pid': process.pid, 'mode': mode, 'config': config_data}\n        self.write_state(state)\n        print(\n            f\"\\n{Style.GREEN2('\u2705 Instance')} '{Style.Bold(self.name)}' {Style.GREEN2('started successfully.')} {Style.GREY(f'(PID: {process.pid})')}\")\n        print(f\"   {Style.BLUE('Logging to:')} {Style.GREY(self.log_file)}\")\n        return True\n    except Exception as e:\n        print(f\"\\n{Style.RED2('\u274c ERROR:')} Failed to launch instance '{self.name}': {e}\")\n        log_handle.close()\n        return False\n</code></pre> <code>stop(timeout=10)</code> \u00b6 <p>Stops the instance process gracefully with a forced kill fallback.</p> Source code in <code>toolboxv2/utils/system/tcm_p2p_cli.py</code> <pre><code>def stop(self, timeout: int = 10) -&gt; bool:\n    \"\"\"Stops the instance process gracefully with a forced kill fallback.\"\"\"\n    if not self.is_running():\n        print(Style.YELLOW(f\"Instance '{self.name}' is not running.\"))\n        self.write_state({})\n        return True\n\n    pid = self.read_state().get('pid')\n    with Spinner(f\"Stopping '{self.name}' (PID: {pid})\", symbols=\"+\", time_in_s=timeout, count_down=True) as s:\n        try:\n            proc = psutil.Process(pid)\n            proc.terminate()\n            proc.wait(timeout)\n        except psutil.TimeoutExpired:\n            s.message = f\"Force killing '{self.name}'\"\n            proc.kill()\n        except psutil.NoSuchProcess:\n            pass\n        except Exception as e:\n            print(f\"\\n{Style.RED2('\u274c ERROR:')} Failed to stop instance '{self.name}': {e}\")\n            return False\n\n    self.write_state({})\n    print(f\"\\n{Style.VIOLET2('\u23f9\ufe0f  Instance')} '{Style.Bold(self.name)}' {Style.VIOLET2('stopped.')}\")\n    return True\n</code></pre> <code>write_state(state_data)</code> \u00b6 <p>Writes the instance's state to its state file.</p> Source code in <code>toolboxv2/utils/system/tcm_p2p_cli.py</code> <pre><code>def write_state(self, state_data: dict):\n    \"\"\"Writes the instance's state to its state file.\"\"\"\n    self.instance_dir.mkdir(parents=True, exist_ok=True)\n    with open(self.state_file, 'w') as f:\n        json.dump(state_data, f, indent=2)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.tcm_p2p_cli.find_instances","title":"<code>find_instances()</code>","text":"<p>Discovers all managed instances by scanning the instances directory.</p> Source code in <code>toolboxv2/utils/system/tcm_p2p_cli.py</code> <pre><code>def find_instances() -&gt; list['InstanceManager']:\n    \"\"\"Discovers all managed instances by scanning the instances directory.\"\"\"\n    if not INSTANCES_ROOT_DIR.is_dir():\n        return []\n\n    instance_managers = []\n    for instance_dir in INSTANCES_ROOT_DIR.iterdir():\n        if instance_dir.is_dir():\n            instance_managers.append(InstanceManager(instance_dir.name))\n    return instance_managers\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.tcm_p2p_cli.get_executable_path","title":"<code>get_executable_path(update=False)</code>","text":"<p>Finds the release executable in standard locations.</p> Source code in <code>toolboxv2/utils/system/tcm_p2p_cli.py</code> <pre><code>def get_executable_path(update=False) -&gt; Path | None:\n    \"\"\"Finds the release executable in standard locations.\"\"\"\n    # Look in a dedicated 'bin' folder first, then cargo's default\n    from toolboxv2 import tb_root_dir\n    search_paths = [\n        tb_root_dir /\"bin\" / EXECUTABLE_NAME,\n        tb_root_dir / \"tcm\"/ \"target\" / \"release\" / EXECUTABLE_NAME,\n    ]\n    if update:\n        search_paths = search_paths[::-1]\n    for path in search_paths:\n        print(path)\n        if path.is_file():\n            return path.resolve()\n    return None\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.types","title":"<code>types</code>","text":""},{"location":"toolboxv2/#toolboxv2.utils.system.types.AppType","title":"<code>AppType</code>","text":"Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>class AppType:\n    prefix: str\n    id: str\n    globals: dict[str, Any] = {\"root\": dict, }\n    locals: dict[str, Any] = {\"user\": {'app': \"self\"}, }\n\n    local_test: bool = False\n    start_dir: str\n    data_dir: str\n    config_dir: str\n    info_dir: str\n    is_server:bool = False\n\n    logger: logging.Logger\n    logging_filename: str\n\n    api_allowed_mods_list: list[str] = []\n\n    version: str\n    loop: asyncio.AbstractEventLoop\n\n    keys: dict[str, str] = {\n        \"MACRO\": \"macro~~~~:\",\n        \"MACRO_C\": \"m_color~~:\",\n        \"HELPER\": \"helper~~~:\",\n        \"debug\": \"debug~~~~:\",\n        \"id\": \"name-spa~:\",\n        \"st-load\": \"mute~load:\",\n        \"comm-his\": \"comm-his~:\",\n        \"develop-mode\": \"dev~mode~:\",\n        \"provider::\": \"provider::\",\n    }\n\n    defaults: dict[str, (bool or dict or dict[str, dict[str, str]] or str or list[str] or list[list]) | None] = {\n        \"MACRO\": list[str],\n        \"MACRO_C\": dict,\n        \"HELPER\": dict,\n        \"debug\": str,\n        \"id\": str,\n        \"st-load\": False,\n        \"comm-his\": list[list],\n        \"develop-mode\": bool,\n    }\n\n    cluster_manager: ClusterManager\n    root_blob_storage: BlobStorage\n    config_fh: FileHandler\n    _debug: bool\n    flows: dict[str, Callable]\n    dev_modi: bool\n    functions: dict[str, Any]\n    modules: dict[str, Any]\n\n    interface_type: ToolBoxInterfaces\n    REFIX: str\n\n    alive: bool\n    called_exit: tuple[bool, float]\n    args_sto: AppArgs\n    system_flag = None\n    session = None\n    appdata = None\n    exit_tasks = []\n\n    enable_profiling: bool = False\n    sto = None\n\n    websocket_handlers: dict[str, dict[str, Callable]] = {}\n    _rust_ws_bridge: Any = None\n\n    def __init__(self, prefix: None | str= None, args: AppArgs | None = None):\n        self.args_sto = args\n        self.prefix = prefix\n        \"\"\"proxi attr\"\"\"\n\n    def start_server(self):\n        from toolboxv2.utils.system.api import manage_server\n        if self.is_server:\n            return\n        manage_server(\"start\")\n        self.is_server = False\n\n    @staticmethod\n    def exit_main(*args, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    @staticmethod\n    async def hide_console(*args, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    @staticmethod\n    async def show_console(*args, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    @staticmethod\n    async def disconnect(*args, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    def set_logger(self, debug=False):\n        \"\"\"proxi attr\"\"\"\n\n    @property\n    def debug(self):\n        \"\"\"proxi attr\"\"\"\n        return self._debug\n\n    def debug_rains(self, e):\n        \"\"\"proxi attr\"\"\"\n\n    def set_flows(self, r):\n        \"\"\"proxi attr\"\"\"\n\n    def run_flows(self, name, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    def rrun_flows(self, name, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    def idle(self):\n        import time\n        self.print(\"idle\")\n        try:\n            while self.alive:\n                time.sleep(1)\n        except KeyboardInterrupt:\n            pass\n        self.print(\"idle done\")\n\n    async def a_idle(self):\n        self.print(\"a idle\")\n        try:\n            if hasattr(self, 'daemon_app'):\n                self.print(\"serving daemon\")\n                await self.daemon_app.connect(self)\n            else:\n                self.print(\"serving default\")\n                while self.alive:\n                    await asyncio.sleep(1)\n        except KeyboardInterrupt:\n            pass\n        self.print(\"a idle done\")\n\n    @debug.setter\n    def debug(self, value):\n        \"\"\"proxi attr\"\"\"\n\n    def _coppy_mod(self, content, new_mod_dir, mod_name, file_type='py'):\n        \"\"\"proxi attr\"\"\"\n\n    def _pre_lib_mod(self, mod_name, path_to=\"./runtime\", file_type='py'):\n        \"\"\"proxi attr\"\"\"\n\n    def _copy_load(self, mod_name, file_type='py', **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    def inplace_load_instance(self, mod_name, loc=\"toolboxv2.mods.\", spec='app', save=True):\n        \"\"\"proxi attr\"\"\"\n\n    def save_instance(self, instance, modular_id, spec='app', instance_type=\"file/application\", tools_class=None):\n        \"\"\"proxi attr\"\"\"\n\n    def save_initialized_module(self, tools_class, spec):\n        \"\"\"proxi attr\"\"\"\n\n    def mod_online(self, mod_name, installed=False):\n        \"\"\"proxi attr\"\"\"\n\n    def _get_function(self,\n                      name: Enum or None,\n                      state: bool = True,\n                      specification: str = \"app\",\n                      metadata=False, as_str: tuple or None = None, r=0):\n        \"\"\"proxi attr\"\"\"\n\n    def save_exit(self):\n        \"\"\"proxi attr\"\"\"\n\n    def load_mod(self, mod_name: str, mlm='I', **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    async def init_module(self, modular):\n        return await self.load_mod(modular)\n\n    async def load_all_mods_in_file(self, working_dir=\"mods\"):\n        \"\"\"proxi attr\"\"\"\n\n    def get_all_mods(self, working_dir=\"mods\", path_to=\"./runtime\"):\n        \"\"\"proxi attr\"\"\"\n\n    def remove_all_modules(self, delete=False):\n        for mod in list(self.functions.keys()):\n            self.logger.info(f\"closing: {mod}\")\n            self.remove_mod(mod, delete=delete)\n\n    async def a_remove_all_modules(self, delete=False):\n        for mod in list(self.functions.keys()):\n            self.logger.info(f\"closing: {mod}\")\n            await self.a_remove_mod(mod, delete=delete)\n\n    def print_ok(self):\n        \"\"\"proxi attr\"\"\"\n        self.logger.info(\"OK\")\n\n    def reload_mod(self, mod_name, spec='app', is_file=True, loc=\"toolboxv2.mods.\"):\n        \"\"\"proxi attr\"\"\"\n\n    def watch_mod(self, mod_name, spec='app', loc=\"toolboxv2.mods.\", use_thread=True, path_name=None):\n        \"\"\"proxi attr\"\"\"\n\n    def remove_mod(self, mod_name, spec='app', delete=True):\n        \"\"\"proxi attr\"\"\"\n\n    async def a_remove_mod(self, mod_name, spec='app', delete=True):\n        \"\"\"proxi attr\"\"\"\n\n    def exit(self):\n        \"\"\"proxi attr\"\"\"\n\n    def web_context(self) -&gt; str:\n        \"\"\"returns the build index ( toolbox web component )\"\"\"\n\n    async def a_exit(self):\n        \"\"\"proxi attr\"\"\"\n\n    def save_load(self, modname, spec='app'):\n        \"\"\"proxi attr\"\"\"\n\n    def get_function(self, name: Enum or tuple, **kwargs):\n        \"\"\"\n        Kwargs for _get_function\n            metadata:: return the registered function dictionary\n                stateless: (function_data, None), 0\n                stateful: (function_data, higher_order_function), 0\n            state::boolean\n                specification::str default app\n        \"\"\"\n\n    def run_a_from_sync(self, function, *args):\n        \"\"\"\n        run a async fuction\n        \"\"\"\n\n    def run_bg_task_advanced(self, task, *args, **kwargs):\n        \"\"\"\n        proxi attr\n        \"\"\"\n\n    def wait_for_bg_tasks(self, timeout=None):\n        \"\"\"\n        proxi attr\n        \"\"\"\n\n    def run_bg_task(self, task):\n        \"\"\"\n                run a async fuction\n                \"\"\"\n    def run_function(self, mod_function_name: Enum or tuple,\n                     tb_run_function_with_state=True,\n                     tb_run_with_specification='app',\n                     args_=None,\n                     kwargs_=None,\n                     *args,\n                     **kwargs) -&gt; Result:\n\n        \"\"\"proxi attr\"\"\"\n\n    async def a_run_function(self, mod_function_name: Enum or tuple,\n                             tb_run_function_with_state=True,\n                             tb_run_with_specification='app',\n                             args_=None,\n                             kwargs_=None,\n                             *args,\n                             **kwargs) -&gt; Result:\n\n        \"\"\"proxi attr\"\"\"\n\n    def fuction_runner(self, function, function_data: dict, args: list, kwargs: dict, t0=.0):\n        \"\"\"\n        parameters = function_data.get('params')\n        modular_name = function_data.get('module_name')\n        function_name = function_data.get('func_name')\n        mod_function_name = f\"{modular_name}.{function_name}\"\n\n        proxi attr\n        \"\"\"\n\n    async def a_fuction_runner(self, function, function_data: dict, args: list, kwargs: dict):\n        \"\"\"\n        parameters = function_data.get('params')\n        modular_name = function_data.get('module_name')\n        function_name = function_data.get('func_name')\n        mod_function_name = f\"{modular_name}.{function_name}\"\n\n        proxi attr\n        \"\"\"\n\n    async def run_http(self, mod_function_name: Enum or str or tuple, function_name=None, method=\"GET\",\n                       args_=None,\n                       kwargs_=None,\n                       *args, **kwargs):\n        \"\"\"run a function remote via http / https\"\"\"\n\n    def run_any(self, mod_function_name: Enum or str or tuple, backwords_compability_variabel_string_holder=None,\n                get_results=False, tb_run_function_with_state=True, tb_run_with_specification='app', args_=None,\n                kwargs_=None,\n                *args, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    async def a_run_any(self, mod_function_name: Enum or str or tuple,\n                        backwords_compability_variabel_string_holder=None,\n                        get_results=False, tb_run_function_with_state=True, tb_run_with_specification='app', args_=None,\n                        kwargs_=None,\n                        *args, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    def get_mod(self, name, spec='app') -&gt; ModuleType or MainToolType:\n        \"\"\"proxi attr\"\"\"\n\n    @staticmethod\n    def print(text, *args, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    @staticmethod\n    def sprint(text, *args, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    # ----------------------------------------------------------------\n    # Decorators for the toolbox\n\n    def _register_function(self, module_name, func_name, data):\n        \"\"\"proxi attr\"\"\"\n\n    def _create_decorator(self, type_: str,\n                          name: str = \"\",\n                          mod_name: str = \"\",\n                          level: int = -1,\n                          restrict_in_virtual_mode: bool = False,\n                          api: bool = False,\n                          helper: str = \"\",\n                          version: str or None = None,\n                          initial=False,\n                          exit_f=False,\n                          test=True,\n                          samples=None,\n                          state=None,\n                          pre_compute=None,\n                          post_compute=None,\n                          memory_cache=False,\n                          file_cache=False,\n                          row=False,\n                          request_as_kwarg=False,\n                          memory_cache_max_size=100,\n                          memory_cache_ttl=300,\n                          websocket_handler: str | None = None,):\n        \"\"\"proxi attr\"\"\"\n\n        # data = {\n        #     \"type\": type_,\n        #     \"module_name\": module_name,\n        #     \"func_name\": func_name,\n        #     \"level\": level,\n        #     \"restrict_in_virtual_mode\": restrict_in_virtual_mode,\n        #     \"func\": func,\n        #     \"api\": api,\n        #     \"helper\": helper,\n        #     \"version\": version,\n        #     \"initial\": initial,\n        #     \"exit_f\": exit_f,\n        #     \"__module__\": func.__module__,\n        #     \"signature\": sig,\n        #     \"params\": params,\n        #     \"state\": (\n        #         False if len(params) == 0 else params[0] in ['self', 'state', 'app']) if state is None else state,\n        #     \"do_test\": test,\n        #     \"samples\": samples,\n        #     \"request_as_kwarg\": request_as_kwarg,\n\n    def tb(self, name=None,\n           mod_name: str = \"\",\n           helper: str = \"\",\n           version: str or None = None,\n           test: bool = True,\n           restrict_in_virtual_mode: bool = False,\n           api: bool = False,\n           initial: bool = False,\n           exit_f: bool = False,\n           test_only: bool = False,\n           memory_cache: bool = False,\n           file_cache: bool = False,\n           row=False,\n           request_as_kwarg: bool = False,\n           state: bool or None = None,\n           level: int = 0,\n           memory_cache_max_size: int = 100,\n           memory_cache_ttl: int = 300,\n           samples: list or dict or None = None,\n           interface: ToolBoxInterfaces or None or str = None,\n           pre_compute=None,\n           post_compute=None,\n           api_methods=None,\n           websocket_handler: str | None = None,\n           ):\n        \"\"\"\n    A decorator for registering and configuring functions within a module.\n\n    This decorator is used to wrap functions with additional functionality such as caching, API conversion, and lifecycle management (initialization and exit). It also handles the registration of the function in the module's function registry.\n\n    Args:\n        name (str, optional): The name to register the function under. Defaults to the function's own name.\n        mod_name (str, optional): The name of the module the function belongs to.\n        helper (str, optional): A helper string providing additional information about the function.\n        version (str or None, optional): The version of the function or module.\n        test (bool, optional): Flag to indicate if the function is for testing purposes.\n        restrict_in_virtual_mode (bool, optional): Flag to restrict the function in virtual mode.\n        api (bool, optional): Flag to indicate if the function is part of an API.\n        initial (bool, optional): Flag to indicate if the function should be executed at initialization.\n        exit_f (bool, optional): Flag to indicate if the function should be executed at exit.\n        test_only (bool, optional): Flag to indicate if the function should only be used for testing.\n        memory_cache (bool, optional): Flag to enable memory caching for the function.\n        request_as_kwarg (bool, optional): Flag to get request if the fuction is calld from api.\n        file_cache (bool, optional): Flag to enable file caching for the function.\n        row (bool, optional): rather to auto wrap the result in Result type default False means no row data aka result type\n        state (bool or None, optional): Flag to indicate if the function maintains state.\n        level (int, optional): The level of the function, used for prioritization or categorization.\n        memory_cache_max_size (int, optional): Maximum size of the memory cache.\n        memory_cache_ttl (int, optional): Time-to-live for the memory cache entries.\n        samples (list or dict or None, optional): Samples or examples of function usage.\n        interface (str, optional): The interface type for the function.\n        pre_compute (callable, optional): A function to be called before the main function.\n        post_compute (callable, optional): A function to be called after the main function.\n        api_methods (list[str], optional): default [\"AUTO\"] (GET if not params, POST if params) , GET, POST, PUT or DELETE.\n\n    Returns:\n        function: The decorated function with additional processing and registration capabilities.\n    \"\"\"\n        if interface is None:\n            interface = \"tb\"\n        if test_only and 'test' not in self.id:\n            return lambda *args, **kwargs: args\n        return self._create_decorator(interface,\n                                      name,\n                                      mod_name,\n                                      level=level,\n                                      restrict_in_virtual_mode=restrict_in_virtual_mode,\n                                      helper=helper,\n                                      api=api,\n                                      version=version,\n                                      initial=initial,\n                                      exit_f=exit_f,\n                                      test=test,\n                                      samples=samples,\n                                      state=state,\n                                      pre_compute=pre_compute,\n                                      post_compute=post_compute,\n                                      memory_cache=memory_cache,\n                                      file_cache=file_cache,\n                                      row=row,\n                                      request_as_kwarg=request_as_kwarg,\n                                      memory_cache_max_size=memory_cache_max_size,\n                                      memory_cache_ttl=memory_cache_ttl)\n\n    def print_functions(self, name=None):\n\n\n        if not self.functions:\n            print(\"Nothing to see\")\n            return\n\n        def helper(_functions):\n            for func_name, data in _functions.items():\n                if not isinstance(data, dict):\n                    continue\n\n                func_type = data.get('type', 'Unknown')\n                func_level = 'r' if data['level'] == -1 else data['level']\n                api_status = 'Api' if data.get('api', False) else 'Non-Api'\n\n                print(f\"  Function: {func_name}{data.get('signature', '()')}; \"\n                      f\"Type: {func_type}, Level: {func_level}, {api_status}\")\n\n        if name is not None:\n            functions = self.functions.get(name)\n            if functions is not None:\n                print(f\"\\nModule: {name}; Type: {functions.get('app_instance_type', 'Unknown')}\")\n                helper(functions)\n                return\n        for module, functions in self.functions.items():\n            print(f\"\\nModule: {module}; Type: {functions.get('app_instance_type', 'Unknown')}\")\n            helper(functions)\n\n    def save_autocompletion_dict(self):\n        \"\"\"proxi attr\"\"\"\n\n    def get_autocompletion_dict(self):\n        \"\"\"proxi attr\"\"\"\n\n    def get_username(self, get_input=False, default=\"loot\") -&gt; str:\n        \"\"\"proxi attr\"\"\"\n\n    def save_registry_as_enums(self, directory: str, filename: str):\n        \"\"\"proxi attr\"\"\"\n\n    async def execute_all_functions_(self, m_query='', f_query=''):\n        print(\"Executing all functions\")\n        from ..extras import generate_test_cases\n        all_data = {\n            \"modular_run\": 0,\n            \"modular_fatal_error\": 0,\n            \"errors\": 0,\n            \"modular_sug\": 0,\n            \"coverage\": [],\n            \"total_coverage\": {},\n        }\n        items = list(self.functions.items()).copy()\n        for module_name, functions in items:\n            infos = {\n                \"functions_run\": 0,\n                \"functions_fatal_error\": 0,\n                \"error\": 0,\n                \"functions_sug\": 0,\n                'calls': {},\n                'callse': {},\n                \"coverage\": [0, 0],\n            }\n            all_data['modular_run'] += 1\n            if not module_name.startswith(m_query):\n                all_data['modular_sug'] += 1\n                continue\n\n            with Spinner(message=f\"In {module_name}| \"):\n                f_items = list(functions.items()).copy()\n                for function_name, function_data in f_items:\n                    if not isinstance(function_data, dict):\n                        continue\n                    if not function_name.startswith(f_query):\n                        continue\n                    test: list = function_data.get('do_test')\n                    # print(test, module_name, function_name, function_data)\n                    infos[\"coverage\"][0] += 1\n                    if test is False:\n                        continue\n\n                    with Spinner(message=f\"\\t\\t\\t\\t\\t\\tfuction {function_name}...\"):\n                        params: list = function_data.get('params')\n                        sig: signature = function_data.get('signature')\n                        state: bool = function_data.get('state')\n                        samples: bool = function_data.get('samples')\n\n                        test_kwargs_list = [{}]\n\n                        if params is not None:\n                            test_kwargs_list = samples if samples is not None else generate_test_cases(sig=sig)\n                            # print(test_kwargs)\n                            # print(test_kwargs[0])\n                            # test_kwargs = test_kwargs_list[0]\n                        # print(module_name, function_name, test_kwargs_list)\n                        infos[\"coverage\"][1] += 1\n                        for test_kwargs in test_kwargs_list:\n                            try:\n                                # print(f\"test Running {state=} |{module_name}.{function_name}\")\n                                result = await self.a_run_function((module_name, function_name),\n                                                                   tb_run_function_with_state=state,\n                                                                   **test_kwargs)\n                                if not isinstance(result, Result):\n                                    result = Result.ok(result)\n                                if result.info.exec_code == 0:\n                                    infos['calls'][function_name] = [test_kwargs, str(result)]\n                                    infos['functions_sug'] += 1\n                                else:\n                                    infos['functions_sug'] += 1\n                                    infos['error'] += 1\n                                    infos['callse'][function_name] = [test_kwargs, str(result)]\n                            except Exception as e:\n                                infos['functions_fatal_error'] += 1\n                                infos['callse'][function_name] = [test_kwargs, str(e)]\n                            finally:\n                                infos['functions_run'] += 1\n\n                if infos['functions_run'] == infos['functions_sug']:\n                    all_data['modular_sug'] += 1\n                else:\n                    all_data['modular_fatal_error'] += 1\n                if infos['error'] &gt; 0:\n                    all_data['errors'] += infos['error']\n\n                all_data[module_name] = infos\n                if infos['coverage'][0] == 0:\n                    c = 0\n                else:\n                    c = infos['coverage'][1] / infos['coverage'][0]\n                all_data[\"coverage\"].append(f\"{module_name}:{c:.2f}\\n\")\n        total_coverage = sum([float(t.split(\":\")[-1]) for t in all_data[\"coverage\"]]) / len(all_data[\"coverage\"])\n        print(\n            f\"\\n{all_data['modular_run']=}\\n{all_data['modular_sug']=}\\n{all_data['modular_fatal_error']=}\\n{total_coverage=}\")\n        d = analyze_data(all_data)\n        return Result.ok(data=all_data, data_info=d)\n\n    @staticmethod\n    def calculate_complexity(filename_or_code):\n        from radon.complexity import cc_rank, cc_visit\n        if os.path.exists(filename_or_code):\n            with open(filename_or_code) as file:\n                code = file.read()\n        else:\n            code = filename_or_code\n\n        # Calculate and print Cyclomatic Complexity\n        complexity_results = cc_visit(code)\n        i = -1\n        avg_complexity = 0\n        for block in complexity_results:\n            complexity = block.complexity\n            i += 1\n            print(f\"block: {block.name} {i} Class/Fuction/Methode : {block.letter}\")\n            print(f\"    fullname: {block.fullname}\")\n            print(f\"    Cyclomatic Complexity: {complexity}\")\n            # Optional: Get complexity rank\n            avg_complexity += complexity\n            rank = cc_rank(complexity)\n            print(f\"    Complexity Rank: {rank}\")\n            # print(f\"    lineno: {block.lineno}\")\n            print(f\"    endline: {block.endline}\")\n            print(f\"    col_offset: {block.col_offset}\\n\")\n        if i &lt;= 0:\n            i += 2\n        avg_complexity = avg_complexity / i\n        print(f\"\\nAVG Complexity: {avg_complexity:.2f}\")\n        print(f\"Total Rank: {cc_rank(int(avg_complexity + i // 10))}\")\n\n    async def execute_function_test(self, module_name: str, function_name: str,\n                                    function_data: dict, test_kwargs: dict,\n                                    profiler: cProfile.Profile) -&gt; tuple[bool, str, dict, float]:\n        start_time = time.time()\n        with profile_section(profiler, hasattr(self, 'enable_profiling') and self.enable_profiling):\n            try:\n                result = await self.a_run_function(\n                    (module_name, function_name),\n                    tb_run_function_with_state=function_data.get('state'),\n                    **test_kwargs\n                )\n\n                if not isinstance(result, Result):\n                    result = Result.ok(result)\n\n                success = result.info.exec_code == 0\n                execution_time = time.time() - start_time\n                return success, str(result), test_kwargs, execution_time\n            except Exception as e:\n                execution_time = time.time() - start_time\n                return False, str(e), test_kwargs, execution_time\n\n    async def process_function(self, module_name: str, function_name: str,\n                               function_data: dict, profiler: cProfile.Profile) -&gt; tuple[str, ModuleInfo]:\n        start_time = time.time()\n        info = ModuleInfo()\n\n        with profile_section(profiler, hasattr(self, 'enable_profiling') and self.enable_profiling):\n            if not isinstance(function_data, dict):\n                return function_name, info\n\n            test = function_data.get('do_test')\n            info.coverage[0] += 1\n\n            if test is False:\n                return function_name, info\n\n            params = function_data.get('params')\n            sig = function_data.get('signature')\n            samples = function_data.get('samples')\n\n            test_kwargs_list = [{}] if params is None else (\n                samples if samples is not None else generate_test_cases(sig=sig)\n            )\n\n            info.coverage[1] += 1\n\n            # Create tasks for all test cases\n            tasks = [\n                self.execute_function_test(module_name, function_name, function_data, test_kwargs, profiler)\n                for test_kwargs in test_kwargs_list\n            ]\n\n            # Execute all tests concurrently\n            results = await asyncio.gather(*tasks)\n\n            total_execution_time = 0\n            for success, result_str, test_kwargs, execution_time in results:\n                info.functions_run += 1\n                total_execution_time += execution_time\n\n                if success:\n                    info.functions_sug += 1\n                    info.calls[function_name] = [test_kwargs, result_str]\n                else:\n                    info.functions_sug += 1\n                    info.error += 1\n                    info.callse[function_name] = [test_kwargs, result_str]\n\n            info.execution_time = time.time() - start_time\n            return function_name, info\n\n    async def process_module(self, module_name: str, functions: dict,\n                             f_query: str, profiler: cProfile.Profile) -&gt; tuple[str, ModuleInfo]:\n        start_time = time.time()\n\n        with profile_section(profiler, hasattr(self, 'enable_profiling') and self.enable_profiling):\n            async with asyncio.Semaphore(mp.cpu_count()):\n                tasks = [\n                    self.process_function(module_name, fname, fdata, profiler)\n                    for fname, fdata in functions.items()\n                    if fname.startswith(f_query)\n                ]\n\n                if not tasks:\n                    return module_name, ModuleInfo()\n\n                results = await asyncio.gather(*tasks)\n\n                # Combine results from all functions in the module\n                combined_info = ModuleInfo()\n                total_execution_time = 0\n\n                for _, info in results:\n                    combined_info.functions_run += info.functions_run\n                    combined_info.functions_fatal_error += info.functions_fatal_error\n                    combined_info.error += info.error\n                    combined_info.functions_sug += info.functions_sug\n                    combined_info.calls.update(info.calls)\n                    combined_info.callse.update(info.callse)\n                    combined_info.coverage[0] += info.coverage[0]\n                    combined_info.coverage[1] += info.coverage[1]\n                    total_execution_time += info.execution_time\n\n                combined_info.execution_time = time.time() - start_time\n                return module_name, combined_info\n\n    async def execute_all_functions(self, m_query='', f_query='', enable_profiling=True):\n        \"\"\"\n        Execute all functions with parallel processing and optional profiling.\n\n        Args:\n            m_query (str): Module name query filter\n            f_query (str): Function name query filter\n            enable_profiling (bool): Enable detailed profiling information\n        \"\"\"\n        print(\"Executing all functions in parallel\" + (\" with profiling\" if enable_profiling else \"\"))\n\n        start_time = time.time()\n        stats = ExecutionStats()\n        items = list(self.functions.items()).copy()\n\n        # Set up profiling\n        self.enable_profiling = enable_profiling\n        profiler = cProfile.Profile()\n\n        with profile_section(profiler, enable_profiling):\n            # Filter modules based on query\n            filtered_modules = [\n                (mname, mfuncs) for mname, mfuncs in items\n                if mname.startswith(m_query)\n            ]\n\n            stats.modular_run = len(filtered_modules)\n\n            # Process all modules concurrently\n            async with asyncio.Semaphore(mp.cpu_count()):\n                tasks = [\n                    self.process_module(mname, mfuncs, f_query, profiler)\n                    for mname, mfuncs in filtered_modules\n                ]\n\n                results = await asyncio.gather(*tasks)\n\n            # Combine results and calculate statistics\n            for module_name, info in results:\n                if info.functions_run == info.functions_sug:\n                    stats.modular_sug += 1\n                else:\n                    stats.modular_fatal_error += 1\n\n                stats.errors += info.error\n\n                # Calculate coverage\n                coverage = (info.coverage[1] / info.coverage[0]) if info.coverage[0] &gt; 0 else 0\n                stats.coverage.append(f\"{module_name}:{coverage:.2f}\\n\")\n\n                # Store module info\n                stats.__dict__[module_name] = info\n\n            # Calculate total coverage\n            total_coverage = (\n                sum(float(t.split(\":\")[-1]) for t in stats.coverage) / len(stats.coverage)\n                if stats.coverage else 0\n            )\n\n            stats.total_execution_time = time.time() - start_time\n\n            # Generate profiling stats if enabled\n            if enable_profiling:\n                s = io.StringIO()\n                ps = pstats.Stats(profiler, stream=s).sort_stats('cumulative')\n                ps.print_stats()\n                stats.profiling_data = {\n                    'detailed_stats': s.getvalue(),\n                    'total_time': stats.total_execution_time,\n                    'function_count': stats.modular_run,\n                    'successful_functions': stats.modular_sug\n                }\n\n            print(\n                f\"\\n{stats.modular_run=}\"\n                f\"\\n{stats.modular_sug=}\"\n                f\"\\n{stats.modular_fatal_error=}\"\n                f\"\\n{total_coverage=}\"\n                f\"\\nTotal execution time: {stats.total_execution_time:.2f}s\"\n            )\n\n            if enable_profiling:\n                print(\"\\nProfiling Summary:\")\n                print(f\"{'=' * 50}\")\n                print(\"Top 10 time-consuming functions:\")\n                ps.print_stats(10)\n\n            analyzed_data = analyze_data(stats.__dict__)\n            return Result.ok(data=stats.__dict__, data_info=analyzed_data)\n</code></pre> <code>debug</code> <code>property</code> <code>writable</code> \u00b6 <p>proxi attr</p> <code>prefix = prefix</code> <code>instance-attribute</code> \u00b6 <p>proxi attr</p> <code>a_exit()</code> <code>async</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>async def a_exit(self):\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>a_fuction_runner(function, function_data, args, kwargs)</code> <code>async</code> \u00b6 <p>parameters = function_data.get('params') modular_name = function_data.get('module_name') function_name = function_data.get('func_name') mod_function_name = f\"{modular_name}.{function_name}\"</p> <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>async def a_fuction_runner(self, function, function_data: dict, args: list, kwargs: dict):\n    \"\"\"\n    parameters = function_data.get('params')\n    modular_name = function_data.get('module_name')\n    function_name = function_data.get('func_name')\n    mod_function_name = f\"{modular_name}.{function_name}\"\n\n    proxi attr\n    \"\"\"\n</code></pre> <code>a_remove_mod(mod_name, spec='app', delete=True)</code> <code>async</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>async def a_remove_mod(self, mod_name, spec='app', delete=True):\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>a_run_any(mod_function_name, backwords_compability_variabel_string_holder=None, get_results=False, tb_run_function_with_state=True, tb_run_with_specification='app', args_=None, kwargs_=None, *args, **kwargs)</code> <code>async</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>async def a_run_any(self, mod_function_name: Enum or str or tuple,\n                    backwords_compability_variabel_string_holder=None,\n                    get_results=False, tb_run_function_with_state=True, tb_run_with_specification='app', args_=None,\n                    kwargs_=None,\n                    *args, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>a_run_function(mod_function_name, tb_run_function_with_state=True, tb_run_with_specification='app', args_=None, kwargs_=None, *args, **kwargs)</code> <code>async</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>async def a_run_function(self, mod_function_name: Enum or tuple,\n                         tb_run_function_with_state=True,\n                         tb_run_with_specification='app',\n                         args_=None,\n                         kwargs_=None,\n                         *args,\n                         **kwargs) -&gt; Result:\n\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>debug_rains(e)</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def debug_rains(self, e):\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>disconnect(*args, **kwargs)</code> <code>async</code> <code>staticmethod</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@staticmethod\nasync def disconnect(*args, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>execute_all_functions(m_query='', f_query='', enable_profiling=True)</code> <code>async</code> \u00b6 <p>Execute all functions with parallel processing and optional profiling.</p> <p>Parameters:</p> Name Type Description Default <code>m_query</code> <code>str</code> <p>Module name query filter</p> <code>''</code> <code>f_query</code> <code>str</code> <p>Function name query filter</p> <code>''</code> <code>enable_profiling</code> <code>bool</code> <p>Enable detailed profiling information</p> <code>True</code> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>async def execute_all_functions(self, m_query='', f_query='', enable_profiling=True):\n    \"\"\"\n    Execute all functions with parallel processing and optional profiling.\n\n    Args:\n        m_query (str): Module name query filter\n        f_query (str): Function name query filter\n        enable_profiling (bool): Enable detailed profiling information\n    \"\"\"\n    print(\"Executing all functions in parallel\" + (\" with profiling\" if enable_profiling else \"\"))\n\n    start_time = time.time()\n    stats = ExecutionStats()\n    items = list(self.functions.items()).copy()\n\n    # Set up profiling\n    self.enable_profiling = enable_profiling\n    profiler = cProfile.Profile()\n\n    with profile_section(profiler, enable_profiling):\n        # Filter modules based on query\n        filtered_modules = [\n            (mname, mfuncs) for mname, mfuncs in items\n            if mname.startswith(m_query)\n        ]\n\n        stats.modular_run = len(filtered_modules)\n\n        # Process all modules concurrently\n        async with asyncio.Semaphore(mp.cpu_count()):\n            tasks = [\n                self.process_module(mname, mfuncs, f_query, profiler)\n                for mname, mfuncs in filtered_modules\n            ]\n\n            results = await asyncio.gather(*tasks)\n\n        # Combine results and calculate statistics\n        for module_name, info in results:\n            if info.functions_run == info.functions_sug:\n                stats.modular_sug += 1\n            else:\n                stats.modular_fatal_error += 1\n\n            stats.errors += info.error\n\n            # Calculate coverage\n            coverage = (info.coverage[1] / info.coverage[0]) if info.coverage[0] &gt; 0 else 0\n            stats.coverage.append(f\"{module_name}:{coverage:.2f}\\n\")\n\n            # Store module info\n            stats.__dict__[module_name] = info\n\n        # Calculate total coverage\n        total_coverage = (\n            sum(float(t.split(\":\")[-1]) for t in stats.coverage) / len(stats.coverage)\n            if stats.coverage else 0\n        )\n\n        stats.total_execution_time = time.time() - start_time\n\n        # Generate profiling stats if enabled\n        if enable_profiling:\n            s = io.StringIO()\n            ps = pstats.Stats(profiler, stream=s).sort_stats('cumulative')\n            ps.print_stats()\n            stats.profiling_data = {\n                'detailed_stats': s.getvalue(),\n                'total_time': stats.total_execution_time,\n                'function_count': stats.modular_run,\n                'successful_functions': stats.modular_sug\n            }\n\n        print(\n            f\"\\n{stats.modular_run=}\"\n            f\"\\n{stats.modular_sug=}\"\n            f\"\\n{stats.modular_fatal_error=}\"\n            f\"\\n{total_coverage=}\"\n            f\"\\nTotal execution time: {stats.total_execution_time:.2f}s\"\n        )\n\n        if enable_profiling:\n            print(\"\\nProfiling Summary:\")\n            print(f\"{'=' * 50}\")\n            print(\"Top 10 time-consuming functions:\")\n            ps.print_stats(10)\n\n        analyzed_data = analyze_data(stats.__dict__)\n        return Result.ok(data=stats.__dict__, data_info=analyzed_data)\n</code></pre> <code>exit()</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def exit(self):\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>exit_main(*args, **kwargs)</code> <code>staticmethod</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@staticmethod\ndef exit_main(*args, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>fuction_runner(function, function_data, args, kwargs, t0=0.0)</code> \u00b6 <p>parameters = function_data.get('params') modular_name = function_data.get('module_name') function_name = function_data.get('func_name') mod_function_name = f\"{modular_name}.{function_name}\"</p> <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def fuction_runner(self, function, function_data: dict, args: list, kwargs: dict, t0=.0):\n    \"\"\"\n    parameters = function_data.get('params')\n    modular_name = function_data.get('module_name')\n    function_name = function_data.get('func_name')\n    mod_function_name = f\"{modular_name}.{function_name}\"\n\n    proxi attr\n    \"\"\"\n</code></pre> <code>get_all_mods(working_dir='mods', path_to='./runtime')</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def get_all_mods(self, working_dir=\"mods\", path_to=\"./runtime\"):\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>get_autocompletion_dict()</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def get_autocompletion_dict(self):\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>get_function(name, **kwargs)</code> \u00b6 <p>Kwargs for _get_function     metadata:: return the registered function dictionary         stateless: (function_data, None), 0         stateful: (function_data, higher_order_function), 0     state::boolean         specification::str default app</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def get_function(self, name: Enum or tuple, **kwargs):\n    \"\"\"\n    Kwargs for _get_function\n        metadata:: return the registered function dictionary\n            stateless: (function_data, None), 0\n            stateful: (function_data, higher_order_function), 0\n        state::boolean\n            specification::str default app\n    \"\"\"\n</code></pre> <code>get_mod(name, spec='app')</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def get_mod(self, name, spec='app') -&gt; ModuleType or MainToolType:\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>get_username(get_input=False, default='loot')</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def get_username(self, get_input=False, default=\"loot\") -&gt; str:\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>hide_console(*args, **kwargs)</code> <code>async</code> <code>staticmethod</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@staticmethod\nasync def hide_console(*args, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>inplace_load_instance(mod_name, loc='toolboxv2.mods.', spec='app', save=True)</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def inplace_load_instance(self, mod_name, loc=\"toolboxv2.mods.\", spec='app', save=True):\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>load_all_mods_in_file(working_dir='mods')</code> <code>async</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>async def load_all_mods_in_file(self, working_dir=\"mods\"):\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>load_mod(mod_name, mlm='I', **kwargs)</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def load_mod(self, mod_name: str, mlm='I', **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>mod_online(mod_name, installed=False)</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def mod_online(self, mod_name, installed=False):\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>print(text, *args, **kwargs)</code> <code>staticmethod</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@staticmethod\ndef print(text, *args, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>print_ok()</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def print_ok(self):\n    \"\"\"proxi attr\"\"\"\n    self.logger.info(\"OK\")\n</code></pre> <code>reload_mod(mod_name, spec='app', is_file=True, loc='toolboxv2.mods.')</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def reload_mod(self, mod_name, spec='app', is_file=True, loc=\"toolboxv2.mods.\"):\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>remove_mod(mod_name, spec='app', delete=True)</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def remove_mod(self, mod_name, spec='app', delete=True):\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>rrun_flows(name, **kwargs)</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def rrun_flows(self, name, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>run_a_from_sync(function, *args)</code> \u00b6 <p>run a async fuction</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def run_a_from_sync(self, function, *args):\n    \"\"\"\n    run a async fuction\n    \"\"\"\n</code></pre> <code>run_any(mod_function_name, backwords_compability_variabel_string_holder=None, get_results=False, tb_run_function_with_state=True, tb_run_with_specification='app', args_=None, kwargs_=None, *args, **kwargs)</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def run_any(self, mod_function_name: Enum or str or tuple, backwords_compability_variabel_string_holder=None,\n            get_results=False, tb_run_function_with_state=True, tb_run_with_specification='app', args_=None,\n            kwargs_=None,\n            *args, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>run_bg_task(task)</code> \u00b6 <p>run a async fuction</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def run_bg_task(self, task):\n    \"\"\"\n            run a async fuction\n            \"\"\"\n</code></pre> <code>run_bg_task_advanced(task, *args, **kwargs)</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def run_bg_task_advanced(self, task, *args, **kwargs):\n    \"\"\"\n    proxi attr\n    \"\"\"\n</code></pre> <code>run_flows(name, **kwargs)</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def run_flows(self, name, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>run_function(mod_function_name, tb_run_function_with_state=True, tb_run_with_specification='app', args_=None, kwargs_=None, *args, **kwargs)</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def run_function(self, mod_function_name: Enum or tuple,\n                 tb_run_function_with_state=True,\n                 tb_run_with_specification='app',\n                 args_=None,\n                 kwargs_=None,\n                 *args,\n                 **kwargs) -&gt; Result:\n\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>run_http(mod_function_name, function_name=None, method='GET', args_=None, kwargs_=None, *args, **kwargs)</code> <code>async</code> \u00b6 <p>run a function remote via http / https</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>async def run_http(self, mod_function_name: Enum or str or tuple, function_name=None, method=\"GET\",\n                   args_=None,\n                   kwargs_=None,\n                   *args, **kwargs):\n    \"\"\"run a function remote via http / https\"\"\"\n</code></pre> <code>save_autocompletion_dict()</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def save_autocompletion_dict(self):\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>save_exit()</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def save_exit(self):\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>save_initialized_module(tools_class, spec)</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def save_initialized_module(self, tools_class, spec):\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>save_instance(instance, modular_id, spec='app', instance_type='file/application', tools_class=None)</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def save_instance(self, instance, modular_id, spec='app', instance_type=\"file/application\", tools_class=None):\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>save_load(modname, spec='app')</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def save_load(self, modname, spec='app'):\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>save_registry_as_enums(directory, filename)</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def save_registry_as_enums(self, directory: str, filename: str):\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>set_flows(r)</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def set_flows(self, r):\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>set_logger(debug=False)</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def set_logger(self, debug=False):\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>show_console(*args, **kwargs)</code> <code>async</code> <code>staticmethod</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@staticmethod\nasync def show_console(*args, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>sprint(text, *args, **kwargs)</code> <code>staticmethod</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@staticmethod\ndef sprint(text, *args, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>tb(name=None, mod_name='', helper='', version=None, test=True, restrict_in_virtual_mode=False, api=False, initial=False, exit_f=False, test_only=False, memory_cache=False, file_cache=False, row=False, request_as_kwarg=False, state=None, level=0, memory_cache_max_size=100, memory_cache_ttl=300, samples=None, interface=None, pre_compute=None, post_compute=None, api_methods=None, websocket_handler=None)</code> \u00b6 <p>A decorator for registering and configuring functions within a module.</p> <p>This decorator is used to wrap functions with additional functionality such as caching, API conversion, and lifecycle management (initialization and exit). It also handles the registration of the function in the module's function registry.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name to register the function under. Defaults to the function's own name.</p> <code>None</code> <code>mod_name</code> <code>str</code> <p>The name of the module the function belongs to.</p> <code>''</code> <code>helper</code> <code>str</code> <p>A helper string providing additional information about the function.</p> <code>''</code> <code>version</code> <code>str or None</code> <p>The version of the function or module.</p> <code>None</code> <code>test</code> <code>bool</code> <p>Flag to indicate if the function is for testing purposes.</p> <code>True</code> <code>restrict_in_virtual_mode</code> <code>bool</code> <p>Flag to restrict the function in virtual mode.</p> <code>False</code> <code>api</code> <code>bool</code> <p>Flag to indicate if the function is part of an API.</p> <code>False</code> <code>initial</code> <code>bool</code> <p>Flag to indicate if the function should be executed at initialization.</p> <code>False</code> <code>exit_f</code> <code>bool</code> <p>Flag to indicate if the function should be executed at exit.</p> <code>False</code> <code>test_only</code> <code>bool</code> <p>Flag to indicate if the function should only be used for testing.</p> <code>False</code> <code>memory_cache</code> <code>bool</code> <p>Flag to enable memory caching for the function.</p> <code>False</code> <code>request_as_kwarg</code> <code>bool</code> <p>Flag to get request if the fuction is calld from api.</p> <code>False</code> <code>file_cache</code> <code>bool</code> <p>Flag to enable file caching for the function.</p> <code>False</code> <code>row</code> <code>bool</code> <p>rather to auto wrap the result in Result type default False means no row data aka result type</p> <code>False</code> <code>state</code> <code>bool or None</code> <p>Flag to indicate if the function maintains state.</p> <code>None</code> <code>level</code> <code>int</code> <p>The level of the function, used for prioritization or categorization.</p> <code>0</code> <code>memory_cache_max_size</code> <code>int</code> <p>Maximum size of the memory cache.</p> <code>100</code> <code>memory_cache_ttl</code> <code>int</code> <p>Time-to-live for the memory cache entries.</p> <code>300</code> <code>samples</code> <code>list or dict or None</code> <p>Samples or examples of function usage.</p> <code>None</code> <code>interface</code> <code>str</code> <p>The interface type for the function.</p> <code>None</code> <code>pre_compute</code> <code>callable</code> <p>A function to be called before the main function.</p> <code>None</code> <code>post_compute</code> <code>callable</code> <p>A function to be called after the main function.</p> <code>None</code> <code>api_methods</code> <code>list[str]</code> <p>default [\"AUTO\"] (GET if not params, POST if params) , GET, POST, PUT or DELETE.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>function</code> <p>The decorated function with additional processing and registration capabilities.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def tb(self, name=None,\n       mod_name: str = \"\",\n       helper: str = \"\",\n       version: str or None = None,\n       test: bool = True,\n       restrict_in_virtual_mode: bool = False,\n       api: bool = False,\n       initial: bool = False,\n       exit_f: bool = False,\n       test_only: bool = False,\n       memory_cache: bool = False,\n       file_cache: bool = False,\n       row=False,\n       request_as_kwarg: bool = False,\n       state: bool or None = None,\n       level: int = 0,\n       memory_cache_max_size: int = 100,\n       memory_cache_ttl: int = 300,\n       samples: list or dict or None = None,\n       interface: ToolBoxInterfaces or None or str = None,\n       pre_compute=None,\n       post_compute=None,\n       api_methods=None,\n       websocket_handler: str | None = None,\n       ):\n    \"\"\"\nA decorator for registering and configuring functions within a module.\n\nThis decorator is used to wrap functions with additional functionality such as caching, API conversion, and lifecycle management (initialization and exit). It also handles the registration of the function in the module's function registry.\n\nArgs:\n    name (str, optional): The name to register the function under. Defaults to the function's own name.\n    mod_name (str, optional): The name of the module the function belongs to.\n    helper (str, optional): A helper string providing additional information about the function.\n    version (str or None, optional): The version of the function or module.\n    test (bool, optional): Flag to indicate if the function is for testing purposes.\n    restrict_in_virtual_mode (bool, optional): Flag to restrict the function in virtual mode.\n    api (bool, optional): Flag to indicate if the function is part of an API.\n    initial (bool, optional): Flag to indicate if the function should be executed at initialization.\n    exit_f (bool, optional): Flag to indicate if the function should be executed at exit.\n    test_only (bool, optional): Flag to indicate if the function should only be used for testing.\n    memory_cache (bool, optional): Flag to enable memory caching for the function.\n    request_as_kwarg (bool, optional): Flag to get request if the fuction is calld from api.\n    file_cache (bool, optional): Flag to enable file caching for the function.\n    row (bool, optional): rather to auto wrap the result in Result type default False means no row data aka result type\n    state (bool or None, optional): Flag to indicate if the function maintains state.\n    level (int, optional): The level of the function, used for prioritization or categorization.\n    memory_cache_max_size (int, optional): Maximum size of the memory cache.\n    memory_cache_ttl (int, optional): Time-to-live for the memory cache entries.\n    samples (list or dict or None, optional): Samples or examples of function usage.\n    interface (str, optional): The interface type for the function.\n    pre_compute (callable, optional): A function to be called before the main function.\n    post_compute (callable, optional): A function to be called after the main function.\n    api_methods (list[str], optional): default [\"AUTO\"] (GET if not params, POST if params) , GET, POST, PUT or DELETE.\n\nReturns:\n    function: The decorated function with additional processing and registration capabilities.\n\"\"\"\n    if interface is None:\n        interface = \"tb\"\n    if test_only and 'test' not in self.id:\n        return lambda *args, **kwargs: args\n    return self._create_decorator(interface,\n                                  name,\n                                  mod_name,\n                                  level=level,\n                                  restrict_in_virtual_mode=restrict_in_virtual_mode,\n                                  helper=helper,\n                                  api=api,\n                                  version=version,\n                                  initial=initial,\n                                  exit_f=exit_f,\n                                  test=test,\n                                  samples=samples,\n                                  state=state,\n                                  pre_compute=pre_compute,\n                                  post_compute=post_compute,\n                                  memory_cache=memory_cache,\n                                  file_cache=file_cache,\n                                  row=row,\n                                  request_as_kwarg=request_as_kwarg,\n                                  memory_cache_max_size=memory_cache_max_size,\n                                  memory_cache_ttl=memory_cache_ttl)\n</code></pre> <code>wait_for_bg_tasks(timeout=None)</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def wait_for_bg_tasks(self, timeout=None):\n    \"\"\"\n    proxi attr\n    \"\"\"\n</code></pre> <code>watch_mod(mod_name, spec='app', loc='toolboxv2.mods.', use_thread=True, path_name=None)</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def watch_mod(self, mod_name, spec='app', loc=\"toolboxv2.mods.\", use_thread=True, path_name=None):\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>web_context()</code> \u00b6 <p>returns the build index ( toolbox web component )</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def web_context(self) -&gt; str:\n    \"\"\"returns the build index ( toolbox web component )\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.types.Headers","title":"<code>Headers</code>  <code>dataclass</code>","text":"<p>Class representing HTTP headers with strongly typed common fields.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@dataclass\nclass Headers:\n    \"\"\"Class representing HTTP headers with strongly typed common fields.\"\"\"\n    # General Headers\n    accept: None | str= None\n    accept_charset: None | str= None\n    accept_encoding: None | str= None\n    accept_language: None | str= None\n    accept_ranges: None | str= None\n    access_control_allow_credentials: None | str= None\n    access_control_allow_headers: None | str= None\n    access_control_allow_methods: None | str= None\n    access_control_allow_origin: None | str= None\n    access_control_expose_headers: None | str= None\n    access_control_max_age: None | str= None\n    access_control_request_headers: None | str= None\n    access_control_request_method: None | str= None\n    age: None | str= None\n    allow: None | str= None\n    alt_svc: None | str= None\n    authorization: None | str= None\n    cache_control: None | str= None\n    clear_site_data: None | str= None\n    connection: None | str= None\n    content_disposition: None | str= None\n    content_encoding: None | str= None\n    content_language: None | str= None\n    content_length: None | str= None\n    content_location: None | str= None\n    content_range: None | str= None\n    content_security_policy: None | str= None\n    content_security_policy_report_only: None | str= None\n    content_type: None | str= None\n    cookie: None | str= None\n    cross_origin_embedder_policy: None | str= None\n    cross_origin_opener_policy: None | str= None\n    cross_origin_resource_policy: None | str= None\n    date: None | str= None\n    device_memory: None | str= None\n    digest: None | str= None\n    dnt: None | str= None\n    dpr: None | str= None\n    etag: None | str= None\n    expect: None | str= None\n    expires: None | str= None\n    feature_policy: None | str= None\n    forwarded: None | str= None\n    from_header: None | str= None  # 'from' is a Python keyword\n    host: None | str= None\n    if_match: None | str= None\n    if_modified_since: None | str= None\n    if_none_match: None | str= None\n    if_range: None | str= None\n    if_unmodified_since: None | str= None\n    keep_alive: None | str= None\n    large_allocation: None | str= None\n    last_modified: None | str= None\n    link: None | str= None\n    location: None | str= None\n    max_forwards: None | str= None\n    origin: None | str= None\n    pragma: None | str= None\n    proxy_authenticate: None | str= None\n    proxy_authorization: None | str= None\n    public_key_pins: None | str= None\n    public_key_pins_report_only: None | str= None\n    range: None | str= None\n    referer: None | str= None\n    referrer_policy: None | str= None\n    retry_after: None | str= None\n    save_data: None | str= None\n    sec_fetch_dest: None | str= None\n    sec_fetch_mode: None | str= None\n    sec_fetch_site: None | str= None\n    sec_fetch_user: None | str= None\n    sec_websocket_accept: None | str= None\n    sec_websocket_extensions: None | str= None\n    sec_websocket_key: None | str= None\n    sec_websocket_protocol: None | str= None\n    sec_websocket_version: None | str= None\n    server: None | str= None\n    server_timing: None | str= None\n    service_worker_allowed: None | str= None\n    set_cookie: None | str= None\n    sourcemap: None | str= None\n    strict_transport_security: None | str= None\n    te: None | str= None\n    timing_allow_origin: None | str= None\n    tk: None | str= None\n    trailer: None | str= None\n    transfer_encoding: None | str= None\n    upgrade: None | str= None\n    upgrade_insecure_requests: None | str= None\n    user_agent: None | str= None\n    vary: None | str= None\n    via: None | str= None\n    warning: None | str= None\n    www_authenticate: None | str= None\n    x_content_type_options: None | str= None\n    x_dns_prefetch_control: None | str= None\n    x_forwarded_for: None | str= None\n    x_forwarded_host: None | str= None\n    x_forwarded_proto: None | str= None\n    x_frame_options: None | str= None\n    x_xss_protection: None | str= None\n\n    # Browser-specific and custom headers\n    sec_ch_ua: None | str= None\n    sec_ch_ua_mobile: None | str= None\n    sec_ch_ua_platform: None | str= None\n    sec_ch_ua_arch: None | str= None\n    sec_ch_ua_bitness: None | str= None\n    sec_ch_ua_full_version: None | str= None\n    sec_ch_ua_full_version_list: None | str= None\n    sec_ch_ua_platform_version: None | str= None\n\n    # HTMX specific headers\n    hx_boosted: None | str= None\n    hx_current_url: None | str= None\n    hx_history_restore_request: None | str= None\n    hx_prompt: None | str= None\n    hx_request: None | str= None\n    hx_target: None | str= None\n    hx_trigger: None | str= None\n    hx_trigger_name: None | str= None\n\n    # Additional fields can be stored in extra_headers\n    extra_headers: dict[str, str] = field(default_factory=dict)\n\n    def __post_init__(self):\n        \"\"\"Convert header keys with hyphens to underscores for attribute access.\"\"\"\n        # Handle the 'from' header specifically since it's a Python keyword\n        if 'from' in self.__dict__:\n            self.from_header = self.__dict__.pop('from')\n\n        # Store any attributes that weren't explicitly defined in extra_headers\n        all_attrs = self.__annotations__.keys()\n        for key in list(self.__dict__.keys()):\n            if key not in all_attrs and key != \"extra_headers\":\n                self.extra_headers[key.replace(\"_\", \"-\")] = getattr(self, key)\n                delattr(self, key)\n\n    @classmethod\n    def from_dict(cls, headers_dict: dict[str, str]) -&gt; 'Headers':\n        \"\"\"Create a Headers instance from a dictionary.\"\"\"\n        # Convert header keys from hyphenated to underscore format for Python attributes\n        processed_headers = {}\n        extra_headers = {}\n\n        for key, value in headers_dict.items():\n            # Handle 'from' header specifically\n            if key.lower() == 'from':\n                processed_headers['from_header'] = value\n                continue\n\n            python_key = key.replace(\"-\", \"_\").lower()\n            if python_key in cls.__annotations__ and python_key != \"extra_headers\":\n                processed_headers[python_key] = value\n            else:\n                extra_headers[key] = value\n\n        return cls(**processed_headers, extra_headers=extra_headers)\n\n    def to_dict(self) -&gt; dict[str, str]:\n        \"\"\"Convert the Headers object back to a dictionary.\"\"\"\n        result = {}\n\n        # Add regular attributes\n        for key, value in self.__dict__.items():\n            if key != \"extra_headers\" and value is not None:\n                # Handle from_header specially\n                if key == \"from_header\":\n                    result[\"from\"] = value\n                else:\n                    result[key.replace(\"_\", \"-\")] = value\n\n        # Add extra headers\n        result.update(self.extra_headers)\n\n        return result\n</code></pre> <code>__post_init__()</code> \u00b6 <p>Convert header keys with hyphens to underscores for attribute access.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def __post_init__(self):\n    \"\"\"Convert header keys with hyphens to underscores for attribute access.\"\"\"\n    # Handle the 'from' header specifically since it's a Python keyword\n    if 'from' in self.__dict__:\n        self.from_header = self.__dict__.pop('from')\n\n    # Store any attributes that weren't explicitly defined in extra_headers\n    all_attrs = self.__annotations__.keys()\n    for key in list(self.__dict__.keys()):\n        if key not in all_attrs and key != \"extra_headers\":\n            self.extra_headers[key.replace(\"_\", \"-\")] = getattr(self, key)\n            delattr(self, key)\n</code></pre> <code>from_dict(headers_dict)</code> <code>classmethod</code> \u00b6 <p>Create a Headers instance from a dictionary.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@classmethod\ndef from_dict(cls, headers_dict: dict[str, str]) -&gt; 'Headers':\n    \"\"\"Create a Headers instance from a dictionary.\"\"\"\n    # Convert header keys from hyphenated to underscore format for Python attributes\n    processed_headers = {}\n    extra_headers = {}\n\n    for key, value in headers_dict.items():\n        # Handle 'from' header specifically\n        if key.lower() == 'from':\n            processed_headers['from_header'] = value\n            continue\n\n        python_key = key.replace(\"-\", \"_\").lower()\n        if python_key in cls.__annotations__ and python_key != \"extra_headers\":\n            processed_headers[python_key] = value\n        else:\n            extra_headers[key] = value\n\n    return cls(**processed_headers, extra_headers=extra_headers)\n</code></pre> <code>to_dict()</code> \u00b6 <p>Convert the Headers object back to a dictionary.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def to_dict(self) -&gt; dict[str, str]:\n    \"\"\"Convert the Headers object back to a dictionary.\"\"\"\n    result = {}\n\n    # Add regular attributes\n    for key, value in self.__dict__.items():\n        if key != \"extra_headers\" and value is not None:\n            # Handle from_header specially\n            if key == \"from_header\":\n                result[\"from\"] = value\n            else:\n                result[key.replace(\"_\", \"-\")] = value\n\n    # Add extra headers\n    result.update(self.extra_headers)\n\n    return result\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.types.MainToolType","title":"<code>MainToolType</code>","text":"Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>class MainToolType:\n    toolID: str\n    app: A\n    interface: ToolBoxInterfaces\n    spec: str\n\n    version: str\n    tools: dict  # legacy\n    name: str\n    logger: logging\n    color: str\n    todo: Callable\n    _on_exit: Callable\n    stuf: bool\n    config: dict\n    user: U | None\n    description: str\n\n    @staticmethod\n    def return_result(error: ToolBoxError = ToolBoxError.none,\n                      exec_code: int = 0,\n                      help_text: str = \"\",\n                      data_info=None,\n                      data=None,\n                      data_to=None) -&gt; Result:\n        \"\"\"proxi attr\"\"\"\n\n    def load(self):\n        \"\"\"proxi attr\"\"\"\n\n    def print(self, message, end=\"\\n\", **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    def add_str_to_config(self, command):\n        if len(command) != 2:\n            self.logger.error('Invalid command must be key value')\n            return False\n        self.config[command[0]] = command[1]\n\n    def webInstall(self, user_instance, construct_render) -&gt; str:\n        \"\"\"\"Returns a web installer for the given user instance and construct render template\"\"\"\n\n    async def get_user(self, username: str) -&gt; Result:\n        return self.app.a_run_any(CLOUDM_AUTHMANAGER.GET_USER_BY_NAME, username=username, get_results=True)\n</code></pre> <code>load()</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def load(self):\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>print(message, end='\\n', **kwargs)</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def print(self, message, end=\"\\n\", **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>return_result(error=ToolBoxError.none, exec_code=0, help_text='', data_info=None, data=None, data_to=None)</code> <code>staticmethod</code> \u00b6 <p>proxi attr</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@staticmethod\ndef return_result(error: ToolBoxError = ToolBoxError.none,\n                  exec_code: int = 0,\n                  help_text: str = \"\",\n                  data_info=None,\n                  data=None,\n                  data_to=None) -&gt; Result:\n    \"\"\"proxi attr\"\"\"\n</code></pre> <code>webInstall(user_instance, construct_render)</code> \u00b6 <p>\"Returns a web installer for the given user instance and construct render template</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def webInstall(self, user_instance, construct_render) -&gt; str:\n    \"\"\"\"Returns a web installer for the given user instance and construct render template\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.types.Request","title":"<code>Request</code>  <code>dataclass</code>","text":"<p>Class representing an HTTP request.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@dataclass\nclass Request:\n    \"\"\"Class representing an HTTP request.\"\"\"\n    content_type: str\n    headers: Headers\n    method: str\n    path: str\n    query_params: dict[str, Any] = field(default_factory=dict)\n    form_data: dict[str, Any] | None = None\n    body: Any | None = None\n\n    @classmethod\n    def from_dict(cls, data: dict[str, Any]) -&gt; 'Request':\n        \"\"\"Create a Request instance from a dictionary.\"\"\"\n        headers = Headers.from_dict(data.get('headers', {}))\n\n        # Extract other fields\n        return cls(\n            content_type=data.get('content_type', ''),\n            headers=headers,\n            method=data.get('method', ''),\n            path=data.get('path', ''),\n            query_params=data.get('query_params', {}),\n            form_data=data.get('form_data'),\n            body=data.get('body')\n        )\n\n    def to_dict(self) -&gt; dict[str, Any]:\n        \"\"\"Convert the Request object back to a dictionary.\"\"\"\n        result = {\n            'content_type': self.content_type,\n            'headers': self.headers.to_dict(),\n            'method': self.method,\n            'path': self.path,\n            'query_params': self.query_params,\n        }\n\n        if self.form_data is not None:\n            result['form_data'] = self.form_data\n\n        if self.body is not None:\n            result['body'] = self.body\n\n        return result\n</code></pre> <code>from_dict(data)</code> <code>classmethod</code> \u00b6 <p>Create a Request instance from a dictionary.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: dict[str, Any]) -&gt; 'Request':\n    \"\"\"Create a Request instance from a dictionary.\"\"\"\n    headers = Headers.from_dict(data.get('headers', {}))\n\n    # Extract other fields\n    return cls(\n        content_type=data.get('content_type', ''),\n        headers=headers,\n        method=data.get('method', ''),\n        path=data.get('path', ''),\n        query_params=data.get('query_params', {}),\n        form_data=data.get('form_data'),\n        body=data.get('body')\n    )\n</code></pre> <code>to_dict()</code> \u00b6 <p>Convert the Request object back to a dictionary.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Convert the Request object back to a dictionary.\"\"\"\n    result = {\n        'content_type': self.content_type,\n        'headers': self.headers.to_dict(),\n        'method': self.method,\n        'path': self.path,\n        'query_params': self.query_params,\n    }\n\n    if self.form_data is not None:\n        result['form_data'] = self.form_data\n\n    if self.body is not None:\n        result['body'] = self.body\n\n    return result\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.types.RequestData","title":"<code>RequestData</code>  <code>dataclass</code>","text":"<p>Main class representing the complete request data structure.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@dataclass\nclass RequestData:\n    \"\"\"Main class representing the complete request data structure.\"\"\"\n    request: Request\n    session: Session\n    session_id: str\n\n    @classmethod\n    def from_dict(cls, data: dict[str, Any]) -&gt; 'RequestData':\n        \"\"\"Create a RequestData instance from a dictionary.\"\"\"\n        return cls(\n            request=Request.from_dict(data.get('request', {})),\n            session=Session.from_dict(data.get('session', {})),\n            session_id=data.get('session_id', '')\n        )\n\n    def to_dict(self) -&gt; dict[str, Any]:\n        \"\"\"Convert the RequestData object back to a dictionary.\"\"\"\n        return {\n            'request': self.request.to_dict(),\n            'session': self.session.to_dict(),\n            'session_id': self.session_id\n        }\n\n    def __getattr__(self, name: str) -&gt; Any:\n        \"\"\"Delegate unknown attributes to the `request` object.\"\"\"\n        # Nur wenn das Attribut nicht direkt in RequestData existiert\n        # und auch nicht `session` oder `session_id` ist\n        if hasattr(self.request, name):\n            return getattr(self.request, name)\n        raise AttributeError(f\"'RequestData' object has no attribute '{name}'\")\n\n    @classmethod\n    def moc(cls):\n        return cls(\n            request=Request.from_dict({\n                'content_type': 'application/x-www-form-urlencoded',\n                'headers': {\n                    'accept': '*/*',\n                    'accept-encoding': 'gzip, deflate, br, zstd',\n                    'accept-language': 'de-DE,de;q=0.9,en-US;q=0.8,en;q=0.7',\n                    'connection': 'keep-alive',\n                    'content-length': '107',\n                    'content-type': 'application/x-www-form-urlencoded',\n                    'cookie': 'session=abc123',\n                    'host': 'localhost:8080',\n                    'hx-current-url': 'http://localhost:8080/api/TruthSeeker/get_main_ui',\n                    'hx-request': 'true',\n                    'hx-target': 'estimates-guest_1fc2c9',\n                    'hx-trigger': 'config-form-guest_1fc2c9',\n                    'origin': 'http://localhost:8080',\n                    'referer': 'http://localhost:8080/api/TruthSeeker/get_main_ui',\n                    'sec-ch-ua': '\"Chromium\";v=\"134\", \"Not:A-Brand\";v=\"24\", \"Google Chrome\";v=\"134\"',\n                    'sec-ch-ua-mobile': '?0',\n                    'sec-ch-ua-platform': '\"Windows\"',\n                    'sec-fetch-dest': 'empty',\n                    'sec-fetch-mode': 'cors',\n                    'sec-fetch-site': 'same-origin',\n                    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n                },\n                'method': 'POST',\n                'path': '/api/TruthSeeker/update_estimates',\n                'query_params': {},\n                'form_data': {\n                    'param1': 'value1',\n                    'param2': 'value2'\n                }\n            }),\n            session=Session.from_dict({\n                'SiID': '29a2e258e18252e2afd5ff943523f09c82f1bb9adfe382a6f33fc6a8381de898',\n                'level': '1',\n                'spec': '74eed1c8de06886842e235486c3c2fd6bcd60586998ac5beb87f13c0d1750e1d',\n                'user_name': 'root',\n                'custom_field': 'custom_value'\n            }),\n            session_id='0x29dd1ac0d1e30d3f'\n        )\n</code></pre> <code>__getattr__(name)</code> \u00b6 <p>Delegate unknown attributes to the <code>request</code> object.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def __getattr__(self, name: str) -&gt; Any:\n    \"\"\"Delegate unknown attributes to the `request` object.\"\"\"\n    # Nur wenn das Attribut nicht direkt in RequestData existiert\n    # und auch nicht `session` oder `session_id` ist\n    if hasattr(self.request, name):\n        return getattr(self.request, name)\n    raise AttributeError(f\"'RequestData' object has no attribute '{name}'\")\n</code></pre> <code>from_dict(data)</code> <code>classmethod</code> \u00b6 <p>Create a RequestData instance from a dictionary.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: dict[str, Any]) -&gt; 'RequestData':\n    \"\"\"Create a RequestData instance from a dictionary.\"\"\"\n    return cls(\n        request=Request.from_dict(data.get('request', {})),\n        session=Session.from_dict(data.get('session', {})),\n        session_id=data.get('session_id', '')\n    )\n</code></pre> <code>to_dict()</code> \u00b6 <p>Convert the RequestData object back to a dictionary.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Convert the RequestData object back to a dictionary.\"\"\"\n    return {\n        'request': self.request.to_dict(),\n        'session': self.session.to_dict(),\n        'session_id': self.session_id\n    }\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.types.Result","title":"<code>Result</code>","text":"Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>class Result:\n    _task = None\n    def __init__(self,\n                 error: ToolBoxError,\n                 result: ToolBoxResult,\n                 info: ToolBoxInfo,\n                 origin: Any | None = None,\n                 ):\n        self.error: ToolBoxError = error\n        self.result: ToolBoxResult = result\n        self.info: ToolBoxInfo = info\n        self.origin = origin\n\n    def as_result(self):\n        return self\n\n    def as_dict(self):\n        return {\n            \"error\":self.error.value if isinstance(self.error, Enum) else self.error,\n        \"result\" : {\n            \"data_to\":self.result.data_to.value if isinstance(self.result.data_to, Enum) else self.result.data_to,\n            \"data_info\":self.result.data_info,\n            \"data\":self.result.data,\n            \"data_type\":self.result.data_type\n        } if self.result else None,\n        \"info\" : {\n            \"exec_code\" : self.info.exec_code,  # exec_code umwandel in http resposn codes\n        \"help_text\" : self.info.help_text\n        } if self.info else None,\n        \"origin\" : self.origin\n        }\n\n    def set_origin(self, origin):\n        if self.origin is not None:\n            raise ValueError(\"You cannot Change the origin of a Result!\")\n        self.origin = origin\n        return self\n\n    def set_dir_origin(self, name, extras=\"assets/\"):\n        if self.origin is not None:\n            raise ValueError(\"You cannot Change the origin of a Result!\")\n        self.origin = f\"mods/{name}/{extras}\"\n        return self\n\n    def is_error(self):\n        if _test_is_result(self.result.data):\n            return self.result.data.is_error()\n        if self.error == ToolBoxError.none:\n            return False\n        if self.info.exec_code == 0:\n            return False\n        return self.info.exec_code != 200\n\n    def is_ok(self):\n        return not self.is_error()\n\n    def is_data(self):\n        return self.result.data is not None\n\n    def to_api_result(self):\n        # print(f\" error={self.error}, result= {self.result}, info= {self.info}, origin= {self.origin}\")\n        return ApiResult(\n            error=self.error.value if isinstance(self.error, Enum) else self.error,\n            result=ToolBoxResultBM(\n                data_to=self.result.data_to.value if isinstance(self.result.data_to, Enum) else self.result.data_to,\n                data_info=self.result.data_info,\n                data=self.result.data,\n                data_type=self.result.data_type\n            ) if self.result else None,\n            info=ToolBoxInfoBM(\n                exec_code=self.info.exec_code,  # exec_code umwandel in http resposn codes\n                help_text=self.info.help_text\n            ) if self.info else None,\n            origin=self.origin\n        )\n\n    def task(self, task):\n        self._task = task\n        return self\n\n    @staticmethod\n    def result_from_dict(error: str, result: dict, info: dict, origin: list or None or str):\n        # print(f\" error={self.error}, result= {self.result}, info= {self.info}, origin= {self.origin}\")\n        return ApiResult(\n            error=error if isinstance(error, Enum) else error,\n            result=ToolBoxResultBM(\n                data_to=result.get('data_to') if isinstance(result.get('data_to'), Enum) else result.get('data_to'),\n                data_info=result.get('data_info', '404'),\n                data=result.get('data'),\n                data_type=result.get('data_type', '404'),\n            ) if result else ToolBoxResultBM(\n                data_to=ToolBoxInterfaces.cli.value,\n                data_info='',\n                data='404',\n                data_type='404',\n            ),\n            info=ToolBoxInfoBM(\n                exec_code=info.get('exec_code', 404),\n                help_text=info.get('help_text', '404')\n            ) if info else ToolBoxInfoBM(\n                exec_code=404,\n                help_text='404'\n            ),\n            origin=origin\n        ).as_result()\n\n    @classmethod\n    def stream(cls,\n               stream_generator: Any,  # Renamed from source for clarity\n               content_type: str = \"text/event-stream\",  # Default to SSE\n               headers: dict | None = None,\n               info: str = \"OK\",\n               interface: ToolBoxInterfaces = ToolBoxInterfaces.remote,\n               cleanup_func: Callable[[], None] | Callable[[], T] | Callable[[], AsyncGenerator[T, None]] | None = None):\n        \"\"\"\n        Create a streaming response Result. Handles SSE and other stream types.\n\n        Args:\n            stream_generator: Any stream source (async generator, sync generator, iterable, or single item).\n            content_type: Content-Type header (default: text/event-stream for SSE).\n            headers: Additional HTTP headers for the response.\n            info: Help text for the result.\n            interface: Interface to send data to.\n            cleanup_func: Optional function for cleanup.\n\n        Returns:\n            A Result object configured for streaming.\n        \"\"\"\n        error = ToolBoxError.none\n        info_obj = ToolBoxInfo(exec_code=0, help_text=info)\n\n        final_generator: AsyncGenerator[str, None]\n\n        if content_type == \"text/event-stream\":\n            # For SSE, always use SSEGenerator.create_sse_stream to wrap the source.\n            # SSEGenerator.create_sse_stream handles various types of stream_generator internally.\n            final_generator = SSEGenerator.create_sse_stream(source=stream_generator, cleanup_func=cleanup_func)\n\n            # Standard SSE headers for the HTTP response itself\n            # These will be stored in the Result object. Rust side decides how to use them.\n            standard_sse_headers = {\n                \"Cache-Control\": \"no-cache\",  # SSE specific\n                \"Connection\": \"keep-alive\",  # SSE specific\n                \"X-Accel-Buffering\": \"no\",  # Useful for proxies with SSE\n                # Content-Type is implicitly text/event-stream, will be in streaming_data below\n            }\n            all_response_headers = standard_sse_headers.copy()\n            if headers:\n                all_response_headers.update(headers)\n        else:\n            # For non-SSE streams.\n            # If stream_generator is sync, wrap it to be async.\n            # If already async or single item, it will be handled.\n            # Rust's stream_generator in ToolboxClient seems to handle both sync/async Python generators.\n            # For consistency with how SSEGenerator does it, we can wrap sync ones.\n            if inspect.isgenerator(stream_generator) or \\\n                (not isinstance(stream_generator, str) and hasattr(stream_generator, '__iter__')):\n                final_generator = SSEGenerator.wrap_sync_generator(stream_generator)  # Simple async wrapper\n            elif inspect.isasyncgen(stream_generator):\n                final_generator = stream_generator\n            else:  # Single item or string\n                async def _single_item_gen():\n                    yield stream_generator\n\n                final_generator = _single_item_gen()\n            all_response_headers = headers if headers else {}\n\n        # Prepare streaming data to be stored in the Result object\n        streaming_data = {\n            \"type\": \"stream\",  # Indicator for Rust side\n            \"generator\": final_generator,\n            \"content_type\": content_type,  # Let Rust know the intended content type\n            \"headers\": all_response_headers  # Intended HTTP headers for the overall response\n        }\n\n        result_payload = ToolBoxResult(\n            data_to=interface,\n            data=streaming_data,\n            data_info=\"Streaming response\" if content_type != \"text/event-stream\" else \"SSE Event Stream\",\n            data_type=\"stream\"  # Generic type for Rust to identify it needs to stream from 'generator'\n        )\n\n        return cls(error=error, info=info_obj, result=result_payload)\n\n    @classmethod\n    def sse(cls,\n            stream_generator: Any,\n            info: str = \"OK\",\n            interface: ToolBoxInterfaces = ToolBoxInterfaces.remote,\n            cleanup_func: Callable[[], None] | Callable[[], T] | Callable[[], AsyncGenerator[T, None]] | None = None,\n            # http_headers: Optional[dict] = None # If we want to allow overriding default SSE HTTP headers\n            ):\n        \"\"\"\n        Create an Server-Sent Events (SSE) streaming response Result.\n\n        Args:\n            stream_generator: A source yielding individual data items. This can be an\n                              async generator, sync generator, iterable, or a single item.\n                              Each item will be formatted as an SSE event.\n            info: Optional help text for the Result.\n            interface: Optional ToolBoxInterface to target.\n            cleanup_func: Optional cleanup function to run when the stream ends or is cancelled.\n            #http_headers: Optional dictionary of custom HTTP headers for the SSE response.\n\n        Returns:\n            A Result object configured for SSE streaming.\n        \"\"\"\n        # Result.stream will handle calling SSEGenerator.create_sse_stream\n        # and setting appropriate default headers for SSE when content_type is \"text/event-stream\".\n        return cls.stream(\n            stream_generator=stream_generator,\n            content_type=\"text/event-stream\",\n            # headers=http_headers, # Pass if we add http_headers param\n            info=info,\n            interface=interface,\n            cleanup_func=cleanup_func\n        )\n\n    @classmethod\n    def default(cls, interface=ToolBoxInterfaces.native):\n        error = ToolBoxError.none\n        info = ToolBoxInfo(exec_code=-1, help_text=\"\")\n        result = ToolBoxResult(data_to=interface)\n        return cls(error=error, info=info, result=result)\n\n    @classmethod\n    def json(cls, data, info=\"OK\", interface=ToolBoxInterfaces.remote, exec_code=0, status_code=None):\n        \"\"\"Create a JSON response Result.\"\"\"\n        error = ToolBoxError.none\n        info_obj = ToolBoxInfo(exec_code=status_code or exec_code, help_text=info)\n\n        result = ToolBoxResult(\n            data_to=interface,\n            data=data,\n            data_info=\"JSON response\",\n            data_type=\"json\"\n        )\n\n        return cls(error=error, info=info_obj, result=result)\n\n    @classmethod\n    def text(cls, text_data, content_type=\"text/plain\",exec_code=None,status=200, info=\"OK\", interface=ToolBoxInterfaces.remote, headers=None):\n        \"\"\"Create a text response Result with specific content type.\"\"\"\n        if headers is not None:\n            return cls.html(text_data, status= exec_code or status, info=info, headers=headers)\n        error = ToolBoxError.none\n        info_obj = ToolBoxInfo(exec_code=exec_code or status, help_text=info)\n\n        result = ToolBoxResult(\n            data_to=interface,\n            data=text_data,\n            data_info=\"Text response\",\n            data_type=content_type\n        )\n\n        return cls(error=error, info=info_obj, result=result)\n\n    @classmethod\n    def binary(cls, data, content_type=\"application/octet-stream\", download_name=None, info=\"OK\",\n               interface=ToolBoxInterfaces.remote):\n        \"\"\"Create a binary data response Result.\"\"\"\n        error = ToolBoxError.none\n        info_obj = ToolBoxInfo(exec_code=0, help_text=info)\n\n        # Create a dictionary with binary data and metadata\n        binary_data = {\n            \"data\": data,\n            \"content_type\": content_type,\n            \"filename\": download_name\n        }\n\n        result = ToolBoxResult(\n            data_to=interface,\n            data=binary_data,\n            data_info=f\"Binary response: {download_name}\" if download_name else \"Binary response\",\n            data_type=\"binary\"\n        )\n\n        return cls(error=error, info=info_obj, result=result)\n\n    @classmethod\n    def file(cls, data, filename, content_type=None, info=\"OK\", interface=ToolBoxInterfaces.remote):\n        \"\"\"Create a file download response Result.\n\n        Args:\n            data: File data as bytes or base64 string\n            filename: Name of the file for download\n            content_type: MIME type of the file (auto-detected if None)\n            info: Response info text\n            interface: Target interface\n\n        Returns:\n            Result object configured for file download\n        \"\"\"\n        import base64\n        import mimetypes\n\n        error = ToolBoxError.none\n        info_obj = ToolBoxInfo(exec_code=200, help_text=info)\n\n        # Auto-detect content type if not provided\n        if content_type is None:\n            content_type, _ = mimetypes.guess_type(filename)\n            if content_type is None:\n                content_type = \"application/octet-stream\"\n\n        # Ensure data is base64 encoded string (as expected by Rust server)\n        if isinstance(data, bytes):\n            base64_data = base64.b64encode(data).decode('utf-8')\n        elif isinstance(data, str):\n            # Assume it's already base64 encoded\n            base64_data = data\n        else:\n            raise ValueError(\"File data must be bytes or base64 string\")\n\n        result = ToolBoxResult(\n            data_to=interface,\n            data=base64_data,  # Rust expects base64 string for \"file\" type\n            data_info=f\"File download: {filename}\",\n            data_type=\"file\"\n        )\n\n        return cls(error=error, info=info_obj, result=result)\n\n    @classmethod\n    def redirect(cls, url, status_code=302, info=\"Redirect\", interface=ToolBoxInterfaces.remote):\n        \"\"\"Create a redirect response.\"\"\"\n        error = ToolBoxError.none\n        info_obj = ToolBoxInfo(exec_code=status_code, help_text=info)\n\n        result = ToolBoxResult(\n            data_to=interface,\n            data=url,\n            data_info=\"Redirect response\",\n            data_type=\"redirect\"\n        )\n\n        return cls(error=error, info=info_obj, result=result)\n\n    @classmethod\n    def ok(cls, data=None, data_info=\"\", info=\"OK\", interface=ToolBoxInterfaces.native):\n        error = ToolBoxError.none\n        info = ToolBoxInfo(exec_code=0, help_text=info)\n        result = ToolBoxResult(data_to=interface, data=data, data_info=data_info, data_type=type(data).__name__)\n        return cls(error=error, info=info, result=result)\n\n    @classmethod\n    def html(cls, data=None, data_info=\"\", info=\"OK\", interface=ToolBoxInterfaces.remote, data_type=\"html\",status=200, headers=None, row=False):\n        error = ToolBoxError.none\n        info = ToolBoxInfo(exec_code=status, help_text=info)\n        from ...utils.system.getting_and_closing_app import get_app\n\n        if not row and not '\"&lt;div class=\"main-content\"\"' in data:\n            data = f'&lt;div class=\"main-content frosted-glass\"&gt;{data}&lt;div&gt;'\n        if not row and not get_app().web_context() in data:\n            data = get_app().web_context() + data\n\n        if isinstance(headers, dict):\n            result = ToolBoxResult(data_to=interface, data={'html':data,'headers':headers}, data_info=data_info,\n                                   data_type=\"special_html\")\n        else:\n            result = ToolBoxResult(data_to=interface, data=data, data_info=data_info,\n                                   data_type=data_type if data_type is not None else type(data).__name__)\n        return cls(error=error, info=info, result=result)\n\n    @classmethod\n    def future(cls, data=None, data_info=\"\", info=\"OK\", interface=ToolBoxInterfaces.future):\n        error = ToolBoxError.none\n        info = ToolBoxInfo(exec_code=0, help_text=info)\n        result = ToolBoxResult(data_to=interface, data=data, data_info=data_info, data_type=\"future\")\n        return cls(error=error, info=info, result=result)\n\n    @classmethod\n    def custom_error(cls, data=None, data_info=\"\", info=\"\", exec_code=-1, interface=ToolBoxInterfaces.native):\n        error = ToolBoxError.custom_error\n        info = ToolBoxInfo(exec_code=exec_code, help_text=info)\n        result = ToolBoxResult(data_to=interface, data=data, data_info=data_info, data_type=type(data).__name__)\n        return cls(error=error, info=info, result=result)\n\n    @classmethod\n    def error(cls, data=None, data_info=\"\", info=\"\", exec_code=450, interface=ToolBoxInterfaces.remote):\n        error = ToolBoxError.custom_error\n        info = ToolBoxInfo(exec_code=exec_code, help_text=info)\n        result = ToolBoxResult(data_to=interface, data=data, data_info=data_info, data_type=type(data).__name__)\n        return cls(error=error, info=info, result=result)\n\n    @classmethod\n    def default_user_error(cls, info=\"\", exec_code=-3, interface=ToolBoxInterfaces.native, data=None):\n        error = ToolBoxError.input_error\n        info = ToolBoxInfo(exec_code, info)\n        result = ToolBoxResult(data_to=interface, data=data, data_type=type(data).__name__)\n        return cls(error=error, info=info, result=result)\n\n    @classmethod\n    def default_internal_error(cls, info=\"\", exec_code=-2, interface=ToolBoxInterfaces.native, data=None):\n        error = ToolBoxError.internal_error\n        info = ToolBoxInfo(exec_code, info)\n        result = ToolBoxResult(data_to=interface, data=data, data_type=type(data).__name__)\n        return cls(error=error, info=info, result=result)\n\n    def print(self, show=True, show_data=True, prifix=\"\"):\n        data = '\\n' + f\"{((prifix + f'Data_{self.result.data_type}: ' + str(self.result.data) if self.result.data is not None else 'NO Data') if not isinstance(self.result.data, Result) else self.result.data.print(show=False, show_data=show_data, prifix=prifix + '-')) if show_data else 'Data: private'}\"\n        origin = '\\n' + f\"{prifix + 'Origin: ' + str(self.origin) if self.origin is not None else 'NO Origin'}\"\n        text = (f\"Function Exec code: {self.info.exec_code}\"\n                f\"\\n{prifix}Info's:\"\n                f\" {self.info.help_text} {'&lt;|&gt; ' + str(self.result.data_info) if self.result.data_info is not None else ''}\"\n                f\"{origin}{(data[:100]+'...') if not data.endswith('NO Data') else ''}\\n\")\n        if not show:\n            return text\n        print(\"\\n======== Result ========\\n\" + text + \"------- EndOfD -------\")\n        return self\n\n    def log(self, show_data=True, prifix=\"\"):\n        from toolboxv2 import get_logger\n        get_logger().debug(self.print(show=False, show_data=show_data, prifix=prifix).replace(\"\\n\", \" - \"))\n        return self\n\n    def __str__(self):\n        return self.print(show=False, show_data=True)\n\n    def get(self, key=None, default=None):\n        data = self.result.data\n        if isinstance(data, Result):\n            return data.get(key=key, default=default)\n        if key is not None and isinstance(data, dict):\n            return data.get(key, default)\n        return data if data is not None else default\n\n    async def aget(self, key=None, default=None):\n        if asyncio.isfuture(self.result.data) or asyncio.iscoroutine(self.result.data) or (\n            isinstance(self.result.data_to, Enum) and self.result.data_to.name == ToolBoxInterfaces.future.name):\n            data = await self.result.data\n        else:\n            data = self.get(key=None, default=None)\n        if isinstance(data, Result):\n            return data.get(key=key, default=default)\n        if key is not None and isinstance(data, dict):\n            return data.get(key, default)\n        return data if data is not None else default\n\n    def lazy_return(self, _=0, data=None, **kwargs):\n        flags = ['raise', 'logg', 'user', 'intern']\n        flag = flags[_] if isinstance(_, int) else _\n        if self.info.exec_code == 0:\n            return self if data is None else data if _test_is_result(data) else self.ok(data=data, **kwargs)\n        if flag == 'raise':\n            raise ValueError(self.print(show=False))\n        if flag == 'logg':\n            from .. import get_logger\n            get_logger().error(self.print(show=False))\n\n        if flag == 'user':\n            return self if data is None else data if _test_is_result(data) else self.default_user_error(data=data,\n                                                                                                        **kwargs)\n        if flag == 'intern':\n            return self if data is None else data if _test_is_result(data) else self.default_internal_error(data=data,\n                                                                                                            **kwargs)\n\n        return self if data is None else data if _test_is_result(data) else self.custom_error(data=data, **kwargs)\n\n    @property\n    def bg_task(self):\n        return self._task\n</code></pre> <code>binary(data, content_type='application/octet-stream', download_name=None, info='OK', interface=ToolBoxInterfaces.remote)</code> <code>classmethod</code> \u00b6 <p>Create a binary data response Result.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@classmethod\ndef binary(cls, data, content_type=\"application/octet-stream\", download_name=None, info=\"OK\",\n           interface=ToolBoxInterfaces.remote):\n    \"\"\"Create a binary data response Result.\"\"\"\n    error = ToolBoxError.none\n    info_obj = ToolBoxInfo(exec_code=0, help_text=info)\n\n    # Create a dictionary with binary data and metadata\n    binary_data = {\n        \"data\": data,\n        \"content_type\": content_type,\n        \"filename\": download_name\n    }\n\n    result = ToolBoxResult(\n        data_to=interface,\n        data=binary_data,\n        data_info=f\"Binary response: {download_name}\" if download_name else \"Binary response\",\n        data_type=\"binary\"\n    )\n\n    return cls(error=error, info=info_obj, result=result)\n</code></pre> <code>file(data, filename, content_type=None, info='OK', interface=ToolBoxInterfaces.remote)</code> <code>classmethod</code> \u00b6 <p>Create a file download response Result.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <p>File data as bytes or base64 string</p> required <code>filename</code> <p>Name of the file for download</p> required <code>content_type</code> <p>MIME type of the file (auto-detected if None)</p> <code>None</code> <code>info</code> <p>Response info text</p> <code>'OK'</code> <code>interface</code> <p>Target interface</p> <code>remote</code> <p>Returns:</p> Type Description <p>Result object configured for file download</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@classmethod\ndef file(cls, data, filename, content_type=None, info=\"OK\", interface=ToolBoxInterfaces.remote):\n    \"\"\"Create a file download response Result.\n\n    Args:\n        data: File data as bytes or base64 string\n        filename: Name of the file for download\n        content_type: MIME type of the file (auto-detected if None)\n        info: Response info text\n        interface: Target interface\n\n    Returns:\n        Result object configured for file download\n    \"\"\"\n    import base64\n    import mimetypes\n\n    error = ToolBoxError.none\n    info_obj = ToolBoxInfo(exec_code=200, help_text=info)\n\n    # Auto-detect content type if not provided\n    if content_type is None:\n        content_type, _ = mimetypes.guess_type(filename)\n        if content_type is None:\n            content_type = \"application/octet-stream\"\n\n    # Ensure data is base64 encoded string (as expected by Rust server)\n    if isinstance(data, bytes):\n        base64_data = base64.b64encode(data).decode('utf-8')\n    elif isinstance(data, str):\n        # Assume it's already base64 encoded\n        base64_data = data\n    else:\n        raise ValueError(\"File data must be bytes or base64 string\")\n\n    result = ToolBoxResult(\n        data_to=interface,\n        data=base64_data,  # Rust expects base64 string for \"file\" type\n        data_info=f\"File download: {filename}\",\n        data_type=\"file\"\n    )\n\n    return cls(error=error, info=info_obj, result=result)\n</code></pre> <code>json(data, info='OK', interface=ToolBoxInterfaces.remote, exec_code=0, status_code=None)</code> <code>classmethod</code> \u00b6 <p>Create a JSON response Result.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@classmethod\ndef json(cls, data, info=\"OK\", interface=ToolBoxInterfaces.remote, exec_code=0, status_code=None):\n    \"\"\"Create a JSON response Result.\"\"\"\n    error = ToolBoxError.none\n    info_obj = ToolBoxInfo(exec_code=status_code or exec_code, help_text=info)\n\n    result = ToolBoxResult(\n        data_to=interface,\n        data=data,\n        data_info=\"JSON response\",\n        data_type=\"json\"\n    )\n\n    return cls(error=error, info=info_obj, result=result)\n</code></pre> <code>redirect(url, status_code=302, info='Redirect', interface=ToolBoxInterfaces.remote)</code> <code>classmethod</code> \u00b6 <p>Create a redirect response.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@classmethod\ndef redirect(cls, url, status_code=302, info=\"Redirect\", interface=ToolBoxInterfaces.remote):\n    \"\"\"Create a redirect response.\"\"\"\n    error = ToolBoxError.none\n    info_obj = ToolBoxInfo(exec_code=status_code, help_text=info)\n\n    result = ToolBoxResult(\n        data_to=interface,\n        data=url,\n        data_info=\"Redirect response\",\n        data_type=\"redirect\"\n    )\n\n    return cls(error=error, info=info_obj, result=result)\n</code></pre> <code>sse(stream_generator, info='OK', interface=ToolBoxInterfaces.remote, cleanup_func=None)</code> <code>classmethod</code> \u00b6 <p>Create an Server-Sent Events (SSE) streaming response Result.</p> <p>Parameters:</p> Name Type Description Default <code>stream_generator</code> <code>Any</code> <p>A source yielding individual data items. This can be an               async generator, sync generator, iterable, or a single item.               Each item will be formatted as an SSE event.</p> required <code>info</code> <code>str</code> <p>Optional help text for the Result.</p> <code>'OK'</code> <code>interface</code> <code>ToolBoxInterfaces</code> <p>Optional ToolBoxInterface to target.</p> <code>remote</code> <code>cleanup_func</code> <code>Callable[[], None] | Callable[[], T] | Callable[[], AsyncGenerator[T, None]] | None</code> <p>Optional cleanup function to run when the stream ends or is cancelled.</p> <code>None</code> <code>#http_headers</code> <p>Optional dictionary of custom HTTP headers for the SSE response.</p> required <p>Returns:</p> Type Description <p>A Result object configured for SSE streaming.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@classmethod\ndef sse(cls,\n        stream_generator: Any,\n        info: str = \"OK\",\n        interface: ToolBoxInterfaces = ToolBoxInterfaces.remote,\n        cleanup_func: Callable[[], None] | Callable[[], T] | Callable[[], AsyncGenerator[T, None]] | None = None,\n        # http_headers: Optional[dict] = None # If we want to allow overriding default SSE HTTP headers\n        ):\n    \"\"\"\n    Create an Server-Sent Events (SSE) streaming response Result.\n\n    Args:\n        stream_generator: A source yielding individual data items. This can be an\n                          async generator, sync generator, iterable, or a single item.\n                          Each item will be formatted as an SSE event.\n        info: Optional help text for the Result.\n        interface: Optional ToolBoxInterface to target.\n        cleanup_func: Optional cleanup function to run when the stream ends or is cancelled.\n        #http_headers: Optional dictionary of custom HTTP headers for the SSE response.\n\n    Returns:\n        A Result object configured for SSE streaming.\n    \"\"\"\n    # Result.stream will handle calling SSEGenerator.create_sse_stream\n    # and setting appropriate default headers for SSE when content_type is \"text/event-stream\".\n    return cls.stream(\n        stream_generator=stream_generator,\n        content_type=\"text/event-stream\",\n        # headers=http_headers, # Pass if we add http_headers param\n        info=info,\n        interface=interface,\n        cleanup_func=cleanup_func\n    )\n</code></pre> <code>stream(stream_generator, content_type='text/event-stream', headers=None, info='OK', interface=ToolBoxInterfaces.remote, cleanup_func=None)</code> <code>classmethod</code> \u00b6 <p>Create a streaming response Result. Handles SSE and other stream types.</p> <p>Parameters:</p> Name Type Description Default <code>stream_generator</code> <code>Any</code> <p>Any stream source (async generator, sync generator, iterable, or single item).</p> required <code>content_type</code> <code>str</code> <p>Content-Type header (default: text/event-stream for SSE).</p> <code>'text/event-stream'</code> <code>headers</code> <code>dict | None</code> <p>Additional HTTP headers for the response.</p> <code>None</code> <code>info</code> <code>str</code> <p>Help text for the result.</p> <code>'OK'</code> <code>interface</code> <code>ToolBoxInterfaces</code> <p>Interface to send data to.</p> <code>remote</code> <code>cleanup_func</code> <code>Callable[[], None] | Callable[[], T] | Callable[[], AsyncGenerator[T, None]] | None</code> <p>Optional function for cleanup.</p> <code>None</code> <p>Returns:</p> Type Description <p>A Result object configured for streaming.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@classmethod\ndef stream(cls,\n           stream_generator: Any,  # Renamed from source for clarity\n           content_type: str = \"text/event-stream\",  # Default to SSE\n           headers: dict | None = None,\n           info: str = \"OK\",\n           interface: ToolBoxInterfaces = ToolBoxInterfaces.remote,\n           cleanup_func: Callable[[], None] | Callable[[], T] | Callable[[], AsyncGenerator[T, None]] | None = None):\n    \"\"\"\n    Create a streaming response Result. Handles SSE and other stream types.\n\n    Args:\n        stream_generator: Any stream source (async generator, sync generator, iterable, or single item).\n        content_type: Content-Type header (default: text/event-stream for SSE).\n        headers: Additional HTTP headers for the response.\n        info: Help text for the result.\n        interface: Interface to send data to.\n        cleanup_func: Optional function for cleanup.\n\n    Returns:\n        A Result object configured for streaming.\n    \"\"\"\n    error = ToolBoxError.none\n    info_obj = ToolBoxInfo(exec_code=0, help_text=info)\n\n    final_generator: AsyncGenerator[str, None]\n\n    if content_type == \"text/event-stream\":\n        # For SSE, always use SSEGenerator.create_sse_stream to wrap the source.\n        # SSEGenerator.create_sse_stream handles various types of stream_generator internally.\n        final_generator = SSEGenerator.create_sse_stream(source=stream_generator, cleanup_func=cleanup_func)\n\n        # Standard SSE headers for the HTTP response itself\n        # These will be stored in the Result object. Rust side decides how to use them.\n        standard_sse_headers = {\n            \"Cache-Control\": \"no-cache\",  # SSE specific\n            \"Connection\": \"keep-alive\",  # SSE specific\n            \"X-Accel-Buffering\": \"no\",  # Useful for proxies with SSE\n            # Content-Type is implicitly text/event-stream, will be in streaming_data below\n        }\n        all_response_headers = standard_sse_headers.copy()\n        if headers:\n            all_response_headers.update(headers)\n    else:\n        # For non-SSE streams.\n        # If stream_generator is sync, wrap it to be async.\n        # If already async or single item, it will be handled.\n        # Rust's stream_generator in ToolboxClient seems to handle both sync/async Python generators.\n        # For consistency with how SSEGenerator does it, we can wrap sync ones.\n        if inspect.isgenerator(stream_generator) or \\\n            (not isinstance(stream_generator, str) and hasattr(stream_generator, '__iter__')):\n            final_generator = SSEGenerator.wrap_sync_generator(stream_generator)  # Simple async wrapper\n        elif inspect.isasyncgen(stream_generator):\n            final_generator = stream_generator\n        else:  # Single item or string\n            async def _single_item_gen():\n                yield stream_generator\n\n            final_generator = _single_item_gen()\n        all_response_headers = headers if headers else {}\n\n    # Prepare streaming data to be stored in the Result object\n    streaming_data = {\n        \"type\": \"stream\",  # Indicator for Rust side\n        \"generator\": final_generator,\n        \"content_type\": content_type,  # Let Rust know the intended content type\n        \"headers\": all_response_headers  # Intended HTTP headers for the overall response\n    }\n\n    result_payload = ToolBoxResult(\n        data_to=interface,\n        data=streaming_data,\n        data_info=\"Streaming response\" if content_type != \"text/event-stream\" else \"SSE Event Stream\",\n        data_type=\"stream\"  # Generic type for Rust to identify it needs to stream from 'generator'\n    )\n\n    return cls(error=error, info=info_obj, result=result_payload)\n</code></pre> <code>text(text_data, content_type='text/plain', exec_code=None, status=200, info='OK', interface=ToolBoxInterfaces.remote, headers=None)</code> <code>classmethod</code> \u00b6 <p>Create a text response Result with specific content type.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@classmethod\ndef text(cls, text_data, content_type=\"text/plain\",exec_code=None,status=200, info=\"OK\", interface=ToolBoxInterfaces.remote, headers=None):\n    \"\"\"Create a text response Result with specific content type.\"\"\"\n    if headers is not None:\n        return cls.html(text_data, status= exec_code or status, info=info, headers=headers)\n    error = ToolBoxError.none\n    info_obj = ToolBoxInfo(exec_code=exec_code or status, help_text=info)\n\n    result = ToolBoxResult(\n        data_to=interface,\n        data=text_data,\n        data_info=\"Text response\",\n        data_type=content_type\n    )\n\n    return cls(error=error, info=info_obj, result=result)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.types.SSEGenerator","title":"<code>SSEGenerator</code>","text":"<p>Production-ready SSE generator that converts any data source to properly formatted Server-Sent Events compatible with browsers.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>class SSEGenerator:\n    \"\"\"\n    Production-ready SSE generator that converts any data source to\n    properly formatted Server-Sent Events compatible with browsers.\n    \"\"\"\n\n    @staticmethod\n    def format_sse_event(data: Any) -&gt; str:\n        \"\"\"Format any data as a proper SSE event message.\"\"\"\n        # Already formatted as SSE\n        if isinstance(data, str) and (data.startswith('data:') or data.startswith('event:')) and '\\n\\n' in data:\n            return data\n\n        # Handle bytes (binary data)\n        if isinstance(data, bytes):\n            try:\n                # Try to decode as UTF-8 first\n                decoded_data_str = data.decode('utf-8')\n                # If decoding works, treat it as a string for further processing\n                # This allows binary data that is valid UTF-8 JSON to be processed as JSON.\n                data = decoded_data_str\n            except UnicodeDecodeError:\n                # Binary data that is not UTF-8, encode as base64\n                b64_data = base64.b64encode(data).decode('utf-8')\n                return f\"event: binary\\ndata: {b64_data}\\n\\n\"\n\n        # Convert non-string objects (that are not already bytes) to JSON string\n        # If data was bytes and successfully decoded to UTF-8 string, it will be processed here.\n        original_data_type_was_complex = False\n        if not isinstance(data, str):\n            original_data_type_was_complex = True\n            try:\n                data_str = json.dumps(data)\n            except Exception:\n                data_str = str(data)  # Fallback to string representation\n        else:\n            data_str = data  # data is already a string\n\n        # Handle JSON data with special event formatting\n        # data_str now holds the string representation (either original string or JSON string)\n        if data_str.strip().startswith('{'):\n            try:\n                json_data = json.loads(data_str)\n                if isinstance(json_data, dict) and 'event' in json_data:\n                    event_type = json_data['event']\n                    event_id = json_data.get('id', None)  # Use None to distinguish from empty string\n\n                    # Determine the actual data payload for the SSE 'data:' field\n                    # If 'data' key exists in json_data, use its content.\n                    # Otherwise, use the original data_str (which is the JSON of json_data).\n                    if 'data' in json_data:\n                        payload_content = json_data['data']\n                        # If payload_content is complex, re-serialize it to JSON string\n                        if isinstance(payload_content, dict | list):\n                            sse_data_field = json.dumps(payload_content)\n                        else:  # Simple type (string, number, bool)\n                            sse_data_field = str(payload_content)\n                    else:\n                        # If original data was complex (e.g. dict) and became json_data,\n                        # and no 'data' key in it, then use the full json_data as payload.\n                        # If original data was a simple string that happened to be JSON parsable\n                        # but without 'event' key, it would have been handled by \"Regular JSON without event\"\n                        # or \"Plain text\" later.\n                        # This path implies original data was a dict with 'event' key.\n                        sse_data_field = data_str\n\n                    sse_lines = []\n                    if event_type:  # Should always be true here\n                        sse_lines.append(f\"event: {event_type}\")\n                    if event_id is not None:  # Check for None, allow empty string id\n                        sse_lines.append(f\"id: {event_id}\")\n\n                    # Handle multi-line data for the data field\n                    for line in sse_data_field.splitlines():\n                        sse_lines.append(f\"data: {line}\")\n\n                    return \"\\n\".join(sse_lines) + \"\\n\\n\"\n                else:\n                    # Regular JSON without special 'event' key\n                    sse_lines = []\n                    for line in data_str.splitlines():\n                        sse_lines.append(f\"data: {line}\")\n                    return \"\\n\".join(sse_lines) + \"\\n\\n\"\n            except json.JSONDecodeError:\n                # Not valid JSON, treat as plain text\n                sse_lines = []\n                for line in data_str.splitlines():\n                    sse_lines.append(f\"data: {line}\")\n                return \"\\n\".join(sse_lines) + \"\\n\\n\"\n        else:\n            # Plain text\n            sse_lines = []\n            for line in data_str.splitlines():\n                sse_lines.append(f\"data: {line}\")\n            return \"\\n\".join(sse_lines) + \"\\n\\n\"\n\n    @classmethod\n    async def wrap_sync_generator(cls, generator):\n        \"\"\"Convert a synchronous generator to an async generator.\"\"\"\n        for item in generator:\n            yield item\n            # Allow other tasks to run\n            await asyncio.sleep(0)\n\n    @classmethod\n    async def create_sse_stream(\n        cls,\n        source: Any,  # Changed from positional arg to keyword for clarity in Result.stream\n        cleanup_func: Callable[[], None] | Callable[[], T] | Callable[[], AsyncGenerator[T, None]] | None = None\n    ) -&gt; AsyncGenerator[str, None]:\n        \"\"\"\n        Convert any source to a properly formatted SSE stream.\n\n        Args:\n            source: Can be async generator, sync generator, iterable, or a single item.\n            cleanup_func: Optional function to call when the stream ends or is cancelled.\n                          Can be a synchronous function, async function, or async generator.\n\n        Yields:\n            Properly formatted SSE messages (strings).\n        \"\"\"\n        # Send stream start event\n        # This structure ensures data field contains {\"id\":\"0\"}\n        yield cls.format_sse_event({\"event\": \"stream_start\", \"data\": {\"id\": \"0\"}})\n\n        try:\n            # Handle different types of sources\n            if inspect.isasyncgen(source):\n                # Source is already an async generator\n                async for item in source:\n                    yield cls.format_sse_event(item)\n            elif inspect.isgenerator(source) or (not isinstance(source, str) and hasattr(source, '__iter__')):\n                # Source is a sync generator or iterable (but not a string)\n                # Strings are iterable but should be treated as single items unless explicitly made a generator\n                async for item in cls.wrap_sync_generator(source):\n                    yield cls.format_sse_event(item)\n            else:\n                # Single item (including strings)\n                yield cls.format_sse_event(source)\n        except asyncio.CancelledError:\n            # Client disconnected\n            yield cls.format_sse_event({\"event\": \"cancelled\", \"data\": {\"id\": \"cancelled\"}})\n            raise\n        except Exception as e:\n            # Error in stream\n            error_info = {\n                \"event\": \"error\",\n                \"data\": {  # Ensure payload is under 'data' key for the new format_sse_event logic\n                    \"message\": str(e),\n                    \"traceback\": traceback.format_exc()\n                }\n            }\n            yield cls.format_sse_event(error_info)\n        finally:\n            # Always send end event\n            yield cls.format_sse_event({\"event\": \"stream_end\", \"data\": {\"id\": \"final\"}})\n\n            # Execute cleanup function if provided\n            if cleanup_func:\n                try:\n                    if inspect.iscoroutinefunction(cleanup_func):  # Check if it's an async def function\n                        await cleanup_func()\n                    elif inspect.isasyncgenfunction(cleanup_func) or inspect.isasyncgen(\n                        cleanup_func):  # Check if it's an async def generator function or already an async generator\n                        # If it's a function, call it to get the generator\n                        gen_to_exhaust = cleanup_func() if inspect.isasyncgenfunction(cleanup_func) else cleanup_func\n                        async for _ in gen_to_exhaust:\n                            pass  # Exhaust the generator to ensure cleanup completes\n                    else:\n                        # Synchronous function\n                        cleanup_func()\n                except Exception as e:\n                    # Log cleanup errors but don't propagate them to client\n                    error_info_cleanup = {\n                        \"event\": \"cleanup_error\",\n                        \"data\": {  # Ensure payload is under 'data' key\n                            \"message\": str(e),\n                            \"traceback\": traceback.format_exc()\n                        }\n                    }\n                    # We can't yield here as the stream is already closing/closed.\n                    # Instead, log the error.\n                    # In a real app, use a proper logger.\n                    print(f\"SSE cleanup error: {cls.format_sse_event(error_info_cleanup)}\", flush=True)\n</code></pre> <code>create_sse_stream(source, cleanup_func=None)</code> <code>async</code> <code>classmethod</code> \u00b6 <p>Convert any source to a properly formatted SSE stream.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>Any</code> <p>Can be async generator, sync generator, iterable, or a single item.</p> required <code>cleanup_func</code> <code>Callable[[], None] | Callable[[], T] | Callable[[], AsyncGenerator[T, None]] | None</code> <p>Optional function to call when the stream ends or is cancelled.           Can be a synchronous function, async function, or async generator.</p> <code>None</code> <p>Yields:</p> Type Description <code>AsyncGenerator[str, None]</code> <p>Properly formatted SSE messages (strings).</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@classmethod\nasync def create_sse_stream(\n    cls,\n    source: Any,  # Changed from positional arg to keyword for clarity in Result.stream\n    cleanup_func: Callable[[], None] | Callable[[], T] | Callable[[], AsyncGenerator[T, None]] | None = None\n) -&gt; AsyncGenerator[str, None]:\n    \"\"\"\n    Convert any source to a properly formatted SSE stream.\n\n    Args:\n        source: Can be async generator, sync generator, iterable, or a single item.\n        cleanup_func: Optional function to call when the stream ends or is cancelled.\n                      Can be a synchronous function, async function, or async generator.\n\n    Yields:\n        Properly formatted SSE messages (strings).\n    \"\"\"\n    # Send stream start event\n    # This structure ensures data field contains {\"id\":\"0\"}\n    yield cls.format_sse_event({\"event\": \"stream_start\", \"data\": {\"id\": \"0\"}})\n\n    try:\n        # Handle different types of sources\n        if inspect.isasyncgen(source):\n            # Source is already an async generator\n            async for item in source:\n                yield cls.format_sse_event(item)\n        elif inspect.isgenerator(source) or (not isinstance(source, str) and hasattr(source, '__iter__')):\n            # Source is a sync generator or iterable (but not a string)\n            # Strings are iterable but should be treated as single items unless explicitly made a generator\n            async for item in cls.wrap_sync_generator(source):\n                yield cls.format_sse_event(item)\n        else:\n            # Single item (including strings)\n            yield cls.format_sse_event(source)\n    except asyncio.CancelledError:\n        # Client disconnected\n        yield cls.format_sse_event({\"event\": \"cancelled\", \"data\": {\"id\": \"cancelled\"}})\n        raise\n    except Exception as e:\n        # Error in stream\n        error_info = {\n            \"event\": \"error\",\n            \"data\": {  # Ensure payload is under 'data' key for the new format_sse_event logic\n                \"message\": str(e),\n                \"traceback\": traceback.format_exc()\n            }\n        }\n        yield cls.format_sse_event(error_info)\n    finally:\n        # Always send end event\n        yield cls.format_sse_event({\"event\": \"stream_end\", \"data\": {\"id\": \"final\"}})\n\n        # Execute cleanup function if provided\n        if cleanup_func:\n            try:\n                if inspect.iscoroutinefunction(cleanup_func):  # Check if it's an async def function\n                    await cleanup_func()\n                elif inspect.isasyncgenfunction(cleanup_func) or inspect.isasyncgen(\n                    cleanup_func):  # Check if it's an async def generator function or already an async generator\n                    # If it's a function, call it to get the generator\n                    gen_to_exhaust = cleanup_func() if inspect.isasyncgenfunction(cleanup_func) else cleanup_func\n                    async for _ in gen_to_exhaust:\n                        pass  # Exhaust the generator to ensure cleanup completes\n                else:\n                    # Synchronous function\n                    cleanup_func()\n            except Exception as e:\n                # Log cleanup errors but don't propagate them to client\n                error_info_cleanup = {\n                    \"event\": \"cleanup_error\",\n                    \"data\": {  # Ensure payload is under 'data' key\n                        \"message\": str(e),\n                        \"traceback\": traceback.format_exc()\n                    }\n                }\n                # We can't yield here as the stream is already closing/closed.\n                # Instead, log the error.\n                # In a real app, use a proper logger.\n                print(f\"SSE cleanup error: {cls.format_sse_event(error_info_cleanup)}\", flush=True)\n</code></pre> <code>format_sse_event(data)</code> <code>staticmethod</code> \u00b6 <p>Format any data as a proper SSE event message.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@staticmethod\ndef format_sse_event(data: Any) -&gt; str:\n    \"\"\"Format any data as a proper SSE event message.\"\"\"\n    # Already formatted as SSE\n    if isinstance(data, str) and (data.startswith('data:') or data.startswith('event:')) and '\\n\\n' in data:\n        return data\n\n    # Handle bytes (binary data)\n    if isinstance(data, bytes):\n        try:\n            # Try to decode as UTF-8 first\n            decoded_data_str = data.decode('utf-8')\n            # If decoding works, treat it as a string for further processing\n            # This allows binary data that is valid UTF-8 JSON to be processed as JSON.\n            data = decoded_data_str\n        except UnicodeDecodeError:\n            # Binary data that is not UTF-8, encode as base64\n            b64_data = base64.b64encode(data).decode('utf-8')\n            return f\"event: binary\\ndata: {b64_data}\\n\\n\"\n\n    # Convert non-string objects (that are not already bytes) to JSON string\n    # If data was bytes and successfully decoded to UTF-8 string, it will be processed here.\n    original_data_type_was_complex = False\n    if not isinstance(data, str):\n        original_data_type_was_complex = True\n        try:\n            data_str = json.dumps(data)\n        except Exception:\n            data_str = str(data)  # Fallback to string representation\n    else:\n        data_str = data  # data is already a string\n\n    # Handle JSON data with special event formatting\n    # data_str now holds the string representation (either original string or JSON string)\n    if data_str.strip().startswith('{'):\n        try:\n            json_data = json.loads(data_str)\n            if isinstance(json_data, dict) and 'event' in json_data:\n                event_type = json_data['event']\n                event_id = json_data.get('id', None)  # Use None to distinguish from empty string\n\n                # Determine the actual data payload for the SSE 'data:' field\n                # If 'data' key exists in json_data, use its content.\n                # Otherwise, use the original data_str (which is the JSON of json_data).\n                if 'data' in json_data:\n                    payload_content = json_data['data']\n                    # If payload_content is complex, re-serialize it to JSON string\n                    if isinstance(payload_content, dict | list):\n                        sse_data_field = json.dumps(payload_content)\n                    else:  # Simple type (string, number, bool)\n                        sse_data_field = str(payload_content)\n                else:\n                    # If original data was complex (e.g. dict) and became json_data,\n                    # and no 'data' key in it, then use the full json_data as payload.\n                    # If original data was a simple string that happened to be JSON parsable\n                    # but without 'event' key, it would have been handled by \"Regular JSON without event\"\n                    # or \"Plain text\" later.\n                    # This path implies original data was a dict with 'event' key.\n                    sse_data_field = data_str\n\n                sse_lines = []\n                if event_type:  # Should always be true here\n                    sse_lines.append(f\"event: {event_type}\")\n                if event_id is not None:  # Check for None, allow empty string id\n                    sse_lines.append(f\"id: {event_id}\")\n\n                # Handle multi-line data for the data field\n                for line in sse_data_field.splitlines():\n                    sse_lines.append(f\"data: {line}\")\n\n                return \"\\n\".join(sse_lines) + \"\\n\\n\"\n            else:\n                # Regular JSON without special 'event' key\n                sse_lines = []\n                for line in data_str.splitlines():\n                    sse_lines.append(f\"data: {line}\")\n                return \"\\n\".join(sse_lines) + \"\\n\\n\"\n        except json.JSONDecodeError:\n            # Not valid JSON, treat as plain text\n            sse_lines = []\n            for line in data_str.splitlines():\n                sse_lines.append(f\"data: {line}\")\n            return \"\\n\".join(sse_lines) + \"\\n\\n\"\n    else:\n        # Plain text\n        sse_lines = []\n        for line in data_str.splitlines():\n            sse_lines.append(f\"data: {line}\")\n        return \"\\n\".join(sse_lines) + \"\\n\\n\"\n</code></pre> <code>wrap_sync_generator(generator)</code> <code>async</code> <code>classmethod</code> \u00b6 <p>Convert a synchronous generator to an async generator.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@classmethod\nasync def wrap_sync_generator(cls, generator):\n    \"\"\"Convert a synchronous generator to an async generator.\"\"\"\n    for item in generator:\n        yield item\n        # Allow other tasks to run\n        await asyncio.sleep(0)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.types.Session","title":"<code>Session</code>  <code>dataclass</code>","text":"<p>Class representing a session.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@dataclass\nclass Session:\n    \"\"\"Class representing a session.\"\"\"\n    SiID: str\n    level: str\n    spec: str\n    user_name: str\n    # Allow for additional fields\n    extra_data: dict[str, Any] = field(default_factory=dict)\n\n    @classmethod\n    def from_dict(cls, data: dict[str, Any]) -&gt; 'Session':\n        \"\"\"Create a Session instance from a dictionary with default values.\"\"\"\n        known_fields = {\n            'SiID': data.get('SiID', '#0'),\n            'level': data.get('level', -1),\n            'spec': data.get('spec', 'app'),\n            'user_name': data.get('user_name', 'anonymous'),\n        }\n\n        extra_data = {k: v for k, v in data.items() if k not in known_fields}\n        return cls(**known_fields, extra_data=extra_data)\n\n    def to_dict(self) -&gt; dict[str, Any]:\n        \"\"\"Convert the Session object back to a dictionary.\"\"\"\n        result = {\n            'SiID': self.SiID,\n            'level': self.level,\n            'spec': self.spec,\n            'user_name': self.user_name,\n        }\n\n        # Add extra data\n        result.update(self.extra_data)\n\n        return result\n\n    @property\n    def valid(self):\n        return int(self.level) &gt; 0\n</code></pre> <code>from_dict(data)</code> <code>classmethod</code> \u00b6 <p>Create a Session instance from a dictionary with default values.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: dict[str, Any]) -&gt; 'Session':\n    \"\"\"Create a Session instance from a dictionary with default values.\"\"\"\n    known_fields = {\n        'SiID': data.get('SiID', '#0'),\n        'level': data.get('level', -1),\n        'spec': data.get('spec', 'app'),\n        'user_name': data.get('user_name', 'anonymous'),\n    }\n\n    extra_data = {k: v for k, v in data.items() if k not in known_fields}\n    return cls(**known_fields, extra_data=extra_data)\n</code></pre> <code>to_dict()</code> \u00b6 <p>Convert the Session object back to a dictionary.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Convert the Session object back to a dictionary.\"\"\"\n    result = {\n        'SiID': self.SiID,\n        'level': self.level,\n        'spec': self.spec,\n        'user_name': self.user_name,\n    }\n\n    # Add extra data\n    result.update(self.extra_data)\n\n    return result\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.system.types.parse_request_data","title":"<code>parse_request_data(data)</code>","text":"<p>Parse the incoming request data into a strongly typed structure.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def parse_request_data(data: dict[str, Any]) -&gt; RequestData:\n    \"\"\"Parse the incoming request data into a strongly typed structure.\"\"\"\n    return RequestData.from_dict(data)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.toolbox","title":"<code>toolbox</code>","text":"<p>Main module.</p>"},{"location":"toolboxv2/#toolboxv2.utils.toolbox.App","title":"<code>App</code>","text":"Source code in <code>toolboxv2/utils/toolbox.py</code> <pre><code>class App(AppType, metaclass=Singleton):\n\n    def __init__(self, prefix: str = \"\", args=AppArgs().default()):\n        super().__init__(prefix, args)\n        self._web_context = None\n        t0 = time.perf_counter()\n        abspath = os.path.abspath(__file__)\n        self.system_flag = system()  # Linux: Linux Mac: Darwin Windows: Windows\n\n        self.appdata = os.getenv('APPDATA') if os.name == 'nt' else os.getenv('XDG_CONFIG_HOME') or os.path.expanduser(\n                '~/.config') if os.name == 'posix' else None\n\n        if self.system_flag == \"Darwin\" or self.system_flag == \"Linux\":\n            dir_name = os.path.dirname(abspath).replace(\"/utils\", \"\")\n        else:\n            dir_name = os.path.dirname(abspath).replace(\"\\\\utils\", \"\")\n\n        self.start_dir = str(dir_name)\n\n        self.bg_tasks = []\n\n        lapp = dir_name + '\\\\.data\\\\'\n\n        if not prefix:\n            if not os.path.exists(f\"{lapp}last-app-prefix.txt\"):\n                os.makedirs(lapp, exist_ok=True)\n                open(f\"{lapp}last-app-prefix.txt\", \"a\").close()\n            with open(f\"{lapp}last-app-prefix.txt\") as prefix_file:\n                cont = prefix_file.read()\n                if cont:\n                    prefix = cont.rstrip()\n        else:\n            if not os.path.exists(f\"{lapp}last-app-prefix.txt\"):\n                os.makedirs(lapp, exist_ok=True)\n                open(f\"{lapp}last-app-prefix.txt\", \"a\").close()\n            with open(f\"{lapp}last-app-prefix.txt\", \"w\") as prefix_file:\n                prefix_file.write(prefix)\n\n        self.prefix = prefix\n\n        node_ = node()\n\n        if 'localhost' in node_ and (host := os.getenv('HOSTNAME', 'localhost')) != 'localhost':\n            node_ = node_.replace('localhost', host)\n        self.id = prefix + '-' + node_\n        self.globals = {\n            \"root\": {**globals()},\n        }\n        self.locals = {\n            \"user\": {'app': self, **locals()},\n        }\n\n        identification = self.id\n        collective_identification = self.id\n        if \"test\" in prefix:\n            if self.system_flag == \"Darwin\" or self.system_flag == \"Linux\":\n                start_dir = self.start_dir.replace(\"ToolBoxV2/toolboxv2\", \"toolboxv2\")\n            else:\n                start_dir = self.start_dir.replace(\"ToolBoxV2\\\\toolboxv2\", \"toolboxv2\")\n            self.data_dir = start_dir + '\\\\.data\\\\' + \"test\"\n            self.config_dir = start_dir + '\\\\.config\\\\' + \"test\"\n            self.info_dir = start_dir + '\\\\.info\\\\' + \"test\"\n        elif identification.startswith('collective-'):\n            collective_identification = identification.split('-')[1]\n            self.data_dir = self.start_dir + '\\\\.data\\\\' + collective_identification\n            self.config_dir = self.start_dir + '\\\\.config\\\\' + collective_identification\n            self.info_dir = self.start_dir + '\\\\.info\\\\' + collective_identification\n            self.id = collective_identification\n        else:\n            self.data_dir = self.start_dir + '\\\\.data\\\\' + identification\n            self.config_dir = self.start_dir + '\\\\.config\\\\' + identification\n            self.info_dir = self.start_dir + '\\\\.info\\\\' + identification\n\n        if self.appdata is None:\n            self.appdata = self.data_dir\n        else:\n            self.appdata += \"/ToolBoxV2\"\n\n        if not os.path.exists(self.appdata):\n            os.makedirs(self.appdata, exist_ok=True)\n        if not os.path.exists(self.data_dir):\n            os.makedirs(self.data_dir, exist_ok=True)\n        if not os.path.exists(self.config_dir):\n            os.makedirs(self.config_dir, exist_ok=True)\n        if not os.path.exists(self.info_dir):\n            os.makedirs(self.info_dir, exist_ok=True)\n\n        print(f\"Starting ToolBox as {prefix} from :\", Style.Bold(Style.CYAN(f\"{os.getcwd()}\")))\n\n        logger_info_str, self.logger, self.logging_filename = self.set_logger(args.debug)\n\n        print(\"Logger \" + logger_info_str)\n        print(\"================================\")\n        self.logger.info(\"Logger initialized\")\n        get_logger().info(Style.GREEN(\"Starting Application instance\"))\n        if args.init and args.init is not None and self.start_dir not in sys.path:\n            sys.path.append(self.start_dir)\n\n        __version__ = get_version_from_pyproject()\n        self.version = __version__\n\n        self.keys = {\n            \"MACRO\": \"macro~~~~:\",\n            \"MACRO_C\": \"m_color~~:\",\n            \"HELPER\": \"helper~~~:\",\n            \"debug\": \"debug~~~~:\",\n            \"id\": \"name-spa~:\",\n            \"st-load\": \"mute~load:\",\n            \"comm-his\": \"comm-his~:\",\n            \"develop-mode\": \"dev~mode~:\",\n            \"provider::\": \"provider::\",\n        }\n\n        defaults = {\n            \"MACRO\": ['Exit'],\n            \"MACRO_C\": {},\n            \"HELPER\": {},\n            \"debug\": args.debug,\n            \"id\": self.id,\n            \"st-load\": False,\n            \"comm-his\": [[]],\n            \"develop-mode\": False,\n        }\n        self.config_fh = FileHandler(collective_identification + \".config\", keys=self.keys, defaults=defaults)\n        self.config_fh.load_file_handler()\n        self._debug = args.debug\n        self.flows = {}\n        self.dev_modi = self.config_fh.get_file_handler(self.keys[\"develop-mode\"])\n        if self.config_fh.get_file_handler(\"provider::\") is None:\n            self.config_fh.add_to_save_file_handler(\"provider::\", \"http://localhost:\" + str(\n                self.args_sto.port) if os.environ.get(\"HOSTNAME\",\"localhost\") == \"localhost\" else \"https://simplecore.app\")\n        self.functions = {}\n        self.modules = {}\n\n        self.interface_type = ToolBoxInterfaces.native\n        self.PREFIX = Style.CYAN(f\"~{node()}@&gt;\")\n        self.alive = True\n        self.called_exit = False, time.time()\n\n        self.print(f\"Infos:\\n  {'Name':&lt;8} -&gt; {node()}\\n  {'ID':&lt;8} -&gt; {self.id}\\n  {'Version':&lt;8} -&gt; {self.version}\\n\")\n\n        self.logger.info(\n            Style.GREEN(\n                f\"Finish init up in {time.perf_counter() - t0:.2f}s\"\n            )\n        )\n\n        self.args_sto = args\n        self.loop = None\n\n        from .system.session import Session\n        self.session: Session = Session(self.get_username())\n        if len(sys.argv) &gt; 2 and sys.argv[1] == \"db\":\n            return\n        from .system.db_cli_manager import ClusterManager, get_executable_path\n        self.cluster_manager = ClusterManager()\n        online_list, server_list = self.cluster_manager.status_all(silent=True)\n        if not server_list:\n            self.cluster_manager.start_all(get_executable_path(), self.version)\n            _, server_list = self.cluster_manager.status_all()\n        from .extras.blobs import BlobStorage\n        self.root_blob_storage = BlobStorage(servers=server_list, storage_directory=self.data_dir+ '\\\\blob_cache\\\\')\n        # self._start_event_loop()\n\n    def _start_event_loop(self):\n        \"\"\"Starts the asyncio event loop in a separate thread.\"\"\"\n        if self.loop is None:\n            self.loop = asyncio.new_event_loop()\n            self.loop_thread = threading.Thread(target=self.loop.run_forever, daemon=True)\n            self.loop_thread.start()\n\n    def get_username(self, get_input=False, default=\"loot\") -&gt; str:\n        user_name = self.config_fh.get_file_handler(\"ac_user:::\")\n        if get_input and user_name is None:\n            user_name = input(\"Input your username: \")\n            self.config_fh.add_to_save_file_handler(\"ac_user:::\", user_name)\n        if user_name is None:\n            user_name = default\n            self.config_fh.add_to_save_file_handler(\"ac_user:::\", user_name)\n        return user_name\n\n    def set_username(self, username):\n        return self.config_fh.add_to_save_file_handler(\"ac_user:::\", username)\n\n    @staticmethod\n    def exit_main(*args, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    @staticmethod\n    def hide_console(*args, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    @staticmethod\n    def show_console(*args, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    @staticmethod\n    def disconnect(*args, **kwargs):\n        \"\"\"proxi attr\"\"\"\n\n    def set_logger(self, debug=False):\n        if \"test\" in self.prefix and not debug:\n            logger, logging_filename = setup_logging(logging.NOTSET, name=\"toolbox-test\", interminal=True,\n                                                     file_level=logging.NOTSET, app_name=self.id)\n            logger_info_str = \"in Test Mode\"\n        elif \"live\" in self.prefix and not debug:\n            logger, logging_filename = setup_logging(logging.DEBUG, name=\"toolbox-live\", interminal=False,\n                                                     file_level=logging.WARNING, app_name=self.id)\n            logger_info_str = \"in Live Mode\"\n            # setup_logging(logging.WARNING, name=\"toolbox-live\", is_online=True\n            #              , online_level=logging.WARNING).info(\"Logger initialized\")\n        elif \"debug\" in self.prefix or self.prefix.endswith(\"D\"):\n            self.prefix = self.prefix.replace(\"-debug\", '').replace(\"debug\", '')\n            logger, logging_filename = setup_logging(logging.DEBUG, name=\"toolbox-debug\", interminal=True,\n                                                     file_level=logging.WARNING, app_name=self.id)\n            logger_info_str = \"in debug Mode\"\n            self.debug = True\n        elif debug:\n            logger, logging_filename = setup_logging(logging.DEBUG, name=f\"toolbox-{self.prefix}-debug\",\n                                                     interminal=True,\n                                                     file_level=logging.DEBUG, app_name=self.id)\n            logger_info_str = \"in args debug Mode\"\n        else:\n            logger, logging_filename = setup_logging(logging.ERROR, name=f\"toolbox-{self.prefix}\", app_name=self.id)\n            logger_info_str = \"in Default\"\n\n        return logger_info_str, logger, logging_filename\n\n    @property\n    def debug(self):\n        return self._debug\n\n    @debug.setter\n    def debug(self, value):\n        if not isinstance(value, bool):\n            self.logger.debug(f\"Value must be an boolean. is : {value} type of {type(value)}\")\n            raise ValueError(\"Value must be an boolean.\")\n\n        # self.logger.info(f\"Setting debug {value}\")\n        self._debug = value\n\n    def debug_rains(self, e):\n        if self.debug:\n            import traceback\n            x = \"=\"*5\n            x += \" DEBUG \"\n            x += \"=\"*5\n            self.print(x)\n            self.print(traceback.format_exc())\n            self.print(x)\n            raise e\n        else:\n            self.logger.error(f\"Error: {e}\")\n            import traceback\n            x = \"=\"*5\n            x += \" DEBUG \"\n            x += \"=\"*5\n            self.print(x)\n            self.print(traceback.format_exc())\n            self.print(x)\n\n    def set_flows(self, r):\n        self.flows = r\n\n    async def run_flows(self, name, **kwargs):\n        from ..flows import flows_dict as flows_dict_func\n        if name not in self.flows:\n            self.flows = {**self.flows, **flows_dict_func(s=name, remote=True)}\n        if name in self.flows:\n            if asyncio.iscoroutinefunction(self.flows[name]):\n                return await self.flows[name](get_app(from_=\"runner\"), self.args_sto, **kwargs)\n            else:\n                return self.flows[name](get_app(from_=\"runner\"), self.args_sto, **kwargs)\n        else:\n            print(\"Flow not found, active flows:\", len(self.flows.keys()))\n\n    def _coppy_mod(self, content, new_mod_dir, mod_name, file_type='py'):\n\n        mode = 'xb'\n        self.logger.info(f\" coppy mod {mod_name} to {new_mod_dir} size : {sys.getsizeof(content) / 8388608:.3f} mb\")\n\n        if not os.path.exists(new_mod_dir):\n            os.makedirs(new_mod_dir)\n            with open(f\"{new_mod_dir}/__init__.py\", \"w\") as nmd:\n                nmd.write(f\"__version__ = '{self.version}'\")\n\n        if os.path.exists(f\"{new_mod_dir}/{mod_name}.{file_type}\"):\n            mode = False\n\n            with open(f\"{new_mod_dir}/{mod_name}.{file_type}\", 'rb') as d:\n                runtime_mod = d.read()  # Testing version but not efficient\n\n            if len(content) != len(runtime_mod):\n                mode = 'wb'\n\n        if mode:\n            with open(f\"{new_mod_dir}/{mod_name}.{file_type}\", mode) as f:\n                f.write(content)\n\n    def _pre_lib_mod(self, mod_name, path_to=\"./runtime\", file_type='py'):\n        working_dir = self.id.replace(\".\", \"_\")\n        lib_mod_dir = f\"toolboxv2.runtime.{working_dir}.mod_lib.\"\n\n        self.logger.info(f\"pre_lib_mod {mod_name} from {lib_mod_dir}\")\n\n        postfix = \"_dev\" if self.dev_modi else \"\"\n        mod_file_dir = f\"./mods{postfix}/{mod_name}.{file_type}\"\n        new_mod_dir = f\"{path_to}/{working_dir}/mod_lib\"\n        with open(mod_file_dir, \"rb\") as c:\n            content = c.read()\n        self._coppy_mod(content, new_mod_dir, mod_name, file_type=file_type)\n        return lib_mod_dir\n\n    def _copy_load(self, mod_name, file_type='py', **kwargs):\n        loc = self._pre_lib_mod(mod_name, file_type)\n        return self.inplace_load_instance(mod_name, loc=loc, **kwargs)\n\n    def helper_install_pip_module(self, module_name):\n        if 'main' in self.id:\n            return\n        self.print(f\"Installing {module_name} GREEDY\")\n        os.system(f\"{sys.executable} -m pip install {module_name}\")\n\n    def python_module_import_classifier(self, mod_name, error_message):\n\n        if error_message.startswith(\"No module named 'toolboxv2.utils\"):\n            return Result.default_internal_error(f\"404 {error_message.split('utils')[1]} not found\")\n        if error_message.startswith(\"No module named 'toolboxv2.mods\"):\n            if mod_name.startswith('.'):\n                return\n            return self.run_a_from_sync(self.a_run_any, (\"CloudM\", \"install\"), module_name=mod_name)\n        if error_message.startswith(\"No module named '\"):\n            pip_requ = error_message.split(\"'\")[1].replace(\"'\", \"\").strip()\n            # if 'y' in input(f\"\\t\\t\\tAuto install {pip_requ} Y/n\").lower:\n            return self.helper_install_pip_module(pip_requ)\n            # return Result.default_internal_error(f\"404 {pip_requ} not found\")\n\n    def inplace_load_instance(self, mod_name, loc=\"toolboxv2.mods.\", spec='app', save=True, mfo=None):\n        if self.dev_modi and loc == \"toolboxv2.mods.\":\n            loc = \"toolboxv2.mods_dev.\"\n        if spec=='app' and self.mod_online(mod_name):\n            self.logger.info(f\"Reloading mod from : {loc + mod_name}\")\n            self.remove_mod(mod_name, spec=spec, delete=False)\n\n        if (os.path.exists(self.start_dir + '/mods/' + mod_name) or os.path.exists(\n            self.start_dir + '/mods/' + mod_name + '.py')) and (\n            os.path.isdir(self.start_dir + '/mods/' + mod_name) or os.path.isfile(\n            self.start_dir + '/mods/' + mod_name + '.py')):\n            try:\n                if mfo is None:\n                    modular_file_object = import_module(loc + mod_name)\n                else:\n                    modular_file_object = mfo\n                self.modules[mod_name] = modular_file_object\n            except ModuleNotFoundError as e:\n                self.logger.error(Style.RED(f\"module {loc + mod_name} not found is type sensitive {e}\"))\n                self.print(Style.RED(f\"module {loc + mod_name} not found is type sensitive {e}\"))\n                if self.debug or self.args_sto.sysPrint:\n                    self.python_module_import_classifier(mod_name, str(e))\n                self.debug_rains(e)\n                return None\n        else:\n            self.print(f\"module {loc + mod_name} is not valid\")\n            return None\n        if hasattr(modular_file_object, \"Tools\"):\n            tools_class = modular_file_object.Tools\n        else:\n            if hasattr(modular_file_object, \"name\"):\n                tools_class = modular_file_object\n                modular_file_object = import_module(loc + mod_name)\n            else:\n                tools_class = None\n\n        modular_id = None\n        instance = modular_file_object\n        app_instance_type = \"file/application\"\n\n        if tools_class is None:\n            modular_id = modular_file_object.Name if hasattr(modular_file_object, \"Name\") else mod_name\n\n        if tools_class is None and modular_id is None:\n            modular_id = str(modular_file_object.__name__)\n            self.logger.warning(f\"Unknown instance loaded {mod_name}\")\n            return modular_file_object\n\n        if tools_class is not None:\n            tools_class = self.save_initialized_module(tools_class, spec)\n            modular_id = tools_class.name\n            app_instance_type = \"functions/class\"\n        else:\n            instance.spec = spec\n        # if private:\n        #     self.functions[modular_id][f\"{spec}_private\"] = private\n\n        if not save:\n            return instance if tools_class is None else tools_class\n\n        return self.save_instance(instance, modular_id, spec, app_instance_type, tools_class=tools_class)\n\n    def save_instance(self, instance, modular_id, spec='app', instance_type=\"file/application\", tools_class=None):\n\n        if modular_id in self.functions and tools_class is None:\n            if self.functions[modular_id].get(f\"{spec}_instance\", None) is None:\n                self.functions[modular_id][f\"{spec}_instance\"] = instance\n                self.functions[modular_id][f\"{spec}_instance_type\"] = instance_type\n            else:\n                self.print(\"Firest instance stays use new spec to get new instance\")\n                if modular_id in self.functions and self.functions[modular_id].get(f\"{spec}_instance\", None) is not None:\n                    return self.functions[modular_id][f\"{spec}_instance\"]\n                else:\n                    raise ImportError(f\"Module already known {modular_id} and not avalabel reload using other spec then {spec}\")\n\n        elif tools_class is not None:\n            if modular_id not in self.functions:\n                self.functions[modular_id] = {}\n            self.functions[modular_id][f\"{spec}_instance\"] = tools_class\n            self.functions[modular_id][f\"{spec}_instance_type\"] = instance_type\n\n            try:\n                if not hasattr(tools_class, 'tools'):\n                    tools_class.tools = {\"Version\": tools_class.get_version, 'name': tools_class.name}\n                for function_name in list(tools_class.tools.keys()):\n                    t_function_name = function_name.lower()\n                    if t_function_name != \"all\" and t_function_name != \"name\":\n                        self.tb(function_name, mod_name=modular_id)(tools_class.tools.get(function_name))\n                self.functions[modular_id][f\"{spec}_instance_type\"] += \"/BC\"\n                if hasattr(tools_class, 'on_exit'):\n                    if \"on_exit\" in self.functions[modular_id]:\n                        self.functions[modular_id][\"on_exit\"].append(tools_class.on_exit)\n                    else:\n                        self.functions[modular_id][\"on_exit\"] = [tools_class.on_exit]\n            except Exception as e:\n                self.logger.error(f\"Starting Module {modular_id} compatibility failed with : {e}\")\n                pass\n        elif modular_id not in self.functions and tools_class is None:\n            self.functions[modular_id] = {}\n            self.functions[modular_id][f\"{spec}_instance\"] = instance\n            self.functions[modular_id][f\"{spec}_instance_type\"] = instance_type\n\n        else:\n            raise ImportError(f\"Modular {modular_id} is not a valid mod\")\n        on_start = self.functions[modular_id].get(\"on_start\")\n        if on_start is not None:\n            i = 1\n            for f in on_start:\n                try:\n                    f_, e = self.get_function((modular_id, f), state=True, specification=spec)\n                    if e == 0:\n                        self.logger.info(Style.GREY(f\"Running On start {f} {i}/{len(on_start)}\"))\n                        if asyncio.iscoroutinefunction(f_):\n                            self.print(f\"Async on start is only in Tool claas supported for {modular_id}.{f}\" if tools_class is None else f\"initialization starting soon for {modular_id}.{f}\")\n                            self.run_bg_task_advanced(f_)\n                        else:\n                            o = f_()\n                            if o is not None:\n                                self.print(f\"Function {modular_id} On start result: {o}\")\n                    else:\n                        self.logger.warning(f\"starting function not found {e}\")\n                except Exception as e:\n                    self.logger.debug(Style.YELLOW(\n                        Style.Bold(f\"modular:{modular_id}.{f} on_start error {i}/{len(on_start)} -&gt; {e}\")))\n                    self.debug_rains(e)\n                finally:\n                    i += 1\n        return instance if tools_class is None else tools_class\n\n    def save_initialized_module(self, tools_class, spec):\n        tools_class.spec = spec\n        live_tools_class = tools_class(app=self)\n        return live_tools_class\n\n    def mod_online(self, mod_name, installed=False):\n        if installed and mod_name not in self.functions:\n            self.save_load(mod_name)\n        return mod_name in self.functions\n\n    def _get_function(self,\n                      name: Enum or None,\n                      state: bool = True,\n                      specification: str = \"app\",\n                      metadata=False, as_str: tuple or None = None, r=0, **kwargs):\n\n        if as_str is None and isinstance(name, Enum):\n            modular_id = str(name.NAME.value)\n            function_id = str(name.value)\n        elif as_str is None and isinstance(name, list):\n            modular_id, function_id = name[0], name[1]\n        else:\n            modular_id, function_id = as_str\n\n        self.logger.info(f\"getting function : {specification}.{modular_id}.{function_id}\")\n\n        if modular_id not in self.functions:\n            if r == 0:\n                self.save_load(modular_id, spec=specification)\n                return self.get_function(name=(modular_id, function_id),\n                                         state=state,\n                                         specification=specification,\n                                         metadata=metadata,\n                                         r=1)\n            self.logger.warning(f\"function modular not found {modular_id} 404\")\n            return \"404\", 404\n\n        if function_id not in self.functions[modular_id]:\n            self.logger.warning(f\"function data not found {modular_id}.{function_id} 404\")\n            return \"404\", 404\n\n        function_data = self.functions[modular_id][function_id]\n\n        if isinstance(function_data, list):\n            print(f\"functions {function_id} : {function_data}\")\n            function_data = self.functions[modular_id][function_data[kwargs.get('i', -1)]]\n            print(f\"functions {modular_id} : {function_data}\")\n        function = function_data.get(\"func\")\n        params = function_data.get(\"params\")\n\n        state_ = function_data.get(\"state\")\n        if state_ is not None and state != state_:\n            state = state_\n\n        if function is None:\n            self.logger.warning(\"No function found\")\n            return \"404\", 404\n\n        if params is None:\n            self.logger.warning(\"No function (params) found\")\n            return \"404\", 301\n\n        if metadata and not state:\n            self.logger.info(\"returning metadata stateless\")\n            return (function_data, function), 0\n\n        if not state:  # mens a stateless function\n            self.logger.info(\"returning stateless function\")\n            return function, 0\n\n        instance = self.functions[modular_id].get(f\"{specification}_instance\")\n\n        # instance_type = self.functions[modular_id].get(f\"{specification}_instance_type\", \"functions/class\")\n\n        if params[0] == 'app':\n            instance = get_app(from_=f\"fuction {specification}.{modular_id}.{function_id}\")\n\n        if instance is None and self.alive:\n            self.inplace_load_instance(modular_id, spec=specification)\n            instance = self.functions[modular_id].get(f\"{specification}_instance\")\n\n        if instance is None:\n            self.logger.warning(\"No live Instance found\")\n            return \"404\", 400\n\n        # if instance_type.endswith(\"/BC\"):  # for backwards compatibility  functions/class/BC old modules\n        #     # returning as stateless\n        #     # return \"422\", -1\n        #     self.logger.info(\n        #         f\"returning stateless function, cant find tools class for state handling found {instance_type}\")\n        #     if metadata:\n        #         self.logger.info(f\"returning metadata stateless\")\n        #         return (function_data, function), 0\n        #     return function, 0\n\n        self.logger.info(\"wrapping in higher_order_function\")\n\n        self.logger.info(f\"returned fuction {specification}.{modular_id}.{function_id}\")\n        higher_order_function = partial(function, instance)\n\n        if metadata:\n            self.logger.info(\"returning metadata stateful\")\n            return (function_data, higher_order_function), 0\n\n        self.logger.info(\"returning stateful function\")\n        return higher_order_function, 0\n\n    def save_exit(self):\n        self.logger.info(f\"save exiting saving data to {self.config_fh.file_handler_filename} states of {self.debug=}\")\n        self.config_fh.add_to_save_file_handler(self.keys[\"debug\"], str(self.debug))\n\n    def init_mod(self, mod_name, spec='app'):\n        \"\"\"\n        Initializes a module in a thread-safe manner by submitting the\n        asynchronous initialization to the running event loop.\n        \"\"\"\n        if '.' in mod_name:\n            mod_name = mod_name.split('.')[0]\n        self.run_bg_task(self.a_init_mod, mod_name, spec)\n        # loop = self.loop_gard()\n        # if loop:\n        #     # Create a future to get the result from the coroutine\n        #     future: Future = asyncio.run_coroutine_threadsafe(\n        #         self.a_init_mod(mod_name, spec), loop\n        #     )\n        #     # Block until the result is available\n        #     return future.result()\n        # else:\n        #     raise ValueError(\"Event loop is not running\")\n        #     # return self.loop_gard().run_until_complete(self.a_init_mod(mod_name, spec))\n\n    def run_bg_task(self, task: Callable, *args, **kwargs) -&gt; asyncio.Task | None:\n        \"\"\"\n        Runs a coroutine in the background without blocking the caller.\n\n        This is the primary method for \"fire-and-forget\" async tasks. It schedules\n        the coroutine to run on the application's main event loop.\n\n        Args:\n            task: The coroutine function to run.\n            *args: Arguments to pass to the coroutine function.\n            **kwargs: Keyword arguments to pass to the coroutine function.\n\n        Returns:\n            An asyncio.Task object representing the scheduled task, or None if\n            the task could not be scheduled.\n        \"\"\"\n        if not callable(task):\n            self.logger.warning(\"Task passed to run_bg_task is not callable!\")\n            return None\n\n        if not asyncio.iscoroutinefunction(task) and not asyncio.iscoroutine(task):\n            self.logger.warning(f\"Task '{getattr(task, '__name__', 'unknown')}' is not a coroutine. \"\n                                f\"Use run_bg_task_advanced for synchronous functions.\")\n            # Fallback to advanced runner for convenience\n            self.run_bg_task_advanced(task, *args, **kwargs)\n            return None\n\n        try:\n            loop = self.loop_gard()\n            if not loop.is_running():\n                # If the main loop isn't running, we can't create a task on it.\n                # This scenario is handled by run_bg_task_advanced.\n                self.logger.info(\"Main event loop not running. Delegating to advanced background runner.\")\n                return self.run_bg_task_advanced(task, *args, **kwargs)\n\n            # Create the coroutine if it's a function\n            coro = task(*args, **kwargs) if asyncio.iscoroutinefunction(task) else task\n\n            # Create a task on the running event loop\n            bg_task = loop.create_task(coro)\n\n            # Add a callback to log exceptions from the background task\n            def _log_exception(the_task: asyncio.Task):\n                if not the_task.cancelled() and the_task.exception():\n                    self.logger.error(f\"Exception in background task '{the_task.get_name()}':\",\n                                      exc_info=the_task.exception())\n\n            bg_task.add_done_callback(_log_exception)\n            self.bg_tasks.append(bg_task)\n            return bg_task\n\n        except Exception as e:\n            self.logger.error(f\"Failed to schedule background task: {e}\", exc_info=True)\n            return None\n\n    def run_bg_task_advanced(self, task: Callable, *args, **kwargs) -&gt; threading.Thread:\n        \"\"\"\n        Runs a task in a separate, dedicated background thread with its own event loop.\n\n        This is ideal for:\n        1. Running an async task from a synchronous context.\n        2. Launching a long-running, independent operation that should not\n           interfere with the main application's event loop.\n\n        Args:\n            task: The function to run (can be sync or async).\n            *args: Arguments for the task.\n            **kwargs: Keyword arguments for the task.\n\n        Returns:\n            The threading.Thread object managing the background execution.\n        \"\"\"\n        if not callable(task):\n            self.logger.warning(\"Task for run_bg_task_advanced is not callable!\")\n            return None\n\n        def thread_target():\n            # Each thread gets its own event loop.\n            loop = asyncio.new_event_loop()\n            asyncio.set_event_loop(loop)\n\n            try:\n                # Prepare the coroutine we need to run\n                if asyncio.iscoroutinefunction(task):\n                    coro = task(*args, **kwargs)\n                elif asyncio.iscoroutine(task):\n                    # It's already a coroutine object\n                    coro = task\n                else:\n                    # It's a synchronous function, run it in an executor\n                    # to avoid blocking the new event loop.\n                    coro = loop.run_in_executor(None, lambda: task(*args, **kwargs))\n\n                # Run the coroutine to completion\n                result = loop.run_until_complete(coro)\n                self.logger.debug(f\"Advanced background task '{getattr(task, '__name__', 'unknown')}' completed.\")\n                if result is not None:\n                    self.logger.debug(f\"Task result: {str(result)[:100]}\")\n\n            except Exception as e:\n                self.logger.error(f\"Error in advanced background task '{getattr(task, '__name__', 'unknown')}':\",\n                                  exc_info=e)\n            finally:\n                # Cleanly shut down the event loop in this thread.\n                try:\n                    all_tasks = asyncio.all_tasks(loop=loop)\n                    if all_tasks:\n                        for t in all_tasks:\n                            t.cancel()\n                        loop.run_until_complete(asyncio.gather(*all_tasks, return_exceptions=True))\n                finally:\n                    loop.close()\n                    asyncio.set_event_loop(None)\n\n        # Create, start, and return the thread.\n        # It's a daemon thread so it won't prevent the main app from exiting.\n        t = threading.Thread(target=thread_target, daemon=True, name=f\"BGTask-{getattr(task, '__name__', 'unknown')}\")\n        self.bg_tasks.append(t)\n        t.start()\n        return t\n\n    # Helper method to wait for background tasks to complete (optional)\n    def wait_for_bg_tasks(self, timeout=None):\n        \"\"\"\n        Wait for all background tasks to complete.\n\n        Args:\n            timeout: Maximum time to wait (in seconds) for all tasks to complete.\n                     None means wait indefinitely.\n\n        Returns:\n            bool: True if all tasks completed, False if timeout occurred\n        \"\"\"\n        active_tasks = [t for t in self.bg_tasks if t.is_alive()]\n\n        for task in active_tasks:\n            task.join(timeout=timeout)\n            if task.is_alive():\n                return False\n\n        return True\n\n    def __call__(self, *args, **kwargs):\n        return self.run(*args, **kwargs)\n\n    def run(self, *args, request=None, running_function_coro=None, **kwargs):\n        \"\"\"\n        Run a function with support for SSE streaming in both\n        threaded and non-threaded contexts.\n        \"\"\"\n        if running_function_coro is None:\n            mn, fn = args[0]\n            if self.functions.get(mn, {}).get(fn, {}).get('request_as_kwarg', False):\n                kwargs[\"request\"] = RequestData.from_dict(request)\n                if 'data' in kwargs and 'data' not in self.functions.get(mn, {}).get(fn, {}).get('params', []):\n                    kwargs[\"request\"].data = kwargs[\"request\"].body = kwargs['data']\n                    del kwargs['data']\n                if 'form_data' in kwargs and 'form_data' not in self.functions.get(mn, {}).get(fn, {}).get('params',\n                                                                                                           []):\n                    kwargs[\"request\"].form_data = kwargs[\"request\"].body = kwargs['form_data']\n                    del kwargs['form_data']\n\n        # Create the coroutine\n        coro = running_function_coro or self.a_run_any(*args, **kwargs)\n\n        # Get or create an event loop\n        try:\n            loop = asyncio.get_event_loop()\n            is_running = loop.is_running()\n        except RuntimeError:\n            loop = asyncio.new_event_loop()\n            asyncio.set_event_loop(loop)\n            is_running = False\n\n        # If the loop is already running, run in a separate thread\n        if is_running:\n            # Create thread pool executor as needed\n            if not hasattr(self.__class__, '_executor'):\n                self.__class__._executor = ThreadPoolExecutor(max_workers=4)\n\n            def run_in_new_thread():\n                # Set up a new loop in this thread\n                new_loop = asyncio.new_event_loop()\n                asyncio.set_event_loop(new_loop)\n\n                try:\n                    # Run the coroutine\n                    return new_loop.run_until_complete(coro)\n                finally:\n                    new_loop.close()\n\n            # Run in thread and get result\n            thread_result = self.__class__._executor.submit(run_in_new_thread).result()\n\n            # Handle streaming results from thread\n            if isinstance(thread_result, dict) and thread_result.get(\"is_stream\"):\n                # Create a new SSE stream in the main thread\n                async def stream_from_function():\n                    # Re-run the function with direct async access\n                    stream_result = await self.a_run_any(*args, **kwargs)\n\n                    if (isinstance(stream_result, Result) and\n                        getattr(stream_result.result, 'data_type', None) == \"stream\"):\n                        # Get and forward data from the original generator\n                        original_gen = stream_result.result.data.get(\"generator\")\n                        if inspect.isasyncgen(original_gen):\n                            async for item in original_gen:\n                                yield item\n\n                # Return a new streaming Result\n                return Result.stream(\n                    stream_generator=stream_from_function(),\n                    headers=thread_result.get(\"headers\", {})\n                )\n\n            result = thread_result\n        else:\n            # Direct execution when loop is not running\n            result = loop.run_until_complete(coro)\n\n        # Process the final result\n        if isinstance(result, Result):\n            if 'debug' in self.id:\n                result.print()\n            if getattr(result.result, 'data_type', None) == \"stream\":\n                return result\n            return result.to_api_result().model_dump(mode='json')\n\n        return result\n\n    def loop_gard(self):\n        if self.loop is None:\n            self._start_event_loop()\n            self.loop = asyncio.get_event_loop()\n        if self.loop.is_closed():\n            self.loop = asyncio.get_event_loop()\n        return self.loop\n\n    async def a_init_mod(self, mod_name, spec='app'):\n        mod = self.save_load(mod_name, spec=spec)\n        if hasattr(mod, \"__initobj\") and not mod.async_initialized:\n            await mod\n        return mod\n\n\n    def load_mod(self, mod_name: str, mlm='I', **kwargs):\n\n        action_list_helper = ['I (inplace load dill on error python)',\n                              # 'C (coppy py file to runtime dir)',\n                              # 'S (save py file to dill)',\n                              # 'CS (coppy and save py file)',\n                              # 'D (development mode, inplace load py file)'\n                              ]\n        action_list = {\"I\": lambda: self.inplace_load_instance(mod_name, **kwargs),\n                       \"C\": lambda: self._copy_load(mod_name, **kwargs)\n                       }\n\n        try:\n            if mlm in action_list:\n\n                return action_list.get(mlm)()\n            else:\n                self.logger.critical(\n                    f\"config mlm must be {' or '.join(action_list_helper)} is {mlm=}\")\n                raise ValueError(f\"config mlm must be {' or '.join(action_list_helper)} is {mlm=}\")\n        except ValueError as e:\n            self.logger.warning(Style.YELLOW(f\"Error Loading Module '{mod_name}', with error :{e}\"))\n            self.debug_rains(e)\n        except ImportError as e:\n            self.logger.error(Style.YELLOW(f\"Error Loading Module '{mod_name}', with error :{e}\"))\n            self.debug_rains(e)\n        except Exception as e:\n            self.logger.critical(Style.RED(f\"Error Loading Module '{mod_name}', with critical error :{e}\"))\n            print(Style.RED(f\"Error Loading Module '{mod_name}'\"))\n            self.debug_rains(e)\n\n        return Result.default_internal_error(info=\"info's in logs.\")\n\n    async def load_all_mods_in_file(self, working_dir=\"mods\"):\n        print(f\"LOADING ALL MODS FROM FOLDER : {working_dir}\")\n        t0 = time.perf_counter()\n        # Get the list of all modules\n        module_list = self.get_all_mods(working_dir)\n        open_modules = self.functions.keys()\n        start_len = len(open_modules)\n\n        for om in open_modules:\n            if om in module_list:\n                module_list.remove(om)\n\n        tasks: set[Task] = set()\n\n        _ = {tasks.add(asyncio.create_task(asyncio.to_thread(self.save_load, mod, 'app'))) for mod in module_list}\n        for t in asyncio.as_completed(tasks):\n            try:\n                result = await t\n                if hasattr(result, 'Name'):\n                    print('Opened :', result.Name)\n                elif hasattr(result, 'name'):\n                    if hasattr(result, 'async_initialized'):\n                        if not result.async_initialized:\n                            async def _():\n                                try:\n                                    if asyncio.iscoroutine(result):\n                                        await result\n                                    if hasattr(result, 'Name'):\n                                        print('Opened :', result.Name)\n                                    elif hasattr(result, 'name'):\n                                        print('Opened :', result.name)\n                                except Exception as e:\n                                    self.debug_rains(e)\n                                    if hasattr(result, 'Name'):\n                                        print('Error opening :', result.Name)\n                                    elif hasattr(result, 'name'):\n                                        print('Error opening :', result.name)\n                            asyncio.create_task(_())\n                        else:\n                            print('Opened :', result.name)\n                else:\n                    print('Opened :', result)\n            except Exception as e:\n                self.logger.error(Style.RED(f\"An Error occurred while opening all modules error: {str(e)}\"))\n                self.debug_rains(e)\n        opened = len(self.functions.keys()) - start_len\n\n        self.logger.info(f\"Opened {opened} modules in {time.perf_counter() - t0:.2f}s\")\n        return f\"Opened {opened} modules in {time.perf_counter() - t0:.2f}s\"\n\n    def get_all_mods(self, working_dir=\"mods\", path_to=\"./runtime\", use_wd=True):\n        self.logger.info(f\"collating all mods in working directory {working_dir}\")\n\n        pr = \"_dev\" if self.dev_modi else \"\"\n        if working_dir == \"mods\" and use_wd:\n            working_dir = f\"{self.start_dir}/mods{pr}\"\n        elif use_wd:\n            pass\n        else:\n            w_dir = self.id.replace(\".\", \"_\")\n            working_dir = f\"{path_to}/{w_dir}/mod_lib{pr}/\"\n        res = os.listdir(working_dir)\n\n        self.logger.info(f\"found : {len(res)} files\")\n\n        def do_helper(_mod):\n            if \"mainTool\" in _mod:\n                return False\n            # if not _mod.endswith(\".py\"):\n            #     return False\n            if _mod.startswith(\"__\"):\n                return False\n            if _mod.startswith(\".\"):\n                return False\n            return not _mod.startswith(\"test_\")\n\n        def r_endings(word: str):\n            if word.endswith(\".py\"):\n                return word[:-3]\n            return word\n\n        mods_list = list(map(r_endings, filter(do_helper, res)))\n\n        self.logger.info(f\"found : {len(mods_list)} Modules\")\n        return mods_list\n\n    def remove_all_modules(self, delete=False):\n        for mod in list(self.functions.keys()):\n            self.logger.info(f\"closing: {mod}\")\n            self.remove_mod(mod, delete=delete)\n\n    def remove_mod(self, mod_name, spec='app', delete=True):\n        if mod_name not in self.functions:\n            self.logger.info(f\"mod not active {mod_name}\")\n            return\n\n        on_exit = self.functions[mod_name].get(\"on_exit\")\n        self.logger.info(f\"closing: {on_exit}\")\n        def helper():\n            if f\"{spec}_instance\" in self.functions[mod_name]:\n                del self.functions[mod_name][f\"{spec}_instance\"]\n            if f\"{spec}_instance_type\" in self.functions[mod_name]:\n                del self.functions[mod_name][f\"{spec}_instance_type\"]\n\n        if on_exit is None and self.functions[mod_name].get(f\"{spec}_instance_type\", \"\").endswith(\"/BC\"):\n            instance = self.functions[mod_name].get(f\"{spec}_instance\", None)\n            if instance is not None and hasattr(instance, 'on_exit'):\n                if asyncio.iscoroutinefunction(instance.on_exit):\n                    self.exit_tasks.append(instance.on_exit)\n                else:\n                    instance.on_exit()\n\n        if on_exit is None and delete:\n            self.functions[mod_name] = {}\n            del self.functions[mod_name]\n            return\n        if on_exit is None:\n            helper()\n            return\n\n        i = 1\n\n        for j, f in enumerate(on_exit):\n            try:\n                f_, e = self.get_function((mod_name, f), state=True, specification=spec, i=j)\n                if e == 0:\n                    self.logger.info(Style.GREY(f\"Running On exit {f} {i}/{len(on_exit)}\"))\n                    if asyncio.iscoroutinefunction(f_):\n                        self.exit_tasks.append(f_)\n                        o = None\n                    else:\n                        o = f_()\n                    if o is not None:\n                        self.print(f\"Function On Exit result: {o}\")\n                else:\n                    self.logger.warning(\"closing function not found\")\n            except Exception as e:\n                self.logger.debug(\n                    Style.YELLOW(Style.Bold(f\"modular:{mod_name}.{f} on_exit error {i}/{len(on_exit)} -&gt; {e}\")))\n\n                self.debug_rains(e)\n            finally:\n                i += 1\n\n        helper()\n\n        if delete:\n            self.functions[mod_name] = {}\n            del self.functions[mod_name]\n\n    async def a_remove_all_modules(self, delete=False):\n        for mod in list(self.functions.keys()):\n            self.logger.info(f\"closing: {mod}\")\n            await self.a_remove_mod(mod, delete=delete)\n\n    async def a_remove_mod(self, mod_name, spec='app', delete=True):\n        if mod_name not in self.functions:\n            self.logger.info(f\"mod not active {mod_name}\")\n            return\n        on_exit = self.functions[mod_name].get(\"on_exit\")\n        self.logger.info(f\"closing: {on_exit}\")\n        def helper():\n            if f\"{spec}_instance\" in self.functions[mod_name]:\n                del self.functions[mod_name][f\"{spec}_instance\"]\n            if f\"{spec}_instance_type\" in self.functions[mod_name]:\n                del self.functions[mod_name][f\"{spec}_instance_type\"]\n\n        if on_exit is None and self.functions[mod_name].get(f\"{spec}_instance_type\", \"\").endswith(\"/BC\"):\n            instance = self.functions[mod_name].get(f\"{spec}_instance\", None)\n            if instance is not None and hasattr(instance, 'on_exit'):\n                if asyncio.iscoroutinefunction(instance.on_exit):\n                    await instance.on_exit()\n                else:\n                    instance.on_exit()\n\n        if on_exit is None and delete:\n            self.functions[mod_name] = {}\n            del self.functions[mod_name]\n            return\n        if on_exit is None:\n            helper()\n            return\n\n        i = 1\n        for f in on_exit:\n            try:\n                e = 1\n                if isinstance(f, str):\n                    f_, e = self.get_function((mod_name, f), state=True, specification=spec)\n                elif isinstance(f, Callable):\n                    f_, e, f  = f, 0, f.__name__\n                if e == 0:\n                    self.logger.info(Style.GREY(f\"Running On exit {f} {i}/{len(on_exit)}\"))\n                    if asyncio.iscoroutinefunction(f_):\n                        o = await f_()\n                    else:\n                        o = f_()\n                    if o is not None:\n                        self.print(f\"Function On Exit result: {o}\")\n                else:\n                    self.logger.warning(\"closing function not found\")\n            except Exception as e:\n                self.logger.debug(\n                    Style.YELLOW(Style.Bold(f\"modular:{mod_name}.{f} on_exit error {i}/{len(on_exit)} -&gt; {e}\")))\n                self.debug_rains(e)\n            finally:\n                i += 1\n\n        helper()\n\n        if delete:\n            self.functions[mod_name] = {}\n            del self.functions[mod_name]\n\n    def exit(self, remove_all=True):\n        if not self.alive:\n            return\n        if self.args_sto.debug:\n            self.hide_console()\n        self.disconnect()\n        if remove_all:\n            self.remove_all_modules()\n        self.logger.info(\"Exiting ToolBox interface\")\n        self.alive = False\n        self.called_exit = True, time.time()\n        self.save_exit()\n        if hasattr(self, 'root_blob_storage') and self.root_blob_storage:\n            self.root_blob_storage.exit()\n        try:\n            self.config_fh.save_file_handler()\n        except SystemExit:\n            print(\"If u ar testing this is fine else ...\")\n\n        if hasattr(self, 'daemon_app'):\n            import threading\n\n            for thread in threading.enumerate()[::-1]:\n                if thread.name == \"MainThread\":\n                    continue\n                try:\n                    with Spinner(f\"closing Thread {thread.name:^50}|\", symbols=\"s\", count_down=True,\n                                 time_in_s=0.751 if not self.debug else 0.6):\n                        thread.join(timeout=0.751 if not self.debug else 0.6)\n                except TimeoutError as e:\n                    self.logger.error(f\"Timeout error on exit {thread.name} {str(e)}\")\n                    print(str(e), f\"Timeout {thread.name}\")\n                except KeyboardInterrupt:\n                    print(\"Unsave Exit\")\n                    break\n        if hasattr(self, 'loop') and self.loop is not None:\n            with Spinner(\"closing Event loop:\", symbols=\"+\"):\n                self.loop.stop()\n\n    async def a_exit(self):\n        await self.a_remove_all_modules(delete=True)\n        results = await asyncio.gather(\n            *[asyncio.create_task(f()) for f in self.exit_tasks if asyncio.iscoroutinefunction(f)])\n        for result in results:\n            self.print(f\"Function On Exit result: {result}\")\n        self.exit(remove_all=False)\n\n    def save_load(self, modname, spec='app'):\n        self.logger.debug(f\"Save load module {modname}\")\n        if not modname:\n            self.logger.warning(\"no filename specified\")\n            return False\n        try:\n            return self.load_mod(modname, spec=spec)\n        except ModuleNotFoundError as e:\n            self.logger.error(Style.RED(f\"Module {modname} not found\"))\n            self.debug_rains(e)\n\n        return False\n\n    def get_function(self, name: Enum or tuple, **kwargs):\n        \"\"\"\n        Kwargs for _get_function\n            metadata:: return the registered function dictionary\n                stateless: (function_data, None), 0\n                stateful: (function_data, higher_order_function), 0\n            state::boolean\n                specification::str default app\n        \"\"\"\n        if isinstance(name, tuple):\n            return self._get_function(None, as_str=name, **kwargs)\n        else:\n            return self._get_function(name, **kwargs)\n\n    async def a_run_function(self, mod_function_name: Enum or tuple,\n                             tb_run_function_with_state=True,\n                             tb_run_with_specification='app',\n                             args_=None,\n                             kwargs_=None,\n                             *args,\n                             **kwargs) -&gt; Result:\n\n        if kwargs_ is not None and not kwargs:\n            kwargs = kwargs_\n        if args_ is not None and not args:\n            args = args_\n        if isinstance(mod_function_name, tuple):\n            modular_name, function_name = mod_function_name\n        elif isinstance(mod_function_name, list):\n            modular_name, function_name = mod_function_name[0], mod_function_name[1]\n        elif isinstance(mod_function_name, Enum):\n            modular_name, function_name = mod_function_name.__class__.NAME.value, mod_function_name.value\n        else:\n            raise TypeError(\"Unknown function type\")\n\n        if tb_run_with_specification == 'ws_internal':\n            modular_name = modular_name.split('/')[0]\n            if not self.mod_online(modular_name, installed=True):\n                self.get_mod(modular_name)\n            handler_id, event_name = mod_function_name\n            if handler_id in self.websocket_handlers and event_name in self.websocket_handlers[handler_id]:\n                handler_func = self.websocket_handlers[handler_id][event_name]\n                try:\n                    # F\u00fchre den asynchronen Handler aus\n                    if inspect.iscoroutinefunction(handler_func):\n                        await handler_func(self, **kwargs)\n                    else:\n                        handler_func(self, **kwargs)  # F\u00fcr synchrone Handler\n                    return Result.ok(info=f\"WS handler '{event_name}' executed.\")\n                except Exception as e:\n                    self.logger.error(f\"Error in WebSocket handler '{handler_id}/{event_name}': {e}\", exc_info=True)\n                    return Result.default_internal_error(info=str(e))\n            else:\n                # Kein Handler registriert, aber das ist kein Fehler (z.B. on_connect ist optional)\n                return Result.ok(info=f\"No WS handler for '{event_name}'.\")\n\n        if not self.mod_online(modular_name, installed=True):\n            self.get_mod(modular_name)\n\n        function_data, error_code = self.get_function(mod_function_name, state=tb_run_function_with_state,\n                                                      metadata=True, specification=tb_run_with_specification)\n        self.logger.info(f\"Received fuction : {mod_function_name}, with execode: {error_code}\")\n        if error_code == 404:\n            mod = self.get_mod(modular_name)\n            if hasattr(mod, \"async_initialized\") and not mod.async_initialized:\n                await mod\n            function_data, error_code = self.get_function(mod_function_name, state=tb_run_function_with_state,\n                                                          metadata=True, specification=tb_run_with_specification)\n\n        if error_code == 404:\n            self.logger.warning(Style.RED(\"Function Not Found\"))\n            return (Result.default_user_error(interface=self.interface_type,\n                                              exec_code=404,\n                                              info=\"function not found function is not decorated\").\n                    set_origin(mod_function_name))\n\n        if error_code == 300:\n            return Result.default_internal_error(interface=self.interface_type,\n                                                 info=f\"module {modular_name}\"\n                                                      f\" has no state (instance)\").set_origin(mod_function_name)\n\n        if error_code != 0:\n            return Result.default_internal_error(interface=self.interface_type,\n                                                 exec_code=error_code,\n                                                 info=f\"Internal error\"\n                                                      f\" {modular_name}.\"\n                                                      f\"{function_name}\").set_origin(mod_function_name)\n\n        if not tb_run_function_with_state:\n            function_data, _ = function_data\n            function = function_data.get('func')\n        else:\n            function_data, function = function_data\n\n        if not function:\n            self.logger.warning(Style.RED(f\"Function {function_name} not found\"))\n            return Result.default_internal_error(interface=self.interface_type,\n                                                 exec_code=404,\n                                                 info=\"function not found function\").set_origin(mod_function_name)\n\n        self.logger.info(\"Profiling function\")\n        t0 = time.perf_counter()\n        if asyncio.iscoroutinefunction(function):\n            return await self.a_fuction_runner(function, function_data, args, kwargs, t0)\n        else:\n            return self.fuction_runner(function, function_data, args, kwargs, t0)\n\n\n    def run_function(self, mod_function_name: Enum or tuple,\n                     tb_run_function_with_state=True,\n                     tb_run_with_specification='app',\n                     args_=None,\n                     kwargs_=None,\n                     *args,\n                     **kwargs) -&gt; Result:\n\n        if kwargs_ is not None and not kwargs:\n            kwargs = kwargs_\n        if args_ is not None and not args:\n            args = args_\n        if isinstance(mod_function_name, tuple):\n            modular_name, function_name = mod_function_name\n        elif isinstance(mod_function_name, list):\n            modular_name, function_name = mod_function_name[0], mod_function_name[1]\n        elif isinstance(mod_function_name, Enum):\n            modular_name, function_name = mod_function_name.__class__.NAME.value, mod_function_name.value\n        else:\n            raise TypeError(\"Unknown function type\")\n\n        if not self.mod_online(modular_name, installed=True):\n            self.get_mod(modular_name)\n\n        if tb_run_with_specification == 'ws_internal':\n            handler_id, event_name = mod_function_name\n            if handler_id in self.websocket_handlers and event_name in self.websocket_handlers[handler_id]:\n                handler_func = self.websocket_handlers[handler_id][event_name]\n                try:\n                    # F\u00fchre den asynchronen Handler aus\n                    if inspect.iscoroutinefunction(handler_func):\n                        return self.loop.run_until_complete(handler_func(self, **kwargs))\n                    else:\n                        handler_func(self, **kwargs)  # F\u00fcr synchrone Handler\n                    return Result.ok(info=f\"WS handler '{event_name}' executed.\")\n                except Exception as e:\n                    self.logger.error(f\"Error in WebSocket handler '{handler_id}/{event_name}': {e}\", exc_info=True)\n                    return Result.default_internal_error(info=str(e))\n            else:\n                # Kein Handler registriert, aber das ist kein Fehler (z.B. on_connect ist optional)\n                return Result.ok(info=f\"No WS handler for '{event_name}'.\")\n\n        function_data, error_code = self.get_function(mod_function_name, state=tb_run_function_with_state,\n                                                      metadata=True, specification=tb_run_with_specification)\n        self.logger.info(f\"Received fuction : {mod_function_name}, with execode: {error_code}\")\n        if error_code == 1 or error_code == 3 or error_code == 400:\n            self.get_mod(modular_name)\n            function_data, error_code = self.get_function(mod_function_name, state=tb_run_function_with_state,\n                                                          metadata=True, specification=tb_run_with_specification)\n\n        if error_code == 2:\n            self.logger.warning(Style.RED(\"Function Not Found\"))\n            return (Result.default_user_error(interface=self.interface_type,\n                                              exec_code=404,\n                                              info=\"function not found function is not decorated\").\n                    set_origin(mod_function_name))\n\n        if error_code == -1:\n            return Result.default_internal_error(interface=self.interface_type,\n                                                 info=f\"module {modular_name}\"\n                                                      f\" has no state (instance)\").set_origin(mod_function_name)\n\n        if error_code != 0:\n            return Result.default_internal_error(interface=self.interface_type,\n                                                 exec_code=error_code,\n                                                 info=f\"Internal error\"\n                                                      f\" {modular_name}.\"\n                                                      f\"{function_name}\").set_origin(mod_function_name)\n\n        if not tb_run_function_with_state:\n            function_data, _ = function_data\n            function = function_data.get('func')\n        else:\n            function_data, function = function_data\n\n        if not function:\n            self.logger.warning(Style.RED(f\"Function {function_name} not found\"))\n            return Result.default_internal_error(interface=self.interface_type,\n                                                 exec_code=404,\n                                                 info=\"function not found function\").set_origin(mod_function_name)\n\n        self.logger.info(\"Profiling function\")\n        t0 = time.perf_counter()\n        if asyncio.iscoroutinefunction(function):\n            raise ValueError(f\"Fuction {function_name} is Async use a_run_any\")\n        else:\n            return self.fuction_runner(function, function_data, args, kwargs, t0)\n\n    def run_a_from_sync(self, function, *args, **kwargs):\n        # Initialize self.loop if not already set.\n        if self.loop is None:\n            try:\n                self.loop = asyncio.get_running_loop()\n            except RuntimeError:\n                self.loop = asyncio.new_event_loop()\n\n        # If the loop is running, offload the coroutine to a new thread.\n        if self.loop.is_running():\n            result_future = Future()\n\n            def run_in_new_loop():\n                new_loop = asyncio.new_event_loop()\n                asyncio.set_event_loop(new_loop)\n                try:\n                    result = new_loop.run_until_complete(function(*args, **kwargs))\n                    result_future.set_result(result)\n                except Exception as e:\n                    result_future.set_exception(e)\n                finally:\n                    new_loop.close()\n\n            thread = threading.Thread(target=run_in_new_loop)\n            thread.start()\n            thread.join()  # Block until the thread completes.\n            return result_future.result()\n        else:\n            # If the loop is not running, schedule and run the coroutine directly.\n            future = self.loop.create_task(function(*args, **kwargs))\n            return self.loop.run_until_complete(future)\n\n    def fuction_runner(self, function, function_data: dict, args: list, kwargs: dict, t0=.0):\n\n        parameters = function_data.get('params')\n        modular_name = function_data.get('module_name')\n        function_name = function_data.get('func_name')\n        row = function_data.get('row')\n        mod_function_name = f\"{modular_name}.{function_name}\"\n\n        if_self_state = 1 if 'self' in parameters else 0\n\n        try:\n            if len(parameters) == 0:\n                res = function()\n            elif len(parameters) == len(args) + if_self_state:\n                res = function(*args)\n            elif len(parameters) == len(kwargs.keys()) + if_self_state:\n                res = function(**kwargs)\n            else:\n                res = function(*args, **kwargs)\n            self.logger.info(f\"Execution done in {time.perf_counter()-t0:.4f}\")\n            if isinstance(res, Result):\n                formatted_result = res\n                if formatted_result.origin is None:\n                    formatted_result.set_origin(mod_function_name)\n            elif isinstance(res, ApiResult):\n                formatted_result = res\n                if formatted_result.origin is None:\n                    formatted_result.as_result().set_origin(mod_function_name).to_api_result()\n            elif row:\n                formatted_result = res\n            else:\n                # Wrap the result in a Result object\n                formatted_result = Result.ok(\n                    interface=self.interface_type,\n                    data_info=\"Auto generated result\",\n                    data=res,\n                    info=\"Function executed successfully\"\n                ).set_origin(mod_function_name)\n            if not row:\n                self.logger.info(\n                    f\"Function Exec code: {formatted_result.info.exec_code} Info's: {formatted_result.info.help_text}\")\n            else:\n                self.logger.info(\n                    f\"Function Exec data: {formatted_result}\")\n        except Exception as e:\n            self.logger.error(\n                Style.YELLOW(Style.Bold(\n                    f\"! Function ERROR: in {modular_name}.{function_name}\")))\n            # Wrap the exception in a Result object\n            formatted_result = Result.default_internal_error(info=str(e)).set_origin(mod_function_name)\n            # res = formatted_result\n            self.logger.error(\n                f\"Function {modular_name}.{function_name}\"\n                f\" executed wit an error {str(e)}, {type(e)}\")\n            self.debug_rains(e)\n            self.print(f\"! Function ERROR: in {modular_name}.{function_name} \")\n\n\n\n        else:\n            self.print_ok()\n\n            self.logger.info(\n                f\"Function {modular_name}.{function_name}\"\n                f\" executed successfully\")\n\n        return formatted_result\n\n    async def a_fuction_runner(self, function, function_data: dict, args: list, kwargs: dict, t0=.0):\n\n        parameters = function_data.get('params')\n        modular_name = function_data.get('module_name')\n        function_name = function_data.get('func_name')\n        row = function_data.get('row')\n        mod_function_name = f\"{modular_name}.{function_name}\"\n\n        if_self_state = 1 if 'self' in parameters else 0\n\n        try:\n            if len(parameters) == 0:\n                res = await function()\n            elif len(parameters) == len(args) + if_self_state:\n                res = await function(*args)\n            elif len(parameters) == len(kwargs.keys()) + if_self_state:\n                res = await function(**kwargs)\n            else:\n                res = await function(*args, **kwargs)\n            self.logger.info(f\"Execution done in {time.perf_counter()-t0:.4f}\")\n            if isinstance(res, Result):\n                formatted_result = res\n                if formatted_result.origin is None:\n                    formatted_result.set_origin(mod_function_name)\n            elif isinstance(res, ApiResult):\n                formatted_result = res\n                if formatted_result.origin is None:\n                    formatted_result.as_result().set_origin(mod_function_name).to_api_result()\n            elif row:\n                formatted_result = res\n            else:\n                # Wrap the result in a Result object\n                formatted_result = Result.ok(\n                    interface=self.interface_type,\n                    data_info=\"Auto generated result\",\n                    data=res,\n                    info=\"Function executed successfully\"\n                ).set_origin(mod_function_name)\n            if not row:\n                self.logger.info(\n                    f\"Function Exec code: {formatted_result.info.exec_code} Info's: {formatted_result.info.help_text}\")\n            else:\n                self.logger.info(\n                    f\"Function Exec data: {formatted_result}\")\n        except Exception as e:\n            self.logger.error(\n                Style.YELLOW(Style.Bold(\n                    f\"! Function ERROR: in {modular_name}.{function_name}\")))\n            # Wrap the exception in a Result object\n            formatted_result = Result.default_internal_error(info=str(e)).set_origin(mod_function_name)\n            # res = formatted_result\n            self.logger.error(\n                f\"Function {modular_name}.{function_name}\"\n                f\" executed wit an error {str(e)}, {type(e)}\")\n            self.debug_rains(e)\n\n        else:\n            self.print_ok()\n\n            self.logger.info(\n                f\"Function {modular_name}.{function_name}\"\n                f\" executed successfully\")\n\n        return formatted_result\n\n    async def run_http(self, mod_function_name: Enum or str or tuple, function_name=None,\n                       args_=None,\n                       kwargs_=None, method=\"GET\",\n                       *args, **kwargs):\n        if kwargs_ is not None and not kwargs:\n            kwargs = kwargs_\n        if args_ is not None and not args:\n            args = args_\n\n        modular_name = mod_function_name\n        function_name = function_name\n\n        if isinstance(mod_function_name, str) and isinstance(function_name, str):\n            mod_function_name = (mod_function_name, function_name)\n\n        if isinstance(mod_function_name, tuple):\n            modular_name, function_name = mod_function_name\n        elif isinstance(mod_function_name, list):\n            modular_name, function_name = mod_function_name[0], mod_function_name[1]\n        elif isinstance(mod_function_name, Enum):\n            modular_name, function_name = mod_function_name.__class__.NAME.value, mod_function_name.value\n\n        self.logger.info(f\"getting function : {modular_name}.{function_name} from http {self.session.base}\")\n        r = await self.session.fetch(f\"/api/{modular_name}/{function_name}{'?' + args_ if args_ is not None else ''}\",\n                                     data=kwargs, method=method)\n        try:\n            if not r:\n                print(\"\u00a7 Session server Offline!\", self.session.base)\n                return Result.default_internal_error(info=\"Session fetch failed\").as_dict()\n\n            content_type = r.headers.get('Content-Type', '').lower()\n\n            if 'application/json' in content_type:\n                try:\n                    return r.json()\n                except Exception as e:\n                    print(f\"\u26a0 JSON decode error: {e}\")\n                    # Fallback to text if JSON decoding fails\n                    text = r.text\n            else:\n                text = r.text\n\n            if isinstance(text, Callable):\n                if asyncio.iscoroutinefunction(text):\n                    text = await text()\n                else:\n                    text = text()\n\n            # Attempt YAML\n            if 'yaml' in content_type or text.strip().startswith('---'):\n                try:\n                    import yaml\n                    return yaml.safe_load(text)\n                except Exception as e:\n                    print(f\"\u26a0 YAML decode error: {e}\")\n\n            # Attempt XML\n            if 'xml' in content_type or text.strip().startswith('&lt;?xml'):\n                try:\n                    import xmltodict\n                    return xmltodict.parse(text)\n                except Exception as e:\n                    print(f\"\u26a0 XML decode error: {e}\")\n\n            # Fallback: return plain text\n            return Result.default_internal_error(data={'raw_text': text, 'content_type': content_type}).as_dict()\n\n        except Exception as e:\n            print(\"\u274c Fatal error during API call:\", e)\n            self.debug_rains(e)\n            return Result.default_internal_error(str(e)).as_dict()\n\n    def run_local(self, *args, **kwargs):\n        return self.run_any(*args, **kwargs)\n\n    async def a_run_local(self, *args, **kwargs):\n        return await self.a_run_any(*args, **kwargs)\n\n    def run_any(self, mod_function_name: Enum or str or tuple, backwords_compability_variabel_string_holder=None,\n                get_results=False, tb_run_function_with_state=True, tb_run_with_specification='app', args_=None,\n                kwargs_=None,\n                *args, **kwargs):\n\n        # if self.debug:\n        #     self.logger.info(f'Called from: {getouterframes(currentframe(), 2)}')\n\n        if kwargs_ is not None and not kwargs:\n            kwargs = kwargs_\n        if args_ is not None and not args:\n            args = args_\n\n        if isinstance(mod_function_name, str) and backwords_compability_variabel_string_holder is None:\n            backwords_compability_variabel_string_holder = mod_function_name.split('.')[-1]\n            mod_function_name = mod_function_name.replace(f\".{backwords_compability_variabel_string_holder}\", \"\")\n\n        if isinstance(mod_function_name, str) and isinstance(backwords_compability_variabel_string_holder, str):\n            mod_function_name = (mod_function_name, backwords_compability_variabel_string_holder)\n\n        res: Result = self.run_function(mod_function_name,\n                                        tb_run_function_with_state=tb_run_function_with_state,\n                                        tb_run_with_specification=tb_run_with_specification,\n                                        args_=args, kwargs_=kwargs).as_result()\n        if isinstance(res, ApiResult):\n            res = res.as_result()\n\n        if isinstance(res, Result) and res.bg_task is not None:\n            self.run_bg_task(res.bg_task)\n\n        if self.debug:\n            res.log(show_data=False)\n\n        if not get_results and isinstance(res, Result):\n            return res.get()\n\n        if get_results and not isinstance(res, Result):\n            return Result.ok(data=res)\n\n        return res\n\n    async def a_run_any(self, mod_function_name: Enum or str or tuple,\n                        backwords_compability_variabel_string_holder=None,\n                        get_results=False, tb_run_function_with_state=True, tb_run_with_specification='app', args_=None,\n                        kwargs_=None,\n                        *args, **kwargs):\n\n        # if self.debug:\n        #     self.logger.info(f'Called from: {getouterframes(currentframe(), 2)}')\n\n        if kwargs_ is not None and not kwargs:\n            kwargs = kwargs_\n        if args_ is not None and not args:\n            args = args_\n\n        if isinstance(mod_function_name, str) and backwords_compability_variabel_string_holder is None:\n            backwords_compability_variabel_string_holder = mod_function_name.split('.')[-1]\n            mod_function_name = mod_function_name.replace(f\".{backwords_compability_variabel_string_holder}\", \"\")\n\n        if isinstance(mod_function_name, str) and isinstance(backwords_compability_variabel_string_holder, str):\n            mod_function_name = (mod_function_name, backwords_compability_variabel_string_holder)\n\n        res: Result = await self.a_run_function(mod_function_name,\n                                                tb_run_function_with_state=tb_run_function_with_state,\n                                                tb_run_with_specification=tb_run_with_specification,\n                                                args_=args, kwargs_=kwargs)\n        if isinstance(res, ApiResult):\n            res = res.as_result()\n\n        if isinstance(res, Result) and res.bg_task is not None:\n            self.run_bg_task(res.bg_task)\n\n        if self.debug:\n            res.print()\n            res.log(show_data=False) if isinstance(res, Result) else self.logger.debug(res)\n        if not get_results and isinstance(res, Result):\n            return res.get()\n\n        if get_results and not isinstance(res, Result):\n            return Result.ok(data=res)\n\n        return res\n\n\n    def web_context(self):\n        if self._web_context is None:\n            try:\n                self._web_context = open(\"./dist/helper.html\", encoding=\"utf-8\").read()\n            except Exception as e:\n                self.logger.error(f\"Could not load web context: {e}\")\n                self._web_context = \"&lt;div&gt;&lt;h1&gt;Web Context not found&lt;/h1&gt;&lt;/div&gt;\"\n        return self._web_context\n\n    def get_mod(self, name, spec='app') -&gt; ModuleType or MainToolType:\n        if spec != \"app\":\n            self.print(f\"Getting Module {name} spec: {spec}\")\n        if name not in self.functions:\n            mod = self.save_load(name, spec=spec)\n            if mod is False or (isinstance(mod, Result) and mod.is_error()):\n                self.logger.warning(f\"Could not find {name} in {list(self.functions.keys())}\")\n                raise ValueError(f\"Could not find {name} in {list(self.functions.keys())} pleas install the module, or its posibly broken use --debug for infos\")\n        # private = self.functions[name].get(f\"{spec}_private\")\n        # if private is not None:\n        #     if private and spec != 'app':\n        #         raise ValueError(\"Module is private\")\n        if name not in self.functions:\n            self.logger.warning(f\"Module '{name}' is not found\")\n            return None\n        instance = self.functions[name].get(f\"{spec}_instance\")\n        if instance is None:\n            return self.load_mod(name, spec=spec)\n        return self.functions[name].get(f\"{spec}_instance\")\n\n    def print(self, text=\"\", *args, **kwargs):\n        # self.logger.info(f\"Output : {text}\")\n        if 'live' in self.id:\n            return\n\n        flush = kwargs.pop('flush', True)\n        if self.sprint(None):\n            print(Style.CYAN(f\"System${self.id}:\"), end=\" \", flush=flush)\n        print(text, *args, **kwargs, flush=flush)\n\n    def sprint(self, text=\"\", *args, **kwargs):\n        if text is None:\n            return True\n        if 'live' in self.id:\n            return\n        flush = kwargs.pop('flush', True)\n        # self.logger.info(f\"Output : {text}\")\n        print(Style.CYAN(f\"System${self.id}:\"), end=\" \", flush=flush)\n        if isinstance(text, str) and kwargs == {} and text:\n            stram_print(text + ' '.join(args))\n            print()\n        else:\n            print(text, *args, **kwargs, flush=flush)\n\n    # ----------------------------------------------------------------\n    # Decorators for the toolbox\n\n    def reload_mod(self, mod_name, spec='app', is_file=True, loc=\"toolboxv2.mods.\"):\n        self.remove_mod(mod_name, delete=True)\n        if mod_name not in self.modules:\n            self.logger.warning(f\"Module '{mod_name}' is not found\")\n            return\n        if hasattr(self.modules[mod_name], 'reload_save') and self.modules[mod_name].reload_save:\n            def reexecute_module_code(x):\n                return x\n        else:\n            def reexecute_module_code(module_name):\n                if isinstance(module_name, str):\n                    module = import_module(module_name)\n                else:\n                    module = module_name\n                # Get the source code of the module\n                try:\n                    source = inspect.getsource(module)\n                except Exception:\n                    # print(f\"No source for {str(module_name).split('from')[0]}: {e}\")\n                    return module\n                # Compile the source code\n                try:\n                    code = compile(source, module.__file__, 'exec')\n                    # Execute the code in the module's namespace\n                    exec(code, module.__dict__)\n                except Exception:\n                    # print(f\"No source for {str(module_name).split('from')[0]}: {e}\")\n                    pass\n                return module\n\n        if not is_file:\n            mods = self.get_all_mods(\"./mods/\" + mod_name)\n            def recursive_reload(package_name):\n                package = import_module(package_name)\n\n                # First, reload all submodules\n                if hasattr(package, '__path__'):\n                    for _finder, name, _ispkg in pkgutil.walk_packages(package.__path__, package.__name__ + \".\"):\n                        try:\n                            mod = import_module(name)\n                            reexecute_module_code(mod)\n                            reload(mod)\n                        except Exception as e:\n                            print(f\"Error reloading module {name}: {e}\")\n                            break\n\n                # Finally, reload the package itself\n                reexecute_module_code(package)\n                reload(package)\n\n            for mod in mods:\n                if mod.endswith(\".txt\") or mod.endswith(\".yaml\"):\n                    continue\n                try:\n                    recursive_reload(loc + mod_name + '.' + mod)\n                    self.print(f\"Reloaded {mod_name}.{mod}\")\n                except ImportError:\n                    self.print(f\"Could not load {mod_name}.{mod}\")\n        reexecute_module_code(self.modules[mod_name])\n        if mod_name in self.functions:\n            if \"on_exit\" in self.functions[mod_name]:\n                self.functions[mod_name][\"on_exit\"] = []\n            if \"on_start\" in self.functions[mod_name]:\n                self.functions[mod_name][\"on_start\"] = []\n        self.inplace_load_instance(mod_name, spec=spec, mfo=reload(self.modules[mod_name]) if mod_name in self.modules else None)\n\n    def watch_mod(self, mod_name, spec='app', loc=\"toolboxv2.mods.\", use_thread=True, path_name=None, on_reload=None):\n        if path_name is None:\n            path_name = mod_name\n        is_file = os.path.isfile(self.start_dir + '/mods/' + path_name + '.py')\n        import watchfiles\n        def helper():\n            paths = f'mods/{path_name}' + ('.py' if is_file else '')\n            self.logger.info(f'Watching Path: {paths}')\n            try:\n                for changes in watchfiles.watch(paths):\n                    if not changes:\n                        continue\n                    self.reload_mod(mod_name, spec, is_file, loc)\n                    if on_reload:\n                        on_reload()\n            except FileNotFoundError:\n                self.logger.warning(f\"Path {paths} not found\")\n\n        if not use_thread:\n            helper()\n        else:\n            threading.Thread(target=helper, daemon=True).start()\n\n    def _register_function(self, module_name, func_name, data):\n        if module_name not in self.functions:\n            self.functions[module_name] = {}\n        if func_name in self.functions[module_name]:\n            self.print(f\"Overriding function {func_name} from {module_name}\", end=\"\\r\")\n            self.functions[module_name][func_name] = data\n        else:\n            self.functions[module_name][func_name] = data\n\n    def _create_decorator(self, type_: str,\n                          name: str = \"\",\n                          mod_name: str = \"\",\n                          level: int = -1,\n                          restrict_in_virtual_mode: bool = False,\n                          api: bool = False,\n                          helper: str = \"\",\n                          version: str or None = None,\n                          initial: bool=False,\n                          exit_f: bool=False,\n                          test: bool=True,\n                          samples:list[dict[str, Any]] | None=None,\n                          state:bool | None=None,\n                          pre_compute:Callable | None=None,\n                          post_compute:Callable[[], Result] | None=None,\n                          api_methods:list[str] | None=None,\n                          memory_cache: bool=False,\n                          file_cache: bool=False,\n                          request_as_kwarg: bool=False,\n                          row: bool=False,\n                          memory_cache_max_size:int=100,\n                          memory_cache_ttl:int=300,\n                          websocket_handler: str | None = None,\n                          ):\n\n        if isinstance(type_, Enum):\n            type_ = type_.value\n\n        if memory_cache and file_cache:\n            raise ValueError(\"Don't use both cash at the same time for the same fuction\")\n\n        use_cache = memory_cache or file_cache\n        cache = {}\n        if file_cache:\n            cache = FileCache(folder=self.data_dir + f'\\\\cache\\\\{mod_name}\\\\',\n                              filename=self.data_dir + f'\\\\cache\\\\{mod_name}\\\\{name}cache.db')\n        if memory_cache:\n            cache = MemoryCache(maxsize=memory_cache_max_size, ttl=memory_cache_ttl)\n\n        version = self.version if version is None else self.version + ':' + version\n\n        def a_additional_process(func):\n\n            async def executor(*args, **kwargs):\n\n                if pre_compute is not None:\n                    args, kwargs = await pre_compute(*args, **kwargs)\n                if asyncio.iscoroutinefunction(func):\n                    result = await func(*args, **kwargs)\n                else:\n                    result = func(*args, **kwargs)\n                if post_compute is not None:\n                    result = await post_compute(result)\n                if row:\n                    return result\n                if not isinstance(result, Result):\n                    result = Result.ok(data=result)\n                if result.origin is None:\n                    result.set_origin((mod_name if mod_name else func.__module__.split('.')[-1]\n                                       , name if name else func.__name__\n                                       , type_))\n                if result.result.data_to == ToolBoxInterfaces.native.name:\n                    result.result.data_to = ToolBoxInterfaces.remote if api else ToolBoxInterfaces.native\n                # Wenden Sie die to_api_result Methode auf das Ergebnis an, falls verf\u00fcgbar\n                if api and hasattr(result, 'to_api_result'):\n                    return result.to_api_result()\n                return result\n\n            @wraps(func)\n            async def wrapper(*args, **kwargs):\n\n                if not use_cache:\n                    return await executor(*args, **kwargs)\n\n                try:\n                    cache_key = (f\"{mod_name if mod_name else func.__module__.split('.')[-1]}\"\n                                 f\"-{func.__name__}-{str(args)},{str(kwargs.items())}\")\n                except ValueError:\n                    cache_key = (f\"{mod_name if mod_name else func.__module__.split('.')[-1]}\"\n                                 f\"-{func.__name__}-{bytes(args)},{str(kwargs.items())}\")\n\n                result = cache.get(cache_key)\n                if result is not None:\n                    return result\n\n                result = await executor(*args, **kwargs)\n\n                cache.set(cache_key, result)\n\n                return result\n\n            return wrapper\n\n        def additional_process(func):\n\n            def executor(*args, **kwargs):\n\n                if pre_compute is not None:\n                    args, kwargs = pre_compute(*args, **kwargs)\n                if asyncio.iscoroutinefunction(func):\n                    result = func(*args, **kwargs)\n                else:\n                    result = func(*args, **kwargs)\n                if post_compute is not None:\n                    result = post_compute(result)\n                if row:\n                    return result\n                if not isinstance(result, Result):\n                    result = Result.ok(data=result)\n                if result.origin is None:\n                    result.set_origin((mod_name if mod_name else func.__module__.split('.')[-1]\n                                       , name if name else func.__name__\n                                       , type_))\n                if result.result.data_to == ToolBoxInterfaces.native.name:\n                    result.result.data_to = ToolBoxInterfaces.remote if api else ToolBoxInterfaces.native\n                # Wenden Sie die to_api_result Methode auf das Ergebnis an, falls verf\u00fcgbar\n                if api and hasattr(result, 'to_api_result'):\n                    return result.to_api_result()\n                return result\n\n            @wraps(func)\n            def wrapper(*args, **kwargs):\n\n                if not use_cache:\n                    return executor(*args, **kwargs)\n\n                try:\n                    cache_key = (f\"{mod_name if mod_name else func.__module__.split('.')[-1]}\"\n                                 f\"-{func.__name__}-{str(args)},{str(kwargs.items())}\")\n                except ValueError:\n                    cache_key = (f\"{mod_name if mod_name else func.__module__.split('.')[-1]}\"\n                                 f\"-{func.__name__}-{bytes(args)},{str(kwargs.items())}\")\n\n                result = cache.get(cache_key)\n                if result is not None:\n                    return result\n\n                result = executor(*args, **kwargs)\n\n                cache.set(cache_key, result)\n\n                return result\n\n            return wrapper\n\n        def decorator(func):\n            sig = signature(func)\n            params = list(sig.parameters)\n            module_name = mod_name if mod_name else func.__module__.split('.')[-1]\n            func_name = name if name else func.__name__\n            if func_name == 'on_start':\n                func_name = 'on_startup'\n            if func_name == 'on_exit':\n                func_name = 'on_close'\n            if api or pre_compute is not None or post_compute is not None or memory_cache or file_cache:\n                if asyncio.iscoroutinefunction(func):\n                    func = a_additional_process(func)\n                else:\n                    func = additional_process(func)\n            if api and str(sig.return_annotation) == 'Result':\n                raise ValueError(f\"Fuction {module_name}.{func_name} registered as \"\n                                 f\"Api fuction but uses {str(sig.return_annotation)}\\n\"\n                                 f\"Please change the sig from ..)-&gt; Result to ..)-&gt; ApiResult\")\n            data = {\n                \"type\": type_,\n                \"module_name\": module_name,\n                \"func_name\": func_name,\n                \"level\": level,\n                \"restrict_in_virtual_mode\": restrict_in_virtual_mode,\n                \"func\": func,\n                \"api\": api,\n                \"helper\": helper,\n                \"version\": version,\n                \"initial\": initial,\n                \"exit_f\": exit_f,\n                \"api_methods\": api_methods if api_methods is not None else [\"AUTO\"],\n                \"__module__\": func.__module__,\n                \"signature\": sig,\n                \"params\": params,\n                \"row\": row,\n                \"state\": (\n                    False if len(params) == 0 else params[0] in ['self', 'state', 'app']) if state is None else state,\n                \"do_test\": test,\n                \"samples\": samples,\n                \"request_as_kwarg\": request_as_kwarg,\n\n            }\n\n            if websocket_handler:\n                # Die dekorierte Funktion sollte ein Dict mit den Handlern zur\u00fcckgeben\n                try:\n                    handler_config = func(self)  # Rufe die Funktion auf, um die Konfiguration zu erhalten\n                    if not isinstance(handler_config, dict):\n                        raise TypeError(\n                            f\"WebSocket handler function '{func.__name__}' must return a dictionary of handlers.\")\n\n                    # Handler-Identifikator, z.B. \"ChatModule/room_chat\"\n                    handler_id = f\"{module_name}/{websocket_handler}\"\n                    self.websocket_handlers[handler_id] = {}\n\n                    for event_name, handler_func in handler_config.items():\n                        if event_name in [\"on_connect\", \"on_message\", \"on_disconnect\"] and callable(handler_func):\n                            self.websocket_handlers[handler_id][event_name] = handler_func\n                        else:\n                            self.logger.warning(f\"Invalid WebSocket handler event '{event_name}' in '{handler_id}'.\")\n\n                    self.logger.info(f\"Registered WebSocket handlers for '{handler_id}'.\")\n\n                except Exception as e:\n                    self.logger.error(f\"Failed to register WebSocket handlers for '{func.__name__}': {e}\",\n                                      exc_info=True)\n            else:\n                self._register_function(module_name, func_name, data)\n\n            if exit_f:\n                if \"on_exit\" not in self.functions[module_name]:\n                    self.functions[module_name][\"on_exit\"] = []\n                self.functions[module_name][\"on_exit\"].append(func_name)\n            if initial:\n                if \"on_start\" not in self.functions[module_name]:\n                    self.functions[module_name][\"on_start\"] = []\n                self.functions[module_name][\"on_start\"].append(func_name)\n\n            return func\n\n        decorator.tb_init = True\n\n        return decorator\n\n    def tb(self, name=None,\n           mod_name: str = \"\",\n           helper: str = \"\",\n           version: str | None = None,\n           test: bool = True,\n           restrict_in_virtual_mode: bool = False,\n           api: bool = False,\n           initial: bool = False,\n           exit_f: bool = False,\n           test_only: bool = False,\n           memory_cache: bool = False,\n           file_cache: bool = False,\n           request_as_kwarg: bool = False,\n           row: bool = False,\n           state: bool | None = None,\n           level: int = -1,\n           memory_cache_max_size: int = 100,\n           memory_cache_ttl: int = 300,\n           samples: list or dict or None = None,\n           interface: ToolBoxInterfaces or None or str = None,\n           pre_compute=None,\n           post_compute=None,\n           api_methods=None,\n           websocket_handler: str | None = None,\n           ):\n        \"\"\"\n    A decorator for registering and configuring functions within a module.\n\n    This decorator is used to wrap functions with additional functionality such as caching, API conversion, and lifecycle management (initialization and exit). It also handles the registration of the function in the module's function registry.\n\n    Args:\n        name (str, optional): The name to register the function under. Defaults to the function's own name.\n        mod_name (str, optional): The name of the module the function belongs to.\n        helper (str, optional): A helper string providing additional information about the function.\n        version (str or None, optional): The version of the function or module.\n        test (bool, optional): Flag to indicate if the function is for testing purposes.\n        restrict_in_virtual_mode (bool, optional): Flag to restrict the function in virtual mode.\n        api (bool, optional): Flag to indicate if the function is part of an API.\n        initial (bool, optional): Flag to indicate if the function should be executed at initialization.\n        exit_f (bool, optional): Flag to indicate if the function should be executed at exit.\n        test_only (bool, optional): Flag to indicate if the function should only be used for testing.\n        memory_cache (bool, optional): Flag to enable memory caching for the function.\n        request_as_kwarg (bool, optional): Flag to get request if the fuction is calld from api.\n        file_cache (bool, optional): Flag to enable file caching for the function.\n        row (bool, optional): rather to auto wrap the result in Result type default False means no row data aka result type\n        state (bool or None, optional): Flag to indicate if the function maintains state.\n        level (int, optional): The level of the function, used for prioritization or categorization.\n        memory_cache_max_size (int, optional): Maximum size of the memory cache.\n        memory_cache_ttl (int, optional): Time-to-live for the memory cache entries.\n        samples (list or dict or None, optional): Samples or examples of function usage.\n        interface (str, optional): The interface type for the function.\n        pre_compute (callable, optional): A function to be called before the main function.\n        post_compute (callable, optional): A function to be called after the main function.\n        api_methods (list[str], optional): default [\"AUTO\"] (GET if not params, POST if params) , GET, POST, PUT or DELETE.\n        websocket_handler (str, optional): The name of the websocket handler to use.\n\n    Returns:\n        function: The decorated function with additional processing and registration capabilities.\n    \"\"\"\n        if interface is None:\n            interface = \"tb\"\n        if test_only and 'test' not in self.id:\n            return lambda *args, **kwargs: args\n        return self._create_decorator(interface,\n                                      name,\n                                      mod_name,\n                                      level=level,\n                                      restrict_in_virtual_mode=restrict_in_virtual_mode,\n                                      helper=helper,\n                                      api=api,\n                                      version=version,\n                                      initial=initial,\n                                      exit_f=exit_f,\n                                      test=test,\n                                      samples=samples,\n                                      state=state,\n                                      pre_compute=pre_compute,\n                                      post_compute=post_compute,\n                                      memory_cache=memory_cache,\n                                      file_cache=file_cache,\n                                      request_as_kwarg=request_as_kwarg,\n                                      row=row,\n                                      api_methods=api_methods,\n                                      memory_cache_max_size=memory_cache_max_size,\n                                      memory_cache_ttl=memory_cache_ttl,\n                                      websocket_handler=websocket_handler,\n                                      )\n\n    def save_autocompletion_dict(self):\n        autocompletion_dict = {}\n        for module_name, _module in self.functions.items():\n            data = {}\n            for function_name, function_data in self.functions[module_name].items():\n                if not isinstance(function_data, dict):\n                    continue\n                data[function_name] = {arg: None for arg in\n                                       function_data.get(\"params\", [])}\n                if len(data[function_name].keys()) == 0:\n                    data[function_name] = None\n            autocompletion_dict[module_name] = data if len(data.keys()) &gt; 0 else None\n        self.config_fh.add_to_save_file_handler(\"auto~~~~~~\", str(autocompletion_dict))\n\n    def get_autocompletion_dict(self):\n        return self.config_fh.get_file_handler(\"auto~~~~~~\")\n\n    def save_registry_as_enums(self, directory: str, filename: str):\n        # Ordner erstellen, falls nicht vorhanden\n        if not os.path.exists(directory):\n            os.makedirs(directory)\n\n        # Dateipfad vorbereiten\n        filepath = os.path.join(directory, filename)\n\n        # Enum-Klassen als Strings generieren\n        enum_classes = [f'\"\"\"Automatic generated by ToolBox v = {self.version}\"\"\"'\n                        f'\\nfrom enum import Enum\\nfrom dataclasses import dataclass'\n                        f'\\n\\n\\n']\n        for module, functions in self.functions.items():\n            if module.startswith(\"APP_INSTANCE\"):\n                continue\n            class_name = module\n            enum_members = \"\\n    \".join(\n                [\n                    f\"{func_name.upper().replace('-', '')}\"\n                    f\" = '{func_name}' \"\n                    f\"# Input: ({fuction_data['params'] if isinstance(fuction_data, dict) else ''}),\"\n                    f\" Output: {fuction_data['signature'].return_annotation if isinstance(fuction_data, dict) else 'None'}\"\n                    for func_name, fuction_data in functions.items()])\n            enum_class = (f'@dataclass\\nclass {class_name.upper().replace(\".\", \"_\").replace(\"-\", \"\")}(Enum):'\n                          f\"\\n    NAME = '{class_name}'\\n    {enum_members}\")\n            enum_classes.append(enum_class)\n\n        # Enums in die Datei schreiben\n        data = \"\\n\\n\\n\".join(enum_classes)\n        if len(data) &lt; 12:\n            raise ValueError(\n                \"Invalid Enums Loosing content pleas delete it ur self in the (utils/system/all_functions_enums.py) or add mor new stuff :}\")\n        with open(filepath, 'w') as file:\n            file.write(data)\n\n        print(Style.Bold(Style.BLUE(f\"Enums gespeichert in {filepath}\")))\n\n\n    # WS logic\n\n    def _set_rust_ws_bridge(self, bridge_object: Any):\n        \"\"\"\n        Diese Methode wird von Rust aufgerufen, um die Kommunikationsbr\u00fccke zu setzen.\n        Sie darf NICHT manuell von Python aus aufgerufen werden.\n        \"\"\"\n        self.print(f\"Rust WebSocket bridge has been set for instance {self.id}.\")\n        self._rust_ws_bridge = bridge_object\n\n    async def ws_send(self, conn_id: str, payload: dict):\n        \"\"\"\n        Sendet eine Nachricht asynchron an eine einzelne WebSocket-Verbindung.\n\n        Args:\n            conn_id: Die eindeutige ID der Zielverbindung.\n            payload: Ein Dictionary, das als JSON gesendet wird.\n        \"\"\"\n        if self._rust_ws_bridge is None:\n            self.logger.error(\"Cannot send WebSocket message: Rust bridge is not initialized.\")\n            return\n\n        try:\n            # Ruft die asynchrone Rust-Methode auf und wartet auf deren Abschluss\n            await self._rust_ws_bridge.send_message(conn_id, json.dumps(payload))\n        except Exception as e:\n            self.logger.error(f\"Failed to send WebSocket message to {conn_id}: {e}\", exc_info=True)\n\n    async def ws_broadcast(self, channel_id: str, payload: dict, source_conn_id: str = \"python_broadcast\"):\n        \"\"\"\n        Sendet eine Nachricht asynchron an alle Clients in einem Kanal/Raum.\n\n        Args:\n            channel_id: Der Kanal, an den gesendet werden soll.\n            payload: Ein Dictionary, das als JSON gesendet wird.\n            source_conn_id (optional): Die ID der urspr\u00fcnglichen Verbindung, um Echos zu vermeiden.\n        \"\"\"\n        if self._rust_ws_bridge is None:\n            self.logger.error(\"Cannot broadcast WebSocket message: Rust bridge is not initialized.\")\n            return\n\n        try:\n            # Ruft die asynchrone Rust-Broadcast-Methode auf\n            await self._rust_ws_bridge.broadcast_message(channel_id, json.dumps(payload), source_conn_id)\n        except Exception as e:\n            self.logger.error(f\"Failed to broadcast WebSocket message to channel {channel_id}: {e}\", exc_info=True)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.toolbox.App.disconnect","title":"<code>disconnect(*args, **kwargs)</code>  <code>staticmethod</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/toolbox.py</code> <pre><code>@staticmethod\ndef disconnect(*args, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.toolbox.App.exit_main","title":"<code>exit_main(*args, **kwargs)</code>  <code>staticmethod</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/toolbox.py</code> <pre><code>@staticmethod\ndef exit_main(*args, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.toolbox.App.get_function","title":"<code>get_function(name, **kwargs)</code>","text":"<p>Kwargs for _get_function     metadata:: return the registered function dictionary         stateless: (function_data, None), 0         stateful: (function_data, higher_order_function), 0     state::boolean         specification::str default app</p> Source code in <code>toolboxv2/utils/toolbox.py</code> <pre><code>def get_function(self, name: Enum or tuple, **kwargs):\n    \"\"\"\n    Kwargs for _get_function\n        metadata:: return the registered function dictionary\n            stateless: (function_data, None), 0\n            stateful: (function_data, higher_order_function), 0\n        state::boolean\n            specification::str default app\n    \"\"\"\n    if isinstance(name, tuple):\n        return self._get_function(None, as_str=name, **kwargs)\n    else:\n        return self._get_function(name, **kwargs)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.toolbox.App.hide_console","title":"<code>hide_console(*args, **kwargs)</code>  <code>staticmethod</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/toolbox.py</code> <pre><code>@staticmethod\ndef hide_console(*args, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.toolbox.App.init_mod","title":"<code>init_mod(mod_name, spec='app')</code>","text":"<p>Initializes a module in a thread-safe manner by submitting the asynchronous initialization to the running event loop.</p> Source code in <code>toolboxv2/utils/toolbox.py</code> <pre><code>def init_mod(self, mod_name, spec='app'):\n    \"\"\"\n    Initializes a module in a thread-safe manner by submitting the\n    asynchronous initialization to the running event loop.\n    \"\"\"\n    if '.' in mod_name:\n        mod_name = mod_name.split('.')[0]\n    self.run_bg_task(self.a_init_mod, mod_name, spec)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.toolbox.App.run","title":"<code>run(*args, request=None, running_function_coro=None, **kwargs)</code>","text":"<p>Run a function with support for SSE streaming in both threaded and non-threaded contexts.</p> Source code in <code>toolboxv2/utils/toolbox.py</code> <pre><code>def run(self, *args, request=None, running_function_coro=None, **kwargs):\n    \"\"\"\n    Run a function with support for SSE streaming in both\n    threaded and non-threaded contexts.\n    \"\"\"\n    if running_function_coro is None:\n        mn, fn = args[0]\n        if self.functions.get(mn, {}).get(fn, {}).get('request_as_kwarg', False):\n            kwargs[\"request\"] = RequestData.from_dict(request)\n            if 'data' in kwargs and 'data' not in self.functions.get(mn, {}).get(fn, {}).get('params', []):\n                kwargs[\"request\"].data = kwargs[\"request\"].body = kwargs['data']\n                del kwargs['data']\n            if 'form_data' in kwargs and 'form_data' not in self.functions.get(mn, {}).get(fn, {}).get('params',\n                                                                                                       []):\n                kwargs[\"request\"].form_data = kwargs[\"request\"].body = kwargs['form_data']\n                del kwargs['form_data']\n\n    # Create the coroutine\n    coro = running_function_coro or self.a_run_any(*args, **kwargs)\n\n    # Get or create an event loop\n    try:\n        loop = asyncio.get_event_loop()\n        is_running = loop.is_running()\n    except RuntimeError:\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n        is_running = False\n\n    # If the loop is already running, run in a separate thread\n    if is_running:\n        # Create thread pool executor as needed\n        if not hasattr(self.__class__, '_executor'):\n            self.__class__._executor = ThreadPoolExecutor(max_workers=4)\n\n        def run_in_new_thread():\n            # Set up a new loop in this thread\n            new_loop = asyncio.new_event_loop()\n            asyncio.set_event_loop(new_loop)\n\n            try:\n                # Run the coroutine\n                return new_loop.run_until_complete(coro)\n            finally:\n                new_loop.close()\n\n        # Run in thread and get result\n        thread_result = self.__class__._executor.submit(run_in_new_thread).result()\n\n        # Handle streaming results from thread\n        if isinstance(thread_result, dict) and thread_result.get(\"is_stream\"):\n            # Create a new SSE stream in the main thread\n            async def stream_from_function():\n                # Re-run the function with direct async access\n                stream_result = await self.a_run_any(*args, **kwargs)\n\n                if (isinstance(stream_result, Result) and\n                    getattr(stream_result.result, 'data_type', None) == \"stream\"):\n                    # Get and forward data from the original generator\n                    original_gen = stream_result.result.data.get(\"generator\")\n                    if inspect.isasyncgen(original_gen):\n                        async for item in original_gen:\n                            yield item\n\n            # Return a new streaming Result\n            return Result.stream(\n                stream_generator=stream_from_function(),\n                headers=thread_result.get(\"headers\", {})\n            )\n\n        result = thread_result\n    else:\n        # Direct execution when loop is not running\n        result = loop.run_until_complete(coro)\n\n    # Process the final result\n    if isinstance(result, Result):\n        if 'debug' in self.id:\n            result.print()\n        if getattr(result.result, 'data_type', None) == \"stream\":\n            return result\n        return result.to_api_result().model_dump(mode='json')\n\n    return result\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.toolbox.App.run_bg_task","title":"<code>run_bg_task(task, *args, **kwargs)</code>","text":"<p>Runs a coroutine in the background without blocking the caller.</p> <p>This is the primary method for \"fire-and-forget\" async tasks. It schedules the coroutine to run on the application's main event loop.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>Callable</code> <p>The coroutine function to run.</p> required <code>*args</code> <p>Arguments to pass to the coroutine function.</p> <code>()</code> <code>**kwargs</code> <p>Keyword arguments to pass to the coroutine function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Task | None</code> <p>An asyncio.Task object representing the scheduled task, or None if</p> <code>Task | None</code> <p>the task could not be scheduled.</p> Source code in <code>toolboxv2/utils/toolbox.py</code> <pre><code>def run_bg_task(self, task: Callable, *args, **kwargs) -&gt; asyncio.Task | None:\n    \"\"\"\n    Runs a coroutine in the background without blocking the caller.\n\n    This is the primary method for \"fire-and-forget\" async tasks. It schedules\n    the coroutine to run on the application's main event loop.\n\n    Args:\n        task: The coroutine function to run.\n        *args: Arguments to pass to the coroutine function.\n        **kwargs: Keyword arguments to pass to the coroutine function.\n\n    Returns:\n        An asyncio.Task object representing the scheduled task, or None if\n        the task could not be scheduled.\n    \"\"\"\n    if not callable(task):\n        self.logger.warning(\"Task passed to run_bg_task is not callable!\")\n        return None\n\n    if not asyncio.iscoroutinefunction(task) and not asyncio.iscoroutine(task):\n        self.logger.warning(f\"Task '{getattr(task, '__name__', 'unknown')}' is not a coroutine. \"\n                            f\"Use run_bg_task_advanced for synchronous functions.\")\n        # Fallback to advanced runner for convenience\n        self.run_bg_task_advanced(task, *args, **kwargs)\n        return None\n\n    try:\n        loop = self.loop_gard()\n        if not loop.is_running():\n            # If the main loop isn't running, we can't create a task on it.\n            # This scenario is handled by run_bg_task_advanced.\n            self.logger.info(\"Main event loop not running. Delegating to advanced background runner.\")\n            return self.run_bg_task_advanced(task, *args, **kwargs)\n\n        # Create the coroutine if it's a function\n        coro = task(*args, **kwargs) if asyncio.iscoroutinefunction(task) else task\n\n        # Create a task on the running event loop\n        bg_task = loop.create_task(coro)\n\n        # Add a callback to log exceptions from the background task\n        def _log_exception(the_task: asyncio.Task):\n            if not the_task.cancelled() and the_task.exception():\n                self.logger.error(f\"Exception in background task '{the_task.get_name()}':\",\n                                  exc_info=the_task.exception())\n\n        bg_task.add_done_callback(_log_exception)\n        self.bg_tasks.append(bg_task)\n        return bg_task\n\n    except Exception as e:\n        self.logger.error(f\"Failed to schedule background task: {e}\", exc_info=True)\n        return None\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.toolbox.App.run_bg_task_advanced","title":"<code>run_bg_task_advanced(task, *args, **kwargs)</code>","text":"<p>Runs a task in a separate, dedicated background thread with its own event loop.</p> <p>This is ideal for: 1. Running an async task from a synchronous context. 2. Launching a long-running, independent operation that should not    interfere with the main application's event loop.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>Callable</code> <p>The function to run (can be sync or async).</p> required <code>*args</code> <p>Arguments for the task.</p> <code>()</code> <code>**kwargs</code> <p>Keyword arguments for the task.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Thread</code> <p>The threading.Thread object managing the background execution.</p> Source code in <code>toolboxv2/utils/toolbox.py</code> <pre><code>def run_bg_task_advanced(self, task: Callable, *args, **kwargs) -&gt; threading.Thread:\n    \"\"\"\n    Runs a task in a separate, dedicated background thread with its own event loop.\n\n    This is ideal for:\n    1. Running an async task from a synchronous context.\n    2. Launching a long-running, independent operation that should not\n       interfere with the main application's event loop.\n\n    Args:\n        task: The function to run (can be sync or async).\n        *args: Arguments for the task.\n        **kwargs: Keyword arguments for the task.\n\n    Returns:\n        The threading.Thread object managing the background execution.\n    \"\"\"\n    if not callable(task):\n        self.logger.warning(\"Task for run_bg_task_advanced is not callable!\")\n        return None\n\n    def thread_target():\n        # Each thread gets its own event loop.\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n\n        try:\n            # Prepare the coroutine we need to run\n            if asyncio.iscoroutinefunction(task):\n                coro = task(*args, **kwargs)\n            elif asyncio.iscoroutine(task):\n                # It's already a coroutine object\n                coro = task\n            else:\n                # It's a synchronous function, run it in an executor\n                # to avoid blocking the new event loop.\n                coro = loop.run_in_executor(None, lambda: task(*args, **kwargs))\n\n            # Run the coroutine to completion\n            result = loop.run_until_complete(coro)\n            self.logger.debug(f\"Advanced background task '{getattr(task, '__name__', 'unknown')}' completed.\")\n            if result is not None:\n                self.logger.debug(f\"Task result: {str(result)[:100]}\")\n\n        except Exception as e:\n            self.logger.error(f\"Error in advanced background task '{getattr(task, '__name__', 'unknown')}':\",\n                              exc_info=e)\n        finally:\n            # Cleanly shut down the event loop in this thread.\n            try:\n                all_tasks = asyncio.all_tasks(loop=loop)\n                if all_tasks:\n                    for t in all_tasks:\n                        t.cancel()\n                    loop.run_until_complete(asyncio.gather(*all_tasks, return_exceptions=True))\n            finally:\n                loop.close()\n                asyncio.set_event_loop(None)\n\n    # Create, start, and return the thread.\n    # It's a daemon thread so it won't prevent the main app from exiting.\n    t = threading.Thread(target=thread_target, daemon=True, name=f\"BGTask-{getattr(task, '__name__', 'unknown')}\")\n    self.bg_tasks.append(t)\n    t.start()\n    return t\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.toolbox.App.show_console","title":"<code>show_console(*args, **kwargs)</code>  <code>staticmethod</code>","text":"<p>proxi attr</p> Source code in <code>toolboxv2/utils/toolbox.py</code> <pre><code>@staticmethod\ndef show_console(*args, **kwargs):\n    \"\"\"proxi attr\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.toolbox.App.tb","title":"<code>tb(name=None, mod_name='', helper='', version=None, test=True, restrict_in_virtual_mode=False, api=False, initial=False, exit_f=False, test_only=False, memory_cache=False, file_cache=False, request_as_kwarg=False, row=False, state=None, level=-1, memory_cache_max_size=100, memory_cache_ttl=300, samples=None, interface=None, pre_compute=None, post_compute=None, api_methods=None, websocket_handler=None)</code>","text":"<p>A decorator for registering and configuring functions within a module.</p> <p>This decorator is used to wrap functions with additional functionality such as caching, API conversion, and lifecycle management (initialization and exit). It also handles the registration of the function in the module's function registry.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name to register the function under. Defaults to the function's own name.</p> <code>None</code> <code>mod_name</code> <code>str</code> <p>The name of the module the function belongs to.</p> <code>''</code> <code>helper</code> <code>str</code> <p>A helper string providing additional information about the function.</p> <code>''</code> <code>version</code> <code>str or None</code> <p>The version of the function or module.</p> <code>None</code> <code>test</code> <code>bool</code> <p>Flag to indicate if the function is for testing purposes.</p> <code>True</code> <code>restrict_in_virtual_mode</code> <code>bool</code> <p>Flag to restrict the function in virtual mode.</p> <code>False</code> <code>api</code> <code>bool</code> <p>Flag to indicate if the function is part of an API.</p> <code>False</code> <code>initial</code> <code>bool</code> <p>Flag to indicate if the function should be executed at initialization.</p> <code>False</code> <code>exit_f</code> <code>bool</code> <p>Flag to indicate if the function should be executed at exit.</p> <code>False</code> <code>test_only</code> <code>bool</code> <p>Flag to indicate if the function should only be used for testing.</p> <code>False</code> <code>memory_cache</code> <code>bool</code> <p>Flag to enable memory caching for the function.</p> <code>False</code> <code>request_as_kwarg</code> <code>bool</code> <p>Flag to get request if the fuction is calld from api.</p> <code>False</code> <code>file_cache</code> <code>bool</code> <p>Flag to enable file caching for the function.</p> <code>False</code> <code>row</code> <code>bool</code> <p>rather to auto wrap the result in Result type default False means no row data aka result type</p> <code>False</code> <code>state</code> <code>bool or None</code> <p>Flag to indicate if the function maintains state.</p> <code>None</code> <code>level</code> <code>int</code> <p>The level of the function, used for prioritization or categorization.</p> <code>-1</code> <code>memory_cache_max_size</code> <code>int</code> <p>Maximum size of the memory cache.</p> <code>100</code> <code>memory_cache_ttl</code> <code>int</code> <p>Time-to-live for the memory cache entries.</p> <code>300</code> <code>samples</code> <code>list or dict or None</code> <p>Samples or examples of function usage.</p> <code>None</code> <code>interface</code> <code>str</code> <p>The interface type for the function.</p> <code>None</code> <code>pre_compute</code> <code>callable</code> <p>A function to be called before the main function.</p> <code>None</code> <code>post_compute</code> <code>callable</code> <p>A function to be called after the main function.</p> <code>None</code> <code>api_methods</code> <code>list[str]</code> <p>default [\"AUTO\"] (GET if not params, POST if params) , GET, POST, PUT or DELETE.</p> <code>None</code> <code>websocket_handler</code> <code>str</code> <p>The name of the websocket handler to use.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>function</code> <p>The decorated function with additional processing and registration capabilities.</p> Source code in <code>toolboxv2/utils/toolbox.py</code> <pre><code>def tb(self, name=None,\n       mod_name: str = \"\",\n       helper: str = \"\",\n       version: str | None = None,\n       test: bool = True,\n       restrict_in_virtual_mode: bool = False,\n       api: bool = False,\n       initial: bool = False,\n       exit_f: bool = False,\n       test_only: bool = False,\n       memory_cache: bool = False,\n       file_cache: bool = False,\n       request_as_kwarg: bool = False,\n       row: bool = False,\n       state: bool | None = None,\n       level: int = -1,\n       memory_cache_max_size: int = 100,\n       memory_cache_ttl: int = 300,\n       samples: list or dict or None = None,\n       interface: ToolBoxInterfaces or None or str = None,\n       pre_compute=None,\n       post_compute=None,\n       api_methods=None,\n       websocket_handler: str | None = None,\n       ):\n    \"\"\"\nA decorator for registering and configuring functions within a module.\n\nThis decorator is used to wrap functions with additional functionality such as caching, API conversion, and lifecycle management (initialization and exit). It also handles the registration of the function in the module's function registry.\n\nArgs:\n    name (str, optional): The name to register the function under. Defaults to the function's own name.\n    mod_name (str, optional): The name of the module the function belongs to.\n    helper (str, optional): A helper string providing additional information about the function.\n    version (str or None, optional): The version of the function or module.\n    test (bool, optional): Flag to indicate if the function is for testing purposes.\n    restrict_in_virtual_mode (bool, optional): Flag to restrict the function in virtual mode.\n    api (bool, optional): Flag to indicate if the function is part of an API.\n    initial (bool, optional): Flag to indicate if the function should be executed at initialization.\n    exit_f (bool, optional): Flag to indicate if the function should be executed at exit.\n    test_only (bool, optional): Flag to indicate if the function should only be used for testing.\n    memory_cache (bool, optional): Flag to enable memory caching for the function.\n    request_as_kwarg (bool, optional): Flag to get request if the fuction is calld from api.\n    file_cache (bool, optional): Flag to enable file caching for the function.\n    row (bool, optional): rather to auto wrap the result in Result type default False means no row data aka result type\n    state (bool or None, optional): Flag to indicate if the function maintains state.\n    level (int, optional): The level of the function, used for prioritization or categorization.\n    memory_cache_max_size (int, optional): Maximum size of the memory cache.\n    memory_cache_ttl (int, optional): Time-to-live for the memory cache entries.\n    samples (list or dict or None, optional): Samples or examples of function usage.\n    interface (str, optional): The interface type for the function.\n    pre_compute (callable, optional): A function to be called before the main function.\n    post_compute (callable, optional): A function to be called after the main function.\n    api_methods (list[str], optional): default [\"AUTO\"] (GET if not params, POST if params) , GET, POST, PUT or DELETE.\n    websocket_handler (str, optional): The name of the websocket handler to use.\n\nReturns:\n    function: The decorated function with additional processing and registration capabilities.\n\"\"\"\n    if interface is None:\n        interface = \"tb\"\n    if test_only and 'test' not in self.id:\n        return lambda *args, **kwargs: args\n    return self._create_decorator(interface,\n                                  name,\n                                  mod_name,\n                                  level=level,\n                                  restrict_in_virtual_mode=restrict_in_virtual_mode,\n                                  helper=helper,\n                                  api=api,\n                                  version=version,\n                                  initial=initial,\n                                  exit_f=exit_f,\n                                  test=test,\n                                  samples=samples,\n                                  state=state,\n                                  pre_compute=pre_compute,\n                                  post_compute=post_compute,\n                                  memory_cache=memory_cache,\n                                  file_cache=file_cache,\n                                  request_as_kwarg=request_as_kwarg,\n                                  row=row,\n                                  api_methods=api_methods,\n                                  memory_cache_max_size=memory_cache_max_size,\n                                  memory_cache_ttl=memory_cache_ttl,\n                                  websocket_handler=websocket_handler,\n                                  )\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.toolbox.App.wait_for_bg_tasks","title":"<code>wait_for_bg_tasks(timeout=None)</code>","text":"<p>Wait for all background tasks to complete.</p> <p>Parameters:</p> Name Type Description Default <code>timeout</code> <p>Maximum time to wait (in seconds) for all tasks to complete.      None means wait indefinitely.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>bool</code> <p>True if all tasks completed, False if timeout occurred</p> Source code in <code>toolboxv2/utils/toolbox.py</code> <pre><code>def wait_for_bg_tasks(self, timeout=None):\n    \"\"\"\n    Wait for all background tasks to complete.\n\n    Args:\n        timeout: Maximum time to wait (in seconds) for all tasks to complete.\n                 None means wait indefinitely.\n\n    Returns:\n        bool: True if all tasks completed, False if timeout occurred\n    \"\"\"\n    active_tasks = [t for t in self.bg_tasks if t.is_alive()]\n\n    for task in active_tasks:\n        task.join(timeout=timeout)\n        if task.is_alive():\n            return False\n\n    return True\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.toolbox.App.ws_broadcast","title":"<code>ws_broadcast(channel_id, payload, source_conn_id='python_broadcast')</code>  <code>async</code>","text":"<p>Sendet eine Nachricht asynchron an alle Clients in einem Kanal/Raum.</p> <p>Parameters:</p> Name Type Description Default <code>channel_id</code> <code>str</code> <p>Der Kanal, an den gesendet werden soll.</p> required <code>payload</code> <code>dict</code> <p>Ein Dictionary, das als JSON gesendet wird.</p> required <code>source_conn_id</code> <code>optional</code> <p>Die ID der urspr\u00fcnglichen Verbindung, um Echos zu vermeiden.</p> <code>'python_broadcast'</code> Source code in <code>toolboxv2/utils/toolbox.py</code> <pre><code>async def ws_broadcast(self, channel_id: str, payload: dict, source_conn_id: str = \"python_broadcast\"):\n    \"\"\"\n    Sendet eine Nachricht asynchron an alle Clients in einem Kanal/Raum.\n\n    Args:\n        channel_id: Der Kanal, an den gesendet werden soll.\n        payload: Ein Dictionary, das als JSON gesendet wird.\n        source_conn_id (optional): Die ID der urspr\u00fcnglichen Verbindung, um Echos zu vermeiden.\n    \"\"\"\n    if self._rust_ws_bridge is None:\n        self.logger.error(\"Cannot broadcast WebSocket message: Rust bridge is not initialized.\")\n        return\n\n    try:\n        # Ruft die asynchrone Rust-Broadcast-Methode auf\n        await self._rust_ws_bridge.broadcast_message(channel_id, json.dumps(payload), source_conn_id)\n    except Exception as e:\n        self.logger.error(f\"Failed to broadcast WebSocket message to channel {channel_id}: {e}\", exc_info=True)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.utils.toolbox.App.ws_send","title":"<code>ws_send(conn_id, payload)</code>  <code>async</code>","text":"<p>Sendet eine Nachricht asynchron an eine einzelne WebSocket-Verbindung.</p> <p>Parameters:</p> Name Type Description Default <code>conn_id</code> <code>str</code> <p>Die eindeutige ID der Zielverbindung.</p> required <code>payload</code> <code>dict</code> <p>Ein Dictionary, das als JSON gesendet wird.</p> required Source code in <code>toolboxv2/utils/toolbox.py</code> <pre><code>async def ws_send(self, conn_id: str, payload: dict):\n    \"\"\"\n    Sendet eine Nachricht asynchron an eine einzelne WebSocket-Verbindung.\n\n    Args:\n        conn_id: Die eindeutige ID der Zielverbindung.\n        payload: Ein Dictionary, das als JSON gesendet wird.\n    \"\"\"\n    if self._rust_ws_bridge is None:\n        self.logger.error(\"Cannot send WebSocket message: Rust bridge is not initialized.\")\n        return\n\n    try:\n        # Ruft die asynchrone Rust-Methode auf und wartet auf deren Abschluss\n        await self._rust_ws_bridge.send_message(conn_id, json.dumps(payload))\n    except Exception as e:\n        self.logger.error(f\"Failed to send WebSocket message to {conn_id}: {e}\", exc_info=True)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.show_console","title":"<code>toolboxv2.show_console(show=True)</code>","text":"Source code in <code>toolboxv2/utils/extras/show_and_hide_console.py</code> <pre><code>def show_console(show=True):\n    global TBRUNNER_console_viabel\n    \"\"\"Brings up the Console Window.\"\"\"\n    try:\n        if show and not TBRUNNER_console_viabel:\n            # Show console\n            ctypes.windll.user32.ShowWindow(ctypes.windll.kernel32.GetConsoleWindow(), 4)\n            TBRUNNER_console_viabel = True\n            return True\n        elif not show and TBRUNNER_console_viabel:\n            # Hide console\n            ctypes.windll.user32.ShowWindow(ctypes.windll.kernel32.GetConsoleWindow(), 0)\n            TBRUNNER_console_viabel = False\n            return True\n    except:\n        print(f\"Could not show_console {show=}\", )\n        return False\n    return False\n</code></pre>"},{"location":"toolboxv2/#logging","title":"Logging","text":""},{"location":"toolboxv2/#toolboxv2.get_logger","title":"<code>toolboxv2.get_logger()</code>","text":"Source code in <code>toolboxv2/utils/system/tb_logger.py</code> <pre><code>def get_logger() -&gt; logging.Logger:\n    return logging.getLogger(loggerNameOfToolboxv2)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.setup_logging","title":"<code>toolboxv2.setup_logging(level, name=loggerNameOfToolboxv2, online_level=None, is_online=False, file_level=None, interminal=False, logs_directory='../logs', app_name='main')</code>","text":"Source code in <code>toolboxv2/utils/system/tb_logger.py</code> <pre><code>def setup_logging(level: int, name=loggerNameOfToolboxv2, online_level=None, is_online=False, file_level=None,\n                  interminal=False, logs_directory=\"../logs\", app_name=\"main\"):\n    global loggerNameOfToolboxv2\n\n    if not online_level:\n        online_level = level\n\n    if not file_level:\n        file_level = level\n\n    if not os.path.exists(logs_directory):\n        os.makedirs(logs_directory, exist_ok=True)\n    if not os.path.exists(logs_directory + \"/Logs.info\"):\n        open(f\"{logs_directory}/Logs.info\", \"a\").close()\n\n    loggerNameOfToolboxv2 = name\n\n    available_log_levels = [logging.CRITICAL, logging.FATAL, logging.ERROR, logging.WARNING, logging.WARN, logging.INFO,\n                            logging.DEBUG, logging.NOTSET]\n\n    if level not in available_log_levels:\n        raise ValueError(f\"level must be one of {available_log_levels}, but logging level is {level}\")\n\n    if online_level not in available_log_levels:\n        raise ValueError(f\"online_level must be one of {available_log_levels}, but logging level is {online_level}\")\n\n    if file_level not in available_log_levels:\n        raise ValueError(f\"file_level must be one of {available_log_levels}, but logging level is {file_level}\")\n\n    log_date = datetime.datetime.today().strftime('%Y-%m-%d')\n    log_levels = [\"CRITICAL\", \"ERROR\", \"WARNING\", \"INFO\", \"DEBUG\", \"NOTSET\"]\n    log_level_index = log_levels.index(logging.getLevelName(level))\n\n    filename = f\"Logs-{name}-{log_date}-{log_levels[log_level_index]}\"\n    log_filename = f\"{logs_directory}/{filename}.log\"\n\n    log_info_data = {\n        filename: 0,\n        \"H\": \"localhost\",\n        \"P\": 62435\n    }\n\n    with open(f\"{logs_directory}/Logs.info\") as li:\n        log_info_data_str = li.read()\n        try:\n            log_info_data = eval(log_info_data_str)\n        except SyntaxError:\n            if log_info_data_str:\n                print(Style.RED(Style.Bold(\"Could not parse log info data\")))\n\n        if filename not in log_info_data:\n            log_info_data[filename] = 0\n\n        if not os.path.exists(log_filename):\n            log_info_data[filename] = 0\n            print(\"new log file\")\n\n        if os.path.exists(log_filename):\n            log_info_data[filename] += 1\n\n            while os.path.exists(f\"{logs_directory}/{filename}#{log_info_data[filename]}.log\"):\n                log_info_data[filename] += 1\n\n            try:\n                os.rename(log_filename,\n                          f\"{logs_directory}/{filename}#{log_info_data[filename]}.log\")\n            except PermissionError:\n                print(Style.YELLOW(Style.Bold(f\"Could not rename log file appending on {filename}\")))\n\n    with open(f\"{logs_directory}/Logs.info\", \"w\") as li:\n        if len(log_info_data.keys()) &gt;= 7:\n            log_info_data = {\n                filename: log_info_data[filename],\n                \"H\": log_info_data[\"H\"],\n                \"P\": log_info_data[\"P\"]\n            }\n        li.write(str(log_info_data))\n\n    try:\n        with open(log_filename, \"a\"):\n            pass\n    except OSError:\n        log_filename = f\"{logs_directory}/Logs-Test-{log_date}-{log_levels[log_level_index]}.log\"\n        with open(log_filename, \"a\"):\n            pass\n\n    logger = logging.getLogger(name)\n\n    logger.setLevel(level)\n    # Prevent logger from propagating to parent loggers\n    logger.propagate = False\n\n    terminal_format = f\"{app_name} %(asctime)s %(levelname)s %(name)s - %(message)s\"\n    file_format = f\"{app_name} %(asctime)s - %(name)s - %(levelname)s - %(filename)s - %(funcName)s:%(lineno)d - %(message)s\"\n\n    # Configure handlers\n    handlers = []\n\n    # File handler (always added)\n    file_handler = logging.FileHandler(log_filename)\n    file_handler.setFormatter(logging.Formatter(file_format))\n    file_handler.setLevel(file_level)\n    handlers.append(file_handler)\n\n    # Terminal handler (if requested)\n    if interminal:\n        terminal_handler = logging.StreamHandler()\n        terminal_handler.setFormatter(logging.Formatter(terminal_format))\n        terminal_handler.setLevel(level)\n        handlers.append(terminal_handler)\n\n    # Socket handler (if requested)\n    if is_online:\n        socket_handler = SocketHandler(log_info_data[\"H\"], log_info_data[\"P\"])\n        socket_handler.setFormatter(logging.Formatter(file_format))\n        socket_handler.setLevel(online_level)\n        handlers.append(socket_handler)\n\n    # Add all handlers to logger\n    for handler in handlers:\n        logger.addHandler(handler)\n\n    return logger, filename\n</code></pre>"},{"location":"toolboxv2/#styling-console-output","title":"Styling &amp; Console Output","text":""},{"location":"toolboxv2/#toolboxv2.Style","title":"<code>toolboxv2.Style</code>","text":"Source code in <code>toolboxv2/utils/extras/Style.py</code> <pre><code>class Style:\n    _END = '\\33[0m'\n    _BLACK = '\\33[30m'\n    _RED = '\\33[31m'\n    _GREEN = '\\33[32m'\n    _YELLOW = '\\33[33m'\n    _BLUE = '\\33[34m'\n    _MAGENTA = '\\33[35m'\n    _CYAN = '\\33[36m'\n    _WHITE = '\\33[37m'\n\n    _Bold = '\\33[1m'\n    _ITALIC = '\\33[3m'\n    _Underline = '\\33[4m'\n    _BLINK = '\\33[5m'\n    _BLINK2 = '\\33[6m'\n    _Reversed = '\\33[7m'\n\n    _BLACKBG = '\\33[40m'\n    _REDBG = '\\33[41m'\n    _GREENBG = '\\33[42m'\n    _YELLOWBG = '\\33[43m'\n    _BLUEBG = '\\33[44m'\n    _VIOLETBG = '\\33[45m'\n    _BEIGEBG = '\\33[46m'\n    _WHITEBG = '\\33[47m'\n\n    _GREY = '\\33[90m'\n    _RED2 = '\\33[91m'\n    _GREEN2 = '\\33[92m'\n    _YELLOW2 = '\\33[93m'\n    _BLUE2 = '\\33[94m'\n    _VIOLET2 = '\\33[95m'\n    _BEIGE2 = '\\33[96m'\n    _WHITE2 = '\\33[97m'\n\n    _GREYBG = '\\33[100m'\n    _REDBG2 = '\\33[101m'\n    _GREENBG2 = '\\33[102m'\n    _YELLOWBG2 = '\\33[103m'\n    _BLUEBG2 = '\\33[104m'\n    _VIOLETBG2 = '\\33[105m'\n    _BEIGEBG2 = '\\33[106m'\n    _WHITEBG2 = '\\33[107m'\n\n    style_dic = {\n        \"END\": _END,\n        \"BLACK\": _BLACK,\n        \"RED\": _RED,\n        \"GREEN\": _GREEN,\n        \"YELLOW\": _YELLOW,\n        \"BLUE\": _BLUE,\n        \"MAGENTA\": _MAGENTA,\n        \"CYAN\": _CYAN,\n        \"WHITE\": _WHITE,\n        \"Bold\": _Bold,\n        \"Underline\": _Underline,\n        \"Reversed\": _Reversed,\n\n        \"ITALIC\": _ITALIC,\n        \"BLINK\": _BLINK,\n        \"BLINK2\": _BLINK2,\n        \"BLACKBG\": _BLACKBG,\n        \"REDBG\": _REDBG,\n        \"GREENBG\": _GREENBG,\n        \"YELLOWBG\": _YELLOWBG,\n        \"BLUEBG\": _BLUEBG,\n        \"VIOLETBG\": _VIOLETBG,\n        \"BEIGEBG\": _BEIGEBG,\n        \"WHITEBG\": _WHITEBG,\n        \"GREY\": _GREY,\n        \"RED2\": _RED2,\n        \"GREEN2\": _GREEN2,\n        \"YELLOW2\": _YELLOW2,\n        \"BLUE2\": _BLUE2,\n        \"VIOLET2\": _VIOLET2,\n        \"BEIGE2\": _BEIGE2,\n        \"WHITE2\": _WHITE2,\n        \"GREYBG\": _GREYBG,\n        \"REDBG2\": _REDBG2,\n        \"GREENBG2\": _GREENBG2,\n        \"YELLOWBG2\": _YELLOWBG2,\n        \"BLUEBG2\": _BLUEBG2,\n        \"VIOLETBG2\": _VIOLETBG2,\n        \"BEIGEBG2\": _BEIGEBG2,\n        \"WHITEBG2\": _WHITEBG2,\n\n    }\n\n    @staticmethod\n    @text_save\n    def END_():\n        print(Style._END)\n\n    @staticmethod\n    @text_save\n    def GREEN_():\n        print(Style._GREEN)\n\n    @staticmethod\n    @text_save\n    def BLUE(text: str):\n        return Style._BLUE + text + Style._END\n\n    @staticmethod\n    @text_save\n    def BLACK(text: str):\n        return Style._BLACK + text + Style._END\n\n    @staticmethod\n    @text_save\n    def RED(text: str):\n        return Style._RED + text + Style._END\n\n    @staticmethod\n    @text_save\n    def GREEN(text: str):\n        return Style._GREEN + text + Style._END\n\n    @staticmethod\n    @text_save\n    def YELLOW(text: str):\n        return Style._YELLOW + text + Style._END\n\n    @staticmethod\n    @text_save\n    def MAGENTA(text: str):\n        return Style._MAGENTA + text + Style._END\n\n    @staticmethod\n    @text_save\n    def CYAN(text: str):\n        return Style._CYAN + text + Style._END\n\n    @staticmethod\n    @text_save\n    def WHITE(text: str):\n        return Style._WHITE + text + Style._END\n\n    @staticmethod\n    @text_save\n    def Bold(text: str):\n        return Style._Bold + text + Style._END\n\n    @staticmethod\n    @text_save\n    def Underline(text: str):\n        return Style._Underline + text + Style._END\n\n    @staticmethod\n    @text_save\n    def Underlined(text: str):\n        return Style._Underline + text + Style._END\n\n    @staticmethod\n    @text_save\n    def Reversed(text: str):\n        return Style._Reversed + text + Style._END\n\n    @staticmethod\n    @text_save\n    def ITALIC(text: str):\n        return Style._ITALIC + text + Style._END\n\n    @staticmethod\n    @text_save\n    def BLINK(text: str):\n        return Style._BLINK + text + Style._END\n\n    @staticmethod\n    @text_save\n    def BLINK2(text: str):\n        return Style._BLINK2 + text + Style._END\n\n    @staticmethod\n    @text_save\n    def BLACKBG(text: str):\n        return Style._BLACKBG + text + Style._END\n\n    @staticmethod\n    @text_save\n    def REDBG(text: str):\n        return Style._REDBG + text + Style._END\n\n    @staticmethod\n    @text_save\n    def GREENBG(text: str):\n        return Style._GREENBG + text + Style._END\n\n    @staticmethod\n    @text_save\n    def YELLOWBG(text: str):\n        return Style._YELLOWBG + text + Style._END\n\n    @staticmethod\n    @text_save\n    def BLUEBG(text: str):\n        return Style._BLUEBG + text + Style._END\n\n    @staticmethod\n    @text_save\n    def VIOLETBG(text: str):\n        return Style._VIOLETBG + text + Style._END\n\n    @staticmethod\n    @text_save\n    def BEIGEBG(text: str):\n        return Style._BEIGEBG + text + Style._END\n\n    @staticmethod\n    @text_save\n    def WHITEBG(text: str):\n        return Style._WHITEBG + text + Style._END\n\n    @staticmethod\n    @text_save\n    def GREY(text: str):\n        return Style._GREY + str(text) + Style._END\n\n    @staticmethod\n    @text_save\n    def RED2(text: str):\n        return Style._RED2 + text + Style._END\n\n    @staticmethod\n    @text_save\n    def GREEN2(text: str):\n        return Style._GREEN2 + text + Style._END\n\n    @staticmethod\n    @text_save\n    def YELLOW2(text: str):\n        return Style._YELLOW2 + text + Style._END\n\n    @staticmethod\n    @text_save\n    def BLUE2(text: str):\n        return Style._BLUE2 + text + Style._END\n\n    @staticmethod\n    @text_save\n    def VIOLET2(text: str):\n        return Style._VIOLET2 + text + Style._END\n\n    @staticmethod\n    @text_save\n    def BEIGE2(text: str):\n        return Style._BEIGE2 + text + Style._END\n\n    @staticmethod\n    @text_save\n    def WHITE2(text: str):\n        return Style._WHITE2 + text + Style._END\n\n    @staticmethod\n    @text_save\n    def GREYBG(text: str):\n        return Style._GREYBG + text + Style._END\n\n    @staticmethod\n    @text_save\n    def REDBG2(text: str):\n        return Style._REDBG2 + text + Style._END\n\n    @staticmethod\n    @text_save\n    def GREENBG2(text: str):\n        return Style._GREENBG2 + text + Style._END\n\n    @staticmethod\n    @text_save\n    def YELLOWBG2(text: str):\n        return Style._YELLOWBG2 + text + Style._END\n\n    @staticmethod\n    @text_save\n    def BLUEBG2(text: str):\n        return Style._BLUEBG2 + text + Style._END\n\n    @staticmethod\n    @text_save\n    def VIOLETBG2(text: str):\n        return Style._VIOLETBG2 + text + Style._END\n\n    @staticmethod\n    @text_save\n    def BEIGEBG2(text: str):\n        return Style._BEIGEBG2 + text + Style._END\n\n    @staticmethod\n    @text_save\n    def WHITEBG2(text: str):\n        return Style._WHITEBG2 + text + Style._END\n\n    @staticmethod\n    @text_save\n    def loading_al(text: str):\n        b = f\"{text} /\"\n        print(b)\n        sleep(0.05)\n        cls()\n        b = f\"{text} -\"\n        print(b)\n        sleep(0.05)\n        cls()\n        b = f\"{text} \\\\\"\n        print(b)\n        sleep(0.05)\n        cls()\n        b = f\"{text} |\"\n        print(b)\n        sleep(0.05)\n        cls()\n\n    @property\n    def END(self):\n        return self._END\n\n    def color_demo(self):\n        for color in self.style_dic:\n            print(f\"{color} -&gt; {self.style_dic[color]}Effect{self._END}\")\n\n    @property\n    def Underline2(self):\n        return self._Underline\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.Spinner","title":"<code>toolboxv2.Spinner</code>","text":"<p>Enhanced Spinner with tqdm-like line rendering.</p> Source code in <code>toolboxv2/utils/extras/Style.py</code> <pre><code>class Spinner:\n    \"\"\"\n    Enhanced Spinner with tqdm-like line rendering.\n    \"\"\"\n    SYMBOL_SETS = {\n        \"c\": [\"\u25d0\", \"\u25d3\", \"\u25d1\", \"\u25d2\"],\n        \"b\": [\"\u2581\", \"\u2583\", \"\u2584\", \"\u2585\", \"\u2586\", \"\u2587\", \"\u2588\", \"\u2587\", \"\u2586\", \"\u2585\", \"\u2584\", \"\u2583\"],\n        \"d\": [\"\u28fe\", \"\u28fd\", \"\u28fb\", \"\u28bf\", \"\u287f\", \"\u28df\", \"\u28ef\", \"\u28f7\"],\n        \"w\": [\"\ud83c\udf0d\", \"\ud83c\udf0e\", \"\ud83c\udf0f\"],\n        \"s\": [\"\ud83c\udf00   \", \" \ud83c\udf00  \", \"  \ud83c\udf00 \", \"   \ud83c\udf00\", \"  \ud83c\udf00 \", \" \ud83c\udf00  \"],\n        \"+\": [\"+\", \"x\"],\n        \"t\": [\"\u2736\", \"\u2738\", \"\u2739\", \"\u273a\", \"\u2739\", \"\u2737\"]\n    }\n\n    def __init__(\n        self,\n        message: str = \"Loading...\",\n        delay: float = 0.1,\n        symbols=None,\n        count_down: bool = False,\n        time_in_s: float = 0\n    ):\n        \"\"\"Initialize spinner with flexible configuration.\"\"\"\n        # Resolve symbol set.\n        if isinstance(symbols, str):\n            symbols = self.SYMBOL_SETS.get(symbols, None)\n\n        # Default symbols if not provided.\n        if symbols is None:\n            symbols = [\"\u280b\", \"\u2819\", \"\u2839\", \"\u2838\", \"\u283c\", \"\u2834\", \"\u2826\", \"\u2827\", \"\u2807\", \"\u280f\"]\n\n        # Test mode symbol set.\n        if 'unittest' in sys.argv[0]:\n            symbols = ['#', '=', '-']\n\n        self.spinner = itertools.cycle(symbols)\n        self.delay = delay\n        self.message = message\n        self.running = False\n        self.spinner_thread = None\n        self.max_t = time_in_s\n        self.contd = count_down\n\n        # Rendering management.\n        self._is_primary = False\n        self._start_time = 0\n\n        # Central manager.\n        self.manager = SpinnerManager()\n\n    def _generate_render_line(self):\n        \"\"\"Generate the primary render line.\"\"\"\n        current_time = time.time()\n        if self.contd:\n            remaining = max(0, self.max_t - (current_time - self._start_time))\n            time_display = f\"{remaining:.2f}\"\n        else:\n            time_display = f\"{current_time - self._start_time:.2f}\"\n\n        symbol = next(self.spinner)\n        return f\"{symbol} {self.message} | {time_display}\"\n\n    def _generate_secondary_info(self):\n        \"\"\"Generate secondary spinner info for additional spinners.\"\"\"\n        return f\"{self.message}\"\n\n    def __enter__(self):\n        \"\"\"Start the spinner.\"\"\"\n        self.running = True\n        self._start_time = time.time()\n        self.manager.register_spinner(self)\n        return self\n\n    def __exit__(self, exc_type, exc_value, exc_traceback):\n        \"\"\"Stop the spinner.\"\"\"\n        self.running = False\n        self.manager.unregister_spinner(self)\n        # Clear the spinner's line if it was the primary spinner.\n        if self._is_primary:\n            sys.stdout.write(\"\\r\\033[K\")\n            sys.stdout.flush()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.Spinner.__enter__","title":"<code>__enter__()</code>","text":"<p>Start the spinner.</p> Source code in <code>toolboxv2/utils/extras/Style.py</code> <pre><code>def __enter__(self):\n    \"\"\"Start the spinner.\"\"\"\n    self.running = True\n    self._start_time = time.time()\n    self.manager.register_spinner(self)\n    return self\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.Spinner.__exit__","title":"<code>__exit__(exc_type, exc_value, exc_traceback)</code>","text":"<p>Stop the spinner.</p> Source code in <code>toolboxv2/utils/extras/Style.py</code> <pre><code>def __exit__(self, exc_type, exc_value, exc_traceback):\n    \"\"\"Stop the spinner.\"\"\"\n    self.running = False\n    self.manager.unregister_spinner(self)\n    # Clear the spinner's line if it was the primary spinner.\n    if self._is_primary:\n        sys.stdout.write(\"\\r\\033[K\")\n        sys.stdout.flush()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.Spinner.__init__","title":"<code>__init__(message='Loading...', delay=0.1, symbols=None, count_down=False, time_in_s=0)</code>","text":"<p>Initialize spinner with flexible configuration.</p> Source code in <code>toolboxv2/utils/extras/Style.py</code> <pre><code>def __init__(\n    self,\n    message: str = \"Loading...\",\n    delay: float = 0.1,\n    symbols=None,\n    count_down: bool = False,\n    time_in_s: float = 0\n):\n    \"\"\"Initialize spinner with flexible configuration.\"\"\"\n    # Resolve symbol set.\n    if isinstance(symbols, str):\n        symbols = self.SYMBOL_SETS.get(symbols, None)\n\n    # Default symbols if not provided.\n    if symbols is None:\n        symbols = [\"\u280b\", \"\u2819\", \"\u2839\", \"\u2838\", \"\u283c\", \"\u2834\", \"\u2826\", \"\u2827\", \"\u2807\", \"\u280f\"]\n\n    # Test mode symbol set.\n    if 'unittest' in sys.argv[0]:\n        symbols = ['#', '=', '-']\n\n    self.spinner = itertools.cycle(symbols)\n    self.delay = delay\n    self.message = message\n    self.running = False\n    self.spinner_thread = None\n    self.max_t = time_in_s\n    self.contd = count_down\n\n    # Rendering management.\n    self._is_primary = False\n    self._start_time = 0\n\n    # Central manager.\n    self.manager = SpinnerManager()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.remove_styles","title":"<code>toolboxv2.remove_styles(text, infos=False)</code>","text":"Source code in <code>toolboxv2/utils/extras/Style.py</code> <pre><code>def remove_styles(text: str, infos=False):\n    in_ = []\n    for key, style in Style.style_dic.items():\n        if style in text:\n            text = text.replace(style, '')\n            if infos:\n                in_.append([key for key, st in Style.style_dic.items() if style == st][0])\n    if infos:\n        if \"END\" in in_:\n            in_.remove('END')\n        return text, in_\n    return text\n</code></pre>"},{"location":"toolboxv2/#data-types-structures","title":"Data Types &amp; Structures","text":""},{"location":"toolboxv2/#toolboxv2.AppArgs","title":"<code>toolboxv2.AppArgs</code>","text":"Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>class AppArgs:\n    init = None\n    init_file = 'init.config'\n    get_version = False\n    mm = False\n    sm = False\n    lm = False\n    modi = 'cli'\n    kill = False\n    remote = False\n    remote_direct_key = None\n    background_application = False\n    background_application_runner = False\n    docker = False\n    build = False\n    install = None\n    remove = None\n    update = None\n    name = 'main'\n    port = 5000\n    host = '0.0.0.0'\n    load_all_mod_in_files = False\n    mods_folder = 'toolboxv2.mods.'\n    debug = None\n    test = None\n    profiler = None\n    hot_reload = False\n    live_application = True\n    sysPrint = False\n    kwargs = {}\n    session = None\n\n    def default(self):\n        return self\n\n    def set(self, name, value):\n        setattr(self, name, value)\n        return self\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.Result","title":"<code>toolboxv2.Result</code>","text":"Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>class Result:\n    _task = None\n    def __init__(self,\n                 error: ToolBoxError,\n                 result: ToolBoxResult,\n                 info: ToolBoxInfo,\n                 origin: Any | None = None,\n                 ):\n        self.error: ToolBoxError = error\n        self.result: ToolBoxResult = result\n        self.info: ToolBoxInfo = info\n        self.origin = origin\n\n    def as_result(self):\n        return self\n\n    def as_dict(self):\n        return {\n            \"error\":self.error.value if isinstance(self.error, Enum) else self.error,\n        \"result\" : {\n            \"data_to\":self.result.data_to.value if isinstance(self.result.data_to, Enum) else self.result.data_to,\n            \"data_info\":self.result.data_info,\n            \"data\":self.result.data,\n            \"data_type\":self.result.data_type\n        } if self.result else None,\n        \"info\" : {\n            \"exec_code\" : self.info.exec_code,  # exec_code umwandel in http resposn codes\n        \"help_text\" : self.info.help_text\n        } if self.info else None,\n        \"origin\" : self.origin\n        }\n\n    def set_origin(self, origin):\n        if self.origin is not None:\n            raise ValueError(\"You cannot Change the origin of a Result!\")\n        self.origin = origin\n        return self\n\n    def set_dir_origin(self, name, extras=\"assets/\"):\n        if self.origin is not None:\n            raise ValueError(\"You cannot Change the origin of a Result!\")\n        self.origin = f\"mods/{name}/{extras}\"\n        return self\n\n    def is_error(self):\n        if _test_is_result(self.result.data):\n            return self.result.data.is_error()\n        if self.error == ToolBoxError.none:\n            return False\n        if self.info.exec_code == 0:\n            return False\n        return self.info.exec_code != 200\n\n    def is_ok(self):\n        return not self.is_error()\n\n    def is_data(self):\n        return self.result.data is not None\n\n    def to_api_result(self):\n        # print(f\" error={self.error}, result= {self.result}, info= {self.info}, origin= {self.origin}\")\n        return ApiResult(\n            error=self.error.value if isinstance(self.error, Enum) else self.error,\n            result=ToolBoxResultBM(\n                data_to=self.result.data_to.value if isinstance(self.result.data_to, Enum) else self.result.data_to,\n                data_info=self.result.data_info,\n                data=self.result.data,\n                data_type=self.result.data_type\n            ) if self.result else None,\n            info=ToolBoxInfoBM(\n                exec_code=self.info.exec_code,  # exec_code umwandel in http resposn codes\n                help_text=self.info.help_text\n            ) if self.info else None,\n            origin=self.origin\n        )\n\n    def task(self, task):\n        self._task = task\n        return self\n\n    @staticmethod\n    def result_from_dict(error: str, result: dict, info: dict, origin: list or None or str):\n        # print(f\" error={self.error}, result= {self.result}, info= {self.info}, origin= {self.origin}\")\n        return ApiResult(\n            error=error if isinstance(error, Enum) else error,\n            result=ToolBoxResultBM(\n                data_to=result.get('data_to') if isinstance(result.get('data_to'), Enum) else result.get('data_to'),\n                data_info=result.get('data_info', '404'),\n                data=result.get('data'),\n                data_type=result.get('data_type', '404'),\n            ) if result else ToolBoxResultBM(\n                data_to=ToolBoxInterfaces.cli.value,\n                data_info='',\n                data='404',\n                data_type='404',\n            ),\n            info=ToolBoxInfoBM(\n                exec_code=info.get('exec_code', 404),\n                help_text=info.get('help_text', '404')\n            ) if info else ToolBoxInfoBM(\n                exec_code=404,\n                help_text='404'\n            ),\n            origin=origin\n        ).as_result()\n\n    @classmethod\n    def stream(cls,\n               stream_generator: Any,  # Renamed from source for clarity\n               content_type: str = \"text/event-stream\",  # Default to SSE\n               headers: dict | None = None,\n               info: str = \"OK\",\n               interface: ToolBoxInterfaces = ToolBoxInterfaces.remote,\n               cleanup_func: Callable[[], None] | Callable[[], T] | Callable[[], AsyncGenerator[T, None]] | None = None):\n        \"\"\"\n        Create a streaming response Result. Handles SSE and other stream types.\n\n        Args:\n            stream_generator: Any stream source (async generator, sync generator, iterable, or single item).\n            content_type: Content-Type header (default: text/event-stream for SSE).\n            headers: Additional HTTP headers for the response.\n            info: Help text for the result.\n            interface: Interface to send data to.\n            cleanup_func: Optional function for cleanup.\n\n        Returns:\n            A Result object configured for streaming.\n        \"\"\"\n        error = ToolBoxError.none\n        info_obj = ToolBoxInfo(exec_code=0, help_text=info)\n\n        final_generator: AsyncGenerator[str, None]\n\n        if content_type == \"text/event-stream\":\n            # For SSE, always use SSEGenerator.create_sse_stream to wrap the source.\n            # SSEGenerator.create_sse_stream handles various types of stream_generator internally.\n            final_generator = SSEGenerator.create_sse_stream(source=stream_generator, cleanup_func=cleanup_func)\n\n            # Standard SSE headers for the HTTP response itself\n            # These will be stored in the Result object. Rust side decides how to use them.\n            standard_sse_headers = {\n                \"Cache-Control\": \"no-cache\",  # SSE specific\n                \"Connection\": \"keep-alive\",  # SSE specific\n                \"X-Accel-Buffering\": \"no\",  # Useful for proxies with SSE\n                # Content-Type is implicitly text/event-stream, will be in streaming_data below\n            }\n            all_response_headers = standard_sse_headers.copy()\n            if headers:\n                all_response_headers.update(headers)\n        else:\n            # For non-SSE streams.\n            # If stream_generator is sync, wrap it to be async.\n            # If already async or single item, it will be handled.\n            # Rust's stream_generator in ToolboxClient seems to handle both sync/async Python generators.\n            # For consistency with how SSEGenerator does it, we can wrap sync ones.\n            if inspect.isgenerator(stream_generator) or \\\n                (not isinstance(stream_generator, str) and hasattr(stream_generator, '__iter__')):\n                final_generator = SSEGenerator.wrap_sync_generator(stream_generator)  # Simple async wrapper\n            elif inspect.isasyncgen(stream_generator):\n                final_generator = stream_generator\n            else:  # Single item or string\n                async def _single_item_gen():\n                    yield stream_generator\n\n                final_generator = _single_item_gen()\n            all_response_headers = headers if headers else {}\n\n        # Prepare streaming data to be stored in the Result object\n        streaming_data = {\n            \"type\": \"stream\",  # Indicator for Rust side\n            \"generator\": final_generator,\n            \"content_type\": content_type,  # Let Rust know the intended content type\n            \"headers\": all_response_headers  # Intended HTTP headers for the overall response\n        }\n\n        result_payload = ToolBoxResult(\n            data_to=interface,\n            data=streaming_data,\n            data_info=\"Streaming response\" if content_type != \"text/event-stream\" else \"SSE Event Stream\",\n            data_type=\"stream\"  # Generic type for Rust to identify it needs to stream from 'generator'\n        )\n\n        return cls(error=error, info=info_obj, result=result_payload)\n\n    @classmethod\n    def sse(cls,\n            stream_generator: Any,\n            info: str = \"OK\",\n            interface: ToolBoxInterfaces = ToolBoxInterfaces.remote,\n            cleanup_func: Callable[[], None] | Callable[[], T] | Callable[[], AsyncGenerator[T, None]] | None = None,\n            # http_headers: Optional[dict] = None # If we want to allow overriding default SSE HTTP headers\n            ):\n        \"\"\"\n        Create an Server-Sent Events (SSE) streaming response Result.\n\n        Args:\n            stream_generator: A source yielding individual data items. This can be an\n                              async generator, sync generator, iterable, or a single item.\n                              Each item will be formatted as an SSE event.\n            info: Optional help text for the Result.\n            interface: Optional ToolBoxInterface to target.\n            cleanup_func: Optional cleanup function to run when the stream ends or is cancelled.\n            #http_headers: Optional dictionary of custom HTTP headers for the SSE response.\n\n        Returns:\n            A Result object configured for SSE streaming.\n        \"\"\"\n        # Result.stream will handle calling SSEGenerator.create_sse_stream\n        # and setting appropriate default headers for SSE when content_type is \"text/event-stream\".\n        return cls.stream(\n            stream_generator=stream_generator,\n            content_type=\"text/event-stream\",\n            # headers=http_headers, # Pass if we add http_headers param\n            info=info,\n            interface=interface,\n            cleanup_func=cleanup_func\n        )\n\n    @classmethod\n    def default(cls, interface=ToolBoxInterfaces.native):\n        error = ToolBoxError.none\n        info = ToolBoxInfo(exec_code=-1, help_text=\"\")\n        result = ToolBoxResult(data_to=interface)\n        return cls(error=error, info=info, result=result)\n\n    @classmethod\n    def json(cls, data, info=\"OK\", interface=ToolBoxInterfaces.remote, exec_code=0, status_code=None):\n        \"\"\"Create a JSON response Result.\"\"\"\n        error = ToolBoxError.none\n        info_obj = ToolBoxInfo(exec_code=status_code or exec_code, help_text=info)\n\n        result = ToolBoxResult(\n            data_to=interface,\n            data=data,\n            data_info=\"JSON response\",\n            data_type=\"json\"\n        )\n\n        return cls(error=error, info=info_obj, result=result)\n\n    @classmethod\n    def text(cls, text_data, content_type=\"text/plain\",exec_code=None,status=200, info=\"OK\", interface=ToolBoxInterfaces.remote, headers=None):\n        \"\"\"Create a text response Result with specific content type.\"\"\"\n        if headers is not None:\n            return cls.html(text_data, status= exec_code or status, info=info, headers=headers)\n        error = ToolBoxError.none\n        info_obj = ToolBoxInfo(exec_code=exec_code or status, help_text=info)\n\n        result = ToolBoxResult(\n            data_to=interface,\n            data=text_data,\n            data_info=\"Text response\",\n            data_type=content_type\n        )\n\n        return cls(error=error, info=info_obj, result=result)\n\n    @classmethod\n    def binary(cls, data, content_type=\"application/octet-stream\", download_name=None, info=\"OK\",\n               interface=ToolBoxInterfaces.remote):\n        \"\"\"Create a binary data response Result.\"\"\"\n        error = ToolBoxError.none\n        info_obj = ToolBoxInfo(exec_code=0, help_text=info)\n\n        # Create a dictionary with binary data and metadata\n        binary_data = {\n            \"data\": data,\n            \"content_type\": content_type,\n            \"filename\": download_name\n        }\n\n        result = ToolBoxResult(\n            data_to=interface,\n            data=binary_data,\n            data_info=f\"Binary response: {download_name}\" if download_name else \"Binary response\",\n            data_type=\"binary\"\n        )\n\n        return cls(error=error, info=info_obj, result=result)\n\n    @classmethod\n    def file(cls, data, filename, content_type=None, info=\"OK\", interface=ToolBoxInterfaces.remote):\n        \"\"\"Create a file download response Result.\n\n        Args:\n            data: File data as bytes or base64 string\n            filename: Name of the file for download\n            content_type: MIME type of the file (auto-detected if None)\n            info: Response info text\n            interface: Target interface\n\n        Returns:\n            Result object configured for file download\n        \"\"\"\n        import base64\n        import mimetypes\n\n        error = ToolBoxError.none\n        info_obj = ToolBoxInfo(exec_code=200, help_text=info)\n\n        # Auto-detect content type if not provided\n        if content_type is None:\n            content_type, _ = mimetypes.guess_type(filename)\n            if content_type is None:\n                content_type = \"application/octet-stream\"\n\n        # Ensure data is base64 encoded string (as expected by Rust server)\n        if isinstance(data, bytes):\n            base64_data = base64.b64encode(data).decode('utf-8')\n        elif isinstance(data, str):\n            # Assume it's already base64 encoded\n            base64_data = data\n        else:\n            raise ValueError(\"File data must be bytes or base64 string\")\n\n        result = ToolBoxResult(\n            data_to=interface,\n            data=base64_data,  # Rust expects base64 string for \"file\" type\n            data_info=f\"File download: {filename}\",\n            data_type=\"file\"\n        )\n\n        return cls(error=error, info=info_obj, result=result)\n\n    @classmethod\n    def redirect(cls, url, status_code=302, info=\"Redirect\", interface=ToolBoxInterfaces.remote):\n        \"\"\"Create a redirect response.\"\"\"\n        error = ToolBoxError.none\n        info_obj = ToolBoxInfo(exec_code=status_code, help_text=info)\n\n        result = ToolBoxResult(\n            data_to=interface,\n            data=url,\n            data_info=\"Redirect response\",\n            data_type=\"redirect\"\n        )\n\n        return cls(error=error, info=info_obj, result=result)\n\n    @classmethod\n    def ok(cls, data=None, data_info=\"\", info=\"OK\", interface=ToolBoxInterfaces.native):\n        error = ToolBoxError.none\n        info = ToolBoxInfo(exec_code=0, help_text=info)\n        result = ToolBoxResult(data_to=interface, data=data, data_info=data_info, data_type=type(data).__name__)\n        return cls(error=error, info=info, result=result)\n\n    @classmethod\n    def html(cls, data=None, data_info=\"\", info=\"OK\", interface=ToolBoxInterfaces.remote, data_type=\"html\",status=200, headers=None, row=False):\n        error = ToolBoxError.none\n        info = ToolBoxInfo(exec_code=status, help_text=info)\n        from ...utils.system.getting_and_closing_app import get_app\n\n        if not row and not '\"&lt;div class=\"main-content\"\"' in data:\n            data = f'&lt;div class=\"main-content frosted-glass\"&gt;{data}&lt;div&gt;'\n        if not row and not get_app().web_context() in data:\n            data = get_app().web_context() + data\n\n        if isinstance(headers, dict):\n            result = ToolBoxResult(data_to=interface, data={'html':data,'headers':headers}, data_info=data_info,\n                                   data_type=\"special_html\")\n        else:\n            result = ToolBoxResult(data_to=interface, data=data, data_info=data_info,\n                                   data_type=data_type if data_type is not None else type(data).__name__)\n        return cls(error=error, info=info, result=result)\n\n    @classmethod\n    def future(cls, data=None, data_info=\"\", info=\"OK\", interface=ToolBoxInterfaces.future):\n        error = ToolBoxError.none\n        info = ToolBoxInfo(exec_code=0, help_text=info)\n        result = ToolBoxResult(data_to=interface, data=data, data_info=data_info, data_type=\"future\")\n        return cls(error=error, info=info, result=result)\n\n    @classmethod\n    def custom_error(cls, data=None, data_info=\"\", info=\"\", exec_code=-1, interface=ToolBoxInterfaces.native):\n        error = ToolBoxError.custom_error\n        info = ToolBoxInfo(exec_code=exec_code, help_text=info)\n        result = ToolBoxResult(data_to=interface, data=data, data_info=data_info, data_type=type(data).__name__)\n        return cls(error=error, info=info, result=result)\n\n    @classmethod\n    def error(cls, data=None, data_info=\"\", info=\"\", exec_code=450, interface=ToolBoxInterfaces.remote):\n        error = ToolBoxError.custom_error\n        info = ToolBoxInfo(exec_code=exec_code, help_text=info)\n        result = ToolBoxResult(data_to=interface, data=data, data_info=data_info, data_type=type(data).__name__)\n        return cls(error=error, info=info, result=result)\n\n    @classmethod\n    def default_user_error(cls, info=\"\", exec_code=-3, interface=ToolBoxInterfaces.native, data=None):\n        error = ToolBoxError.input_error\n        info = ToolBoxInfo(exec_code, info)\n        result = ToolBoxResult(data_to=interface, data=data, data_type=type(data).__name__)\n        return cls(error=error, info=info, result=result)\n\n    @classmethod\n    def default_internal_error(cls, info=\"\", exec_code=-2, interface=ToolBoxInterfaces.native, data=None):\n        error = ToolBoxError.internal_error\n        info = ToolBoxInfo(exec_code, info)\n        result = ToolBoxResult(data_to=interface, data=data, data_type=type(data).__name__)\n        return cls(error=error, info=info, result=result)\n\n    def print(self, show=True, show_data=True, prifix=\"\"):\n        data = '\\n' + f\"{((prifix + f'Data_{self.result.data_type}: ' + str(self.result.data) if self.result.data is not None else 'NO Data') if not isinstance(self.result.data, Result) else self.result.data.print(show=False, show_data=show_data, prifix=prifix + '-')) if show_data else 'Data: private'}\"\n        origin = '\\n' + f\"{prifix + 'Origin: ' + str(self.origin) if self.origin is not None else 'NO Origin'}\"\n        text = (f\"Function Exec code: {self.info.exec_code}\"\n                f\"\\n{prifix}Info's:\"\n                f\" {self.info.help_text} {'&lt;|&gt; ' + str(self.result.data_info) if self.result.data_info is not None else ''}\"\n                f\"{origin}{(data[:100]+'...') if not data.endswith('NO Data') else ''}\\n\")\n        if not show:\n            return text\n        print(\"\\n======== Result ========\\n\" + text + \"------- EndOfD -------\")\n        return self\n\n    def log(self, show_data=True, prifix=\"\"):\n        from toolboxv2 import get_logger\n        get_logger().debug(self.print(show=False, show_data=show_data, prifix=prifix).replace(\"\\n\", \" - \"))\n        return self\n\n    def __str__(self):\n        return self.print(show=False, show_data=True)\n\n    def get(self, key=None, default=None):\n        data = self.result.data\n        if isinstance(data, Result):\n            return data.get(key=key, default=default)\n        if key is not None and isinstance(data, dict):\n            return data.get(key, default)\n        return data if data is not None else default\n\n    async def aget(self, key=None, default=None):\n        if asyncio.isfuture(self.result.data) or asyncio.iscoroutine(self.result.data) or (\n            isinstance(self.result.data_to, Enum) and self.result.data_to.name == ToolBoxInterfaces.future.name):\n            data = await self.result.data\n        else:\n            data = self.get(key=None, default=None)\n        if isinstance(data, Result):\n            return data.get(key=key, default=default)\n        if key is not None and isinstance(data, dict):\n            return data.get(key, default)\n        return data if data is not None else default\n\n    def lazy_return(self, _=0, data=None, **kwargs):\n        flags = ['raise', 'logg', 'user', 'intern']\n        flag = flags[_] if isinstance(_, int) else _\n        if self.info.exec_code == 0:\n            return self if data is None else data if _test_is_result(data) else self.ok(data=data, **kwargs)\n        if flag == 'raise':\n            raise ValueError(self.print(show=False))\n        if flag == 'logg':\n            from .. import get_logger\n            get_logger().error(self.print(show=False))\n\n        if flag == 'user':\n            return self if data is None else data if _test_is_result(data) else self.default_user_error(data=data,\n                                                                                                        **kwargs)\n        if flag == 'intern':\n            return self if data is None else data if _test_is_result(data) else self.default_internal_error(data=data,\n                                                                                                            **kwargs)\n\n        return self if data is None else data if _test_is_result(data) else self.custom_error(data=data, **kwargs)\n\n    @property\n    def bg_task(self):\n        return self._task\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.Result.binary","title":"<code>binary(data, content_type='application/octet-stream', download_name=None, info='OK', interface=ToolBoxInterfaces.remote)</code>  <code>classmethod</code>","text":"<p>Create a binary data response Result.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@classmethod\ndef binary(cls, data, content_type=\"application/octet-stream\", download_name=None, info=\"OK\",\n           interface=ToolBoxInterfaces.remote):\n    \"\"\"Create a binary data response Result.\"\"\"\n    error = ToolBoxError.none\n    info_obj = ToolBoxInfo(exec_code=0, help_text=info)\n\n    # Create a dictionary with binary data and metadata\n    binary_data = {\n        \"data\": data,\n        \"content_type\": content_type,\n        \"filename\": download_name\n    }\n\n    result = ToolBoxResult(\n        data_to=interface,\n        data=binary_data,\n        data_info=f\"Binary response: {download_name}\" if download_name else \"Binary response\",\n        data_type=\"binary\"\n    )\n\n    return cls(error=error, info=info_obj, result=result)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.Result.file","title":"<code>file(data, filename, content_type=None, info='OK', interface=ToolBoxInterfaces.remote)</code>  <code>classmethod</code>","text":"<p>Create a file download response Result.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <p>File data as bytes or base64 string</p> required <code>filename</code> <p>Name of the file for download</p> required <code>content_type</code> <p>MIME type of the file (auto-detected if None)</p> <code>None</code> <code>info</code> <p>Response info text</p> <code>'OK'</code> <code>interface</code> <p>Target interface</p> <code>remote</code> <p>Returns:</p> Type Description <p>Result object configured for file download</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@classmethod\ndef file(cls, data, filename, content_type=None, info=\"OK\", interface=ToolBoxInterfaces.remote):\n    \"\"\"Create a file download response Result.\n\n    Args:\n        data: File data as bytes or base64 string\n        filename: Name of the file for download\n        content_type: MIME type of the file (auto-detected if None)\n        info: Response info text\n        interface: Target interface\n\n    Returns:\n        Result object configured for file download\n    \"\"\"\n    import base64\n    import mimetypes\n\n    error = ToolBoxError.none\n    info_obj = ToolBoxInfo(exec_code=200, help_text=info)\n\n    # Auto-detect content type if not provided\n    if content_type is None:\n        content_type, _ = mimetypes.guess_type(filename)\n        if content_type is None:\n            content_type = \"application/octet-stream\"\n\n    # Ensure data is base64 encoded string (as expected by Rust server)\n    if isinstance(data, bytes):\n        base64_data = base64.b64encode(data).decode('utf-8')\n    elif isinstance(data, str):\n        # Assume it's already base64 encoded\n        base64_data = data\n    else:\n        raise ValueError(\"File data must be bytes or base64 string\")\n\n    result = ToolBoxResult(\n        data_to=interface,\n        data=base64_data,  # Rust expects base64 string for \"file\" type\n        data_info=f\"File download: {filename}\",\n        data_type=\"file\"\n    )\n\n    return cls(error=error, info=info_obj, result=result)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.Result.json","title":"<code>json(data, info='OK', interface=ToolBoxInterfaces.remote, exec_code=0, status_code=None)</code>  <code>classmethod</code>","text":"<p>Create a JSON response Result.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@classmethod\ndef json(cls, data, info=\"OK\", interface=ToolBoxInterfaces.remote, exec_code=0, status_code=None):\n    \"\"\"Create a JSON response Result.\"\"\"\n    error = ToolBoxError.none\n    info_obj = ToolBoxInfo(exec_code=status_code or exec_code, help_text=info)\n\n    result = ToolBoxResult(\n        data_to=interface,\n        data=data,\n        data_info=\"JSON response\",\n        data_type=\"json\"\n    )\n\n    return cls(error=error, info=info_obj, result=result)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.Result.redirect","title":"<code>redirect(url, status_code=302, info='Redirect', interface=ToolBoxInterfaces.remote)</code>  <code>classmethod</code>","text":"<p>Create a redirect response.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@classmethod\ndef redirect(cls, url, status_code=302, info=\"Redirect\", interface=ToolBoxInterfaces.remote):\n    \"\"\"Create a redirect response.\"\"\"\n    error = ToolBoxError.none\n    info_obj = ToolBoxInfo(exec_code=status_code, help_text=info)\n\n    result = ToolBoxResult(\n        data_to=interface,\n        data=url,\n        data_info=\"Redirect response\",\n        data_type=\"redirect\"\n    )\n\n    return cls(error=error, info=info_obj, result=result)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.Result.sse","title":"<code>sse(stream_generator, info='OK', interface=ToolBoxInterfaces.remote, cleanup_func=None)</code>  <code>classmethod</code>","text":"<p>Create an Server-Sent Events (SSE) streaming response Result.</p> <p>Parameters:</p> Name Type Description Default <code>stream_generator</code> <code>Any</code> <p>A source yielding individual data items. This can be an               async generator, sync generator, iterable, or a single item.               Each item will be formatted as an SSE event.</p> required <code>info</code> <code>str</code> <p>Optional help text for the Result.</p> <code>'OK'</code> <code>interface</code> <code>ToolBoxInterfaces</code> <p>Optional ToolBoxInterface to target.</p> <code>remote</code> <code>cleanup_func</code> <code>Callable[[], None] | Callable[[], T] | Callable[[], AsyncGenerator[T, None]] | None</code> <p>Optional cleanup function to run when the stream ends or is cancelled.</p> <code>None</code> <code>#http_headers</code> <p>Optional dictionary of custom HTTP headers for the SSE response.</p> required <p>Returns:</p> Type Description <p>A Result object configured for SSE streaming.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@classmethod\ndef sse(cls,\n        stream_generator: Any,\n        info: str = \"OK\",\n        interface: ToolBoxInterfaces = ToolBoxInterfaces.remote,\n        cleanup_func: Callable[[], None] | Callable[[], T] | Callable[[], AsyncGenerator[T, None]] | None = None,\n        # http_headers: Optional[dict] = None # If we want to allow overriding default SSE HTTP headers\n        ):\n    \"\"\"\n    Create an Server-Sent Events (SSE) streaming response Result.\n\n    Args:\n        stream_generator: A source yielding individual data items. This can be an\n                          async generator, sync generator, iterable, or a single item.\n                          Each item will be formatted as an SSE event.\n        info: Optional help text for the Result.\n        interface: Optional ToolBoxInterface to target.\n        cleanup_func: Optional cleanup function to run when the stream ends or is cancelled.\n        #http_headers: Optional dictionary of custom HTTP headers for the SSE response.\n\n    Returns:\n        A Result object configured for SSE streaming.\n    \"\"\"\n    # Result.stream will handle calling SSEGenerator.create_sse_stream\n    # and setting appropriate default headers for SSE when content_type is \"text/event-stream\".\n    return cls.stream(\n        stream_generator=stream_generator,\n        content_type=\"text/event-stream\",\n        # headers=http_headers, # Pass if we add http_headers param\n        info=info,\n        interface=interface,\n        cleanup_func=cleanup_func\n    )\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.Result.stream","title":"<code>stream(stream_generator, content_type='text/event-stream', headers=None, info='OK', interface=ToolBoxInterfaces.remote, cleanup_func=None)</code>  <code>classmethod</code>","text":"<p>Create a streaming response Result. Handles SSE and other stream types.</p> <p>Parameters:</p> Name Type Description Default <code>stream_generator</code> <code>Any</code> <p>Any stream source (async generator, sync generator, iterable, or single item).</p> required <code>content_type</code> <code>str</code> <p>Content-Type header (default: text/event-stream for SSE).</p> <code>'text/event-stream'</code> <code>headers</code> <code>dict | None</code> <p>Additional HTTP headers for the response.</p> <code>None</code> <code>info</code> <code>str</code> <p>Help text for the result.</p> <code>'OK'</code> <code>interface</code> <code>ToolBoxInterfaces</code> <p>Interface to send data to.</p> <code>remote</code> <code>cleanup_func</code> <code>Callable[[], None] | Callable[[], T] | Callable[[], AsyncGenerator[T, None]] | None</code> <p>Optional function for cleanup.</p> <code>None</code> <p>Returns:</p> Type Description <p>A Result object configured for streaming.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@classmethod\ndef stream(cls,\n           stream_generator: Any,  # Renamed from source for clarity\n           content_type: str = \"text/event-stream\",  # Default to SSE\n           headers: dict | None = None,\n           info: str = \"OK\",\n           interface: ToolBoxInterfaces = ToolBoxInterfaces.remote,\n           cleanup_func: Callable[[], None] | Callable[[], T] | Callable[[], AsyncGenerator[T, None]] | None = None):\n    \"\"\"\n    Create a streaming response Result. Handles SSE and other stream types.\n\n    Args:\n        stream_generator: Any stream source (async generator, sync generator, iterable, or single item).\n        content_type: Content-Type header (default: text/event-stream for SSE).\n        headers: Additional HTTP headers for the response.\n        info: Help text for the result.\n        interface: Interface to send data to.\n        cleanup_func: Optional function for cleanup.\n\n    Returns:\n        A Result object configured for streaming.\n    \"\"\"\n    error = ToolBoxError.none\n    info_obj = ToolBoxInfo(exec_code=0, help_text=info)\n\n    final_generator: AsyncGenerator[str, None]\n\n    if content_type == \"text/event-stream\":\n        # For SSE, always use SSEGenerator.create_sse_stream to wrap the source.\n        # SSEGenerator.create_sse_stream handles various types of stream_generator internally.\n        final_generator = SSEGenerator.create_sse_stream(source=stream_generator, cleanup_func=cleanup_func)\n\n        # Standard SSE headers for the HTTP response itself\n        # These will be stored in the Result object. Rust side decides how to use them.\n        standard_sse_headers = {\n            \"Cache-Control\": \"no-cache\",  # SSE specific\n            \"Connection\": \"keep-alive\",  # SSE specific\n            \"X-Accel-Buffering\": \"no\",  # Useful for proxies with SSE\n            # Content-Type is implicitly text/event-stream, will be in streaming_data below\n        }\n        all_response_headers = standard_sse_headers.copy()\n        if headers:\n            all_response_headers.update(headers)\n    else:\n        # For non-SSE streams.\n        # If stream_generator is sync, wrap it to be async.\n        # If already async or single item, it will be handled.\n        # Rust's stream_generator in ToolboxClient seems to handle both sync/async Python generators.\n        # For consistency with how SSEGenerator does it, we can wrap sync ones.\n        if inspect.isgenerator(stream_generator) or \\\n            (not isinstance(stream_generator, str) and hasattr(stream_generator, '__iter__')):\n            final_generator = SSEGenerator.wrap_sync_generator(stream_generator)  # Simple async wrapper\n        elif inspect.isasyncgen(stream_generator):\n            final_generator = stream_generator\n        else:  # Single item or string\n            async def _single_item_gen():\n                yield stream_generator\n\n            final_generator = _single_item_gen()\n        all_response_headers = headers if headers else {}\n\n    # Prepare streaming data to be stored in the Result object\n    streaming_data = {\n        \"type\": \"stream\",  # Indicator for Rust side\n        \"generator\": final_generator,\n        \"content_type\": content_type,  # Let Rust know the intended content type\n        \"headers\": all_response_headers  # Intended HTTP headers for the overall response\n    }\n\n    result_payload = ToolBoxResult(\n        data_to=interface,\n        data=streaming_data,\n        data_info=\"Streaming response\" if content_type != \"text/event-stream\" else \"SSE Event Stream\",\n        data_type=\"stream\"  # Generic type for Rust to identify it needs to stream from 'generator'\n    )\n\n    return cls(error=error, info=info_obj, result=result_payload)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.Result.text","title":"<code>text(text_data, content_type='text/plain', exec_code=None, status=200, info='OK', interface=ToolBoxInterfaces.remote, headers=None)</code>  <code>classmethod</code>","text":"<p>Create a text response Result with specific content type.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@classmethod\ndef text(cls, text_data, content_type=\"text/plain\",exec_code=None,status=200, info=\"OK\", interface=ToolBoxInterfaces.remote, headers=None):\n    \"\"\"Create a text response Result with specific content type.\"\"\"\n    if headers is not None:\n        return cls.html(text_data, status= exec_code or status, info=info, headers=headers)\n    error = ToolBoxError.none\n    info_obj = ToolBoxInfo(exec_code=exec_code or status, help_text=info)\n\n    result = ToolBoxResult(\n        data_to=interface,\n        data=text_data,\n        data_info=\"Text response\",\n        data_type=content_type\n    )\n\n    return cls(error=error, info=info_obj, result=result)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.ApiResult","title":"<code>toolboxv2.ApiResult</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>class ApiResult(BaseModel):\n    error: None | str= None\n    origin: Any | None\n    result: ToolBoxResultBM | None = None\n    info: ToolBoxInfoBM | None\n\n    def as_result(self):\n        return Result(\n            error=self.error.value if isinstance(self.error, Enum) else self.error,\n            result=ToolBoxResult(\n                data_to=self.result.data_to.value if isinstance(self.result.data_to, Enum) else self.result.data_to,\n                data_info=self.result.data_info,\n                data=self.result.data,\n                data_type=self.result.data_type\n            ) if self.result else None,\n            info=ToolBoxInfo(\n                exec_code=self.info.exec_code,\n                help_text=self.info.help_text\n            ) if self.info else None,\n            origin=self.origin\n        )\n\n    def to_api_result(self):\n        return self\n\n    def print(self, *args, **kwargs):\n        res = self.as_result().print(*args, **kwargs)\n        if not isinstance(res, str):\n            res = res.to_api_result()\n        return res\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.RequestData","title":"<code>toolboxv2.RequestData</code>  <code>dataclass</code>","text":"<p>Main class representing the complete request data structure.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@dataclass\nclass RequestData:\n    \"\"\"Main class representing the complete request data structure.\"\"\"\n    request: Request\n    session: Session\n    session_id: str\n\n    @classmethod\n    def from_dict(cls, data: dict[str, Any]) -&gt; 'RequestData':\n        \"\"\"Create a RequestData instance from a dictionary.\"\"\"\n        return cls(\n            request=Request.from_dict(data.get('request', {})),\n            session=Session.from_dict(data.get('session', {})),\n            session_id=data.get('session_id', '')\n        )\n\n    def to_dict(self) -&gt; dict[str, Any]:\n        \"\"\"Convert the RequestData object back to a dictionary.\"\"\"\n        return {\n            'request': self.request.to_dict(),\n            'session': self.session.to_dict(),\n            'session_id': self.session_id\n        }\n\n    def __getattr__(self, name: str) -&gt; Any:\n        \"\"\"Delegate unknown attributes to the `request` object.\"\"\"\n        # Nur wenn das Attribut nicht direkt in RequestData existiert\n        # und auch nicht `session` oder `session_id` ist\n        if hasattr(self.request, name):\n            return getattr(self.request, name)\n        raise AttributeError(f\"'RequestData' object has no attribute '{name}'\")\n\n    @classmethod\n    def moc(cls):\n        return cls(\n            request=Request.from_dict({\n                'content_type': 'application/x-www-form-urlencoded',\n                'headers': {\n                    'accept': '*/*',\n                    'accept-encoding': 'gzip, deflate, br, zstd',\n                    'accept-language': 'de-DE,de;q=0.9,en-US;q=0.8,en;q=0.7',\n                    'connection': 'keep-alive',\n                    'content-length': '107',\n                    'content-type': 'application/x-www-form-urlencoded',\n                    'cookie': 'session=abc123',\n                    'host': 'localhost:8080',\n                    'hx-current-url': 'http://localhost:8080/api/TruthSeeker/get_main_ui',\n                    'hx-request': 'true',\n                    'hx-target': 'estimates-guest_1fc2c9',\n                    'hx-trigger': 'config-form-guest_1fc2c9',\n                    'origin': 'http://localhost:8080',\n                    'referer': 'http://localhost:8080/api/TruthSeeker/get_main_ui',\n                    'sec-ch-ua': '\"Chromium\";v=\"134\", \"Not:A-Brand\";v=\"24\", \"Google Chrome\";v=\"134\"',\n                    'sec-ch-ua-mobile': '?0',\n                    'sec-ch-ua-platform': '\"Windows\"',\n                    'sec-fetch-dest': 'empty',\n                    'sec-fetch-mode': 'cors',\n                    'sec-fetch-site': 'same-origin',\n                    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n                },\n                'method': 'POST',\n                'path': '/api/TruthSeeker/update_estimates',\n                'query_params': {},\n                'form_data': {\n                    'param1': 'value1',\n                    'param2': 'value2'\n                }\n            }),\n            session=Session.from_dict({\n                'SiID': '29a2e258e18252e2afd5ff943523f09c82f1bb9adfe382a6f33fc6a8381de898',\n                'level': '1',\n                'spec': '74eed1c8de06886842e235486c3c2fd6bcd60586998ac5beb87f13c0d1750e1d',\n                'user_name': 'root',\n                'custom_field': 'custom_value'\n            }),\n            session_id='0x29dd1ac0d1e30d3f'\n        )\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.RequestData.__getattr__","title":"<code>__getattr__(name)</code>","text":"<p>Delegate unknown attributes to the <code>request</code> object.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def __getattr__(self, name: str) -&gt; Any:\n    \"\"\"Delegate unknown attributes to the `request` object.\"\"\"\n    # Nur wenn das Attribut nicht direkt in RequestData existiert\n    # und auch nicht `session` oder `session_id` ist\n    if hasattr(self.request, name):\n        return getattr(self.request, name)\n    raise AttributeError(f\"'RequestData' object has no attribute '{name}'\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.RequestData.from_dict","title":"<code>from_dict(data)</code>  <code>classmethod</code>","text":"<p>Create a RequestData instance from a dictionary.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: dict[str, Any]) -&gt; 'RequestData':\n    \"\"\"Create a RequestData instance from a dictionary.\"\"\"\n    return cls(\n        request=Request.from_dict(data.get('request', {})),\n        session=Session.from_dict(data.get('session', {})),\n        session_id=data.get('session_id', '')\n    )\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.RequestData.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert the RequestData object back to a dictionary.</p> Source code in <code>toolboxv2/utils/system/types.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Convert the RequestData object back to a dictionary.\"\"\"\n    return {\n        'request': self.request.to_dict(),\n        'session': self.session.to_dict(),\n        'session_id': self.session_id\n    }\n</code></pre>"},{"location":"toolboxv2/#security","title":"Security","text":""},{"location":"toolboxv2/#toolboxv2.Code","title":"<code>toolboxv2.Code</code>","text":"Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>class Code:\n\n    @staticmethod\n    def DK():\n        return DEVICE_KEY\n\n    def decode_code(self, encrypted_data, key=None):\n\n        if not isinstance(encrypted_data, str):\n            encrypted_data = str(encrypted_data)\n\n        if key is None:\n            key = DEVICE_KEY()\n\n        return self.decrypt_symmetric(encrypted_data, key)\n\n    def encode_code(self, data, key=None):\n\n        if not isinstance(data, str):\n            data = str(data)\n\n        if key is None:\n            key = DEVICE_KEY()\n\n        return self.encrypt_symmetric(data, key)\n\n    @staticmethod\n    def generate_seed() -&gt; int:\n        \"\"\"\n        Erzeugt eine zuf\u00e4llige Zahl als Seed.\n\n        Returns:\n            int: Eine zuf\u00e4llige Zahl.\n        \"\"\"\n        return random.randint(2 ** 32 - 1, 2 ** 64 - 1)\n\n    @staticmethod\n    def one_way_hash(text: str, salt: str = '', pepper: str = '') -&gt; str:\n        \"\"\"\n        Erzeugt einen Hash eines gegebenen Textes mit Salt, Pepper und optional einem Seed.\n\n        Args:\n            text (str): Der zu hashende Text.\n            salt (str): Der Salt-Wert.\n            pepper (str): Der Pepper-Wert.\n            seed (int, optional): Ein optionaler Seed-Wert. Standardm\u00e4\u00dfig None.\n\n        Returns:\n            str: Der resultierende Hash-Wert.\n        \"\"\"\n        return hashlib.sha256((salt + text + pepper).encode()).hexdigest()\n\n    @staticmethod\n    def generate_symmetric_key(as_str=True) -&gt; str or bytes:\n        \"\"\"\n        Generiert einen Schl\u00fcssel f\u00fcr die symmetrische Verschl\u00fcsselung.\n\n        Returns:\n            str: Der generierte Schl\u00fcssel.\n        \"\"\"\n        key = Fernet.generate_key()\n        if as_str:\n            key = key.decode()\n        return key\n\n    @staticmethod\n    def encrypt_symmetric(text: str or bytes, key: str) -&gt; str:\n        \"\"\"\n        Verschl\u00fcsselt einen Text mit einem gegebenen symmetrischen Schl\u00fcssel.\n\n        Args:\n            text (str): Der zu verschl\u00fcsselnde Text.\n            key (str): Der symmetrische Schl\u00fcssel.\n\n        Returns:\n            str: Der verschl\u00fcsselte Text.\n        \"\"\"\n        if isinstance(text, str):\n            text = text.encode()\n\n        try:\n            fernet = Fernet(key.encode())\n            return fernet.encrypt(text).decode()\n        except Exception as e:\n            get_logger().error(f\"Error encrypt_symmetric #{str(e)}#\")\n            return \"Error encrypt\"\n\n    @staticmethod\n    def decrypt_symmetric(encrypted_text: str, key: str, to_str=True, mute=False) -&gt; str or bytes:\n        \"\"\"\n        Entschl\u00fcsselt einen Text mit einem gegebenen symmetrischen Schl\u00fcssel.\n\n        Args:\n            encrypted_text (str): Der zu entschl\u00fcsselnde Text.\n            key (str): Der symmetrische Schl\u00fcssel.\n            to_str (bool): default true returns str if false returns bytes\n        Returns:\n            str: Der entschl\u00fcsselte Text.\n        \"\"\"\n\n        if isinstance(key, str):\n            key = key.encode()\n\n        #try:\n        fernet = Fernet(key)\n        text_b = fernet.decrypt(encrypted_text)\n        if not to_str:\n            return text_b\n        return text_b.decode()\n        # except Exception as e:\n        #     get_logger().error(f\"Error decrypt_symmetric {e}\")\n        #     if not mute:\n        #         raise e\n        #     if not to_str:\n        #         return f\"Error decoding\".encode()\n        #     return f\"Error decoding\"\n\n    @staticmethod\n    def generate_asymmetric_keys() -&gt; (str, str):\n        \"\"\"\n        Generiert ein Paar von \u00f6ffentlichen und privaten Schl\u00fcsseln f\u00fcr die asymmetrische Verschl\u00fcsselung.\n\n        Args:\n            seed (int, optional): Ein optionaler Seed-Wert. Standardm\u00e4\u00dfig None.\n\n        Returns:\n            (str, str): Ein Tupel aus \u00f6ffentlichem und privatem Schl\u00fcssel.\n        \"\"\"\n        private_key = rsa.generate_private_key(\n            public_exponent=65537,\n            key_size=2048 * 3,\n        )\n        public_key = private_key.public_key()\n\n        # Serialisieren der Schl\u00fcssel\n        pem_private_key = private_key.private_bytes(\n            encoding=serialization.Encoding.PEM,\n            format=serialization.PrivateFormat.PKCS8,\n            encryption_algorithm=serialization.NoEncryption()\n        ).decode()\n\n        pem_public_key = public_key.public_bytes(\n            encoding=serialization.Encoding.PEM,\n            format=serialization.PublicFormat.SubjectPublicKeyInfo\n        ).decode()\n\n        return pem_public_key, pem_private_key\n\n    @staticmethod\n    def save_keys_to_files(public_key: str, private_key: str, directory: str = \"keys\") -&gt; None:\n        \"\"\"\n        Speichert die generierten Schl\u00fcssel in separate Dateien.\n        Der private Schl\u00fcssel wird mit dem Device Key verschl\u00fcsselt.\n\n        Args:\n            public_key (str): Der \u00f6ffentliche Schl\u00fcssel im PEM-Format\n            private_key (str): Der private Schl\u00fcssel im PEM-Format\n            directory (str): Das Verzeichnis, in dem die Schl\u00fcssel gespeichert werden sollen\n        \"\"\"\n        # Erstelle das Verzeichnis, falls es nicht existiert\n        os.makedirs(directory, exist_ok=True)\n\n        # Hole den Device Key\n        device_key = DEVICE_KEY()\n\n        # Verschl\u00fcssele den privaten Schl\u00fcssel mit dem Device Key\n        encrypted_private_key = Code.encrypt_symmetric(private_key, device_key)\n\n        # Speichere den \u00f6ffentlichen Schl\u00fcssel\n        public_key_path = os.path.join(directory, \"public_key.pem\")\n        with open(public_key_path, \"w\") as f:\n            f.write(public_key)\n\n        # Speichere den verschl\u00fcsselten privaten Schl\u00fcssel\n        private_key_path = os.path.join(directory, \"private_key.pem\")\n        with open(private_key_path, \"w\") as f:\n            f.write(encrypted_private_key)\n\n        print(\"Saved keys in \", public_key_path)\n\n    @staticmethod\n    def load_keys_from_files(directory: str = \"keys\") -&gt; (str, str):\n        \"\"\"\n        L\u00e4dt die Schl\u00fcssel aus den Dateien.\n        Der private Schl\u00fcssel wird mit dem Device Key entschl\u00fcsselt.\n\n        Args:\n            directory (str): Das Verzeichnis, aus dem die Schl\u00fcssel geladen werden sollen\n\n        Returns:\n            (str, str): Ein Tupel aus \u00f6ffentlichem und privatem Schl\u00fcssel\n\n        Raises:\n            FileNotFoundError: Wenn die Schl\u00fcsseldateien nicht gefunden werden k\u00f6nnen\n        \"\"\"\n        # Pfade zu den Schl\u00fcsseldateien\n        public_key_path = os.path.join(directory, \"public_key.pem\")\n        private_key_path = os.path.join(directory, \"private_key.pem\")\n\n        # Pr\u00fcfe ob die Dateien existieren\n        if not os.path.exists(public_key_path) or not os.path.exists(private_key_path):\n            return \"\", \"\"\n\n        # Hole den Device Key\n        device_key = DEVICE_KEY()\n\n        # Lade den \u00f6ffentlichen Schl\u00fcssel\n        with open(public_key_path) as f:\n            public_key = f.read()\n\n        # Lade und entschl\u00fcssele den privaten Schl\u00fcssel\n        with open(private_key_path) as f:\n            encrypted_private_key = f.read()\n            private_key = Code.decrypt_symmetric(encrypted_private_key, device_key)\n\n        return public_key, private_key\n\n    @staticmethod\n    def encrypt_asymmetric(text: str, public_key_str: str) -&gt; str:\n        \"\"\"\n        Verschl\u00fcsselt einen Text mit einem gegebenen \u00f6ffentlichen Schl\u00fcssel.\n\n        Args:\n            text (str): Der zu verschl\u00fcsselnde Text.\n            public_key_str (str): Der \u00f6ffentliche Schl\u00fcssel als String oder im pem format.\n\n        Returns:\n            str: Der verschl\u00fcsselte Text.\n        \"\"\"\n        # try:\n        #    public_key: RSAPublicKey = serialization.load_pem_public_key(public_key_str.encode())\n        #  except Exception as e:\n        #     get_logger().error(f\"Error encrypt_asymmetric {e}\")\n        try:\n            public_key: RSAPublicKey = serialization.load_pem_public_key(public_key_str.encode())\n            encrypted = public_key.encrypt(\n                text.encode(),\n                padding.OAEP(\n                    mgf=padding.MGF1(algorithm=hashes.SHA512()),\n                    algorithm=hashes.SHA512(),\n                    label=None\n                )\n            )\n            return encrypted.hex()\n        except Exception as e:\n            get_logger().error(f\"Error encrypt_asymmetric {e}\")\n            return \"Invalid\"\n\n    @staticmethod\n    def decrypt_asymmetric(encrypted_text_hex: str, private_key_str: str) -&gt; str:\n        \"\"\"\n        Entschl\u00fcsselt einen Text mit einem gegebenen privaten Schl\u00fcssel.\n\n        Args:\n            encrypted_text_hex (str): Der verschl\u00fcsselte Text als Hex-String.\n            private_key_str (str): Der private Schl\u00fcssel als String.\n\n        Returns:\n            str: Der entschl\u00fcsselte Text.\n        \"\"\"\n        try:\n            private_key = serialization.load_pem_private_key(private_key_str.encode(), password=None)\n            decrypted = private_key.decrypt(\n                bytes.fromhex(encrypted_text_hex),\n                padding.OAEP(\n                    mgf=padding.MGF1(algorithm=hashes.SHA512()),\n                    algorithm=hashes.SHA512(),\n                    label=None\n                )\n            )\n            return decrypted.decode()\n\n        except Exception as e:\n            get_logger().error(f\"Error decrypt_asymmetric {e}\")\n        return \"Invalid\"\n\n    @staticmethod\n    def verify_signature(signature: str or bytes, message: str or bytes, public_key_str: str,\n                         salt_length=padding.PSS.MAX_LENGTH) -&gt; bool:\n        if isinstance(signature, str):\n            signature = signature.encode()\n        if isinstance(message, str):\n            message = message.encode()\n        try:\n            public_key: RSAPublicKey = serialization.load_pem_public_key(public_key_str.encode())\n            public_key.verify(\n                signature=signature,\n                data=message,\n                padding=padding.PSS(\n                    mgf=padding.MGF1(hashes.SHA512()),\n                    salt_length=salt_length\n                ),\n                algorithm=hashes.SHA512()\n            )\n            return True\n        except:\n            pass\n        return False\n\n    @staticmethod\n    def verify_signature_web_algo(signature: str or bytes, message: str or bytes, public_key_str: str,\n                                  algo: int = -512) -&gt; bool:\n        signature_algorithm = ECDSA(hashes.SHA512())\n        if algo != -512:\n            signature_algorithm = ECDSA(hashes.SHA256())\n\n        if isinstance(signature, str):\n            signature = signature.encode()\n        if isinstance(message, str):\n            message = message.encode()\n        try:\n            public_key = serialization.load_pem_public_key(public_key_str.encode())\n            public_key.verify(\n                signature=signature,\n                data=message,\n                # padding=padding.PSS(\n                #    mgf=padding.MGF1(hashes.SHA512()),\n                #    salt_length=padding.PSS.MAX_LENGTH\n                # ),\n                signature_algorithm=signature_algorithm\n            )\n            return True\n        except:\n            pass\n        return False\n\n    @staticmethod\n    def create_signature(message: str, private_key_str: str, salt_length=padding.PSS.MAX_LENGTH,\n                         row=False) -&gt; str or bytes:\n        try:\n            private_key = serialization.load_pem_private_key(private_key_str.encode(), password=None)\n            signature = private_key.sign(\n                message.encode(),\n                padding.PSS(\n                    mgf=padding.MGF1(hashes.SHA512()),\n                    salt_length=salt_length\n                ),\n                hashes.SHA512()\n            )\n            if row:\n                return signature\n            return base64.b64encode(signature).decode()\n        except Exception as e:\n            get_logger().error(f\"Error create_signature {e}\")\n            print(e)\n        return \"Invalid Key\"\n\n    @staticmethod\n    def pem_to_public_key(pem_key: str):\n        \"\"\"\n        Konvertiert einen PEM-kodierten \u00f6ffentlichen Schl\u00fcssel in ein PublicKey-Objekt.\n\n        Args:\n            pem_key (str): Der PEM-kodierte \u00f6ffentliche Schl\u00fcssel.\n\n        Returns:\n            PublicKey: Das PublicKey-Objekt.\n        \"\"\"\n        public_key = serialization.load_pem_public_key(pem_key.encode())\n        return public_key\n\n    @staticmethod\n    def public_key_to_pem(public_key: RSAPublicKey):\n        \"\"\"\n        Konvertiert ein PublicKey-Objekt in einen PEM-kodierten String.\n\n        Args:\n            public_key (PublicKey): Das PublicKey-Objekt.\n\n        Returns:\n            str: Der PEM-kodierte \u00f6ffentliche Schl\u00fcssel.\n        \"\"\"\n        pem = public_key.public_bytes(\n            encoding=serialization.Encoding.PEM,\n            format=serialization.PublicFormat.SubjectPublicKeyInfo\n        )\n        return pem.decode()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.Code.decrypt_asymmetric","title":"<code>decrypt_asymmetric(encrypted_text_hex, private_key_str)</code>  <code>staticmethod</code>","text":"<p>Entschl\u00fcsselt einen Text mit einem gegebenen privaten Schl\u00fcssel.</p> <p>Parameters:</p> Name Type Description Default <code>encrypted_text_hex</code> <code>str</code> <p>Der verschl\u00fcsselte Text als Hex-String.</p> required <code>private_key_str</code> <code>str</code> <p>Der private Schl\u00fcssel als String.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Der entschl\u00fcsselte Text.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef decrypt_asymmetric(encrypted_text_hex: str, private_key_str: str) -&gt; str:\n    \"\"\"\n    Entschl\u00fcsselt einen Text mit einem gegebenen privaten Schl\u00fcssel.\n\n    Args:\n        encrypted_text_hex (str): Der verschl\u00fcsselte Text als Hex-String.\n        private_key_str (str): Der private Schl\u00fcssel als String.\n\n    Returns:\n        str: Der entschl\u00fcsselte Text.\n    \"\"\"\n    try:\n        private_key = serialization.load_pem_private_key(private_key_str.encode(), password=None)\n        decrypted = private_key.decrypt(\n            bytes.fromhex(encrypted_text_hex),\n            padding.OAEP(\n                mgf=padding.MGF1(algorithm=hashes.SHA512()),\n                algorithm=hashes.SHA512(),\n                label=None\n            )\n        )\n        return decrypted.decode()\n\n    except Exception as e:\n        get_logger().error(f\"Error decrypt_asymmetric {e}\")\n    return \"Invalid\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.Code.decrypt_symmetric","title":"<code>decrypt_symmetric(encrypted_text, key, to_str=True, mute=False)</code>  <code>staticmethod</code>","text":"<p>Entschl\u00fcsselt einen Text mit einem gegebenen symmetrischen Schl\u00fcssel.</p> <p>Parameters:</p> Name Type Description Default <code>encrypted_text</code> <code>str</code> <p>Der zu entschl\u00fcsselnde Text.</p> required <code>key</code> <code>str</code> <p>Der symmetrische Schl\u00fcssel.</p> required <code>to_str</code> <code>bool</code> <p>default true returns str if false returns bytes</p> <code>True</code> <p>Returns:     str: Der entschl\u00fcsselte Text.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef decrypt_symmetric(encrypted_text: str, key: str, to_str=True, mute=False) -&gt; str or bytes:\n    \"\"\"\n    Entschl\u00fcsselt einen Text mit einem gegebenen symmetrischen Schl\u00fcssel.\n\n    Args:\n        encrypted_text (str): Der zu entschl\u00fcsselnde Text.\n        key (str): Der symmetrische Schl\u00fcssel.\n        to_str (bool): default true returns str if false returns bytes\n    Returns:\n        str: Der entschl\u00fcsselte Text.\n    \"\"\"\n\n    if isinstance(key, str):\n        key = key.encode()\n\n    #try:\n    fernet = Fernet(key)\n    text_b = fernet.decrypt(encrypted_text)\n    if not to_str:\n        return text_b\n    return text_b.decode()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.Code.encrypt_asymmetric","title":"<code>encrypt_asymmetric(text, public_key_str)</code>  <code>staticmethod</code>","text":"<p>Verschl\u00fcsselt einen Text mit einem gegebenen \u00f6ffentlichen Schl\u00fcssel.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Der zu verschl\u00fcsselnde Text.</p> required <code>public_key_str</code> <code>str</code> <p>Der \u00f6ffentliche Schl\u00fcssel als String oder im pem format.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Der verschl\u00fcsselte Text.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef encrypt_asymmetric(text: str, public_key_str: str) -&gt; str:\n    \"\"\"\n    Verschl\u00fcsselt einen Text mit einem gegebenen \u00f6ffentlichen Schl\u00fcssel.\n\n    Args:\n        text (str): Der zu verschl\u00fcsselnde Text.\n        public_key_str (str): Der \u00f6ffentliche Schl\u00fcssel als String oder im pem format.\n\n    Returns:\n        str: Der verschl\u00fcsselte Text.\n    \"\"\"\n    # try:\n    #    public_key: RSAPublicKey = serialization.load_pem_public_key(public_key_str.encode())\n    #  except Exception as e:\n    #     get_logger().error(f\"Error encrypt_asymmetric {e}\")\n    try:\n        public_key: RSAPublicKey = serialization.load_pem_public_key(public_key_str.encode())\n        encrypted = public_key.encrypt(\n            text.encode(),\n            padding.OAEP(\n                mgf=padding.MGF1(algorithm=hashes.SHA512()),\n                algorithm=hashes.SHA512(),\n                label=None\n            )\n        )\n        return encrypted.hex()\n    except Exception as e:\n        get_logger().error(f\"Error encrypt_asymmetric {e}\")\n        return \"Invalid\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.Code.encrypt_symmetric","title":"<code>encrypt_symmetric(text, key)</code>  <code>staticmethod</code>","text":"<p>Verschl\u00fcsselt einen Text mit einem gegebenen symmetrischen Schl\u00fcssel.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Der zu verschl\u00fcsselnde Text.</p> required <code>key</code> <code>str</code> <p>Der symmetrische Schl\u00fcssel.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Der verschl\u00fcsselte Text.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef encrypt_symmetric(text: str or bytes, key: str) -&gt; str:\n    \"\"\"\n    Verschl\u00fcsselt einen Text mit einem gegebenen symmetrischen Schl\u00fcssel.\n\n    Args:\n        text (str): Der zu verschl\u00fcsselnde Text.\n        key (str): Der symmetrische Schl\u00fcssel.\n\n    Returns:\n        str: Der verschl\u00fcsselte Text.\n    \"\"\"\n    if isinstance(text, str):\n        text = text.encode()\n\n    try:\n        fernet = Fernet(key.encode())\n        return fernet.encrypt(text).decode()\n    except Exception as e:\n        get_logger().error(f\"Error encrypt_symmetric #{str(e)}#\")\n        return \"Error encrypt\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.Code.generate_asymmetric_keys","title":"<code>generate_asymmetric_keys()</code>  <code>staticmethod</code>","text":"<p>Generiert ein Paar von \u00f6ffentlichen und privaten Schl\u00fcsseln f\u00fcr die asymmetrische Verschl\u00fcsselung.</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>int</code> <p>Ein optionaler Seed-Wert. Standardm\u00e4\u00dfig None.</p> required <p>Returns:</p> Type Description <code>(str, str)</code> <p>Ein Tupel aus \u00f6ffentlichem und privatem Schl\u00fcssel.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef generate_asymmetric_keys() -&gt; (str, str):\n    \"\"\"\n    Generiert ein Paar von \u00f6ffentlichen und privaten Schl\u00fcsseln f\u00fcr die asymmetrische Verschl\u00fcsselung.\n\n    Args:\n        seed (int, optional): Ein optionaler Seed-Wert. Standardm\u00e4\u00dfig None.\n\n    Returns:\n        (str, str): Ein Tupel aus \u00f6ffentlichem und privatem Schl\u00fcssel.\n    \"\"\"\n    private_key = rsa.generate_private_key(\n        public_exponent=65537,\n        key_size=2048 * 3,\n    )\n    public_key = private_key.public_key()\n\n    # Serialisieren der Schl\u00fcssel\n    pem_private_key = private_key.private_bytes(\n        encoding=serialization.Encoding.PEM,\n        format=serialization.PrivateFormat.PKCS8,\n        encryption_algorithm=serialization.NoEncryption()\n    ).decode()\n\n    pem_public_key = public_key.public_bytes(\n        encoding=serialization.Encoding.PEM,\n        format=serialization.PublicFormat.SubjectPublicKeyInfo\n    ).decode()\n\n    return pem_public_key, pem_private_key\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.Code.generate_seed","title":"<code>generate_seed()</code>  <code>staticmethod</code>","text":"<p>Erzeugt eine zuf\u00e4llige Zahl als Seed.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Eine zuf\u00e4llige Zahl.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef generate_seed() -&gt; int:\n    \"\"\"\n    Erzeugt eine zuf\u00e4llige Zahl als Seed.\n\n    Returns:\n        int: Eine zuf\u00e4llige Zahl.\n    \"\"\"\n    return random.randint(2 ** 32 - 1, 2 ** 64 - 1)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.Code.generate_symmetric_key","title":"<code>generate_symmetric_key(as_str=True)</code>  <code>staticmethod</code>","text":"<p>Generiert einen Schl\u00fcssel f\u00fcr die symmetrische Verschl\u00fcsselung.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str or bytes</code> <p>Der generierte Schl\u00fcssel.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef generate_symmetric_key(as_str=True) -&gt; str or bytes:\n    \"\"\"\n    Generiert einen Schl\u00fcssel f\u00fcr die symmetrische Verschl\u00fcsselung.\n\n    Returns:\n        str: Der generierte Schl\u00fcssel.\n    \"\"\"\n    key = Fernet.generate_key()\n    if as_str:\n        key = key.decode()\n    return key\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.Code.load_keys_from_files","title":"<code>load_keys_from_files(directory='keys')</code>  <code>staticmethod</code>","text":"<p>L\u00e4dt die Schl\u00fcssel aus den Dateien. Der private Schl\u00fcssel wird mit dem Device Key entschl\u00fcsselt.</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>str</code> <p>Das Verzeichnis, aus dem die Schl\u00fcssel geladen werden sollen</p> <code>'keys'</code> <p>Returns:</p> Type Description <code>(str, str)</code> <p>Ein Tupel aus \u00f6ffentlichem und privatem Schl\u00fcssel</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>Wenn die Schl\u00fcsseldateien nicht gefunden werden k\u00f6nnen</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef load_keys_from_files(directory: str = \"keys\") -&gt; (str, str):\n    \"\"\"\n    L\u00e4dt die Schl\u00fcssel aus den Dateien.\n    Der private Schl\u00fcssel wird mit dem Device Key entschl\u00fcsselt.\n\n    Args:\n        directory (str): Das Verzeichnis, aus dem die Schl\u00fcssel geladen werden sollen\n\n    Returns:\n        (str, str): Ein Tupel aus \u00f6ffentlichem und privatem Schl\u00fcssel\n\n    Raises:\n        FileNotFoundError: Wenn die Schl\u00fcsseldateien nicht gefunden werden k\u00f6nnen\n    \"\"\"\n    # Pfade zu den Schl\u00fcsseldateien\n    public_key_path = os.path.join(directory, \"public_key.pem\")\n    private_key_path = os.path.join(directory, \"private_key.pem\")\n\n    # Pr\u00fcfe ob die Dateien existieren\n    if not os.path.exists(public_key_path) or not os.path.exists(private_key_path):\n        return \"\", \"\"\n\n    # Hole den Device Key\n    device_key = DEVICE_KEY()\n\n    # Lade den \u00f6ffentlichen Schl\u00fcssel\n    with open(public_key_path) as f:\n        public_key = f.read()\n\n    # Lade und entschl\u00fcssele den privaten Schl\u00fcssel\n    with open(private_key_path) as f:\n        encrypted_private_key = f.read()\n        private_key = Code.decrypt_symmetric(encrypted_private_key, device_key)\n\n    return public_key, private_key\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.Code.one_way_hash","title":"<code>one_way_hash(text, salt='', pepper='')</code>  <code>staticmethod</code>","text":"<p>Erzeugt einen Hash eines gegebenen Textes mit Salt, Pepper und optional einem Seed.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Der zu hashende Text.</p> required <code>salt</code> <code>str</code> <p>Der Salt-Wert.</p> <code>''</code> <code>pepper</code> <code>str</code> <p>Der Pepper-Wert.</p> <code>''</code> <code>seed</code> <code>int</code> <p>Ein optionaler Seed-Wert. Standardm\u00e4\u00dfig None.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Der resultierende Hash-Wert.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef one_way_hash(text: str, salt: str = '', pepper: str = '') -&gt; str:\n    \"\"\"\n    Erzeugt einen Hash eines gegebenen Textes mit Salt, Pepper und optional einem Seed.\n\n    Args:\n        text (str): Der zu hashende Text.\n        salt (str): Der Salt-Wert.\n        pepper (str): Der Pepper-Wert.\n        seed (int, optional): Ein optionaler Seed-Wert. Standardm\u00e4\u00dfig None.\n\n    Returns:\n        str: Der resultierende Hash-Wert.\n    \"\"\"\n    return hashlib.sha256((salt + text + pepper).encode()).hexdigest()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.Code.pem_to_public_key","title":"<code>pem_to_public_key(pem_key)</code>  <code>staticmethod</code>","text":"<p>Konvertiert einen PEM-kodierten \u00f6ffentlichen Schl\u00fcssel in ein PublicKey-Objekt.</p> <p>Parameters:</p> Name Type Description Default <code>pem_key</code> <code>str</code> <p>Der PEM-kodierte \u00f6ffentliche Schl\u00fcssel.</p> required <p>Returns:</p> Name Type Description <code>PublicKey</code> <p>Das PublicKey-Objekt.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef pem_to_public_key(pem_key: str):\n    \"\"\"\n    Konvertiert einen PEM-kodierten \u00f6ffentlichen Schl\u00fcssel in ein PublicKey-Objekt.\n\n    Args:\n        pem_key (str): Der PEM-kodierte \u00f6ffentliche Schl\u00fcssel.\n\n    Returns:\n        PublicKey: Das PublicKey-Objekt.\n    \"\"\"\n    public_key = serialization.load_pem_public_key(pem_key.encode())\n    return public_key\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.Code.public_key_to_pem","title":"<code>public_key_to_pem(public_key)</code>  <code>staticmethod</code>","text":"<p>Konvertiert ein PublicKey-Objekt in einen PEM-kodierten String.</p> <p>Parameters:</p> Name Type Description Default <code>public_key</code> <code>PublicKey</code> <p>Das PublicKey-Objekt.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>Der PEM-kodierte \u00f6ffentliche Schl\u00fcssel.</p> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef public_key_to_pem(public_key: RSAPublicKey):\n    \"\"\"\n    Konvertiert ein PublicKey-Objekt in einen PEM-kodierten String.\n\n    Args:\n        public_key (PublicKey): Das PublicKey-Objekt.\n\n    Returns:\n        str: Der PEM-kodierte \u00f6ffentliche Schl\u00fcssel.\n    \"\"\"\n    pem = public_key.public_bytes(\n        encoding=serialization.Encoding.PEM,\n        format=serialization.PublicFormat.SubjectPublicKeyInfo\n    )\n    return pem.decode()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.Code.save_keys_to_files","title":"<code>save_keys_to_files(public_key, private_key, directory='keys')</code>  <code>staticmethod</code>","text":"<p>Speichert die generierten Schl\u00fcssel in separate Dateien. Der private Schl\u00fcssel wird mit dem Device Key verschl\u00fcsselt.</p> <p>Parameters:</p> Name Type Description Default <code>public_key</code> <code>str</code> <p>Der \u00f6ffentliche Schl\u00fcssel im PEM-Format</p> required <code>private_key</code> <code>str</code> <p>Der private Schl\u00fcssel im PEM-Format</p> required <code>directory</code> <code>str</code> <p>Das Verzeichnis, in dem die Schl\u00fcssel gespeichert werden sollen</p> <code>'keys'</code> Source code in <code>toolboxv2/utils/security/cryp.py</code> <pre><code>@staticmethod\ndef save_keys_to_files(public_key: str, private_key: str, directory: str = \"keys\") -&gt; None:\n    \"\"\"\n    Speichert die generierten Schl\u00fcssel in separate Dateien.\n    Der private Schl\u00fcssel wird mit dem Device Key verschl\u00fcsselt.\n\n    Args:\n        public_key (str): Der \u00f6ffentliche Schl\u00fcssel im PEM-Format\n        private_key (str): Der private Schl\u00fcssel im PEM-Format\n        directory (str): Das Verzeichnis, in dem die Schl\u00fcssel gespeichert werden sollen\n    \"\"\"\n    # Erstelle das Verzeichnis, falls es nicht existiert\n    os.makedirs(directory, exist_ok=True)\n\n    # Hole den Device Key\n    device_key = DEVICE_KEY()\n\n    # Verschl\u00fcssele den privaten Schl\u00fcssel mit dem Device Key\n    encrypted_private_key = Code.encrypt_symmetric(private_key, device_key)\n\n    # Speichere den \u00f6ffentlichen Schl\u00fcssel\n    public_key_path = os.path.join(directory, \"public_key.pem\")\n    with open(public_key_path, \"w\") as f:\n        f.write(public_key)\n\n    # Speichere den verschl\u00fcsselten privaten Schl\u00fcssel\n    private_key_path = os.path.join(directory, \"private_key.pem\")\n    with open(private_key_path, \"w\") as f:\n        f.write(encrypted_private_key)\n\n    print(\"Saved keys in \", public_key_path)\n</code></pre>"},{"location":"toolboxv2/#modules-flows","title":"Modules &amp; Flows","text":""},{"location":"toolboxv2/#toolboxv2.mods","title":"<code>toolboxv2.mods</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.Canvas","title":"<code>Canvas</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.Canvas.Tools","title":"<code>Tools</code>","text":"<p>               Bases: <code>MainTool</code></p> Source code in <code>toolboxv2/mods/Canvas.py</code> <pre><code>class Tools(MainTool):  # Removed EventManager for simplicity, as it was causing the issue. Direct SSE is better here.\n    def __init__(self, app: App):\n        self.name = MOD_NAME\n        self.version = VERSION\n        self.color = \"GREEN\"\n        self.tools_dict = {\"name\": MOD_NAME, \"Version\": self.show_version}\n\n        # Canvas specific state\n        self.live_canvas_sessions: dict[str, list[asyncio.Queue]] = defaultdict(list)\n        self.active_user_previews: dict[str, dict[str, Any]] = defaultdict(dict)\n        self.previews_lock = asyncio.Lock()\n\n        MainTool.__init__(self, load=on_start, v=self.version, tool=self.tools_dict, name=self.name,\n                          color=self.color, app=app)\n        self.app.logger.info(f\"Canvas Tools (v{self.version}) initialized for app {self.app.id}.\")\n\n    @property\n    def db_mod(self):\n        db = self.app.get_mod(\"DB\", spec=Name)\n        if db.mode.value != \"CLUSTER_BLOB\":\n            db.edit_cli(\"CB\")\n        return db\n\n    def _broadcast_to_canvas_listeners(self, canvas_id: str, event_type: str, data: dict[str, Any],\n                                       originator_user_id: str | None = None):\n        \"\"\"\n        Creates a broadcast coroutine and submits it to the app's dedicated\n        async manager to be run in the background.\n        This is now a non-blocking fire-and-forget operation.\n        \"\"\"\n\n        async def broadcast_coro():\n            if canvas_id not in self.live_canvas_sessions:\n                return\n\n            message_obj = {\n                \"event\": event_type,\n                \"data\": json.dumps({\n                    \"canvas_id\": canvas_id,\n                    \"originator_user_id\": originator_user_id,\n                    **data\n                })\n            }\n\n            listeners = list(self.live_canvas_sessions.get(canvas_id, []))\n\n            for q in listeners:\n                try:\n                    # Non-blocking put. If the queue is full, the client is lagging,\n                    # and it's better to drop a message than to block the server.\n                    q.put_nowait(message_obj)\n                except asyncio.QueueFull:\n                    self.app.logger.warning(\n                        f\"SSE queue full for canvas {canvas_id}. Message '{event_type}' dropped for one client.\")\n                except Exception as e:\n                    self.app.logger.error(f\"Error putting message on SSE queue: {e}\")\n\n        # Use the app's robust background runner to execute immediately and not block the caller.\n        self.app.run_bg_task(broadcast_coro)\n\n    def show_version(self):\n        self.app.logger.info(f\"{self.name} Version: {self.version}\")\n        return self.version\n\n    async def _get_user_specific_db_key(self, request: RequestData, base_key: str) -&gt; str | None:\n        # This logic is correct and can remain as is.\n\n        user = await get_user_from_request(self.app, request)\n        if user and user.uid:\n            return f\"{base_key}_{user.uid}\"\n        self.print(\"ok\")\n        # Fallback for public/guest access if you want to support it\n        return f\"{base_key}_public\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.Canvas.handle_send_canvas_action","title":"<code>handle_send_canvas_action(app, request, data)</code>  <code>async</code>","text":"<p>Handles incremental, real-time actions from clients (e.g., adding an element). It persists the change to the database and then broadcasts it to all live listeners.</p> Source code in <code>toolboxv2/mods/Canvas.py</code> <pre><code>@export(mod_name=MOD_NAME, api=True, version=VERSION, name=\"send_canvas_action\", api_methods=['POST'],\n        request_as_kwarg=True)\nasync def handle_send_canvas_action(app: App, request: RequestData, data: dict[str, Any]):\n    \"\"\"\n    Handles incremental, real-time actions from clients (e.g., adding an element).\n    It persists the change to the database and then broadcasts it to all live listeners.\n    \"\"\"\n    canvas_tool = app.get_mod(MOD_NAME)\n    if not canvas_tool or not canvas_tool.db_mod:\n        return Result.default_internal_error(\"Canvas module or DB not loaded.\")\n\n    if not data:\n        return Result.default_user_error(\"Request data is missing.\", 400)\n\n    canvas_id = data.get(\"canvas_id\")\n    action_type = data.get(\"action_type\")\n    action_payload = data.get(\"payload\")\n    user_id = data.get(\"user_id\")\n\n    if not all([canvas_id, action_type, user_id]) or action_payload is None:\n        return Result.default_user_error(\"Request missing required fields.\", 400)\n\n    # --- Flow 1: Ephemeral 'preview' actions that DO NOT get persisted ---\n    if action_type in [\"preview_update\", \"preview_clear\"]:\n        sse_event_type = \"user_preview_update\" if action_type == \"preview_update\" else \"clear_user_preview\"\n        sse_data = {\"user_id\": user_id}\n\n        async with canvas_tool.previews_lock:\n            if action_type == \"preview_update\":\n                canvas_tool.active_user_previews[canvas_id][user_id] = action_payload\n                sse_data[\"preview_data\"] = action_payload\n            elif user_id in canvas_tool.active_user_previews.get(canvas_id, {}):\n                del canvas_tool.active_user_previews[canvas_id][user_id]\n\n        # MODIFICATION: Call the non-blocking broadcast method. This returns immediately.\n        canvas_tool._broadcast_to_canvas_listeners(\n            canvas_id=canvas_id, event_type=sse_event_type,\n            data=sse_data, originator_user_id=user_id\n        )\n        return Result.ok(info=f\"'{action_type}' broadcasted.\")\n\n    # --- Flow 2: Persistent actions that modify the canvas state ---\n    if action_type not in [\"element_add\", \"element_update\", \"element_remove\"]:\n        return Result.default_user_error(f\"Unknown persistent action_type: {action_type}\", 400)\n\n    # Load the full, current session state from the database\n    user_db_key_base = await canvas_tool._get_user_specific_db_key(request, SESSION_DATA_PREFIX)\n    session_db_key = f\"{user_db_key_base}_{canvas_id}\"\n    try:\n        db_result = canvas_tool.db_mod.get(session_db_key)\n        if not db_result or db_result.is_error() or not db_result.get():\n            return Result.default_user_error(\"Canvas session not found in database.\", 404)\n\n        session_data_str = db_result.get()[0] if isinstance(db_result.get(), list) else db_result.get()\n        session_data = IdeaSessionData.model_validate_json(session_data_str)\n    except Exception as e:\n        app.logger.error(f\"DB Load/Parse failed for C:{canvas_id}. Error: {e}\", exc_info=True)\n        return Result.default_internal_error(\"Could not load canvas data to apply changes.\")\n\n    # Apply the action to the in-memory Pydantic object\n    if action_type == \"element_add\":\n        session_data.canvas_elements.append(CanvasElement(**action_payload))\n    elif action_type == \"element_update\":\n        element_id = action_payload.get(\"id\")\n        for i, el in enumerate(session_data.canvas_elements):\n            if el.id == element_id:\n                session_data.canvas_elements[i] = el.model_copy(update=action_payload)\n                break\n    elif action_type == \"element_remove\":\n        ids_to_remove = set(action_payload.get(\"ids\", [action_payload.get(\"id\")]))\n        session_data.canvas_elements = [el for el in session_data.canvas_elements if el.id not in ids_to_remove]\n\n    # Save the modified object back to the database\n    session_data.last_modified = datetime.now(UTC).timestamp()\n    canvas_tool.db_mod.set(session_db_key, session_data.model_dump_json(exclude_none=True))\n\n    # Broadcast the successful, persisted action to all connected clients\n    # MODIFICATION: Call the non-blocking broadcast method.\n    canvas_tool._broadcast_to_canvas_listeners(\n        canvas_id=canvas_id,\n        event_type=\"canvas_elements_changed\",\n        data={\"action\": action_type, \"element\": action_payload},\n        originator_user_id=user_id\n    )\n\n    # Clear the temporary preview of the user who made the change\n    async with canvas_tool.previews_lock:\n        if user_id in canvas_tool.active_user_previews.get(canvas_id, {}):\n            del canvas_tool.active_user_previews[canvas_id][user_id]\n\n    # MODIFICATION: Call the non-blocking broadcast method.\n    canvas_tool._broadcast_to_canvas_listeners(\n        canvas_id=canvas_id, event_type=\"clear_user_preview\",\n        data={\"user_id\": user_id}, originator_user_id=user_id\n    )\n\n    return Result.ok(info=f\"Action '{action_type}' persisted and broadcast.\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.Canvas.markdown_to_svg","title":"<code>markdown_to_svg(self, request, markdown_text='', width=400, font_family='sans-serif', font_size=14, bg_color='#ffffff', text_color='#000000')</code>  <code>async</code>","text":"<p>Converts a string of Markdown text into an SVG image. The SVG is returned as a base64 encoded data URL. This version uses a viewBox for better scalability and multi-line handling.</p> Source code in <code>toolboxv2/mods/Canvas.py</code> <pre><code>@export(mod_name=MOD_NAME, api=True, version=VERSION, name=\"markdown_to_svg\", api_methods=['POST'],\n        request_as_kwarg=True)\nasync def markdown_to_svg(self, request: RequestData, markdown_text: str = \"\", width: int = 400,\n                          font_family: str = \"sans-serif\", font_size: int = 14,\n                          bg_color: str = \"#ffffff\", text_color: str = \"#000000\") -&gt; Result:\n    \"\"\"\n    Converts a string of Markdown text into an SVG image.\n    The SVG is returned as a base64 encoded data URL.\n    This version uses a viewBox for better scalability and multi-line handling.\n    \"\"\"\n    if request is None:\n        return Result.default_user_error(\"Request data is missing.\", 400)\n    if not markdown_text and request.data:\n        markdown_text = request.data.get(\"markdown_text\", \"\")\n\n    if not markdown_text:\n        return Result.default_user_error(\"markdown_text cannot be empty.\")\n\n    try:\n        # Convert Markdown to HTML\n        html_content = markdown2.markdown(markdown_text, extras=[\"fenced-code-blocks\", \"tables\", \"strike\"])\n\n        # --- FIX for Multi-line text ---\n        # The key is to NOT set a fixed height on the SVG itself, but to use a viewBox.\n        # The client will determine the final rendered size.\n        # The width of the div inside the foreignObject controls the line wrapping.\n\n        # We still need a rough height for the viewBox.\n        # Estimate height: (number of lines * line-height) + padding\n        # A simple line-height estimate is font_size * 1.6\n        line_height_estimate = font_size * 1.6\n        num_lines_estimate = len(html_content.split('\\n')) + html_content.count('&lt;br') + html_content.count(\n            '&lt;p&gt;') + html_content.count('&lt;li&gt;')\n        estimated_height = (num_lines_estimate * line_height_estimate) + 40  # 20px top/bottom padding\n\n        svg_template = f\"\"\"\n        &lt;svg viewBox=\"0 0 {width} {int(estimated_height)}\" xmlns=\"http://www.w3.org/2000/svg\"&gt;\n            &lt;foreignObject x=\"0\" y=\"0\" width=\"{width}\" height=\"{int(estimated_height)}\"&gt;\n                &lt;div xmlns=\"http://www.w3.org/1999/xhtml\"&gt;\n                    &lt;style&gt;\n                        div {{\n                            font-family: {font_family};\n                            font-size: {font_size}px;\n                            color: {text_color};\n                            background-color: {bg_color};\n                            padding: 10px;\n                            border-radius: 5px;\n                            line-height: 1.6;\n                            width: {width - 20}px; /* Width minus padding */\n                            word-wrap: break-word;\n                            height: 100%;\n                            overflow-y: auto; /* Allow scrolling if content overflows estimate */\n                        }}\n                        h1, h2, h3 {{ border-bottom: 1px solid #ccc; padding-bottom: 5px; margin-top: 1em; }}\n                        pre {{ background-color: #f0f0f0; padding: 10px; border-radius: 4px; overflow-x: auto; }}\n                        code {{ font-family: monospace; }}\n                        table {{ border-collapse: collapse; width: 100%; }}\n                        th, td {{ border: 1px solid #ddd; padding: 8px; }}\n                        th {{ background-color: #f2f2f2; }}\n                        blockquote {{ border-left: 4px solid #ccc; padding-left: 10px; color: #555; margin-left: 0; }}\n                    &lt;/style&gt;\n                    {html_content}\n                &lt;/div&gt;\n            &lt;/foreignObject&gt;\n        &lt;/svg&gt;\n        \"\"\"\n\n        svg_base64 = base64.b64encode(svg_template.encode('utf-8')).decode('utf-8')\n        data_url = f\"data:image/svg+xml;base64,{svg_base64}\"\n\n        # --- FIX for Editability ---\n        # Return the original markdown text along with the SVG\n        return Result.ok(data={\"svg_data_url\": data_url, \"original_markdown\": markdown_text})\n\n    except Exception as e:\n        self.app.logger.error(f\"Error converting Markdown to SVG: {e}\", exc_info=True)\n        return Result.default_internal_error(\"Failed to convert Markdown to SVG.\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.Canvas.save_session","title":"<code>save_session(app, request, data)</code>  <code>async</code>","text":"<p>Saves the entire state of a canvas session to the database. This is typically triggered by a user's explicit \"Save\" action.</p> Source code in <code>toolboxv2/mods/Canvas.py</code> <pre><code>@export(mod_name=MOD_NAME, api=True, version=VERSION, name=\"save_session\", api_methods=['POST'], request_as_kwarg=True)\nasync def save_session(app: App, request: RequestData, data: dict[str, Any] | IdeaSessionData) -&gt; Result:\n    \"\"\"\n    Saves the entire state of a canvas session to the database.\n    This is typically triggered by a user's explicit \"Save\" action.\n    \"\"\"\n    if not data:\n        return Result.default_user_error(\"Request data is missing.\", 400)\n    if request is None:\n        return Result.default_user_error(\"Request data is missing.\", 400)\n    canvas_tool = app.get_mod(MOD_NAME)\n    if not canvas_tool or not canvas_tool.db_mod:\n        app.logger.error(\"Save failed: Canvas module or DB not available.\")\n        return Result.custom_error(info=\"Database module not available.\", exec_code=503)\n\n    user_db_key_base = await canvas_tool._get_user_specific_db_key(request, SESSION_DATA_PREFIX)\n    if not user_db_key_base:\n        return Result.default_user_error(info=\"User authentication required to save.\", exec_code=401)\n\n    try:\n        # Validate the incoming data against the Pydantic model\n        session_data_obj = IdeaSessionData(**data) if isinstance(data, dict) else data\n    except Exception as e:\n        app.logger.error(f\"Invalid session data for save: {e}. Data: {str(data)[:500]}\", exc_info=True)\n        return Result.default_user_error(info=f\"Invalid session data format: {e}\", exec_code=400)\n\n    # Update timestamp and construct the main session key\n    if session_data_obj:\n        session_data_obj.last_modified = datetime.now(UTC).timestamp()\n    session_db_key = f\"{user_db_key_base}_{session_data_obj.id}\"\n\n    # Save the full session object to the database\n    canvas_tool.db_mod.set(session_db_key, session_data_obj.model_dump_json(exclude_none=True))\n    app.logger.info(f\"Saved session data for C:{session_data_obj.id}\")\n\n    # --- Update the session list metadata ---\n    session_list_key = f\"{user_db_key_base}{SESSION_LIST_KEY_SUFFIX}\"\n    try:\n        list_res_obj = canvas_tool.db_mod.get(session_list_key)\n        user_sessions = []\n        if list_res_obj and not list_res_obj.is_error() and list_res_obj.get():\n            list_content = list_res_obj.get()[0] if isinstance(list_res_obj.get(), list) else list_res_obj.get()\n            user_sessions = json.loads(list_content)\n\n        # Find and update the existing entry, or add a new one\n        session_metadata = {\n            \"id\": session_data_obj.id,\n            \"name\": session_data_obj.name,\n            \"last_modified\": session_data_obj.last_modified\n        }\n        found_in_list = False\n        for i, sess_meta in enumerate(user_sessions):\n            if sess_meta.get(\"id\") == session_data_obj.id:\n                user_sessions[i] = session_metadata\n                found_in_list = True\n                break\n        if not found_in_list:\n            user_sessions.append(session_metadata)\n\n        canvas_tool.db_mod.set(session_list_key, json.dumps(user_sessions))\n        app.logger.info(f\"Updated session list for user key ending in ...{user_db_key_base[-12:]}\")\n\n    except Exception as e:\n        app.logger.error(f\"Failed to update session list for C:{session_data_obj.id}. Error: {e}\", exc_info=True)\n        # Non-fatal error; the main data was saved. We can continue.\n\n    return Result.ok(\n        info=\"Session saved successfully.\",\n        data={\"id\": session_data_obj.id, \"last_modified\": session_data_obj.last_modified}\n    )\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.ChatModule","title":"<code>ChatModule</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.ChatModule.get_chat_ui","title":"<code>get_chat_ui(app)</code>","text":"<p>Liefert das Haupt-HTML-UI f\u00fcr das Chat-Widget. Es verwendet <code>app.web_context()</code>, um das notwendige tbjs CSS und JS einzubinden.</p> Source code in <code>toolboxv2/mods/ChatModule.py</code> <pre><code>@export(mod_name=Name, version=version, api=True, name=\"ui\", row=True)\ndef get_chat_ui(app: App) -&gt; Result:\n    \"\"\"\n    Liefert das Haupt-HTML-UI f\u00fcr das Chat-Widget.\n    Es verwendet `app.web_context()`, um das notwendige tbjs CSS und JS einzubinden.\n    \"\"\"\n\n    html_content = f\"\"\"\n        {app.web_context()}\n        &lt;style&gt;\n            body {{\n                display: flex;\n                align-items: center;\n                justify-content: center;\n                min-height: 100vh;\n                padding: 1rem;\n                background-color: var(--theme-bg);\n            }}\n        &lt;/style&gt;\n        &lt;main id=\"chat-container\" style=\"width: 100%; height: 80vh;\"&gt;\n            &lt;!-- Das Chat-Widget wird hier initialisiert --&gt;\n        &lt;/main&gt;\n\n        &lt;script unsave=\"true\"&gt;\n            // Verwende TB.once, um sicherzustellen, dass das Framework vollst\u00e4ndig initialisiert ist,\n            // bevor unser Code ausgef\u00fchrt wird.\n            TB.once(() =&gt; {{\n                const chatContainer = document.getElementById('chat-container');\n                if (chatContainer &amp;&amp; TB.ui.ChatWidget) {{\n                    // Initialisiere das Chat-Widget in unserem Container\n                    TB.ui.ChatWidget.init(chatContainer);\n\n                    // Verbinde mit dem in diesem Modul definierten WebSocket-Endpunkt\n                    TB.ui.ChatWidget.connect();\n                }} else {{\n                    console.error(\"Chat UI initialization failed: container or ChatWidget not found.\");\n                }}\n            }});\n        &lt;/script&gt;\n    \"\"\"\n\n    return Result.html(data=html_content)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.ChatModule.on_chat_message","title":"<code>on_chat_message(app, conn_id, session, payload)</code>  <code>async</code>","text":"<p>Wird aufgerufen, wenn eine Nachricht von einem Client empfangen wird.</p> Source code in <code>toolboxv2/mods/ChatModule.py</code> <pre><code>async def on_chat_message(app: App, conn_id: str, session: dict, payload: dict):\n    \"\"\"\n    Wird aufgerufen, wenn eine Nachricht von einem Client empfangen wird.\n    \"\"\"\n    username = session.get(\"user_name\", \"Anonymous\")\n    print(f\"WS MESSAGE from {username} ({conn_id}): {session}\")\n    message_text = payload.get(\"data\", {}).get(\"message\", \"\").strip()\n\n    if not message_text:\n        return  # Ignoriere leere Nachrichten\n\n    app.print(f\"WS MESSAGE from {username} ({conn_id}): {message_text}\")\n\n    # Sende die Nachricht an alle im Raum (einschlie\u00dflich des Absenders)\n    await app.ws_broadcast(\n        channel_id=\"ChatModule/public_room\",\n        payload={\"event\": \"new_message\", \"data\": {\"user\": username, \"text\": message_text}}\n    )\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.ChatModule.on_user_connect","title":"<code>on_user_connect(app, conn_id, session)</code>  <code>async</code>","text":"<p>Wird vom Rust WebSocket Actor aufgerufen, wenn ein neuer Client eine Verbindung herstellt.</p> Source code in <code>toolboxv2/mods/ChatModule.py</code> <pre><code>async def on_user_connect(app: App, conn_id: str, session: dict):\n    \"\"\"\n    Wird vom Rust WebSocket Actor aufgerufen, wenn ein neuer Client eine Verbindung herstellt.\n    \"\"\"\n    username = session.get(\"user_name\", \"Anonymous\")\n    app.print(f\"WS CONNECT: User '{username}' connected with conn_id: {conn_id}\")\n\n    # Sende eine Willkommensnachricht direkt an den neuen Benutzer (1-zu-1)\n    await app.ws_send(conn_id, {\"event\": \"welcome\", \"data\": f\"Welcome to the public chat, {username}!\"})\n\n    # K\u00fcndige den neuen Benutzer allen anderen im Raum an (1-zu-n)\n    await app.ws_broadcast(\n        channel_id=\"ChatModule/public_room\",\n        payload={\"event\": \"user_joined\", \"data\": f\"\ud83d\udc4b {username} has joined the chat.\"},\n        source_conn_id=conn_id  # Schlie\u00dft den Absender von diesem Broadcast aus\n    )\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.ChatModule.on_user_disconnect","title":"<code>on_user_disconnect(app, conn_id, session=None)</code>  <code>async</code>","text":"<p>Wird aufgerufen, wenn die Verbindung eines Clients geschlossen wird.</p> Source code in <code>toolboxv2/mods/ChatModule.py</code> <pre><code>async def on_user_disconnect(app: App, conn_id: str, session: dict=None):\n    \"\"\"\n    Wird aufgerufen, wenn die Verbindung eines Clients geschlossen wird.\n    \"\"\"\n    if session is None:\n        session = {}\n    username = session.get(\"user_name\", \"Anonymous\")\n    app.print(f\"WS DISCONNECT: User '{username}' disconnected (conn_id: {conn_id})\")\n\n    # K\u00fcndige den Weggang des Benutzers allen verbleibenden Benutzern im Raum an\n    await app.ws_broadcast(\n        channel_id=\"ChatModule/public_room\",\n        payload={\"event\": \"user_left\", \"data\": f\"\ud83d\ude25 {username} has left the chat.\"}\n    )\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.ChatModule.register_chat_handlers","title":"<code>register_chat_handlers(app)</code>","text":"<p>Registriert die asynchronen Funktionen als Handler f\u00fcr spezifische WebSocket-Ereignisse. Der Funktionsname (<code>register_chat_handlers</code>) ist beliebig. Der Decorator ist entscheidend.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Ein Dictionary, das Ereignisnamen auf ihre Handler-Funktionen abbildet.</p> Source code in <code>toolboxv2/mods/ChatModule.py</code> <pre><code>@export(mod_name=Name, version=version, websocket_handler=\"public_room\")\ndef register_chat_handlers(app: App) -&gt; dict:\n    \"\"\"\n    Registriert die asynchronen Funktionen als Handler f\u00fcr spezifische WebSocket-Ereignisse.\n    Der Funktionsname (`register_chat_handlers`) ist beliebig. Der Decorator ist entscheidend.\n\n    Returns:\n        Ein Dictionary, das Ereignisnamen auf ihre Handler-Funktionen abbildet.\n    \"\"\"\n    return {\n        \"on_connect\": on_user_connect,\n        \"on_message\": on_chat_message,\n        \"on_disconnect\": on_user_disconnect,\n    }\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CloudM","title":"<code>CloudM</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.CloudM.check_multiple_processes","title":"<code>check_multiple_processes(pids)</code>","text":"<p>Checks the status of multiple processes in a single system call. Returns a dictionary mapping PIDs to their status (GREEN_CIRCLE, RED_CIRCLE, or YELLOW_CIRCLE).</p> Source code in <code>toolboxv2/mods/CloudM/mini.py</code> <pre><code>def check_multiple_processes(pids: list[int]) -&gt; dict[int, str]:\n    \"\"\"\n    Checks the status of multiple processes in a single system call.\n    Returns a dictionary mapping PIDs to their status (GREEN_CIRCLE, RED_CIRCLE, or YELLOW_CIRCLE).\n    \"\"\"\n    if not pids:\n        return {}\n\n    pid_status = {}\n\n    if os.name == 'nt':  # Windows\n        try:\n            # Windows tasklist requires separate /FI for each filter\n            command = 'tasklist'\n\n            # Add encoding handling for Windows\n            result = subprocess.run(\n                command,\n                capture_output=True,\n                text=True,\n                shell=True,\n                encoding='cp850'  # Use cp850 for Windows console output\n            )\n            # Create a set of running PIDs from the output\n            running_pids = set()\n            for line in result.stdout.lower().split('\\n'):\n                for pid in pids:\n                    if str(pid) in line:\n                        running_pids.add(pid)\n            # Assign status based on whether PID was found in output\n            for pid in pids:\n                if pid in running_pids:\n                    pid_status[pid] = GREEN_CIRCLE\n                else:\n                    pid_status[pid] = RED_CIRCLE\n\n        except subprocess.SubprocessError as e:\n            print(f\"SubprocessError: {e}\")  # For debugging\n            # Mark all as YELLOW_CIRCLE if there's an error running the command\n            for pid in pids:\n                pid_status[pid] = YELLOW_CIRCLE\n        except UnicodeDecodeError as e:\n            print(f\"UnicodeDecodeError: {e}\")  # For debugging\n            # Try alternate encoding if cp850 fails\n            try:\n                result = subprocess.run(\n                    command,\n                    capture_output=True,\n                    text=True,\n                    shell=True,\n                    encoding='utf-8'\n                )\n                running_pids = set()\n                for line in result.stdout.lower().split('\\n'):\n                    for pid in pids:\n                        if str(pid) in line:\n                            running_pids.add(pid)\n\n                for pid in pids:\n                    pid_status[pid] = GREEN_CIRCLE if pid in running_pids else RED_CIRCLE\n            except Exception as e:\n                print(f\"Failed with alternate encoding: {e}\")  # For debugging\n                for pid in pids:\n                    pid_status[pid] = YELLOW_CIRCLE\n\n    else:  # Unix/Linux/Mac\n        try:\n            pids_str = ','.join(str(pid) for pid in pids)\n            command = f'ps -p {pids_str} -o pid='\n\n            result = subprocess.run(\n                command,\n                capture_output=True,\n                text=True,\n                shell=True,\n                encoding='utf-8'\n            )\n            running_pids = set(int(pid) for pid in result.stdout.strip().split())\n\n            for pid in pids:\n                pid_status[pid] = GREEN_CIRCLE if pid in running_pids else RED_CIRCLE\n\n        except subprocess.SubprocessError as e:\n            print(f\"SubprocessError: {e}\")  # For debugging\n            for pid in pids:\n                pid_status[pid] = YELLOW_CIRCLE\n\n    return pid_status\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CloudM.get_service_pids","title":"<code>get_service_pids(info_dir)</code>","text":"<p>Extracts service names and PIDs from pid files.</p> Source code in <code>toolboxv2/mods/CloudM/mini.py</code> <pre><code>def get_service_pids(info_dir):\n    \"\"\"Extracts service names and PIDs from pid files.\"\"\"\n    services = {}\n    pid_files = [f for f in os.listdir(info_dir) if re.match(r'(.+)-(.+)\\.pid', f)]\n    for pid_file in pid_files:\n        match = re.match(r'(.+)-(.+)\\.pid', pid_file)\n        if match:\n            services_type, service_name = match.groups()\n            # Read the PID from the file\n            with open(os.path.join(info_dir, pid_file)) as file:\n                pid = file.read().strip()\n                # Store the PID using a formatted key\n                services[f\"{service_name} - {services_type}\"] = int(pid)\n    return services\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CloudM.get_service_status","title":"<code>get_service_status(dir)</code>","text":"<p>Displays the status of all services.</p> Source code in <code>toolboxv2/mods/CloudM/mini.py</code> <pre><code>def get_service_status(dir: str) -&gt; str:\n    \"\"\"Displays the status of all services.\"\"\"\n    if time.time()-services_data_sto_last_update_time[0] &gt; 30:\n        services = get_service_pids(dir)\n        services_data_sto[0] = services\n        services_data_sto_last_update_time[0] = time.time()\n    else:\n        services = services_data_sto[0]\n    if not services:\n        return \"No services found\"\n\n    # Get status for all PIDs in a single call\n    pid_statuses = check_multiple_processes(list(services.values()))\n\n    # Build the status string\n    res_s = \"Service(s):\" + (\"\\n\" if len(services) &gt; 1 else ' ')\n    for service_name, pid in services.items():\n        status = pid_statuses.get(pid, YELLOW_CIRCLE)\n        res_s += f\"{status} {service_name} (PID: {pid})\\n\"\n    services_data_display[0] = res_s.strip()\n    return res_s.rstrip()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CloudM.AuthManager","title":"<code>AuthManager</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.CloudM.AuthManager.delete_user","title":"<code>delete_user(app, username)</code>","text":"<p>Deletes a user and all their data.</p> Source code in <code>toolboxv2/mods/CloudM/AuthManager.py</code> <pre><code>@export(mod_name=Name, state=True, test=False, interface=ToolBoxInterfaces.native)\ndef delete_user(app: App, username: str):\n    \"\"\"Deletes a user and all their data.\"\"\"\n    if not db_helper_test_exist(app, username):\n        return Result.default_user_error(f\"User '{username}' not found.\")\n\n    # This will delete all entries matching the user\n    result = db_helper_delete_user(app, username, '*', matching=True)\n\n    if result.is_ok():\n        # Also remove the local private key file if it exists\n        app.config_fh.remove_key_file_handler(\"Pk\" + Code.one_way_hash(username, \"dvp-k\")[:8])\n        return Result.ok(f\"User '{username}' deleted successfully.\")\n    else:\n        return Result.default_internal_error(f\"Failed to delete user '{username}'.\", data=result)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CloudM.AuthManager.list_users","title":"<code>list_users(app)</code>","text":"<p>Lists all registered users.</p> Source code in <code>toolboxv2/mods/CloudM/AuthManager.py</code> <pre><code>@export(mod_name=Name, state=True, test=False, interface=ToolBoxInterfaces.native)\ndef list_users(app: App):\n    \"\"\"Lists all registered users.\"\"\"\n    keys_result = app.run_any(TBEF.DB.GET, query=\"all-k\", get_results=True)\n    if keys_result.is_error():\n        return keys_result\n\n    user_keys = keys_result.get()\n    if not user_keys:\n        return Result.ok(\"No users found.\")\n\n    users = []\n    for key in user_keys:\n        if isinstance(key, bytes):\n            key = key.decode()\n        if not key.startswith(\"USER::\"):\n            continue\n        # Extract username from the key USER::username::uid\n        parts = key.split('::')\n        if len(parts) &gt; 1 and parts[1] not in [u['username'] for u in users]:\n            user_res = get_user_by_name(app, parts[1])\n            if user_res.is_ok():\n                user_data = user_res.get()\n                users.append({\"username\": user_data.name, \"email\": user_data.email, \"level\": user_data.level})\n\n    return Result.ok(data=users)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CloudM.ModManager","title":"<code>ModManager</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.CloudM.ModManager.create_and_pack_module","title":"<code>create_and_pack_module(path, module_name='', version='-.-.-', additional_dirs=None, yaml_data=None)</code>","text":"<p>Erstellt ein Python-Modul und packt es in eine ZIP-Datei.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Pfad zum Ordner oder zur Datei, die in das Modul aufgenommen werden soll.</p> required <code>additional_dirs</code> <code>dict</code> <p>Zus\u00e4tzliche Verzeichnisse, die hinzugef\u00fcgt werden sollen.</p> <code>None</code> <code>version</code> <code>str</code> <p>Version des Moduls.</p> <code>'-.-.-'</code> <code>module_name</code> <code>str</code> <p>Name des Moduls.</p> <code>''</code> <p>Returns:</p> Name Type Description <code>str</code> <p>Pfad zur erstellten ZIP-Datei.</p> Source code in <code>toolboxv2/mods/CloudM/ModManager.py</code> <pre><code>def create_and_pack_module(path, module_name='', version='-.-.-', additional_dirs=None, yaml_data=None):\n    \"\"\"\n    Erstellt ein Python-Modul und packt es in eine ZIP-Datei.\n\n    Args:\n        path (str): Pfad zum Ordner oder zur Datei, die in das Modul aufgenommen werden soll.\n        additional_dirs (dict): Zus\u00e4tzliche Verzeichnisse, die hinzugef\u00fcgt werden sollen.\n        version (str): Version des Moduls.\n        module_name (str): Name des Moduls.\n\n    Returns:\n        str: Pfad zur erstellten ZIP-Datei.\n    \"\"\"\n    if additional_dirs is None:\n        additional_dirs = {}\n    if yaml_data is None:\n        yaml_data = {}\n\n    os.makedirs(\"./mods_sto/temp/\", exist_ok=True)\n\n    module_path = os.path.join(path, module_name)\n    print(\"module_pathmodule_pathmodule_path\", module_path)\n    if not os.path.exists(module_path):\n        module_path += '.py'\n\n    temp_dir = tempfile.mkdtemp(dir=os.path.join(\"./mods_sto\", \"temp\"))\n    zip_file_name = f\"RST${module_name}&amp;{__version__}\u00a7{version}.zip\"\n    zip_path = f\"./mods_sto/{zip_file_name}\"\n\n    # Modulverzeichnis erstellen, falls es nicht existiert\n    if not os.path.exists(module_path):\n        return False\n\n    if os.path.isdir(module_path):\n        # tbConfig.yaml erstellen\n        config_path = os.path.join(module_path, \"tbConfig.yaml\")\n        with open(config_path, 'w') as config_file:\n            yaml.dump({\"version\": version, \"module_name\": module_name,\n                       \"dependencies_file\": f\"./mods/{module_name}/requirements.txt\",\n                       \"zip\": zip_file_name, **yaml_data}, config_file)\n\n        generate_requirements(module_path, os.path.join(module_path, \"requirements.txt\"))\n    # Datei oder Ordner in das Modulverzeichnis kopieren\n    if os.path.isdir(module_path):\n        shutil.copytree(module_path, os.path.join(temp_dir, os.path.basename(module_path)), dirs_exist_ok=True)\n    else:\n        shutil.copy2(module_path, temp_dir)\n        config_path = os.path.join(temp_dir, f\"{module_name}.yaml\")\n        with open(config_path, 'w') as config_file:\n            yaml.dump({\"version\": version, \"dependencies_file\": f\"./mods/{module_name}/requirements.txt\",\n                       \"module_name\": module_name, **yaml_data}, config_file)\n        generate_requirements(temp_dir, os.path.join(temp_dir, \"requirements.txt\"))\n    # Zus\u00e4tzliche Verzeichnisse hinzuf\u00fcgen\n    for dir_name, dir_paths in additional_dirs.items():\n        if isinstance(dir_paths, str):\n            dir_paths = [dir_paths]\n        for dir_path in dir_paths:\n            full_path = os.path.join(temp_dir, dir_name)\n            if os.path.isdir(dir_path):\n                shutil.copytree(dir_path, full_path, dirs_exist_ok=True)\n            elif os.path.isfile(dir_path):\n                # Stellen Sie sicher, dass das Zielverzeichnis existiert\n                os.makedirs(full_path, exist_ok=True)\n                # Kopieren Sie die Datei statt des Verzeichnisses\n                shutil.copy2(dir_path, full_path)\n            else:\n                print(f\"Der Pfad {dir_path} ist weder ein Verzeichnis noch eine Datei.\")\n\n    # Modul in eine ZIP-Datei packen\n    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        for root, _dirs, files in os.walk(temp_dir):\n            for file in files:\n                file_path = os.path.join(root, file)\n                zipf.write(file_path, os.path.relpath(file_path, temp_dir))\n\n    # Temperatures Modulverzeichnis l\u00f6schen\n    shutil.rmtree(temp_dir)\n\n    return zip_path\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CloudM.ModManager.download_files","title":"<code>download_files(urls, directory, desc, print_func, filename=None)</code>","text":"<p>Hilfsfunktion zum Herunterladen von Dateien.</p> Source code in <code>toolboxv2/mods/CloudM/ModManager.py</code> <pre><code>def download_files(urls, directory, desc, print_func, filename=None):\n    \"\"\" Hilfsfunktion zum Herunterladen von Dateien. \"\"\"\n    for url in tqdm(urls, desc=desc):\n        if filename is None:\n            filename = os.path.basename(url)\n        print_func(f\"Download {filename}\")\n        print_func(f\"{url} -&gt; {directory}/{filename}\")\n        os.makedirs(directory, exist_ok=True)\n        urllib.request.urlretrieve(url, f\"{directory}/{filename}\")\n    return f\"{directory}/{filename}\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CloudM.ModManager.handle_requirements","title":"<code>handle_requirements(requirements_url, module_name, print_func)</code>","text":"<p>Verarbeitet und installiert Requirements.</p> Source code in <code>toolboxv2/mods/CloudM/ModManager.py</code> <pre><code>def handle_requirements(requirements_url, module_name, print_func):\n    \"\"\" Verarbeitet und installiert Requirements. \"\"\"\n    if requirements_url:\n        requirements_filename = f\"{module_name}-requirements.txt\"\n        print_func(f\"Download requirements {requirements_filename}\")\n        urllib.request.urlretrieve(requirements_url, requirements_filename)\n\n        print_func(\"Install requirements\")\n        run_command(\n            [sys.executable, \"-m\", \"pip\", \"install\", \"-r\", requirements_filename])\n\n        os.remove(requirements_filename)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CloudM.ModManager.increment_version","title":"<code>increment_version(version_str, max_value=99)</code>","text":"<p>Inkrementiert eine Versionsnummer im Format \"vX.Y.Z\".</p> <p>Parameters:</p> Name Type Description Default <code>version_str</code> <code>str</code> <p>Die aktuelle Versionsnummer, z. B. \"v0.0.1\".</p> required <code>max_value</code> <code>int</code> <p>Die maximale Zahl pro Stelle (default: 99).</p> <code>99</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Die inkrementierte Versionsnummer.</p> Source code in <code>toolboxv2/mods/CloudM/ModManager.py</code> <pre><code>def increment_version(version_str: str, max_value: int = 99) -&gt; str:\n    \"\"\"\n    Inkrementiert eine Versionsnummer im Format \"vX.Y.Z\".\n\n    Args:\n        version_str (str): Die aktuelle Versionsnummer, z. B. \"v0.0.1\".\n        max_value (int): Die maximale Zahl pro Stelle (default: 99).\n\n    Returns:\n        str: Die inkrementierte Versionsnummer.\n    \"\"\"\n    if not version_str.startswith(\"v\"):\n        raise ValueError(\"Die Versionsnummer muss mit 'v' beginnen, z. B. 'v0.0.1'.\")\n\n    # Entferne das f\u00fchrende 'v' und parse die Versionsnummer\n    version_core = version_str[1:]\n    try:\n        version = Version(version_core)\n    except ValueError as e:\n        raise ValueError(f\"Ung\u00fcltige Versionsnummer: {version_core}\") from e\n\n    # Extrahiere die Versionsteile und konvertiere sie zu einer Liste\n    parts = list(version.release)\n\n    # Inkrementiere die letzte Stelle\n    for i in range(len(parts) - 1, -1, -1):\n        if parts[i] &lt; max_value:\n            parts[i] += 1\n            break\n        else:\n            parts[i] = 0\n            # Schleife f\u00e4hrt fort, um die n\u00e4chsth\u00f6here Stelle zu inkrementieren\n    else:\n        # Wenn alle Stellen auf \"max_value\" sind, f\u00fcge eine neue Stelle hinzu\n        parts.insert(0, 1)\n\n    # Baue die neue Version\n    new_version = \"v\" + \".\".join(map(str, parts))\n    return new_version\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CloudM.ModManager.installer","title":"<code>installer(app, module_name, build_state=True)</code>  <code>async</code>","text":"<p>Installiert oder aktualisiert ein Modul basierend auf der Remote-Version.</p> Source code in <code>toolboxv2/mods/CloudM/ModManager.py</code> <pre><code>@export(mod_name=Name, name=\"install\", test=False)\nasync def installer(app: App | None, module_name: str, build_state=True):\n    \"\"\"\n    Installiert oder aktualisiert ein Modul basierend auf der Remote-Version.\n    \"\"\"\n    if app is None:\n        app = get_app(f\"{Name}.installer\")\n\n    if not app.session.valid and not await app.session.login():\n        return Result.default_user_error(\"Please login with CloudM login\")\n\n    # Hole nur die h\u00f6chste verf\u00fcgbare Version vom Server\n    response = await app.session.fetch(f\"/api/{Name}/getModVersion?module_name={module_name}\", method=\"GET\")\n    remote_version: str = await response.text()\n    if remote_version == \"None\":\n        remote_version = None\n    # Finde lokale Version\n    local_version = find_highest_zip_version(\n        module_name, version_only=True\n    )\n\n    if not local_version and not remote_version:\n        return Result.default_user_error(f\"404 mod {module_name} not found\")\n\n    # Vergleiche Versionen\n    local_ver = pv.parse(local_version) if local_version else pv.parse(\"0.0.0\")\n    remote_ver = pv.parse(remote_version)\n\n    app.print(f\"Mod versions - Local: {local_ver}, Remote: {remote_ver}\")\n\n    if remote_ver &gt; local_ver:\n        # Konstruiere die URL direkt aus Modulname und Version\n        download_path = Path(app.start_dir) / 'mods_sto'\n\n        app.print(f\"Fetching Mod from {app.session.base}/api/{Name}/download_mod?module_name={module_name}\")\n        if not await app.session.download_file(f\"/api/{Name}/download_mod?module_name={module_name}\", str(download_path)):\n            app.print(\"Failed to download mod\")\n            if 'y' not in input(\"Download manually and place in mods_sto folder. Done? (y/n) \").lower():\n                return Result.default_user_error(\"Installation cancelled\")\n\n        # Korrigiere Dateinamen\n        zip_name = f\"RST${module_name}&amp;{app.version}\u00a7{remote_version}.zip\"\n\n        with Spinner(\"Installing from zip\"):\n            report = install_from_zip(app, zip_name)\n\n        if not report:\n            return Result.default_user_error(\"Setup error occurred\")\n\n        if build_state:\n            get_state_from_app(app)\n\n        return report\n\n    app.print(\"Module is already up to date\")\n    return Result.ok()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CloudM.ModManager.run_command","title":"<code>run_command(command, cwd=None)</code>","text":"<p>F\u00fchrt einen Befehl aus und gibt den Output zur\u00fcck.</p> Source code in <code>toolboxv2/mods/CloudM/ModManager.py</code> <pre><code>def run_command(command, cwd=None):\n    \"\"\"F\u00fchrt einen Befehl aus und gibt den Output zur\u00fcck.\"\"\"\n    result = subprocess.run(command, cwd=cwd, capture_output=True, text=True, check=True,\n                            encoding='cp850')\n    return result.stdout\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CloudM.ModManager.uninstall_module","title":"<code>uninstall_module(path, module_name='', version='-.-.-', additional_dirs=None, yaml_data=None)</code>","text":"<p>Deinstalliert ein Python-Modul, indem es das Modulverzeichnis oder die ZIP-Datei entfernt.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Pfad zum Ordner oder zur Datei, die in das Modul aufgenommen werden soll.</p> required <code>additional_dirs</code> <code>dict</code> <p>Zus\u00e4tzliche Verzeichnisse, die hinzugef\u00fcgt werden sollen.</p> <code>None</code> <code>version</code> <code>str</code> <p>Version des Moduls.</p> <code>'-.-.-'</code> <code>module_name</code> <code>str</code> <p>Name des Moduls.</p> <code>''</code> Source code in <code>toolboxv2/mods/CloudM/ModManager.py</code> <pre><code>def uninstall_module(path, module_name='', version='-.-.-', additional_dirs=None, yaml_data=None):\n    \"\"\"\n    Deinstalliert ein Python-Modul, indem es das Modulverzeichnis oder die ZIP-Datei entfernt.\n\n    Args:\n        path (str): Pfad zum Ordner oder zur Datei, die in das Modul aufgenommen werden soll.\n        additional_dirs (dict): Zus\u00e4tzliche Verzeichnisse, die hinzugef\u00fcgt werden sollen.\n        version (str): Version des Moduls.\n        module_name (str): Name des Moduls.\n\n    \"\"\"\n    if additional_dirs is None:\n        additional_dirs = {}\n    if yaml_data is None:\n        yaml_data = {}\n\n    os.makedirs(\"./mods_sto/temp/\", exist_ok=True)\n\n    base_path = os.path.dirname(path)\n    module_path = os.path.join(base_path, module_name)\n    zip_path = f\"./mods_sto/RST${module_name}&amp;{__version__}\u00a7{version}.zip\"\n\n    # Modulverzeichnis erstellen, falls es nicht existiert\n    if not os.path.exists(module_path):\n        print(\"Module %s already uninstalled\")\n        return False\n\n    # Datei oder Ordner in das Modulverzeichnis kopieren\n    shutil.rmtree(module_path)\n\n    # Zus\u00e4tzliche Verzeichnisse hinzuf\u00fcgen\n    for _dir_name, dir_paths in additional_dirs.items():\n        if isinstance(dir_paths, str):\n            dir_paths = [dir_paths]\n        for dir_path in dir_paths:\n            shutil.rmtree(dir_path)\n            print(f\"Der Pfad {dir_path} wurde entfernt\")\n\n    # Urspr\u00fcngliches Modulverzeichnis l\u00f6schen\n    shutil.rmtree(zip_path)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CloudM.ModManager.unpack_and_move_module","title":"<code>unpack_and_move_module(zip_path, base_path='./mods', module_name='')</code>","text":"<p>Entpackt eine ZIP-Datei und verschiebt die Inhalte an die richtige Stelle. \u00dcberschreibt existierende Dateien f\u00fcr Update-Unterst\u00fctzung.</p> <p>Parameters:</p> Name Type Description Default <code>zip_path</code> <code>str</code> <p>Pfad zur ZIP-Datei, die entpackt werden soll</p> required <code>base_path</code> <code>str</code> <p>Basispfad, unter dem das Modul gespeichert werden soll</p> <code>'./mods'</code> <code>module_name</code> <code>str</code> <p>Name des Moduls (optional, wird sonst aus ZIP-Namen extrahiert)</p> <code>''</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Name des installierten Moduls</p> Source code in <code>toolboxv2/mods/CloudM/ModManager.py</code> <pre><code>def unpack_and_move_module(zip_path: str, base_path: str = './mods', module_name: str = '') -&gt; str:\n    \"\"\"\n    Entpackt eine ZIP-Datei und verschiebt die Inhalte an die richtige Stelle.\n    \u00dcberschreibt existierende Dateien f\u00fcr Update-Unterst\u00fctzung.\n\n    Args:\n        zip_path (str): Pfad zur ZIP-Datei, die entpackt werden soll\n        base_path (str): Basispfad, unter dem das Modul gespeichert werden soll\n        module_name (str): Name des Moduls (optional, wird sonst aus ZIP-Namen extrahiert)\n\n    Returns:\n        str: Name des installierten Moduls\n    \"\"\"\n    # Konvertiere Pfade zu Path-Objekten f\u00fcr bessere Handhabung\n    zip_path = Path(zip_path)\n    base_path = Path(base_path)\n\n    # Extrahiere Modulnamen falls nicht angegeben\n    if not module_name:\n        module_name = zip_path.name.split('$')[1].split('&amp;')[0]\n\n    module_path = base_path / module_name\n    temp_base = Path('./mods_sto/temp')\n\n    try:\n        # Erstelle tempor\u00e4res Verzeichnis\n        temp_base.mkdir(parents=True, exist_ok=True)\n        with tempfile.TemporaryDirectory(dir=str(temp_base)) as temp_dir:\n            temp_dir = Path(temp_dir)\n\n            with Spinner(f\"Extracting {zip_path.name}\"):\n                # Entpacke ZIP-Datei\n                with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n                    zip_ref.extractall(temp_dir)\n\n            # Behandle Modul-Verzeichnis\n            source_module = temp_dir / module_name\n            if source_module.exists():\n                with Spinner(f\"Installing module to {module_path}\"):\n                    if module_path.exists():\n                        # L\u00f6sche existierendes Modul-Verzeichnis f\u00fcr sauberes Update\n                        shutil.rmtree(module_path)\n                    # Verschiebe neues Modul-Verzeichnis\n                    shutil.copytree(source_module, module_path, dirs_exist_ok=True)\n\n            # Behandle zus\u00e4tzliche Dateien im Root\n            with Spinner(\"Installing additional files\"):\n                for item in temp_dir.iterdir():\n                    if item.name == module_name:\n                        continue\n\n                    target = Path('./') / item.name\n                    if item.is_dir():\n                        with Spinner(f\"Installing directory {item.name}\"):\n                            if target.exists():\n                                shutil.rmtree(target)\n                            shutil.copytree(item, target, dirs_exist_ok=True)\n                    else:\n                        with Spinner(f\"Installing file {item.name}\"):\n                            shutil.copy2(item, target)\n\n            print(f\"Successfully installed/updated module {module_name} to {module_path}\")\n            return module_name\n\n    except Exception as e:\n        print(f\"Error during installation: {str(e)}\")\n        # Cleanup bei Fehler\n        if module_path.exists():\n            shutil.rmtree(module_path)\n        raise\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CloudM.ModManager_tests","title":"<code>ModManager_tests</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.CloudM.ModManager_tests.TestModManager","title":"<code>TestModManager</code>","text":"<p>               Bases: <code>TestCase</code></p> Source code in <code>toolboxv2/mods/CloudM/ModManager_tests.py</code> <pre><code>class TestModManager(unittest.TestCase):\n    app: App = None\n\n    def test_increment_version(self):\n        \"\"\"Tests the version increment logic.\"\"\"\n        print(\"\\nTesting increment_version...\")\n        self.assertEqual(increment_version(\"v0.0.1\"), \"v0.0.2\")\n        self.assertEqual(increment_version(\"v0.0.99\", max_value=99), \"v0.1.0\")\n        self.assertEqual(increment_version(\"v0.99.99\", max_value=99), \"v1.0.0\")\n        self.assertEqual(increment_version(\"v98\"), \"v99\")\n        with self.assertRaises(ValueError, msg=\"Should fail if 'v' is missing\"):\n            print(increment_version(\"0.0.1\"))\n        print(\"increment_version tests passed.\")\n\n    def setUp(self):\n        \"\"\"Set up a temporary environment for each test.\"\"\"\n        self.original_cwd = os.getcwd()\n        self.test_dir = tempfile.mkdtemp(prefix=\"mod_manager_test_\")\n\n        # The functions in ModManager use relative paths like './mods' and './mods_sto'\n        # We'll create these inside our temp directory and chdir into it.\n        os.chdir(self.test_dir)\n        os.makedirs(\"mods\", exist_ok=True)\n        os.makedirs(\"mods_sto\", exist_ok=True)\n        os.makedirs(\"source_module\", exist_ok=True)\n\n    def tearDown(self):\n        \"\"\"Clean up the temporary environment after each test.\"\"\"\n        os.chdir(self.original_cwd)\n        shutil.rmtree(self.test_dir, ignore_errors=True)\n\n    def test_create_pack_unpack_cycle(self):\n        \"\"\"Tests the full cycle of creating, packing, and unpacking a module.\"\"\"\n        print(\"\\nTesting create_pack_unpack_cycle...\")\n        module_name = \"MyTestMod\"\n        module_version = \"v0.1.0\"\n\n        # 1. Create a dummy module structure inside the temp 'source_module' dir\n        source_path = Path(\"source_module\")\n        module_source_path = source_path / module_name\n        module_source_path.mkdir()\n        (module_source_path / \"main.py\").write_text(\"print('hello from my test mod')\")\n        (module_source_path / \"data.txt\").write_text(\"some test data\")\n\n        # 2. Call create_and_pack_module\n        # The 'path' argument is the parent directory of the module directory.\n        zip_path_str = create_and_pack_module(\n            path=str(source_path),\n            module_name=module_name,\n            version=module_version\n        )\n        self.assertTrue(zip_path_str, \"create_and_pack_module should return a path.\")\n        zip_path = Path(zip_path_str)\n\n        # 3. Assert the zip file was created in the correct location ('./mods_sto')\n        self.assertTrue(zip_path.exists(), f\"Zip file should exist at {zip_path}\")\n        self.assertEqual(zip_path.parent.name, \"mods_sto\")\n\n        # 4. Call unpack_and_move_module\n        # We unpack into the './mods' directory.\n        unpacked_name = unpack_and_move_module(\n            zip_path=str(zip_path),\n            base_path=\"mods\"\n        )\n\n        # 5. Assert the module was unpacked correctly\n        self.assertEqual(unpacked_name, module_name)\n        unpacked_dir = Path(\"mods\") / module_name\n        self.assertTrue(unpacked_dir.is_dir(), \"Unpacked module directory should exist.\")\n\n        # Verify content\n        self.assertTrue((unpacked_dir / \"main.py\").exists())\n        self.assertEqual((unpacked_dir / \"main.py\").read_text(), \"print('hello from my test mod')\")\n        self.assertTrue((unpacked_dir / \"data.txt\").exists())\n        self.assertEqual((unpacked_dir / \"data.txt\").read_text(), \"some test data\")\n\n        # Verify that the tbConfig.yaml was created and has correct info\n        config_path = unpacked_dir / \"tbConfig.yaml\"\n        self.assertTrue(config_path.exists())\n        with open(config_path) as f:\n            config = yaml.safe_load(f)\n        self.assertEqual(config.get(\"module_name\"), module_name)\n        self.assertEqual(config.get(\"version\"), module_version)\n\n        print(\"create_pack_unpack_cycle tests passed.\")\n\n    def test_install_from_zip(self):\n        \"\"\"Tests the install_from_zip helper function.\"\"\"\n        print(\"\\nTesting install_from_zip...\")\n        module_name = \"MyInstallTestMod\"\n        module_version = \"v0.1.1\"\n\n        # 1. Create a dummy module and zip it\n        source_path = Path(\"source_module\")\n        module_source_path = source_path / module_name\n        module_source_path.mkdir()\n        (module_source_path / \"main.py\").write_text(\"pass\")\n        zip_path_str = create_and_pack_module(\n            path=str(source_path),\n            module_name=module_name,\n            version=module_version\n        )\n        zip_path = Path(zip_path_str)\n        zip_name = zip_path.name\n\n        # 2. Mock the app object needed by install_from_zip\n        mock_app = lambda :None\n        mock_app.start_dir = self.test_dir\n\n        # 3. Call install_from_zip\n        result = install_from_zip(mock_app, zip_name, no_dep=True)\n\n        # 4. Assert the installation was successful\n        self.assertTrue(result)\n        unpacked_dir = Path(\"mods\") / module_name\n        self.assertTrue(unpacked_dir.is_dir())\n        self.assertTrue((unpacked_dir / \"main.py\").exists())\n        print(\"install_from_zip tests passed.\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CloudM.ModManager_tests.TestModManager.setUp","title":"<code>setUp()</code>","text":"<p>Set up a temporary environment for each test.</p> Source code in <code>toolboxv2/mods/CloudM/ModManager_tests.py</code> <pre><code>def setUp(self):\n    \"\"\"Set up a temporary environment for each test.\"\"\"\n    self.original_cwd = os.getcwd()\n    self.test_dir = tempfile.mkdtemp(prefix=\"mod_manager_test_\")\n\n    # The functions in ModManager use relative paths like './mods' and './mods_sto'\n    # We'll create these inside our temp directory and chdir into it.\n    os.chdir(self.test_dir)\n    os.makedirs(\"mods\", exist_ok=True)\n    os.makedirs(\"mods_sto\", exist_ok=True)\n    os.makedirs(\"source_module\", exist_ok=True)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CloudM.ModManager_tests.TestModManager.tearDown","title":"<code>tearDown()</code>","text":"<p>Clean up the temporary environment after each test.</p> Source code in <code>toolboxv2/mods/CloudM/ModManager_tests.py</code> <pre><code>def tearDown(self):\n    \"\"\"Clean up the temporary environment after each test.\"\"\"\n    os.chdir(self.original_cwd)\n    shutil.rmtree(self.test_dir, ignore_errors=True)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CloudM.ModManager_tests.TestModManager.test_create_pack_unpack_cycle","title":"<code>test_create_pack_unpack_cycle()</code>","text":"<p>Tests the full cycle of creating, packing, and unpacking a module.</p> Source code in <code>toolboxv2/mods/CloudM/ModManager_tests.py</code> <pre><code>def test_create_pack_unpack_cycle(self):\n    \"\"\"Tests the full cycle of creating, packing, and unpacking a module.\"\"\"\n    print(\"\\nTesting create_pack_unpack_cycle...\")\n    module_name = \"MyTestMod\"\n    module_version = \"v0.1.0\"\n\n    # 1. Create a dummy module structure inside the temp 'source_module' dir\n    source_path = Path(\"source_module\")\n    module_source_path = source_path / module_name\n    module_source_path.mkdir()\n    (module_source_path / \"main.py\").write_text(\"print('hello from my test mod')\")\n    (module_source_path / \"data.txt\").write_text(\"some test data\")\n\n    # 2. Call create_and_pack_module\n    # The 'path' argument is the parent directory of the module directory.\n    zip_path_str = create_and_pack_module(\n        path=str(source_path),\n        module_name=module_name,\n        version=module_version\n    )\n    self.assertTrue(zip_path_str, \"create_and_pack_module should return a path.\")\n    zip_path = Path(zip_path_str)\n\n    # 3. Assert the zip file was created in the correct location ('./mods_sto')\n    self.assertTrue(zip_path.exists(), f\"Zip file should exist at {zip_path}\")\n    self.assertEqual(zip_path.parent.name, \"mods_sto\")\n\n    # 4. Call unpack_and_move_module\n    # We unpack into the './mods' directory.\n    unpacked_name = unpack_and_move_module(\n        zip_path=str(zip_path),\n        base_path=\"mods\"\n    )\n\n    # 5. Assert the module was unpacked correctly\n    self.assertEqual(unpacked_name, module_name)\n    unpacked_dir = Path(\"mods\") / module_name\n    self.assertTrue(unpacked_dir.is_dir(), \"Unpacked module directory should exist.\")\n\n    # Verify content\n    self.assertTrue((unpacked_dir / \"main.py\").exists())\n    self.assertEqual((unpacked_dir / \"main.py\").read_text(), \"print('hello from my test mod')\")\n    self.assertTrue((unpacked_dir / \"data.txt\").exists())\n    self.assertEqual((unpacked_dir / \"data.txt\").read_text(), \"some test data\")\n\n    # Verify that the tbConfig.yaml was created and has correct info\n    config_path = unpacked_dir / \"tbConfig.yaml\"\n    self.assertTrue(config_path.exists())\n    with open(config_path) as f:\n        config = yaml.safe_load(f)\n    self.assertEqual(config.get(\"module_name\"), module_name)\n    self.assertEqual(config.get(\"version\"), module_version)\n\n    print(\"create_pack_unpack_cycle tests passed.\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CloudM.ModManager_tests.TestModManager.test_increment_version","title":"<code>test_increment_version()</code>","text":"<p>Tests the version increment logic.</p> Source code in <code>toolboxv2/mods/CloudM/ModManager_tests.py</code> <pre><code>def test_increment_version(self):\n    \"\"\"Tests the version increment logic.\"\"\"\n    print(\"\\nTesting increment_version...\")\n    self.assertEqual(increment_version(\"v0.0.1\"), \"v0.0.2\")\n    self.assertEqual(increment_version(\"v0.0.99\", max_value=99), \"v0.1.0\")\n    self.assertEqual(increment_version(\"v0.99.99\", max_value=99), \"v1.0.0\")\n    self.assertEqual(increment_version(\"v98\"), \"v99\")\n    with self.assertRaises(ValueError, msg=\"Should fail if 'v' is missing\"):\n        print(increment_version(\"0.0.1\"))\n    print(\"increment_version tests passed.\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CloudM.ModManager_tests.TestModManager.test_install_from_zip","title":"<code>test_install_from_zip()</code>","text":"<p>Tests the install_from_zip helper function.</p> Source code in <code>toolboxv2/mods/CloudM/ModManager_tests.py</code> <pre><code>def test_install_from_zip(self):\n    \"\"\"Tests the install_from_zip helper function.\"\"\"\n    print(\"\\nTesting install_from_zip...\")\n    module_name = \"MyInstallTestMod\"\n    module_version = \"v0.1.1\"\n\n    # 1. Create a dummy module and zip it\n    source_path = Path(\"source_module\")\n    module_source_path = source_path / module_name\n    module_source_path.mkdir()\n    (module_source_path / \"main.py\").write_text(\"pass\")\n    zip_path_str = create_and_pack_module(\n        path=str(source_path),\n        module_name=module_name,\n        version=module_version\n    )\n    zip_path = Path(zip_path_str)\n    zip_name = zip_path.name\n\n    # 2. Mock the app object needed by install_from_zip\n    mock_app = lambda :None\n    mock_app.start_dir = self.test_dir\n\n    # 3. Call install_from_zip\n    result = install_from_zip(mock_app, zip_name, no_dep=True)\n\n    # 4. Assert the installation was successful\n    self.assertTrue(result)\n    unpacked_dir = Path(\"mods\") / module_name\n    self.assertTrue(unpacked_dir.is_dir())\n    self.assertTrue((unpacked_dir / \"main.py\").exists())\n    print(\"install_from_zip tests passed.\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CloudM.ModManager_tests.run_mod_manager_tests","title":"<code>run_mod_manager_tests(app)</code>","text":"<p>This function will be automatically discovered and run by the test runner. It uses the standard unittest framework to run tests.</p> Source code in <code>toolboxv2/mods/CloudM/ModManager_tests.py</code> <pre><code>@export(test_only=True)\ndef run_mod_manager_tests(app: App):\n    \"\"\"\n    This function will be automatically discovered and run by the test runner.\n    It uses the standard unittest framework to run tests.\n    \"\"\"\n    print(\"Running ModManager Tests...\")\n    # We pass the app instance to the test class so it can be used if needed.\n    TestModManager.app = app\n    suite = unittest.TestSuite()\n    suite.addTest(unittest.makeSuite(TestModManager))\n    runner = unittest.TextTestRunner()\n    result = runner.run(suite)\n    if not result.wasSuccessful():\n        # Raise an exception to signal failure to the toolboxv2 test runner\n        raise AssertionError(f\"ModManager tests failed: {result.errors} {result.failures}\")\n    print(\"ModManager tests passed successfully.\")\n    return True\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CloudM.UserAccountManager","title":"<code>UserAccountManager</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.CloudM.UserAccountManager.get_current_user_from_request_api_wrapper","title":"<code>get_current_user_from_request_api_wrapper(app, request)</code>  <code>async</code>","text":"<p>API callable version of get_current_user_from_request for tbjs/admin panel</p> Source code in <code>toolboxv2/mods/CloudM/UserAccountManager.py</code> <pre><code>@export(mod_name=Name, api=True, version=version, request_as_kwarg=True, row=False)  # row=False to return JSON\nasync def get_current_user_from_request_api_wrapper(app: App, request: RequestData):\n    \"\"\" API callable version of get_current_user_from_request for tbjs/admin panel \"\"\"\n    user = await get_current_user_from_request(app, request)\n    if not user:\n        # Return error that tbjs can handle\n        return Result.default_user_error(info=\"User not authenticated or found.\", data=None, exec_code=401)\n    user_dict = asdict(user)\n    pub_user_data = {}\n    for key in ['name','pub_key','email','creation_time','is_persona','level','log_level','settings']:\n        pub_user_data[key] = user_dict.get(key, None)\n    return Result.ok(data=pub_user_data)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CloudM.email_services","title":"<code>email_services</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.CloudM.email_services.send_email_verification_email","title":"<code>send_email_verification_email(app, user_email, username, verification_url)</code>","text":"<p>Sends an email verification link to the user.</p> Source code in <code>toolboxv2/mods/CloudM/email_services.py</code> <pre><code>@s_export\ndef send_email_verification_email(app: App, user_email: str, username: str, verification_url: str):\n    \"\"\"Sends an email verification link to the user.\"\"\"\n    sender = EmailSender(app)\n    subject = f\"Verify Your Email for {APP_NAME}\"\n    preview_text = f\"Almost there, {username}! Just one more step to activate your account.\"\n\n    content_html = f\"\"\"\n        &lt;h2&gt;Hi {username},&lt;/h2&gt;\n        &lt;p&gt;Thanks for signing up for {APP_NAME}! To complete your registration, please verify your email address by clicking the button below.&lt;/p&gt;\n        &lt;a href=\"{verification_url}\" class=\"button\"&gt;Verify Email Address&lt;/a&gt;\n        &lt;p&gt;If you didn't create an account with {APP_NAME}, you can safely ignore this email.&lt;/p&gt;\n        &lt;p&gt;If the button doesn't work, copy and paste this link into your browser:&lt;br&gt;&lt;span class=\"link-in-text\"&gt;{verification_url}&lt;/span&gt;&lt;/p&gt;\n        &lt;p&gt;Sincerely,&lt;br&gt;The {APP_NAME} Team&lt;/p&gt;\n    \"\"\"\n    return sender.send_html_email(user_email, subject, content_html, preview_text)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CloudM.email_services.send_magic_link_email","title":"<code>send_magic_link_email(app, user_email, magic_link_url, username=None)</code>","text":"<p>Sends a magic link email for login.</p> Source code in <code>toolboxv2/mods/CloudM/email_services.py</code> <pre><code>@s_export\ndef send_magic_link_email(app: App, user_email: str, magic_link_url: str, username: str = None):\n    \"\"\"Sends a magic link email for login.\"\"\"\n    sender = EmailSender(app)\n    greeting_name = f\", {username}\" if username else \"\"\n    subject = f\"Your Magic Login Link for {APP_NAME}\"\n    preview_text = \"Securely access your account with this one-time link.\"\n\n    content_html = f\"\"\"\n        &lt;h2&gt;Hello{greeting_name}!&lt;/h2&gt;\n        &lt;p&gt;You requested a magic link to sign in to your {APP_NAME} account.&lt;/p&gt;\n        &lt;p&gt;Click the button below to log in. This link is temporary and will expire shortly.&lt;/p&gt;\n        &lt;a href=\"{magic_link_url}\" class=\"button\"&gt;Log In Securely&lt;/a&gt;\n        &lt;p&gt; Invitation key: {magic_link_url.split('?key=')[1].split('&amp;name=')[0].replace('%23', '#')}&lt;/p&gt;\n        &lt;p&gt;If you did not request this link, please ignore this email. Your account is safe.&lt;/p&gt;\n        &lt;p&gt;If the button doesn't work, copy and paste this link into your browser:&lt;br&gt;&lt;span class=\"link-in-text\"&gt;{magic_link_url}&lt;/span&gt;&lt;/p&gt;\n        &lt;p&gt;Thanks,&lt;br&gt;The {APP_NAME} Team&lt;/p&gt;\n    \"\"\"\n    return sender.send_html_email(user_email, subject, content_html, preview_text)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CloudM.email_services.send_signup_invitation_email","title":"<code>send_signup_invitation_email(app, invited_user_email, invited_username, inviter_username=None)</code>","text":"<p>Generates an invitation link and sends it via email.</p> Source code in <code>toolboxv2/mods/CloudM/email_services.py</code> <pre><code>@s_export\ndef send_signup_invitation_email(app: App, invited_user_email: str, invited_username: str,\n                                 inviter_username: str = None):\n    \"\"\"Generates an invitation link and sends it via email.\"\"\"\n    sender = EmailSender(app)\n\n    # Generate invitation code as specified in the prompt\n    # This uses the Code class, assuming TB_R_KEY is set in the environment\n    invitation_code = Code.one_way_hash(invited_username, \"00#\", os.getenv(\"TB_R_KEY\", \"pepper123\"))[:12] + str(\n        uuid.uuid4())[:6]\n\n    # Construct the signup link URL (adjust your frontend signup path as needed)\n    signup_link_url = f\"{APP_BASE_URL}/web/assets/signup.html?invitation={quote(invitation_code)}&amp;email={quote(invited_user_email)}&amp;username={quote(invited_username)}\"\n\n    subject = f\"You're Invited to Join {APP_NAME}!\"\n    preview_text = f\"{inviter_username or 'A friend'} has invited you to {APP_NAME}!\"\n    inviter_line = f\"&lt;p&gt;{inviter_username} has invited you to join.&lt;/p&gt;\" if inviter_username else \"&lt;p&gt;You've been invited to join.&lt;/p&gt;\"\n\n    content_html = f\"\"\"\n        &lt;h2&gt;Hello {invited_username},&lt;/h2&gt;\n        {inviter_line}\n        &lt;p&gt;{APP_NAME} is an exciting platform, and we'd love for you to be a part of it!&lt;/p&gt;\n        &lt;p&gt;Click the button below to accept the invitation and create your account:&lt;/p&gt;\n        &lt;a href=\"{signup_link_url}\" class=\"button\"&gt;Accept Invitation &amp; Sign Up&lt;/a&gt;\n        &lt;p&gt;This invitation is unique to you : {invitation_code}&lt;/p&gt;\n        &lt;p&gt;If the button doesn't work, copy and paste this link into your browser:&lt;br&gt;&lt;span class=\"link-in-text\"&gt;{signup_link_url}&lt;/span&gt;&lt;/p&gt;\n        &lt;p&gt;We look forward to seeing you there!&lt;br&gt;The {APP_NAME} Team&lt;/p&gt;\n    \"\"\"\n    return sender.send_html_email(invited_user_email, subject, content_html, preview_text)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CloudM.email_services.send_waiting_list_confirmation_email","title":"<code>send_waiting_list_confirmation_email(app, user_email)</code>","text":"<p>Sends a confirmation email for joining the waiting list.</p> Source code in <code>toolboxv2/mods/CloudM/email_services.py</code> <pre><code>@s_export\ndef send_waiting_list_confirmation_email(app: App, user_email: str):\n    \"\"\"Sends a confirmation email for joining the waiting list.\"\"\"\n    sender = EmailSender(app)\n    subject = f\"You're on the Waiting List for {APP_NAME}!\"\n    preview_text = \"Thanks for your interest! We'll keep you updated.\"\n\n    content_html = f\"\"\"\n        &lt;h2&gt;You're In!&lt;/h2&gt;\n        &lt;p&gt;Thank you for joining the waiting list for {APP_NAME}. We're working hard to get things ready and appreciate your interest.&lt;/p&gt;\n        &lt;p&gt;We'll notify you as soon as we have updates or when access becomes available.&lt;/p&gt;\n        &lt;p&gt;In the meantime, you can follow our progress or learn more at &lt;a href=\"{APP_BASE_URL}\" class=\"link-in-text\"&gt;{APP_BASE_URL}&lt;/a&gt;.&lt;/p&gt;\n        &lt;p&gt;Stay tuned,&lt;br&gt;The {APP_NAME} Team&lt;/p&gt;\n    \"\"\"\n    return sender.send_html_email(user_email, subject, content_html, preview_text,\n                                  recipient_email_for_unsubscribe=user_email, show_unsubscribe_link=True)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CloudM.email_services.send_welcome_email","title":"<code>send_welcome_email(app, user_email, username, welcome_action_url=None)</code>","text":"<p>Sends a welcome email to a new user.</p> Source code in <code>toolboxv2/mods/CloudM/email_services.py</code> <pre><code>@s_export  # Changed to native, api=False as it's a backend function\ndef send_welcome_email(app: App, user_email: str, username: str, welcome_action_url: str = None):\n    \"\"\"Sends a welcome email to a new user.\"\"\"\n    sender = EmailSender(app)\n    subject = f\"Welcome to {APP_NAME}, {username}!\"\n    preview_text = f\"We're thrilled to have you, {username}!\"\n    action_url = welcome_action_url or f\"{APP_BASE_URL}/dashboard\"  # Default to dashboard\n\n    content_html = f\"\"\"\n        &lt;h2&gt;Welcome Aboard, {username}!&lt;/h2&gt;\n        &lt;p&gt;Thank you for signing up for {APP_NAME}. We're excited to have you join our community!&lt;/p&gt;\n        &lt;p&gt;Here are a few things you might want to do next:&lt;/p&gt;\n        &lt;ul&gt;\n            &lt;li&gt;Explore your new account features.&lt;/li&gt;\n            &lt;li&gt;Customize your profile.&lt;/li&gt;\n        &lt;/ul&gt;\n        &lt;p&gt;Click the button below to get started:&lt;/p&gt;\n        &lt;a href=\"{action_url}\" class=\"button\"&gt;Go to Your Dashboard&lt;/a&gt;\n        &lt;p&gt;If the button doesn't work, copy and paste this link into your browser:&lt;br&gt;&lt;span class=\"link-in-text\"&gt;{action_url}&lt;/span&gt;&lt;/p&gt;\n        &lt;p&gt;Best regards,&lt;br&gt;The {APP_NAME} Team&lt;/p&gt;\n    \"\"\"\n    return sender.send_html_email(user_email, subject, content_html, preview_text,\n                                  recipient_email_for_unsubscribe=user_email, show_unsubscribe_link=True)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CloudM.mini","title":"<code>mini</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.CloudM.mini.check_multiple_processes","title":"<code>check_multiple_processes(pids)</code>","text":"<p>Checks the status of multiple processes in a single system call. Returns a dictionary mapping PIDs to their status (GREEN_CIRCLE, RED_CIRCLE, or YELLOW_CIRCLE).</p> Source code in <code>toolboxv2/mods/CloudM/mini.py</code> <pre><code>def check_multiple_processes(pids: list[int]) -&gt; dict[int, str]:\n    \"\"\"\n    Checks the status of multiple processes in a single system call.\n    Returns a dictionary mapping PIDs to their status (GREEN_CIRCLE, RED_CIRCLE, or YELLOW_CIRCLE).\n    \"\"\"\n    if not pids:\n        return {}\n\n    pid_status = {}\n\n    if os.name == 'nt':  # Windows\n        try:\n            # Windows tasklist requires separate /FI for each filter\n            command = 'tasklist'\n\n            # Add encoding handling for Windows\n            result = subprocess.run(\n                command,\n                capture_output=True,\n                text=True,\n                shell=True,\n                encoding='cp850'  # Use cp850 for Windows console output\n            )\n            # Create a set of running PIDs from the output\n            running_pids = set()\n            for line in result.stdout.lower().split('\\n'):\n                for pid in pids:\n                    if str(pid) in line:\n                        running_pids.add(pid)\n            # Assign status based on whether PID was found in output\n            for pid in pids:\n                if pid in running_pids:\n                    pid_status[pid] = GREEN_CIRCLE\n                else:\n                    pid_status[pid] = RED_CIRCLE\n\n        except subprocess.SubprocessError as e:\n            print(f\"SubprocessError: {e}\")  # For debugging\n            # Mark all as YELLOW_CIRCLE if there's an error running the command\n            for pid in pids:\n                pid_status[pid] = YELLOW_CIRCLE\n        except UnicodeDecodeError as e:\n            print(f\"UnicodeDecodeError: {e}\")  # For debugging\n            # Try alternate encoding if cp850 fails\n            try:\n                result = subprocess.run(\n                    command,\n                    capture_output=True,\n                    text=True,\n                    shell=True,\n                    encoding='utf-8'\n                )\n                running_pids = set()\n                for line in result.stdout.lower().split('\\n'):\n                    for pid in pids:\n                        if str(pid) in line:\n                            running_pids.add(pid)\n\n                for pid in pids:\n                    pid_status[pid] = GREEN_CIRCLE if pid in running_pids else RED_CIRCLE\n            except Exception as e:\n                print(f\"Failed with alternate encoding: {e}\")  # For debugging\n                for pid in pids:\n                    pid_status[pid] = YELLOW_CIRCLE\n\n    else:  # Unix/Linux/Mac\n        try:\n            pids_str = ','.join(str(pid) for pid in pids)\n            command = f'ps -p {pids_str} -o pid='\n\n            result = subprocess.run(\n                command,\n                capture_output=True,\n                text=True,\n                shell=True,\n                encoding='utf-8'\n            )\n            running_pids = set(int(pid) for pid in result.stdout.strip().split())\n\n            for pid in pids:\n                pid_status[pid] = GREEN_CIRCLE if pid in running_pids else RED_CIRCLE\n\n        except subprocess.SubprocessError as e:\n            print(f\"SubprocessError: {e}\")  # For debugging\n            for pid in pids:\n                pid_status[pid] = YELLOW_CIRCLE\n\n    return pid_status\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CloudM.mini.get_service_pids","title":"<code>get_service_pids(info_dir)</code>","text":"<p>Extracts service names and PIDs from pid files.</p> Source code in <code>toolboxv2/mods/CloudM/mini.py</code> <pre><code>def get_service_pids(info_dir):\n    \"\"\"Extracts service names and PIDs from pid files.\"\"\"\n    services = {}\n    pid_files = [f for f in os.listdir(info_dir) if re.match(r'(.+)-(.+)\\.pid', f)]\n    for pid_file in pid_files:\n        match = re.match(r'(.+)-(.+)\\.pid', pid_file)\n        if match:\n            services_type, service_name = match.groups()\n            # Read the PID from the file\n            with open(os.path.join(info_dir, pid_file)) as file:\n                pid = file.read().strip()\n                # Store the PID using a formatted key\n                services[f\"{service_name} - {services_type}\"] = int(pid)\n    return services\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CloudM.mini.get_service_status","title":"<code>get_service_status(dir)</code>","text":"<p>Displays the status of all services.</p> Source code in <code>toolboxv2/mods/CloudM/mini.py</code> <pre><code>def get_service_status(dir: str) -&gt; str:\n    \"\"\"Displays the status of all services.\"\"\"\n    if time.time()-services_data_sto_last_update_time[0] &gt; 30:\n        services = get_service_pids(dir)\n        services_data_sto[0] = services\n        services_data_sto_last_update_time[0] = time.time()\n    else:\n        services = services_data_sto[0]\n    if not services:\n        return \"No services found\"\n\n    # Get status for all PIDs in a single call\n    pid_statuses = check_multiple_processes(list(services.values()))\n\n    # Build the status string\n    res_s = \"Service(s):\" + (\"\\n\" if len(services) &gt; 1 else ' ')\n    for service_name, pid in services.items():\n        status = pid_statuses.get(pid, YELLOW_CIRCLE)\n        res_s += f\"{status} {service_name} (PID: {pid})\\n\"\n    services_data_display[0] = res_s.strip()\n    return res_s.rstrip()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CloudM.module","title":"<code>module</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.CloudM.module.hash_password","title":"<code>hash_password(password)</code>","text":"<p>Hash a password for storing.</p> Source code in <code>toolboxv2/mods/CloudM/module.py</code> <pre><code>def hash_password(password):\n    \"\"\"Hash a password for storing.\"\"\"\n    salt = hashlib.sha256(os.urandom(60)).hexdigest().encode('ascii')\n    pwdhash = hashlib.pbkdf2_hmac('sha512', password.encode('utf-8'), salt,\n                                  100000)\n    pwdhash = binascii.hexlify(pwdhash)\n    return (salt + pwdhash).decode('ascii')\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CloudM.module.verify_password","title":"<code>verify_password(stored_password, provided_password)</code>","text":"<p>Verify a stored password against one provided by user</p> Source code in <code>toolboxv2/mods/CloudM/module.py</code> <pre><code>def verify_password(stored_password, provided_password):\n    \"\"\"Verify a stored password against one provided by user\"\"\"\n    salt = stored_password[:64]\n    stored_password = stored_password[64:]\n    pwdhash = hashlib.pbkdf2_hmac('sha512', provided_password.encode('utf-8'),\n                                  salt.encode('ascii'), 100000)\n    pwdhash = binascii.hexlify(pwdhash).decode('ascii')\n    return pwdhash == stored_password\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CodeVerification","title":"<code>CodeVerification</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.CodeVerification.VerificationSystem","title":"<code>VerificationSystem</code>","text":"Source code in <code>toolboxv2/mods/CodeVerification.py</code> <pre><code>class VerificationSystem:\n    def __init__(self, tools_db, scope=\"main\"):\n        \"\"\"\n        Initialize VerificationSystem with DB Tools integration\n\n        Args:\n            tools_db (Tools): Database tools from toolboxv2.mods.DB\n            scope (str, optional): Scope for templates and codes. Defaults to \"main\".\n        \"\"\"\n        self.tools_db = tools_db\n        self.scope = scope\n        self.tidmp = {}\n        self._ensure_scope_templates()\n\n    def get(self):\n        return self\n\n    def reset_scope_templates(self):\n        \"\"\"\n        Ensure a templates dictionary exists for the current scope in the database\n        \"\"\"\n        templates_key = f\"verification_templates_{self.scope}\"\n\n        self.tools_db.set(templates_key, json.dumps({}))\n\n    def _ensure_scope_templates(self):\n        \"\"\"\n        Ensure a templates dictionary exists for the current scope in the database\n        \"\"\"\n        templates_key = f\"verification_templates_{self.scope}\"\n\n        # Check if templates exist for this scope\n        templates_exist = self.tools_db.if_exist(templates_key)\n\n        if templates_exist.is_error() and not templates_exist.is_data():\n            # Initialize empty templates dictionary if not exists\n            self.tools_db.set(templates_key, json.dumps({}))\n        else:\n            allt = self.get_all_templates()\n\n            for k, v in allt.items():\n                if 'name' not in v:\n                    continue\n                self.tidmp[v['name']] = k\n\n    def add_config_template(self, template: ConfigTemplate) -&gt; str:\n        \"\"\"\n        Add a new configuration template to the database\n\n        Args:\n            template (ConfigTemplate): The configuration template\n\n        Returns:\n            str: Unique identifier of the template\n        \"\"\"\n        # Ensure template has the current scope\n        template.scope = self.scope\n\n        # Generate a unique template ID\n        template_id = secrets.token_urlsafe(8)\n\n        # Get existing templates for this scope\n        templates = self.get_all_templates()\n\n        # Add new template\n        self.tidmp[template.name] = template_id\n        templates[template_id] = asdict(template)\n\n        # Save updated templates back to database\n        templates_key = f\"verification_templates_{self.scope}\"\n        save_result = self.tools_db.set(templates_key, json.dumps(templates))\n\n        if save_result.is_error():\n            raise ValueError(\"Could not save template\")\n\n        return template_id\n\n    def get_all_templates(self):\n        templates_key = f\"verification_templates_{self.scope}\"\n        templates_result = self.tools_db.get(templates_key)\n\n        if not templates_result.is_error() and templates_result.is_data():\n            try:\n                templates_result.result.data = json.loads(templates_result.get())\n            except Exception as e:\n                templates_result.print()\n                print(f\"Errro loding template data curupted : {str(e)}\")\n                templates_result.result.data = {}\n        else:\n            templates_result.result.data = {}\n        if not isinstance(templates_result, dict):\n            templates_result = templates_result.result.data\n        return templates_result\n\n    def generate_code(self, template_id: str) -&gt; str:\n        \"\"\"\n        Generate a code based on the configuration template\n\n        Args:\n            template_id (str): ID of the configuration template\n\n        Returns:\n            str: Generated verification code\n        \"\"\"\n        # Get templates for this scope\n        templates = self.get_all_templates()\n        print(templates, self.tidmp, template_id)\n        if template_id not in templates:\n            template_id = self.tidmp.get(template_id, template_id)\n        if template_id not in templates:\n            raise ValueError(\"Invalid configuration template\")\n\n        template_dict = templates[template_id]\n        ConfigTemplate(**template_dict)\n\n        # Generate a random code with max 16 characters\n        code = secrets.token_urlsafe(10)[:16]\n\n        # Prepare code information\n        code_info = {\n            'template_id': template_id,\n            'created_at': time.time(),\n            'uses_count': 0,\n            'scope': self.scope\n        }\n\n        # Store code information in database\n        codes_key = f\"verification_codes_{self.scope}\"\n        existing_codes_result = self.tools_db.get(codes_key)\n\n        existing_codes = {}\n        if not existing_codes_result.is_error() and existing_codes_result.is_data():\n            d = existing_codes_result.get()\n            if isinstance(d, list):\n                d = d[0]\n            existing_codes = json.loads(d)\n\n        existing_codes[code] = code_info\n\n        save_result = self.tools_db.set(codes_key, json.dumps(existing_codes))\n\n        if save_result.is_error():\n            raise ValueError(\"Could not save generated code\")\n\n        return code\n\n    def validate_code(self, code: str) -&gt; dict[str, Any] | None:\n        \"\"\"\n        Validate a code and return template information\n\n        Args:\n            code (str): Code to validate\n\n        Returns:\n            Optional[Dict[str, Any]]: Template information for valid code, else None\n        \"\"\"\n        # Get codes for this scope\n        codes_key = f\"verification_codes_{self.scope}\"\n        codes_result = self.tools_db.get(codes_key)\n\n        if codes_result.is_error() or not codes_result.is_data():\n            return None\n\n        d = codes_result.get()\n        if isinstance(d, list):\n            d = d[0]\n        existing_codes = json.loads(d)\n\n        if code not in existing_codes:\n            return None\n\n        code_info = existing_codes[code]\n\n        # Check if code is from the same scope\n        if code_info.get('scope') != self.scope:\n            return None\n\n        # Get templates for this scope\n        templates = self.get_all_templates()\n        template_id = code_info['template_id']\n\n        if template_id not in templates:\n            return templates\n\n        template_dict = templates[template_id]\n        template = ConfigTemplate(**template_dict)\n\n        # Check usage count\n        if code_info['uses_count'] &gt;= template.max_uses:\n            del existing_codes[code]\n            self.tools_db.set(codes_key, json.dumps(existing_codes))\n            return None\n\n        # Check time validity for timed codes\n        if template.usage_type == 'timed':\n            current_time = time.time()\n            if template.valid_duration and (current_time - code_info['created_at']) &gt; template.valid_duration:\n                del existing_codes[code]\n                self.tools_db.set(codes_key, json.dumps(existing_codes))\n                return None\n\n        # Update uses count\n        existing_codes[code]['uses_count'] += 1\n        uses_count = existing_codes[code].get('uses_count', 1)\n        # Remove code if it's a one-time use\n        if template.usage_type == 'one_time':\n            del existing_codes[code]\n\n        # Save updated codes\n        self.tools_db.set(codes_key, json.dumps(existing_codes))\n\n        return {\n            'template_name': template.name,\n            'usage_type': template.usage_type,\n            'uses_count': uses_count\n        }\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CodeVerification.VerificationSystem.__init__","title":"<code>__init__(tools_db, scope='main')</code>","text":"<p>Initialize VerificationSystem with DB Tools integration</p> <p>Parameters:</p> Name Type Description Default <code>tools_db</code> <code>Tools</code> <p>Database tools from toolboxv2.mods.DB</p> required <code>scope</code> <code>str</code> <p>Scope for templates and codes. Defaults to \"main\".</p> <code>'main'</code> Source code in <code>toolboxv2/mods/CodeVerification.py</code> <pre><code>def __init__(self, tools_db, scope=\"main\"):\n    \"\"\"\n    Initialize VerificationSystem with DB Tools integration\n\n    Args:\n        tools_db (Tools): Database tools from toolboxv2.mods.DB\n        scope (str, optional): Scope for templates and codes. Defaults to \"main\".\n    \"\"\"\n    self.tools_db = tools_db\n    self.scope = scope\n    self.tidmp = {}\n    self._ensure_scope_templates()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CodeVerification.VerificationSystem.add_config_template","title":"<code>add_config_template(template)</code>","text":"<p>Add a new configuration template to the database</p> <p>Parameters:</p> Name Type Description Default <code>template</code> <code>ConfigTemplate</code> <p>The configuration template</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Unique identifier of the template</p> Source code in <code>toolboxv2/mods/CodeVerification.py</code> <pre><code>def add_config_template(self, template: ConfigTemplate) -&gt; str:\n    \"\"\"\n    Add a new configuration template to the database\n\n    Args:\n        template (ConfigTemplate): The configuration template\n\n    Returns:\n        str: Unique identifier of the template\n    \"\"\"\n    # Ensure template has the current scope\n    template.scope = self.scope\n\n    # Generate a unique template ID\n    template_id = secrets.token_urlsafe(8)\n\n    # Get existing templates for this scope\n    templates = self.get_all_templates()\n\n    # Add new template\n    self.tidmp[template.name] = template_id\n    templates[template_id] = asdict(template)\n\n    # Save updated templates back to database\n    templates_key = f\"verification_templates_{self.scope}\"\n    save_result = self.tools_db.set(templates_key, json.dumps(templates))\n\n    if save_result.is_error():\n        raise ValueError(\"Could not save template\")\n\n    return template_id\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CodeVerification.VerificationSystem.generate_code","title":"<code>generate_code(template_id)</code>","text":"<p>Generate a code based on the configuration template</p> <p>Parameters:</p> Name Type Description Default <code>template_id</code> <code>str</code> <p>ID of the configuration template</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Generated verification code</p> Source code in <code>toolboxv2/mods/CodeVerification.py</code> <pre><code>def generate_code(self, template_id: str) -&gt; str:\n    \"\"\"\n    Generate a code based on the configuration template\n\n    Args:\n        template_id (str): ID of the configuration template\n\n    Returns:\n        str: Generated verification code\n    \"\"\"\n    # Get templates for this scope\n    templates = self.get_all_templates()\n    print(templates, self.tidmp, template_id)\n    if template_id not in templates:\n        template_id = self.tidmp.get(template_id, template_id)\n    if template_id not in templates:\n        raise ValueError(\"Invalid configuration template\")\n\n    template_dict = templates[template_id]\n    ConfigTemplate(**template_dict)\n\n    # Generate a random code with max 16 characters\n    code = secrets.token_urlsafe(10)[:16]\n\n    # Prepare code information\n    code_info = {\n        'template_id': template_id,\n        'created_at': time.time(),\n        'uses_count': 0,\n        'scope': self.scope\n    }\n\n    # Store code information in database\n    codes_key = f\"verification_codes_{self.scope}\"\n    existing_codes_result = self.tools_db.get(codes_key)\n\n    existing_codes = {}\n    if not existing_codes_result.is_error() and existing_codes_result.is_data():\n        d = existing_codes_result.get()\n        if isinstance(d, list):\n            d = d[0]\n        existing_codes = json.loads(d)\n\n    existing_codes[code] = code_info\n\n    save_result = self.tools_db.set(codes_key, json.dumps(existing_codes))\n\n    if save_result.is_error():\n        raise ValueError(\"Could not save generated code\")\n\n    return code\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CodeVerification.VerificationSystem.reset_scope_templates","title":"<code>reset_scope_templates()</code>","text":"<p>Ensure a templates dictionary exists for the current scope in the database</p> Source code in <code>toolboxv2/mods/CodeVerification.py</code> <pre><code>def reset_scope_templates(self):\n    \"\"\"\n    Ensure a templates dictionary exists for the current scope in the database\n    \"\"\"\n    templates_key = f\"verification_templates_{self.scope}\"\n\n    self.tools_db.set(templates_key, json.dumps({}))\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.CodeVerification.VerificationSystem.validate_code","title":"<code>validate_code(code)</code>","text":"<p>Validate a code and return template information</p> <p>Parameters:</p> Name Type Description Default <code>code</code> <code>str</code> <p>Code to validate</p> required <p>Returns:</p> Type Description <code>dict[str, Any] | None</code> <p>Optional[Dict[str, Any]]: Template information for valid code, else None</p> Source code in <code>toolboxv2/mods/CodeVerification.py</code> <pre><code>def validate_code(self, code: str) -&gt; dict[str, Any] | None:\n    \"\"\"\n    Validate a code and return template information\n\n    Args:\n        code (str): Code to validate\n\n    Returns:\n        Optional[Dict[str, Any]]: Template information for valid code, else None\n    \"\"\"\n    # Get codes for this scope\n    codes_key = f\"verification_codes_{self.scope}\"\n    codes_result = self.tools_db.get(codes_key)\n\n    if codes_result.is_error() or not codes_result.is_data():\n        return None\n\n    d = codes_result.get()\n    if isinstance(d, list):\n        d = d[0]\n    existing_codes = json.loads(d)\n\n    if code not in existing_codes:\n        return None\n\n    code_info = existing_codes[code]\n\n    # Check if code is from the same scope\n    if code_info.get('scope') != self.scope:\n        return None\n\n    # Get templates for this scope\n    templates = self.get_all_templates()\n    template_id = code_info['template_id']\n\n    if template_id not in templates:\n        return templates\n\n    template_dict = templates[template_id]\n    template = ConfigTemplate(**template_dict)\n\n    # Check usage count\n    if code_info['uses_count'] &gt;= template.max_uses:\n        del existing_codes[code]\n        self.tools_db.set(codes_key, json.dumps(existing_codes))\n        return None\n\n    # Check time validity for timed codes\n    if template.usage_type == 'timed':\n        current_time = time.time()\n        if template.valid_duration and (current_time - code_info['created_at']) &gt; template.valid_duration:\n            del existing_codes[code]\n            self.tools_db.set(codes_key, json.dumps(existing_codes))\n            return None\n\n    # Update uses count\n    existing_codes[code]['uses_count'] += 1\n    uses_count = existing_codes[code].get('uses_count', 1)\n    # Remove code if it's a one-time use\n    if template.usage_type == 'one_time':\n        del existing_codes[code]\n\n    # Save updated codes\n    self.tools_db.set(codes_key, json.dumps(existing_codes))\n\n    return {\n        'template_name': template.name,\n        'usage_type': template.usage_type,\n        'uses_count': uses_count\n    }\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.DB","title":"<code>DB</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.DB.blob_instance","title":"<code>blob_instance</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.DB.blob_instance.BlobDB","title":"<code>BlobDB</code>","text":"<p>A persistent, encrypted dictionary-like database that uses the BlobStorage system as its backend, making it networked and fault-tolerant.</p> Source code in <code>toolboxv2/mods/DB/blob_instance.py</code> <pre><code>class BlobDB:\n    \"\"\"\n    A persistent, encrypted dictionary-like database that uses the BlobStorage\n    system as its backend, making it networked and fault-tolerant.\n    \"\"\"\n    auth_type = AuthenticationTypes.location\n\n    def __init__(self):\n        self.data: dict = {}\n        self.key: str | None = None\n        self.db_path: str | None = None\n        self.storage_client: BlobStorage | None = None\n\n\n    def initialize(self, db_path: str, key: str, storage_client: BlobStorage) -&gt; Result:\n        \"\"\"\n        Initializes the database from a location within the blob storage.\n\n        Args:\n            db_path (str): The virtual path within the blob storage,\n                           e.g., \"my_database_blob/database.json\".\n            key (str): The encryption key for the database content.\n            storage_client (BlobStorage): An initialized BlobStorage client instance.\n\n        Returns:\n            Result: An OK result if successful.\n        \"\"\"\n        self.db_path = db_path\n        self.key = key\n        self.storage_client = storage_client\n\n        print(f\"Initializing BlobDB from blob path: '{self.db_path}'...\")\n\n        try:\n            # Use BlobFile for reading. It handles caching, networking, and decryption.\n            db_file = BlobFile(self.db_path, mode='r', storage=self.storage_client, key=self.key)\n            if not db_file.exists():\n                print(f\"Database file not found at '{self.db_path}'. Starting with an empty database.\")\n                db_file.create()\n                self.data = {}\n            else:\n                with db_file as f:\n                    # read_json safely loads the content.\n                    self.data = f.read_json()\n                    if not self.data:  # Handle case where file exists but is empty\n                        self.data = {}\n                print(\"Successfully initialized database.\")\n\n        except Exception as e:\n            print(f\"Warning: Could not initialize BlobDB from '{self.db_path}'. Error: {e}. Starting fresh.\")\n            self.data = {}\n\n        return Result.ok().set_origin(\"Blob Dict DB\")\n\n    def exit(self) -&gt; Result:\n        \"\"\"\n        Saves the current state of the database back to the blob storage.\n        \"\"\"\n        print(\"BLOB DB on exit \", not all([self.key, self.db_path, self.storage_client]))\n        if not all([self.key, self.db_path, self.storage_client]):\n            return Result.default_internal_error(\n                info=\"Database not initialized. Cannot exit.\"\n            ).set_origin(\"Blob Dict DB\")\n\n        print(f\"Saving database to blob path: '{self.db_path}'...\")\n        try:\n            # Use BlobFile for writing. It handles encryption, networking, and updates.\n            with BlobFile(self.db_path, mode='w', storage=self.storage_client, key=self.key) as f:\n                f.write_json(self.data)\n\n            print(\"Success: Database saved to blob storage.\")\n            return Result.ok().set_origin(\"Blob Dict DB\")\n\n        except Exception as e:\n            return Result.custom_error(\n                data=e,\n                info=f\"Error saving database to blob storage: {e}\"\n            ).set_origin(\"Blob Dict DB\")\n\n    # --- Data Manipulation Methods (Unchanged Logic) ---\n    # These methods operate on the in-memory `self.data` dictionary and do not\n    # need to be changed, as the loading/saving is handled by initialize/exit.\n\n    def get(self, key: str) -&gt; Result:\n        if not self.data:\n            return Result.default_internal_error(info=f\"No data found for key '{key}' (database is empty).\").set_origin(\n                \"Blob Dict DB\")\n\n        data = []\n        if key == 'all':\n            data_info = \"Returning all data available\"\n            data = list(self.data.items())\n        elif key == \"all-k\":\n            data_info = \"Returning all keys\"\n            data = list(self.data.keys())\n        else:\n            data_info = f\"Returning values for keys starting with '{key.replace('*', '')}'\"\n            data = [self.data[k] for k in self.scan_iter(key)]\n\n        if not data:\n            return Result.default_internal_error(info=f\"No data found for key '{key}'\").set_origin(\"Blob Dict DB\")\n\n        return Result.ok(data=data, data_info=data_info).set_origin(\"Blob Dict DB\")\n\n    def set(self, key: str, value) -&gt; Result:\n        if not isinstance(key, str) or not key:\n            return Result.default_user_error(info=\"Key must be a non-empty string.\").set_origin(\"Blob Dict DB\")\n\n        self.data[key] = value\n        return Result.ok().set_origin(\"Blob Dict DB\")\n\n    def scan_iter(self, search: str = ''):\n        if not self.data:\n            return []\n        prefix = search.replace('*', '')\n        return [key for key in self.data if key.startswith(prefix)]\n\n    def append_on_set(self, key: str, value: list) -&gt; Result:\n        if key not in self.data:\n            self.data[key] = []\n\n        if not isinstance(self.data[key], list):\n            return Result.default_user_error(info=f\"Existing value for key '{key}' is not a list.\").set_origin(\n                \"Blob Dict DB\")\n\n        # Use a set for efficient checking to avoid duplicates\n        existing_set = set(self.data[key])\n        new_items = [item for item in value if item not in existing_set]\n        self.data[key].extend(new_items)\n        return Result.ok().set_origin(\"Blob Dict DB\")\n\n    def if_exist(self, key: str) -&gt; int:\n        if key.endswith('*'):\n            return len(self.scan_iter(key))\n        return 1 if key in self.data else 0\n\n    def delete(self, key: str, matching: bool = False) -&gt; Result:\n        keys_to_delete = []\n        if matching:\n            keys_to_delete = self.scan_iter(key)\n        elif key in self.data:\n            keys_to_delete.append(key)\n\n        if not keys_to_delete:\n            return Result.default_internal_error(info=f\"No keys found to delete for pattern '{key}'\").set_origin(\n                \"Blob Dict DB\")\n\n        deleted_items = {k: self.data.pop(k) for k in keys_to_delete}\n        return Result.ok(\n            data=list(deleted_items.items()),\n            data_info=f\"Successfully removed {len(deleted_items)} item(s).\"\n        ).set_origin(\"Blob Dict DB\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.DB.blob_instance.BlobDB.exit","title":"<code>exit()</code>","text":"<p>Saves the current state of the database back to the blob storage.</p> Source code in <code>toolboxv2/mods/DB/blob_instance.py</code> <pre><code>def exit(self) -&gt; Result:\n    \"\"\"\n    Saves the current state of the database back to the blob storage.\n    \"\"\"\n    print(\"BLOB DB on exit \", not all([self.key, self.db_path, self.storage_client]))\n    if not all([self.key, self.db_path, self.storage_client]):\n        return Result.default_internal_error(\n            info=\"Database not initialized. Cannot exit.\"\n        ).set_origin(\"Blob Dict DB\")\n\n    print(f\"Saving database to blob path: '{self.db_path}'...\")\n    try:\n        # Use BlobFile for writing. It handles encryption, networking, and updates.\n        with BlobFile(self.db_path, mode='w', storage=self.storage_client, key=self.key) as f:\n            f.write_json(self.data)\n\n        print(\"Success: Database saved to blob storage.\")\n        return Result.ok().set_origin(\"Blob Dict DB\")\n\n    except Exception as e:\n        return Result.custom_error(\n            data=e,\n            info=f\"Error saving database to blob storage: {e}\"\n        ).set_origin(\"Blob Dict DB\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.DB.blob_instance.BlobDB.initialize","title":"<code>initialize(db_path, key, storage_client)</code>","text":"<p>Initializes the database from a location within the blob storage.</p> <p>Parameters:</p> Name Type Description Default <code>db_path</code> <code>str</code> <p>The virtual path within the blob storage,            e.g., \"my_database_blob/database.json\".</p> required <code>key</code> <code>str</code> <p>The encryption key for the database content.</p> required <code>storage_client</code> <code>BlobStorage</code> <p>An initialized BlobStorage client instance.</p> required <p>Returns:</p> Name Type Description <code>Result</code> <code>Result</code> <p>An OK result if successful.</p> Source code in <code>toolboxv2/mods/DB/blob_instance.py</code> <pre><code>def initialize(self, db_path: str, key: str, storage_client: BlobStorage) -&gt; Result:\n    \"\"\"\n    Initializes the database from a location within the blob storage.\n\n    Args:\n        db_path (str): The virtual path within the blob storage,\n                       e.g., \"my_database_blob/database.json\".\n        key (str): The encryption key for the database content.\n        storage_client (BlobStorage): An initialized BlobStorage client instance.\n\n    Returns:\n        Result: An OK result if successful.\n    \"\"\"\n    self.db_path = db_path\n    self.key = key\n    self.storage_client = storage_client\n\n    print(f\"Initializing BlobDB from blob path: '{self.db_path}'...\")\n\n    try:\n        # Use BlobFile for reading. It handles caching, networking, and decryption.\n        db_file = BlobFile(self.db_path, mode='r', storage=self.storage_client, key=self.key)\n        if not db_file.exists():\n            print(f\"Database file not found at '{self.db_path}'. Starting with an empty database.\")\n            db_file.create()\n            self.data = {}\n        else:\n            with db_file as f:\n                # read_json safely loads the content.\n                self.data = f.read_json()\n                if not self.data:  # Handle case where file exists but is empty\n                    self.data = {}\n            print(\"Successfully initialized database.\")\n\n    except Exception as e:\n        print(f\"Warning: Could not initialize BlobDB from '{self.db_path}'. Error: {e}. Starting fresh.\")\n        self.data = {}\n\n    return Result.ok().set_origin(\"Blob Dict DB\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.DB.local_instance","title":"<code>local_instance</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.DB.local_instance.load_from_json","title":"<code>load_from_json(filename)</code>","text":"<p>L\u00e4dt Daten aus einer JSON-Datei.</p> <p>:param filename: Der Dateiname oder Pfad der zu ladenden Datei. :return: Die geladenen Daten.</p> Source code in <code>toolboxv2/mods/DB/local_instance.py</code> <pre><code>def load_from_json(filename):\n    \"\"\"\n    L\u00e4dt Daten aus einer JSON-Datei.\n\n    :param filename: Der Dateiname oder Pfad der zu ladenden Datei.\n    :return: Die geladenen Daten.\n    \"\"\"\n    if not os.path.exists(filename):\n        return {'data': ''}\n\n    with open(filename) as file:\n        return json.load(file)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.DB.local_instance.save_to_json","title":"<code>save_to_json(data, filename)</code>","text":"<p>Speichert die \u00fcbergebenen Daten in einer JSON-Datei.</p> <p>:param data: Die zu speichernden Daten. :param filename: Der Dateiname oder Pfad, in dem die Daten gespeichert werden sollen.</p> Source code in <code>toolboxv2/mods/DB/local_instance.py</code> <pre><code>def save_to_json(data, filename):\n    \"\"\"\n    Speichert die \u00fcbergebenen Daten in einer JSON-Datei.\n\n    :param data: Die zu speichernden Daten.\n    :param filename: Der Dateiname oder Pfad, in dem die Daten gespeichert werden sollen.\n    \"\"\"\n    if not os.path.exists(filename):\n        open(filename, 'a').close()\n\n    with open(filename, 'w+') as file:\n        json.dump(data, file, indent=4)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.DB.reddis_instance","title":"<code>reddis_instance</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.DB.reddis_instance.sync_redis_databases","title":"<code>sync_redis_databases(source_url, target_url)</code>","text":"<p>Synchronize keys from the source Redis database to the target Redis database. This function scans all keys in the source DB and uses DUMP/RESTORE to replicate data to the target.</p> <p>Parameters:</p> Name Type Description Default <code>source_url</code> <code>str</code> <p>The Redis URL of the source database.</p> required <code>target_url</code> <code>str</code> <p>The Redis URL of the target database.</p> required <p>Returns:</p> Name Type Description <code>int</code> <p>The number of keys successfully synchronized.</p> Source code in <code>toolboxv2/mods/DB/reddis_instance.py</code> <pre><code>def sync_redis_databases(source_url, target_url):\n    \"\"\"Synchronize keys from the source Redis database to the target Redis database.\n    This function scans all keys in the source DB and uses DUMP/RESTORE to replicate data to the target.\n\n    Args:\n        source_url (str): The Redis URL of the source database.\n        target_url (str): The Redis URL of the target database.\n\n    Returns:\n        int: The number of keys successfully synchronized.\n    \"\"\"\n    try:\n        src_client = redis.from_url(source_url)\n        tgt_client = redis.from_url(target_url)\n    except Exception as e:\n        print(f\"Error connecting to one of the Redis instances: {e}\")\n        return 0\n\n    total_synced = 0\n    cursor = 0\n    try:\n        while True:\n            cursor, keys = src_client.scan(cursor=cursor, count=100)\n            for key in keys:\n                try:\n                    serialized_value = src_client.dump(key)\n                    if serialized_value is None:\n                        continue\n                    # Restore key with TTL=0 and replace existing key\n                    tgt_client.restore(key, 0, serialized_value, replace=True)\n                    total_synced += 1\n                except Exception as e:\n                    print(f\"Error syncing key {key}: {e}\")\n            if cursor == 0:\n                break\n    except Exception as scan_error:\n        print(f\"Error during scanning keys: {scan_error}\")\n\n    print(f\"Synced {total_synced} keys from {source_url} to {target_url}\")\n    return total_synced\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.DB.tb_adapter","title":"<code>tb_adapter</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.DB.tb_adapter.DB","title":"<code>DB</code>","text":"<p>               Bases: <code>ABC</code></p> Source code in <code>toolboxv2/mods/DB/tb_adapter.py</code> <pre><code>class DB(ABC):\n    @abc.abstractmethod\n    def get(self, query: str) -&gt; Result:\n        \"\"\"get data\"\"\"\n\n    @abc.abstractmethod\n    def set(self, query: str, value) -&gt; Result:\n        \"\"\"set data\"\"\"\n\n    @abc.abstractmethod\n    def append_on_set(self, query: str, value) -&gt; Result:\n        \"\"\"append set data\"\"\"\n\n    @abc.abstractmethod\n    def delete(self, query: str, matching=False) -&gt; Result:\n        \"\"\"delete data\"\"\"\n\n    @abc.abstractmethod\n    def if_exist(self, query: str) -&gt; bool:\n        \"\"\"return True if query exists\"\"\"\n\n    @abc.abstractmethod\n    def exit(self) -&gt; Result:\n        \"\"\"Close DB connection and optional save data\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.DB.tb_adapter.DB.append_on_set","title":"<code>append_on_set(query, value)</code>  <code>abstractmethod</code>","text":"<p>append set data</p> Source code in <code>toolboxv2/mods/DB/tb_adapter.py</code> <pre><code>@abc.abstractmethod\ndef append_on_set(self, query: str, value) -&gt; Result:\n    \"\"\"append set data\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.DB.tb_adapter.DB.delete","title":"<code>delete(query, matching=False)</code>  <code>abstractmethod</code>","text":"<p>delete data</p> Source code in <code>toolboxv2/mods/DB/tb_adapter.py</code> <pre><code>@abc.abstractmethod\ndef delete(self, query: str, matching=False) -&gt; Result:\n    \"\"\"delete data\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.DB.tb_adapter.DB.exit","title":"<code>exit()</code>  <code>abstractmethod</code>","text":"<p>Close DB connection and optional save data</p> Source code in <code>toolboxv2/mods/DB/tb_adapter.py</code> <pre><code>@abc.abstractmethod\ndef exit(self) -&gt; Result:\n    \"\"\"Close DB connection and optional save data\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.DB.tb_adapter.DB.get","title":"<code>get(query)</code>  <code>abstractmethod</code>","text":"<p>get data</p> Source code in <code>toolboxv2/mods/DB/tb_adapter.py</code> <pre><code>@abc.abstractmethod\ndef get(self, query: str) -&gt; Result:\n    \"\"\"get data\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.DB.tb_adapter.DB.if_exist","title":"<code>if_exist(query)</code>  <code>abstractmethod</code>","text":"<p>return True if query exists</p> Source code in <code>toolboxv2/mods/DB/tb_adapter.py</code> <pre><code>@abc.abstractmethod\ndef if_exist(self, query: str) -&gt; bool:\n    \"\"\"return True if query exists\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.DB.tb_adapter.DB.set","title":"<code>set(query, value)</code>  <code>abstractmethod</code>","text":"<p>set data</p> Source code in <code>toolboxv2/mods/DB/tb_adapter.py</code> <pre><code>@abc.abstractmethod\ndef set(self, query: str, value) -&gt; Result:\n    \"\"\"set data\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.DB.ui","title":"<code>ui</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.DB.ui.api_change_mode","title":"<code>api_change_mode(self, request)</code>  <code>async</code>","text":"<p>Changes the database mode from a JSON POST body.</p> Source code in <code>toolboxv2/mods/DB/ui.py</code> <pre><code>@export(mod_name=Name, name=\"api_change_mode\", api=True, api_methods=['POST'], request_as_kwarg=True)\nasync def api_change_mode(self, request: RequestData):\n    \"\"\"Changes the database mode from a JSON POST body.\"\"\"\n    data = request.body\n    if not data or \"mode\" not in data:\n        return Result.default_user_error(\"Request body must contain 'mode'.\")\n    new_mode = data.get(\"mode\", \"LC\")\n    return self.edit_programmable(DatabaseModes.crate(new_mode))\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.DB.ui.api_delete_key","title":"<code>api_delete_key(self, request)</code>  <code>async</code>","text":"<p>Deletes a key from a JSON POST body.</p> Source code in <code>toolboxv2/mods/DB/ui.py</code> <pre><code>@export(mod_name=Name, name=\"api_delete_key\", api=True, api_methods=['POST'], request_as_kwarg=True)\nasync def api_delete_key(self, request: RequestData):\n    \"\"\"Deletes a key from a JSON POST body.\"\"\"\n    data = request.body\n    if not data or 'key' not in data:\n        return Result.default_user_error(\"Request body must contain 'key'.\")\n    key = data['key']\n    if not key:\n        return Result.default_user_error(\"Key parameter is required.\")\n    return self.delete(key)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.DB.ui.api_get_all_keys","title":"<code>api_get_all_keys(self, request)</code>  <code>async</code>","text":"<p>Returns a list of all keys in the database.</p> Source code in <code>toolboxv2/mods/DB/ui.py</code> <pre><code>@export(mod_name=Name, name=\"api_get_all_keys\", api=True, request_as_kwarg=True)\nasync def api_get_all_keys(self, request: RequestData):\n    \"\"\"Returns a list of all keys in the database.\"\"\"\n    if self.data_base:\n        keys_result = self.data_base.get('all-k')\n        if keys_result.is_error():\n            return keys_result\n\n        unwrapped_keys = _unwrap_data(keys_result.get())\n        if not isinstance(unwrapped_keys, list):\n            self.app.logger.warning(f\"get_all_keys did not return a list. Got: {type(unwrapped_keys)}\")\n            return Result.json(data=[])\n\n        return Result.json(data=sorted(unwrapped_keys))\n    return Result.default_internal_error(\"DB not initialized\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.DB.ui.api_get_status","title":"<code>api_get_status(self, request)</code>  <code>async</code>","text":"<p>Returns the current status of the DB manager.</p> Source code in <code>toolboxv2/mods/DB/ui.py</code> <pre><code>@export(mod_name=Name, name=\"api_get_status\", api=True, request_as_kwarg=True)\nasync def api_get_status(self, request: RequestData):\n    \"\"\"Returns the current status of the DB manager.\"\"\"\n    return Result.json(data={\"mode\": self.mode})\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.DB.ui.api_get_value","title":"<code>api_get_value(self, request, key)</code>  <code>async</code>","text":"<p>Gets a value for a key and returns it as JSON-friendly text.</p> Source code in <code>toolboxv2/mods/DB/ui.py</code> <pre><code>@export(mod_name=Name, name=\"api_get_value\", api=True, request_as_kwarg=True)\nasync def api_get_value(self, request: RequestData, key: str):\n    \"\"\"Gets a value for a key and returns it as JSON-friendly text.\"\"\"\n    if not key:\n        return Result.default_user_error(\"Key parameter is required.\")\n    value_res = self.get(key)\n    if value_res.is_error():\n        return value_res\n\n    value_unwrapped = _unwrap_data(value_res.get())\n\n    if isinstance(value_unwrapped, bytes):\n        try:\n            value_str = value_unwrapped.decode('utf-8')\n        except UnicodeDecodeError:\n            value_str = str(value_unwrapped)\n    else:\n        value_str = str(value_unwrapped)\n\n    # Simplified for a JSON-focused UI. The client will handle formatting.\n    return Result.json(data={\"key\": key, \"value\": value_str})\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.DB.ui.api_set_value","title":"<code>api_set_value(self, request)</code>  <code>async</code>","text":"<p>Sets a key-value pair from a JSON POST body.</p> Source code in <code>toolboxv2/mods/DB/ui.py</code> <pre><code>@export(mod_name=Name, name=\"api_set_value\", api=True, api_methods=['POST'], request_as_kwarg=True)\nasync def api_set_value(self, request: RequestData):\n    \"\"\"Sets a key-value pair from a JSON POST body.\"\"\"\n    data = request.body\n    if not data or 'key' not in data or 'value' not in data:\n        return Result.default_user_error(\"Request body must contain 'key' and 'value'.\")\n    key = data['key']\n    value = data['value']\n    if not key:\n        return Result.default_user_error(\"Key cannot be empty.\")\n    return self.set(key, value)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.DB.ui.db_manager_ui","title":"<code>db_manager_ui(**kwargs)</code>","text":"<p>Serves the refactored, JSON-focused UI for the DB Manager.</p> Source code in <code>toolboxv2/mods/DB/ui.py</code> <pre><code>@export(mod_name=Name, name=\"ui\", api=True, state=False)\ndef db_manager_ui(**kwargs):\n    \"\"\"Serves the refactored, JSON-focused UI for the DB Manager.\"\"\"\n    html_content = \"\"\"\n    &lt;!DOCTYPE html&gt;\n    &lt;html lang=\"en\"&gt;\n    &lt;head&gt;\n        &lt;meta charset=\"UTF-8\"&gt;\n        &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;\n        &lt;title&gt;DB Manager&lt;/title&gt;\n        &lt;style&gt;\n            :root {\n                --font-family-sans: -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial, sans-serif;\n                --font-family-mono: \"SF Mono\", \"Menlo\", \"Monaco\", \"Courier New\", Courier, monospace;\n                --color-bg: #f8f9fa;\n                --color-panel-bg: #ffffff;\n                --color-border: #dee2e6;\n                --color-text: #212529;\n                --color-text-muted: #6c757d;\n                --color-primary: #0d6efd;\n                --color-primary-hover: #0b5ed7;\n                --color-danger: #dc3545;\n                --color-danger-hover: #bb2d3b;\n                --color-key-folder-icon: #f7b731;\n                --color-key-file-icon: #adb5bd;\n                --color-key-hover-bg: #e9ecef;\n                --color-key-selected-bg: #0d6efd;\n                --color-key-selected-text: #ffffff;\n                --shadow-sm: 0 1px 2px 0 rgba(0, 0, 0, 0.05);\n                --radius: 0.375rem;\n            }\n\n            /* Basic styles */\n            * { box-sizing: border-box; }\n            html { font-size: 16px; }\n\n            body {\n                font-family: var(--font-family-sans);\n                background-color: var(--color-bg);\n                color: var(--color-text);\n                margin: 0;\n                padding: 1rem;\n                display: flex;\n                flex-direction: column;\n                height: 100vh;\n            }\n\n            /* Main layout */\n            .db-manager-container { display: flex; flex-direction: column; height: 100%; gap: 1rem; }\n            .db-header { display: flex; justify-content: space-between; align-items: center; padding-bottom: 1rem; border-bottom: 1px solid var(--color-border); flex-shrink: 0; }\n            .db-main-content { display: flex; gap: 1rem; flex: 1; min-height: 0; }\n\n            /* Panels */\n            .db-panel { background-color: var(--color-panel-bg); border: 1px solid var(--color-border); border-radius: var(--radius); box-shadow: var(--shadow-sm); display: flex; flex-direction: column; min-height: 0; }\n            .key-panel { width: 350px; min-width: 250px; max-width: 450px; }\n            .editor-panel, .placeholder-panel { flex-grow: 1; }\n            .panel-header { display: flex; justify-content: space-between; align-items: center; padding: 0.75rem 1rem; border-bottom: 1px solid var(--color-border); flex-shrink: 0; }\n            .panel-header h2 { font-size: 1.1rem; margin: 0; white-space: nowrap; overflow: hidden; text-overflow: ellipsis; }\n\n            /* Controls */\n            select, input[type=\"text\"], textarea, button { font-size: 1rem; }\n            select, input[type=\"text\"] { background-color: var(--color-bg); color: var(--color-text); border: 1px solid var(--color-border); border-radius: var(--radius); padding: 0.5rem 0.75rem; }\n            select:focus, input[type=\"text\"]:focus, textarea:focus { outline: 2px solid var(--color-primary); outline-offset: -1px; }\n            button { border: none; border-radius: var(--radius); padding: 0.5rem 1rem; font-weight: 500; cursor: pointer; transition: background-color 0.2s; }\n            button.primary { background-color: var(--color-primary); color: white; }\n            button.primary:hover { background-color: var(--color-primary-hover); }\n            button.danger { background-color: var(--color-danger); color: white; }\n            button.danger:hover { background-color: var(--color-danger-hover); }\n            .header-actions { display: flex; gap: 0.5rem; }\n\n            /* Key Tree View */\n            #keySearchInput { width: calc(100% - 2rem); margin: 1rem; flex-shrink: 0; }\n            .key-tree-container { font-family: var(--font-family-mono); font-size: 0.9rem; padding: 0 0.5rem 1rem; overflow-y: auto; flex: 1; min-height: 0; }\n            .key-tree-container ul { list-style: none; padding-left: 0; margin: 0; }\n            .key-tree-container li { padding-left: 20px; position: relative; }\n            .node-label { display: flex; align-items: center; padding: 4px 8px; cursor: pointer; border-radius: 4px; word-break: break-all; user-select: none; }\n            .node-label:hover { background-color: var(--color-key-hover-bg); }\n            .node-label.selected { background-color: var(--color-key-selected-bg); color: var(--color-key-selected-text); }\n            .node-label.selected .node-icon { color: var(--color-key-selected-text) !important; }\n            .node-icon { width: 20px; text-align: center; margin-right: 5px; flex-shrink: 0; }\n            .tree-folder &gt; .node-label .node-icon { color: var(--color-key-folder-icon); font-style: normal; }\n            .tree-folder &gt; .node-label .node-icon::before { content: '\u25b8'; display: inline-block; transition: transform 0.15s ease-in-out; }\n            .tree-folder.open &gt; .node-label .node-icon::before { transform: rotate(90deg); }\n            .tree-leaf &gt; .node-label .node-icon { color: var(--color-key-file-icon); }\n            .tree-leaf &gt; .node-label .node-icon::before { content: '\u2022'; }\n            .tree-children { display: none; }\n            .tree-folder.open &gt; .tree-children { display: block; }\n\n            /* Editor Panel */\n            .editor-toolbar { display: flex; gap: 1rem; align-items: center; padding: 0.75rem 1rem; border-bottom: 1px solid var(--color-border); flex-shrink: 0; }\n            #valueEditor { flex: 1; width: 100%; min-height: 0; border: none; resize: none; font-family: var(--font-family-mono); font-size: 0.95rem; line-height: 1.5; padding: 1rem; background: transparent; color: var(--color-text); }\n            #valueEditor:focus { outline: none; }\n\n            /* Placeholder and Utility */\n            .placeholder-panel { display: flex; flex-direction: column; align-items: center; justify-content: center; color: var(--color-text-muted); text-align: center; }\n            .hidden { display: none !important; }\n            .key-tree-container p.status-message { padding: 1rem; margin: 0; color: var(--color-text-muted); text-align: center; }\n\n            /* Custom Scrollbars */\n            .key-tree-container::-webkit-scrollbar, #valueEditor::-webkit-scrollbar { width: 8px; height: 8px; }\n            .key-tree-container::-webkit-scrollbar-track, #valueEditor::-webkit-scrollbar-track { background: transparent; }\n            .key-tree-container::-webkit-scrollbar-thumb, #valueEditor::-webkit-scrollbar-thumb { background-color: var(--color-border); border-radius: 4px; }\n            .key-tree-container::-webkit-scrollbar-thumb:hover, #valueEditor::-webkit-scrollbar-thumb:hover { background-color: var(--color-text-muted); }\n            #valueEditor::-webkit-scrollbar-corner { background: transparent; }\n\n            /* Responsive */\n            @media (max-width: 768px) {\n                body { padding: 0.5rem; }\n                .db-main-content { flex-direction: column; }\n                .key-panel { width: 100%; max-height: 40vh; }\n            }\n        &lt;/style&gt;\n    &lt;/head&gt;\n    &lt;body&gt;\n        &lt;div id=\"dbManagerContainer\" class=\"db-manager-container\"&gt;\n            &lt;header class=\"db-header\"&gt;\n                &lt;h1&gt;DB Manager&lt;/h1&gt;\n                &lt;div class=\"db-mode-selector\"&gt;\n                    &lt;label for=\"modeSelect\"&gt;Mode:&lt;/label&gt;\n                    &lt;select id=\"modeSelect\"&gt;\n                        &lt;option value=\"LC\"&gt;Local Dict&lt;/option&gt;\n                        &lt;option value=\"CB\"&gt;Cloud Blob&lt;/option&gt;\n                        &lt;option value=\"LR\"&gt;Local Redis&lt;/option&gt;\n                        &lt;option value=\"RR\"&gt;Remote Redis&lt;/option&gt;\n                    &lt;/select&gt;\n                &lt;/div&gt;\n            &lt;/header&gt;\n            &lt;main class=\"db-main-content\"&gt;\n                &lt;aside id=\"keyPanel\" class=\"db-panel key-panel\"&gt;\n                    &lt;div class=\"panel-header\"&gt;\n                        &lt;h2&gt;Keys&lt;/h2&gt;\n                        &lt;div class=\"header-actions\"&gt;\n                            &lt;button id=\"addKeyBtn\" title=\"Add New Key\" style=\"font-size: 1.2rem;\"&gt;+&lt;/button&gt;\n                            &lt;button id=\"refreshKeysBtn\" title=\"Refresh Keys\"&gt;\ud83d\udd04&lt;/button&gt;\n                        &lt;/div&gt;\n                    &lt;/div&gt;\n                    &lt;input type=\"text\" id=\"keySearchInput\" placeholder=\"Search keys...\"&gt;\n                    &lt;div id=\"keyTreeContainer\" class=\"key-tree-container\"&gt;&lt;/div&gt;\n                &lt;/aside&gt;\n                &lt;section id=\"editorPanel\" class=\"db-panel editor-panel hidden\"&gt;\n                    &lt;div class=\"panel-header\"&gt;\n                        &lt;h2 id=\"selectedKey\"&gt;&lt;/h2&gt;\n                        &lt;div class=\"header-actions\"&gt;\n                            &lt;button id=\"saveBtn\" class=\"primary\"&gt;Save&lt;/button&gt;\n                            &lt;button id=\"deleteBtn\" class=\"danger\"&gt;Delete&lt;/button&gt;\n                        &lt;/div&gt;\n                    &lt;/div&gt;\n                    &lt;div class=\"editor-toolbar\"&gt;\n                        &lt;button id=\"formatBtn\"&gt;Format JSON&lt;/button&gt;\n                    &lt;/div&gt;\n                    &lt;textarea id=\"valueEditor\" placeholder=\"Select a key to view its value...\"&gt;&lt;/textarea&gt;\n                &lt;/section&gt;\n                &lt;section id=\"placeholderPanel\" class=\"db-panel editor-panel placeholder-panel\"&gt;\n                    &lt;h3&gt;Select a key to get started&lt;/h3&gt;\n                    &lt;p&gt;Or click the '+' button to add a new one.&lt;/p&gt;\n                &lt;/section&gt;\n            &lt;/main&gt;\n        &lt;/div&gt;\n        &lt;script&gt;\n        (() =&gt; {\n            \"use strict\";\n            const API_NAME = \"DB\";\n\n            class DBManager {\n                constructor() {\n                    this.cache = {\n                        keys: [],\n                        selectedKey: null\n                    };\n                    this.dom = {\n                        modeSelect: document.getElementById('modeSelect'),\n                        keySearchInput: document.getElementById('keySearchInput'),\n                        keyTreeContainer: document.getElementById('keyTreeContainer'),\n                        editorPanel: document.getElementById('editorPanel'),\n                        placeholderPanel: document.getElementById('placeholderPanel'),\n                        selectedKey: document.getElementById('selectedKey'),\n                        valueEditor: document.getElementById('valueEditor'),\n                        addKeyBtn: document.getElementById('addKeyBtn'),\n                        refreshKeysBtn: document.getElementById('refreshKeysBtn'),\n                        saveBtn: document.getElementById('saveBtn'),\n                        deleteBtn: document.getElementById('deleteBtn'),\n                        formatBtn: document.getElementById('formatBtn'),\n                    };\n                    this.init();\n                }\n\n                async init() {\n                    this.setStatusMessage('Loading...');\n                    this.addEventListeners();\n                    await this.loadInitialStatus();\n                    await this.loadKeys();\n                }\n\n                addEventListeners() {\n                    this.dom.refreshKeysBtn.addEventListener('click', () =&gt; this.loadKeys());\n                    this.dom.addKeyBtn.addEventListener('click', () =&gt; this.showAddKeyModal());\n                    this.dom.saveBtn.addEventListener('click', () =&gt; this.saveValue());\n                    this.dom.deleteBtn.addEventListener('click', () =&gt; this.confirmDeleteKey());\n                    this.dom.formatBtn.addEventListener('click', () =&gt; this.formatJson());\n                    this.dom.keySearchInput.addEventListener('input', (e) =&gt; this.renderKeyTree(e.target.value));\n                    this.dom.modeSelect.addEventListener('change', (e) =&gt; this.changeMode(e.target.value));\n\n                    this.dom.keyTreeContainer.addEventListener('click', (e) =&gt; {\n                        const label = e.target.closest('.node-label');\n                        if (!label) return;\n                        const node = label.parentElement;\n                        if (node.classList.contains('tree-folder')) {\n                            node.classList.toggle('open');\n                        } else if (node.dataset.key) {\n                            this.selectKey(node.dataset.key);\n                        }\n                    });\n                }\n\n                async apiRequest(endpoint, payload = null, method = 'POST') {\n                    if (!window.TB?.api?.request) {\n                        console.error(\"TB.api not available!\");\n                        return { error: true, message: \"TB.api not available\" };\n                    }\n                    try {\n                        const url = (method === 'GET' &amp;&amp; payload) ? `${endpoint}?${new URLSearchParams(payload)}` : endpoint;\n                        const body = (method !== 'GET') ? payload : null;\n                        const response = await window.TB.api.request(API_NAME, url, body, method);\n\n                        if (response.error &amp;&amp; response.error !== 'none') {\n                            const errorMsg = response.info?.help_text || response.error;\n                            console.error(`API Error on ${endpoint}:`, errorMsg, response);\n                            if (window.TB?.ui?.Toast) TB.ui.Toast.showError(errorMsg, { duration: 5000 });\n                            return { error: true, message: errorMsg, data: response.get() };\n                        }\n                        return { error: false, data: response.get() };\n                    } catch (err) {\n                        console.error(\"Framework/Network Error:\", err);\n                        if (window.TB?.ui?.Toast) TB.ui.Toast.showError(\"Application or network error.\", { duration: 5000 });\n                        return { error: true, message: \"Network error\" };\n                    }\n                }\n\n                async loadInitialStatus() {\n                    const res = await this.apiRequest('api_get_status', null, 'GET');\n                    if (!res.error) this.dom.modeSelect.value = res.data.mode;\n                }\n\n                async loadKeys() {\n                    this.setStatusMessage('Loading keys...');\n                    const res = await this.apiRequest('api_get_all_keys', null, 'GET');\n                    if (!res.error) {\n                        this.cache.keys = res.data || [];\n                        this.renderKeyTree();\n                    } else {\n                        this.setStatusMessage('Failed to load keys.', true);\n                    }\n                }\n\n                renderKeyTree(filter = '') {\n                    const treeData = {};\n                    const filteredKeys = this.cache.keys.filter(k =&gt; k.toLowerCase().includes(filter.toLowerCase().trim()));\n\n                    for (const key of filteredKeys) {\n                        let currentLevel = treeData;\n                        const parts = key.split(':');\n                        for (let i = 0; i &lt; parts.length; i++) {\n                            const part = parts[i];\n                            if (!part) continue; // Skip empty parts from keys like \"a::b\"\n                            const isLeaf = i === parts.length - 1;\n\n                            if (!currentLevel[part]) {\n                                currentLevel[part] = { _children: {} };\n                            }\n                            if (isLeaf) {\n                                currentLevel[part]._fullKey = key;\n                            }\n                            currentLevel = currentLevel[part]._children;\n                        }\n                    }\n\n                    const treeHtml = this.buildTreeHtml(treeData);\n                    if (treeHtml) {\n                        this.dom.keyTreeContainer.innerHTML = `&lt;ul class=\"key-tree\"&gt;${treeHtml}&lt;/ul&gt;`;\n                        // Re-select the key if it's still visible\n                        if (this.cache.selectedKey) {\n                             const nodeEl = this.dom.keyTreeContainer.querySelector(`[data-key=\"${this.cache.selectedKey}\"] .node-label`);\n                             if(nodeEl) nodeEl.classList.add('selected');\n                        }\n                    } else {\n                         this.setStatusMessage(filter ? 'No keys match your search.' : 'No keys found.');\n                    }\n                }\n\n                buildTreeHtml(node) {\n                    return Object.keys(node).sort().map(key =&gt; {\n                        const childNode = node[key];\n                        const isFolder = Object.keys(childNode._children).length &gt; 0;\n\n                        if (isFolder) {\n                            return `&lt;li class=\"tree-folder\" ${childNode._fullKey ? `data-key=\"${childNode._fullKey}\"`: ''}&gt;\n                                        &lt;div class=\"node-label\"&gt;&lt;i class=\"node-icon\"&gt;&lt;/i&gt;${key}&lt;/div&gt;\n                                        &lt;ul class=\"tree-children\"&gt;${this.buildTreeHtml(childNode._children)}&lt;/ul&gt;\n                                    &lt;/li&gt;`;\n                        } else {\n                            return `&lt;li class=\"tree-leaf\" data-key=\"${childNode._fullKey}\"&gt;\n                                        &lt;div class=\"node-label\"&gt;&lt;i class=\"node-icon\"&gt;&lt;/i&gt;${key}&lt;/div&gt;\n                                    &lt;/li&gt;`;\n                        }\n                    }).join('');\n                }\n\n                async selectKey(key) {\n                    if (!key) return;\n                    this.showEditor(true);\n                    this.cache.selectedKey = key;\n\n                    document.querySelectorAll('.node-label.selected').forEach(el =&gt; el.classList.remove('selected'));\n                    const nodeEl = this.dom.keyTreeContainer.querySelector(`[data-key=\"${key}\"] &gt; .node-label`);\n                    if (nodeEl) nodeEl.classList.add('selected');\n\n                    this.dom.selectedKey.textContent = key;\n                    this.dom.selectedKey.title = key;\n                    this.dom.valueEditor.value = \"Loading...\";\n\n                    const res = await this.apiRequest('api_get_value', { key }, 'GET');\n                    this.dom.valueEditor.value = res.error ? `Error: ${res.message}` : res.data.value;\n                    if (!res.error) this.formatJson(false); // Auto-format if it's valid JSON, without showing an error\n                }\n\n                async saveValue() {\n                    if (!this.cache.selectedKey) return;\n                    if (window.TB?.ui?.Loader) TB.ui.Loader.show(\"Saving...\");\n                    const res = await this.apiRequest('api_set_value', {\n                        key: this.cache.selectedKey,\n                        value: this.dom.valueEditor.value\n                    });\n                    if (window.TB?.ui?.Loader) TB.ui.Loader.hide();\n                    if (!res.error &amp;&amp; window.TB?.ui?.Toast) TB.ui.Toast.showSuccess(\"Key saved successfully!\");\n                }\n\n                async confirmDeleteKey() {\n                    if (!this.cache.selectedKey) return;\n                    if (!window.TB?.ui?.Modal) {\n                        if(confirm(`Delete key \"${this.cache.selectedKey}\"?`)) this.deleteKey();\n                        return;\n                    }\n                    TB.ui.Modal.confirm({\n                        title: 'Delete Key?',\n                        content: `Are you sure you want to delete the key \"&lt;strong&gt;${this.cache.selectedKey}&lt;/strong&gt;\"?&lt;br/&gt;This action cannot be undone.`,\n                        confirmButtonText: 'Delete',\n                        confirmButtonVariant: 'danger',\n                        onConfirm: () =&gt; this.deleteKey()\n                    });\n                }\n\n                async deleteKey() {\n                    const keyToDelete = this.cache.selectedKey;\n                    if (!keyToDelete) return;\n                    if (window.TB?.ui?.Loader) TB.ui.Loader.show(\"Deleting...\");\n                    const res = await this.apiRequest('api_delete_key', { key: keyToDelete });\n                    if (window.TB?.ui?.Loader) TB.ui.Loader.hide();\n\n                    if (!res.error) {\n                        if (window.TB?.ui?.Toast) TB.ui.Toast.showSuccess(`Key \"${keyToDelete}\" deleted.`);\n                        this.cache.selectedKey = null;\n                        this.showEditor(false);\n                        this.loadKeys(); // Refresh the key list\n                    }\n                }\n\n                formatJson(showErrorToast = true) {\n                    try {\n                        const currentVal = this.dom.valueEditor.value.trim();\n                        if (!currentVal) return;\n                        const formatted = JSON.stringify(JSON.parse(currentVal), null, 2);\n                        this.dom.valueEditor.value = formatted;\n                    } catch (e) {\n                        if (showErrorToast &amp;&amp; window.TB?.ui?.Toast) {\n                            TB.ui.Toast.showWarning(\"Value is not valid JSON.\", { duration: 3000 });\n                        }\n                    }\n                }\n\n                showAddKeyModal() {\n                     if (!window.TB?.ui?.Modal) { alert(\"Add Key modal not available.\"); return; }\n                     TB.ui.Modal.show({\n                        title: 'Add New Key',\n                        content: `&lt;input type=\"text\" id=\"newKeyInput\" placeholder=\"Enter new key name (e.g., app:settings:user)\" style=\"width: 100%; margin-bottom: 1rem;\"/&gt;\n                                  &lt;textarea id=\"newValueInput\" placeholder='Enter value (e.g., {\"theme\": \"dark\"})' style=\"width: 100%; height: 150px; font-family: var(--font-family-mono);\"&gt;&lt;/textarea&gt;`,\n                        onOpen: (modal) =&gt; document.getElementById('newKeyInput').focus(),\n                        buttons: [{\n                            text: 'Save', variant: 'primary',\n                            action: async (modal) =&gt; {\n                                const newKey = document.getElementById('newKeyInput').value.trim();\n                                const newValue = document.getElementById('newValueInput').value;\n                                if (!newKey) { if (window.TB?.ui?.Toast) TB.ui.Toast.showError(\"Key name cannot be empty.\"); return; }\n                                modal.close();\n                                if (window.TB?.ui.Loader) TB.ui.Loader.show(\"Saving...\");\n                                const res = await this.apiRequest('api_set_value', { key: newKey, value: newValue });\n                                if (window.TB?.ui.Loader) TB.ui.Loader.hide();\n                                if (!res.error) {\n                                    if (window.TB?.ui?.Toast) TB.ui.Toast.showSuccess(\"New key created!\");\n                                    await this.loadKeys();\n                                    this.selectKey(newKey);\n                                }\n                            }\n                        }, { text: 'Cancel', action: (modal) =&gt; modal.close() }]\n                    });\n                }\n\n                async changeMode(newMode) {\n                    if (window.TB?.ui?.Loader) TB.ui.Loader.show(`Switching to ${newMode}...`);\n                    const res = await this.apiRequest('api_change_mode', { mode: newMode });\n                    if (!res.error) {\n                       this.cache.selectedKey = null;\n                       this.showEditor(false);\n                       await this.loadKeys();\n                       if (window.TB?.ui?.Toast) TB.ui.Toast.showSuccess(`Switched to ${newMode} mode.`);\n                    } else {\n                       if (window.TB?.ui?.Toast) TB.ui.Toast.showError(`Failed to switch mode.`);\n                       await this.loadInitialStatus(); // Revert dropdown to actual status\n                    }\n                    if (window.TB?.ui?.Loader) TB.ui.Loader.hide();\n                }\n\n                showEditor(show) {\n                    this.dom.editorPanel.classList.toggle('hidden', !show);\n                    this.dom.placeholderPanel.classList.toggle('hidden', show);\n                }\n\n                setStatusMessage(message, isError = false) {\n                    this.dom.keyTreeContainer.innerHTML = `&lt;p class=\"status-message\" style=\"${isError ? 'color: var(--color-danger);' : ''}\"&gt;${message}&lt;/p&gt;`;\n                }\n            }\n\n            // Defer initialization until the ToolboxV2 framework is ready\n\n             function onTbReady() { new DBManager(); }\n             if (window.TB?.events) {\n    if (window.TB.config?.get('appRootId')) { // A sign that TB.init might have run\n         onTbReady();\n    } else {\n        window.TB.events.on('tbjs:initialized', onTbReady, { once: true });\n    }\n} else {\n    // Fallback if TB is not even an object yet, very early load\n    document.addEventListener('tbjs:initialized', onTbReady, { once: true }); // Custom event dispatch from TB.init\n}\n\n        })();\n        &lt;/script&gt;\n    &lt;/body&gt;\n    &lt;/html&gt;\n    \"\"\"\n    app = get_app(Name)\n    try:\n        # Prepend the web context to include necessary framework scripts (like TB.js)\n        web_context = app.web_context()\n        return Result.html(web_context + html_content)\n    except Exception:\n        # Fallback in case web_context is not available\n        return Result.html(html_content)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.EventManager","title":"<code>EventManager</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.EventManager.module","title":"<code>module</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.EventManager.module.EventManagerClass","title":"<code>EventManagerClass</code>","text":"Source code in <code>toolboxv2/mods/EventManager/module.py</code> <pre><code>class EventManagerClass:\n    events: set[Event] = set()\n    source_id: str\n    _name: str\n    _identification: str\n\n    routes_client: dict[str, ProxyRout] = {}\n    routers_servers: dict[str, DaemonRout] = {}\n    routers_servers_tasks: list[Any] = []\n    routers_servers_tasks_running_flag: bool = False\n\n    receiver_que: queue.Queue\n    response_que: queue.Queue\n\n    def add_c_route(self, name, route: ProxyRout):\n        self.routes_client[name] = route\n\n    async def receive_all_client_data(self):\n\n        close_connections = []\n        add_ev = []\n        for name, client in self.routes_client.items():\n            if client.client is None or not client.client.get('alive', False):\n                close_connections.append(name)\n                continue\n            data = client.r\n\n            if isinstance(data, str) and data == \"No data\":\n                continue\n            elif isinstance(data, EventID) and len(data.get_source()) != 0:\n                await self.trigger_event(data)\n            elif isinstance(data, EventID) and len(data.get_source()) == 0:\n                print(f\"Event returned {data.payload}\")\n                self.response_que.put(data)\n            elif isinstance(data,\n                            dict) and 'error' in data and 'origin' in data and 'result' in data and 'info' in data:\n\n                self.response_que.put(Result.result_from_dict(**data).print())\n            elif isinstance(data,\n                            dict) and 'source' in data and 'path' in data and 'ID' in data and 'identifier' in data:\n                del data['identifier']\n                ev_id = EventID(**data)\n                await self.trigger_event(ev_id)\n            elif isinstance(data, Event):\n                print(\"Event:\", str(data.event_id), data.name)\n                add_ev.append(data)\n            elif isinstance(data, Result):\n                self.response_que.put(data.print())\n            else:\n                print(f\"Unknown Data {data}\")\n\n        for ev in add_ev:\n            await self.register_event(ev)\n\n        for client_name in close_connections:\n            print(f\"Client {client_name} closing connection\")\n            self.remove_c_route(client_name)\n\n    def remove_c_route(self, name):\n        self.routes_client[name].close()\n        del self.routes_client[name]\n\n    def crate_rout(self, source, addr=None):\n        if addr is None:\n            addr = ('0.0.0.0', 6588)\n        host, port = addr\n        if isinstance(port, str):\n            port = int(port)\n        return Rout(\n            _from=self.source_id,\n            _to=source,\n            _from_port=int(os.getenv(\"TOOLBOXV2_BASE_PORT\", 6588)),\n            _from_host=os.getenv(\"TOOLBOXV2_BASE_HOST\"),\n            _to_port=port,\n            _to_host=host,\n            routing_function=self.routing_function_router,\n        )\n\n    def __init__(self, source_id, _identification=\"PN\"):\n        self.bo = False\n        self.running = False\n        self.source_id = source_id\n        self.receiver_que = queue.Queue()\n        self.response_que = queue.Queue()\n        self._identification = _identification\n        self._name = self._identification + '-' + str(uuid.uuid4()).split('-')[1]\n        self.routes = {}\n        self.logger = get_logger()\n\n    @property\n    def identification(self) -&gt; str:\n        return self._identification\n\n    @identification.setter\n    def identification(self, _identification: str):\n        self.stop()\n        self._identification = _identification\n        self._name = self._identification + '-' + str(uuid.uuid4()).split('-')[1]\n\n    async def identity_post_setter(self):\n\n        do_reconnect = len(list(self.routers_servers.keys())) &gt; 0\n        if self._identification == \"P0\":\n            await self.add_server_route(self._identification, ('0.0.0.0', 6568))\n        if self._identification == \"P0|S0\":\n            await self.add_server_route(self._identification, ('0.0.0.0', 6567))\n\n        await asyncio.sleep(0.1)\n        self.start()\n        await asyncio.sleep(0.1)\n        if do_reconnect:\n            self.reconnect(\"ALL\")\n\n    async def open_connection_server(self, port):\n        await self.add_server_route(self._identification, ('0.0.0.0', port))\n\n    def start(self):\n        self.running = True\n        threading.Thread(target=async_test(self.receiver), daemon=True).start()\n\n    def make_event_from_fuction(self, fuction, name, *args, source_types=SourceTypes.F,\n                                scope=Scope.local,\n                                exec_in=ExecIn.local,\n                                threaded=False, **kwargs):\n\n        return Event(source=fuction,\n                     name=name,\n                     event_id=EventID.crate_with_source(self.source_id), args=args,\n                     kwargs_=kwargs,\n                     source_types=source_types,\n                     scope=scope,\n                     exec_in=exec_in,\n                     threaded=threaded,\n                     )\n\n    async def add_client_route(self, source_id, addr):\n        if source_id in self.routes_client:\n            if self.routes_client[source_id].client is None or not self.routes_client[source_id].client.get('alive'):\n                await self.routes_client[source_id].reconnect()\n                return True\n            print(\"Already connected\")\n            return False\n        try:\n            pr = await ProxyRout.toProxy(rout=self.crate_rout(source_id, addr=addr), name=source_id)\n            await asyncio.sleep(0.1)\n            await pr.client.get('sender')({\"id\": self._identification,\n                                           \"continue\": False,\n                                           \"key\": os.getenv('TB_R_KEY', 'root@remote')})\n            await asyncio.sleep(0.1)\n            self.add_c_route(source_id, pr)\n            return True\n        except Exception as e:\n            print(f\"Check the port {addr} Sever likely not Online : {e}\")\n            return False\n\n    async def add_mini_client(self, name: str, addr: tuple[str, int]):\n\n        mini_proxy = await ProxyRout(class_instance=None, timeout=15, app=get_app(),\n                                     remote_functions=[\"\"], peer=False, name=name, do_connect=False)\n\n        async def _(x):\n            return await self.routers_servers[self._identification].send(x, addr)\n\n        mini_proxy.put_data = _\n        mini_proxy.connect = lambda *x, **_: None\n        mini_proxy.reconnect = lambda *x, **_: None\n        mini_proxy.close = lambda *x, **_: None\n        mini_proxy.client = {'alive': True}\n        mini_proxy.r = \"No data\"\n        self.routes_client[name] = mini_proxy\n\n    async def on_register(self, id_, data):\n        try:\n            if \"unknown\" not in self.routes:\n                self.routes[\"unknown\"] = {}\n\n            if id_ != \"new_con\" and 'id' in data:\n                id_data = data.get('id')\n                id_ = eval(id_)\n                c_host, c_pot = id_\n                print(f\"Registering: new client {id_data} : {c_host, c_pot}\")\n                if id_data not in self.routes_client:\n                    await self.add_mini_client(id_data, (c_host, c_pot))\n                    self.routes[str((c_host, c_pot))] = id_data\n\n            # print(\"self.routes:\", self.routes)\n        except Exception as e:\n            print(\"Error in on_register\", str(e))\n\n    def on_client_exit(self, id_):\n\n        if isinstance(id_, str):\n            id_ = eval(id_)\n\n        c_name = self.routes.get(id_)\n\n        if c_name is None:\n            return\n\n        if c_name in self.routes_client:\n            self.remove_c_route(c_name)\n            print(f\"Removed route to {c_name}\")\n\n    async def add_server_route(self, source_id, addr=None):\n        if addr is None:\n            addr = ('0.0.0.0', 6588)\n        try:\n            self.routers_servers[source_id] = await DaemonRout(rout=self.crate_rout(source_id, addr=addr),\n                                                               name=source_id,\n                                                               on_r=self.on_register)\n            self.routers_servers_tasks.append(self.routers_servers[source_id].online)\n        except Exception as e:\n            print(f\"Sever already Online : {e}\")\n\n        if not self.routers_servers_tasks_running_flag:\n            self.routers_servers_tasks_running_flag = True\n            threading.Thread(target=self.server_route_runner, daemon=True).start()\n\n    def server_route_runner(self):\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n\n        # Sammle alle Ergebnisse zusammen\n        results = loop.run_until_complete(asyncio.gather(*self.routers_servers_tasks))\n\n        for result in results:\n            print(result)\n\n        loop.close()\n        self.routers_servers_tasks_running_flag = False\n\n    async def add_js_route(self, source_id=\"js:web\"):\n        await self.add_server_route(source_id, (\"./web/scripts/tb_socket.sock\", 0))\n\n    async def register_event(self, event: Event):\n\n        if event in self.events:\n            return Result.default_user_error(\"Event registration failed Event already registered\")\n\n        print(f\"Registration new Event : {event.name}, {str(event.event_id)}\")\n        self.events.add(event)\n\n        if event.scope.name == Scope.instance.name:\n            return\n\n        if event.scope.name == Scope.local.name:\n            if not self.bo and \"P0\" not in self.routes_client and os.getenv(\"TOOLBOXV2_BASE_HOST\",\n                                                                            \"localhost\") != \"localhost\":\n                await self.add_client_route(\"P0\", (os.getenv(\"TOOLBOXV2_BASE_HOST\", \"localhost\"),\n                                                   os.getenv(\"TOOLBOXV2_BASE_PORT\", 6568)))\n                self.bo = True\n            return\n\n        if event.scope.name == Scope.local_network.name:\n            if self.identification == \"P0\" and not self.bo:\n                t0 = threading.Thread(target=self.start_brodcast_router_local_network, daemon=True)\n                t0.start()\n            elif not self.bo and \"P0\" not in self.routes_client and os.getenv(\"TOOLBOXV2_BASE_HOST\",\n                                                                              \"localhost\") == \"localhost\":\n                self.bo = True\n                # self.add_server_route(self.identification, (\"127.0.0.1\", 44667))\n                with Spinner(message=\"Sercheing for Rooter instance\", count_down=True, time_in_s=6):\n                    with ThreadPoolExecutor(max_workers=1) as executor:\n                        t0 = executor.submit(make_known, self.identification)\n                        try:\n                            data = t0.result(timeout=6)\n                        except TimeoutError:\n                            print(\"No P0 found in network or on device\")\n                            return\n                    print(f\"Found P0 on {type(data)} {data.get('host')}\")\n                    await self.add_client_route(\"P0\", (data.get(\"host\"), os.getenv(\"TOOLBOXV2_BASE_PORT\", 6568)))\n            elif not self.bo and \"P0\" not in self.routes_client and os.getenv(\"TOOLBOXV2_BASE_HOST\",\n                                                                              \"localhost\") != \"localhost\":\n                do = await self.add_client_route(\"P0\", (\n                    os.getenv(\"TOOLBOXV2_BASE_HOST\", \"localhost\"), os.getenv(\"TOOLBOXV2_BASE_PORT\", 6568)))\n                self.bo = do\n                if not do:\n                    print(\"Connection failed\")\n                    os.environ[\"TOOLBOXV2_BASE_HOST\"] = \"localhost\"\n\n        if event.scope.name == Scope.global_network.name:\n            await self.add_server_route(self.source_id, ('0.0.0.0', os.getenv(\"TOOLBOXV2_REMOTE_PORT\", 6587)))\n\n    async def connect_to_remote(self, host=os.getenv(\"TOOLBOXV2_REMOTE_IP\"),\n                                port=os.getenv(\"TOOLBOXV2_REMOTE_PORT\", 6587)):\n        await self.add_client_route(\"S0\", (host, port))\n\n    def start_brodcast_router_local_network(self):\n        self.bo = True\n\n        # print(\"Starting brodcast router 0\")\n        router = start_client(get_local_ip())\n        # print(\"Starting brodcast router 1\")\n        # next(router)\n        # print(\"Starting brodcast router\")\n        while self.running:\n            source_id, connection = next(router)\n            print(f\"Infos :{source_id}, connection :{connection}\")\n            self.routes[source_id] = connection[0]\n            router.send(self.running)\n\n        router.send(\"e\")\n        router.close()\n\n    def _get_event_by_id_or_name(self, event_id: str or EventID):\n        if isinstance(event_id, str):\n            events = [e for e in self.events if e.name == event_id]\n            if len(events) &lt; 1:\n                return Result.default_user_error(\"Event not registered\")\n            event = events[0]\n\n        elif isinstance(event_id, EventID):\n            events = [e for e in self.events if e.event_id.ID == event_id.ID]\n            if len(events) &lt; 1:\n                events = [e for e in self.events if e.name == event_id.ID]\n            if len(events) &lt; 1:\n                return Result.default_user_error(\"Event not registered\")\n            event = events[0]\n\n        elif isinstance(event_id, Event):\n            if event_id not in self.events:\n                return Result.default_user_error(\"Event not registered\")\n            event = event_id\n\n        else:\n            event = Result.default_user_error(\"Event not registered\")\n\n        return event\n\n    def remove_event(self, event: Event or EventID or str):\n\n        event = self._get_event_by_id_or_name(event)\n        if isinstance(event, Event):\n            self.events.remove(event)\n        else:\n            return event\n\n    async def _trigger_local(self, event_id: EventID):\n        \"\"\"\n        Exec source based on\n\n        source_types\n            F -&gt; call directly\n            R -&gt; use get_app(str(event_id)).run_any(*args, **kwargs)\n            S -&gt; evaluate string\n        scope\n            instance -&gt; _trigger_local\n            local -&gt; if you ar proxy app run the event through get_app(str(event_id)).run_any(TBEF.EventManager._trigger_local, args=args, kwargs=kwargs, get_result=True)\n            local_network -&gt; use proxy0 app to communicate withe Daemon0 then local\n            global_network -&gt;\n        exec_in\n        event_id\n        threaded\n\n                       \"\"\"\n        event = self._get_event_by_id_or_name(event_id)\n\n        if isinstance(event, Result):\n            event.print()\n            if self.identification == \"P0\":\n                return event\n            print(f\"Routing to P0 {self.events}\")\n            if self.source_id not in self.routes_client:\n                # self.routers[self.source_id] = DaemonRout(rout=self.crate_rout(self.source_id))\n                await self.add_client_route(\"P0\", ('127.0.0.1', 6568))\n            return await self.route_event_id(event_id)\n\n        # if event.threaded:\n        #    threading.Thread(target=self.runner, args=(event, event_id), daemon=True).start()\n        #    return \"Event running In Thread\"\n        # else:\n\n        return await self.runner(event, event_id)\n\n    async def runner(self, event, event_id: EventID):\n\n        if event.kwargs_ is None:\n            event.kwargs_ = {}\n        if event.args is None:\n            event.args = []\n\n        if event.source_types.name is SourceTypes.P.name:\n            return event.source(*event.args, payload=event_id, **event.kwargs_)\n\n        if event.source_types.name is SourceTypes.F.name:\n            return event.source(*event.args, **event.kwargs_)\n\n        if event.source_types.name is SourceTypes.R.name:\n            return get_app(str(event_id)).run_any(mod_function_name=event.source, get_results=True, args_=event.args,\n                                                  kwargs_=event.kwargs_)\n\n        if event.source_types.name is SourceTypes.AP.name:\n            if 'payload' in event.kwargs_:\n                if event_id.payload != event.kwargs_['payload']:\n                    event_id.payload = event.kwargs_['payload']\n                del event.kwargs_['payload']\n            print(event.args, event.kwargs_, \"TODO: remove\")\n            return await event.source(*event.args, payload=event_id, **event.kwargs_)\n\n        if event.source_types.name is SourceTypes.AF.name:\n            return await event.source(*event.args, **event.kwargs_)\n\n        if event.source_types.name is SourceTypes.AR.name:\n            return await get_app(str(event_id)).run_any(mod_function_name=event.source, get_results=True,\n                                                        args_=event.args,\n                                                        kwargs_=event.kwargs_)\n\n        if event.source_types.name is SourceTypes.S.name:\n            return eval(event.source, __locals={'app': get_app(str(event_id)), 'event': event, 'eventManagerC': self})\n\n    async def routing_function_router(self, event_id: EventID):\n\n        result = await self.trigger_event(event_id)\n\n        if result is None:\n            result = Result.default_user_error(\"Invalid Event ID\")\n\n        if isinstance(result, bytes | dict):\n            pass\n        elif isinstance(result, Result):\n            result.result.data_info = str(event_id)\n        elif isinstance(result, EventID):\n            result = Result.default_internal_error(\"Event not found\", data=result)\n        else:\n            result = Result.ok(data=result, data_info=\"&lt;automatic&gt;\", info=str(event_id.path))\n\n        if isinstance(result, str):\n            result = result.encode()\n\n        return result\n\n    async def trigger_evnet_by_name(self, name: str):\n        await self.trigger_event(EventID.crate_name_as_id(name=name))\n\n    async def trigger_event(self, event_id: EventID):\n        \"\"\"\n        Exec source based on\n\n        source_types\n            F -&gt; call directly\n            R -&gt; use get_app(str(event_id)).run_any(*args, **kwargs)\n            S -&gt; evaluate string\n        scope\n            instance -&gt; _trigger_local\n            local -&gt; if you ar proxy app run the event through get_app(str(event_id)).run_any(TBEF.EventManager._trigger_local, args=args, kwargs=kwargs, get_result=True)\n            local_network -&gt; use proxy0 app to communicate withe Daemon0 then local\n            global_network -&gt;\n        exec_in\n        event_id\n        threaded\n\n                       \"\"\"\n        # print(f\"event-id Ptah : {event_id.get_path()}\")\n        # print(f\"testing trigger_event for {event_id.get_source()} {event_id.get_source()[-1] == self.source_id} \")\n        print(str(event_id))\n        if event_id.get_source()[-1] == self.source_id:\n            payload = await self._trigger_local(event_id)\n            event_id.set_payload(payload)\n            if len(event_id.path) &gt; 1:\n                event_id.source = ':'.join([e.split(':')[0] for e in event_id.get_path() if e != \"E\"])\n                res = await self.route_event_id(event_id)\n                if isinstance(res, Result):\n                    res.print()\n                else:\n                    print(res)\n            return payload\n        return await self.route_event_id(event_id)\n\n    async def route_event_id(self, event_id: EventID):\n\n        # print(f\"testing route_event_id for {event_id.get_source()[-1]}\")\n        if event_id.get_source()[-1] == '*':  # self.identification == \"P0\" and\n            responses = []\n            event_id.source = ':'.join(event_id.get_source()[:-1])\n            event_id.add_path(f\"{self._name}({self.source_id})\")\n            data = asdict(event_id)\n            for name, rout_ in self.routes_client.items():\n                if name in event_id.path:\n                    continue\n                ret = await rout_.put_data(data)\n                responses.append(ret)\n            return responses\n        route = self.routes_client.get(event_id.get_source()[-1])\n        # print(\"route:\", route)\n        if route is None:\n            route = self.routes_client.get(event_id.get_path()[-1])\n        if route is None:\n            return event_id.add_path((\"\" if len(event_id.get_source()) == 1 else \"404#\")+self.identification)\n        time.sleep(0.25)\n        event_id.source = ':'.join(event_id.get_source()[:-1])\n        event_id.add_path(f\"{self._name}({self.source_id})\")\n        return await route.put_data(asdict(event_id))\n\n    async def receiver(self):\n\n        t0 = time.time()\n\n        while self.running:\n            time.sleep(0.25)\n            if not self.receiver_que.empty():\n                event_id = self.receiver_que.get()\n                print(\"Receiver Event\", str(event_id))\n                await self.trigger_event(event_id)\n\n            if time.time() - t0 &gt; 5:\n                await self.receive_all_client_data()\n                t0 = time.time()\n\n    def info(self):\n        return {\"source\": self.source_id, \"known_routs:\": self.routers_servers, \"_router\": self.routes_client,\n                \"events\": self.events}\n\n    def stop(self):\n        self.running = False\n        list(map(lambda x: x.disconnect(), self.routes_client.values()))\n        list(map(lambda x: x.stop(), self.routers_servers.values()))\n\n    def reconnect(self, name):\n        if name is None:\n            pass\n        elif name in self.routes_client:\n            self.routes_client[name].reconnect()\n            return\n        list(map(lambda x: x.reconnect(), self.routes_client.values()))\n\n    async def verify(self, name):\n        if name is None:\n            pass\n        elif name in self.routes_client:\n            await self.routes_client[name].verify()\n            return\n        for x in self.routes_client.values():\n            await x.verify()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.EventManager.module.EventManagerClass.trigger_event","title":"<code>trigger_event(event_id)</code>  <code>async</code>","text":"<p>Exec source based on</p> <p>source_types     F -&gt; call directly     R -&gt; use get_app(str(event_id)).run_any(args, *kwargs)     S -&gt; evaluate string scope     instance -&gt; _trigger_local     local -&gt; if you ar proxy app run the event through get_app(str(event_id)).run_any(TBEF.EventManager._trigger_local, args=args, kwargs=kwargs, get_result=True)     local_network -&gt; use proxy0 app to communicate withe Daemon0 then local     global_network -&gt; exec_in event_id threaded</p> Source code in <code>toolboxv2/mods/EventManager/module.py</code> <pre><code>async def trigger_event(self, event_id: EventID):\n    \"\"\"\n    Exec source based on\n\n    source_types\n        F -&gt; call directly\n        R -&gt; use get_app(str(event_id)).run_any(*args, **kwargs)\n        S -&gt; evaluate string\n    scope\n        instance -&gt; _trigger_local\n        local -&gt; if you ar proxy app run the event through get_app(str(event_id)).run_any(TBEF.EventManager._trigger_local, args=args, kwargs=kwargs, get_result=True)\n        local_network -&gt; use proxy0 app to communicate withe Daemon0 then local\n        global_network -&gt;\n    exec_in\n    event_id\n    threaded\n\n                   \"\"\"\n    # print(f\"event-id Ptah : {event_id.get_path()}\")\n    # print(f\"testing trigger_event for {event_id.get_source()} {event_id.get_source()[-1] == self.source_id} \")\n    print(str(event_id))\n    if event_id.get_source()[-1] == self.source_id:\n        payload = await self._trigger_local(event_id)\n        event_id.set_payload(payload)\n        if len(event_id.path) &gt; 1:\n            event_id.source = ':'.join([e.split(':')[0] for e in event_id.get_path() if e != \"E\"])\n            res = await self.route_event_id(event_id)\n            if isinstance(res, Result):\n                res.print()\n            else:\n                print(res)\n        return payload\n    return await self.route_event_id(event_id)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.EventManager.module.Rout","title":"<code>Rout</code>  <code>dataclass</code>","text":"Source code in <code>toolboxv2/mods/EventManager/module.py</code> <pre><code>@dataclass\nclass Rout:\n    _from: str\n    _to: str\n\n    _from_port: int\n    _from_host: str\n\n    _to_port: int\n    _to_host: str\n\n    routing_function: Callable\n\n    @property\n    def to_host(self):\n        return self._to_host\n\n    @property\n    def to_port(self):\n        return self._to_port\n\n    async def put_data(self, event_id_data: dict[str, str]):\n        event_id: EventID = EventID(**event_id_data)\n        return await self.routing_function(event_id)\n\n    def close(self):\n        \"\"\" Close \"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.EventManager.module.Rout.close","title":"<code>close()</code>","text":"<p>Close</p> Source code in <code>toolboxv2/mods/EventManager/module.py</code> <pre><code>def close(self):\n    \"\"\" Close \"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FastApi","title":"<code>FastApi</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.FastApi.fast_api_install","title":"<code>fast_api_install</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.FastApi.fast_api_install.FileBrowser","title":"<code>FileBrowser</code>","text":"Source code in <code>toolboxv2/mods/FastApi/fast_api_install.py</code> <pre><code>class FileBrowser:\n    ALLOWED_DIRECTORIES: set[str] = {\"mods_sto\", \"flows\", \"static\", \"apps\"}\n\n    def __init__(self, start_dir: str):\n        self.static_dir = pathlib.Path(start_dir).resolve()\n        self.current_container = None\n\n    def is_path_allowed(self, file_path: pathlib.Path) -&gt; bool:\n        \"\"\"Check if the path is within allowed directories.\"\"\"\n        if not file_path.is_relative_to(self.static_dir):\n            return False\n\n        relative_parts = file_path.parts[len(self.static_dir.parts):]\n        return any(part in self.ALLOWED_DIRECTORIES for part in relative_parts)\n\n    async def download_file(self, file_path: pathlib.Path) -&gt; None:\n        \"\"\"Handle file download.\"\"\"\n        if not file_path.is_file() or not self.is_path_allowed(file_path):\n            ui.notify('Access denied or file not found', type='negative')\n            return\n\n        # Use NiceGUI's download function\n        await ui.download(str(file_path))\n\n    def refresh_view(self, path: pathlib.Path) -&gt; None:\n        \"\"\"Refresh the file browser view.\"\"\"\n        if self.current_container:\n            self.current_container.clear()\n\n        with self.current_container:\n            # Add header with current path\n            ui.label(f'Current directory: {path.relative_to(self.static_dir)}').classes('text-h6')\n\n            # Add parent directory link if not at root\n            if path != self.static_dir and path.parent.is_relative_to(self.static_dir):\n                with ui.row().classes('w-full items-center'):\n                    ui.button('..', on_click=lambda p=path.parent: self.refresh_view(p)) \\\n                        .classes('bg-blue-100 px-4 py-2 rounded')\n\n            # List directories first\n            for item in sorted(path.iterdir()):\n                if not self.is_path_allowed(item):\n                    continue\n\n                with ui.row().classes('w-full items-center gap-2'):\n                    if item.is_dir():\n                        ui.button(f'\ud83d\udcc1 {item.name}/',\n                                  on_click=lambda p=item: self.refresh_view(p)) \\\n                            .classes('bg-blue-100 px-4 py-2 rounded')\n                    else:\n                        ui.label(f'\ud83d\udcc4 {item.name}').classes('flex-grow')\n                        ui.button('Download',\n                                  on_click=lambda p=item: self.download_file(p)) \\\n                            .classes('bg-green-100 px-4 py-2 rounded')\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FastApi.fast_api_install.FileBrowser.download_file","title":"<code>download_file(file_path)</code>  <code>async</code>","text":"<p>Handle file download.</p> Source code in <code>toolboxv2/mods/FastApi/fast_api_install.py</code> <pre><code>async def download_file(self, file_path: pathlib.Path) -&gt; None:\n    \"\"\"Handle file download.\"\"\"\n    if not file_path.is_file() or not self.is_path_allowed(file_path):\n        ui.notify('Access denied or file not found', type='negative')\n        return\n\n    # Use NiceGUI's download function\n    await ui.download(str(file_path))\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FastApi.fast_api_install.FileBrowser.is_path_allowed","title":"<code>is_path_allowed(file_path)</code>","text":"<p>Check if the path is within allowed directories.</p> Source code in <code>toolboxv2/mods/FastApi/fast_api_install.py</code> <pre><code>def is_path_allowed(self, file_path: pathlib.Path) -&gt; bool:\n    \"\"\"Check if the path is within allowed directories.\"\"\"\n    if not file_path.is_relative_to(self.static_dir):\n        return False\n\n    relative_parts = file_path.parts[len(self.static_dir.parts):]\n    return any(part in self.ALLOWED_DIRECTORIES for part in relative_parts)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FastApi.fast_api_install.FileBrowser.refresh_view","title":"<code>refresh_view(path)</code>","text":"<p>Refresh the file browser view.</p> Source code in <code>toolboxv2/mods/FastApi/fast_api_install.py</code> <pre><code>def refresh_view(self, path: pathlib.Path) -&gt; None:\n    \"\"\"Refresh the file browser view.\"\"\"\n    if self.current_container:\n        self.current_container.clear()\n\n    with self.current_container:\n        # Add header with current path\n        ui.label(f'Current directory: {path.relative_to(self.static_dir)}').classes('text-h6')\n\n        # Add parent directory link if not at root\n        if path != self.static_dir and path.parent.is_relative_to(self.static_dir):\n            with ui.row().classes('w-full items-center'):\n                ui.button('..', on_click=lambda p=path.parent: self.refresh_view(p)) \\\n                    .classes('bg-blue-100 px-4 py-2 rounded')\n\n        # List directories first\n        for item in sorted(path.iterdir()):\n            if not self.is_path_allowed(item):\n                continue\n\n            with ui.row().classes('w-full items-center gap-2'):\n                if item.is_dir():\n                    ui.button(f'\ud83d\udcc1 {item.name}/',\n                              on_click=lambda p=item: self.refresh_view(p)) \\\n                        .classes('bg-blue-100 px-4 py-2 rounded')\n                else:\n                    ui.label(f'\ud83d\udcc4 {item.name}').classes('flex-grow')\n                    ui.button('Download',\n                              on_click=lambda p=item: self.download_file(p)) \\\n                        .classes('bg-green-100 px-4 py-2 rounded')\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FastApi.fast_lit","title":"<code>fast_lit</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.FastApi.fast_lit.APIRequestHelper","title":"<code>APIRequestHelper</code>","text":"Source code in <code>toolboxv2/mods/FastApi/fast_lit.py</code> <pre><code>class APIRequestHelper:\n    def __init__(self, token_secret: str):\n        self.token_secret = token_secret\n\n    async def make_api_request(self, endpoint: str, method: str, data: dict | None = None,\n                               headers: dict | None = None, session_token: str | None = None) -&gt; Any:\n        \"\"\"\n        Make API requests while maintaining session context\n        \"\"\"\n        import httpx\n\n        if headers is None:\n            headers = {}\n\n        if session_token:\n            try:\n                session_data = jwt.decode(session_token, self.token_secret, algorithms=[\"HS256\"])\n                headers['X-Session-ID'] = session_data.get('session_id')\n                headers['Authorization'] = f'Bearer {session_token}'\n            except jwt.InvalidTokenError:\n                raise ValueError(\"Invalid session token\")\n\n        async with httpx.AsyncClient() as client:\n            response = await client.request(\n                method=method,\n                url=endpoint,\n                json=data,\n                headers=headers\n            )\n\n            return response.json()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FastApi.fast_lit.APIRequestHelper.make_api_request","title":"<code>make_api_request(endpoint, method, data=None, headers=None, session_token=None)</code>  <code>async</code>","text":"<p>Make API requests while maintaining session context</p> Source code in <code>toolboxv2/mods/FastApi/fast_lit.py</code> <pre><code>async def make_api_request(self, endpoint: str, method: str, data: dict | None = None,\n                           headers: dict | None = None, session_token: str | None = None) -&gt; Any:\n    \"\"\"\n    Make API requests while maintaining session context\n    \"\"\"\n    import httpx\n\n    if headers is None:\n        headers = {}\n\n    if session_token:\n        try:\n            session_data = jwt.decode(session_token, self.token_secret, algorithms=[\"HS256\"])\n            headers['X-Session-ID'] = session_data.get('session_id')\n            headers['Authorization'] = f'Bearer {session_token}'\n        except jwt.InvalidTokenError:\n            raise ValueError(\"Invalid session token\")\n\n    async with httpx.AsyncClient() as client:\n        response = await client.request(\n            method=method,\n            url=endpoint,\n            json=data,\n            headers=headers\n        )\n\n        return response.json()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FastApi.fast_lit.BidirectionalStreamlitAppManager","title":"<code>BidirectionalStreamlitAppManager</code>","text":"<p>               Bases: <code>BaseHTTPMiddleware</code></p> Source code in <code>toolboxv2/mods/FastApi/fast_lit.py</code> <pre><code>class BidirectionalStreamlitAppManager(BaseHTTPMiddleware, metaclass=Singleton):\n    def __init__(self, app: FastAPI, streamlit_apps_dir: str = \"./apps\"):\n        super().__init__(app)\n        self.streamlit_manager = StreamlitAppManager()\n        self.streamlit_apps_dir = streamlit_apps_dir\n        self.token_secret = os.getenv(\"TOKEN_SECRET\", \"your-secret-key\")\n        self.api_helper = APIRequestHelper(self.token_secret)\n\n        # Run cleanup task\n        asyncio.create_task(self.periodic_cleanup())\n\n    #def add_ws(self, fast_app):\n        # Register WebSocket routes\n     #   fast_app.add_api_websocket_route(\"/ws/{session_id}/{app_id}\", self.websocket_endpoint, \"StWebSocket\")\n\n    async def periodic_cleanup(self):\n        while True:\n            self.streamlit_manager.cleanup_inactive_apps()\n            await asyncio.sleep(3600)\n\n    def create_streamlit_token(self, session_data: dict, app_name: str) -&gt; str:\n        payload = {\n            \"app_name\": app_name,\n            \"session_id\": session_data.get(\"ID\"),\n            \"user_data\": session_data.get(\"live_data\"),\n            \"exp\": datetime.utcnow() + timedelta(hours=1)\n        }\n        return jwt.encode(payload, self.token_secret, algorithm=\"HS256\")\n\n    #async def websocket_endpoint(self, websocket: WebSocket, session_id: str, app_id: str):\n    #    await self.streamlit_manager.ws_manager.connect(websocket, session_id, app_id)\n    #    try:\n    #        while True:\n    #            message = await websocket.receive_json()\n    #            await self.streamlit_manager.ws_manager.handle_message(session_id, message)\n    #    except WebSocketDisconnect:\n    #        await self.streamlit_manager.ws_manager.disconnect(session_id, app_id)\n\n    async def resolve_session_token(self, request: Request) -&gt; str | None:\n        \"\"\"\n        Extract and validate session token from request\n        \"\"\"\n        token = request.headers.get('Authorization', '').replace('Bearer ', '')\n        if not token:\n            token = request.query_params.get('token')\n\n        if token:\n            try:\n                jwt.decode(token, self.token_secret, algorithms=[\"HS256\"])\n                return token\n            except jwt.InvalidTokenError:\n                return None\n        return None\n\n    async def dispatch(self, request: Request, call_next) -&gt; Response:\n        # Handle API routes with session token resolution\n        if request.url.path.startswith(\"/api/\"):\n            session_token = await self.resolve_session_token(request)\n            if session_token:\n                # Inject session data into request state\n                request.state.session_token = session_token\n                request.state.api_helper = self.api_helper\n\n        # Handle Streamlit routes\n        elif request.url.path.startswith(\"/apps/\"):\n            app_name = request.url.path.split(\"/\")[-1]\n            app_path = os.path.join(self.streamlit_apps_dir, f\"{app_name}.py\")\n\n            # Verify session is valid\n            if 'public' not in app_name and not request.session.get(\"valid\", False):\n                return JSONResponse(\n                    status_code=401,\n                    content={\"message\": \"Invalid session\"}\n                )\n\n            if not os.path.exists(app_path):\n                return JSONResponse(\n                    status_code=401,\n                    content={\"message\": \"no app found\"}\n                )\n\n            streamlit_token = self.create_streamlit_token(request.session, app_name)\n            port = await self.streamlit_manager.start_app(app_path, request.session.get(\"ID\")+app_name)\n            streamlit_url = f\"http://{host}:{port}?token={streamlit_token}\"\n            return RedirectResponse(url=streamlit_url)\n\n        resposee = await call_next(request)\n        return resposee\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FastApi.fast_lit.BidirectionalStreamlitAppManager.resolve_session_token","title":"<code>resolve_session_token(request)</code>  <code>async</code>","text":"<p>Extract and validate session token from request</p> Source code in <code>toolboxv2/mods/FastApi/fast_lit.py</code> <pre><code>async def resolve_session_token(self, request: Request) -&gt; str | None:\n    \"\"\"\n    Extract and validate session token from request\n    \"\"\"\n    token = request.headers.get('Authorization', '').replace('Bearer ', '')\n    if not token:\n        token = request.query_params.get('token')\n\n    if token:\n        try:\n            jwt.decode(token, self.token_secret, algorithms=[\"HS256\"])\n            return token\n        except jwt.InvalidTokenError:\n            return None\n    return None\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FastApi.fast_lit.inject_custom_css","title":"<code>inject_custom_css(css_file_path='./web/assets/styles.css')</code>","text":"<p>Liest eine CSS-Datei ein und injiziert sie in die Streamlit-App.</p> Source code in <code>toolboxv2/mods/FastApi/fast_lit.py</code> <pre><code>def inject_custom_css(css_file_path=\"./web/assets/styles.css\"):\n    \"\"\"\n    Liest eine CSS-Datei ein und injiziert sie in die Streamlit-App.\n    \"\"\"\n    import streamlit as st\n    try:\n        with open(css_file_path) as f:\n            css_content = f.read()\n\n        # CSS in einen &lt;style&gt;-Tag einbetten\n        css_injection = f\"&lt;style&gt;{css_content}&lt;/style&gt;\"\n\n        # CSS in Streamlit injizieren\n        st.markdown(css_injection, unsafe_allow_html=True)\n    except Exception as e:\n        st.error(f\"Fehler beim Laden des CSS: {e}\")\n\n    st.markdown(\"\"\"\n        &lt;style&gt;\n            .reportview-container {\n                margin-top: -2em;\n            }\n            #MainMenu {visibility: hidden;}\n            .stDeployButton {display:none;}\n            footer {visibility: hidden;}\n            #stDecoration {display:none;}\n        &lt;/style&gt;\n    \"\"\", unsafe_allow_html=True)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FastApi.fast_lit.make_api_request","title":"<code>make_api_request(endpoint, method='GET', data=None)</code>  <code>async</code>","text":"<p>Helper function for making API requests from Streamlit apps</p> Source code in <code>toolboxv2/mods/FastApi/fast_lit.py</code> <pre><code>async def make_api_request(endpoint: str, method: str = \"GET\", data: dict | None = None):\n    \"\"\"Helper function for making API requests from Streamlit apps\"\"\"\n    import streamlit as st\n\n    if not hasattr(st.session_state, 'token'):\n        st.error(\"No valid session token found\")\n        st.stop()\n\n    headers = {\n        'Authorization': f'Bearer {st.session_state.token}',\n        'Content-Type': 'application/json'\n    }\n\n    try:\n        api_helper = APIRequestHelper(os.getenv(\"TOKEN_SECRET\", \"your-secret-key\"))\n        response = await api_helper.make_api_request(\n            endpoint=endpoint,\n            method=method,\n            data=data,\n            headers=headers,\n            session_token=st.session_state.token\n        )\n        return response\n    except Exception as e:\n        st.error(f\"API request failed: {str(e)}\")\n        return None\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FastApi.fast_nice","title":"<code>fast_nice</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.FastApi.fast_nice.NiceGUIManager","title":"<code>NiceGUIManager</code>","text":"Source code in <code>toolboxv2/mods/FastApi/fast_nice.py</code> <pre><code>class NiceGUIManager(metaclass=Singleton):\n    init = False\n    def __init__(self, fastapi_app: FastAPI = None, styles_path: str = \"./web/assets/styles.css\"):\n\n        if fastapi_app is None:\n            return None\n        self.admin_password = os.getenv(\"TB_R_KEY\", \"root@admin\")\n        self.app = fastapi_app\n        self.styles_path = styles_path\n        self.registered_guis: dict[str, dict[str, Any]] = {}\n        self.ws_connections: dict[str, dict[str, WebSocket]] = {}\n        self.mount_path = \"/gui\"\n        self.endpoints: list[UIEndpoint] = []\n\n        self.helper_contex = open(\"./dist/helper.html\", encoding=\"utf-8\").read()\n\n        self.app.add_middleware(BaseHTTPMiddleware, dispatch=self.middleware_dispatch)\n\n        # Add WebSocket endpoint\n        self.app.websocket(\"/ws/{session_id}/{gui_id}\")(self.websocket_endpoint)\n        self._setup_admin_gui()\n        self._setup_endpoints_api()\n\n    def _setup_endpoints_api(self):\n        @self.app.get(\"/api/CloudM/openui\")\n        def get_ui_endpoints(request: Request) -&gt; list[dict]:\n            def _(endpoint):\n                add_true = True\n                if endpoint.only_valid:\n                    add_true = request.session['valid']\n\n                if add_true and endpoint.only_root:\n                    add_true = request.session.get('live_data', {}).get('user_name') == 'root'\n                return add_true\n            return [{\"path\": endpoint.path,\n    \"title\": endpoint.title,\n    \"description\": endpoint.description} for endpoint in self.endpoints if endpoint.show and _(endpoint)]\n\n    def _setup_admin_gui(self):\n        \"\"\"Setup the admin GUI interface\"\"\"\n\n        @ui.page('/admin')\n        def admin_gui(user=None):\n            print(\"admin_gui;\", user)\n            if user is None or user.name != \"root\":\n                return\n\n            with ui.card().style(\"background-color: var(--background-color) !important\").classes('w-full'):\n                ui.label('NiceGUI Manager Admin Interface').classes('text-2xl font-bold mb-4')\n\n                # GUI Management Section\n                with ui.tabs().style(\"background-color: var(--background-color) !important\") as tabs:\n                    ui.tab('Registered GUIs')\n                    ui.tab('Add New GUI')\n                    ui.tab('System Status')\n\n                with ui.tab_panels(tabs, value='Registered GUIs').style(\n                    \"background-color: var(--background-color) !important\"):\n                    with ui.tab_panel('Registered GUIs'):\n                        self._show_registered_guis()\n\n                    with ui.tab_panel('Add New GUI'):\n                        self._show_add_gui_form()\n\n                    with ui.tab_panel('System Status'):\n                        self._show_system_status()\n\n        self.register_gui(\"admin\", admin_gui, \"/admin\", only_root=True)\n\n    def _show_registered_guis(self):\n        \"\"\"Show list of registered GUIs with management options\"\"\"\n        with ui.column().classes('w-full gap-4'):\n            for gui_id, gui_info in self.registered_guis.items():\n                with ui.card().classes('w-full').style(\"background-color: var(--background-color) !important\"):\n                    with ui.row().classes('w-full items-center justify-between').style(\n                        \"background-color: var(--background-color) !important\"):\n                        ui.label(f'GUI ID: {gui_id}').classes('font-bold')\n                        ui.label(f'Path: {gui_info[\"path\"]}')\n\n                        created_at = gui_info['created_at'].strftime('%Y-%m-%d %H:%M:%S')\n                        ui.label(f'Created: {created_at}')\n\n                        with ui.row().classes('gap-2').style(\"background-color: var(--background-color) !important\"):\n                            ui.button('View', on_click=lambda g=gui_info['path']: ui.navigate.to(g))\n                            ui.button('Remove', on_click=lambda g=gui_id: self._handle_gui_removal(g))\n                            ui.button('Restart', on_click=lambda g=gui_id: self._handle_gui_restart(g))\n\n                    # Show connection status\n                    active_connections = sum(\n                        1 for connections in self.ws_connections.values()\n                        if gui_id in connections\n                    )\n                    ui.label(f'Active Connections: {active_connections}')\n\n    def _show_add_gui_form(self):\n        \"\"\"Show form for adding new GUI\"\"\"\n        with ui.card().classes('w-full').style(\"background-color: var(--background-color) !important\"):\n            gui_id = ui.input('GUI ID').classes('w-full')\n            mount_path = ui.input('Mount Path (optional)').classes('w-full')\n\n            # Code editor for GUI setup\n            code_editor = ui.editor(\n                value='def setup_gui():\\n    ui.label(\"New GUI\")\\n',\n            ).classes('w-full h-64')\n\n            def add_new_gui():\n                try:\n                    # Create setup function from code\n                    setup_code = code_editor.value\n                    setup_namespace = {}\n                    exec(setup_code, {'ui': ui}, setup_namespace)\n                    setup_func = setup_namespace['setup_gui']\n\n                    # Register the new GUI\n                    self.register_gui(\n                        gui_id.value,\n                        setup_func,\n                        mount_path.value if mount_path.value else None\n                    )\n\n                    ui.notify('GUI added successfully')\n                    ui.navigate.to('admin')  # Refresh page\n                except Exception as e:\n                    ui.notify(f'Error adding GUI: {str(e)}', color='negative')\n\n            ui.button('Add GUI', on_click=add_new_gui).classes('w-full mt-4')\n\n    def _show_system_status(self):\n        \"\"\"Show system status information\"\"\"\n        with ui.card().classes('w-full').style(\"background-color: var(--background-color) !important\"):\n            ui.label('System Status').classes('text-xl font-bold mb-4')\n\n            # System stats\n            ui.label(f'Total GUIs: {len(self.registered_guis)}')\n            ui.label(f'Total WebSocket Connections: {sum(len(conns) for conns in self.ws_connections.values())}')\n\n            # Memory usage\n            import psutil\n            process = psutil.Process()\n            memory_usage = process.memory_info().rss / 1024 / 1024  # MB\n            ui.label(f'Memory Usage: {memory_usage:.2f} MB')\n\n            # Add refresh button\n            ui.button('Refresh Stats', on_click=lambda: ui.navigate.to('/admin'))\n\n    def _handle_gui_removal(self, gui_id: str):\n        \"\"\"Handle GUI removal with confirmation\"\"\"\n\n        def confirm_remove():\n            if self.remove_gui(gui_id):\n                ui.notify(f'GUI {gui_id} removed successfully')\n                ui.navigate.to('/admin')  # Refresh page\n            else:\n                ui.notify('Error removing GUI', color='negative')\n\n        ui.notify('Are you sure?',\n                  actions=[{'label': 'Yes', 'on_click': confirm_remove},\n                           {'label': 'No'}])\n\n    def _handle_gui_restart(self, gui_id: str):\n        \"\"\"Handle GUI restart\"\"\"\n        try:\n            if gui_id in self.registered_guis:\n                gui_info = self.registered_guis[gui_id]\n                # Re-register the GUI with the same setup\n                self.register_gui(gui_id, gui_info['setup'], gui_info['path'])\n                ui.notify(f'GUI {gui_id} restarted successfully')\n            else:\n                ui.notify('GUI not found', color='negative')\n        except Exception as e:\n            ui.notify(f'Error restarting GUI: {str(e)}', color='negative')\n\n    def _load_styles(self) -&gt; str:\n        \"\"\"Load custom styles from CSS file\"\"\"\n        try:\n            with open(self.styles_path) as f:\n                return f.read()\n        except Exception as e:\n            print(f\"Error loading styles: {e}\")\n            return \"\"\n\n    def register_gui(self, gui_id: str, setup_func: Callable, mount_path: str | None = None, additional: str | None = None, title: str | None = None , description: str | None = None, **kwargs) -&gt; None:\n        \"\"\"Register a new NiceGUI application\"\"\"\n        path = mount_path or f\"/{gui_id}\"\n        self.endpoints.append(UIEndpoint(path=self.mount_path+path, title=title if title is not None else path.replace('/', '') , description=description if description is not None else '', **kwargs))\n        if additional is None:\n            additional = \"\"\n\n        def has_parameters(func, *params):\n            \"\"\"\n            \u00dcberpr\u00fcft, ob die Funktion bestimmte Parameter hat.\n\n            :param func: Die zu analysierende Funktion.\n            :param params: Eine Liste der zu suchenden Parameter.\n            :return: Ein Dictionary mit den Parametern und einem booleschen Wert.\n            \"\"\"\n            signature = inspect.signature(func)\n            func_params = signature.parameters.keys()\n            return {param: param in func_params for param in params}\n\n        async def request_to_request_session(request):\n            jk = request.json()\n            if asyncio.iscoroutine(jk):\n                with contextlib.suppress(Exception):\n                    jk = await jk\n            def js():\n                return jk\n            return RequestSession(\n                session=request.session,\n                body=request.body,\n                json=js,\n                row=request,\n            )\n\n        get_app()\n\n        @ui.page(path)\n        async def wrapped_gui(request: Request):\n            # Inject custom styles\n            ui.add_body_html(self.helper_contex + additional)\n            # ui.switch('Dark').bind_value(ui, 'dark_mode')\n            # ui.add_css(\"q-card {background-color: var(--background-color)} !important\")\n            # ui.add_body_html('&lt;script src=\"../index.js\" type=\"module\" defer&gt;&lt;/script&gt;')\n\n            # Initialize the GUI\n            params_ = {}\n            params = has_parameters(setup_func, 'request', 'user', 'session', 'id', 'sid')\n\n            if params.get('request'):\n                params_['request'] = await request_to_request_session(request)\n            if params.get('user'):\n                params_['user'] = await get_user_from_request(get_app(), request)\n            if params.get('session'):\n                params_['session'] = request.session\n            if params.get('spec'):\n                params_['spec'] = get_spec(request)\n            if params.get('sid'):\n                params_['sid'] = get_s_id(request)\n\n            async def task():\n                if asyncio.iscoroutine(setup_func):\n\n                    # Event Listener f\u00fcr Button hinzuf\u00fcgen\n                    await ui.run_javascript('''\n                            Quasar.Dark.set(\"auto\");\n                            tailwind.config.darkMode = \"media\";\n                        ''')\n\n                    await ui.run_javascript(\"\"\"\n                    document.getElementById('darkModeToggle').addEventListener('click', function () {\n                    const labelToggel = document.getElementById('toggleLabel')\n                    if (labelToggel.innerHTML == `&lt;span class=\"material-symbols-outlined\"&gt;\ndark_mode\n&lt;/span&gt;`){\n                            Quasar.Dark.set(true);\n                            tailwind.config.darkMode = \"class\";\n                            document.body.classList.add(\"dark\");\n                        }else{\n                            Quasar.Dark.set(false);\n                            tailwind.config.darkMode = \"class\"\n                            document.body.classList.remove(\"dark\");\n                        }\n                    });\n                    \"\"\")\n\n                    if not params_:\n                        await setup_func()\n                    else:\n                        await setup_func(**params_)\n                else:\n                    if not params_:\n                        setup_func()\n                    else:\n                        setup_func(**params_)\n\n\n\n\n            await task()\n            # return result\n\n        self.registered_guis[gui_id] = {\n            'path': path,\n            'setup': setup_func,\n            'created_at': datetime.now()\n        }\n\n        print(\"Registered GUI:\", self.registered_guis[gui_id])\n        return True\n\n    def remove_gui(self, gui_id: str) -&gt; bool:\n        \"\"\"Remove a registered GUI application\"\"\"\n        if gui_id in self.registered_guis:\n            # Remove from registry\n            del self.registered_guis[gui_id]\n\n            # Clean up any WebSocket connections\n            for session_id in self.ws_connections:\n                if gui_id in self.ws_connections[session_id]:\n                    del self.ws_connections[session_id][gui_id]\n\n            return True\n        return False\n\n    async def websocket_endpoint(self, websocket: WebSocket, session_id: str, gui_id: str):\n        \"\"\"Handle WebSocket connections for real-time updates\"\"\"\n        await websocket.accept()\n\n        if session_id not in self.ws_connections:\n            self.ws_connections[session_id] = {}\n        self.ws_connections[session_id][gui_id] = websocket\n\n        try:\n            while True:\n                data = await websocket.receive_json()\n                # Handle incoming WebSocket messages\n                await self.handle_ws_message(session_id, gui_id, data)\n        except WebSocketDisconnect:\n            if session_id in self.ws_connections:\n                if gui_id in self.ws_connections[session_id]:\n                    del self.ws_connections[session_id][gui_id]\n\n    async def handle_ws_message(self, session_id: str, gui_id: str, message: dict):\n        \"\"\"Handle incoming WebSocket messages\"\"\"\n        # Implement custom WebSocket message handling\n        if message.get('type') == 'update':\n            # Broadcast updates to all connected clients for this GUI\n            await self.broadcast_to_gui(gui_id, {\n                'type': 'update',\n                'data': message.get('data')\n            })\n\n    async def broadcast_to_gui(self, gui_id: str, message: dict):\n        \"\"\"Broadcast a message to all sessions connected to a specific GUI\"\"\"\n        for session_connections in self.ws_connections.values():\n            if gui_id in session_connections:\n                await session_connections[gui_id].send_json(message)\n\n    async def middleware_dispatch(self, request: Request, call_next) -&gt; Response:\n        \"\"\"Custom middleware for session handling and authentication\"\"\"\n        async def callN():\n            response = await call_next(request)\n            return response\n\n        if not request.url.path.startswith(self.mount_path):\n            return await callN()\n\n        if request.url.path.endswith(\"/favicon.ico\"):\n            return await callN()\n        if \"_nicegui\" in request.url.path and \"static\" in request.url.path:\n            return await callN()\n        if \"_nicegui\" in request.url.path and \"components\" in request.url.path:\n            return await callN()\n        if \"_nicegui\" in request.url.path and \"codehilite\" in request.url.path:\n            return await callN()\n        if \"_nicegui\" in request.url.path and \"libraries\" in request.url.path:\n            return await callN()\n\n        if \"open\" in request.url.path:\n            return await callN()\n\n        # Verify session if needed\n        if not request.session.get(\"valid\", False):\n            return RedirectResponse(f\"/web/login?next={request.url.path}\")\n\n        response = await call_next(request)\n        return response\n\n    def init_app(self) -&gt; None:\n        \"\"\"Initialize the FastAPI application with NiceGUI integration\"\"\"\n        self.init = True\n        ui.run_with(\n            self.app,\n            mount_path=self.mount_path,\n            favicon=os.getenv(\"FAVI\"), # \"/root/Toolboxv2/toolboxv2/favicon.ico\"\n            show_welcome_message=False,\n            # prod_js=False,\n        )\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FastApi.fast_nice.NiceGUIManager.broadcast_to_gui","title":"<code>broadcast_to_gui(gui_id, message)</code>  <code>async</code>","text":"<p>Broadcast a message to all sessions connected to a specific GUI</p> Source code in <code>toolboxv2/mods/FastApi/fast_nice.py</code> <pre><code>async def broadcast_to_gui(self, gui_id: str, message: dict):\n    \"\"\"Broadcast a message to all sessions connected to a specific GUI\"\"\"\n    for session_connections in self.ws_connections.values():\n        if gui_id in session_connections:\n            await session_connections[gui_id].send_json(message)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FastApi.fast_nice.NiceGUIManager.handle_ws_message","title":"<code>handle_ws_message(session_id, gui_id, message)</code>  <code>async</code>","text":"<p>Handle incoming WebSocket messages</p> Source code in <code>toolboxv2/mods/FastApi/fast_nice.py</code> <pre><code>async def handle_ws_message(self, session_id: str, gui_id: str, message: dict):\n    \"\"\"Handle incoming WebSocket messages\"\"\"\n    # Implement custom WebSocket message handling\n    if message.get('type') == 'update':\n        # Broadcast updates to all connected clients for this GUI\n        await self.broadcast_to_gui(gui_id, {\n            'type': 'update',\n            'data': message.get('data')\n        })\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FastApi.fast_nice.NiceGUIManager.init_app","title":"<code>init_app()</code>","text":"<p>Initialize the FastAPI application with NiceGUI integration</p> Source code in <code>toolboxv2/mods/FastApi/fast_nice.py</code> <pre><code>def init_app(self) -&gt; None:\n    \"\"\"Initialize the FastAPI application with NiceGUI integration\"\"\"\n    self.init = True\n    ui.run_with(\n        self.app,\n        mount_path=self.mount_path,\n        favicon=os.getenv(\"FAVI\"), # \"/root/Toolboxv2/toolboxv2/favicon.ico\"\n        show_welcome_message=False,\n        # prod_js=False,\n    )\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FastApi.fast_nice.NiceGUIManager.middleware_dispatch","title":"<code>middleware_dispatch(request, call_next)</code>  <code>async</code>","text":"<p>Custom middleware for session handling and authentication</p> Source code in <code>toolboxv2/mods/FastApi/fast_nice.py</code> <pre><code>async def middleware_dispatch(self, request: Request, call_next) -&gt; Response:\n    \"\"\"Custom middleware for session handling and authentication\"\"\"\n    async def callN():\n        response = await call_next(request)\n        return response\n\n    if not request.url.path.startswith(self.mount_path):\n        return await callN()\n\n    if request.url.path.endswith(\"/favicon.ico\"):\n        return await callN()\n    if \"_nicegui\" in request.url.path and \"static\" in request.url.path:\n        return await callN()\n    if \"_nicegui\" in request.url.path and \"components\" in request.url.path:\n        return await callN()\n    if \"_nicegui\" in request.url.path and \"codehilite\" in request.url.path:\n        return await callN()\n    if \"_nicegui\" in request.url.path and \"libraries\" in request.url.path:\n        return await callN()\n\n    if \"open\" in request.url.path:\n        return await callN()\n\n    # Verify session if needed\n    if not request.session.get(\"valid\", False):\n        return RedirectResponse(f\"/web/login?next={request.url.path}\")\n\n    response = await call_next(request)\n    return response\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FastApi.fast_nice.NiceGUIManager.register_gui","title":"<code>register_gui(gui_id, setup_func, mount_path=None, additional=None, title=None, description=None, **kwargs)</code>","text":"<p>Register a new NiceGUI application</p> Source code in <code>toolboxv2/mods/FastApi/fast_nice.py</code> <pre><code>    def register_gui(self, gui_id: str, setup_func: Callable, mount_path: str | None = None, additional: str | None = None, title: str | None = None , description: str | None = None, **kwargs) -&gt; None:\n        \"\"\"Register a new NiceGUI application\"\"\"\n        path = mount_path or f\"/{gui_id}\"\n        self.endpoints.append(UIEndpoint(path=self.mount_path+path, title=title if title is not None else path.replace('/', '') , description=description if description is not None else '', **kwargs))\n        if additional is None:\n            additional = \"\"\n\n        def has_parameters(func, *params):\n            \"\"\"\n            \u00dcberpr\u00fcft, ob die Funktion bestimmte Parameter hat.\n\n            :param func: Die zu analysierende Funktion.\n            :param params: Eine Liste der zu suchenden Parameter.\n            :return: Ein Dictionary mit den Parametern und einem booleschen Wert.\n            \"\"\"\n            signature = inspect.signature(func)\n            func_params = signature.parameters.keys()\n            return {param: param in func_params for param in params}\n\n        async def request_to_request_session(request):\n            jk = request.json()\n            if asyncio.iscoroutine(jk):\n                with contextlib.suppress(Exception):\n                    jk = await jk\n            def js():\n                return jk\n            return RequestSession(\n                session=request.session,\n                body=request.body,\n                json=js,\n                row=request,\n            )\n\n        get_app()\n\n        @ui.page(path)\n        async def wrapped_gui(request: Request):\n            # Inject custom styles\n            ui.add_body_html(self.helper_contex + additional)\n            # ui.switch('Dark').bind_value(ui, 'dark_mode')\n            # ui.add_css(\"q-card {background-color: var(--background-color)} !important\")\n            # ui.add_body_html('&lt;script src=\"../index.js\" type=\"module\" defer&gt;&lt;/script&gt;')\n\n            # Initialize the GUI\n            params_ = {}\n            params = has_parameters(setup_func, 'request', 'user', 'session', 'id', 'sid')\n\n            if params.get('request'):\n                params_['request'] = await request_to_request_session(request)\n            if params.get('user'):\n                params_['user'] = await get_user_from_request(get_app(), request)\n            if params.get('session'):\n                params_['session'] = request.session\n            if params.get('spec'):\n                params_['spec'] = get_spec(request)\n            if params.get('sid'):\n                params_['sid'] = get_s_id(request)\n\n            async def task():\n                if asyncio.iscoroutine(setup_func):\n\n                    # Event Listener f\u00fcr Button hinzuf\u00fcgen\n                    await ui.run_javascript('''\n                            Quasar.Dark.set(\"auto\");\n                            tailwind.config.darkMode = \"media\";\n                        ''')\n\n                    await ui.run_javascript(\"\"\"\n                    document.getElementById('darkModeToggle').addEventListener('click', function () {\n                    const labelToggel = document.getElementById('toggleLabel')\n                    if (labelToggel.innerHTML == `&lt;span class=\"material-symbols-outlined\"&gt;\ndark_mode\n&lt;/span&gt;`){\n                            Quasar.Dark.set(true);\n                            tailwind.config.darkMode = \"class\";\n                            document.body.classList.add(\"dark\");\n                        }else{\n                            Quasar.Dark.set(false);\n                            tailwind.config.darkMode = \"class\"\n                            document.body.classList.remove(\"dark\");\n                        }\n                    });\n                    \"\"\")\n\n                    if not params_:\n                        await setup_func()\n                    else:\n                        await setup_func(**params_)\n                else:\n                    if not params_:\n                        setup_func()\n                    else:\n                        setup_func(**params_)\n\n\n\n\n            await task()\n            # return result\n\n        self.registered_guis[gui_id] = {\n            'path': path,\n            'setup': setup_func,\n            'created_at': datetime.now()\n        }\n\n        print(\"Registered GUI:\", self.registered_guis[gui_id])\n        return True\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FastApi.fast_nice.NiceGUIManager.remove_gui","title":"<code>remove_gui(gui_id)</code>","text":"<p>Remove a registered GUI application</p> Source code in <code>toolboxv2/mods/FastApi/fast_nice.py</code> <pre><code>def remove_gui(self, gui_id: str) -&gt; bool:\n    \"\"\"Remove a registered GUI application\"\"\"\n    if gui_id in self.registered_guis:\n        # Remove from registry\n        del self.registered_guis[gui_id]\n\n        # Clean up any WebSocket connections\n        for session_id in self.ws_connections:\n            if gui_id in self.ws_connections[session_id]:\n                del self.ws_connections[session_id][gui_id]\n\n        return True\n    return False\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FastApi.fast_nice.NiceGUIManager.websocket_endpoint","title":"<code>websocket_endpoint(websocket, session_id, gui_id)</code>  <code>async</code>","text":"<p>Handle WebSocket connections for real-time updates</p> Source code in <code>toolboxv2/mods/FastApi/fast_nice.py</code> <pre><code>async def websocket_endpoint(self, websocket: WebSocket, session_id: str, gui_id: str):\n    \"\"\"Handle WebSocket connections for real-time updates\"\"\"\n    await websocket.accept()\n\n    if session_id not in self.ws_connections:\n        self.ws_connections[session_id] = {}\n    self.ws_connections[session_id][gui_id] = websocket\n\n    try:\n        while True:\n            data = await websocket.receive_json()\n            # Handle incoming WebSocket messages\n            await self.handle_ws_message(session_id, gui_id, data)\n    except WebSocketDisconnect:\n        if session_id in self.ws_connections:\n            if gui_id in self.ws_connections[session_id]:\n                del self.ws_connections[session_id][gui_id]\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FastApi.fast_nice.create_nicegui_manager","title":"<code>create_nicegui_manager(app, token_secret=None)</code>","text":"<p>Create and initialize a NiceGUI manager instance</p> Source code in <code>toolboxv2/mods/FastApi/fast_nice.py</code> <pre><code>def create_nicegui_manager(app: FastAPI, token_secret: str | None = None) -&gt; NiceGUIManager:\n    \"\"\"Create and initialize a NiceGUI manager instance\"\"\"\n    manager = NiceGUIManager(app, token_secret)\n    manager.init_app()\n    manager_online[0] = True\n    return manager\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FastApi.manager","title":"<code>manager</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.FastApi.manager.Tools","title":"<code>Tools</code>","text":"<p>               Bases: <code>MainTool</code>, <code>FileHandler</code></p> <p>A production-ready API Manager for running, monitoring, and managing FastAPI instances.</p> This class allows you to <ul> <li>Start API instances (live, development, debug)</li> <li>Stop and restart running APIs</li> <li>Update configuration for APIs</li> <li>Get live diagnostic info about running APIs</li> </ul> Source code in <code>toolboxv2/mods/FastApi/manager.py</code> <pre><code>class Tools(MainTool, FileHandler):\n    \"\"\"\n    A production-ready API Manager for running, monitoring, and managing FastAPI instances.\n\n    This class allows you to:\n      - Start API instances (live, development, debug)\n      - Stop and restart running APIs\n      - Update configuration for APIs\n      - Get live diagnostic info about running APIs\n    \"\"\"\n\n    def __init__(self, app: Any | None = None) -&gt; None:\n        # Running APIs will be stored as a mapping from api_name to subprocess.Popen\n        self.running_apis: dict[str, multiprocessing.Process] = {}\n        self.api_config: dict[str, dict[str, str | int]] = {}\n        self.version: str = VERSION\n        self.name: str = NAME\n        self.logger: logging.Logger = app.logger if app else logging.getLogger(__name__)\n        self.color: str = \"WHITE\"\n        self.keys: dict[str, str] = {\"Apis\": \"api~config\"}\n        # In case app is not passed in, ensure that we have a dummy object with required properties\n\n        # Define available tool commands\n        self.tools: dict[str, Any] = {\n            \"all\": [\n                [\"Version\", \"Shows current Version\"],\n                [\"edit-api\", \"Set default API for name, host and port\"],\n                [\"start-api\", \"Start an API instance\"],\n                [\"stop-api\", \"Stop a running API instance\"],\n                [\"restart-api\", \"Restart an API instance\"],\n                [\"info\", \"Show API configurations and running APIs\"],\n            ],\n            \"name\": \"api_manager\",\n            \"Version\": self.show_version,\n            \"edit-api\": self.conf_api,\n            \"stop-api\": self.stop_api,\n            \"start\": self.start_live,\n            \"startE\": self._start_api,\n            \"startDev\": self.start_dev,\n            \"startDUG\": self.start_debug,\n            \"info\": self.show_running,\n            \"restart-api\": self.restart_api,\n        }\n\n        # Initialize FileHandler with default configuration data\n        default_config = {\n            \"Apis\": {\n                'main': {\n                    \"Name\": 'main',\n                    \"version\": self.version,\n                    \"port\": 5000,\n                    \"host\": '127.0.0.1'\n                }\n            }\n        }\n        FileHandler.__init__(self, \"apis.config\", self.app.id, self.keys, default_config)\n        MainTool.__init__(\n            self,\n            load=self.on_start,\n            v=self.version,\n            tool=self.tools,\n            name=self.name,\n            logs=self.logger,\n            color=self.color,\n            on_exit=self.on_exit,\n        )\n        os.makedirs(\"./.data\", exist_ok=True)\n\n    @staticmethod\n    def _get_pid_file_path(api_name: str) -&gt; str:\n        \"\"\"Get the path to the PID file for an API.\"\"\"\n        return os.path.join(\"./.data\", f\"api_pid_{api_name}\")\n\n\n    def show_version(self) -&gt; str:\n        \"\"\"Display and return the current version.\"\"\"\n        self.logger.info(\"Version: %s\", self.version)\n        return self.version\n\n    def info(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Return diagnostic information about API configurations and currently running APIs.\n        \"\"\"\n        config_info = {name: cfg for name, cfg in self.api_config.items()}\n        running_info = {name: proc.pid for name, proc in self.running_apis.items() if proc.is_alive()}\n        self.logger.info(\"API Configurations: %s\", config_info)\n        self.logger.info(\"Running APIs: %s\", running_info)\n        # Optionally, print to console as well\n        for api_name, cfg in config_info.items():\n            print(f\"Configured API - Name: {api_name}, Config: {cfg}\")\n        print(\"Running APIs:\")\n        for api_name, pid in running_info.items():\n            print(f\"API: {api_name}, Process ID: {pid}\")\n        return {\"configurations\": config_info, \"running\": running_info}\n\n    def conf_api(self, api_name: str, host: str = \"localhost\", port: int = 5000) -&gt; None:\n        \"\"\"\n        Update or create an API configuration.\n\n        Args:\n            api_name (str): The name of the API.\n            host (str): The host address (default \"localhost\"). Use \"lh\" for \"127.0.0.1\" or \"0\" for \"0.0.0.0\".\n            port (int): The port number (default 5000; use \"0\" for port 8000).\n        \"\"\"\n        if host.lower() == \"lh\":\n            host = \"127.0.0.1\"\n        if host == \"0\":\n            host = \"0.0.0.0\"\n        if str(port) == \"0\":\n            port = 8000\n\n        self.api_config[api_name] = {\n            \"Name\": api_name,\n            \"version\": self.version,\n            \"port\": int(port),\n            \"host\": host,\n        }\n        self.logger.info(\"Updated API configuration for '%s': %s\", api_name, self.api_config[api_name])\n        print(f\"API configuration updated: {self.api_config[api_name]}\")\n\n    def start_dev(self, api_name: str, *modules: str, **kwargs: Any) -&gt; str | None:\n        \"\"\"\n        Start an API in development mode.\n\n        If additional modules are provided, they are stored in a BlobFile for later use.\n\n        Args:\n            api_name (str): The API name.\n            *modules (str): Additional modules for the API.\n\n        Returns:\n            Optional[str]: Status message.\n        \"\"\"\n        if modules:\n            api_name_dev = f\"{api_name}_D\"\n            with BlobFile(f\"FastApi/{api_name_dev}/dev\", mode='w') as f:\n                f.write_json({'modules': modules})\n            api_name = api_name_dev\n\n        return self._start_api(api_name, live=False, reload=False, test_override=False, host=\"localhost\")\n\n    def start_live(self, api_name: str) -&gt; str | None:\n        \"\"\"\n        Start an API in live mode.\n        \"\"\"\n        return self._start_api(api_name, live=True, reload=False, test_override=False)\n\n    def start_debug(self, api_name: str) -&gt; str | None:\n        \"\"\"\n        Start an API in debug mode.\n        \"\"\"\n        return self._start_api(api_name, live=False, reload=True, test_override=True, host=\"localhost\")\n\n    def _start_api(\n        self,\n        api_name: str,\n        live: bool = False,\n        reload: bool = False,\n        test_override: bool = False,\n        host: str = \"localhost\"\n    ) -&gt; str | None:\n        \"\"\"\n        Start an API process with the given configuration.\n\n        Args:\n            api_name (str): The API name.\n            live (bool): Whether to run in live mode.\n            reload (bool): Whether to enable auto-reload.\n            test_override (bool): If True, allow start even if running in a test environment.\n            host (str): Host to bind the API on.\n\n        Returns:\n            Optional[str]: A status message or error message.\n        \"\"\"\n        # Prevent starting an API if in test mode unless explicitly overridden.\n        if 'test' in self.app.id and not test_override:\n            msg = \"No API allowed in test mode\"\n            self.logger.warning(msg)\n            return msg\n\n        if not api_name:\n            self.logger.error(\"No API name provided.\")\n            return None\n\n        # Check if API is already running.\n        if api_name in self.running_apis and self.running_apis[api_name].is_alive():\n            msg = f\"API '{api_name}' is already running.\"\n            self.logger.info(msg)\n            return msg\n\n        # Ensure that live and reload are not both enabled.\n        if live and reload:\n            raise ValueError(\"Live mode and reload mode cannot be enabled simultaneously.\")\n\n        # If configuration does not exist, add it automatically.\n        if api_name not in self.api_config:\n            self.api_config[api_name] = {\n                \"Name\": api_name,\n                \"version\": self.version,\n                \"port\": self.app.args_sto.port,\n                \"host\": host if host and isinstance(host, str) else \"localhost\",\n            }\n            if live:\n                self.api_config[api_name]['host'] = \"0.0.0.0\"\n            self.logger.info(\"Auto-added API configuration for '%s': %s\", api_name, self.api_config[api_name])\n\n        # For live mode, always bind to all interfaces.\n        if live:\n            self.api_config[api_name]['host'] = \"0.0.0.0\"\n\n        api_data = self.api_config[api_name]\n\n        # Check for required frontend dependencies.\n        node_modules_path = os.path.join(self.app.start_dir, \"web\", \"node_modules\")\n        if not os.path.exists(node_modules_path):\n            self.logger.info(\"Node modules folder not found. Installing dependencies in '%s'\", node_modules_path)\n            os.system(\"npm install --prefix ./web ./web\")\n\n        # Build the uvicorn command.\n        cmd_parts: list[str] = [\n            # sys.executable,\n            # \"-m\",\n            \"uvicorn\",\n            \"toolboxv2.mods.FastApi.fast_api_main:app\",\n            f\"--host {api_data['host']}\",\n            f\"--port {api_data['port']}\",\n            f\"--header data:{self.app.debug}:{api_name}\"\n        ]\n        if reload:\n            # Reload directories can be adjusted as needed.\n            cmd_parts.append(\"--reload\")\n            cmd_parts.append(\"--reload-dir ./utils\")\n            cmd_parts.append(\"--reload-dir ./mods/FastApi\")\n        command: str = \" \".join(cmd_parts)\n        self.logger.info(\"Starting API '%s' with command: %s\", api_name, command)\n\n        print(command)\n\n        # Print QR codes for local and public IPs for convenience.\n        protocol = \"http\"  # Adjust if SSL is configured\n        local_url = f\"{protocol}://{get_local_ip()}:{api_data['port']}\"\n        public_url = f\"{protocol}://{get_public_ip()}:{api_data['port']}\"\n        print_qrcode_to_console(local_url)\n        print_qrcode_to_console(public_url)\n\n        try:\n\n            process = multiprocessing.Process(\n                target=os.system,\n                args=(command,),\n                # daemon=True\n            )\n            process.start()\n\n            # Store the process\n            self.running_apis[api_name] = process\n\n            # Save PID to file\n            with open(self._get_pid_file_path(api_name), \"w\") as f:\n                f.write(str(process.pid))\n\n            # Store process info in file handler\n            self.add_to_save_file_handler(\n                key=f\"pr{api_name}\",\n                value=json.dumps({\n                    \"pid\": process.pid,\n                    \"start_time\": datetime.now().isoformat(),\n                    \"host\": api_data['host'],\n                    \"port\": api_data['port']\n                })\n            )\n\n            msg = f\"Starting API '{api_name}' at {api_data['host']}:{api_data['port']} (PID: {process.pid})\"\n            self.logger.info(msg)\n            return msg\n        except Exception as e:\n            self.logger.exception(\"Failed to start API '%s': %s\", api_name, e)\n            return f\"Failed to start API '{api_name}': {e}\"\n\n    async def stop_api(self, api_name: str, delete: bool = True) -&gt; str:\n        \"\"\"\n        Stop a running API and clean up resources.\n        \"\"\"\n        if api_name not in self.api_config:\n            msg = f\"API with the name '{api_name}' is not configured.\"\n            self.logger.warning(msg)\n            return msg\n\n        pid_file = self._get_pid_file_path(api_name)\n        if not os.path.exists(pid_file):\n            self.logger.warning(\"No pid file found for API '%s'\", api_name)\n            return f\"No pid file found for API '{api_name}'.\"\n\n        try:\n            # Read PID from file\n            with open(pid_file) as f:\n                api_pid = int(f.read().strip())\n\n            # Try graceful shutdown first\n            if 'core' in self.app.id:\n                if not await self.app.session.login():\n                    self.logger.warning(\"Could not login with username '%s'\", self.app.get_username())\n                try:\n                    response = await self.app.session.fetch(f\"/api/exit/{api_pid}\", method=\"POST\")\n                    self.logger.info(\"Exit response for API '%s': %s\", api_name, response)\n                except Exception as e:\n                    self.logger.warning(\"Failed to stop API gracefully: %s\", e)\n\n            # Force kill if process still exists\n            process = self.running_apis.get(api_name)\n            if process and process.is_alive():\n                process.terminate()\n                process.join(timeout=5)\n                if process.is_alive():\n                    process.kill()\n\n            # Fallback to system commands if needed\n            try:\n                if system() == \"Windows\":\n                    os.system(f\"taskkill /pid {api_pid} /F\")\n                else:\n                    os.kill(api_pid, signal.SIGKILL)\n            except ProcessLookupError:\n                pass  # Process already terminated\n\n            # Cleanup\n            if os.path.exists(pid_file):\n                os.remove(pid_file)\n            if delete and api_name in self.running_apis:\n                del self.running_apis[api_name]\n\n            # Update file handler\n            self.add_to_save_file_handler(\n                key=f\"pr{api_name}\",\n                value=json.dumps({\n                    \"stop_time\": datetime.now().isoformat(),\n                    \"status\": \"stopped\"\n                })\n            )\n            self.save_file_handler()\n\n            msg = f\"Stopped API '{api_name}'.\"\n            self.logger.info(msg)\n            return msg\n\n        except Exception as e:\n            self.logger.exception(\"Error stopping API '%s': %s\", api_name, e)\n            return f\"Error stopping API '{api_name}': {e}\"\n\n    def nf(self, name):\n        if len(name) &gt; 10:\n            return name[:10]\n        elif len(name) &lt; 10:\n            return name + '~' * (len(name)-10)\n        else:\n            return name\n\n    def show_running(self) -&gt; list[str]:\n        \"\"\"\n        Display and return the list of currently running APIs with their status.\n        \"\"\"\n        self.on_start()\n        running_list = []\n        print(self.api_config)\n        for api_name in self.api_config:\n\n            # Get stored process info\n            process_info = self.get_file_handler(f\"pr{api_name}\")\n            print('#',api_name, '#',process_info)\n            if process_info is None:\n                process_info = {}\n            status = {\n                \"name\": api_name,\n                \"online\": api_name in self.running_apis,\n                \"start_time\": process_info.get(\"start_time\", \"offline\"),\n                \"pid\": process_info.get(\"pid\", ''),\n                \"host\": process_info.get(\"host\", ''),\n                \"port\": process_info.get(\"port\", '')\n            }\n            running_list.append(status)\n\n        # Log and print current status\n        self.logger.info(\"APIs: %s\", running_list)\n        print(\"\\nAPIs:\")\n        for api in running_list:\n            print(f\"- {api['name']}: at {api['host']}:{api['port']}\")\n            print(f\"  Started: {api['start_time']}\")\n\n        return [api[\"name\"] for api in running_list]\n\n    async def restart_api(self, api_name: str) -&gt; str:\n        \"\"\"\n        Restart the given API by stopping it and starting it again.\n\n        Args:\n            api_name (str): The name of the API to restart.\n\n        Returns:\n            str: A status message.\n        \"\"\"\n        stop_message = await self.stop_api(api_name)\n        self.logger.info(\"Restart: %s\", stop_message)\n        # Allow some time for the process to fully terminate.\n        time.sleep(4)\n        start_message = self._start_api(api_name)\n        return f\"Restarting API '{api_name}': {start_message}\"\n\n    def on_start(self) -&gt; None:\n        \"\"\"\n        Load API configuration from file when the tool starts.\n        \"\"\"\n        self.load_file_handler()\n        data = self.get_file_handler(self.keys[\"Apis\"])\n        try:\n            if isinstance(data, str):\n                self.api_config = json.loads(data)\n            else:\n                self.api_config = data\n            self.logger.info(\"Loaded API configuration: %s\", self.api_config)\n        except Exception as e:\n            self.logger.exception(\"Error loading API configuration: %s\", e)\n            self.api_config = {}\n\n    async def on_exit(self) -&gt; None:\n        \"\"\"\n        Gracefully stop all running APIs and save configuration upon exit.\n        \"\"\"\n        # Save configuration data.\n        if len(self.api_config) != 0:\n            self.add_to_save_file_handler(self.keys[\"Apis\"], json.dumps(self.api_config))\n        # Attempt to stop all running APIs.\n        # for api_name in list(self.running_apis.keys()):\n        #     await self.stop_api(api_name, delete=False)\n        self.running_apis = {}\n        self.save_file_handler()\n        self.logger.info(\"Exiting API Manager. All running APIs stopped and configuration saved.\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FastApi.manager.Tools.conf_api","title":"<code>conf_api(api_name, host='localhost', port=5000)</code>","text":"<p>Update or create an API configuration.</p> <p>Parameters:</p> Name Type Description Default <code>api_name</code> <code>str</code> <p>The name of the API.</p> required <code>host</code> <code>str</code> <p>The host address (default \"localhost\"). Use \"lh\" for \"127.0.0.1\" or \"0\" for \"0.0.0.0\".</p> <code>'localhost'</code> <code>port</code> <code>int</code> <p>The port number (default 5000; use \"0\" for port 8000).</p> <code>5000</code> Source code in <code>toolboxv2/mods/FastApi/manager.py</code> <pre><code>def conf_api(self, api_name: str, host: str = \"localhost\", port: int = 5000) -&gt; None:\n    \"\"\"\n    Update or create an API configuration.\n\n    Args:\n        api_name (str): The name of the API.\n        host (str): The host address (default \"localhost\"). Use \"lh\" for \"127.0.0.1\" or \"0\" for \"0.0.0.0\".\n        port (int): The port number (default 5000; use \"0\" for port 8000).\n    \"\"\"\n    if host.lower() == \"lh\":\n        host = \"127.0.0.1\"\n    if host == \"0\":\n        host = \"0.0.0.0\"\n    if str(port) == \"0\":\n        port = 8000\n\n    self.api_config[api_name] = {\n        \"Name\": api_name,\n        \"version\": self.version,\n        \"port\": int(port),\n        \"host\": host,\n    }\n    self.logger.info(\"Updated API configuration for '%s': %s\", api_name, self.api_config[api_name])\n    print(f\"API configuration updated: {self.api_config[api_name]}\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FastApi.manager.Tools.info","title":"<code>info()</code>","text":"<p>Return diagnostic information about API configurations and currently running APIs.</p> Source code in <code>toolboxv2/mods/FastApi/manager.py</code> <pre><code>def info(self) -&gt; dict[str, Any]:\n    \"\"\"\n    Return diagnostic information about API configurations and currently running APIs.\n    \"\"\"\n    config_info = {name: cfg for name, cfg in self.api_config.items()}\n    running_info = {name: proc.pid for name, proc in self.running_apis.items() if proc.is_alive()}\n    self.logger.info(\"API Configurations: %s\", config_info)\n    self.logger.info(\"Running APIs: %s\", running_info)\n    # Optionally, print to console as well\n    for api_name, cfg in config_info.items():\n        print(f\"Configured API - Name: {api_name}, Config: {cfg}\")\n    print(\"Running APIs:\")\n    for api_name, pid in running_info.items():\n        print(f\"API: {api_name}, Process ID: {pid}\")\n    return {\"configurations\": config_info, \"running\": running_info}\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FastApi.manager.Tools.on_exit","title":"<code>on_exit()</code>  <code>async</code>","text":"<p>Gracefully stop all running APIs and save configuration upon exit.</p> Source code in <code>toolboxv2/mods/FastApi/manager.py</code> <pre><code>async def on_exit(self) -&gt; None:\n    \"\"\"\n    Gracefully stop all running APIs and save configuration upon exit.\n    \"\"\"\n    # Save configuration data.\n    if len(self.api_config) != 0:\n        self.add_to_save_file_handler(self.keys[\"Apis\"], json.dumps(self.api_config))\n    # Attempt to stop all running APIs.\n    # for api_name in list(self.running_apis.keys()):\n    #     await self.stop_api(api_name, delete=False)\n    self.running_apis = {}\n    self.save_file_handler()\n    self.logger.info(\"Exiting API Manager. All running APIs stopped and configuration saved.\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FastApi.manager.Tools.on_start","title":"<code>on_start()</code>","text":"<p>Load API configuration from file when the tool starts.</p> Source code in <code>toolboxv2/mods/FastApi/manager.py</code> <pre><code>def on_start(self) -&gt; None:\n    \"\"\"\n    Load API configuration from file when the tool starts.\n    \"\"\"\n    self.load_file_handler()\n    data = self.get_file_handler(self.keys[\"Apis\"])\n    try:\n        if isinstance(data, str):\n            self.api_config = json.loads(data)\n        else:\n            self.api_config = data\n        self.logger.info(\"Loaded API configuration: %s\", self.api_config)\n    except Exception as e:\n        self.logger.exception(\"Error loading API configuration: %s\", e)\n        self.api_config = {}\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FastApi.manager.Tools.restart_api","title":"<code>restart_api(api_name)</code>  <code>async</code>","text":"<p>Restart the given API by stopping it and starting it again.</p> <p>Parameters:</p> Name Type Description Default <code>api_name</code> <code>str</code> <p>The name of the API to restart.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>A status message.</p> Source code in <code>toolboxv2/mods/FastApi/manager.py</code> <pre><code>async def restart_api(self, api_name: str) -&gt; str:\n    \"\"\"\n    Restart the given API by stopping it and starting it again.\n\n    Args:\n        api_name (str): The name of the API to restart.\n\n    Returns:\n        str: A status message.\n    \"\"\"\n    stop_message = await self.stop_api(api_name)\n    self.logger.info(\"Restart: %s\", stop_message)\n    # Allow some time for the process to fully terminate.\n    time.sleep(4)\n    start_message = self._start_api(api_name)\n    return f\"Restarting API '{api_name}': {start_message}\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FastApi.manager.Tools.show_running","title":"<code>show_running()</code>","text":"<p>Display and return the list of currently running APIs with their status.</p> Source code in <code>toolboxv2/mods/FastApi/manager.py</code> <pre><code>def show_running(self) -&gt; list[str]:\n    \"\"\"\n    Display and return the list of currently running APIs with their status.\n    \"\"\"\n    self.on_start()\n    running_list = []\n    print(self.api_config)\n    for api_name in self.api_config:\n\n        # Get stored process info\n        process_info = self.get_file_handler(f\"pr{api_name}\")\n        print('#',api_name, '#',process_info)\n        if process_info is None:\n            process_info = {}\n        status = {\n            \"name\": api_name,\n            \"online\": api_name in self.running_apis,\n            \"start_time\": process_info.get(\"start_time\", \"offline\"),\n            \"pid\": process_info.get(\"pid\", ''),\n            \"host\": process_info.get(\"host\", ''),\n            \"port\": process_info.get(\"port\", '')\n        }\n        running_list.append(status)\n\n    # Log and print current status\n    self.logger.info(\"APIs: %s\", running_list)\n    print(\"\\nAPIs:\")\n    for api in running_list:\n        print(f\"- {api['name']}: at {api['host']}:{api['port']}\")\n        print(f\"  Started: {api['start_time']}\")\n\n    return [api[\"name\"] for api in running_list]\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FastApi.manager.Tools.show_version","title":"<code>show_version()</code>","text":"<p>Display and return the current version.</p> Source code in <code>toolboxv2/mods/FastApi/manager.py</code> <pre><code>def show_version(self) -&gt; str:\n    \"\"\"Display and return the current version.\"\"\"\n    self.logger.info(\"Version: %s\", self.version)\n    return self.version\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FastApi.manager.Tools.start_debug","title":"<code>start_debug(api_name)</code>","text":"<p>Start an API in debug mode.</p> Source code in <code>toolboxv2/mods/FastApi/manager.py</code> <pre><code>def start_debug(self, api_name: str) -&gt; str | None:\n    \"\"\"\n    Start an API in debug mode.\n    \"\"\"\n    return self._start_api(api_name, live=False, reload=True, test_override=True, host=\"localhost\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FastApi.manager.Tools.start_dev","title":"<code>start_dev(api_name, *modules, **kwargs)</code>","text":"<p>Start an API in development mode.</p> <p>If additional modules are provided, they are stored in a BlobFile for later use.</p> <p>Parameters:</p> Name Type Description Default <code>api_name</code> <code>str</code> <p>The API name.</p> required <code>*modules</code> <code>str</code> <p>Additional modules for the API.</p> <code>()</code> <p>Returns:</p> Type Description <code>str | None</code> <p>Optional[str]: Status message.</p> Source code in <code>toolboxv2/mods/FastApi/manager.py</code> <pre><code>def start_dev(self, api_name: str, *modules: str, **kwargs: Any) -&gt; str | None:\n    \"\"\"\n    Start an API in development mode.\n\n    If additional modules are provided, they are stored in a BlobFile for later use.\n\n    Args:\n        api_name (str): The API name.\n        *modules (str): Additional modules for the API.\n\n    Returns:\n        Optional[str]: Status message.\n    \"\"\"\n    if modules:\n        api_name_dev = f\"{api_name}_D\"\n        with BlobFile(f\"FastApi/{api_name_dev}/dev\", mode='w') as f:\n            f.write_json({'modules': modules})\n        api_name = api_name_dev\n\n    return self._start_api(api_name, live=False, reload=False, test_override=False, host=\"localhost\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FastApi.manager.Tools.start_live","title":"<code>start_live(api_name)</code>","text":"<p>Start an API in live mode.</p> Source code in <code>toolboxv2/mods/FastApi/manager.py</code> <pre><code>def start_live(self, api_name: str) -&gt; str | None:\n    \"\"\"\n    Start an API in live mode.\n    \"\"\"\n    return self._start_api(api_name, live=True, reload=False, test_override=False)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FastApi.manager.Tools.stop_api","title":"<code>stop_api(api_name, delete=True)</code>  <code>async</code>","text":"<p>Stop a running API and clean up resources.</p> Source code in <code>toolboxv2/mods/FastApi/manager.py</code> <pre><code>async def stop_api(self, api_name: str, delete: bool = True) -&gt; str:\n    \"\"\"\n    Stop a running API and clean up resources.\n    \"\"\"\n    if api_name not in self.api_config:\n        msg = f\"API with the name '{api_name}' is not configured.\"\n        self.logger.warning(msg)\n        return msg\n\n    pid_file = self._get_pid_file_path(api_name)\n    if not os.path.exists(pid_file):\n        self.logger.warning(\"No pid file found for API '%s'\", api_name)\n        return f\"No pid file found for API '{api_name}'.\"\n\n    try:\n        # Read PID from file\n        with open(pid_file) as f:\n            api_pid = int(f.read().strip())\n\n        # Try graceful shutdown first\n        if 'core' in self.app.id:\n            if not await self.app.session.login():\n                self.logger.warning(\"Could not login with username '%s'\", self.app.get_username())\n            try:\n                response = await self.app.session.fetch(f\"/api/exit/{api_pid}\", method=\"POST\")\n                self.logger.info(\"Exit response for API '%s': %s\", api_name, response)\n            except Exception as e:\n                self.logger.warning(\"Failed to stop API gracefully: %s\", e)\n\n        # Force kill if process still exists\n        process = self.running_apis.get(api_name)\n        if process and process.is_alive():\n            process.terminate()\n            process.join(timeout=5)\n            if process.is_alive():\n                process.kill()\n\n        # Fallback to system commands if needed\n        try:\n            if system() == \"Windows\":\n                os.system(f\"taskkill /pid {api_pid} /F\")\n            else:\n                os.kill(api_pid, signal.SIGKILL)\n        except ProcessLookupError:\n            pass  # Process already terminated\n\n        # Cleanup\n        if os.path.exists(pid_file):\n            os.remove(pid_file)\n        if delete and api_name in self.running_apis:\n            del self.running_apis[api_name]\n\n        # Update file handler\n        self.add_to_save_file_handler(\n            key=f\"pr{api_name}\",\n            value=json.dumps({\n                \"stop_time\": datetime.now().isoformat(),\n                \"status\": \"stopped\"\n            })\n        )\n        self.save_file_handler()\n\n        msg = f\"Stopped API '{api_name}'.\"\n        self.logger.info(msg)\n        return msg\n\n    except Exception as e:\n        self.logger.exception(\"Error stopping API '%s': %s\", api_name, e)\n        return f\"Error stopping API '{api_name}': {e}\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FileWidget","title":"<code>FileWidget</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.FileWidget.FileUploadHandler","title":"<code>FileUploadHandler</code>","text":"Source code in <code>toolboxv2/mods/FileWidget.py</code> <pre><code>class FileUploadHandler:\n    def __init__(self, upload_dir: str = 'uploads'):\n        self.upload_dir = Path(upload_dir)\n        self.upload_dir.mkdir(parents=True, exist_ok=True)\n        # self.app = get_app().app # If logger is needed here\n\n    def save_file(self, chunk_info: ChunkInfo, storage: BlobStorage) -&gt; str:\n        \"\"\"Speichert die Datei oder Chunk. Chunks werden lokal gespeichert, dann zu BlobStorage gemerged.\"\"\"\n        final_blob_path = Path(chunk_info.filename).name  # Use only filename part for security within blob storage\n\n        if chunk_info.total_chunks == 1:\n            # Komplette Datei direkt in BlobStorage speichern\n            # print(f\"Saving single part file: {final_blob_path} to BlobStorage directly.\") # Debug\n            with BlobFile(final_blob_path, 'w', storage=storage) as bf:\n                bf.write(chunk_info.content)\n        else:\n            # Chunk lokal speichern\n            # Sanitize filename for local path (original chunk_info.filename might contain path parts client-side)\n            safe_base_filename = \"\".join(\n                c if c.isalnum() or c in ('.', '_', '-') else '_' for c in Path(chunk_info.filename).name)\n            chunk_path = self.upload_dir / f\"{safe_base_filename}.part{chunk_info.chunk_index}\"\n            # print(f\"Saving chunk: {chunk_path} locally. Total chunks: {chunk_info.total_chunks}\") # Debug\n\n            with open(chunk_path, 'wb') as f:\n                f.write(chunk_info.content)\n\n            if self._all_chunks_received(safe_base_filename, chunk_info.total_chunks):\n                # print(f\"All chunks received for {safe_base_filename}. Merging to BlobStorage path: {final_blob_path}\") # Debug\n                self._merge_chunks_to_blob(safe_base_filename, chunk_info.total_chunks, final_blob_path, storage)\n                self._cleanup_chunks(safe_base_filename, chunk_info.total_chunks)\n            # else:\n            # print(f\"Still waiting for more chunks for {safe_base_filename}.\") # Debug\n\n        return final_blob_path  # Path within BlobStorage\n\n    def _all_chunks_received(self, safe_base_filename: str, total_chunks: int) -&gt; bool:\n        for i in range(total_chunks):\n            chunk_path = self.upload_dir / f\"{safe_base_filename}.part{i}\"\n            if not chunk_path.exists():\n                # print(f\"Chunk {i} for {safe_base_filename} not found. Path: {chunk_path}\") # Debug\n                return False\n        # print(f\"All {total_chunks} chunks found for {safe_base_filename}.\") # Debug\n        return True\n\n    def _merge_chunks_to_blob(self, safe_base_filename: str, total_chunks: int, final_blob_path: str,\n                              storage: BlobStorage):\n        # print(f\"Merging {total_chunks} chunks for {safe_base_filename} into Blob: {final_blob_path}\") # Debug\n        with BlobFile(final_blob_path, 'w', storage=storage) as outfile:\n            for i in range(total_chunks):\n                chunk_path = self.upload_dir / f\"{safe_base_filename}.part{i}\"\n                # print(f\"Appending chunk {i} ({chunk_path}) to Blob.\") # Debug\n                with open(chunk_path, 'rb') as chunk_file:\n                    outfile.write(chunk_file.read())\n        # print(f\"Finished merging chunks for {safe_base_filename} to Blob: {final_blob_path}\") # Debug\n\n    def _cleanup_chunks(self, safe_base_filename: str, total_chunks: int):\n        # print(f\"Cleaning up {total_chunks} chunks for {safe_base_filename}.\") # Debug\n        for i in range(total_chunks):\n            chunk_path = self.upload_dir / f\"{safe_base_filename}.part{i}\"\n            if chunk_path.exists():\n                # print(f\"Removing chunk: {chunk_path}\") # Debug\n                try:\n                    os.remove(chunk_path)\n                except OSError as e:\n                    # self.app.logger.error(f\"Error removing chunk {chunk_path}: {e}\") # If logger available\n                    print(f\"Error removing chunk {chunk_path}: {e}\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FileWidget.FileUploadHandler.save_file","title":"<code>save_file(chunk_info, storage)</code>","text":"<p>Speichert die Datei oder Chunk. Chunks werden lokal gespeichert, dann zu BlobStorage gemerged.</p> Source code in <code>toolboxv2/mods/FileWidget.py</code> <pre><code>def save_file(self, chunk_info: ChunkInfo, storage: BlobStorage) -&gt; str:\n    \"\"\"Speichert die Datei oder Chunk. Chunks werden lokal gespeichert, dann zu BlobStorage gemerged.\"\"\"\n    final_blob_path = Path(chunk_info.filename).name  # Use only filename part for security within blob storage\n\n    if chunk_info.total_chunks == 1:\n        # Komplette Datei direkt in BlobStorage speichern\n        # print(f\"Saving single part file: {final_blob_path} to BlobStorage directly.\") # Debug\n        with BlobFile(final_blob_path, 'w', storage=storage) as bf:\n            bf.write(chunk_info.content)\n    else:\n        # Chunk lokal speichern\n        # Sanitize filename for local path (original chunk_info.filename might contain path parts client-side)\n        safe_base_filename = \"\".join(\n            c if c.isalnum() or c in ('.', '_', '-') else '_' for c in Path(chunk_info.filename).name)\n        chunk_path = self.upload_dir / f\"{safe_base_filename}.part{chunk_info.chunk_index}\"\n        # print(f\"Saving chunk: {chunk_path} locally. Total chunks: {chunk_info.total_chunks}\") # Debug\n\n        with open(chunk_path, 'wb') as f:\n            f.write(chunk_info.content)\n\n        if self._all_chunks_received(safe_base_filename, chunk_info.total_chunks):\n            # print(f\"All chunks received for {safe_base_filename}. Merging to BlobStorage path: {final_blob_path}\") # Debug\n            self._merge_chunks_to_blob(safe_base_filename, chunk_info.total_chunks, final_blob_path, storage)\n            self._cleanup_chunks(safe_base_filename, chunk_info.total_chunks)\n        # else:\n        # print(f\"Still waiting for more chunks for {safe_base_filename}.\") # Debug\n\n    return final_blob_path  # Path within BlobStorage\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FileWidget.access_shared_file","title":"<code>access_shared_file(self, request, share_id, filename=None, row=None)</code>  <code>async</code>","text":"<p>Accesses a shared file via its share_id. The URL for this would be like /api/FileWidget/shared/{share_id_value} The 'share_id: str' in signature implies ToolBoxV2 extracts it from path.</p> Source code in <code>toolboxv2/mods/FileWidget.py</code> <pre><code>@export(mod_name=MOD_NAME, api=True, version=VERSION, name=\"open_shared\", api_methods=['GET'],\n        request_as_kwarg=True, level=-1, row=True)\nasync def access_shared_file(self, request: RequestData, share_id: str, filename: str = None, row=None) -&gt; Result:  # share_id from query params\n    \"\"\"\n    Accesses a shared file via its share_id.\n    The URL for this would be like /api/FileWidget/shared/{share_id_value}\n    The 'share_id: str' in signature implies ToolBoxV2 extracts it from path.\n    \"\"\"\n    if not share_id:\n        return Result.html(data=\"Share ID is missing in path.\", status=302)\n\n    share_info = self.shares.get(share_id) if self.shares is not None else None\n    if not share_info:\n        return Result.html(data=\"Share link is invalid or has expired.\", status=404)\n\n    owner_uid = share_info[\"owner_uid\"]\n    file_path_in_owner_storage = share_info[\"file_path\"]\n\n    try:\n        # Get BlobStorage for the owner, not the current request's user (if any)\n        owner_storage = await self.get_blob_storage(\n            owner_uid_override=owner_uid)  # Crucially, pass request=None if not needed\n        self.app.logger.info(\n            f\"Accessing shared file via link {share_id}: owner {owner_uid}, path {file_path_in_owner_storage}\")\n        result = await _prepare_file_response(self, owner_storage, file_path_in_owner_storage, row=row is not None)\n        if result.is_error():\n            self.app.logger.error(f\"Error preparing shared file response for {share_id}: {result.info.help_text}\")\n            return Result.html(data=f\"Failed to prepare shared file for download. {result.info.help_text} {result.result.data_info}\")\n        return result\n    except ValueError as e:  # From get_blob_storage if owner_uid is invalid for some reason\n        self.app.logger.error(f\"Error getting owner's storage for shared file {share_id} (owner {owner_uid}): {e}\",\n                              exc_info=True)\n        return Result.html(data=\"Could not access owner's storage for shared file.\")\n    except Exception as e:\n        self.app.logger.error(\n            f\"Error accessing shared file {share_id} (owner {owner_uid}, path {file_path_in_owner_storage}): {e}\",\n            exc_info=True)\n        return Result.html(data=\"Could not retrieve shared file.\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FileWidget.get_main_ui","title":"<code>get_main_ui(self)</code>  <code>async</code>","text":"<p>Serves the main HTML UI for the FileWidget.</p> Source code in <code>toolboxv2/mods/FileWidget.py</code> <pre><code>@export(mod_name=MOD_NAME, api=True, version=VERSION, name=\"ui\", api_methods=['GET'])\nasync def get_main_ui(self) -&gt; Result:\n    \"\"\"Serves the main HTML UI for the FileWidget.\"\"\"\n    html_content = get_template_content()\n    return Result.html(data=html_content)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.FileWidget.handle_upload","title":"<code>handle_upload(self, request, form_data=None)</code>  <code>async</code>","text":"<p>Handles file uploads. Expects chunked data via form_data kwarg from Rust server. 'form_data' structure (from Rust's parsing of multipart) after client sends FormData with fields: 'file' (the blob), 'fileName', 'chunkIndex', 'totalChunks'.</p> <p>Expected <code>form_data</code> in this Python function: {     \"file\": {  // This 'file' key is the NAME of the form field that held the file blob         \"filename\": \"original_file_name_for_this_chunk.txt\", // from Content-Disposition of the 'file' field part         \"content_type\": \"mime/type_of_chunk\",         \"content_base64\": \"BASE64_ENCODED_CHUNK_CONTENT\"     },     \"fileName\": \"overall_final_filename.txt\", // From a separate form field named 'fileName'     \"chunkIndex\": \"0\",                        // From a separate form field named 'chunkIndex'     \"totalChunks\": \"5\"                        // From a separate form field named 'totalChunks' }</p> Source code in <code>toolboxv2/mods/FileWidget.py</code> <pre><code>@export(mod_name=MOD_NAME, api=True, version=VERSION, name=\"upload\", api_methods=['POST'], request_as_kwarg=True)\nasync def handle_upload(self, request: RequestData, form_data: dict[str, Any] | None = None) -&gt; Result:\n    \"\"\"\n    Handles file uploads. Expects chunked data via form_data kwarg from Rust server.\n    'form_data' structure (from Rust's parsing of multipart) after client sends FormData with fields:\n    'file' (the blob), 'fileName', 'chunkIndex', 'totalChunks'.\n\n    Expected `form_data` in this Python function:\n    {\n        \"file\": {  // This 'file' key is the NAME of the form field that held the file blob\n            \"filename\": \"original_file_name_for_this_chunk.txt\", // from Content-Disposition of the 'file' field part\n            \"content_type\": \"mime/type_of_chunk\",\n            \"content_base64\": \"BASE64_ENCODED_CHUNK_CONTENT\"\n        },\n        \"fileName\": \"overall_final_filename.txt\", // From a separate form field named 'fileName'\n        \"chunkIndex\": \"0\",                        // From a separate form field named 'chunkIndex'\n        \"totalChunks\": \"5\"                        // From a separate form field named 'totalChunks'\n    }\n    \"\"\"\n    self.app.logger.debug(\n        f\"FileWidget: handle_upload called. Received form_data keys: {list(form_data.keys()) if form_data else 'None'}\"\n    )\n    self.app.logger.debug(f\"FileWidget: handle_upload called. Received form_data: {request.to_dict()}\")\n    # self.app.logger.debug(f\"Full form_data: {form_data}\") # For deeper debugging if needed\n\n    if not form_data:\n        return Result.default_user_error(info=\"No form data received for upload.\", exec_code=400)\n\n    try:\n        storage = await self.get_blob_storage(request)\n\n        # Extract data from form_data (populated by Rust server from multipart)\n        file_field_data = form_data.get('file')  # This is the dict from UploadedFile struct\n        # The 'file_field_data.get('filename')' is the name of the chunk part,\n        # which the JS client sets to be the same as the original file's name.\n        # This is fine for FileUploadHandler.save_file's chunk_info.filename if total_chunks &gt; 1,\n        # as it will be used to create temporary part files like \"original_file_name.txt.part0\".\n\n        overall_filename_from_form = form_data.get('fileName') # This is the target filename for the assembled file.\n        chunk_index_str = form_data.get('chunkIndex')\n        total_chunks_str = form_data.get('totalChunks')\n\n        if not all([\n            file_field_data, isinstance(file_field_data, dict),\n            overall_filename_from_form,\n            chunk_index_str is not None, # Check for presence, not just truthiness (0 is valid)\n            total_chunks_str is not None # Check for presence\n        ]):\n            missing = []\n            if not file_field_data or not isinstance(file_field_data, dict): missing.append(\"'file' object field\")\n            if not overall_filename_from_form: missing.append(\"'fileName' field\")\n            if chunk_index_str is None: missing.append(\"'chunkIndex' field\")\n            if total_chunks_str is None: missing.append(\"'totalChunks' field\")\n\n            self.app.logger.error(\n                f\"Missing critical form data fields for upload: {missing}. Received form_data: {form_data}\")\n            return Result.default_user_error(info=f\"Incomplete upload data. Missing: {', '.join(missing)}\",\n                                             exec_code=400)\n\n        content_base64 = file_field_data.get('content_base64')\n        if not content_base64:\n            return Result.default_user_error(info=\"File content (base64) not found in 'file' field data.\",\n                                             exec_code=400)\n\n        try:\n            content_bytes = base64.b64decode(content_base64)\n        except base64.binascii.Error as b64_error:\n            self.app.logger.error(f\"Base64 decoding failed for upload: {b64_error}\")\n            return Result.default_user_error(info=\"Invalid file content encoding.\", exec_code=400)\n\n        try:\n            chunk_index = int(chunk_index_str)\n            total_chunks = int(total_chunks_str)\n        except ValueError:\n            return Result.default_user_error(info=\"Invalid chunk index or total chunks value. Must be integers.\", exec_code=400)\n\n        # Use the 'overall_filename_from_form' for the ChunkInfo.filename,\n        # as this is the intended final name in blob storage.\n        # FileUploadHandler will use Path(this_name).name to ensure it's just a filename.\n        chunk_info_to_save = ChunkInfo(\n            filename=overall_filename_from_form, # THIS IS THE KEY CHANGE FOR CONSISTENCY\n            chunk_index=chunk_index,\n            total_chunks=total_chunks,\n            content=content_bytes\n        )\n\n        self.app.logger.info(\n            f\"Processing chunk {chunk_index + 1}/{total_chunks} for final file '{overall_filename_from_form}'. \" # Log the intended final name\n            f\"Size: {len(content_bytes)} bytes.\"\n        )\n\n        saved_blob_path = self.upload_handler.save_file(chunk_info_to_save, storage) # saved_blob_path will be Path(overall_filename_from_form).name\n\n        msg = f\"Chunk {chunk_index + 1}/{total_chunks} for '{saved_blob_path}' saved.\"\n        if chunk_info_to_save.chunk_index == chunk_info_to_save.total_chunks - 1:\n            # Check if fully assembled\n            # The 'safe_base_filename' in FileUploadHandler is derived from ChunkInfo.filename,\n            # which we've now set to 'overall_filename_from_form'.\n            # So, this check should work correctly.\n            safe_base_filename_for_check = \"\".join(\n                c if c.isalnum() or c in ('.', '_', '-') else '_' for c in Path(overall_filename_from_form).name)\n\n            # A slight delay might be needed if file system operations are not instantly consistent across threads/processes\n            # For now, assume direct check is okay.\n            # await asyncio.sleep(0.1) # Optional small delay if race conditions are suspected with file system\n\n            if self.upload_handler._all_chunks_received(safe_base_filename_for_check, total_chunks):\n                msg = f\"File '{saved_blob_path}' upload complete and assembled.\"\n                self.app.logger.info(msg)\n            else:\n                msg = f\"Final chunk for '{saved_blob_path}' saved, but assembly check failed or is pending.\"\n                self.app.logger.warning(msg + f\" (Could not verify all chunks for '{safe_base_filename_for_check}' immediately after final one)\")\n\n\n        return Result.ok(data={\"message\": msg, \"path\": saved_blob_path}) # Return the blob-relative path\n\n    except ValueError as e:\n        self.app.logger.error(f\"Upload processing error: {e}\", exc_info=True)\n        return Result.default_user_error(info=f\"Upload error: {str(e)}\",\n                                         exec_code=400 if \"authentication\" in str(e).lower() else 400)\n    except Exception as e:\n        self.app.logger.error(f\"Unexpected error during file upload: {e}\", exc_info=True)\n        return Result.default_internal_error(info=\"An unexpected error occurred during upload.\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.P2PRPCClient","title":"<code>P2PRPCClient</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.P2PRPCClient.P2PRPCClient","title":"<code>P2PRPCClient</code>","text":"Source code in <code>toolboxv2/mods/P2PRPCClient.py</code> <pre><code>class P2PRPCClient:\n    def __init__(self, app: App, host: str, port: int, tb_r_key: str = None):\n        self.app = app\n        self.host = host\n        self.port = port\n        self.reader = None\n        self.writer = None\n        self.futures = {}\n        self.code = Code()\n\n        if tb_r_key is None:\n            tb_r_key = os.getenv(\"TB_R_KEY\")\n            if tb_r_key is None:\n                raise ValueError(\"TB_R_KEY environment variable is not set.\")\n\n        if len(tb_r_key) &lt; 24:\n            raise ValueError(\"TB_R_KEY must be at least 24 characters long for security.\")\n        self.auth_key_part = tb_r_key[:24]\n        self.identification_part = tb_r_key[24:]\n        self.session_key = None\n\n    async def connect(self):\n        \"\"\"Connects to the local tcm instance and performs key exchange.\"\"\"\n        try:\n            self.reader, self.writer = await asyncio.open_connection(self.host, self.port)\n            print(f\"RPC Client: Connected to tcm at {self.host}:{self.port}\")\n\n            # Receive encrypted session key from server\n            len_data = await self.reader.readexactly(4)\n            encrypted_session_key_len = int.from_bytes(len_data, 'big')\n            encrypted_session_key = (await self.reader.readexactly(encrypted_session_key_len)).decode('utf-8')\n\n            # Decrypt session key using auth_key_part\n            self.session_key = self.code.decrypt_symmetric(encrypted_session_key, self.auth_key_part)\n\n            # Send challenge back to server, encrypted with session key\n            challenge = \"CHALLENGE_ACK\"\n            encrypted_challenge = self.code.encrypt_symmetric(challenge, self.session_key)\n            self.writer.write(len(encrypted_challenge).to_bytes(4, 'big'))\n            self.writer.write(encrypted_challenge.encode('utf-8'))\n            await self.writer.drain()\n\n            # Start a background task to listen for responses\n            asyncio.create_task(self.listen_for_responses())\n\n        except ConnectionRefusedError:\n            print(f\"RPC Client: Connection to {self.host}:{self.port} refused. Is the tcm peer running?\")\n            raise\n        except Exception as e:\n            print(f\"RPC Client: Error during connection/key exchange: {e}\")\n            raise\n\n    async def listen_for_responses(self):\n        \"\"\"Listens for incoming responses, decrypts them, and resolves the corresponding future.\"\"\"\n        try:\n            while True:\n                len_data = await self.reader.readexactly(4)\n                msg_len = int.from_bytes(len_data, 'big')\n                encrypted_msg_data = (await self.reader.readexactly(msg_len)).decode('utf-8')\n\n                decrypted_msg_data = self.code.decrypt_symmetric(encrypted_msg_data, self.session_key)\n                response = json.loads(decrypted_msg_data)\n\n                call_id = response.get('call_id')\n                if call_id in self.futures:\n                    future = self.futures.pop(call_id)\n                    future.set_result(response)\n        except asyncio.IncompleteReadError:\n            print(\"RPC Client: Connection closed.\")\n        except Exception as e:\n            print(f\"RPC Client: Error listening for responses: {e}\")\n        finally:\n            # Clean up any pending futures\n            for future in self.futures.values():\n                future.set_exception(ConnectionError(\"Connection lost\"))\n            self.futures.clear()\n\n    async def call(self, module: str, function: str, *args, **kwargs):\n        \"\"\"Makes a remote procedure call.\"\"\"\n        if not self.writer:\n            await self.connect()\n\n        call_id = str(uuid.uuid4())\n        request = {\n            \"type\": \"request\",\n            \"call_id\": call_id,\n            \"module\": module,\n            \"function\": function,\n            \"args\": args,\n            \"kwargs\": kwargs,\n            \"identification_part\": self.identification_part\n        }\n\n        future = asyncio.get_running_loop().create_future()\n        self.futures[call_id] = future\n\n        try:\n            request_str = json.dumps(request)\n            encrypted_request = self.code.encrypt_symmetric(request_str, self.session_key)\n\n            self.writer.write(len(encrypted_request).to_bytes(4, 'big'))\n            self.writer.write(encrypted_request.encode('utf-8'))\n            await self.writer.drain()\n\n            # Wait for the response with a timeout\n            response = await asyncio.wait_for(future, timeout=30.0)\n\n            if response.get('error'):\n                return Result(**response['error'])\n            else:\n                return Result.ok(response.get('result'))\n\n        except TimeoutError:\n            self.futures.pop(call_id, None)\n            return Result.default_internal_error(\"RPC call timed out.\")\n        except Exception as e:\n            self.futures.pop(call_id, None)\n            return Result.default_internal_error(f\"RPC call failed: {e}\")\n\n    async def close(self):\n        \"\"\"Closes the connection.\"\"\"\n        if self.writer:\n            self.writer.close()\n            await self.writer.wait_closed()\n            print(\"RPC Client: Connection closed.\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.P2PRPCClient.P2PRPCClient.call","title":"<code>call(module, function, *args, **kwargs)</code>  <code>async</code>","text":"<p>Makes a remote procedure call.</p> Source code in <code>toolboxv2/mods/P2PRPCClient.py</code> <pre><code>async def call(self, module: str, function: str, *args, **kwargs):\n    \"\"\"Makes a remote procedure call.\"\"\"\n    if not self.writer:\n        await self.connect()\n\n    call_id = str(uuid.uuid4())\n    request = {\n        \"type\": \"request\",\n        \"call_id\": call_id,\n        \"module\": module,\n        \"function\": function,\n        \"args\": args,\n        \"kwargs\": kwargs,\n        \"identification_part\": self.identification_part\n    }\n\n    future = asyncio.get_running_loop().create_future()\n    self.futures[call_id] = future\n\n    try:\n        request_str = json.dumps(request)\n        encrypted_request = self.code.encrypt_symmetric(request_str, self.session_key)\n\n        self.writer.write(len(encrypted_request).to_bytes(4, 'big'))\n        self.writer.write(encrypted_request.encode('utf-8'))\n        await self.writer.drain()\n\n        # Wait for the response with a timeout\n        response = await asyncio.wait_for(future, timeout=30.0)\n\n        if response.get('error'):\n            return Result(**response['error'])\n        else:\n            return Result.ok(response.get('result'))\n\n    except TimeoutError:\n        self.futures.pop(call_id, None)\n        return Result.default_internal_error(\"RPC call timed out.\")\n    except Exception as e:\n        self.futures.pop(call_id, None)\n        return Result.default_internal_error(f\"RPC call failed: {e}\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.P2PRPCClient.P2PRPCClient.close","title":"<code>close()</code>  <code>async</code>","text":"<p>Closes the connection.</p> Source code in <code>toolboxv2/mods/P2PRPCClient.py</code> <pre><code>async def close(self):\n    \"\"\"Closes the connection.\"\"\"\n    if self.writer:\n        self.writer.close()\n        await self.writer.wait_closed()\n        print(\"RPC Client: Connection closed.\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.P2PRPCClient.P2PRPCClient.connect","title":"<code>connect()</code>  <code>async</code>","text":"<p>Connects to the local tcm instance and performs key exchange.</p> Source code in <code>toolboxv2/mods/P2PRPCClient.py</code> <pre><code>async def connect(self):\n    \"\"\"Connects to the local tcm instance and performs key exchange.\"\"\"\n    try:\n        self.reader, self.writer = await asyncio.open_connection(self.host, self.port)\n        print(f\"RPC Client: Connected to tcm at {self.host}:{self.port}\")\n\n        # Receive encrypted session key from server\n        len_data = await self.reader.readexactly(4)\n        encrypted_session_key_len = int.from_bytes(len_data, 'big')\n        encrypted_session_key = (await self.reader.readexactly(encrypted_session_key_len)).decode('utf-8')\n\n        # Decrypt session key using auth_key_part\n        self.session_key = self.code.decrypt_symmetric(encrypted_session_key, self.auth_key_part)\n\n        # Send challenge back to server, encrypted with session key\n        challenge = \"CHALLENGE_ACK\"\n        encrypted_challenge = self.code.encrypt_symmetric(challenge, self.session_key)\n        self.writer.write(len(encrypted_challenge).to_bytes(4, 'big'))\n        self.writer.write(encrypted_challenge.encode('utf-8'))\n        await self.writer.drain()\n\n        # Start a background task to listen for responses\n        asyncio.create_task(self.listen_for_responses())\n\n    except ConnectionRefusedError:\n        print(f\"RPC Client: Connection to {self.host}:{self.port} refused. Is the tcm peer running?\")\n        raise\n    except Exception as e:\n        print(f\"RPC Client: Error during connection/key exchange: {e}\")\n        raise\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.P2PRPCClient.P2PRPCClient.listen_for_responses","title":"<code>listen_for_responses()</code>  <code>async</code>","text":"<p>Listens for incoming responses, decrypts them, and resolves the corresponding future.</p> Source code in <code>toolboxv2/mods/P2PRPCClient.py</code> <pre><code>async def listen_for_responses(self):\n    \"\"\"Listens for incoming responses, decrypts them, and resolves the corresponding future.\"\"\"\n    try:\n        while True:\n            len_data = await self.reader.readexactly(4)\n            msg_len = int.from_bytes(len_data, 'big')\n            encrypted_msg_data = (await self.reader.readexactly(msg_len)).decode('utf-8')\n\n            decrypted_msg_data = self.code.decrypt_symmetric(encrypted_msg_data, self.session_key)\n            response = json.loads(decrypted_msg_data)\n\n            call_id = response.get('call_id')\n            if call_id in self.futures:\n                future = self.futures.pop(call_id)\n                future.set_result(response)\n    except asyncio.IncompleteReadError:\n        print(\"RPC Client: Connection closed.\")\n    except Exception as e:\n        print(f\"RPC Client: Error listening for responses: {e}\")\n    finally:\n        # Clean up any pending futures\n        for future in self.futures.values():\n            future.set_exception(ConnectionError(\"Connection lost\"))\n        self.futures.clear()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.P2PRPCClient.test_rpc_client","title":"<code>test_rpc_client(app, host='127.0.0.1', port=8000, tb_r_key=None)</code>  <code>async</code>","text":"<p>An example of how to use the P2P RPC Client.</p> Source code in <code>toolboxv2/mods/P2PRPCClient.py</code> <pre><code>@export(mod_name=Name, name=\"test_rpc_client\", test=False)\nasync def test_rpc_client(app: App, host: str = '127.0.0.1', port: int = 8000, tb_r_key: str = None):\n    \"\"\"An example of how to use the P2P RPC Client.\"\"\"\n    if tb_r_key is None:\n        tb_r_key = os.getenv(\"TB_R_KEY\")\n        if tb_r_key is None:\n            raise ValueError(\"TB_R_KEY environment variable is not set.\")\n\n    client = P2PRPCClient(app, host, port, tb_r_key)\n    try:\n        await client.connect()\n        # Example: Call the 'list-users' function from the 'helper' module\n        result = await client.call(\"helper\", \"list-users\")\n        result.print()\n    finally:\n        await client.close()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.P2PRPCServer","title":"<code>P2PRPCServer</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.P2PRPCServer.P2PRPCServer","title":"<code>P2PRPCServer</code>","text":"Source code in <code>toolboxv2/mods/P2PRPCServer.py</code> <pre><code>class P2PRPCServer:\n    def __init__(self, app: App, host: str, port: int, tb_r_key: str, function_access_config: dict = None):\n        self.app = app\n        self.host = host\n        self.port = port\n        self.server = None\n        self.code = Code()\n\n        if len(tb_r_key) &lt; 24:\n            raise ValueError(\"TB_R_KEY must be at least 24 characters long for security.\")\n        self.auth_key_part = tb_r_key[:24]\n        self.identification_part_server = tb_r_key[24:]\n\n        self.function_access_config = function_access_config if function_access_config is not None else {}\n\n    async def handle_client(self, reader, writer):\n        \"\"\"Callback to handle a single client connection from a tcm instance.\"\"\"\n        addr = writer.get_extra_info('peername')\n        print(f\"RPC Server: New connection from {addr}\")\n\n        session_key = self.code.generate_symmetric_key()\n        encrypted_session_key = self.code.encrypt_symmetric(session_key, self.auth_key_part)\n\n        try:\n            writer.write(len(encrypted_session_key).to_bytes(4, 'big'))\n            writer.write(encrypted_session_key.encode('utf-8'))\n            await writer.drain()\n\n            len_data = await reader.readexactly(4)\n            encrypted_challenge_len = int.from_bytes(len_data, 'big')\n            encrypted_challenge = (await reader.readexactly(encrypted_challenge_len)).decode('utf-8')\n\n            decrypted_challenge = self.code.decrypt_symmetric(encrypted_challenge, session_key)\n            if decrypted_challenge != \"CHALLENGE_ACK\":\n                raise ValueError(\"Invalid challenge received.\")\n\n            print(f\"RPC Server: Authenticated client {addr}\")\n\n            while True:\n                len_data = await reader.readexactly(4)\n                msg_len = int.from_bytes(len_data, 'big')\n\n                encrypted_msg_data = (await reader.readexactly(msg_len)).decode('utf-8')\n\n                decrypted_msg_data = self.code.decrypt_symmetric(encrypted_msg_data, session_key)\n\n                response = await self.process_rpc(decrypted_msg_data, session_key)\n\n                encrypted_response = self.code.encrypt_symmetric(json.dumps(response), session_key)\n\n                writer.write(len(encrypted_response).to_bytes(4, 'big'))\n                writer.write(encrypted_response.encode('utf-8'))\n                await writer.drain()\n\n        except asyncio.IncompleteReadError:\n            print(f\"RPC Server: Connection from {addr} closed.\")\n        except Exception as e:\n            print(f\"RPC Server: Error with client {addr}: {e}\")\n        finally:\n            writer.close()\n            await writer.wait_closed()\n\n    async def process_rpc(self, msg_data: str, session_key: str) -&gt; dict:\n        \"\"\"Processes a single RPC request and returns a response dictionary.\"\"\"\n        try:\n            call = json.loads(msg_data)\n            if call.get('type') != 'request':\n                raise ValueError(\"Invalid message type\")\n        except (json.JSONDecodeError, ValueError) as e:\n            return self.format_error(call.get('call_id'), -32700, f\"Parse error: {e}\")\n\n        call_id = call.get('call_id')\n        module = call.get('module')\n        function = call.get('function')\n        args = call.get('args', [])\n        kwargs = call.get('kwargs', {})\n        client_identification = call.get('identification_part')\n\n        if not self.is_function_allowed(module, function, client_identification):\n            error_msg = f\"Function '{module}.{function}' is not allowed for identification '{client_identification}'.\"\n            print(f\"RPC Server: {error_msg}\")\n            return self.format_error(call_id, -32601, \"Method not found or not allowed\")\n\n        print(f\"RPC Server: Executing '{module}.{function}' for '{client_identification}'\")\n        try:\n            result: Result = await self.app.a_run_any(\n                (module, function),\n                args_=args,\n                kwargs_=kwargs,\n                get_results=True\n            )\n\n            if result.is_error():\n                return self.format_error(call_id, result.info.get('exec_code', -32000), result.info.get('help_text'), result.get())\n            else:\n                return {\n                    \"type\": \"response\",\n                    \"call_id\": call_id,\n                    \"result\": result.get(),\n                    \"error\": None\n                }\n        except Exception as e:\n            print(f\"RPC Server: Exception during execution of '{module}.{function}': {e}\")\n            return self.format_error(call_id, -32603, \"Internal error during execution\", str(e))\n\n    def is_function_allowed(self, module: str, function: str, client_identification: str) -&gt; bool:\n        \"\"\"Checks if a function is allowed for a given client identification.\"\"\"\n        if module not in self.function_access_config:\n            return False\n\n        allowed_functions_for_module = self.function_access_config[module]\n\n        if function not in allowed_functions_for_module:\n            return False\n\n        # If the function is whitelisted, and there's a specific identification part,\n        # you might want to add more granular control here.\n        # For now, if it's in the whitelist, it's allowed for any identified client.\n        # You could extend function_access_config to be:\n        # {\"ModuleName\": {\"function1\": [\"id1\", \"id2\"], \"function2\": [\"id3\"]}}\n        # For simplicity, current implementation assumes if module.function is in whitelist,\n        # it's generally allowed for any authenticated client.\n        return True\n\n    def format_error(self, call_id, code, message, details=None) -&gt; dict:\n        \"\"\"Helper to create a JSON-RPC error response object.\"\"\"\n        return {\n            \"type\": \"response\",\n            \"call_id\": call_id,\n            \"result\": None,\n            \"error\": {\n                \"code\": code,\n                \"message\": message,\n                \"details\": details\n            }\n        }\n\n    async def start(self):\n        \"\"\"Starts the TCP server.\"\"\"\n        self.server = await asyncio.start_server(\n            self.handle_client, self.host, self.port\n        )\n        addr = self.server.sockets[0].getsockname()\n        print(f\"P2P RPC Server listening on {addr}\")\n        async with self.server:\n            await self.server.serve_forever()\n\n    def stop(self):\n        \"\"\"Stops the TCP server.\"\"\"\n        if self.server:\n            self.server.close()\n            print(\"P2P RPC Server stopped.\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.P2PRPCServer.P2PRPCServer.format_error","title":"<code>format_error(call_id, code, message, details=None)</code>","text":"<p>Helper to create a JSON-RPC error response object.</p> Source code in <code>toolboxv2/mods/P2PRPCServer.py</code> <pre><code>def format_error(self, call_id, code, message, details=None) -&gt; dict:\n    \"\"\"Helper to create a JSON-RPC error response object.\"\"\"\n    return {\n        \"type\": \"response\",\n        \"call_id\": call_id,\n        \"result\": None,\n        \"error\": {\n            \"code\": code,\n            \"message\": message,\n            \"details\": details\n        }\n    }\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.P2PRPCServer.P2PRPCServer.handle_client","title":"<code>handle_client(reader, writer)</code>  <code>async</code>","text":"<p>Callback to handle a single client connection from a tcm instance.</p> Source code in <code>toolboxv2/mods/P2PRPCServer.py</code> <pre><code>async def handle_client(self, reader, writer):\n    \"\"\"Callback to handle a single client connection from a tcm instance.\"\"\"\n    addr = writer.get_extra_info('peername')\n    print(f\"RPC Server: New connection from {addr}\")\n\n    session_key = self.code.generate_symmetric_key()\n    encrypted_session_key = self.code.encrypt_symmetric(session_key, self.auth_key_part)\n\n    try:\n        writer.write(len(encrypted_session_key).to_bytes(4, 'big'))\n        writer.write(encrypted_session_key.encode('utf-8'))\n        await writer.drain()\n\n        len_data = await reader.readexactly(4)\n        encrypted_challenge_len = int.from_bytes(len_data, 'big')\n        encrypted_challenge = (await reader.readexactly(encrypted_challenge_len)).decode('utf-8')\n\n        decrypted_challenge = self.code.decrypt_symmetric(encrypted_challenge, session_key)\n        if decrypted_challenge != \"CHALLENGE_ACK\":\n            raise ValueError(\"Invalid challenge received.\")\n\n        print(f\"RPC Server: Authenticated client {addr}\")\n\n        while True:\n            len_data = await reader.readexactly(4)\n            msg_len = int.from_bytes(len_data, 'big')\n\n            encrypted_msg_data = (await reader.readexactly(msg_len)).decode('utf-8')\n\n            decrypted_msg_data = self.code.decrypt_symmetric(encrypted_msg_data, session_key)\n\n            response = await self.process_rpc(decrypted_msg_data, session_key)\n\n            encrypted_response = self.code.encrypt_symmetric(json.dumps(response), session_key)\n\n            writer.write(len(encrypted_response).to_bytes(4, 'big'))\n            writer.write(encrypted_response.encode('utf-8'))\n            await writer.drain()\n\n    except asyncio.IncompleteReadError:\n        print(f\"RPC Server: Connection from {addr} closed.\")\n    except Exception as e:\n        print(f\"RPC Server: Error with client {addr}: {e}\")\n    finally:\n        writer.close()\n        await writer.wait_closed()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.P2PRPCServer.P2PRPCServer.is_function_allowed","title":"<code>is_function_allowed(module, function, client_identification)</code>","text":"<p>Checks if a function is allowed for a given client identification.</p> Source code in <code>toolboxv2/mods/P2PRPCServer.py</code> <pre><code>def is_function_allowed(self, module: str, function: str, client_identification: str) -&gt; bool:\n    \"\"\"Checks if a function is allowed for a given client identification.\"\"\"\n    if module not in self.function_access_config:\n        return False\n\n    allowed_functions_for_module = self.function_access_config[module]\n\n    if function not in allowed_functions_for_module:\n        return False\n\n    # If the function is whitelisted, and there's a specific identification part,\n    # you might want to add more granular control here.\n    # For now, if it's in the whitelist, it's allowed for any identified client.\n    # You could extend function_access_config to be:\n    # {\"ModuleName\": {\"function1\": [\"id1\", \"id2\"], \"function2\": [\"id3\"]}}\n    # For simplicity, current implementation assumes if module.function is in whitelist,\n    # it's generally allowed for any authenticated client.\n    return True\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.P2PRPCServer.P2PRPCServer.process_rpc","title":"<code>process_rpc(msg_data, session_key)</code>  <code>async</code>","text":"<p>Processes a single RPC request and returns a response dictionary.</p> Source code in <code>toolboxv2/mods/P2PRPCServer.py</code> <pre><code>async def process_rpc(self, msg_data: str, session_key: str) -&gt; dict:\n    \"\"\"Processes a single RPC request and returns a response dictionary.\"\"\"\n    try:\n        call = json.loads(msg_data)\n        if call.get('type') != 'request':\n            raise ValueError(\"Invalid message type\")\n    except (json.JSONDecodeError, ValueError) as e:\n        return self.format_error(call.get('call_id'), -32700, f\"Parse error: {e}\")\n\n    call_id = call.get('call_id')\n    module = call.get('module')\n    function = call.get('function')\n    args = call.get('args', [])\n    kwargs = call.get('kwargs', {})\n    client_identification = call.get('identification_part')\n\n    if not self.is_function_allowed(module, function, client_identification):\n        error_msg = f\"Function '{module}.{function}' is not allowed for identification '{client_identification}'.\"\n        print(f\"RPC Server: {error_msg}\")\n        return self.format_error(call_id, -32601, \"Method not found or not allowed\")\n\n    print(f\"RPC Server: Executing '{module}.{function}' for '{client_identification}'\")\n    try:\n        result: Result = await self.app.a_run_any(\n            (module, function),\n            args_=args,\n            kwargs_=kwargs,\n            get_results=True\n        )\n\n        if result.is_error():\n            return self.format_error(call_id, result.info.get('exec_code', -32000), result.info.get('help_text'), result.get())\n        else:\n            return {\n                \"type\": \"response\",\n                \"call_id\": call_id,\n                \"result\": result.get(),\n                \"error\": None\n            }\n    except Exception as e:\n        print(f\"RPC Server: Exception during execution of '{module}.{function}': {e}\")\n        return self.format_error(call_id, -32603, \"Internal error during execution\", str(e))\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.P2PRPCServer.P2PRPCServer.start","title":"<code>start()</code>  <code>async</code>","text":"<p>Starts the TCP server.</p> Source code in <code>toolboxv2/mods/P2PRPCServer.py</code> <pre><code>async def start(self):\n    \"\"\"Starts the TCP server.\"\"\"\n    self.server = await asyncio.start_server(\n        self.handle_client, self.host, self.port\n    )\n    addr = self.server.sockets[0].getsockname()\n    print(f\"P2P RPC Server listening on {addr}\")\n    async with self.server:\n        await self.server.serve_forever()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.P2PRPCServer.P2PRPCServer.stop","title":"<code>stop()</code>","text":"<p>Stops the TCP server.</p> Source code in <code>toolboxv2/mods/P2PRPCServer.py</code> <pre><code>def stop(self):\n    \"\"\"Stops the TCP server.\"\"\"\n    if self.server:\n        self.server.close()\n        print(\"P2P RPC Server stopped.\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.P2PRPCServer.start_rpc_server","title":"<code>start_rpc_server(app, host='127.0.0.1', port=8888, tb_r_key=None, function_access_config=None)</code>  <code>async</code>","text":"<p>Starts the P2P RPC server.</p> Source code in <code>toolboxv2/mods/P2PRPCServer.py</code> <pre><code>@export(mod_name=Name, name=\"start_server\", test=False)\nasync def start_rpc_server(app: App, host: str = '127.0.0.1', port: int = 8888, tb_r_key: str = None, function_access_config: dict = None):\n    \"\"\"Starts the P2P RPC server.\"\"\"\n    if tb_r_key is None:\n        tb_r_key = os.getenv(\"TB_R_KEY\")\n        if tb_r_key is None:\n            raise ValueError(\"TB_R_KEY environment variable is not set.\")\n\n    server = P2PRPCServer(app, host, port, tb_r_key, function_access_config)\n    try:\n        await server.start()\n    except KeyboardInterrupt:\n        server.stop()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.POA","title":"<code>POA</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.POA.module","title":"<code>module</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.POA.module.ActionManagerEnhanced","title":"<code>ActionManagerEnhanced</code>","text":"Source code in <code>toolboxv2/mods/POA/module.py</code> <pre><code>class ActionManagerEnhanced:\n    DB_ITEMS_PREFIX = \"donext_items\"\n    DB_HISTORY_PREFIX = \"donext_history\"\n    DB_CURRENT_ITEM_PREFIX = \"donext_current_item\"\n    DB_UNDO_LOG_PREFIX = \"donext_undo_log\"\n    DB_SETTINGS_PREFIX = \"donext_settings\"  # Added for user settings\n\n    def __init__(self, app: App, user_id: str):\n        self.app = app\n        self.user_id = user_id\n        self.db = app.get_mod(\"DB\")\n        self.isaa = app.get_mod(\"isaa\")\n\n        self.settings: UserSettings = UserSettings(user_id=user_id)  # Initialize with defaults\n        self.items: list[ActionItem] = []\n        self.history: list[HistoryEntry] = []\n        self.current_item: ActionItem | None = None\n        self.undo_log: list[UndoLogEntry] = []\n\n        self._load_settings()  # Load settings first as they might affect item loading\n        self._load_data()\n\n    def _get_db_key(self, prefix: str) -&gt; str:\n        return f\"{prefix}_{self.user_id}\"\n\n    def get_user_timezone(self) -&gt; pytz.BaseTzInfo:\n        try:\n            return pytz.timezone(self.settings.timezone)\n        except pytz.UnknownTimeZoneError:\n            return pytz.utc\n\n    def _load_settings(self):\n        settings_key = self._get_db_key(self.DB_SETTINGS_PREFIX)\n        try:\n            settings_data = self.db.get(settings_key)\n            if settings_data.is_data() and settings_data.get():\n                loaded_settings = json.loads(settings_data.get()[0]) if isinstance(settings_data.get(),\n                                                                                   list) else json.loads(\n                    settings_data.get())\n                self.settings = UserSettings.model_validate_json_safe(loaded_settings)\n            else:  # Save default settings if not found\n                self._save_settings()\n        except Exception as e:\n            self.app.logger.error(f\"Error loading settings for user {self.user_id}: {e}. Using defaults.\")\n            self.settings = UserSettings(user_id=self.user_id)  # Fallback to defaults\n            self._save_settings()  # Attempt to save defaults\n\n    def _save_settings(self):\n        try:\n            self.db.set(self._get_db_key(self.DB_SETTINGS_PREFIX), json.dumps(self.settings.model_dump_json_safe()))\n        except Exception as e:\n            self.app.logger.error(f\"Error saving settings for user {self.user_id}: {e}\")\n\n    def update_user_settings(self, settings_data: dict[str, Any]) -&gt; UserSettings:\n        # Ensure user_id is not changed by malicious input\n        current_user_id = self.settings.user_id\n        updated_settings = UserSettings.model_validate(\n            {**self.settings.model_dump(), **settings_data, \"user_id\": current_user_id})\n        self.settings = updated_settings\n        self._save_settings()\n        # Potentially re-process items if timezone change affects interpretations, though this is complex.\n        # For now, new items will use the new timezone. Existing UTC times remain.\n        self.app.logger.info(f\"User {self.user_id} settings updated: Timezone {self.settings.timezone}\")\n        return self.settings\n\n    def _load_data(self):\n        items_key = self._get_db_key(self.DB_ITEMS_PREFIX)\n        history_key = self._get_db_key(self.DB_HISTORY_PREFIX)\n        current_item_key = self._get_db_key(self.DB_CURRENT_ITEM_PREFIX)\n        undo_log_key = self._get_db_key(self.DB_UNDO_LOG_PREFIX)\n        user_tz_str = self.settings.timezone  # For model_validate_json_safe context\n\n        try:\n            items_data = self.db.get(items_key)\n            if items_data.is_data() and items_data.get():\n                loaded_items_raw = json.loads(items_data.get()[0]) if isinstance(items_data.get(),\n                                                                                 list) else json.loads(items_data.get())\n                self.items = [ActionItem.model_validate_json_safe(item_dict, user_timezone_str=user_tz_str) for\n                              item_dict in loaded_items_raw]\n\n            history_data = self.db.get(history_key)\n            if history_data.is_data() and history_data.get():\n                loaded_history_raw = json.loads(history_data.get()[0]) if isinstance(history_data.get(),\n                                                                                     list) else json.loads(\n                    history_data.get())\n                self.history = [HistoryEntry.model_validate_json_safe(entry_dict) for entry_dict in loaded_history_raw]\n\n            current_item_data = self.db.get(current_item_key)\n            if current_item_data.is_data() and current_item_data.get():\n                current_item_dict = json.loads(current_item_data.get()[0]) if isinstance(current_item_data.get(),\n                                                                                         list) else json.loads(\n                    current_item_data.get())\n                if current_item_dict:\n                    self.current_item = ActionItem.model_validate_json_safe(current_item_dict,\n                                                                            user_timezone_str=user_tz_str)\n\n            undo_log_data = self.db.get(undo_log_key)\n            if undo_log_data.is_data() and undo_log_data.get():\n                loaded_undo_raw = json.loads(undo_log_data.get()[0]) if isinstance(undo_log_data.get(),\n                                                                                   list) else json.loads(\n                    undo_log_data.get())\n                self.undo_log = [UndoLogEntry.model_validate_json_safe(entry_dict) for entry_dict in loaded_undo_raw]\n\n        except Exception as e:\n            self.app.logger.error(f\"Error loading data for user {self.user_id}: {e}\")\n            self.items, self.history, self.current_item, self.undo_log = [], [], None, []\n        self._recalculate_next_due_for_all()\n\n    def _save_data(self):\n        try:\n            self.db.set(self._get_db_key(self.DB_ITEMS_PREFIX),\n                        json.dumps([item.model_dump_json_safe() for item in self.items]))\n            self.db.set(self._get_db_key(self.DB_HISTORY_PREFIX),\n                        json.dumps([entry.model_dump_json_safe() for entry in self.history]))\n            self.db.set(self._get_db_key(self.DB_CURRENT_ITEM_PREFIX),\n                        json.dumps(self.current_item.model_dump_json_safe() if self.current_item else None))\n            self.db.set(self._get_db_key(self.DB_UNDO_LOG_PREFIX),\n                        json.dumps([entry.model_dump_json_safe() for entry in self.undo_log]))\n        except Exception as e:\n            self.app.logger.error(f\"Error saving data for user {self.user_id}: {e}\")\n\n    def _add_history_entry(self, item: ActionItem, status_override: ActionStatus | None = None,\n                           notes: str | None = None):\n        entry = HistoryEntry(\n            item_id=item.id, item_title=item.title, item_type=item.item_type,\n            status_changed_to=status_override or item.status,\n            parent_id=item.parent_id, notes=notes\n        )\n        self.history.append(entry)\n\n    def _datetime_to_user_tz(self, dt_utc: datetime | None) -&gt; datetime | None:\n        if not dt_utc: return None\n        if dt_utc.tzinfo is None: dt_utc = pytz.utc.localize(dt_utc)  # Should already be UTC\n        return dt_utc.astimezone(self.get_user_timezone())\n\n    def _datetime_from_user_input_str(self, dt_str: str | None) -&gt; datetime | None:\n        if not dt_str: return None\n        try:\n            dt = isoparse(dt_str)\n            if dt.tzinfo is None or dt.tzinfo.utcoffset(dt) is None:  # Naive\n                return self.get_user_timezone().localize(dt).astimezone(pytz.utc)\n            return dt.astimezone(pytz.utc)  # Aware, convert to UTC\n        except ValueError:\n            self.app.logger.warning(f\"Could not parse datetime string: {dt_str}\")\n            return None\n\n    def _recalculate_next_due(self, item: ActionItem):\n        now_utc = datetime.now(pytz.utc)\n        user_tz = self.get_user_timezone()\n\n        if item.status == ActionStatus.COMPLETED and item.item_type == ItemType.TASK:\n            if item.frequency and item.frequency != Frequency.ONE_TIME:\n                base_time_utc = item.last_completed or now_utc  # last_completed is already UTC\n\n                # If item had a fixed_time, align next_due to that time of day in user's timezone\n                if item.fixed_time:\n                    original_fixed_time_user_tz = item.fixed_time.astimezone(user_tz)\n                    # Start from last_completed (or now if missing) in user's timezone for calculation\n                    base_time_user_tz = base_time_utc.astimezone(user_tz)\n\n                    # Ensure base_time_user_tz is at least original_fixed_time_user_tz for alignment\n                    # but calculations should project from last completion.\n                    # For example, if daily task due 9am was completed at 11am, next one is tomorrow 9am.\n                    # If completed at 8am, next one is today 9am (if fixed_time was today 9am) or tomorrow 9am.\n\n                    # Let's use last_completed as the primary anchor for when the *next* cycle starts.\n                    # The original fixed_time's time component is used for the *time of day* of the next due.\n\n                    current_anchor_user_tz = base_time_user_tz\n\n                    # Calculate next occurrence based on frequency\n                    if item.frequency == Frequency.DAILY:\n                        next_due_user_tz_date = (current_anchor_user_tz + timedelta(days=1)).date()\n                    elif item.frequency == Frequency.WEEKLY:\n                        next_due_user_tz_date = (current_anchor_user_tz + timedelta(weeks=1)).date()\n                    elif item.frequency == Frequency.MONTHLY:  # Simplified\n                        next_due_user_tz_date = (current_anchor_user_tz + timedelta(days=30)).date()\n                    elif item.frequency == Frequency.ANNUALLY:\n                        next_due_user_tz_date = (current_anchor_user_tz + timedelta(days=365)).date()\n                    else:  # Should not happen for recurring\n                        item.next_due = None\n                        return\n\n                    # Combine with original time of day\n                    next_due_user_tz = datetime.combine(next_due_user_tz_date, original_fixed_time_user_tz.time(),\n                                                        tzinfo=user_tz)\n                    item.next_due = next_due_user_tz.astimezone(pytz.utc)\n\n                else:  # No original fixed_time, so recur based on current time of completion\n                    if item.frequency == Frequency.DAILY:\n                        item.next_due = base_time_utc + timedelta(days=1)\n                    elif item.frequency == Frequency.WEEKLY:\n                        item.next_due = base_time_utc + timedelta(weeks=1)\n                    elif item.frequency == Frequency.MONTHLY:\n                        item.next_due = base_time_utc + timedelta(days=30)\n                    elif item.frequency == Frequency.ANNUALLY:\n                        item.next_due = base_time_utc + timedelta(days=365)\n\n                # Advance until future if needed (e.g., completing an overdue recurring task)\n                # This loop must operate on user's local time perception of \"next day\"\n                while item.next_due and item.next_due &lt; now_utc:\n                    next_due_user = item.next_due.astimezone(user_tz)\n                    original_time_comp = next_due_user.time()  # Preserve time of day\n\n                    if item.frequency == Frequency.DAILY:\n                        next_due_user_adv = next_due_user + timedelta(days=1)\n                    elif item.frequency == Frequency.WEEKLY:\n                        next_due_user_adv = next_due_user + timedelta(weeks=1)\n                    # For monthly/annually, simple timedelta might shift day of month. Using replace for date part.\n                    elif item.frequency == Frequency.MONTHLY:\n                        # This simplified logic might need dateutil.relativedelta for accuracy\n                        year, month = (next_due_user.year, next_due_user.month + 1) if next_due_user.month &lt; 12 else (\n                            next_due_user.year + 1, 1)\n                        try:\n                            next_due_user_adv = next_due_user.replace(year=year, month=month)\n                        except ValueError:  # Handle e.g. trying to set Feb 30\n                            import calendar\n                            last_day = calendar.monthrange(year, month)[1]\n                            next_due_user_adv = next_due_user.replace(year=year, month=month, day=last_day)\n\n                    elif item.frequency == Frequency.ANNUALLY:\n                        try:\n                            next_due_user_adv = next_due_user.replace(year=next_due_user.year + 1)\n                        except ValueError:  # Handle leap day if original was Feb 29\n                            next_due_user_adv = next_due_user.replace(year=next_due_user.year + 1,\n                                                                      day=28)  # Or March 1st\n                    else:\n                        break\n\n                    item.next_due = user_tz.localize(\n                        datetime.combine(next_due_user_adv.date(), original_time_comp)).astimezone(pytz.utc)\n\n                item.status = ActionStatus.NOT_STARTED  # Reset for next occurrence\n            else:  # One-time task\n                item.next_due = None\n        elif item.status == ActionStatus.NOT_STARTED and item.fixed_time and not item.next_due:\n            item.next_due = item.fixed_time  # fixed_time is already UTC\n\n        # If task is not completed, not started, and has a next_due in the past, but also a fixed_time in the future\n        # (e.g. recurring task whose current instance was missed, but fixed_time points to a specific time for all instances)\n        # ensure next_due is not before fixed_time if fixed_time is relevant for setting.\n        # This logic is complex. Current setup: fixed_time is the \"template\", next_due is the \"instance\".\n\n    def _recalculate_next_due_for_all(self):\n        for item in self.items:\n            self._recalculate_next_due(item)\n\n    def add_item(self, item_data: dict[str, Any], by_ai: bool = False, imported: bool = False) -&gt; ActionItem:\n        item_data['_user_timezone_str'] = self.settings.timezone  # For validation context\n        item = ActionItem.model_validate(\n            item_data)  # Pydantic handles string-&gt;datetime, then model_validator converts to UTC\n        item.created_by_ai = by_ai\n        item.updated_at = datetime.now(pytz.utc)  # Ensure update\n\n        # Initial next_due for new items if not already set by iCal import logic\n        if not item.next_due and item.fixed_time and item.status == ActionStatus.NOT_STARTED:\n            item.next_due = item.fixed_time\n\n        self.items.append(item)\n        self._add_history_entry(item, status_override=ActionStatus.NOT_STARTED,\n                                notes=\"Item created\" + (\" by AI\" if by_ai else \"\") + (\n                                    \" via import\" if imported else \"\"))\n        if by_ai:\n            self._log_ai_action(\"ai_create_item\", [item.id])\n\n        self._save_data()\n        return item\n\n    def get_item_by_id(self, item_id: str) -&gt; ActionItem | None:\n        return next((item for item in self.items if item.id == item_id), None)\n\n    def update_item(self, item_id: str, update_data: dict[str, Any], by_ai: bool = False) -&gt; ActionItem | None:\n        item = self.get_item_by_id(item_id)\n        if not item: return None\n\n        previous_data_json = item.model_dump_json() if by_ai else None\n\n        # Pass user timezone for validation context if datetime strings are present\n        update_data_with_tz_context = {**update_data, '_user_timezone_str': self.settings.timezone}\n\n        updated_item_dict = item.model_dump()\n        updated_item_dict.update(update_data_with_tz_context)\n\n        try:\n            # Re-validate the whole model to ensure consistency and proper conversions\n            new_item_state = ActionItem.model_validate(updated_item_dict)\n            # Preserve original ID and created_at, apply new state\n            new_item_state.id = item.id\n            new_item_state.created_at = item.created_at\n            self.items[self.items.index(item)] = new_item_state\n            item = new_item_state\n        except Exception as e:\n            self.app.logger.error(f\"Error validating updated item data: {e}. Update aborted for item {item_id}.\")\n            return None  # Or raise error\n\n        item.updated_at = datetime.now(pytz.utc)\n        item.created_by_ai = by_ai\n\n        self._recalculate_next_due(item)\n        self._add_history_entry(item, notes=\"Item updated\" + (\" by AI\" if by_ai else \"\"))\n\n        if by_ai:\n            self._log_ai_action(\"ai_modify_item\", [item.id],\n                                {item.id: previous_data_json} if previous_data_json else None)\n\n        self._save_data()\n        return item\n\n    def remove_item(self, item_id: str, record_history: bool = True) -&gt; bool:\n        item = self.get_item_by_id(item_id)\n        if not item: return False\n\n        children_ids = [child.id for child in self.items if child.parent_id == item_id]\n        for child_id in children_ids:\n            self.remove_item(child_id, record_history=record_history)\n\n        self.items = [i for i in self.items if i.id != item_id]\n        if self.current_item and self.current_item.id == item_id:\n            self.current_item = None\n\n        if record_history:\n            self._add_history_entry(item, status_override=ActionStatus.CANCELLED, notes=\"Item removed\")\n        self._save_data()\n        return True\n\n    def set_current_item(self, item_id: str) -&gt; ActionItem | None:\n        item = self.get_item_by_id(item_id)\n        if not item: return None\n        if item.status == ActionStatus.COMPLETED and item.item_type == ItemType.TASK and item.frequency == Frequency.ONE_TIME:\n            return None\n\n        self.current_item = item\n        if item.status == ActionStatus.NOT_STARTED:\n            item.status = ActionStatus.IN_PROGRESS\n            item.updated_at = datetime.now(pytz.utc)\n            self._add_history_entry(item, notes=\"Set as current, status to In Progress\")\n        else:\n            self._add_history_entry(item, notes=\"Set as current\")\n        self._save_data()\n        return item\n\n    def complete_current_item(self) -&gt; ActionItem | None:\n        if not self.current_item: return None\n\n        item_to_complete = self.current_item\n        item_to_complete.status = ActionStatus.COMPLETED\n        item_to_complete.last_completed = datetime.now(pytz.utc)\n        item_to_complete.updated_at = datetime.now(pytz.utc)\n\n        self._recalculate_next_due(item_to_complete)\n        self._add_history_entry(item_to_complete, status_override=ActionStatus.COMPLETED, notes=\"Marked as completed\")\n\n        self.current_item = None  # Clear current item after completion\n        self._save_data()\n        return item_to_complete\n\n    def get_suggestions(self, count: int = 2) -&gt; list[ActionItem]:\n        # Prioritize AI suggestions if ISAA is available\n        if self.isaa:\n            active_items_for_ai = []\n            for item in self.items:\n                if item.status != ActionStatus.COMPLETED and item.status != ActionStatus.CANCELLED:\n                    # Convert datetimes to user's local timezone string for AI context\n                    item_dump = item.model_dump_json_safe()  # This is already UTC ISO\n                    # Optionally, convert to user's timezone string if AI is better with local times\n                    # For now, UTC ISO is fine.\n                    active_items_for_ai.append(item_dump)\n\n            MAX_ITEMS_FOR_CONTEXT = 20\n            if len(active_items_for_ai) &gt; MAX_ITEMS_FOR_CONTEXT:\n                active_items_for_ai.sort(\n                    key=lambda x: (x.get('priority', 3), x.get('next_due') or '9999-12-31T23:59:59Z'))\n                active_items_for_ai = active_items_for_ai[:MAX_ITEMS_FOR_CONTEXT]\n\n            now_user_tz_str = datetime.now(self.get_user_timezone()).isoformat()\n\n            prompt = (\n                f\"User's current time: {now_user_tz_str} (Timezone: {self.settings.timezone}). \"\n                f\"Active items (tasks/notes) are provided below (datetimes are in UTC ISO format). \"\n                f\"Suggest the top {count} item IDs to focus on. Consider priority, due dates (next_due), \"\n                f\"and if a current item is set (current_item_id), its sub-items might be relevant. \"\n                f\"Tasks are generally more actionable. Focus on 'not_started' or 'in_progress'.\\n\\n\"\n                f\"Active Items (JSON):\\n{json.dumps(active_items_for_ai, indent=2)}\\n\\n\"\n                f\"Current Item ID: {self.current_item.id if self.current_item else 'None'}\\n\\n\"\n                f\"Return JSON: {{ \\\"suggested_item_ids\\\": [\\\"id1\\\", \\\"id2\\\"] }}.\"\n            )\n\n            class SuggestedIds(BaseModel):\n                suggested_item_ids: list[str]\n\n            try:\n                structured_response = asyncio.run(\n                    self.isaa.format_class(SuggestedIds, prompt, agent_name=\"TaskCompletion\"))\n                if structured_response and isinstance(structured_response, dict):\n                    suggested_ids_model = SuggestedIds(**structured_response)\n                    ai_suggestions = [self.get_item_by_id(id_str) for id_str in suggested_ids_model.suggested_item_ids\n                                      if self.get_item_by_id(id_str)]\n                    if ai_suggestions: return ai_suggestions[:count]\n            except Exception as e:\n                self.app.logger.error(f\"Error getting AI suggestions: {e}\")\n\n        # Fallback to basic suggestions\n        return self._get_basic_suggestions(count)\n\n    def _get_basic_suggestions(self, count: int = 2) -&gt; list[ActionItem]:\n        now_utc = datetime.now(pytz.utc)\n        available_items = [\n            item for item in self.items\n            if item.status in [ActionStatus.NOT_STARTED, ActionStatus.IN_PROGRESS]\n        ]\n\n        if self.current_item:\n            sub_items = [item for item in available_items if item.parent_id == self.current_item.id]\n            # If current item has actionable sub-items, prioritize them\n            if any(s.next_due and s.next_due &lt; (now_utc + timedelta(hours=2)) for s in sub_items) or \\\n                any(s.priority &lt;= 2 for s in sub_items):  # Urgent sub-items (due soon or high priority)\n                available_items = sub_items  # Focus on sub-items\n            # If no urgent sub-items, consider other items too, but maybe give slight preference to other sub-items.\n            # For simplicity now, if current_item is set, and it has sub-items, suggestions come from sub-items.\n            # If no sub-items, or current_item is not set, consider all available_items.\n            elif sub_items:  # Has sub-items, but none are \"urgent\" by above criteria\n                available_items = sub_items\n            # If current_item has no sub_items, then general pool is used.\n\n        def sort_key(item: ActionItem):\n            # Sort by: 1. Due Date (earlier is better, None is last) 2. Priority (lower num is higher)\n            due_date_utc = item.next_due if item.next_due else datetime.max.replace(tzinfo=pytz.utc)\n            return (due_date_utc, item.priority)\n\n        available_items.sort(key=sort_key)\n        return available_items[:count]\n\n    def get_history(self, limit: int = 50) -&gt; list[HistoryEntry]:\n        return sorted(self.history, key=lambda x: x.timestamp, reverse=True)[:limit]\n\n    def get_all_items_hierarchy(self) -&gt; dict[str, list[dict[str, Any]]]:\n        # This method remains largely the same, just ensure model_dump_json_safe is used.\n        # Datetimes will be ISO UTC strings. Client JS needs to handle display in user's local time.\n        hierarchy = {\"root\": []}\n        item_map = {item.id: item.model_dump_json_safe() for item in self.items}  # Uses UTC ISO dates\n\n        # This part seems fine, it builds hierarchy based on parent_id\n        processed_ids = set()\n        root_items_temp = []\n\n        for _item_id, item_dict in item_map.items():\n            parent_id = item_dict.get(\"parent_id\")\n            if parent_id and parent_id in item_map:\n                if \"children\" not in item_map[parent_id]:\n                    item_map[parent_id][\"children\"] = []\n                item_map[parent_id][\"children\"].append(item_dict)\n            else:\n                root_items_temp.append(item_dict)\n        hierarchy[\"root\"] = root_items_temp\n\n        def sort_children_recursive(node_list):\n            for node_dict in node_list:\n                if \"children\" in node_dict:\n                    # Sort children by priority, then creation date\n                    node_dict[\"children\"].sort(key=lambda x: (x.get('priority', 3), isoparse(x.get('created_at'))))\n                    sort_children_recursive(node_dict[\"children\"])\n\n        # Sort root items\n        hierarchy[\"root\"].sort(key=lambda x: (x.get('priority', 3), isoparse(x.get('created_at'))))\n        sort_children_recursive(hierarchy[\"root\"])\n        return hierarchy\n\n    # --- AI Specific Methods ---\n    async def ai_create_item_from_text(self, text: str) -&gt; ActionItem | None:\n        if not self.isaa:\n            self.app.logger.warning(\"ISAA module not available for AI item creation.\")\n            return None\n\n        class ParsedItemFromText(BaseModel):\n            item_type: Literal[\"task\", \"note\"] = \"task\"\n            title: str\n            description: str | None = None\n            priority: int | None = Field(default=3, ge=1, le=5)\n            due_date_str: str | None = None  # e.g., \"tomorrow\", \"next monday at 5pm\", \"2024-12-25 17:00\"\n            frequency_str: str | None = Field(default=\"one_time\",\n                                                 description=\"e.g. 'daily', 'weekly', 'one_time', 'every friday'\")\n\n        user_tz = self.get_user_timezone()\n        current_time_user_tz_str = datetime.now(user_tz).strftime('%Y-%m-%d %H:%M:%S %Z%z')\n        prompt = (\n            f\"User's current time is {current_time_user_tz_str}. Parse the input into a structured item. \"\n            f\"For due_date_str, interpret relative dates/times based on this current time and output \"\n            f\"a specific date string like 'YYYY-MM-DD HH:MM:SS'. If time is omitted, assume a default like 9 AM. \"\n            f\"If date is omitted but time is given (e.g. 'at 5pm'), assume today if 5pm is future, else tomorrow. \"\n            f\"User input: \\\"{text}\\\"\\n\\n\"\n            f\"Format as JSON for ParsedItemFromText.\"\n        )\n        try:\n            raw_response = await self.isaa.mini_task_completion(prompt, agent_name=\"TaskCompletion\")\n            if not raw_response: self.app.logger.error(\"AI parsing returned empty.\"); return None\n\n            json_str = raw_response\n            if \"```json\" in json_str: json_str = json_str.split(\"```json\")[1].split(\"```\")[0].strip()\n            parsed_dict = json.loads(json_str)\n            parsed_data_model = ParsedItemFromText(**parsed_dict)\n\n            item_constructor_data = {\n                \"item_type\": ItemType(parsed_data_model.item_type),\n                \"title\": parsed_data_model.title,\n                \"description\": parsed_data_model.description,\n                \"priority\": parsed_data_model.priority or 3,\n            }\n\n            if parsed_data_model.due_date_str:\n                # ISAA is prompted to return YYYY-MM-DD HH:MM:SS.\n                # This string is assumed to be in the user's local timezone.\n                # The ActionItem model_validator will convert this to UTC.\n                item_constructor_data[\"fixed_time\"] = parsed_data_model.due_date_str  # Pass as string\n\n            # Frequency parsing (simplified)\n            if parsed_data_model.frequency_str:\n                freq_str_lower = parsed_data_model.frequency_str.lower()\n                if \"daily\" in freq_str_lower:\n                    item_constructor_data[\"frequency\"] = Frequency.DAILY\n                elif \"weekly\" in freq_str_lower:\n                    item_constructor_data[\"frequency\"] = Frequency.WEEKLY\n                elif \"monthly\" in freq_str_lower:\n                    item_constructor_data[\"frequency\"] = Frequency.MONTHLY\n                elif \"annually\" in freq_str_lower or \"yearly\" in freq_str_lower:\n                    item_constructor_data[\"frequency\"] = Frequency.ANNUALLY\n                else:\n                    item_constructor_data[\"frequency\"] = Frequency.ONE_TIME\n\n            return self.add_item(item_constructor_data, by_ai=True)\n        except Exception as e:\n            self.app.logger.error(\n                f\"Error creating item with AI: {e}. Raw: {raw_response if 'raw_response' in locals() else 'N/A'}\")\n            return None\n\n    def _log_ai_action(self, action_type: Literal[\"ai_create_item\", \"ai_modify_item\", \"ical_import\"],\n                       item_ids: list[str], previous_data_map: dict[str, str] | None = None):\n        entry = UndoLogEntry(action_type=action_type, item_ids=item_ids, previous_data_json_map=previous_data_map)\n        self.undo_log.append(entry)\n        if len(self.undo_log) &gt; 20: self.undo_log = self.undo_log[-20:]\n        # _save_data called by caller\n\n    async def undo_last_ai_action(self) -&gt; bool:  # Also handles iCal import undo\n        if not self.undo_log: return False\n        last_action = self.undo_log.pop()\n        action_undone_count = 0\n\n        if last_action.action_type in [\"ai_create_item\", \"ical_import\"]:\n            for item_id in last_action.item_ids:\n                if self.remove_item(item_id, record_history=False):  # Don't double-log removal for undo\n                    action_undone_count += 1\n        elif last_action.action_type == \"ai_modify_item\":\n            if last_action.previous_data_json_map:\n                for item_id, prev_data_json in last_action.previous_data_json_map.items():\n                    try:\n                        prev_data = ActionItem.model_validate_json_safe(json.loads(prev_data_json),\n                                                                        user_timezone_str=self.settings.timezone)\n                        # Replace item\n                        found = False\n                        for i, item_in_list in enumerate(self.items):\n                            if item_in_list.id == item_id:\n                                self.items[i] = prev_data\n                                if self.current_item and self.current_item.id == item_id:\n                                    self.current_item = prev_data\n                                found = True\n                                break\n                        if found:\n                            action_undone_count += 1\n                        else:\n                            self.app.logger.warning(f\"Could not find item {item_id} to restore during AI undo.\")\n                    except Exception as e:\n                        self.app.logger.error(f\"Error restoring item {item_id} during undo: {e}\")\n            else:  # Should not happen for modify\n                self.app.logger.warning(\n                    f\"Undo for AI modify action on item(s) {last_action.item_ids} had no previous_data_json_map.\")\n\n        if action_undone_count &gt; 0:\n            # Create a generic history entry for the undo action\n            generic_undo_item_title = f\"Related to {len(last_action.item_ids)} item(s)\"\n            if len(last_action.item_ids) == 1:\n                item_for_title = self.get_item_by_id(last_action.item_ids[0])  # Might be None if it was a create undo\n                generic_undo_item_title = item_for_title.title if item_for_title else \"N/A (Undone Action)\"\n\n            self.history.append(HistoryEntry(\n                item_id=last_action.item_ids[0],  # Representative item\n                item_title=generic_undo_item_title,\n                item_type=ItemType.TASK,  # Generic\n                status_changed_to=ActionStatus.CANCELLED,  # Generic status for undo\n                notes=f\"Undid action: {last_action.action_type} for {len(last_action.item_ids)} item(s).\"\n            ))\n            self._save_data()\n            return True\n\n        # If nothing was undone, put action back to log\n        self.undo_log.append(last_action)\n        return False\n\n    # --- iCalendar Methods ---\n    def _parse_ical_dt(self, dt_ical: vDatetime | vDate, user_tz: pytz.BaseTzInfo) -&gt; datetime | None:\n        \"\"\"Converts icalendar vDatetime or vDate to UTC datetime.\"\"\"\n        if not dt_ical: return None\n        dt_val = dt_ical.dt\n\n        if isinstance(dt_val, datetime):\n            if dt_val.tzinfo is None:  # Naive datetime, assume user's local timezone as per iCal spec for floating\n                return user_tz.localize(dt_val).astimezone(pytz.utc)\n            return dt_val.astimezone(pytz.utc)  # Aware datetime\n        elif isinstance(dt_val, date):  # All-day event, represent as start of day in user's TZ, then UTC\n            return user_tz.localize(datetime.combine(dt_val, datetime.min.time())).astimezone(pytz.utc)\n        return None\n\n    def _map_ical_priority_to_app(self, ical_priority: int | None) -&gt; int:\n        if ical_priority is None: return 3  # Default\n        if 1 &lt;= ical_priority &lt;= 4: return 1  # High\n        if ical_priority == 5: return 3  # Medium\n        if 6 &lt;= ical_priority &lt;= 9: return 5  # Low\n        return 3  # Default for 0 or other values\n\n    def _map_app_priority_to_ical(self, app_priority: int) -&gt; int:\n        if app_priority == 1: return 1  # High\n        if app_priority == 2: return 3\n        if app_priority == 3: return 5  # Medium\n        if app_priority == 4: return 7\n        if app_priority == 5: return 9  # Low\n        return 0  # No priority\n\n    def _map_rrule_to_frequency(self, rrule_prop: vRecur | None) -&gt; tuple[Frequency, str | None]:\n        if not rrule_prop:\n            return Frequency.ONE_TIME, None\n\n        rrule_dict = rrule_prop.to_dict()\n        freq = rrule_dict.get('FREQ')\n        original_rrule_str = vRecur.from_dict(rrule_dict).to_ical().decode('utf-8')\n\n        if freq == 'DAILY': return Frequency.DAILY, original_rrule_str\n        if freq == 'WEEKLY': return Frequency.WEEKLY, original_rrule_str\n        if freq == 'MONTHLY': return Frequency.MONTHLY, original_rrule_str\n        if freq == 'YEARLY': return Frequency.ANNUALLY, original_rrule_str\n\n        # If RRULE is complex or not a direct match, import as ONE_TIME for each instance\n        # but store the original RRULE string for reference or future advanced handling.\n        return Frequency.ONE_TIME, original_rrule_str\n\n    def import_ical_events(self, ical_string: str) -&gt; list[ActionItem]:\n        imported_items: list[ActionItem] = []\n        try:\n            cal = iCalCalendar.from_ical(ical_string)\n            user_tz = self.get_user_timezone()\n            now_utc = datetime.now(pytz.utc)\n            import_limit_date_utc = now_utc + timedelta(days=RECURRING_IMPORT_WINDOW_DAYS)\n\n            processed_uids_for_session = set()  # To avoid processing same base recurring event multiple times in one import\n\n            for component in cal.walk():\n                if component.name == \"VEVENT\":\n                    uid = component.get('uid')\n                    if not uid:\n                        uid = str(uuid.uuid4())  # Generate a UID if missing\n                    else:\n                        uid = uid.to_ical().decode('utf-8')\n\n                    summary = component.get('summary', 'Untitled Event').to_ical().decode('utf-8')\n                    description = component.get('description', '').to_ical().decode('utf-8')\n                    location = component.get('location', '').to_ical().decode('utf-8')\n                    dtstart_ical = component.get('dtstart')\n                    dtend_ical = component.get('dtend')  # Can be used for duration if needed\n                    ical_priority_val = component.get('priority')\n                    ical_priority = int(ical_priority_val.to_ical().decode('utf-8')) if ical_priority_val else None\n\n                    rrule_prop = component.get('rrule')  # This is a vRecur object or None\n\n                    start_time_utc = self._parse_ical_dt(dtstart_ical, user_tz)\n                    if not start_time_utc:\n                        self.app.logger.warning(f\"Skipping event '{summary}' due to missing/invalid DTSTART.\")\n                        continue\n\n                    app_priority = self._map_ical_priority_to_app(ical_priority)\n\n                    # Check for existing item with this iCal UID to potentially update (simplistic check)\n                    # A more robust update would involve comparing sequence numbers, etc.\n                    # For now, if UID exists, we might skip or update. Let's try to update.\n                    # To keep it simpler for now, we will create new items for occurrences.\n                    # UID management needs to be precise for updates.\n                    # If an item is an instance of a recurring event, its UID in our system might be base_uid + occurrence_date.\n\n                    if rrule_prop:\n                        if uid in processed_uids_for_session:  # Already processed this recurring event's base\n                            continue\n                        processed_uids_for_session.add(uid)\n\n                        # Handle recurring event\n                        rrule_str = rrule_prop.to_ical().decode('utf-8')\n                        # Ensure DTSTART is part of the rrule context if not explicitly in rrulestr\n                        if 'DTSTART' not in rrule_str.upper() and start_time_utc:\n                            # dateutil.rrule needs start time; icalendar often bakes it in.\n                            # If start_time_utc is naive, use user_tz to make it aware.\n                            dtstart_for_rrule = start_time_utc.astimezone(\n                                user_tz) if start_time_utc.tzinfo else user_tz.localize(start_time_utc)\n                            # rrule_obj = rrulestr(rrule_str, dtstart=dtstart_for_rrule) # This is complex due to TZ handling in rrulestr\n                            # The icalendar library's component should be timezone aware from DTSTART\n                            # So, let's assume dtstart_ical.dt is the correct starting point.\n                            try:\n                                rrule_obj = rrulestr(rrule_str, dtstart=dtstart_ical.dt)\n                            except Exception as e_rr:\n                                self.app.logger.error(\n                                    f\"Could not parse RRULE '{rrule_str}' for event '{summary}': {e_rr}\")\n                                continue\n\n                        occurrences_imported = 0\n                        # Generate occurrences starting from now (in user's timezone, aligned to event's time)\n                        # or from event's start_time_utc if it's in the future.\n\n                        # The rrule iteration should be in the event's original timezone context if possible,\n                        # or consistently in user's timezone for 'now'.\n                        # Let's use UTC for iteration and then convert.\n\n                        # Iterate from the event's actual start time or now, whichever is later for relevant future instances.\n                        iteration_start_utc = max(now_utc, start_time_utc)\n\n                        for occ_dt_aware in rrule_obj.between(iteration_start_utc, import_limit_date_utc, inc=True):\n                            if occurrences_imported &gt;= MAX_RECURRING_INSTANCES_TO_IMPORT:\n                                break\n\n                            # occ_dt_aware is usually from dateutil.rrule, may need tzinfo set or conversion.\n                            # If rrulestr was given an aware dtstart, occurrences should be aware.\n                            # Ensure it's UTC for our system.\n                            occ_utc = occ_dt_aware.astimezone(pytz.utc) if occ_dt_aware.tzinfo else pytz.utc.localize(\n                                occ_dt_aware)\n\n                            instance_uid = f\"{uid}-{occ_utc.strftime('%Y%m%dT%H%M%S%Z')}\"\n\n                            # Check if this specific instance already exists\n                            existing_instance = next((item for item in self.items if item.ical_uid == instance_uid),\n                                                     None)\n                            if existing_instance:\n                                self.app.logger.info(\n                                    f\"Instance {instance_uid} for '{summary}' already exists. Skipping.\")\n                                continue\n\n                            item_data = {\n                                \"title\": summary, \"description\": description, \"location\": location,\n                                \"item_type\": ItemType.TASK, \"fixed_time\": occ_utc,\n                                \"frequency\": Frequency.ONE_TIME,  # Each imported instance is one-time in our system\n                                \"priority\": app_priority, \"ical_uid\": instance_uid,  # Instance-specific UID\n                                \"status\": ActionStatus.NOT_STARTED,\n                                \"ical_rrule_original\": rrule_str  # Store original rule for reference\n                            }\n                            new_item = self.add_item(item_data, imported=True)\n                            imported_items.append(new_item)\n                            occurrences_imported += 1\n\n                        if occurrences_imported == 0 and start_time_utc &gt; now_utc and start_time_utc &lt;= import_limit_date_utc:\n                            # If it's a future non-recurring event (or rrule didn't yield instances in window but start is in window)\n                            # This case is for when rrule_prop exists but yields no instances in the .between() range,\n                            # but the initial DTSTART itself is valid and upcoming.\n                            # However, rrule.between should include dtstart if inc=True and it's within range.\n                            # This path might be redundant if .between is inclusive and dtstart is in range.\n                            pass\n\n\n                    else:  # Non-recurring event\n                        # Only import if it's upcoming or started recently and not completed (e.g. within last day)\n                        if start_time_utc &lt; (\n                            now_utc - timedelta(days=1)) and not dtend_ical:  # Too old, and no end time to check\n                            self.app.logger.info(f\"Skipping old non-recurring event '{summary}' (UID: {uid})\")\n                            continue\n                        if dtend_ical:\n                            end_time_utc = self._parse_ical_dt(dtend_ical, user_tz)\n                            if end_time_utc and end_time_utc &lt; now_utc:  # Event has already ended\n                                self.app.logger.info(f\"Skipping past event '{summary}' (UID: {uid}) that has ended.\")\n                                continue\n\n                        existing_item = next((item for item in self.items if item.ical_uid == uid), None)\n                        if existing_item:  # Simplistic update: remove old, add new. Better: update in place.\n                            self.app.logger.info(\n                                f\"Event with UID {uid} ('{summary}') already exists. Re-importing (simple replace).\")\n                            self.remove_item(existing_item.id, record_history=False)\n\n                        item_data = {\n                            \"title\": summary, \"description\": description, \"location\": location,\n                            \"item_type\": ItemType.TASK, \"fixed_time\": start_time_utc,\n                            \"frequency\": Frequency.ONE_TIME, \"priority\": app_priority,\n                            \"ical_uid\": uid, \"status\": ActionStatus.NOT_STARTED\n                        }\n                        new_item = self.add_item(item_data, imported=True)\n                        imported_items.append(new_item)\n\n            if imported_items:\n                self._log_ai_action(\"ical_import\", [item.id for item in imported_items])\n            self._save_data()  # Ensure all changes are saved\n            self.app.logger.info(f\"Imported {len(imported_items)} items from iCalendar data.\")\n\n        except Exception as e:\n            self.app.logger.error(f\"Failed to parse iCalendar string: {e}\", exc_info=True)\n            # Potentially re-raise or return empty list with error status\n        return imported_items\n\n    def import_ical_from_url(self, url: str) -&gt; list[ActionItem]:\n        try:\n            headers = {'User-Agent': 'POA_App/1.0 (+https://yourdomain.com/poa_app_info)'}  # Be a good internet citizen\n            response = requests.get(url, timeout=10, headers=headers)\n            response.raise_for_status()  # Raises HTTPError for bad responses (4XX or 5XX)\n            return self.import_ical_events(response.text)\n        except requests.exceptions.RequestException as e:\n            self.app.logger.error(f\"Error fetching iCalendar from URL {url}: {e}\")\n            return []\n        except Exception as e:  # Catch other errors like parsing\n            self.app.logger.error(f\"Error processing iCalendar from URL {url}: {e}\")\n            return []\n\n    def import_ical_from_file_content(self, file_content: bytes) -&gt; list[ActionItem]:\n        try:\n            # Try to decode as UTF-8, but iCal can have other encodings.\n            # Standard is UTF-8. `icalendar` lib handles encoding detection mostly.\n            ical_string = file_content.decode('utf-8', errors='replace')\n            return self.import_ical_events(ical_string)\n        except UnicodeDecodeError as e:\n            self.app.logger.error(f\"Encoding error reading iCalendar file: {e}. Try ensuring UTF-8 encoding.\")\n            # Try with 'latin-1' as a common fallback for some older files\n            try:\n                ical_string = file_content.decode('latin-1', errors='replace')\n                return self.import_ical_events(ical_string)\n            except Exception as e_fallback:\n                self.app.logger.error(f\"Fallback decoding also failed for iCalendar file: {e_fallback}\")\n                return []\n        except Exception as e:\n            self.app.logger.error(f\"Error processing iCalendar file content: {e}\")\n            return []\n\n    def export_to_ical_string(self) -&gt; str:\n        cal = iCalCalendar()\n        cal.add('prodid', '-//POA App//yourdomain.com//')\n        cal.add('version', '2.0')\n        user_tz = self.get_user_timezone()\n\n        for item in self.items:\n            if item.item_type == ItemType.TASK and item.fixed_time:\n                event = iCalEvent()\n                event.add('summary', item.title)\n\n                # Ensure fixed_time is UTC for iCal standard practice\n                dtstart_utc = item.fixed_time\n                if dtstart_utc.tzinfo is None:  # Should not happen if stored correctly\n                    dtstart_utc = pytz.utc.localize(dtstart_utc)\n                else:\n                    dtstart_utc = dtstart_utc.astimezone(pytz.utc)\n                event.add('dtstart', dtstart_utc)  # vDatetime handles UTC conversion for .to_ical()\n\n                # Add DTEND (e.g., 1 hour duration for tasks, or based on item if available)\n                # For simplicity, let's assume 1 hour duration if not specified\n                event.add('dtend', dtstart_utc + timedelta(hours=1))\n\n                event.add('dtstamp', datetime.now(pytz.utc))  # Time the event was created in iCal\n                event.add('uid', item.ical_uid or item.id)  # Use original iCal UID if present, else our ID\n\n                if item.description:\n                    event.add('description', item.description)\n                if item.location:\n                    event.add('location', item.location)\n\n                event.add('priority', self._map_app_priority_to_ical(item.priority))\n\n                # Handle recurrence\n                if item.frequency != Frequency.ONE_TIME:\n                    if item.ical_rrule_original:  # If we have the original complex rule, use it\n                        try:\n                            # vRecur.from_ical requires bytes\n                            event.add('rrule', vRecur.from_ical(item.ical_rrule_original.encode()))\n                        except Exception as e_rrule:\n                            self.app.logger.warning(\n                                f\"Could not parse stored original RRULE '{item.ical_rrule_original}' for item {item.id}: {e_rrule}. Exporting as simple recurrence.\")\n                            # Fallback to simple mapping\n                            self._add_simple_rrule(event, item.frequency)\n                    else:  # Map simple frequency\n                        self._add_simple_rrule(event, item.frequency)\n\n                cal.add_component(event)\n        return cal.to_ical().decode('utf-8')\n\n    def _add_simple_rrule(self, event: iCalEvent, frequency: Frequency):\n        rrule_params = {}\n        if frequency == Frequency.DAILY:\n            rrule_params['freq'] = 'DAILY'\n        elif frequency == Frequency.WEEKLY:\n            rrule_params['freq'] = 'WEEKLY'\n        elif frequency == Frequency.MONTHLY:\n            rrule_params['freq'] = 'MONTHLY'\n        elif frequency == Frequency.ANNUALLY:\n            rrule_params['freq'] = 'YEARLY'\n\n        if rrule_params:\n            event.add('rrule', vRecur(rrule_params))\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.SchedulerManager","title":"<code>SchedulerManager</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.SchedulerManager.SchedulerManagerClass","title":"<code>SchedulerManagerClass</code>","text":"Source code in <code>toolboxv2/mods/SchedulerManager.py</code> <pre><code>class SchedulerManagerClass:\n    def __init__(self):\n        self.jobs = {}\n        self.thread = None\n        self.running = False\n        self.last_successful_jobs = deque(maxlen=3)  # Stores last 3 successful job names\n        self.job_errors = {}  # Stores job names as keys and error messages as values\n\n    def _run(self):\n        while self.running:\n            schedule.run_pending()\n            time.sleep(1)\n\n    def start(self):\n        if not self.running:\n            self.running = True\n            self.thread = threading.Thread(target=self._run, daemon=True)\n            self.thread.start()\n\n    def stop(self):\n        self.running = False\n        if self.thread is not None:\n            self.thread.join()\n\n    def job_wrapper(self, job_name: str, job_function: callable):\n        \"\"\"\n        Wrap a job function to track success and errors.\n        \"\"\"\n        def wrapped_job(*args, **kwargs):\n            try:\n                job_function(*args, **kwargs)\n                # If the job ran successfully, store it in the success queue\n                self.last_successful_jobs.append(job_name)\n                if job_name in self.job_errors:\n                    del self.job_errors[job_name]  # Remove error record if job succeeded after failing\n            except Exception as e:\n                # Capture any exceptions and store them\n                self.job_errors[job_name] = str(e)\n\n        return wrapped_job\n\n\n    def register_job(self,\n                     job_id: str,\n                     second: int = -1,\n                     func: (Callable or str) | None = None,\n                     job: schedule.Job | None = None,\n                     time_passer: schedule.Job | None = None,\n                     object_name: str | None = None,\n                     receive_job: bool = False,\n                     save: bool = False,\n                     max_live: bool = False,\n                     serializer=serializer_default,\n                     args=None, kwargs=None):\n        \"\"\"\n            Parameters\n            ----------\n                job_id : str\n                    id for the job for management\n                second : int\n                    The time interval in seconds between each call of the job.\n                func : Callable or str\n                    The function to be executed as the job.\n                job : schedule.Job\n                    An existing job object from the schedule library.\n                time_passer : schedule.Job\n                    A job without a function, used to specify the time interval.\n                object_name : str\n                    The name of the object containing in the 'func' var to be executed.\n                receive_job : bool\n                    A flag indicating whether the job should be received from an object from 'func' var.\n                save : bool\n                    A flag indicating whether the job should be saved.\n                max_live : bool\n                    A flag indicating whether the job should have a maximum live time.\n                serializer : dill\n                    json pickel or dill must have a dumps fuction\n                *args, **kwargs : Any serializable and deserializable\n                    Additional arguments to be passed to the job function.\n\n            Returns\n            -------\n           \"\"\"\n\n        if job is None and func is None:\n            return Result.default_internal_error(\"Both job and func are not specified.\"\n                                                 \" Please specify either job or func.\")\n        if job is not None and func is not None:\n            return Result.default_internal_error(\"Both job and func are specified. Please specify either job or func.\")\n\n        if job is not None:\n            def func(x):\n                return x\n            return self._save_job(job_id=job_id,\n                                  job=job,\n                                  save=save,\n                                  func=func,\n                                  args=args,\n                                  kwargs=kwargs,\n                                  serializer=serializer)\n\n        parsed_attr = self._parse_function(func=func, object_name=object_name)\n\n        if parsed_attr.is_error():\n            parsed_attr.result.data_info = f\"Error parsing function for job : {job_id}\"\n            return parsed_attr\n\n        if receive_job:\n            job = parsed_attr.get()\n        else:\n            func = parsed_attr.get()\n\n        time_passer = self._prepare_time_passer(time_passer=time_passer,\n                                                second=second)\n\n        job_func = self._prepare_job_func(func=func,\n                                          max_live=max_live,\n                                          second=second,\n                                          args=args,\n                                          kwargs=kwargs,\n                                          job_id=job_id)\n\n        job = self._get_final_job(job=job,\n                                  func=self.job_wrapper(job_id, job_func),\n                                  time_passer=time_passer,\n                                  job_func=job_func,\n                                  args=args,\n                                  kwargs=kwargs)\n        if job.is_error():\n            return job\n\n        job = job.get()\n\n        return self._save_job(job_id=job_id,\n                              job=job,\n                              save=save,\n                              func=func,\n                              args=args,\n                              kwargs=kwargs,\n                              serializer=serializer)\n\n    @staticmethod\n    def _parse_function(func: str or Callable, object_name):\n        if isinstance(func, str) and func.endswith('.py'):\n            with open(func) as file:\n                func_code = file.read()\n                exec(func_code)\n                func = locals()[object_name]\n        elif isinstance(func, str) and func.endswith('.dill') and safety_mode == 'open':\n            try:\n                with open(func, 'rb') as file:\n                    func = dill.load(file)\n            except FileNotFoundError:\n                return Result.default_internal_error(f\"Function file {func} not found or dill not installed\")\n        elif isinstance(func, str):\n            local_vars = {'app': get_app(from_=Name + f\".pasing.{object_name}\")}\n            try:\n                exec(func.strip(), {}, local_vars)\n            except Exception as e:\n                return Result.default_internal_error(f\"Function parsing failed withe {e}\")\n            func = local_vars[object_name]\n        elif isinstance(func, Callable):\n            pass\n        else:\n            return Result.default_internal_error(\"Could not parse object scheduler_manager.parse_function\")\n        return Result.ok(func)\n\n    @staticmethod\n    def _prepare_time_passer(time_passer, second):\n        if time_passer is None and second &gt; 0:\n            return schedule.every(second).seconds\n        elif time_passer is None and second &lt;= 0:\n            raise ValueError(\"second must be greater than 0\")\n        return time_passer\n\n    def _prepare_job_func(self, func: Callable, max_live: bool, second: float, job_id: str, *args, **kwargs):\n        if max_live:\n            end_time = datetime.now() + timedelta(seconds=second)\n\n            def job_func():\n                if datetime.now() &lt; end_time:\n                    func(*args, **kwargs)\n                else:\n                    job = self.jobs.get(job_id, {}).get('job')\n                    if job is not None:\n                        schedule.cancel_job(job)\n                    else:\n                        print(\"Error Canceling job\")\n\n            return job_func\n        return func\n\n    @staticmethod\n    def _get_final_job(job, func, time_passer, job_func, args, kwargs):\n        if job is None and isinstance(func, Callable):\n            job = time_passer.do(job_func, *args, **kwargs)\n        elif job is not None:\n            pass\n        else:\n            return Result.default_internal_error(\"No Final job found for register\")\n        return Result.ok(job)\n\n    def _save_job(self, job_id, job, save, args=None, **kwargs):\n        if job is not None:\n            self.jobs[job_id] = {'id': job_id, 'job': job, 'save': save, 'func': job_id, 'args': args,\n                                 'kwargs': kwargs}\n            f = (f\"Added Job {job_id} :{' - saved' if save else ''}\"\n                  f\"{' - args ' + str(len(args)) if args else ''}\"\n                  f\"{' - kwargs ' + str(len(kwargs.keys())) if kwargs else ''}\")\n            return Result.ok(f)\n        else:\n            return Result.default_internal_error(job_id)\n\n    def cancel_job(self, job_id):\n        if job_id not in self.jobs:\n            print(\"Job not found\")\n            return\n        schedule.cancel_job(self.jobs[job_id].get('job'))\n        self.jobs[job_id][\"cancelled\"] = True\n        self.jobs[job_id][\"save\"] = False\n        print(\"Job cancelled\")\n\n    def del_job(self, job_id):\n        if job_id not in self.jobs:\n            print(\"Job not found\")\n            return\n        if not self.jobs[job_id].get(\"cancelled\", False):\n            print(\"Job not cancelled canceling job\")\n            self.cancel_job(job_id)\n        del self.jobs[job_id]\n        print(\"Job deleted\")\n\n    def save_jobs(self, file_path, serializer=serializer_default):\n        with open(file_path, 'wb') as file:\n            save_jobs = [job for job in self.jobs.values() if job['save']]\n            serializer.dump(save_jobs, file)\n\n    def load_jobs(self, file_path, deserializer=deserializer_default):\n        with open(file_path, 'rb') as file:\n            jobs = deserializer.load(file)\n            for job_info in jobs:\n                del job_info['job']\n                func = deserializer.loads(job_info['func'])\n                self.register_job(job_info['id'], func=func, **job_info)\n\n    def get_tasks_table(self):\n        if not self.jobs:\n            return \"No tasks registered.\"\n\n        # Calculate the maximum width for each column\n        id_width = max(len(\"Task ID\"), max(len(job_id) for job_id in self.jobs))\n        next_run_width = len(\"Next Execution\")\n        interval_width = len(\"Interval\")\n\n        # Create the header\n        header = f\"| {'Task ID':&lt;{id_width}} | {'Next Execution':&lt;{next_run_width}} | {'Interval':&lt;{interval_width}} |\"\n        separator = f\"|{'-' * (id_width + 2)}|{'-' * (next_run_width + 2)}|{'-' * (interval_width + 2)}|\"\n\n        # Create the table rows\n        rows = []\n        for job_id, job_info in self.jobs.items():\n            job = job_info['job']\n            next_run = job.next_run.strftime(\"%Y-%m-%d %H:%M:%S\") if job.next_run else \"N/A\"\n            interval = self._get_interval_str(job)\n            row = f\"| {job_id:&lt;{id_width}} | {next_run:&lt;{next_run_width}} | {interval:&lt;{interval_width}} |\"\n            rows.append(row)\n\n        # Combine all parts of the table\n        table = \"\\n\".join([header, separator] + rows)\n        return table\n\n    def _get_interval_str(self, job):\n        if job.interval == 0:\n            return \"Once\"\n\n        units = [\n            (86400, \"day\"),\n            (3600, \"hour\"),\n            (60, \"minute\"),\n            (1, \"second\")\n        ]\n\n        for seconds, unit in units:\n            if job.interval % seconds == 0:\n                count = job.interval // seconds\n                return f\"Every {count} {unit}{'s' if count &gt; 1 else ''}\"\n\n        return f\"Every {job.interval} seconds\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.SchedulerManager.SchedulerManagerClass.job_wrapper","title":"<code>job_wrapper(job_name, job_function)</code>","text":"<p>Wrap a job function to track success and errors.</p> Source code in <code>toolboxv2/mods/SchedulerManager.py</code> <pre><code>def job_wrapper(self, job_name: str, job_function: callable):\n    \"\"\"\n    Wrap a job function to track success and errors.\n    \"\"\"\n    def wrapped_job(*args, **kwargs):\n        try:\n            job_function(*args, **kwargs)\n            # If the job ran successfully, store it in the success queue\n            self.last_successful_jobs.append(job_name)\n            if job_name in self.job_errors:\n                del self.job_errors[job_name]  # Remove error record if job succeeded after failing\n        except Exception as e:\n            # Capture any exceptions and store them\n            self.job_errors[job_name] = str(e)\n\n    return wrapped_job\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.SchedulerManager.SchedulerManagerClass.register_job","title":"<code>register_job(job_id, second=-1, func=None, job=None, time_passer=None, object_name=None, receive_job=False, save=False, max_live=False, serializer=serializer_default, args=None, kwargs=None)</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.SchedulerManager.SchedulerManagerClass.register_job--parameters","title":"Parameters","text":"<pre><code>job_id : str\n    id for the job for management\nsecond : int\n    The time interval in seconds between each call of the job.\nfunc : Callable or str\n    The function to be executed as the job.\njob : schedule.Job\n    An existing job object from the schedule library.\ntime_passer : schedule.Job\n    A job without a function, used to specify the time interval.\nobject_name : str\n    The name of the object containing in the 'func' var to be executed.\nreceive_job : bool\n    A flag indicating whether the job should be received from an object from 'func' var.\nsave : bool\n    A flag indicating whether the job should be saved.\nmax_live : bool\n    A flag indicating whether the job should have a maximum live time.\nserializer : dill\n    json pickel or dill must have a dumps fuction\n*args, **kwargs : Any serializable and deserializable\n    Additional arguments to be passed to the job function.\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.SchedulerManager.SchedulerManagerClass.register_job--returns","title":"Returns","text":"Source code in <code>toolboxv2/mods/SchedulerManager.py</code> <pre><code>def register_job(self,\n                 job_id: str,\n                 second: int = -1,\n                 func: (Callable or str) | None = None,\n                 job: schedule.Job | None = None,\n                 time_passer: schedule.Job | None = None,\n                 object_name: str | None = None,\n                 receive_job: bool = False,\n                 save: bool = False,\n                 max_live: bool = False,\n                 serializer=serializer_default,\n                 args=None, kwargs=None):\n    \"\"\"\n        Parameters\n        ----------\n            job_id : str\n                id for the job for management\n            second : int\n                The time interval in seconds between each call of the job.\n            func : Callable or str\n                The function to be executed as the job.\n            job : schedule.Job\n                An existing job object from the schedule library.\n            time_passer : schedule.Job\n                A job without a function, used to specify the time interval.\n            object_name : str\n                The name of the object containing in the 'func' var to be executed.\n            receive_job : bool\n                A flag indicating whether the job should be received from an object from 'func' var.\n            save : bool\n                A flag indicating whether the job should be saved.\n            max_live : bool\n                A flag indicating whether the job should have a maximum live time.\n            serializer : dill\n                json pickel or dill must have a dumps fuction\n            *args, **kwargs : Any serializable and deserializable\n                Additional arguments to be passed to the job function.\n\n        Returns\n        -------\n       \"\"\"\n\n    if job is None and func is None:\n        return Result.default_internal_error(\"Both job and func are not specified.\"\n                                             \" Please specify either job or func.\")\n    if job is not None and func is not None:\n        return Result.default_internal_error(\"Both job and func are specified. Please specify either job or func.\")\n\n    if job is not None:\n        def func(x):\n            return x\n        return self._save_job(job_id=job_id,\n                              job=job,\n                              save=save,\n                              func=func,\n                              args=args,\n                              kwargs=kwargs,\n                              serializer=serializer)\n\n    parsed_attr = self._parse_function(func=func, object_name=object_name)\n\n    if parsed_attr.is_error():\n        parsed_attr.result.data_info = f\"Error parsing function for job : {job_id}\"\n        return parsed_attr\n\n    if receive_job:\n        job = parsed_attr.get()\n    else:\n        func = parsed_attr.get()\n\n    time_passer = self._prepare_time_passer(time_passer=time_passer,\n                                            second=second)\n\n    job_func = self._prepare_job_func(func=func,\n                                      max_live=max_live,\n                                      second=second,\n                                      args=args,\n                                      kwargs=kwargs,\n                                      job_id=job_id)\n\n    job = self._get_final_job(job=job,\n                              func=self.job_wrapper(job_id, job_func),\n                              time_passer=time_passer,\n                              job_func=job_func,\n                              args=args,\n                              kwargs=kwargs)\n    if job.is_error():\n        return job\n\n    job = job.get()\n\n    return self._save_job(job_id=job_id,\n                          job=job,\n                          save=save,\n                          func=func,\n                          args=args,\n                          kwargs=kwargs,\n                          serializer=serializer)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.SchedulerManager.Tools","title":"<code>Tools</code>","text":"<p>               Bases: <code>MainTool</code>, <code>SchedulerManagerClass</code></p> Source code in <code>toolboxv2/mods/SchedulerManager.py</code> <pre><code>class Tools(MainTool, SchedulerManagerClass):\n    version = version\n\n    def __init__(self, app=None):\n        self.name = Name\n        self.color = \"VIOLET2\"\n\n        self.keys = {\"mode\": \"db~mode~~:\"}\n        self.encoding = 'utf-8'\n        self.tools = {'name': Name}\n\n        SchedulerManagerClass.__init__(self)\n        MainTool.__init__(self,\n                          load=self.init_sm,\n                          v=self.version,\n                          name=self.name,\n                          color=self.color,\n                          on_exit=self.on_exit)\n\n\n    @export(\n        mod_name=Name,\n        name=\"Version\",\n        version=version,\n    )\n    def get_version(self):\n        return self.version\n\n    # Exportieren der Scheduler-Instanz f\u00fcr die Nutzung in anderen Modulen\n    @export(mod_name=Name, name='init', version=version, initial=True)\n    def init_sm(self):\n        if os.path.exists(self.app.data_dir + '/jobs.compact'):\n            print(\"SchedulerManager try loading from file\")\n            self.load_jobs(\n                self.app.data_dir + '/jobs.compact'\n            )\n            print(\"SchedulerManager Successfully loaded\")\n        print(\"STARTING SchedulerManager\")\n        self.start()\n\n    @export(mod_name=Name, name='clos_manager', version=version, exit_f=True)\n    def on_exit(self):\n        self.stop()\n        self.save_jobs(self.app.data_dir + '/jobs.compact')\n        return f\"saved {len(self.jobs.keys())} jobs in {self.app.data_dir + '/jobs.compact'}\"\n\n    @export(mod_name=Name, name='instance', version=version)\n    def get_instance(self):\n        return self\n\n    @export(mod_name=Name, name='start', version=version)\n    def start_instance(self):\n        return self.start()\n\n    @export(mod_name=Name, name='stop', version=version)\n    def stop_instance(self):\n        return self.stop()\n\n    @export(mod_name=Name, name='cancel', version=version)\n    def cancel_instance(self, job_id):\n        return self.cancel_job(job_id)\n\n    @export(mod_name=Name, name='dealt', version=version)\n    def dealt_instance(self, job_id):\n        return self.del_job(job_id)\n\n    @export(mod_name=Name, name='add', version=version)\n    def register_instance(self, job_data: dict):\n        \"\"\"\n        example dicts :\n            -----------\n            {\n                \"job_id\": \"job0\",\n                \"second\": 0,\n                \"func\": None,\n                \"job\": None,\n                \"time_passer\": None,\n                \"object_name\": \"tb_job_fuction\",\n                \"receive_job\": False,\n                \"save\": False,\n                \"max_live\": True,\n                # just lev it out \"serializer\": serializer_default,\n                \"args\": [],\n                \"kwargs\": {},\n            }\n\n            job_id : str\n                id for the job for management\n            second (optional): int\n                The time interval in seconds between each call of the job.\n            func (optional): Callable or str\n                The function to be executed as the job.\n            job (optional):  schedule.Job\n                An existing job object from the schedule library.\n            time_passer (optional):  schedule.Job\n                A job without a function, used to specify the time interval.\n            object_name (optional): str\n                The name of the object containing in the 'func' var to be executed.\n            receive_job (optional): bool\n                A flag indicating whether the job should be received from an object from 'func' var.\n            save (optional): bool\n                A flag indicating whether the job should be saved.\n            max_live (optional): bool\n                A flag indicating whether the job should have a maximum live time.\n            serializer (optional): bool\n                json pickel or dill must have a dumps fuction\n            *args, **kwargs (optional):\n                Additional arguments to be passed to the job function.\n\n\n        Parameters\n            ----------\n           job_data : dict\n\n        example usage\n            ----------\n            `python\n\n            `\n\n    \"\"\"\n        if job_data is None:\n            self.app.logger.error(\"No job data provided\")\n            return None\n        job_id = job_data[\"job_id\"]\n        second = job_data.get(\"second\", 0)\n        func = job_data.get(\"func\")\n        job = job_data.get(\"job\")\n        time_passer = job_data.get(\"time_passer\")\n        object_name = job_data.get(\"object_name\", \"tb_job_fuction\")\n        receive_job = job_data.get(\"receive_job\", False)\n        save = job_data.get(\"save\", False)\n        max_live = job_data.get(\"max_live\", True)\n        serializer = job_data.get(\"serializer\", serializer_default)\n        args = job_data.get(\"args\", ())\n        kwargs = job_data.get(\"kwargs\", {})\n\n        return self.register_job(\n            job_id=job_id,\n            second=second,\n            func=func,\n            job=job,\n            time_passer=time_passer,\n            object_name=object_name,\n            receive_job=receive_job,\n            save=save,\n            max_live=max_live,\n            serializer=serializer,\n            args=args,\n            kwargs=kwargs\n        )\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.SchedulerManager.Tools.register_instance","title":"<code>register_instance(job_data)</code>","text":"example dicts <p>{     \"job_id\": \"job0\",     \"second\": 0,     \"func\": None,     \"job\": None,     \"time_passer\": None,     \"object_name\": \"tb_job_fuction\",     \"receive_job\": False,     \"save\": False,     \"max_live\": True,     # just lev it out \"serializer\": serializer_default,     \"args\": [],     \"kwargs\": {}, }</p> <p>job_id : str     id for the job for management second (optional): int     The time interval in seconds between each call of the job. func (optional): Callable or str     The function to be executed as the job. job (optional):  schedule.Job     An existing job object from the schedule library. time_passer (optional):  schedule.Job     A job without a function, used to specify the time interval. object_name (optional): str     The name of the object containing in the 'func' var to be executed. receive_job (optional): bool     A flag indicating whether the job should be received from an object from 'func' var. save (optional): bool     A flag indicating whether the job should be saved. max_live (optional): bool     A flag indicating whether the job should have a maximum live time. serializer (optional): bool     json pickel or dill must have a dumps fuction args, *kwargs (optional):     Additional arguments to be passed to the job function.</p> <p>Parameters     ----------    job_data : dict</p> <p>example usage     ----------     `python</p> <pre><code>`\n</code></pre> Source code in <code>toolboxv2/mods/SchedulerManager.py</code> <pre><code>@export(mod_name=Name, name='add', version=version)\ndef register_instance(self, job_data: dict):\n    \"\"\"\n    example dicts :\n        -----------\n        {\n            \"job_id\": \"job0\",\n            \"second\": 0,\n            \"func\": None,\n            \"job\": None,\n            \"time_passer\": None,\n            \"object_name\": \"tb_job_fuction\",\n            \"receive_job\": False,\n            \"save\": False,\n            \"max_live\": True,\n            # just lev it out \"serializer\": serializer_default,\n            \"args\": [],\n            \"kwargs\": {},\n        }\n\n        job_id : str\n            id for the job for management\n        second (optional): int\n            The time interval in seconds between each call of the job.\n        func (optional): Callable or str\n            The function to be executed as the job.\n        job (optional):  schedule.Job\n            An existing job object from the schedule library.\n        time_passer (optional):  schedule.Job\n            A job without a function, used to specify the time interval.\n        object_name (optional): str\n            The name of the object containing in the 'func' var to be executed.\n        receive_job (optional): bool\n            A flag indicating whether the job should be received from an object from 'func' var.\n        save (optional): bool\n            A flag indicating whether the job should be saved.\n        max_live (optional): bool\n            A flag indicating whether the job should have a maximum live time.\n        serializer (optional): bool\n            json pickel or dill must have a dumps fuction\n        *args, **kwargs (optional):\n            Additional arguments to be passed to the job function.\n\n\n    Parameters\n        ----------\n       job_data : dict\n\n    example usage\n        ----------\n        `python\n\n        `\n\n\"\"\"\n    if job_data is None:\n        self.app.logger.error(\"No job data provided\")\n        return None\n    job_id = job_data[\"job_id\"]\n    second = job_data.get(\"second\", 0)\n    func = job_data.get(\"func\")\n    job = job_data.get(\"job\")\n    time_passer = job_data.get(\"time_passer\")\n    object_name = job_data.get(\"object_name\", \"tb_job_fuction\")\n    receive_job = job_data.get(\"receive_job\", False)\n    save = job_data.get(\"save\", False)\n    max_live = job_data.get(\"max_live\", True)\n    serializer = job_data.get(\"serializer\", serializer_default)\n    args = job_data.get(\"args\", ())\n    kwargs = job_data.get(\"kwargs\", {})\n\n    return self.register_job(\n        job_id=job_id,\n        second=second,\n        func=func,\n        job=job,\n        time_passer=time_passer,\n        object_name=object_name,\n        receive_job=receive_job,\n        save=save,\n        max_live=max_live,\n        serializer=serializer,\n        args=args,\n        kwargs=kwargs\n    )\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.SocketManager","title":"<code>SocketManager</code>","text":"<p>The SocketManager Supports 2 types of connections 1. Client Server 2. Peer to Peer</p>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker","title":"<code>TruthSeeker</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.arXivCrawler","title":"<code>arXivCrawler</code>","text":"<p>ArXiv Crawler for TruthSeeker. Main module for processing research queries.</p>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.arXivCrawler.ArXivPDFProcessor","title":"<code>ArXivPDFProcessor</code>","text":"<p>Main processor for research queries. This is a wrapper around the new ResearchProcessor for backward compatibility.</p> Source code in <code>toolboxv2/mods/TruthSeeker/arXivCrawler.py</code> <pre><code>class ArXivPDFProcessor:\n    \"\"\"\n    Main processor for research queries.\n    This is a wrapper around the new ResearchProcessor for backward compatibility.\n    \"\"\"\n    def __init__(self,\n                 query: str,\n                 tools,\n                 chunk_size: int = 1_000_000,\n                 overlap: int = 2_000,\n                 max_workers=None,\n                 num_search_result_per_query=6,\n                 max_search=6,\n                 download_dir=\"pdfs\",\n                 callback=None,\n                 num_workers=None):\n        \"\"\"Initialize the ArXiv PDF processor.\n\n        Args:\n            query: Research query\n            tools: Tools module\n            chunk_size: Size of text chunks for processing\n            overlap: Overlap between chunks\n            max_workers: Maximum number of worker threads\n            num_search_result_per_query: Number of search results per query\n            max_search: Maximum number of search queries\n            download_dir: Directory to save downloaded files\n            callback: Callback function for status updates\n            num_workers: Number of worker threads\n        \"\"\"\n        # Create the new research processor\n        self.processor = ResearchProcessor(\n            query=query,\n            tools=tools,\n            chunk_size=chunk_size,\n            overlap=overlap,\n            max_workers=max_workers,\n            num_search_result_per_query=num_search_result_per_query,\n            max_search=max_search,\n            download_dir=download_dir,\n            callback=callback,\n            num_workers=num_workers\n        )\n\n        # Copy attributes for backward compatibility\n        self.insights_generated = False\n        self.queries_generated = False\n        self.query = query\n        self.tools = tools\n        self.mem = tools.get_memory()\n        self.chunk_size = chunk_size\n        self.overlap = overlap\n        self.max_workers = max_workers\n        self.nsrpq = num_search_result_per_query\n        self.max_search = max_search\n        self.download_dir = download_dir\n        self.parser = RobustPDFDownloader(download_dir=download_dir)\n        self.callback = callback if callback is not None else lambda status: None\n        self.mem_name = None\n        self.current_session = None\n        self.all_ref_papers = 0\n        self.last_insights_list = None\n        self.all_texts_len = 0\n        self.f_texts_len = 0\n        self.s_id = str(uuid.uuid4())\n        self.semantic_model = self.processor.semantic_model\n        self._query_progress = {}\n        self._progress_lock = threading.Lock()\n        self.num_workers = self.processor.num_workers\n\n    def _update_global_progress(self) -&gt; float:\n        \"\"\"Calculate overall progress considering all processing phases.\"\"\"\n        return self.processor._update_global_progress()\n\n    async def search_and_process_papers(self, queries: list[str]) -&gt; list[Paper]:\n        \"\"\"Search for and process papers based on queries.\n\n        Args:\n            queries: List of search queries\n\n        Returns:\n            List of processed papers\n        \"\"\"\n        # Use the new processor to search and process papers\n        unified_papers = await self.processor.search_and_process_papers(queries)\n\n        # Convert UnifiedPaper objects to Paper objects for backward compatibility\n        papers = []\n        for paper in unified_papers:\n            if paper.source == \"arxiv\":\n                # Convert to the old Paper format\n                arxiv_paper = Paper(\n                    title=paper.title,\n                    authors=paper.authors,\n                    summary=paper.summary,\n                    url=paper.url,\n                    pdf_url=paper.pdf_url,\n                    published=paper.published,\n                    updated=paper.source_specific_data.get(\"updated\", \"\"),\n                    categories=paper.source_specific_data.get(\"categories\", []),\n                    paper_id=paper.paper_id\n                )\n                papers.append(arxiv_paper)\n\n        # Update attributes for backward compatibility\n        self.all_ref_papers = self.processor.all_ref_papers\n        self.all_texts_len = self.processor.all_texts_len\n        self.f_texts_len = self.processor.f_texts_len\n\n        return papers\n\n    def send_status(self, step: str, progress: float = None, additional_info: str = \"\"):\n        \"\"\"Send status update via callback.\"\"\"\n        if progress is None:\n            progress = self._update_global_progress()\n        self.callback({\n            \"step\": step,\n            \"progress\": progress,\n            \"info\": additional_info\n        })\n\n    def generate_queries(self) -&gt; list[str]:\n        self.send_status(\"Generating search queries\")\n        self.queries_generated = False\n\n        class ArXivQueries(BaseModel):\n            queries: list[str] = Field(..., description=\"List of ArXiv search queries (en)\")\n\n        try:\n            query_generator: ArXivQueries = self.tools.format_class(\n                ArXivQueries,\n                f\"Generate a list of precise ArXiv search queries to comprehensively address: {self.query}\"\n            )\n            queries = [self.query] + query_generator[\"queries\"]\n        except Exception:\n            self.send_status(\"Error generating queries\", additional_info=\"Using default query.\")\n            queries = [self.query]\n\n        if len(queries[:self.max_search]) &gt; 0:\n            self.queries_generated = True\n        return queries[:self.max_search]\n\n    def init_process_papers(self):\n        self.mem.create_memory(self.mem_name, model_config={\"model_name\": \"anthropic/claude-3-5-haiku-20241022\"})\n        self.send_status(\"Memory initialized\")\n\n\n    async def generate_insights(self, queries) -&gt; dict:\n        self.send_status(\"Generating insights\")\n        query = self.query\n        # max_it = 0\n        results = await self.mem.query(query=query, memory_names=self.mem_name, unified_retrieve=True, query_params={\n            \"max_sentences\": 25})\n        #query = queries[min(len(queries)-1, max_it)]\n\n        self.insights_generated = True\n        self.send_status(\"Insights generated\", progress=1.0)\n        return results\n\n    async def extra_query(self, query, query_params=None, unified_retrieve=True):\n        self.send_status(\"Processing follow-up query\", progress=0.5)\n        results = await self.mem.query(query=query, memory_names=self.mem_name,\n                                                      query_params=query_params, unified_retrieve=unified_retrieve)\n        self.send_status(\"Processing follow-up query Done\", progress=1)\n        return results\n\n    def generate_mem_name(self):\n        class UniqueMemoryName(BaseModel):\n            \"\"\"unique memory name based on the user query\"\"\"\n            name: str\n        return self.tools.get_agent(\"thinkm\").format_class(UniqueMemoryName, self.query).get('name', '_'.join(self.query.split(\" \")[:3]))\n\n    def initialize(self, session_id, second=False):\n        self.current_session = session_id\n        self.insights_generated = False\n        self.queries_generated = False\n        if second:\n            return\n        self.mem_name = self.generate_mem_name().strip().replace(\"\\n\", '') + '_' + session_id\n        self.init_process_papers()\n\n    async def process(self, query=None) -&gt; tuple[list[Paper], dict]:\n        if query is not None:\n            self.query = query\n        self.send_status(\"Starting research process\")\n        t0 = time.perf_counter()\n        self.initialize(self.s_id, query is not None)\n\n        queries = self.generate_queries()\n\n        papers = await self.search_and_process_papers(queries)\n\n        if len(papers) == 0:\n            class UserQuery(BaseModel):\n                \"\"\"Fix all typos and clear the original user query\"\"\"\n                new_query: str\n            self.query= self.tools.format_class(\n                UserQuery,\n                self.query\n            )[\"new_query\"]\n            queries = self.generate_queries()\n            papers = await self.search_and_process_papers(queries)\n\n        insights = await self.generate_insights(queries)\n\n        elapsed_time = time.perf_counter() - t0\n        self.send_status(\"Process complete\", progress=1.0,\n                         additional_info=f\"Total time: {elapsed_time:.2f}s, Papers analyzed: {len(papers)}/{self.all_ref_papers}\")\n\n        return papers, insights\n\n    @staticmethod\n    def estimate_processing_metrics(query_length: int, **config) -&gt; (float, float):\n        \"\"\"Return estimated time (seconds) and price for processing.\"\"\"\n        total_papers = config['max_search'] * config['num_search_result_per_query']\n        median_text_length = 100000  # 10 pages * 10000 characters\n\n        # Estimated chunks to process\n        total_chunks = total_papers * (median_text_length / config['chunk_size']) + 1 / config['overlap']\n        processed_chunks = total_chunks * 0.45\n        total_chars = TextSplitter(config['chunk_size'],\n                     config['overlap']\n                     ).approximate(config['chunk_size'] * processed_chunks)\n        # Time estimation (seconds)\n        .75 / config['chunk_size']  # Hypothetical time per chunk in seconds\n        w = (config.get('num_workers', 16) if config.get('num_workers', 16) is not None else 16 / 10)\n        # Processing_ time - Insights Genration - Insights Query   -   Indexing Time     -    Download Time     -       workers   -   Query Genration time - Ui - Init Db\n        estimated_time = ((8+total_papers*0.012)+(total_chunks/20000) * .005 + (total_chunks/2) * .0003 + total_papers * 2.8 ) / w + (0.25 * config['max_search']) + 6 + 4\n\n        price_per_char = 0.0000012525\n        price_per_t_chunk =  total_chars * price_per_char\n        estimated_price = price_per_t_chunk ** 1.7\n\n        # estimated_price = 0 if query_length &lt; 420 and estimated_price &lt; 5 else estimated_price\n        if estimated_time &lt; 10:\n            estimated_time = 10\n        if estimated_price &lt; .04:\n            estimated_price = .04\n        return round(estimated_time, 2), round(estimated_price, 4)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.arXivCrawler.ArXivPDFProcessor.__init__","title":"<code>__init__(query, tools, chunk_size=1000000, overlap=2000, max_workers=None, num_search_result_per_query=6, max_search=6, download_dir='pdfs', callback=None, num_workers=None)</code>","text":"<p>Initialize the ArXiv PDF processor.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Research query</p> required <code>tools</code> <p>Tools module</p> required <code>chunk_size</code> <code>int</code> <p>Size of text chunks for processing</p> <code>1000000</code> <code>overlap</code> <code>int</code> <p>Overlap between chunks</p> <code>2000</code> <code>max_workers</code> <p>Maximum number of worker threads</p> <code>None</code> <code>num_search_result_per_query</code> <p>Number of search results per query</p> <code>6</code> <code>max_search</code> <p>Maximum number of search queries</p> <code>6</code> <code>download_dir</code> <p>Directory to save downloaded files</p> <code>'pdfs'</code> <code>callback</code> <p>Callback function for status updates</p> <code>None</code> <code>num_workers</code> <p>Number of worker threads</p> <code>None</code> Source code in <code>toolboxv2/mods/TruthSeeker/arXivCrawler.py</code> <pre><code>def __init__(self,\n             query: str,\n             tools,\n             chunk_size: int = 1_000_000,\n             overlap: int = 2_000,\n             max_workers=None,\n             num_search_result_per_query=6,\n             max_search=6,\n             download_dir=\"pdfs\",\n             callback=None,\n             num_workers=None):\n    \"\"\"Initialize the ArXiv PDF processor.\n\n    Args:\n        query: Research query\n        tools: Tools module\n        chunk_size: Size of text chunks for processing\n        overlap: Overlap between chunks\n        max_workers: Maximum number of worker threads\n        num_search_result_per_query: Number of search results per query\n        max_search: Maximum number of search queries\n        download_dir: Directory to save downloaded files\n        callback: Callback function for status updates\n        num_workers: Number of worker threads\n    \"\"\"\n    # Create the new research processor\n    self.processor = ResearchProcessor(\n        query=query,\n        tools=tools,\n        chunk_size=chunk_size,\n        overlap=overlap,\n        max_workers=max_workers,\n        num_search_result_per_query=num_search_result_per_query,\n        max_search=max_search,\n        download_dir=download_dir,\n        callback=callback,\n        num_workers=num_workers\n    )\n\n    # Copy attributes for backward compatibility\n    self.insights_generated = False\n    self.queries_generated = False\n    self.query = query\n    self.tools = tools\n    self.mem = tools.get_memory()\n    self.chunk_size = chunk_size\n    self.overlap = overlap\n    self.max_workers = max_workers\n    self.nsrpq = num_search_result_per_query\n    self.max_search = max_search\n    self.download_dir = download_dir\n    self.parser = RobustPDFDownloader(download_dir=download_dir)\n    self.callback = callback if callback is not None else lambda status: None\n    self.mem_name = None\n    self.current_session = None\n    self.all_ref_papers = 0\n    self.last_insights_list = None\n    self.all_texts_len = 0\n    self.f_texts_len = 0\n    self.s_id = str(uuid.uuid4())\n    self.semantic_model = self.processor.semantic_model\n    self._query_progress = {}\n    self._progress_lock = threading.Lock()\n    self.num_workers = self.processor.num_workers\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.arXivCrawler.ArXivPDFProcessor.estimate_processing_metrics","title":"<code>estimate_processing_metrics(query_length, **config)</code>  <code>staticmethod</code>","text":"<p>Return estimated time (seconds) and price for processing.</p> Source code in <code>toolboxv2/mods/TruthSeeker/arXivCrawler.py</code> <pre><code>@staticmethod\ndef estimate_processing_metrics(query_length: int, **config) -&gt; (float, float):\n    \"\"\"Return estimated time (seconds) and price for processing.\"\"\"\n    total_papers = config['max_search'] * config['num_search_result_per_query']\n    median_text_length = 100000  # 10 pages * 10000 characters\n\n    # Estimated chunks to process\n    total_chunks = total_papers * (median_text_length / config['chunk_size']) + 1 / config['overlap']\n    processed_chunks = total_chunks * 0.45\n    total_chars = TextSplitter(config['chunk_size'],\n                 config['overlap']\n                 ).approximate(config['chunk_size'] * processed_chunks)\n    # Time estimation (seconds)\n    .75 / config['chunk_size']  # Hypothetical time per chunk in seconds\n    w = (config.get('num_workers', 16) if config.get('num_workers', 16) is not None else 16 / 10)\n    # Processing_ time - Insights Genration - Insights Query   -   Indexing Time     -    Download Time     -       workers   -   Query Genration time - Ui - Init Db\n    estimated_time = ((8+total_papers*0.012)+(total_chunks/20000) * .005 + (total_chunks/2) * .0003 + total_papers * 2.8 ) / w + (0.25 * config['max_search']) + 6 + 4\n\n    price_per_char = 0.0000012525\n    price_per_t_chunk =  total_chars * price_per_char\n    estimated_price = price_per_t_chunk ** 1.7\n\n    # estimated_price = 0 if query_length &lt; 420 and estimated_price &lt; 5 else estimated_price\n    if estimated_time &lt; 10:\n        estimated_time = 10\n    if estimated_price &lt; .04:\n        estimated_price = .04\n    return round(estimated_time, 2), round(estimated_price, 4)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.arXivCrawler.ArXivPDFProcessor.search_and_process_papers","title":"<code>search_and_process_papers(queries)</code>  <code>async</code>","text":"<p>Search for and process papers based on queries.</p> <p>Parameters:</p> Name Type Description Default <code>queries</code> <code>list[str]</code> <p>List of search queries</p> required <p>Returns:</p> Type Description <code>list[Paper]</code> <p>List of processed papers</p> Source code in <code>toolboxv2/mods/TruthSeeker/arXivCrawler.py</code> <pre><code>async def search_and_process_papers(self, queries: list[str]) -&gt; list[Paper]:\n    \"\"\"Search for and process papers based on queries.\n\n    Args:\n        queries: List of search queries\n\n    Returns:\n        List of processed papers\n    \"\"\"\n    # Use the new processor to search and process papers\n    unified_papers = await self.processor.search_and_process_papers(queries)\n\n    # Convert UnifiedPaper objects to Paper objects for backward compatibility\n    papers = []\n    for paper in unified_papers:\n        if paper.source == \"arxiv\":\n            # Convert to the old Paper format\n            arxiv_paper = Paper(\n                title=paper.title,\n                authors=paper.authors,\n                summary=paper.summary,\n                url=paper.url,\n                pdf_url=paper.pdf_url,\n                published=paper.published,\n                updated=paper.source_specific_data.get(\"updated\", \"\"),\n                categories=paper.source_specific_data.get(\"categories\", []),\n                paper_id=paper.paper_id\n            )\n            papers.append(arxiv_paper)\n\n    # Update attributes for backward compatibility\n    self.all_ref_papers = self.processor.all_ref_papers\n    self.all_texts_len = self.processor.all_texts_len\n    self.f_texts_len = self.processor.f_texts_len\n\n    return papers\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.arXivCrawler.ArXivPDFProcessor.send_status","title":"<code>send_status(step, progress=None, additional_info='')</code>","text":"<p>Send status update via callback.</p> Source code in <code>toolboxv2/mods/TruthSeeker/arXivCrawler.py</code> <pre><code>def send_status(self, step: str, progress: float = None, additional_info: str = \"\"):\n    \"\"\"Send status update via callback.\"\"\"\n    if progress is None:\n        progress = self._update_global_progress()\n    self.callback({\n        \"step\": step,\n        \"progress\": progress,\n        \"info\": additional_info\n    })\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.arXivCrawler.main","title":"<code>main(query='Beste strategien in bretspielen sitler von katar')</code>  <code>async</code>","text":"<p>Main execution function</p> Source code in <code>toolboxv2/mods/TruthSeeker/arXivCrawler.py</code> <pre><code>async def main(query: str = \"Beste strategien in bretspielen sitler von katar\"):\n    \"\"\"Main execution function\"\"\"\n    with Spinner(\"Init Isaa\"):\n        tools = get_app(\"ArXivPDFProcessor\", name=None).get_mod(\"isaa\")\n        tools.init_isaa(build=True)\n    processor = ArXivPDFProcessor(query, tools=tools)\n    papers, insights = await processor.process()\n\n    print(\"Generated Insights:\", insights)\n    print(\"Generated Insights_list:\", processor.last_insights_list)\n    kb = tools.get_memory(processor.mem_name)\n    print(await kb.query_concepts(\"AI\"))\n    print(await kb.retrieve(\"Evaluation metrics for assessing AI Agent performance\"))\n    print(kb.concept_extractor.concept_graph.concepts.keys())\n    kb.vis(output_file=\"insights_graph.html\")\n    kb.save(\"mem.plk\")\n    # await get_app(\"ArXivPDFProcessor\", name=None).a_idle()\n    return insights\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.nGui","title":"<code>nGui</code>","text":"<p>import colorsys import json import time from datetime import datetime, timedelta from queue import Queue from typing import Dict, Union, List, Any</p> <p>from fastapi import Request import os import random from threading import Thread, Event</p> <p>import networkx as nx from dataclasses import asdict</p> <p>from toolboxv2 import get_app from toolboxv2.mods.FastApi.fast_nice import register_nicegui</p> <p>import asyncio</p> <p>from nicegui import ui</p> <p>from pathlib import Path import stripe</p> <p>from toolboxv2.mods.TruthSeeker.arXivCrawler import Paper from toolboxv2.mods.isaa.base.AgentUtils import anything_from_str_to_dict</p>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.nGui--set-your-secret-key-use-environment-variables-in-production","title":"Set your secret key (use environment variables in production!)","text":"<p>stripe.api_key = os.getenv('STRIPE_SECRET_KEY', 'sk_test_YourSecretKey')</p> <p>def create_landing_page():     # Set up dynamic background     ui.query(\"body\").style(\"background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%)\")</p> <pre><code># Main container with enhanced responsive design\nwith ui.column().classes(\n\"w-full max-w-md p-8 rounded-3xl shadow-2xl \"\n\"items-center self-center mx-auto my-8\"\n):\n    # Advanced styling for glass-morphism effect\n    ui.query(\".nicegui-column\").style(\"\"\"\n    background: rgba(255, 255, 255, 0.05);\n    backdrop-filter: blur(12px);\n    border: 1px solid rgba(255, 255, 255, 0.1);\n    transition: all 0.3s ease-in-out;\n    \"\"\")\n\n    # Animated logo/brand icon\n    with ui.element(\"div\").classes(\"animate-fadeIn\"):\n        ui.icon(\"science\").classes(\n        \"text-7xl mb-6 text-primary \"\n        \"transform hover:scale-110 transition-transform\"\n        )\n\n    # Enhanced typography for title\n    ui.label(\"TruthSeeker\").classes(\n    \"text-5xl font-black text-center \"\n    \"text-primary mb-2 animate-slideDown\"\n    )\n\n    # Stylized subtitle with brand message\n    ui.label(\"Precision. Discovery. Insights.\").classes(\n    \"text-xl font-medium text-center \"\n    \"mb-10 animate-fadeIn\"\n    )\n\n    # Button container for consistent spacing\n    ui.button(\n    \"Start Research\",\n    on_click=lambda: ui.navigate.to(\"/open-Seeker.seek\")\n    ).classes(\n    \"w-full px-6 py-4 text-lg font-bold \"\n    \"bg-primary hover:bg-primary-dark \"\n    \"transform hover:-translate-y-0.5 \"\n    \"transition-all duration-300 ease-in-out \"\n    \"rounded-xl shadow-lg animate-slideUp\"\n    )\n\n    # Navigation links container\n    with ui.element(\"div\").classes(\"mt-8 space-y-3 text-center\"):\n        ui.link(\n        \"Demo video\",\n        ).classes(\n        \"block text-lg text-gray-200 hover:text-primary \"\n        \"transition-colors duration-300 animate-fadeIn\"\n        ).on(\"click\", lambda: ui.navigate.to(\"/open-Seeker.demo\"))\n\n        ui.link(\n        \"About Us\",\n        ).classes(\n        \"block text-lg text-gray-400 hover:text-primary \"\n        \"transition-colors duration-300 animate-fadeIn\"\n        ).on(\"click\", lambda: ui.navigate.to(\"/open-Seeker.about\"))\n</code></pre> <p>def create_video_demo():     with ui.card().classes('w-full max-w-3xl mx-auto').style(         'background: var(--background-color); color: var(--text-color)'):         # Video container with responsive aspect ratio         with ui.element('div').classes('relative w-full aspect-video'):             video = ui.video('../api/TruthSeeker/video').classes('w-full h-full object-cover')</p> <pre><code>        # Custom controls overlay\n        with ui.element('div').classes('absolute bottom-0 left-0 right-0 bg-black/50 p-2'):\n            with ui.row().classes('items-center gap-2'):\n                #play_btn = ui.button(icon='play_arrow', on_click=lambda: video.props('playing=true'))\n                #pause_btn = ui.button(icon='pause', on_click=lambda: video.props('playing=false'))\n                ui.slider(min=0, max=100, value=0).classes('w-full').bind_value(video, 'time')\n                #mute_btn = ui.button(icon='volume_up', on_click=lambda: video.props('muted=!muted'))\n                #fullscreen_btn = ui.button(icon='fullscreen', on_click=lambda: video.props('fullscreen=true'))\n\n\n    # Video description\n    ui.markdown('Walkthrough of TruthSeeker features and capabilities.')\n    # Back to Home Button\n    ui.button('Back to Home', on_click=lambda: ui.navigate.to('/open-Seeker')).classes(\n        'mt-6 w-full bg-primary text-white hover:opacity-90'\n    )\n\nreturn video\n</code></pre> <p>def create_about_page():     \"\"\"Create a comprehensive About page for TruthSeeker\"\"\"     with ui.column().classes('w-full max-w-4xl mx-auto p-6'):         # Page Header         ui.label('About TruthSeeker').classes('text-4xl font-bold text-primary mb-6')</p> <pre><code>    # Mission Statement\n    with ui.card().classes('w-full mb-6').style(\n        'background: var(--background-color); color: var(--text-color); padding: 20px; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1);'\n    ):\n        ui.label('Our Mission').classes('text-2xl font-semibold text-primary mb-4')\n        ui.markdown(\"\"\"\n            TruthSeeker aims to democratize access to scientific knowledge,\n            transforming complex academic research into comprehensible insights.\n            We bridge the gap between raw data and meaningful understanding.\n        \"\"\").classes('text-lg').style('color: var(--text-color);')\n\n    # Core Technologies\n    with ui.card().classes('w-full mb-6').style(\n        'background: var(--background-color); color: var(--text-color); padding: 20px; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1);'\n    ):\n        ui.label('Core Technologies').classes('text-2xl font-semibold text-primary mb-4')\n        with ui.row().classes('gap-4 w-full'):\n            with ui.column().classes('flex-1 text-center'):\n                ui.icon('search').classes('text-4xl text-primary mb-2')\n                ui.label('Advanced Query Processing').classes('font-bold')\n                ui.markdown('Intelligent algorithms that extract nuanced research insights.').style(\n                    'color: var(--text-color);')\n            with ui.column().classes('flex-1 text-center'):\n                ui.icon('analytics').classes('text-4xl text-primary mb-2')\n                ui.label('Semantic Analysis').classes('font-bold')\n                ui.markdown('Deep learning models for comprehensive research verification.').style(\n                    'color: var(--text-color);')\n            with ui.column().classes('flex-1 text-center'):\n                ui.icon('verified').classes('text-4xl text-primary mb-2')\n                ui.label('Research Validation').classes('font-bold')\n                ui.markdown('Multi-layered verification of academic sources.').style('color: var(--text-color);')\n    # Research Process\n    with ui.card().classes('w-full').style('background: var(--background-color);color: var(--text-color);'):\n        ui.label('Research Discovery Process').classes('text-2xl font-semibold text-primary mb-4')\n        with ui.card().classes('q-pa-md q-mx-auto').style(\n            'max-width: 800px; background: var(--background-color); border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1);'\n        ) as card:\n            ui.markdown(\"# Research Workflow\").style(\n                \"color: var(--primary-color); text-align: center; margin-bottom: 20px;\")\n            ui.markdown(\n                \"\"\"\n                Welcome to TruthSeeker\u2019s interactive research assistant. Follow the steps below to transform your initial inquiry into a refined, actionable insight.\n                \"\"\"\n            ).style(\"color: var(--text-color); text-align: center; margin-bottom: 30px;\")\n\n            # The stepper component\n            with ui.stepper().style('background: var(--background-color); color: var(--text-color);') as stepper:\n                # Step 1: Query Initialization\n                with ui.step('Query Initialization'):\n                    ui.markdown(\"### Step 1: Query Initialization\").style(\"color: var(--primary-color);\")\n                    ui.markdown(\n                        \"\"\"\n                        Begin by entering your research question or selecting from popular academic domains.\n                        This sets the direction for our semantic analysis engine.\n                        \"\"\"\n                    ).style(\"color: var(--text-color); margin-bottom: 20px;\")\n                    with ui.stepper_navigation():\n                        ui.button('Next', on_click=stepper.next).props('rounded color=primary')\n\n                # Step 2: Semantic Search\n                with ui.step('Semantic Search'):\n                    ui.markdown(\"### Step 2: Semantic Search\").style(\"color: var(--primary-color);\")\n                    ui.markdown(\n                        \"\"\"\n                        Our advanced algorithms now process your input to generate context-rich queries.\n                        This stage refines the search context by understanding the deeper intent behind your question.\n                        \"\"\"\n                    ).style(\"color: var(--text-color); margin-bottom: 20px;\")\n                    with ui.stepper_navigation():\n                        ui.button('Back', on_click=stepper.previous).props('flat')\n                        ui.button('Next', on_click=stepper.next).props('rounded color=primary')\n\n                # Step 3: Document Analysis\n                with ui.step('Document Analysis'):\n                    ui.markdown(\"### Step 3: Document Analysis\").style(\"color: var(--primary-color);\")\n                    ui.markdown(\n                        \"\"\"\n                        The system then dives into a detailed analysis of academic papers, parsing content to extract key insights and connections.\n                        This ensures that even subtle but crucial information is captured.\n                        \"\"\"\n                    ).style(\"color: var(--text-color); margin-bottom: 20px;\")\n                    with ui.stepper_navigation():\n                        ui.button('Back', on_click=stepper.previous).props('flat')\n                        ui.button('Next', on_click=stepper.next).props('rounded color=primary')\n\n                # Step 4: Insight Generation\n                with ui.step('Insight Generation'):\n                    ui.markdown(\"### Step 4: Insight Generation\").style(\"color: var(--primary-color);\")\n                    ui.markdown(\n                        \"\"\"\n                        Finally, we synthesize the analyzed data into clear, actionable research summaries.\n                        These insights empower you with concise guidance to drive further inquiry or practical application.\n                        \"\"\"\n                    ).style(\"color: var(--text-color); margin-bottom: 20px;\")\n                    with ui.stepper_navigation():\n                        ui.button('Back', on_click=stepper.previous).props('flat')\n\n    # Back to Home Button\n    ui.button('Back to Home', on_click=lambda: ui.navigate.to('/open-Seeker')).classes(\n        'mt-6 w-full bg-primary text-white hover:opacity-90'\n    )\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.nGui--dummy-implementierung-fur-get_tools","title":"Dummy-Implementierung f\u00fcr get_tools()","text":"<p>def get_tools():     \"\"\"     Hier solltest du dein richtiges Werkzeug-Objekt zur\u00fcckliefern.     In diesem Beispiel gehen wir davon aus, dass du \u00fcber eine Funktion wie get_app verf\u00fcgst.     \"\"\"     return get_app(\"ArXivPDFProcessor\", name=None).get_mod(\"isaa\")</p> <p>def create_graph_tab(processor_instance: Dict, graph_ui: ui.element, main_ui: ui.element):     \"\"\"Create and update the graph visualization\"\"\"</p> <pre><code># Get HTML graph from processor\n_html_content = processor_instance[\"instance\"].tools.get_memory(processor_instance[\"instance\"].mem_name)\nhtml_content = \"\" if isinstance(_html_content, list) else _html_content.vis(get_output_html=True)\n\n# Ensure static directory exists\nstatic_dir = Path('dist/static')\nstatic_dir.mkdir(exist_ok=True)\n\n# Save HTML to static file\ngraph_file = static_dir / f'graph{processor_instance[\"instance\"].mem_name}.html'\n# Save HTML to static file with added fullscreen functionality\n\n# Add fullscreen JavaScript\ngraph_file.write_text(html_content, encoding='utf-8')\n\nwith main_ui:\n    # Clear existing content except fullscreen button\n    graph_ui.clear()\n\n    with graph_ui:\n        ui.html(f\"\"\"\n\n            &lt;iframe\n                 src=\"/static/graph{processor_instance[\"instance\"].mem_name}.html\"\n                style=\"width: 100%; height: 800px; border: none; background: #1a1a1a;\"\n                &gt;\n            &lt;/iframe&gt;\n        \"\"\").classes('w-full h-full')\n</code></pre> <p>is_init = [False]</p>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.nGui---database-setup-","title":"--- Database Setup ---","text":"<p>def get_db():     db = get_app().get_mod(\"DB\")     if not is_init[0]:         is_init[0] = True         db.edit_cli(\"LD\")         db.initialize_database()     return db</p> <p>import pickle</p>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.nGui---session-state-management-","title":"--- Session State Management ---","text":"<p>def get_user_state(session_id: str, is_new=False) -&gt; dict:     db = get_db()     state_ = {         'balance': .5,         'last_reset': datetime.utcnow().isoformat(),         'research_history': [],         'payment_id': '',     }     if session_id is None:         state_['balance'] *= -1         if is_new:             return state_, True         return state_     state = db.get(f\"TruthSeeker::session:{session_id}\")     if state.get() is None:         state = state_         if is_new:             return state_, True     else:         try:             state = pickle.loads(state.get())         except Exception as e:             print(e)             state = {         'balance': 0.04,         'last_reset': datetime.utcnow().isoformat(),         'research_history': [\"Sorry we had an error recreating your state\"],         'payment_id': '',             }             if is_new:                 return state, True     if is_new:         return state, False     return state</p> <p>def save_user_state(session_id: str, state: dict):     db = get_db()     print(\"Saving state\")     db.set(f\"TruthSeeker::session:{session_id}\", pickle.dumps(state)).print()</p> <p>def delete_user_state(session_id: str):     db = get_db()     print(\"Saving state\")     db.delete(f\"TruthSeeker::session:{session_id}\").print()</p> <p>def reset_daily_balance(state: dict, valid=False) -&gt; dict:     now = datetime.utcnow()     last_reset = datetime.fromisoformat(state.get('last_reset', now.isoformat()))     if now - last_reset &gt; timedelta(hours=24):         state['balance'] = max(state.get('balance', 1.6 if valid else 0.5), 1.6 if valid else 0.5)         state['last_reset'] = now.isoformat()     return state</p> class MemoryResultsDisplay <p>def init(self, results: List[Dict[str, Any]], main_ui: ui.element):     self.results = results     self.main_ui = main_ui     self.setup_ui()</p> <p>def setup_ui(self):     \"\"\"Set up the main UI for displaying memory results\"\"\"     with self.main_ui:         self.main_ui.clear()         with ui.column().classes('w-full'):             for mem_result in self.results:                 self.create_memory_card(mem_result)</p> <p>def create_memory_card(self, mem_result: Dict[str, Any]):     \"\"\"Create a card for each memory result\"\"\"     result = mem_result.get(\"result\", {})     with self.main_ui:         if isinstance(result, dict):             self.display_dict_result(result)         elif hasattr(result, 'overview'):  # Assuming RetrievalResult type             self.display_retrieval_result(result)         else:             ui.label(\"Unsupported result type\").classes('--text-color:error')</p> <p>def display_dict_result(self, result: Dict[str, Any]):     \"\"\"Display dictionary-based result with collapsible sections\"\"\"     # Summary Section     summary = result.get(\"summary\", {})     if isinstance(summary, str):         try:             summary = json.loads(summary[:-1])         except json.JSONDecodeError:             summary = {\"error\": \"Could not parse summary\"}</p> <pre><code># Raw Results Section\nraw_results = result.get(\"raw_results\", {})\nif isinstance(raw_results, str):\n    try:\n        raw_results = json.loads(raw_results[:-1])\n    except json.JSONDecodeError:\n        raw_results = {\"error\": \"Could not parse raw results\"}\n\n# Metadata Section\nmetadata = result.get(\"metadata\", {})\nwith self.main_ui:\n    # Collapsible Sections\n    with ui.column().classes('w-full space-y-2').style(\"max-width: 100%;\"):\n        # Summary Section\n        with ui.expansion('Summary', icon='description').classes('w-full') as se:\n            self.display_nested_data(summary, main_ui=se)\n\n        # Raw Results Section\n        with ui.expansion('Raw Results', icon='work').classes('w-full') as re:\n            self.display_nested_data(raw_results, main_ui=re)\n\n        # Metadata Section\n        if metadata:\n            with ui.expansion('Metadata', icon='info').classes('w-full'):\n                ui.markdown(f\"```json\n</code></pre> <p>{json.dumps(metadata, indent=2)} ```\").style(\"max-width: 100%;\")</p> <pre><code>def display_retrieval_result(self, result):\n    \"\"\"Display retrieval result with detailed sections\"\"\"\n    with self.main_ui:\n        with ui.column().classes('w-full space-y-4').style(\"max-width: 100%;\"):\n            # Overview Section\n            with ui.expansion('Overview', icon='visibility').classes('w-full') as ov:\n                for overview_item in result.overview:\n                    if isinstance(overview_item, str):\n                        overview_item = json.loads(overview_item)\n                    self.display_nested_data(overview_item, main_ui=ov)\n\n            # Details Section\n            with ui.expansion('Details', icon='article').classes('w-full'):\n                for chunk in result.details:\n                    with ui.card().classes('w-full p-3 mb-2').style(\"background: var(--background-color)\"):\n                        ui.label(chunk.text).classes('font-medium mb-2 --text-color:secondary')\n\n                        with ui.row().classes('w-full justify-between').style(\"background: var(--background-color)\"):\n                            ui.label(f\"Embedding Shape: {chunk.embedding.shape}\").classes('text-sm')\n                            ui.label(f\"Content Hash: {chunk.content_hash}\").classes('text-sm')\n\n                        if chunk.cluster_id is not None:\n                            ui.label(f\"Cluster ID: {chunk.cluster_id}\").classes('text-sm')\n\n            # Cross References Section\n            with ui.expansion('Cross References', icon='link').classes('w-full'):\n                for topic, chunks in result.cross_references.items():\n                    with ui.card().classes('w-full p-3 mb-2').style(\"background: var(--background-color)\"):\n                        ui.label(topic).classes('font-semibold mb-2 --text-color:secondary')\n                        for chunk in chunks:\n                            ui.label(chunk.text).classes('text-sm mb-1')\n\ndef display_nested_data(self, data: Union[Dict, List], indent: int = 0, main_ui=None):\n    \"\"\"Recursively display nested dictionary or list data\"\"\"\n    with (self.main_ui if main_ui is None else main_ui):\n        if isinstance(data, dict):\n            with ui.column().classes(f'ml-{indent * 2}').style(\"max-width: 100%;\"):\n                for key, value in data.items():\n                    with ui.row().classes('items-center'):\n                        ui.label(f\"{key}:\").classes('font-bold mr-2 --text-color:primary')\n                        if isinstance(value, list):\n                            if key == \"main_chunks\":\n                                continue\n                            self.display_nested_data(value, indent + 1, main_ui=main_ui)\n                        if isinstance(value, dict):\n                            ui.markdown(f\"```json\n</code></pre> <p>{json.dumps(value, indent=2)} <code>\").classes(\"break-words w-full\").style(\"max-width: 100%;\")                             else:                                 ui.label(str(value)).classes('--text-color:secondary')             elif isinstance(data, list):                 with ui.column().classes(f'ml-{indent * 2}').style(\"max-width: 100%;\"):                     for item in data:                         if isinstance(item, str):                             item = json.loads(item)                         if isinstance(item, list):                             self.display_nested_data(item, indent + 1, main_ui=main_ui)                         if isinstance(item, dict):                             ui.markdown(f\"</code>json {json.dumps(item, indent=2)} ```\").classes(\"break-words w-full\").style(\"max-width: 100%;\")                         else:                             ui.label(str(item)).classes('--text-color:secondary')</p> <p>def create_followup_section(processor_instance: Dict, main_ui: ui.element, session_id, balance):     main_ui.clear()     with main_ui:         ui.label(\"Query Interface  (1ct)\").classes(\"text-xl font-semibold mb-4\")</p> <pre><code>    # Container for query inputs\n    query_container = ui.column().classes(\"w-full gap-4\")\n    query = \"\"  # Store references to query inputs\n    # Query parameters section\n    with ui.expansion(\"Query Parameters\", icon=\"settings\").classes(\"w-full\") as query_e:\n        with ui.grid(columns=2).classes(\"w-full gap-4\"):\n            k_input = ui.number(\"Results Count (k)\", value=2, min=1, max=20)\n            min_sim = ui.number(\"Min Similarity\", value=.3, min=0, max=1, step=0.1)\n            cross_depth = ui.number(\"Cross Reference Depth\", value=2, min=1, max=5)\n            max_cross = ui.number(\"Max Cross References\", value=10, min=1, max=20)\n            max_sent = ui.number(\"Max Sentences\", value=10, min=1, max=50)\n            unified = ui.switch(\"Unified Retrieve (+3ct)\", value=True)\n\n    # Results display\n    with ui.element(\"div\").classes(\"w-full mt-4\") as results_display:\n        pass\n    results_display = results_display\n    with query_container:\n        query_input = ui.input(\"Query\", placeholder=\"Enter your query...\")                 .classes(\"w-full\")\n    # Control buttons\n    with ui.row().classes(\"w-full gap-4 mt-4\"):\n        ui.button(\"Execute Query\", on_click=lambda: asyncio.create_task(execute_query()))                 .classes(\"bg-green-600 hover:bg-green-700\")\n        ui.button(\"Clear Results\", on_click=lambda: results_display.clear())                 .classes(\"bg-red-600 hover:bg-red-700\")\nquery_input = query_input\n\nasync def execute_query():\n    \"\"\"Execute a single query with parameters\"\"\"\n    nonlocal query_input, results_display, main_ui\n    try:\n        query_text = query_input.value\n        if not query_text.strip():\n            with main_ui:\n                ui.notify(\"No Input\", type=\"warning\")\n            return \"\"\n\n        if not processor_instance.get(\"instance\"):\n            with main_ui:\n                ui.notify(\"No active processor instance\", type=\"warning\")\n            return\n        # Collect parameters\n        params = {\n            \"k\": int(k_input.value),\n            \"min_similarity\": min_sim.value,\n            \"cross_ref_depth\": int(cross_depth.value),\n            \"max_cross_refs\": int(max_cross.value),\n            \"max_sentences\": int(max_sent.value),\n            \"unified\": unified.value\n        }\n        # Construct query parameters\n        query_params = {\n            \"k\": params[\"k\"],\n            \"min_similarity\": params[\"min_similarity\"],\n            \"cross_ref_depth\": params[\"cross_ref_depth\"],\n            \"max_cross_refs\": params[\"max_cross_refs\"],\n            \"max_sentences\": params[\"max_sentences\"]\n        }\n\n        # Execute query\n        results = await processor_instance[\"instance\"].extra_query(\n            query=query_text,\n            query_params=query_params,\n            unified_retrieve=params[\"unified\"]\n        )\n        print(\"results\",results)\n        s = get_user_state(session_id)\n        s['balance'] -= .04 if unified.value else .01\n        save_user_state(session_id, s)\n        with main_ui:\n            balance.set_text(f\"Balance: {s['balance']:.2f}\u20ac\")\n        # Format results\n        with main_ui:\n            with results_display:\n                MemoryResultsDisplay(results, results_display)\n\n    except Exception as e:\n        return f\"Error executing query: {str(e)}\n</code></pre> <p>\"</p> <pre><code># Add initial query input\n</code></pre> <p>online_states = [0] def create_research_interface(Processor):</p> <pre><code>def helpr(request, session: dict):\n\n    state = {'balance':0, 'research_history': []}\n    main_ui = None\n    with ui.column().classes(\"w-full max-w-6xl mx-auto p-6 space-y-6\") as loading:\n        ui.spinner(size='lg')\n        ui.label('Initializing...').classes('ml-2')\n\n    # Container for main content (initially hidden)\n    content = ui.column().classes('hidden')\n\n    # Extract session data before spawning thread\n    session_id = session.get('ID')\n    session_id_h = session.get('IDh')\n    session_rid = request.row.query_params.get('session_id') if hasattr(request, 'row') else request.query_params.get('session_id')\n    session_valid = session.get('valid')\n\n    # Thread communication\n    result_queue = Queue()\n    ready_event = Event()\n\n    def init_background():\n        nonlocal session_id, session_id_h, session_rid, session_valid\n        try:\n            # Original initialization logic\n            _state, is_new = get_user_state(session_id, is_new=True)\n\n            if is_new and session_id_h != \"#0\":\n                _state = get_user_state(session_id_h)\n                save_user_state(session_id, _state)\n                delete_user_state(session_id_h)\n            if session_rid:\n                state_: dict\n                state_, is_new_ = get_user_state(session_rid, is_new=True)\n                if not is_new_:\n                    _state = state_.copy()\n                    state_['payment_id'] = ''\n                    state_['last_reset'] = datetime.utcnow().isoformat()\n                    state_['research_history'] = state_['research_history'][:3]\n                    state_['balance'] = 0\n                    save_user_state(session_id, _state)\n            _state = reset_daily_balance(_state, session_valid)\n            save_user_state(session_id, _state)\n\n            # Send result back to main thread\n            result_queue.put(_state)\n            ready_event.set()\n        except Exception as e:\n            result_queue.put(e)\n            ready_event.set()\n\n        # Start background initialization\n\n    Thread(target=init_background).start()\n\n    def check_ready():\n        nonlocal state\n        if ready_event.is_set():\n            result = result_queue.get()\n\n            # Check if initialization failed\n            if isinstance(result, Exception):\n                loading.clear()\n                with loading:\n                    ui.label(f\"Error during initialization: {str(result)}\").classes('text-red-500')\n                return\n\n            # Get state and build main UI\n            state = result\n            loading.classes('hidden')\n            content.classes(remove='hidden')\n            main_ui.visible = True\n            with main_ui:\n                balance.set_text(f\"Balance: {state['balance']:.2f}\u20ac\")\n                show_history()\n            return  # Stop the timer\n\n        # Check again in 100ms\n        ui.timer(0.1, check_ready, once=True)\n\n    # Start checking for completion\n    check_ready()\n\n    # Wir speichern die aktive Instanz, damit Follow-Up Fragen gestellt werden k\u00f6nnen\n    processor_instance = {\"instance\": None}\n\n    # UI-Elemente als Platzhalter; wir definieren sie sp\u00e4ter in der UI und machen sie so\n    # in den Callback-Funktionen \u00fcber \"nonlocal\" verf\u00fcgbar.\n    overall_progress = None\n    status_label = None\n    results_card = None\n    summary_content = None\n    analysis_content = None\n    references_content = None\n    followup_card = None\n    research_card = None\n    config_cart = None\n    progress_card = None\n    balance = None\n    graph_ui = None\n\n    sr_button = None\n    r_button = None\n    r_text = None\n\n\n    # Global config storage with default values\n    config = {\n        'chunk_size': 21000,\n        'overlap': 600,\n        'num_search_result_per_query': 3,\n        'max_search': 3,\n        'num_workers': None\n    }\n\n    def update_estimates():\n        \"\"\"\n        Dummy estimation based on query length and configuration.\n        (Replace with your own non-linear formula if needed.)\n        \"\"\"\n        query_text = query.value or \"\"\n        query_length = len(query_text)\n        # For example: estimated time scales with chunk size and query length.\n        estimated_time ,estimated_price = Processor.estimate_processing_metrics(query_length, **config)\n        estimated_time *= max(1, online_states[0] * 6)\n        if processor_instance[\"instance\"] is not None:\n            estimated_price += .25\n        if estimated_time &lt; 60:\n            time_str = f\"~{int(estimated_time)}s\"\n        elif estimated_time &lt; 3600:\n            minutes = estimated_time // 60\n            seconds = estimated_time % 60\n            time_str = f\"~{int(minutes)}m {int(seconds)}s\"\n        else:\n            hours = estimated_time // 3600\n            minutes = (estimated_time % 3600) // 60\n            time_str = f\"~{int(hours)}h {int(minutes)}m\"\n        with main_ui:\n            query_length_label.set_text(f\"Total Papers: {config['max_search']*config['num_search_result_per_query']}\")\n            time_label.set_text(f\"Processing Time: {time_str}\")\n            price_label.set_text(f\"Price: {estimated_price:.2f}\u20ac\")\n\n        return estimated_price\n\n    def on_config_change(event):\n        \"\"\"\n        Update the global config based on input changes and recalc estimates.\n        \"\"\"\n        try:\n            config['chunk_size'] = int(chunk_size_input.value)\n        except ValueError:\n            pass\n        try:\n            config['overlap'] = int(overlap_input.value)\n            if config['overlap'] &gt; config['chunk_size'] / 4:\n                config['overlap'] = int(config['chunk_size'] / 4)\n                with main_ui:\n                    overlap_input.value = config['overlap']\n        except ValueError:\n            pass\n        try:\n            config['num_search_result_per_query'] = int(num_search_result_input.value)\n        except ValueError:\n            pass\n        try:\n            config['max_search'] = int(max_search_input.value)\n        except ValueError:\n            pass\n        try:\n            config['num_workers'] = int(num_workers_input.value) if num_workers_input.value != 0 else None\n        except ValueError:\n            config['num_workers'] = None\n\n        update_estimates()\n\n    def on_query_change():\n        update_estimates()\n\n    # Callback, der vom Processor (\u00fcber processor_instance.callback) aufgerufen wird.\n    def update_status(data: dict):\n        nonlocal overall_progress, status_label\n        if not data:\n            return\n        # Aktualisiere den Fortschrittsbalken und den aktuellen Schritt (wenn vorhanden)\n        with main_ui:\n            if isinstance(data, dict):\n                progress = data.get(\"progress\", 0)\n                step = data.get(\"step\", \"Processing...\")\n                overall_progress.value =round( progress ,2) # nicegui.linear_progress erwartet einen Wert zwischen 0 und 1\n                status_label.set_text(f\"{step} {data.get('info','')}\")\n            else:\n                status_label.set_text(f\"{data}\")\n\n    def start_search():\n        nonlocal balance\n\n        async def helper():\n            nonlocal processor_instance, overall_progress, status_label, results_card,                     summary_content, analysis_content,config, references_content, followup_card,sr_button,r_button,r_text\n\n            try:\n                if not validate_inputs():\n                    with main_ui:\n                        state['balance'] += est_price\n                        save_user_state(session_id, state)\n                        balance.set_text(f\"Balance: {state['balance']:.2f}\u20ac\")\n                    return\n                reset_interface()\n                show_progress_indicators()\n\n                query_text = query.value.strip()\n                # Erzeuge das \"tools\"-Objekt (abh\u00e4ngig von deiner konkreten Implementation)\n                tools = get_tools()\n                with main_ui:\n                    research_card.visible = False\n                    config_cart.visible = False\n                    config_section.visible = False\n                    query.set_value(\"\")\n                # Direkt instanziieren: Eine neue ArXivPDFProcessor-Instanz\n                if processor_instance[\"instance\"] is not None:\n                    processor = processor_instance[\"instance\"]\n                    processor.chunk_size = config['chunk_size']\n                    processor.overlap = config['overlap']\n                    processor.num_search_result_per_query = config['num_search_result_per_query']\n                    processor.max_search = config['max_search']\n                    processor.num_workers = config['num_workers']\n                    papers, insights = await processor.process(query_text)\n                else:\n                    processor = Processor(query_text, tools=tools, **config)\n                # Setze den Callback so, dass Updates in der GUI angezeigt werden\n                    processor.callback = update_status\n                    processor_instance[\"instance\"] = processor\n                    papers, insights = await processor.process()\n\n                update_results({\n                    \"papers\": papers,\n                    \"insights\": insights\n                })\n                with main_ui:\n                    research_card.visible = True\n                    config_cart.visible = True\n                    show_history()\n\n            except Exception as e:\n                import traceback\n\n                with main_ui:\n                    update_status({\"progress\": 0, \"step\": \"Error\", \"info\": str(e)})\n                    state['balance'] += est_price\n                    save_user_state(session_id, state)\n                    balance.set_text(f\"Balance: {state['balance']:.2f}\u20ac\")\n                    ui.notify(f\"Error {str(e)})\", type=\"negative\")\n                    research_card.visible = True\n                    config_cart.visible = True\n                    config_section.visible = True\n                print(traceback.format_exc())\n\n        def target():\n            get_app().run_a_from_sync(helper, )\n\n        est_price = update_estimates()\n        if est_price &gt; state['balance']:\n            with main_ui:\n                ui.notify(f\"Insufficient balance. Need \u20ac{est_price:.2f}\", type='negative')\n        else:\n            state['balance'] -= est_price\n            save_user_state(session_id, state)\n            with main_ui:\n                online_states[0] += 1\n                balance.set_text(f\"Balance: {state['balance']:.2f}\u20ac Running Queries: {online_states[0]}\")\n\n            Thread(target=target, daemon=True).start()\n            with main_ui:\n                online_states[0] -= 1\n                balance.set_text(f\"Balance: {get_user_state(session_id)['balance']:.2f}\u20ac\")\n\n\n    def show_history():\n        with config_cart:\n            for idx, entry in enumerate(state['research_history']):\n                with ui.card().classes(\"w-full backdrop-blur-lg bg-white/10 p-4\"):\n                    ui.label(entry['query']).classes('text-sm')\n                    ui.button(\"Open\").on_click(lambda _, i=idx: load_history(i))\n\n    def reset():\n        nonlocal processor_instance, results_card, followup_card, sr_button, r_button, r_text\n        processor_instance[\"instance\"] = None\n        show_progress_indicators()\n        with main_ui:\n            config_cart.visible = False\n            config_section.visible = False\n            followup_card.visible = False\n            results_card.visible = False\n            r_button.visible = False\n            r_text.set_text(\"Research Interface\")\n            sr_button.set_text(\"Start Research\")\n        start_search()\n    # UI-Aufbau\n\n    with ui.column().classes(\"w-full max-w-6xl mx-auto p-6 space-y-6\") as main_ui:\n        balance = ui.label(f\"Balance: {state['balance']:.2f}\u20ac\").classes(\"text-s font-semibold\")\n\n        config_cart = config_cart\n\n        # --- Research Input UI Card ---\n        with ui.card().classes(\"w-full backdrop-blur-lg bg-white/10 p-4\") as research_card:\n            r_text = ui.label(\"Research Interface\").classes(\"text-3xl font-bold mb-4\")\n\n            # Query input section with auto-updating estimates\n            query = ui.input(\"Research Query\",\n                                placeholder=\"Gib hier deine Forschungsfrage ein...\",\n                                value=\"\")                     .classes(\"w-full min-h-[100px]\")                     .on('change', lambda e: on_query_change()).style(\"color: var(--text-color)\")\n\n            # --- Action Buttons ---\n            with ui.row().classes(\"mt-4\"):\n                sr_button =ui.button(\"Start Research\", on_click=start_search)                         .classes(\"bg-blue-600 hover:bg-blue-700 py-3 rounded-lg\")\n                ui.button(\"toggle config\",\n                          on_click=lambda: setattr(config_section, 'visible', not config_section.visible) or show_progress_indicators()).style(\n                    \"color: var(--text-color)\")\n                r_button = ui.button(\"Start new Research\",\n                          on_click=reset).style(\n                    \"color: var(--text-color)\")\n        sr_button = sr_button\n        r_button = r_button\n        r_button.visible = False\n        research_card = research_card\n\n        # --- Options Cart / Configurations ---\n        with ui.card_section().classes(\"w-full backdrop-blur-lg bg-white/10 hidden\") as config_section:\n            ui.separator()\n            ui.label(\"Configuration Options\").classes(\"text-xl font-semibold mt-4 mb-2\")\n            with ui.row():\n                chunk_size_input = ui.number(label=\"Chunk Size\",\n                                             value=config['chunk_size'], format='%.0f', max=64_000, min=1000,\n                                             step=100)                         .on('change', on_config_change).style(\"color: var(--text-color)\")\n                overlap_input = ui.number(label=\"Overlap\",\n                                          value=config['overlap'], format='%.0f', max=6400, min=100, step=50)                         .on('change', on_config_change).style(\"color: var(--text-color)\")\n\n            with ui.row():\n                num_search_result_input = ui.number(label=\"Results per Query\",\n                                                    value=config['num_search_result_per_query'], format='%.0f',\n                                                    min=1, max=100, step=1)                         .on('change', on_config_change).style(\"color: var(--text-color)\")\n                max_search_input = ui.number(label=\"Max Search Queries\",\n                                             value=config['max_search'], format='%.0f', min=1, max=100, step=1)                         .on('change', on_config_change).style(\"color: var(--text-color)\")\n                num_workers_input = ui.number(label=\"Number of Workers (leave empty for default)\",\n                                              value=0, format='%.0f', min=0, max=32, step=1)                         .on('change', on_config_change).style(\"color: var(--text-color)\")\n        config_section = config_section\n        config_section.visible = False\n        # --- Ergebnisse anzeigen ---\n        with ui.card().classes(\"w-full backdrop-blur-lg p-4 bg-white/10\") as results_card:\n            ui.label(\"Research Results\").classes(\"text-xl font-semibold mb-4\")\n            with ui.tabs() as tabs:\n                ui.tab(\"Summary\")\n                ui.tab(\"References\")\n                ui.tab(\"SystemStates\")\n            with ui.tab_panels(tabs, value=\"Summary\").classes(\"w-full\").style(\"background-color: var(--background-color)\"):\n                with ui.tab_panel(\"Summary\"):\n                    summary_content = ui.markdown(\"\").style(\"color : var(--text-color)\")\n                with ui.tab_panel(\"References\"):\n                    references_content = ui.markdown(\"\").style(\"color : var(--text-color)\")\n                with ui.tab_panel(\"SystemStates\"):\n                    analysis_content = ui.markdown(\"\").style(\"color : var(--text-color)\")\n\n\n        # Ergebnisse sichtbar machen, sobald sie vorliegen.\n        results_card = results_card\n        results_card.visible = False\n\n        # --- Follow-Up Bereich mit mehrfachen Folgefragen und Suchparametern ---\n        with ui.card().classes(\"w-full backdrop-blur-lg bg-white/10 p-4 hidden\") as followup_card:\n            pass\n\n        # Zugriff auf followup_card (falls sp\u00e4ter ben\u00f6tigt)\n        followup_card = followup_card\n        followup_card.visible = False\n\n        # --- Fortschrittsanzeige ---\n        with ui.card().classes(\"w-full backdrop-blur-lg bg-white/10 p-4\") as progress_card:\n            with ui.row():\n                ui.label(\"Research Progress\").classes(\"text-xl font-semibold mb-4\")\n                query_length_label = ui.label(\"\").classes(\"mt-6 hover:text-primary transition-colors duration-300\")\n                time_label = ui.label(\"Time: ...\").classes(\"mt-6 hover:text-primary transition-colors duration-300\")\n                price_label = ui.label(\"Price: ...\").classes(\n                    \"mt-6 hover:text-primary transition-colors duration-300\")\n\n            overall_progress = ui.linear_progress(0).classes(\"w-full mb-4\")\n            status_label = ui.label(\"Warte auf Start...\").classes(\"text-base\")\n        # Wir merken uns progress_card, falls wir ihn zur\u00fccksetzen wollen.\n        progress_card = progress_card\n\n        query_length_label = query_length_label\n        time_label = time_label\n        price_label = price_label\n\n        with ui.card().classes(\"w-full backdrop-blur-lg bg-white/10 p-4\") as config_cart:\n            # --- Process Code Section ---\n            # --- Estimated Time and Price ---\n            # ui.label(\"History\").classes(\"text-xl font-semibold mt-4 mb-2\")\n            ui.label('Research History').classes('text-xl p-4')\n            show_history()\n\n        ui.button('Add Credits', on_click=lambda: balance_overlay(session_id)).props('icon=paid')\n        ui.label('About TruthSeeker').classes(\n            'mt-6 text-gray-500 hover:text-primary '\n            'transition-colors duration-300'\n        ).on('click', lambda: ui.navigate.to('/open-Seeker.about', new_tab=True))\n\n        with ui.element('div').classes(\"w-full\").style(\"white:100%; height:100%\") as graph_ui:\n            pass\n\n        with ui.card().classes(\"w-full p-4\").style(\"background-color: var(--background-color)\"):\n            ui.label(\"Private Session link (restore the session on a different device)\")\n            base_url = f'https://{os.getenv(\"HOSTNAME\")}/gui/open-Seeker.seek' if not 'localhost' in os.getenv(\"HOSTNAME\") else 'http://localhost:5000/gui/open-Seeker.seek'\n            ui.label(f\"{base_url}?session_id={session_id}\").style(\"white:100%\")\n            ui.label(\"Changes each time!\")\n\n        graph_ui = graph_ui\n        graph_ui.visible = False\n    main_ui = main_ui\n    main_ui.visible = False\n\n    # --- Hilfsfunktionen ---\n    def validate_inputs() -&gt; bool:\n        if not query.value.strip():\n            with main_ui:\n                ui.notify(\"Bitte gib eine Forschungsfrage ein.\", type=\"warning\")\n            return False\n        return True\n\n    def reset_interface():\n        nonlocal overall_progress, status_label, results_card, followup_card\n        overall_progress.value = 0\n        with main_ui:\n            status_label.set_text(\"Research startet...\")\n        # Ergebnisse und Follow-Up Bereich verstecken\n        results_card.visible = False\n        followup_card.visible = False\n        graph_ui.visible = False\n\n    def show_progress_indicators():\n        nonlocal progress_card\n        progress_card.visible = True\n\n    def update_results(data: dict, save=True):\n        nonlocal summary_content, analysis_content, references_content, results_card,                followup_card,graph_ui, r_button, r_text, sr_button\n        with main_ui:\n            r_button.visible = True\n            r_text.set_text(\"Add to current Results or press 'Start new Research'\")\n            sr_button.set_text(\"Add to current Results\")\n        # Handle papers (1-to-1 case)\n        papers = data.get(\"papers\", [])\n        if not isinstance(papers, list):\n            papers = [papers]\n\n        # Get insights\n        insights = data.get(\"insights\", [])\n\n        if save:\n            history_entry = data.copy()\n            history_entry['papers'] = [paper.model_dump_json() for paper in papers]\n            if processor_instance is not None and processor_instance['instance'] is not None:\n                history_entry[\"mam_name\"] = processor_instance['instance'].mem_name\n                history_entry[\"query\"] = processor_instance['instance'].query\n\n                history_entry[\"processor_memory\"] = processor_instance['instance'].tools.get_memory(\n\n                ).save_memory(history_entry[\"mam_name\"], None)\n            state['research_history'].append(history_entry)\n            save_user_state(session_id, state)\n        else:\n            papers = [Paper(**json.loads(paper)) for paper in papers]\n        create_followup_section(processor_instance, followup_card, session_id, balance)\n        with main_ui:\n            progress_card.visible = False\n            # Build summary from insights\n            summaries = []\n            for insight in insights:\n                if 'result' in insight and 'summary' in insight['result']:\n                    if isinstance(insight['result']['summary'], str):\n                        # print(insight['result']['summary'], \"NEXT\", json.loads(insight['result']['summary'][:-1]),\"NEXT22\",  type(json.loads(insight['result']['summary'][:-1])))\n                        insight['result']['summary'] = json.loads(insight['result']['summary'][:-1])\n                    main_summary = insight['result']['summary'].get('main_summary', '')\n                    if main_summary:\n                        summaries.append(main_summary)\n            summary_text = \"\n</code></pre> <p>\".join(summaries) if summaries else \"No summary available.\"                 summary_content.set_content(f\"# Research Summary</p> <p>{summary_text}\")</p> <pre><code>            # Analysis section (unchanged if processor details haven't changed)\n            if processor_instance[\"instance\"] is not None:\n                inst = processor_instance[\"instance\"]\n                analysis_md = (\n                    f\"# Analysis\n</code></pre> <p>\"                         f\"- query: {inst.query} \"                         f\"- chunk_size: {inst.chunk_size} \"                         f\"- overlap: {inst.overlap} \"                         f\"- max_workers: {inst.max_workers} \"                         f\"- num_search_result_per_query: {inst.nsrpq} \"                         f\"- max_search: {inst.max_search} \"                         f\"- download_dir: {inst.download_dir} \"                         f\"- mem_name: {inst.mem_name} \"                         f\"- current_session: {inst.current_session} \"                         f\"- all_ref_papers: {inst.all_ref_papers} \"                         f\"- all_texts_len: {inst.all_texts_len} \"                         f\"- final_texts_len: {inst.f_texts_len} \"                         f\"- num_workers: {inst.num_workers}\"                     )                     analysis_content.set_content(analysis_md)</p> <pre><code>            # References and Insights section\n            references_md = \"# References\n</code></pre> <p>\"                 # Add papers                 references_md += \" \".join(                     f\"- ({i}) {getattr(paper, 'title', 'Unknown Title')}})\"                     for i, paper in enumerate(papers)                 )</p> <pre><code>            # Add detailed insights\n            references_md += \"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.nGui--insights","title":"Insights","text":"<p>\"                 for i, insight in enumerate(insights):                     print(insight)                     result = insight.get('result', {})                     summary = result.get('summary', {})</p> <pre><code>                if isinstance(summary, str):\n                    summary = json.loads(summary)\n\n                # Main summary\n                references_md += f\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.nGui--insight","title":"Insight","text":"<p>\"                     references_md += f\"### Main Summary {summary.get('main_summary', 'No summary available.')} \"</p> <pre><code>                # Concept Analysis\n                concept_analysis = summary.get('concept_analysis', {})\n                if concept_analysis:\n                    references_md += \"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.nGui--concept-analysis","title":"Concept Analysis","text":"<p>\"                         references_md += \"#### Key Concepts - \" + \" - \".join(                             concept_analysis.get('key_concepts', [])) + \" \"                         references_md += \"</p>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.nGui--relationships","title":"Relationships","text":"<ul> <li>\" + \"</li> <li>\".join(                             concept_analysis.get('relationships', [])) + \" \"                         references_md += \"</li> </ul>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.nGui--importance-hierarchy","title":"Importance Hierarchy","text":"<ul> <li>\" + \"</li> <li> <p>\".join(                             concept_analysis.get('importance_hierarchy', [])) + \" \"</p> <pre><code>            # Topic Insights\n            topic_insights = summary.get('topic_insights', {})\n            if topic_insights:\n                references_md += \"\n</code></pre> </li> </ul>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.nGui--topic-insights","title":"Topic Insights","text":"<p>\"                     references_md += \"#### Primary Topics - \" + \" - \".join(                         topic_insights.get('primary_topics', [])) + \" \"                     references_md += \"</p>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.nGui--cross-references","title":"Cross References","text":"<ul> <li>\" + \"</li> <li>\".join(                         topic_insights.get('cross_references', [])) + \" \"                     references_md += \"</li> </ul>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.nGui--knowledge-gaps","title":"Knowledge Gaps","text":"<ul> <li>\" + \"</li> <li> <p>\".join(                         topic_insights.get('knowledge_gaps', [])) + \" \"</p> <pre><code>        # Relevance Assessment\n        relevance = summary.get('relevance_assessment', {})\n        if relevance:\n            references_md += \"\n</code></pre> </li> </ul> <p>return helpr</p>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.nGui--relevance-assessment","title":"Relevance Assessment","text":"<p>\"                 references_md += f\"- Query Alignment: {relevance.get('query_alignment', 'N/A')} \"                 references_md += f\"- Confidence Score: {relevance.get('confidence_score', 'N/A')} \"                 references_md += f\"- Coverage Analysis: {relevance.get('coverage_analysis', 'N/A')} \"</p> <pre><code>    references_content.set_content(references_md)\n\n    # nx concpts graph\n    if processor_instance[\"instance\"] is not None:\n        create_graph_tab(\n            processor_instance,\n            graph_ui,main_ui\n        )\n\n    # Show results and followup cards\n    results_card.visible = True\n    followup_card.visible = True\n    graph_ui.visible = True\n</code></pre> <p>def load_history(index: int):     entry = state['research_history'][index]     if processor_instance is not None and processor_instance['instance'] is not None:</p> <pre><code>    processor_instance[\"instance\"].mem_name = entry[\"mam_name\"]\n    processor_instance['instance'].query = entry[\"query\"]\n\n    pass\nelse:\n    processor = Processor(entry[\"query\"], tools=get_tools(), **config)\n    # Setze den Callback so, dass Updates in der GUI angezeigt werden\n    processor.callback = update_status\n    processor.mem_name = entry[\"mam_name\"]\n    processor_instance[\"instance\"] = processor\n\nprocessor_instance[\"instance\"].tools.get_memory().load_memory(entry[\"mam_name\"], entry[\"processor_memory\"])\nprocessor_instance[\"instance\"].mem_name = entry[\"mam_name\"]\nupdate_results(entry, save=False)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.nGui---stripe-integration-","title":"--- Stripe Integration ---","text":"<p>def regiser_stripe_integration(is_scc=True):     def stripe_callback(request: Request):</p> <pre><code>    sid = request.row.query_params.get('session_id') if hasattr(request, 'row') else request.query_params.get('session_id')\n    state = get_user_state(sid)\n\n    if state['payment_id'] == '':\n        with ui.card().classes(\"w-full items-center\").style(\"background-color: var(--background-color)\"):\n            ui.label(f\"No payment id!\").classes(\"text-lg font-bold\")\n            ui.button(\n                \"Start Research\",\n                on_click=lambda: ui.navigate.to(\"/open-Seeker.seek?session_id=\"+sid)\n            ).classes(\n                \"w-full px-6 py-4 text-lg font-bold \"\n                \"bg-primary hover:bg-primary-dark \"\n                \"transform hover:-translate-y-0.5 \"\n                \"transition-all duration-300 ease-in-out \"\n                \"rounded-xl shadow-lg animate-slideUp\"\n            )\n        return\n\n    try:\n        session_data = stripe.checkout.Session.retrieve(state['payment_id'])\n    except Exception as e:\n        with ui.card().classes(\"w-full items-center\").style(\"background-color: var(--background-color)\"):\n            ui.label(f\"No Transactions Details !{e}\").classes(\"text-lg font-bold\")\n            ui.button(\n                \"Start Research\",\n                on_click=lambda: ui.navigate.to(\"/open-Seeker.seek\")\n            ).classes(\n                \"w-full px-6 py-4 text-lg font-bold \"\n                \"bg-primary hover:bg-primary-dark \"\n                \"transform hover:-translate-y-0.5 \"\n                \"transition-all duration-300 ease-in-out \"\n                \"rounded-xl shadow-lg animate-slideUp\"\n            )\n            return\n    with ui.card().classes(\"w-full items-center\").style(\"background-color: var(--background-color)\"):\n        if is_scc and state['payment_id'] != '' and session_data.payment_status == 'paid':\n            state = get_user_state(sid)\n            amount = session_data.amount_total / 100  # Convert cents to euros\n            state['balance'] += amount\n            state['payment_id'] = ''\n            save_user_state(sid, state)\n\n        # ui.navigate.to(f'/session?session={session}')\n            ui.label(f\"Transaction Complete - New balance :{state['balance']}\").classes(\"text-lg font-bold\")\n            with ui.card().classes(\"w-full p-4\").style(\"background-color: var(--background-color)\"):\n                ui.label(\"Private Session link (restore the session on a different device)\")\n                base_url = f'https://{os.getenv(\"HOSTNAME\")}/gui/open-Seeker.seek' if not 'localhost' in os.getenv(\"HOSTNAME\")else 'http://localhost:5000/gui/open-Seeker.seek'\n                ui.label(f\"{base_url}?session_id={sid}\").style(\"white:100%\")\n                ui.label(\"Changes each time!\")\n        else:\n            ui.label(f\"Transaction Error! {session_data}, {dir(session_data)}\").classes(\"text-lg font-bold\")\n        ui.button(\n            \"Start Research\",\n            on_click=lambda: ui.navigate.to(\"/open-Seeker.seek\")\n        ).classes(\n            \"w-full px-6 py-4 text-lg font-bold \"\n            \"bg-primary hover:bg-primary-dark \"\n            \"transform hover:-translate-y-0.5 \"\n            \"transition-all duration-300 ease-in-out \"\n            \"rounded-xl shadow-lg animate-slideUp\"\n        )\n\n\nreturn stripe_callback\n</code></pre> <p>def handle_stripe_payment(amount: float, session_id):     base_url = f'https://{os.getenv(\"HOSTNAME\")}/gui/open-Seeker.stripe' if not 'localhost' in os.getenv(\"HOSTNAME\") else 'http://localhost:5000/gui/open-Seeker.stripe'     session = stripe.checkout.Session.create(         payment_method_types=['card',                               \"link\",                               ],         line_items=[{             'price_data': {                 'currency': 'eur',                 'product_data': {'name': 'Research Credits'},                 'unit_amount': int(amount * 100),             },             'quantity': 1,         }],         automatic_tax={\"enabled\": True},         mode='payment',         success_url=f'{base_url}?session_id={session_id}',         cancel_url=f'{base_url}.error'     )     state = get_user_state(session_id)     state['payment_id'] = session.id     save_user_state(session_id, state)     ui.navigate.to(session.url, new_tab=True)</p>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.nGui---ui-components-","title":"--- UI Components ---","text":"<p>def balance_overlay(session_id):     with ui.dialog().classes('w-full max-w-md bg-white/20 backdrop-blur-lg rounded-xl') as dialog:         with ui.card().classes('w-full p-6 space-y-4').style(\"background-color: var(--background-color)\"):             ui.label('Add Research Credits').classes('text-2xl font-bold')             amount = ui.number('Amount (\u20ac) min 2', value=5, format='%.2f', min=2, max=9999, step=1).classes('w-full')             with ui.row().classes('w-full justify-between'):                 ui.button('Cancel', on_click=dialog.close).props('flat')                 ui.button('Purchase', on_click=lambda: handle_stripe_payment(amount.value, session_id))     return dialog</p> <p>def create_ui(processor):     # ui_instance =     register_nicegui(\"open-Seeker\", create_landing_page                      , additional=\"\"\"     \"\"\", show=False)     register_nicegui(\"open-Seeker.demo\", create_video_demo, additional=\"\"\"          \"\"\", show=False)</p>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.newui","title":"<code>newui</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.newui.cleanup_module","title":"<code>cleanup_module(app)</code>","text":"<p>Cleanup resources when the module is unloaded</p> Source code in <code>toolboxv2/mods/TruthSeeker/newui.py</code> <pre><code>@export(mod_name=MOD_NAME, version=version, exit_f=True)\ndef cleanup_module(app: App):\n    \"\"\"Cleanup resources when the module is unloaded\"\"\"\n    # Clean up any temp files or resources\n    import glob\n    import shutil\n\n    # Remove temporary PDF directories\n    for pdf_dir in glob.glob(\"pdfs_*\"):\n        try:\n            shutil.rmtree(pdf_dir)\n        except Exception as e:\n            print(f\"Error removing directory {pdf_dir}: {str(e)}\")\n\n    # Clear any SSE queues\n    if hasattr(app, 'sse_queues'):\n        app.sse_queues = {}\n\n    if hasattr(app, 'payment_queues'):\n        app.payment_queues = {}\n\n    return Result.ok(info=\"ArXivPDFProcessor UI cleaned up\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.newui.create_payment","title":"<code>create_payment(app, data)</code>  <code>async</code>","text":"<p>Create a Stripe payment session</p> Source code in <code>toolboxv2/mods/TruthSeeker/newui.py</code> <pre><code>@export(mod_name=MOD_NAME, api=True, version=version)\nasync def create_payment(app: App, data):\n    \"\"\"Create a Stripe payment session\"\"\"\n    amount = data.get(\"amount\")\n    session_id = data.get(\"session_id\")\n\n    if amount &lt; 2:\n        return Result.default_user_error(info=\"Minimum donation amount is \u20ac2\")\n\n    try:\n        # Create a Stripe Checkout Session\n        base_url = f\"https://{os.getenv('HOSTNAME', 'localhost:5000')}\"\n        success_url = f\"{base_url}/api/{MOD_NAME}/payment_success?session_id={session_id}\"\n        cancel_url = f\"{base_url}/api/{MOD_NAME}/payment_cancel?session_id={session_id}\"\n\n        stripe_session = stripe.checkout.Session.create(\n            payment_method_types=['card', 'link'],\n            line_items=[{\n                'price_data': {\n                    'currency': 'eur',\n                    'product_data': {'name': 'Research Credits'},\n                    'unit_amount': int(amount * 100),\n                },\n                'quantity': 1,\n            }],\n            automatic_tax={\"enabled\": True},\n            mode='payment',\n            success_url=success_url,\n            cancel_url=cancel_url\n        )\n\n        # Store the payment info\n        if not hasattr(app, 'payment_info'):\n            app.payment_info = {}\n\n        # Initialize payment_queues if not already done\n        if not hasattr(app, 'payment_queues'):\n            app.payment_queues = {}\n\n        # Create a queue for this payment\n        app.payment_queues[session_id] = asyncio.Queue()\n\n        app.payment_info[session_id] = {\n            'payment_id': stripe_session.id,\n            'amount': amount,\n            'status': 'pending'\n        }\n\n        return Result.ok(data={\"url\": stripe_session.url})\n    except Exception as e:\n        return Result.default_internal_error(info=f\"Error creating payment: {str(e)}\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.newui.estimate_processing","title":"<code>estimate_processing(data)</code>  <code>async</code>","text":"<p>Estimate processing time and cost for a given query</p> Source code in <code>toolboxv2/mods/TruthSeeker/newui.py</code> <pre><code>@export(mod_name=MOD_NAME, api=True, version=version)\nasync def estimate_processing(data):\n    \"\"\"Estimate processing time and cost for a given query\"\"\"\n    # Use the static method to estimate metrics\n    query, max_search, num_search_result_per_query= data.get(\"query\", \"\"), data.get(\"max_search\",4), data.get(\"num_search_result_per_query\",6)\n    estimated_time, estimated_price = ArXivPDFProcessor.estimate_processing_metrics(\n        query_length=len(query),\n        max_search=max_search,\n        num_search_result_per_query=num_search_result_per_query,\n        chunk_size=1_000_000,\n        overlap=2_000,\n        num_workers=None\n    )\n\n    return Result.ok(data={\n        \"time\": estimated_time,\n        \"price\": estimated_price\n    })\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.newui.follow_up_query","title":"<code>follow_up_query(app, data)</code>  <code>async</code>","text":"<p>Ask a follow-up question about the research</p> Source code in <code>toolboxv2/mods/TruthSeeker/newui.py</code> <pre><code>@export(mod_name=MOD_NAME, api=True, version=version)\nasync def follow_up_query(app: App, data):\n    \"\"\"Ask a follow-up question about the research\"\"\"\n    research_id = data.get(\"research_id\")\n    query = data.get(\"query\")\n\n    if not hasattr(app, 'research_processes') or research_id not in app.research_processes:\n        return Result.default_user_error(info=\"Research process not found\")\n\n    research_process = app.research_processes[research_id]\n\n    if research_process['status'] != 'complete':\n        return Result.default_user_error(info=\"Research is not complete\")\n\n    processor = research_process['processor']\n    if not processor:\n        return Result.default_user_error(info=\"Processor not available\")\n\n    try:\n        # Use the extra_query method to ask follow-up questions\n        result = await processor.extra_query(query)\n\n        return Result.ok(data={\"answer\": result['response'] if result and 'response' in result else \"No response\"})\n    except Exception as e:\n        return Result.default_internal_error(info=f\"Error processing follow-up query: {str(e)}\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.newui.initialize_module","title":"<code>initialize_module(app)</code>","text":"<p>Initialize the module and register UI with CloudM</p> Source code in <code>toolboxv2/mods/TruthSeeker/newui.py</code> <pre><code>@export(mod_name=MOD_NAME, version=version, initial=True)\ndef initialize_module(app: App):\n    \"\"\"Initialize the module and register UI with CloudM\"\"\"\n    # Register the UI with CloudM\n    app.run_any((\"CloudM\", \"add_ui\"),\n                name=\"TruthSeeker\",\n                title=\"TruthSeeker Research\",\n                path=f\"/api/{MOD_NAME}/get_main_ui\",\n                description=\"AI Research Assistant\"\n                )\n\n    # Initialize SSE message queues\n    if not hasattr(app, 'sse_queues'):\n        app.sse_queues = {}\n    print(\"TruthSeeker online\")\n    return Result.ok(info=\"ArXivPDFProcessor UI initialized\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.newui.payment_cancel","title":"<code>payment_cancel(app, session_id, request_as_kwarg=True, request=None)</code>  <code>async</code>","text":"<p>Handle cancelled payment</p> Source code in <code>toolboxv2/mods/TruthSeeker/newui.py</code> <pre><code>@export(mod_name=MOD_NAME, api=True, version=version)\nasync def payment_cancel(app: App, session_id: str, request_as_kwarg=True, request=None):\n    \"\"\"Handle cancelled payment\"\"\"\n    if hasattr(app, 'payment_info') and session_id in app.payment_info:\n        app.payment_info[session_id]['status'] = 'cancelled'\n\n        # Notify SSE clients about payment cancellation\n        if hasattr(app, 'payment_queues') and session_id in app.payment_queues:\n            await app.payment_queues[session_id].put({\n                \"status\": \"cancelled\"\n            })\n\n    return Result.html(app.web_context() + \"\"\"\n    &lt;div style=\"text-align: center; padding: 50px;\"&gt;\n        &lt;h2&gt;Payment Cancelled&lt;/h2&gt;\n        &lt;p&gt;Your payment was cancelled.&lt;/p&gt;\n        &lt;script&gt;\n            setTimeout(function() {\n                window.close();\n            }, 3000);\n        &lt;/script&gt;\n    &lt;/div&gt;\n    \"\"\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.newui.payment_stream","title":"<code>payment_stream(app, session_id)</code>  <code>async</code>","text":"<p>SSE stream endpoint for payment status updates</p> Source code in <code>toolboxv2/mods/TruthSeeker/newui.py</code> <pre><code>@export(mod_name=MOD_NAME, api=True, version=version)\nasync def payment_stream(app: App, session_id: str):\n    \"\"\"SSE stream endpoint for payment status updates\"\"\"\n    if not hasattr(app, 'payment_queues'):\n        app.payment_queues = {}\n\n    # Create a message queue for this session_id if it doesn't exist\n    if session_id not in app.payment_queues:\n        app.payment_queues[session_id] = asyncio.Queue()\n\n    async def generate():\n        try:\n            # Stream payment updates\n            while True:\n                try:\n                    # Wait for a payment update with a timeout\n                    payment_data = await asyncio.wait_for(app.payment_queues[session_id].get(), timeout=30)\n                    yield f\"event: payment_update\\ndata: {json.dumps(payment_data)}\\n\\n\"\n\n                    # If the payment is complete or cancelled, exit the loop\n                    if payment_data.get('status') in ['completed', 'cancelled']:\n                        break\n                except TimeoutError:\n                    # Send a keep-alive comment to prevent connection timeout\n                    yield \":\\n\\n\"\n        finally:\n            # Clean up resources when the client disconnects\n            if session_id in app.payment_queues:\n                # Keep the queue for other potential clients\n                pass\n\n    return Result.stream(generate())\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.newui.payment_success","title":"<code>payment_success(app, session_id, request_as_kwarg=True, request=None)</code>  <code>async</code>","text":"<p>Handle successful payment</p> Source code in <code>toolboxv2/mods/TruthSeeker/newui.py</code> <pre><code>@export(mod_name=MOD_NAME, api=True, version=version)\nasync def payment_success(app: App, session_id: str, request_as_kwarg=True, request=None):\n    \"\"\"Handle successful payment\"\"\"\n    if not hasattr(app, 'payment_info') or session_id not in app.payment_info:\n        return Result.html(app.web_context() + \"\"\"\n        &lt;div style=\"text-align: center; padding: 50px;\"&gt;\n            &lt;h2&gt;Payment Session Not Found&lt;/h2&gt;\n            &lt;p&gt;Return to the main page to continue.&lt;/p&gt;\n            &lt;a href=\"/\" style=\"display: inline-block; margin-top: 20px; padding: 10px 20px; background-color: #4F46E5; color: white; text-decoration: none; border-radius: 5px;\"&gt;Return to Home&lt;/a&gt;\n        &lt;/div&gt;\n        \"\"\")\n\n    payment_info = app.payment_info[session_id]\n\n    try:\n        # Verify the payment with Stripe\n        stripe_session = stripe.checkout.Session.retrieve(payment_info['payment_id'])\n\n        if stripe_session.payment_status == 'paid':\n            payment_info['status'] = 'completed'\n\n            # Notify SSE clients about payment completion\n            if hasattr(app, 'payment_queues') and session_id in app.payment_queues:\n                await app.payment_queues[session_id].put({\n                    \"status\": \"completed\",\n                    \"amount\": payment_info['amount']\n                })\n\n            return Result.html(app.web_context() + \"\"\"\n            &lt;div style=\"text-align: center; padding: 50px;\"&gt;\n                &lt;h2&gt;Thank You for Your Support!&lt;/h2&gt;\n                &lt;p&gt;Your payment was successful. You can now close this window and continue with your research.&lt;/p&gt;\n                &lt;script&gt;\n                    setTimeout(function() {\n                        window.close();\n                    }, 5000);\n                &lt;/script&gt;\n            &lt;/div&gt;\n            \"\"\")\n        else:\n            return Result.html(app.web_context() + \"\"\"\n            &lt;div style=\"text-align: center; padding: 50px;\"&gt;\n                &lt;h2&gt;Payment Not Completed&lt;/h2&gt;\n                &lt;p&gt;Your payment has not been completed. Please try again.&lt;/p&gt;\n                &lt;button onclick=\"window.close()\"&gt;Close Window&lt;/button&gt;\n            &lt;/div&gt;\n            \"\"\")\n    except Exception as e:\n        return Result.html(app.web_context() + f\"\"\"\n        &lt;div style=\"text-align: center; padding: 50px;\"&gt;\n            &lt;h2&gt;Error Processing Payment&lt;/h2&gt;\n            &lt;p&gt;There was an error processing your payment: {str(e)}&lt;/p&gt;\n            &lt;button onclick=\"window.close()\"&gt;Close Window&lt;/button&gt;\n        &lt;/div&gt;\n        \"\"\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.newui.research_results","title":"<code>research_results(app, research_id)</code>  <code>async</code>","text":"<p>Get the results of a completed research process</p> Source code in <code>toolboxv2/mods/TruthSeeker/newui.py</code> <pre><code>@export(mod_name=MOD_NAME, api=True, version=version)\nasync def research_results(app: App, research_id: str):\n    \"\"\"Get the results of a completed research process\"\"\"\n    if not hasattr(app, 'research_processes') or research_id not in app.research_processes:\n        return Result.default_user_error(info=\"Research process not found\")\n\n    research_process = app.research_processes[research_id]\n\n    if research_process['status'] != 'complete':\n        return Result.default_user_error(info=\"Research is not complete\")\n\n    return Result.ok(data=research_process['results'])\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.newui.research_status","title":"<code>research_status(app, research_id)</code>  <code>async</code>","text":"<p>Get the status of a research process</p> Source code in <code>toolboxv2/mods/TruthSeeker/newui.py</code> <pre><code>@export(mod_name=MOD_NAME, api=True, version=version)\nasync def research_status(app: App, research_id: str):\n    \"\"\"Get the status of a research process\"\"\"\n    if not hasattr(app, 'research_processes') or research_id not in app.research_processes:\n        return Result.default_user_error(info=\"Research process not found\")\n\n    research_process = app.research_processes[research_id]\n\n    return Result.ok(data={\n        \"status\": research_process['status'],\n        \"progress\": research_process['progress'],\n        \"step\": research_process['step'],\n        \"info\": research_process['info']\n    })\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.newui.start_research","title":"<code>start_research(app, data)</code>  <code>async</code>","text":"<p>Start a new research process</p> Source code in <code>toolboxv2/mods/TruthSeeker/newui.py</code> <pre><code>@export(mod_name=MOD_NAME, api=True, version=version)\nasync def start_research(app: App, data):\n    \"\"\"Start a new research process\"\"\"\n    # Get data from the request\n    query = data.get(\"query\")\n    session_id = data.get(\"session_id\")\n    max_search = data.get(\"max_search\", 4)\n    num_search_result_per_query = data.get(\"num_search_result_per_query\", 4)\n\n    # Get the tools module\n    tools = get_app(\"ArXivPDFProcessor\").get_mod(\"isaa\")\n    if not hasattr(tools, 'initialized') or not tools.initialized:\n        tools.init_isaa(build=True)\n\n    # Generate a unique research_id\n    research_id = str(uuid.uuid4())\n\n    # Store the research information in a global dictionary\n    if not hasattr(app, 'research_processes'):\n        app.research_processes = {}\n\n    # Initialize SSE queues if not already done\n    if not hasattr(app, 'sse_queues'):\n        app.sse_queues = {}\n\n    # Create a queue for this research process\n    app.sse_queues[research_id] = asyncio.Queue()\n\n    # Create a processor with callback for status updates\n    app.research_processes[research_id] = {\n        'status': 'initializing',\n        'progress': 0.0,\n        'step': 'Initializing',\n        'info': '',\n        'query': query,\n        'session_id': session_id,\n        'processor': None,\n        'results': None,\n        'stop_requested': False\n    }\n\n    # Define the callback function that sends updates to the SSE queue\n    def status_callback(status_data):\n        if research_id in app.research_processes:\n            process = app.research_processes[research_id]\n            process['status'] = 'processing'\n            process['progress'] = status_data.get('progress', 0.0)\n            process['step'] = status_data.get('step', '')\n            process['info'] = status_data.get('info', '')\n\n            # Put the status update in the SSE queue\n            status_update = {\n                \"status\": process['status'],\n                \"progress\": process['progress'],\n                \"step\": process['step'],\n                \"info\": process['info']\n            }\n\n            if research_id in app.sse_queues:\n                asyncio.create_task(app.sse_queues[research_id].put(status_update))\n\n    # Create the processor\n    processor = ArXivPDFProcessor(\n        query=query,\n        tools=tools,\n        chunk_size=1_000_000,\n        overlap=2_000,\n        max_search=max_search,\n        num_search_result_per_query=num_search_result_per_query,\n        download_dir=f\"pdfs_{research_id}\",\n        callback=status_callback\n    )\n\n    app.research_processes[research_id]['processor'] = processor\n\n    # Process in the background\n    async def process_in_background():\n        try:\n            # Check if stop was requested before starting\n            if app.research_processes[research_id]['stop_requested']:\n                app.research_processes[research_id]['status'] = 'stopped'\n                if research_id in app.sse_queues:\n                    await app.sse_queues[research_id].put({\n                        \"status\": \"stopped\",\n                        \"progress\": 0,\n                        \"step\": \"Research stopped\",\n                        \"info\": \"\"\n                    })\n                return\n\n            # Start processing\n            papers, insights = await processor.process()\n\n            # Check if stop was requested during processing\n            if app.research_processes[research_id]['stop_requested']:\n                app.research_processes[research_id]['status'] = 'stopped'\n                if research_id in app.sse_queues:\n                    await app.sse_queues[research_id].put({\n                        \"status\": \"stopped\",\n                        \"progress\": 1,\n                        \"step\": \"Research stopped\",\n                        \"info\": \"\"\n                    })\n                return\n\n            # Store results\n            app.research_processes[research_id]['results'] = {\n                'papers': papers,\n                'insights': insights['response'] if insights and 'response' in insights else None\n            }\n            app.research_processes[research_id]['status'] = 'complete'\n\n            # Send final status update\n            if research_id in app.sse_queues:\n                await app.sse_queues[research_id].put({\n                    \"status\": \"complete\",\n                    \"progress\": 1,\n                    \"step\": \"Research complete\",\n                    \"info\": f\"Found {len(papers)} papers\"\n                })\n\n        except Exception as e:\n            app.research_processes[research_id]['status'] = 'error'\n            app.research_processes[research_id]['info'] = str(e)\n\n            # Send error status\n            if research_id in app.sse_queues:\n                await app.sse_queues[research_id].put({\n                    \"status\": \"error\",\n                    \"progress\": 0,\n                    \"step\": \"Error\",\n                    \"info\": str(e)\n                })\n\n            print(f\"Error in research process {research_id}: {str(e)}\")\n\n    # Start the background task\n    asyncio.create_task(process_in_background())\n\n    return Result.ok(data={\"research_id\": research_id})\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.newui.status_stream","title":"<code>status_stream(app, research_id)</code>  <code>async</code>","text":"<p>SSE stream endpoint for research status updates</p> Source code in <code>toolboxv2/mods/TruthSeeker/newui.py</code> <pre><code>@export(mod_name=MOD_NAME, api=True, version=version)\nasync def status_stream(app: App, research_id: str):\n    \"\"\"SSE stream endpoint for research status updates\"\"\"\n    if not hasattr(app, 'sse_queues'):\n        app.sse_queues = {}\n\n    # Create a message queue for this research_id if it doesn't exist\n    if research_id not in app.sse_queues:\n        app.sse_queues[research_id] = asyncio.Queue()\n\n    async def generate():\n        # Send initial status\n        if hasattr(app, 'research_processes') and research_id in app.research_processes:\n            process = app.research_processes[research_id]\n            initial_status = {\n                \"status\": process['status'],\n                \"progress\": process['progress'],\n                \"step\": process['step'],\n                \"info\": process['info']\n            }\n            yield f\"event: status_update\\ndata: {json.dumps(initial_status)}\\n\\n\"\n\n        try:\n            # Stream status updates\n            while True:\n                try:\n                    # Wait for a new status update with a timeout\n                    status_data = await asyncio.wait_for(app.sse_queues[research_id].get(), timeout=30)\n                    yield f\"event: status_update\\ndata: {json.dumps(status_data)}\\n\\n\"\n\n                    # If the research is complete or there was an error, exit the loop\n                    if status_data.get('status') in ['complete', 'error', 'stopped']:\n                        break\n                except TimeoutError:\n                    # Send a keep-alive comment to prevent connection timeout\n                    yield \":\\n\\n\"\n        finally:\n            # Clean up resources when the client disconnects\n            if research_id in app.sse_queues:\n                # Keep the queue for other potential clients\n                pass\n\n    return Result.stream(generate())\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.newui.stop_research","title":"<code>stop_research(app, data)</code>  <code>async</code>","text":"<p>Stop a research process</p> Source code in <code>toolboxv2/mods/TruthSeeker/newui.py</code> <pre><code>@export(mod_name=MOD_NAME, api=True, version=version)\nasync def stop_research(app: App, data):\n    \"\"\"Stop a research process\"\"\"\n    research_id = data.get(\"research_id\")\n    if not hasattr(app, 'research_processes') or research_id not in app.research_processes:\n        return Result.default_user_error(info=\"Research process not found\")\n\n    app.research_processes[research_id]['stop_requested'] = True\n\n    # Send stopped status to SSE clients\n    if hasattr(app, 'sse_queues') and research_id in app.sse_queues:\n        await app.sse_queues[research_id].put({\n            \"status\": \"stopped\",\n            \"progress\": app.research_processes[research_id]['progress'],\n            \"step\": \"Stopping research\",\n            \"info\": \"\"\n        })\n\n    return Result.ok(data={\"status\": \"stop_requested\"})\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.one","title":"<code>one</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.one.IntelligenceRingEmbeddings","title":"<code>IntelligenceRingEmbeddings</code>","text":"Source code in <code>toolboxv2/mods/TruthSeeker/one.py</code> <pre><code>class IntelligenceRingEmbeddings:\n    name: str = \"sentence-transformers/all-MiniLM-L6-v2\"\n    clip_name: str = \"openai/clip-vit-base-patch32\"\n    wav2vec_name: str = \"facebook/wav2vec2-base-960h\"\n    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    vector_size: int = 768\n    tokenizer: Any | None = None\n    text_model: Any | None = None\n\n    clip_processor: Any | None = None\n    clip_model: Any | None = None\n\n    audio_processor: Any | None = None\n    audio_model: Any | None = None\n\n    text_projection: Any | None = None\n    image_projection: Any | None = None\n    audio_projection: Any | None = None\n\n    def __init__(self, **kwargs):\n\n        super().__init__(**kwargs)\n        self._ndims = self.vector_size\n\n        # Text embedding model\n        self.tokenizer = AutoTokenizer.from_pretrained(self.name)\n        self.text_model = AutoModel.from_pretrained(self.name).to(self.device)\n\n        # Image embedding model (CLIP)\n        self.clip_processor = CLIPProcessor.from_pretrained(self.clip_name)\n        self.clip_model = CLIPModel.from_pretrained(self.clip_name).to(self.device)\n\n        # Audio embedding model (Wav2Vec2)\n        self.audio_processor = Wav2Vec2Processor.from_pretrained(self.wav2vec_name)\n        self.audio_model = Wav2Vec2Model.from_pretrained(self.wav2vec_name).to(self.device)\n\n        # Projection layers to align dimensions\n        self.text_projection = torch.nn.Linear(\n            self.text_model.config.hidden_size,\n            self.vector_size\n        ).to(self.device)\n        self.image_projection = torch.nn.Linear(\n            self.clip_model.config.vision_config.hidden_size,\n            self.vector_size\n        ).to(self.device)\n        self.audio_projection = torch.nn.Linear(\n            self.audio_model.config.hidden_size,\n            self.vector_size\n        ).to(self.device)\n\n    def _process_text(self, text: str) -&gt; torch.Tensor:\n        encoded_input = self.tokenizer(\n            text,\n            padding=True,\n            truncation=True,\n            max_length=self.vector_size,\n            return_tensors='pt'\n        ).to(self.device)\n\n        with torch.no_grad():\n            outputs = self.text_model(**encoded_input)\n            embeddings = self._mean_pooling(outputs, encoded_input['attention_mask'])\n            projected = self.text_projection(embeddings)\n            return torch.nn.functional.normalize(projected, p=2, dim=1)\n\n    def _process_image(self, image_data: bytes | str) -&gt; torch.Tensor:\n        # Handle different image input types\n        if isinstance(image_data, str):\n            if image_data.startswith('data:image'):\n                # Handle base64 encoded images\n                image_data = base64.b64decode(image_data.split(',')[1])\n            else:\n                # Handle file paths\n                with open(image_data, 'rb') as f:\n                    image_data = f.read()\n\n        # Convert bytes to PIL Image\n        image = Image.open(io.BytesIO(image_data))\n\n        # Process image with CLIP\n        inputs = self.clip_processor(images=image, return_tensors=\"pt\").to(self.device)\n\n        with torch.no_grad():\n            outputs = self.clip_model.get_image_features(**inputs)\n            projected = self.image_projection(outputs)\n            return torch.nn.functional.normalize(projected, p=2, dim=1)\n\n    def _process_audio(self, audio_data: bytes | str | np.ndarray) -&gt; torch.Tensor:\n        try:\n            import torchaudio\n        except ImportError:\n            raise ValueError(\"Couldn't load audio install torchaudio'\")\n        # Handle different audio input types\n        if isinstance(audio_data, str):\n            if audio_data.startswith('data:audio'):\n                # Handle base64 encoded audio\n                audio_data = base64.b64decode(audio_data.split(',')[1])\n                waveform, sample_rate = torchaudio.load(io.BytesIO(audio_data))\n            else:\n                # Handle file paths\n                waveform, sample_rate = torchaudio.load(audio_data)\n        elif isinstance(audio_data, bytes):\n            waveform, sample_rate = torchaudio.load(io.BytesIO(audio_data))\n        else:\n            # Assume numpy array with sample rate in metadata\n            waveform = torch.from_numpy(audio_data)\n            sample_rate = 16000  # Default sample rate\n\n        # Resample if necessary\n        if sample_rate != 16000:\n            resampler = torchaudio.transforms.Resample(sample_rate, 16000)\n            waveform = resampler(waveform)\n\n        # Process audio with Wav2Vec2\n        inputs = self.audio_processor(waveform, sampling_rate=16000, return_tensors=\"pt\").to(self.device)\n\n        with torch.no_grad():\n            outputs = self.audio_model(**inputs)\n            # Mean pooling over time dimension\n            embeddings = outputs.last_hidden_state.mean(dim=1)\n            projected = self.audio_projection(embeddings)\n            return torch.nn.functional.normalize(projected, p=2, dim=1)\n\n    def _mean_pooling(self, model_output: torch.Tensor, attention_mask: torch.Tensor) -&gt; torch.Tensor:\n        token_embeddings = model_output[0]\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n\n    def process_input(self, input_data: InputData) -&gt; np.ndarray:\n        if input_data.modality == \"text\":\n            embeddings = self._process_text(input_data.content)\n        elif input_data.modality == \"image\":\n            embeddings = self._process_image(input_data.content)\n        elif input_data.modality == \"audio\":\n            embeddings = self._process_audio(input_data.content)\n        else:\n            raise ValueError(f\"Unsupported modality: {input_data.modality}\")\n\n        return embeddings.cpu().numpy()\n\n    def compute_query_embeddings(self, query: str | bytes | np.ndarray, modality: str = \"text\") -&gt; list[\n        np.ndarray]:\n        \"\"\"Compute embeddings for query input\"\"\"\n        input_data = InputData(query, modality)\n        embedding = self.process_input(input_data)\n        return [embedding.squeeze()]\n\n    def compute_source_embeddings(self, sources: list[str | bytes | np.ndarray], modalities: list[str]) -&gt; list[\n        np.ndarray]:\n        \"\"\"Compute embeddings for source inputs\"\"\"\n        embeddings = []\n        for source, modality in zip(sources, modalities, strict=False):\n            input_data = InputData(source, modality)\n            embedding = self.process_input(input_data)\n            embeddings.append(embedding.squeeze())\n        return embeddings\n\n    def ndims(self) -&gt; int:\n        return self._ndims\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.one.IntelligenceRingEmbeddings.compute_query_embeddings","title":"<code>compute_query_embeddings(query, modality='text')</code>","text":"<p>Compute embeddings for query input</p> Source code in <code>toolboxv2/mods/TruthSeeker/one.py</code> <pre><code>def compute_query_embeddings(self, query: str | bytes | np.ndarray, modality: str = \"text\") -&gt; list[\n    np.ndarray]:\n    \"\"\"Compute embeddings for query input\"\"\"\n    input_data = InputData(query, modality)\n    embedding = self.process_input(input_data)\n    return [embedding.squeeze()]\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.one.IntelligenceRingEmbeddings.compute_source_embeddings","title":"<code>compute_source_embeddings(sources, modalities)</code>","text":"<p>Compute embeddings for source inputs</p> Source code in <code>toolboxv2/mods/TruthSeeker/one.py</code> <pre><code>def compute_source_embeddings(self, sources: list[str | bytes | np.ndarray], modalities: list[str]) -&gt; list[\n    np.ndarray]:\n    \"\"\"Compute embeddings for source inputs\"\"\"\n    embeddings = []\n    for source, modality in zip(sources, modalities, strict=False):\n        input_data = InputData(source, modality)\n        embedding = self.process_input(input_data)\n        embeddings.append(embedding.squeeze())\n    return embeddings\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.tests","title":"<code>tests</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.tests.TestTruthSeeker","title":"<code>TestTruthSeeker</code>","text":"<p>               Bases: <code>TestCase</code></p> Source code in <code>toolboxv2/mods/TruthSeeker/tests.py</code> <pre><code>class TestTruthSeeker(unittest.TestCase):\n    def setUp(self):\n        # Mock the App class\n        self.mock_app = Mock()\n        self.mock_app.get_mod.return_value = Mock()\n\n        # Setup mock for run_any that returns iterable dict\n        self.mock_app.run_any.return_value = {\n            \"1\": {\"name\": \"template1\"},\n            \"2\": {\"name\": \"template2\"}\n        }\n\n        # Mock RequestSession\n        self.mock_request = Mock()\n        self.mock_request.json = AsyncMock()\n\n    @patch('os.path.join')\n    @patch('builtins.open', create=True)\n    def test_start_initialization(self, mock_open, mock_join):\n        \"\"\"Test the start function initializes correctly\"\"\"\n        # Setup mock file handling\n        mock_file = Mock()\n        mock_file.read.return_value = \"test content\"\n        mock_open.return_value.__enter__.return_value = mock_file\n\n        # Call start function\n        start(self.mock_app)\n\n        # Verify app initialization calls\n        self.mock_app.get_mod.assert_called_with(\"CodeVerification\")\n        self.mock_app.run_any.assert_any_call((\"CodeVerification\", \"init_scope\"), scope=\"TruthSeeker\")\n        self.mock_app.run_any.assert_any_call((\"CodeVerification\", \"init_scope\"), scope=\"TruthSeeker-promo\")\n\n    @async_test\n    async def test_codes_valid_request(self):\n        \"\"\"Test the codes function with valid input\"\"\"\n        # Mock request data\n        test_data = {\n            \"query\": \"test query\",\n            \"depth\": \"Q\",\n            \"promoCode\": \"PROMO15\",\n            \"ontimeCode\": \"TEST123\"\n        }\n        self.mock_request.json.return_value = test_data\n\n        # Mock code verification\n        self.mock_app.run_any.return_value = {\n            \"template_name\": \"Promo15\",\n            \"usage_type\": \"one_time\"\n        }\n\n        result = await codes(self.mock_app, self.mock_request)\n\n        self.assertTrue(result['valid'])\n        self.assertIn('ontimeKey', result)\n        self.assertIn('ppc', result)\n\n    @async_test\n    async def test_codes_invalid_promo(self):\n        \"\"\"Test the codes function with invalid promo code\"\"\"\n        test_data = {\n            \"query\": \"test query\",\n            \"depth\": \"I\",\n            \"promoCode\": \"INVALID\",\n            \"ontimeCode\": \"TEST123\"\n        }\n        self.mock_request.json.return_value = test_data\n\n        # Mock invalid promo code verification\n        self.mock_app.run_any.return_value = None\n\n        result = await codes(self.mock_app, self.mock_request)\n\n        self.assertIn('ppc', result)\n        self.assertTrue(result['ppc']['price'] &gt; 0)\n\n    @async_test\n    async def test_process_valid_request(self):\n        \"\"\"Test the process function with valid input\"\"\"\n        test_data = {\n            \"query\": \"test query\",\n            \"depth\": \"Q\",\n            \"ontimeKey\": \"VALID_KEY\",\n            \"email\": \"test@example.com\"\n        }\n        self.mock_request.json.return_value = test_data\n\n        # Mock valid key verification\n        self.mock_app.run_any.return_value = {\n            \"template_name\": \"PROCESS\",\n            \"usage_type\": \"timed\",\n            \"uses_count\": 1\n        }\n\n        # Mock ArXivPDFProcessor\n        with patch('toolboxv2.mods.TruthSeeker.module.ArXivPDFProcessor') as mock_processor:\n            mock_insights = MagicMock()\n            mock_insights.is_true = \"True\"\n            mock_insights.summary = \"Test summary\"\n            mock_insights.key_point = \"Point1&gt;\\n\\n&lt;Point2\"\n\n            mock_processor.return_value.process.return_value = ([], mock_insights)\n\n            result = await process(self.mock_app, self.mock_request)\n\n            self.assertEqual(result['is_true'], \"True\")\n            self.assertEqual(result['summary'], \"Test summary\")\n\n    @async_test\n    async def test_process_invalid_key(self):\n        \"\"\"Test the process function with invalid key\"\"\"\n        test_data = {\n            \"query\": \"test query\",\n            \"depth\": \"Q\",\n            \"ontimeKey\": \"INVALID_KEY\",\n            \"email\": \"test@example.com\"\n        }\n        self.mock_request.json.return_value = test_data\n\n        # Mock invalid key verification\n        self.mock_app.run_any.return_value = None\n\n        result = await process(self.mock_app, self.mock_request)\n\n        self.assertEqual(result['summary'], \"INVALID QUERY\")\n        self.assertEqual(result['insights'], [])\n        self.assertEqual(result['papers'], [])\n\n    def test_byCode_functionality(self):\n        \"\"\"Test the byCode function\"\"\"\n        test_request = Mock()\n        test_request.json.return_value = [\"payKey\", \"codeClass\", \"ontimeKey\"]\n\n        result = byCode(self.mock_app, test_request)\n\n        self.assertEqual(result, {'code': 'code'})\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.tests.TestTruthSeeker.test_byCode_functionality","title":"<code>test_byCode_functionality()</code>","text":"<p>Test the byCode function</p> Source code in <code>toolboxv2/mods/TruthSeeker/tests.py</code> <pre><code>def test_byCode_functionality(self):\n    \"\"\"Test the byCode function\"\"\"\n    test_request = Mock()\n    test_request.json.return_value = [\"payKey\", \"codeClass\", \"ontimeKey\"]\n\n    result = byCode(self.mock_app, test_request)\n\n    self.assertEqual(result, {'code': 'code'})\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.tests.TestTruthSeeker.test_codes_invalid_promo","title":"<code>test_codes_invalid_promo()</code>  <code>async</code>","text":"<p>Test the codes function with invalid promo code</p> Source code in <code>toolboxv2/mods/TruthSeeker/tests.py</code> <pre><code>@async_test\nasync def test_codes_invalid_promo(self):\n    \"\"\"Test the codes function with invalid promo code\"\"\"\n    test_data = {\n        \"query\": \"test query\",\n        \"depth\": \"I\",\n        \"promoCode\": \"INVALID\",\n        \"ontimeCode\": \"TEST123\"\n    }\n    self.mock_request.json.return_value = test_data\n\n    # Mock invalid promo code verification\n    self.mock_app.run_any.return_value = None\n\n    result = await codes(self.mock_app, self.mock_request)\n\n    self.assertIn('ppc', result)\n    self.assertTrue(result['ppc']['price'] &gt; 0)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.tests.TestTruthSeeker.test_codes_valid_request","title":"<code>test_codes_valid_request()</code>  <code>async</code>","text":"<p>Test the codes function with valid input</p> Source code in <code>toolboxv2/mods/TruthSeeker/tests.py</code> <pre><code>@async_test\nasync def test_codes_valid_request(self):\n    \"\"\"Test the codes function with valid input\"\"\"\n    # Mock request data\n    test_data = {\n        \"query\": \"test query\",\n        \"depth\": \"Q\",\n        \"promoCode\": \"PROMO15\",\n        \"ontimeCode\": \"TEST123\"\n    }\n    self.mock_request.json.return_value = test_data\n\n    # Mock code verification\n    self.mock_app.run_any.return_value = {\n        \"template_name\": \"Promo15\",\n        \"usage_type\": \"one_time\"\n    }\n\n    result = await codes(self.mock_app, self.mock_request)\n\n    self.assertTrue(result['valid'])\n    self.assertIn('ontimeKey', result)\n    self.assertIn('ppc', result)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.tests.TestTruthSeeker.test_process_invalid_key","title":"<code>test_process_invalid_key()</code>  <code>async</code>","text":"<p>Test the process function with invalid key</p> Source code in <code>toolboxv2/mods/TruthSeeker/tests.py</code> <pre><code>@async_test\nasync def test_process_invalid_key(self):\n    \"\"\"Test the process function with invalid key\"\"\"\n    test_data = {\n        \"query\": \"test query\",\n        \"depth\": \"Q\",\n        \"ontimeKey\": \"INVALID_KEY\",\n        \"email\": \"test@example.com\"\n    }\n    self.mock_request.json.return_value = test_data\n\n    # Mock invalid key verification\n    self.mock_app.run_any.return_value = None\n\n    result = await process(self.mock_app, self.mock_request)\n\n    self.assertEqual(result['summary'], \"INVALID QUERY\")\n    self.assertEqual(result['insights'], [])\n    self.assertEqual(result['papers'], [])\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.tests.TestTruthSeeker.test_process_valid_request","title":"<code>test_process_valid_request()</code>  <code>async</code>","text":"<p>Test the process function with valid input</p> Source code in <code>toolboxv2/mods/TruthSeeker/tests.py</code> <pre><code>@async_test\nasync def test_process_valid_request(self):\n    \"\"\"Test the process function with valid input\"\"\"\n    test_data = {\n        \"query\": \"test query\",\n        \"depth\": \"Q\",\n        \"ontimeKey\": \"VALID_KEY\",\n        \"email\": \"test@example.com\"\n    }\n    self.mock_request.json.return_value = test_data\n\n    # Mock valid key verification\n    self.mock_app.run_any.return_value = {\n        \"template_name\": \"PROCESS\",\n        \"usage_type\": \"timed\",\n        \"uses_count\": 1\n    }\n\n    # Mock ArXivPDFProcessor\n    with patch('toolboxv2.mods.TruthSeeker.module.ArXivPDFProcessor') as mock_processor:\n        mock_insights = MagicMock()\n        mock_insights.is_true = \"True\"\n        mock_insights.summary = \"Test summary\"\n        mock_insights.key_point = \"Point1&gt;\\n\\n&lt;Point2\"\n\n        mock_processor.return_value.process.return_value = ([], mock_insights)\n\n        result = await process(self.mock_app, self.mock_request)\n\n        self.assertEqual(result['is_true'], \"True\")\n        self.assertEqual(result['summary'], \"Test summary\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.tests.TestTruthSeeker.test_start_initialization","title":"<code>test_start_initialization(mock_open, mock_join)</code>","text":"<p>Test the start function initializes correctly</p> Source code in <code>toolboxv2/mods/TruthSeeker/tests.py</code> <pre><code>@patch('os.path.join')\n@patch('builtins.open', create=True)\ndef test_start_initialization(self, mock_open, mock_join):\n    \"\"\"Test the start function initializes correctly\"\"\"\n    # Setup mock file handling\n    mock_file = Mock()\n    mock_file.read.return_value = \"test content\"\n    mock_open.return_value.__enter__.return_value = mock_file\n\n    # Call start function\n    start(self.mock_app)\n\n    # Verify app initialization calls\n    self.mock_app.get_mod.assert_called_with(\"CodeVerification\")\n    self.mock_app.run_any.assert_any_call((\"CodeVerification\", \"init_scope\"), scope=\"TruthSeeker\")\n    self.mock_app.run_any.assert_any_call((\"CodeVerification\", \"init_scope\"), scope=\"TruthSeeker-promo\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.tests.run_all_tests","title":"<code>run_all_tests()</code>","text":"<p>Run all test classes</p> Source code in <code>toolboxv2/mods/TruthSeeker/tests.py</code> <pre><code>@default_test\ndef run_all_tests():\n    \"\"\"Run all test classes\"\"\"\n    return run_test_suite()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.tests.run_arxiv_processor_tests","title":"<code>run_arxiv_processor_tests(test_name=None)</code>","text":"<p>Run TestArXivPDFProcessor tests</p> Source code in <code>toolboxv2/mods/TruthSeeker/tests.py</code> <pre><code>def run_arxiv_processor_tests(test_name=None):\n    \"\"\"Run TestArXivPDFProcessor tests\"\"\"\n    return run_test_suite(TestArXivPDFProcessor, test_name)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.tests.run_pdf_downloader_tests","title":"<code>run_pdf_downloader_tests(test_name=None)</code>","text":"<p>Run TestRobustPDFDownloader tests</p> Source code in <code>toolboxv2/mods/TruthSeeker/tests.py</code> <pre><code>def run_pdf_downloader_tests(test_name=None):\n    \"\"\"Run TestRobustPDFDownloader tests\"\"\"\n    return run_test_suite(TestRobustPDFDownloader, test_name)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.tests.run_specific_test","title":"<code>run_specific_test(test_class, test_name)</code>","text":"<p>Run a specific test from a test class</p> Source code in <code>toolboxv2/mods/TruthSeeker/tests.py</code> <pre><code>def run_specific_test(test_class, test_name):\n    \"\"\"Run a specific test from a test class\"\"\"\n    return run_test_suite(test_class, test_name)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.tests.run_test_suite","title":"<code>run_test_suite(test_class=None, test_name=None, verbosity=2)</code>","text":"<p>Run specific test class or test case.</p> <p>Parameters:</p> Name Type Description Default <code>test_class</code> <p>The test class to run (optional)</p> <code>None</code> <code>test_name</code> <p>Specific test method name to run (optional)</p> <code>None</code> <code>verbosity</code> <p>Output detail level (default=2)</p> <code>2</code> <p>Returns:</p> Type Description <p>TestResult object</p> Source code in <code>toolboxv2/mods/TruthSeeker/tests.py</code> <pre><code>def run_test_suite(test_class=None, test_name=None, verbosity=2):\n    \"\"\"\n    Run specific test class or test case.\n\n    Args:\n        test_class: The test class to run (optional)\n        test_name: Specific test method name to run (optional)\n        verbosity: Output detail level (default=2)\n\n    Returns:\n        TestResult object\n    \"\"\"\n    loader = unittest.TestLoader()\n    suite = unittest.TestSuite()\n\n    if test_class and test_name:\n        # Run specific test method\n        suite.addTest(test_class(test_name))\n    elif test_class:\n        # Run all tests in the class\n        suite.addTests(loader.loadTestsFromTestCase(test_class))\n    else:\n        # Run all tests\n        suite.addTests(loader.loadTestsFromModule(sys.modules[__name__]))\n\n    runner = unittest.TextTestRunner(verbosity=verbosity)\n    return runner.run(suite)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.tests.run_truth_seeker_tests","title":"<code>run_truth_seeker_tests(test_name=None)</code>","text":"<p>Run TestTruthSeeker tests</p> Source code in <code>toolboxv2/mods/TruthSeeker/tests.py</code> <pre><code>def run_truth_seeker_tests(test_name=None):\n    \"\"\"Run TestTruthSeeker tests\"\"\"\n    return run_test_suite(TestTruthSeeker, test_name)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.tests.test_arxiv_search","title":"<code>test_arxiv_search()</code>","text":"<p>Run only ArXiv search tests</p> Source code in <code>toolboxv2/mods/TruthSeeker/tests.py</code> <pre><code>@default_test\ndef test_arxiv_search():\n    \"\"\"Run only ArXiv search tests\"\"\"\n    return run_specific_test(\n        TestArXivPDFProcessor,\n        'test_search_and_process_papers'\n    )\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.tests.test_pdf_download","title":"<code>test_pdf_download()</code>","text":"<p>Run only PDF download tests</p> Source code in <code>toolboxv2/mods/TruthSeeker/tests.py</code> <pre><code>@default_test\ndef test_pdf_download():\n    \"\"\"Run only PDF download tests\"\"\"\n    return run_specific_test(\n        TestRobustPDFDownloader,\n        'test_download_pdf_success'\n    )\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.TruthSeeker.tests.test_truth_seeker","title":"<code>test_truth_seeker()</code>","text":"<p>Run only PDF download tests</p> Source code in <code>toolboxv2/mods/TruthSeeker/tests.py</code> <pre><code>@default_test\ndef test_truth_seeker():\n    \"\"\"Run only PDF download tests\"\"\"\n    return run_specific_test(\n        TestTruthSeeker,\n        'test_truth_seeker_success'\n    )\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.UltimateTTT","title":"<code>UltimateTTT</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.UltimateTTT.UltimateTTTGameEngine","title":"<code>UltimateTTTGameEngine</code>","text":"Source code in <code>toolboxv2/mods/UltimateTTT.py</code> <pre><code>class UltimateTTTGameEngine:  # Renamed for clarity\n    def __init__(self, game_state: GameState):\n        self.gs = game_state\n        self.size = game_state.config.grid_size\n\n    def _check_line_for_win(self, line: list[CellState | BoardWinner],\n                            symbol_to_check: CellState | BoardWinner) -&gt; bool:\n        if not line or line[0] == CellState.EMPTY or line[0] == BoardWinner.NONE:\n            return False\n        return all(cell == symbol_to_check for cell in line)\n\n    def _get_board_winner_symbol(self, board: list[list[CellState | BoardWinner]],\n                                 symbol_class: type[CellState] | type[BoardWinner]) -&gt; CellState | BoardWinner | None:\n        symbols_to_try = [symbol_class.X, symbol_class.O]\n        for symbol in symbols_to_try:\n            # Rows\n            for r in range(self.size):\n                if self._check_line_for_win([board[r][c] for c in range(self.size)], symbol): return symbol\n            # Columns\n            for c in range(self.size):\n                if self._check_line_for_win([board[r][c] for r in range(self.size)], symbol): return symbol\n            # Diagonals\n            if self._check_line_for_win([board[i][i] for i in range(self.size)], symbol): return symbol\n            if self._check_line_for_win([board[i][self.size - 1 - i] for i in range(self.size)], symbol): return symbol\n        return None  # No winner\n\n    def _is_board_full(self, board: list[list[CellState | BoardWinner]],\n                       empty_value: CellState | BoardWinner) -&gt; bool:\n        return all(cell != empty_value for row in board for cell in row)\n\n    def _determine_local_board_result(self, global_r: int, global_c: int) -&gt; BoardWinner:\n        if self.gs.global_board_winners[global_r][global_c] != BoardWinner.NONE:\n            return self.gs.global_board_winners[global_r][global_c]\n\n        local_board_cells = self.gs.local_boards_state[global_r][global_c]\n        winner_symbol = self._get_board_winner_symbol(local_board_cells, CellState)\n        if winner_symbol:\n            return BoardWinner(winner_symbol.value)  # Convert CellState.X to BoardWinner.X\n        if self._is_board_full(local_board_cells, CellState.EMPTY):\n            return BoardWinner.DRAW\n        return BoardWinner.NONE\n\n    def _update_local_winner_and_check_global(self, global_r: int, global_c: int):\n        new_local_winner = self._determine_local_board_result(global_r, global_c)\n        if new_local_winner != BoardWinner.NONE and self.gs.global_board_winners[global_r][\n            global_c] == BoardWinner.NONE:\n            self.gs.global_board_winners[global_r][global_c] = new_local_winner\n            self._check_for_overall_game_end()\n\n    def _check_for_overall_game_end(self):\n        if self.gs.status == GameStatus.FINISHED: return\n\n        winner_board_symbol = self._get_board_winner_symbol(self.gs.global_board_winners, BoardWinner)\n        if winner_board_symbol:  # This is BoardWinner.X or BoardWinner.O\n            self.gs.overall_winner_symbol = PlayerSymbol(winner_board_symbol.value)  # Convert to PlayerSymbol\n            self.gs.status = GameStatus.FINISHED\n            return\n\n        if self._is_board_full(self.gs.global_board_winners, BoardWinner.NONE):\n            self.gs.is_draw = True\n            self.gs.status = GameStatus.FINISHED\n\n    def _determine_next_forced_board(self, last_move_local_r: int, last_move_local_c: int) -&gt; tuple[int, int] | None:\n        target_gr, target_gc = last_move_local_r, last_move_local_c\n\n        if self.gs.global_board_winners[target_gr][target_gc] == BoardWinner.NONE and \\\n            not self._is_local_board_full(self.gs.local_boards_state[target_gr][target_gc], CellState.EMPTY):\n            return (target_gr, target_gc)\n        return None  # Play anywhere valid\n\n    def _is_local_board_full(self, local_board_cells: list[list[CellState]], cell_type=CellState.EMPTY) -&gt; bool:\n        \"\"\"Checks if a specific local board (passed as a 2D list of CellState) is full.\"\"\"\n        for r in range(self.size):\n            for c in range(self.size):\n                if local_board_cells[r][c] == cell_type:\n                    return False\n        return True\n\n    def add_player(self, player_id: str, player_name: str,\n                   is_npc: bool = False, npc_difficulty: NPCDifficulty | None = None) -&gt; bool:\n        if len(self.gs.players) &gt;= 2:\n            self.gs.last_error_message = \"Game is already full (2 players max).\"\n            return False\n\n        # Reconnect logic for existing player (human or NPC if that makes sense)\n        existing_player = self.gs.get_player_info(player_id)\n        if existing_player:\n            if not existing_player.is_connected:\n                existing_player.is_connected = True\n                # If NPC \"reconnects\", ensure its properties are correct (though unlikely scenario for NPC)\n                if is_npc:\n                    existing_player.is_npc = True\n                    existing_player.npc_difficulty = npc_difficulty\n                    existing_player.name = player_name  # Update name if it changed for NPC\n\n                self.gs.last_error_message = None\n                self.gs.updated_at = datetime.now(UTC)\n\n                if len(self.gs.players) == 2 and all(p.is_connected for p in self.gs.players) and \\\n                    self.gs.status == GameStatus.WAITING_FOR_OPPONENT:  # Should not be waiting if NPC is P2\n                    self.gs.status = GameStatus.IN_PROGRESS\n                    player_x_info = next(p for p in self.gs.players if p.symbol == PlayerSymbol.X)\n                    self.gs.current_player_id = player_x_info.id\n                    self.gs.waiting_since = None\n                return True\n            else:  # Player ID exists and is already connected\n                self.gs.last_error_message = f\"Player with ID {player_id} is already in the game and connected.\"\n                return False\n\n        # Adding a new player\n        symbol = PlayerSymbol.X if not self.gs.players else PlayerSymbol.O\n\n        # Construct PlayerInfo with NPC details if applicable\n        player_info_data = {\n            \"id\": player_id,\n            \"symbol\": symbol,\n            \"name\": player_name,\n            \"is_connected\": True,  # NPCs are always \"connected\"\n            \"is_npc\": is_npc\n        }\n        if is_npc and npc_difficulty:\n            player_info_data[\"npc_difficulty\"] = npc_difficulty\n\n        new_player = PlayerInfo(**player_info_data)\n        self.gs.players.append(new_player)\n        self.gs.last_error_message = None\n\n        if len(self.gs.players) == 1:  # First player added\n            if self.gs.mode == GameMode.ONLINE:\n                self.gs.status = GameStatus.WAITING_FOR_OPPONENT\n                self.gs.current_player_id = player_id\n                self.gs.waiting_since = datetime.now(UTC)\n            # For local mode with P1, we wait for P2 (human or NPC) to be added\n            # No status change yet, current_player_id not set until P2 joins\n\n        elif len(self.gs.players) == 2:  # Both players now present\n            self.gs.status = GameStatus.IN_PROGRESS\n            player_x_info = next(p for p in self.gs.players if p.symbol == PlayerSymbol.X)\n            self.gs.current_player_id = player_x_info.id  # X always starts\n            self.gs.next_forced_global_board = None\n            self.gs.waiting_since = None\n\n            # If the second player added is an NPC and it's their turn (e.g. P1 is human, P2 is NPC, P1 made a move)\n            # This specific logic is more for when make_move hands over to an NPC.\n            # Here, we just set up the game. X (P1) will make the first move.\n\n        self.gs.updated_at = datetime.now(UTC)\n        return True\n\n    def make_move(self, move: Move) -&gt; bool:\n        self.gs.last_error_message = None\n\n        if self.gs.status != GameStatus.IN_PROGRESS:\n            self.gs.last_error_message = \"Game is not in progress.\"\n            return False\n\n        player_info = self.gs.get_player_info(move.player_id)\n        if not player_info or move.player_id != self.gs.current_player_id:\n            self.gs.last_error_message = \"Not your turn or invalid player.\"\n            return False\n\n        s = self.size\n        if not (0 &lt;= move.global_row &lt; s and 0 &lt;= move.global_col &lt; s and \\\n                0 &lt;= move.local_row &lt; s and 0 &lt;= move.local_col &lt; s):\n            self.gs.last_error_message = f\"Coordinates out of bounds for {s}x{s} grid.\"\n            return False\n\n        gr, gc, lr, lc = move.global_row, move.global_col, move.local_row, move.local_col\n\n        if self.gs.next_forced_global_board and (gr, gc) != self.gs.next_forced_global_board:\n            self.gs.last_error_message = f\"Must play in global board {self.gs.next_forced_global_board}.\"\n            return False\n\n        if self.gs.global_board_winners[gr][gc] != BoardWinner.NONE:\n            self.gs.last_error_message = f\"Local board ({gr},{gc}) is already decided.\"\n            return False\n        if self.gs.local_boards_state[gr][gc][lr][lc] != CellState.EMPTY:\n            self.gs.last_error_message = f\"Cell ({gr},{gc})-({lr},{lc}) is already empty.\"  # Should be 'not empty' or 'occupied'\n            # Correction:\n            self.gs.last_error_message = f\"Cell ({gr},{gc})-({lr},{lc}) is already occupied.\"\n            return False\n\n        self.gs.local_boards_state[gr][gc][lr][lc] = CellState(player_info.symbol.value)\n        self.gs.moves_history.append(move)\n\n        self._update_local_winner_and_check_global(gr, gc)\n\n        if self.gs.status == GameStatus.FINISHED:\n            self.gs.next_forced_global_board = None\n        else:\n            opponent_info = self.gs.get_opponent_info(self.gs.current_player_id)\n            self.gs.current_player_id = opponent_info.id\n            self.gs.next_forced_global_board = self._determine_next_forced_board(lr, lc)\n\n            if self.gs.next_forced_global_board is None:\n                is_any_move_possible = any(\n                    self.gs.global_board_winners[r_idx][c_idx] == BoardWinner.NONE and \\\n                    not self._is_local_board_full(self.gs.local_boards_state[r_idx][c_idx], CellState.EMPTY)\n                    for r_idx in range(s) for c_idx in range(s)\n                )\n                if not is_any_move_possible:\n                    self._check_for_overall_game_end()\n                    if self.gs.status != GameStatus.FINISHED:\n                        self.gs.is_draw = True\n                        self.gs.status = GameStatus.FINISHED\n\n        self.gs.updated_at = datetime.now(UTC)\n        self.gs.last_made_move_coords = (move.global_row, move.global_col, move.local_row, move.local_col)\n\n        return True\n\n    def handle_player_disconnect(self, player_id: str):\n        player = self.gs.get_player_info(player_id)\n        app = get_app(GAME_NAME)  # Hol dir die App-Instanz\n        if player:\n            if not player.is_connected:  # Already marked as disconnected\n                app.logger.info(f\"Player {player_id} was already marked as disconnected from game {self.gs.game_id}.\")\n                return\n\n            player.is_connected = False\n            self.gs.updated_at = datetime.now(UTC)\n            app.logger.info(f\"Player {player_id} disconnected from game {self.gs.game_id}. Name: {player.name}\")\n\n            if self.gs.mode == GameMode.ONLINE:\n                if self.gs.status == GameStatus.IN_PROGRESS:\n                    opponent = self.gs.get_opponent_info(player_id)\n                    if opponent and opponent.is_connected:\n                        self.gs.status = GameStatus.ABORTED  # Use ABORTED as \"paused\"\n                        self.gs.player_who_paused = player_id  # Store who disconnected\n                        # This message is for the game state, will be seen by the other player via SSE\n                        self.gs.last_error_message = f\"Player {player.name} disconnected. Waiting for them to rejoin.\"\n                        app.logger.info(\n                            f\"Game {self.gs.game_id} PAUSED, waiting for {player.name} ({player_id}) to reconnect.\")\n                    else:\n                        # Opponent also disconnected or was already gone\n                        self.gs.status = GameStatus.ABORTED\n                        self.gs.last_error_message = \"Both players disconnected. Game aborted.\"\n                        self.gs.player_who_paused = None  # No specific player to wait for\n                        app.logger.info(\n                            f\"Game {self.gs.game_id} ABORTED, both players (or last active player) disconnected.\")\n                elif self.gs.status == GameStatus.WAITING_FOR_OPPONENT:\n                    # If the creator (P1) disconnects while waiting for P2\n                    if len(self.gs.players) == 1 and self.gs.players[0].id == player_id:\n                        self.gs.status = GameStatus.ABORTED\n                        self.gs.last_error_message = \"Game creator disconnected before opponent joined. Game aborted.\"\n                        self.gs.player_who_paused = None\n                        app.logger.info(\n                            f\"Game {self.gs.game_id} ABORTED, creator {player.name} ({player_id}) disconnected while WAITING_FOR_OPPONENT.\")\n                elif self.gs.status == GameStatus.ABORTED and self.gs.player_who_paused:\n                    # Game was already paused (e.g. P1 disconnected), and now P2 (the waiting one) disconnects\n                    if self.gs.player_who_paused != player_id:  # Ensure it's the other player\n                        self.gs.last_error_message = \"Other player also disconnected during pause. Game aborted.\"\n                        self.gs.player_who_paused = None  # No one specific to wait for now\n                        app.logger.info(\n                            f\"Game {self.gs.game_id} ABORTED, waiting player {player.name} ({player_id}) disconnected.\")\n\n    def handle_player_reconnect(self, player_id: str) -&gt; bool:\n        player = self.gs.get_player_info(player_id)\n        app = get_app(GAME_NAME)\n        if not player:\n            app.logger.warning(f\"Reconnect attempt for unknown player {player_id} in game {self.gs.game_id}.\")\n            return False\n\n        if player.is_connected:\n            app.logger.info(\n                f\"Player {player.name} ({player_id}) attempted reconnect but was already marked as connected to game {self.gs.game_id}.\")\n            if self.gs.status == GameStatus.ABORTED and self.gs.player_who_paused == player_id:\n                opponent = self.gs.get_opponent_info(player_id)\n                if opponent and opponent.is_connected:\n                    self.gs.status = GameStatus.IN_PROGRESS\n                    self.gs.last_error_message = f\"Connection for {player.name} re-established. Game resumed.\"\n                    self.gs.player_who_paused = None\n                    self.gs.updated_at = datetime.now(UTC)\n                    app.logger.info(\n                        f\"Game {self.gs.game_id} resumed as already-connected pauser {player.name} re-interacted.\")\n                else:\n                    self.gs.last_error_message = f\"Welcome back, {player.name}! Your opponent is still not connected.\"\n            return True\n\n        player.is_connected = True\n        self.gs.updated_at = datetime.now(UTC)\n        app.logger.info(\n            f\"Player {player.name} ({player_id}) reconnected to game {self.gs.game_id}. Previous status: {self.gs.status}, Paused by: {self.gs.player_who_paused}\")\n\n        if self.gs.status == GameStatus.ABORTED:\n            if self.gs.player_who_paused == player_id:  # The player who caused the pause has reconnected\n                opponent = self.gs.get_opponent_info(player_id)\n                if opponent and opponent.is_connected:\n                    self.gs.status = GameStatus.IN_PROGRESS\n                    self.gs.last_error_message = f\"Player {player.name} reconnected. Game resumed!\"\n                    self.gs.player_who_paused = None\n                    app.logger.info(\n                        f\"Game {self.gs.game_id} RESUMED. Pauser {player.name} reconnected, opponent {opponent.name} is present.\")\n                else:  # Pauser reconnected, opponent (still) gone or never joined (if P1 disconnected from WAITING)\n                    if not opponent and len(\n                        self.gs.players) == 1:  # P1 reconnected to a game they created but no P2 yet\n                        self.gs.status = GameStatus.WAITING_FOR_OPPONENT\n                        self.gs.player_who_paused = None\n                        self.gs.current_player_id = player_id\n                        self.gs.last_error_message = f\"Creator {player.name} reconnected. Waiting for opponent.\"\n                        self.gs.waiting_since = datetime.now(UTC)  # Reset waiting timer\n                    elif opponent:  # Opponent was there but is now disconnected\n                        self.gs.player_who_paused = opponent.id  # Now waiting for the other person\n                        self.gs.last_error_message = f\"Welcome back, {player.name}! Your opponent ({opponent.name}) is not connected. Game remains paused.\"\n                        app.logger.info(\n                            f\"Game {self.gs.game_id} still PAUSED. {player.name} reconnected, but opponent {opponent.name} is NOT. Waiting for {opponent.name}.\")\n                    else:  # Should be rare: 2 players in list, but opponent object not found for P1\n                        self.gs.last_error_message = f\"Welcome back, {player.name}! Opponent details unclear. Game remains paused.\"\n\n\n            elif self.gs.player_who_paused and self.gs.player_who_paused != player_id:\n                # The *other* player reconnected, while game was paused for initial pauser.\n                initial_pauser_info = self.gs.get_player_info(self.gs.player_who_paused)\n                if initial_pauser_info and initial_pauser_info.is_connected:  # This implies both are now connected.\n                    self.gs.status = GameStatus.IN_PROGRESS\n                    self.gs.last_error_message = \"Both players are now connected. Game resumed!\"\n                    self.gs.player_who_paused = None\n                    app.logger.info(\n                        f\"Game {self.gs.game_id} RESUMED. Waiting player {player.name} reconnected, initial pauser {initial_pauser_info.name} also present.\")\n                else:\n                    self.gs.last_error_message = f\"Welcome back, {player.name}! Still waiting for {initial_pauser_info.name if initial_pauser_info else 'the other player'} to reconnect.\"\n                    app.logger.info(\n                        f\"Game {self.gs.game_id} still PAUSED. Player {player.name} reconnected, but still waiting for original pauser {self.gs.player_who_paused}.\")\n\n            else:  # game is ABORTED but no specific player_who_paused (hard abort by timeout or both disconnected)\n                if len(self.gs.players) == 2:  # Was a two-player game\n                    opponent = self.gs.get_opponent_info(player_id)\n                    if opponent:\n                        # Revive the game to a paused state, waiting for the other player\n                        self.gs.player_who_paused = opponent.id\n                        self.gs.status = GameStatus.ABORTED  # Remains aborted, but now specifically for opponent\n                        self.gs.last_error_message = f\"Welcome back, {player.name}! Game was fully aborted. Now waiting for {opponent.name} to rejoin.\"\n                        app.logger.info(\n                            f\"Game {self.gs.game_id} REVIVED from HARD ABORT by {player.name}. Now paused, waiting for {opponent.name} ({opponent.id}).\")\n                    else:  # Should not happen if two players were in game and player_id is one of them\n                        self.gs.last_error_message = f\"Player {player.name} reconnected, but game state is inconsistent (opponent not found).\"\n                        app.logger.warning(\n                            f\"Game {self.gs.game_id} HARD ABORT revival by {player.name} failed, opponent info missing.\")\n                elif len(self.gs.players) == 1 and self.gs.players[0].id == player_id:\n                    # P1 created, P1 disconnected, game WAITING_FOR_OPPONENT timed out &amp; hard aborted. P1 tries to rejoin.\n                    self.gs.status = GameStatus.WAITING_FOR_OPPONENT\n                    self.gs.player_who_paused = None\n                    self.gs.current_player_id = player_id\n                    self.gs.last_error_message = f\"Creator {player.name} reconnected. Waiting for opponent.\"\n                    self.gs.waiting_since = datetime.now(UTC)  # Reset waiting timer\n                    app.logger.info(\n                        f\"Game {self.gs.game_id} (previously hard aborted while waiting) revived by creator {player.name}. Now WAITING_FOR_OPPONENT.\")\n                else:\n                    self.gs.last_error_message = f\"Player {player.name} reconnected, but the game was aborted and cannot be revived in its current player configuration.\"\n                    app.logger.info(\n                        f\"Game {self.gs.game_id} HARD ABORTED. Player {player.name} reconnected, but game cannot resume in current configuration.\")\n\n\n        elif self.gs.status == GameStatus.IN_PROGRESS:\n            opponent = self.gs.get_opponent_info(player_id)\n            if not opponent or not opponent.is_connected:\n                self.gs.status = GameStatus.ABORTED\n                self.gs.player_who_paused = opponent.id if opponent else None\n                self.gs.last_error_message = f\"Welcome back, {player.name}! Your opponent disconnected while you were away. Waiting for them.\"\n                app.logger.info(\n                    f\"Game {self.gs.game_id} transitions to PAUSED. {player.name} reconnected to IN_PROGRESS, but opponent {opponent.id if opponent else 'N/A'} is gone.\")\n            else:\n                self.gs.last_error_message = f\"Player {player.name} re-established connection during active game.\"\n                app.logger.info(\n                    f\"Player {player.name} ({player_id}) re-established connection to IN_PROGRESS game {self.gs.game_id}.\")\n\n        elif self.gs.status == GameStatus.WAITING_FOR_OPPONENT:\n            if len(self.gs.players) == 1 and self.gs.players[0].id == player_id:\n                self.gs.last_error_message = f\"Creator {player.name} reconnected. Still waiting for opponent.\"\n                self.gs.current_player_id = player_id\n                self.gs.waiting_since = datetime.now(UTC)  # Reset waiting timer\n                app.logger.info(\n                    f\"Creator {player.name} ({player_id}) reconnected to WAITING_FOR_OPPONENT game {self.gs.game_id}.\")\n            else:\n                app.logger.warning(\n                    f\"Non-creator {player.name} or unexpected player count for reconnect to WAITING_FOR_OPPONENT game {self.gs.game_id}.\")\n\n        return True\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WebSocketManager","title":"<code>WebSocketManager</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.WebSocketManager.WebSocketPoolManager","title":"<code>WebSocketPoolManager</code>","text":"Source code in <code>toolboxv2/mods/WebSocketManager.py</code> <pre><code>class WebSocketPoolManager:\n    def __init__(self):\n        self.pools: dict[str, dict[str, Any]] = {}\n        self.logger = logging.getLogger(__name__)\n\n    async def create_pool(self, pool_id: str) -&gt; None:\n        \"\"\"Create a new WebSocket pool.\"\"\"\n        if pool_id not in self.pools:\n            self.pools[pool_id] = {\n                'connections': {},\n                'actions': {},\n                'global_actions': {}\n            }\n            self.logger.info(f\"Created new pool: {pool_id}\")\n        else:\n            self.logger.warning(f\"Pool {pool_id} already exists\")\n\n    async def add_connection(self, pool_id: str, connection_id: str, websocket) -&gt; None:\n        \"\"\"Add a WebSocket connection to a pool.\"\"\"\n        if pool_id not in self.pools:\n            await self.create_pool(pool_id)\n\n        self.pools[pool_id]['connections'][connection_id] = websocket\n        self.logger.info(f\"Added connection {connection_id} to pool {pool_id}\")\n\n    async def remove_connection(self, pool_id: str, connection_id: str) -&gt; None:\n        \"\"\"Remove a WebSocket connection from a pool.\"\"\"\n        if pool_id in self.pools and connection_id in self.pools[pool_id]['connections']:\n            del self.pools[pool_id]['connections'][connection_id]\n            self.logger.info(f\"Removed connection {connection_id} from pool {pool_id}\")\n        else:\n            self.logger.warning(f\"Connection {connection_id} not found in pool {pool_id}\")\n\n    def register_action(self, pool_id: str, action_name: str, handler: Callable,\n                        connection_ids: list[str] = None) -&gt; None:\n        \"\"\"Register an action for specific connections or the entire pool.\"\"\"\n        if pool_id not in self.pools:\n            self.logger.error(f\"Pool {pool_id} does not exist\")\n            return\n\n        if connection_ids is None:\n            self.pools[pool_id]['global_actions'][action_name] = handler\n            self.logger.info(f\"Registered global action {action_name} for pool {pool_id}\")\n        else:\n            for conn_id in connection_ids:\n                if conn_id not in self.pools[pool_id]['actions']:\n                    self.pools[pool_id]['actions'][conn_id] = {}\n                self.pools[pool_id]['actions'][conn_id][action_name] = handler\n            self.logger.info(f\"Registered action {action_name} for connections {connection_ids} in pool {pool_id}\")\n\n    async def handle_message(self, pool_id: str, connection_id: str, message: str) -&gt; None:\n        \"\"\"Handle incoming messages and route them to the appropriate action handler.\"\"\"\n        if pool_id not in self.pools or connection_id not in self.pools[pool_id]['connections']:\n            self.logger.error(f\"Invalid pool_id or connection_id: {pool_id}, {connection_id}\")\n            return\n\n        try:\n            data = json.loads(message)\n            action = data.get('action')\n\n            if action:\n                if action in self.pools[pool_id]['global_actions']:\n                    await self.pools[pool_id]['global_actions'][action](pool_id, connection_id, data)\n                elif connection_id in self.pools[pool_id]['actions'] and action in self.pools[pool_id]['actions'][\n                    connection_id]:\n                    await self.pools[pool_id]['actions'][connection_id][action](pool_id, connection_id, data)\n                else:\n                    self.logger.warning(f\"No handler found for action {action} in pool {pool_id}\")\n            else:\n                self.logger.warning(f\"No action specified in message from {connection_id} in pool {pool_id}\")\n        except json.JSONDecodeError:\n            self.logger.error(f\"Invalid JSON received from {connection_id} in pool {pool_id}\")\n\n    async def broadcast(self, pool_id: str, message: str, exclude_connection_id: str = None) -&gt; None:\n        \"\"\"Broadcast a message to all connections in a pool, optionally excluding one connection.\"\"\"\n        if pool_id not in self.pools:\n            self.logger.error(f\"Pool {pool_id} does not exist\")\n            return\n\n        for conn_id, websocket in self.pools[pool_id]['connections'].items():\n            if conn_id != exclude_connection_id:\n                try:\n                    await websocket.send_text(message)\n                except Exception as e:\n                    self.logger.error(f\"Error sending message to {conn_id} in pool {pool_id}: {str(e)}\")\n\n    async def send_to_connection(self, pool_id: str, connection_id: str, message: str) -&gt; None:\n        \"\"\"Send a message to a specific connection in a pool.\"\"\"\n        if pool_id in self.pools and connection_id in self.pools[pool_id]['connections']:\n            try:\n                await self.pools[pool_id]['connections'][connection_id].send_text(message)\n            except Exception as e:\n                self.logger.error(f\"Error sending message to {connection_id} in pool {pool_id}: {str(e)}\")\n        else:\n            self.logger.error(f\"Connection {connection_id} not found in pool {pool_id}\")\n\n    def get_pool_connections(self, pool_id: str) -&gt; list[str]:\n        \"\"\"Get a list of all connection IDs in a pool.\"\"\"\n        if pool_id in self.pools:\n            return list(self.pools[pool_id]['connections'].keys())\n        else:\n            self.logger.error(f\"Pool {pool_id} does not exist\")\n            return []\n\n    def get_all_pools(self) -&gt; list[str]:\n        \"\"\"Get a list of all pool IDs.\"\"\"\n        return list(self.pools.keys())\n\n    async def close_pool(self, pool_id: str) -&gt; None:\n        \"\"\"Close all connections in a pool and remove the pool.\"\"\"\n        if pool_id in self.pools:\n            for websocket in self.pools[pool_id]['connections'].values():\n                await websocket.close()\n            del self.pools[pool_id]\n            self.logger.info(f\"Closed and removed pool {pool_id}\")\n        else:\n            self.logger.warning(f\"Pool {pool_id} does not exist\")\n\n    async def close_all_pools(self) -&gt; None:\n        \"\"\"Close all connections in all pools and remove all pools.\"\"\"\n        for pool_id in list(self.pools.keys()):\n            await self.close_pool(pool_id)\n        self.logger.info(\"Closed all pools\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WebSocketManager.WebSocketPoolManager.add_connection","title":"<code>add_connection(pool_id, connection_id, websocket)</code>  <code>async</code>","text":"<p>Add a WebSocket connection to a pool.</p> Source code in <code>toolboxv2/mods/WebSocketManager.py</code> <pre><code>async def add_connection(self, pool_id: str, connection_id: str, websocket) -&gt; None:\n    \"\"\"Add a WebSocket connection to a pool.\"\"\"\n    if pool_id not in self.pools:\n        await self.create_pool(pool_id)\n\n    self.pools[pool_id]['connections'][connection_id] = websocket\n    self.logger.info(f\"Added connection {connection_id} to pool {pool_id}\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WebSocketManager.WebSocketPoolManager.broadcast","title":"<code>broadcast(pool_id, message, exclude_connection_id=None)</code>  <code>async</code>","text":"<p>Broadcast a message to all connections in a pool, optionally excluding one connection.</p> Source code in <code>toolboxv2/mods/WebSocketManager.py</code> <pre><code>async def broadcast(self, pool_id: str, message: str, exclude_connection_id: str = None) -&gt; None:\n    \"\"\"Broadcast a message to all connections in a pool, optionally excluding one connection.\"\"\"\n    if pool_id not in self.pools:\n        self.logger.error(f\"Pool {pool_id} does not exist\")\n        return\n\n    for conn_id, websocket in self.pools[pool_id]['connections'].items():\n        if conn_id != exclude_connection_id:\n            try:\n                await websocket.send_text(message)\n            except Exception as e:\n                self.logger.error(f\"Error sending message to {conn_id} in pool {pool_id}: {str(e)}\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WebSocketManager.WebSocketPoolManager.close_all_pools","title":"<code>close_all_pools()</code>  <code>async</code>","text":"<p>Close all connections in all pools and remove all pools.</p> Source code in <code>toolboxv2/mods/WebSocketManager.py</code> <pre><code>async def close_all_pools(self) -&gt; None:\n    \"\"\"Close all connections in all pools and remove all pools.\"\"\"\n    for pool_id in list(self.pools.keys()):\n        await self.close_pool(pool_id)\n    self.logger.info(\"Closed all pools\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WebSocketManager.WebSocketPoolManager.close_pool","title":"<code>close_pool(pool_id)</code>  <code>async</code>","text":"<p>Close all connections in a pool and remove the pool.</p> Source code in <code>toolboxv2/mods/WebSocketManager.py</code> <pre><code>async def close_pool(self, pool_id: str) -&gt; None:\n    \"\"\"Close all connections in a pool and remove the pool.\"\"\"\n    if pool_id in self.pools:\n        for websocket in self.pools[pool_id]['connections'].values():\n            await websocket.close()\n        del self.pools[pool_id]\n        self.logger.info(f\"Closed and removed pool {pool_id}\")\n    else:\n        self.logger.warning(f\"Pool {pool_id} does not exist\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WebSocketManager.WebSocketPoolManager.create_pool","title":"<code>create_pool(pool_id)</code>  <code>async</code>","text":"<p>Create a new WebSocket pool.</p> Source code in <code>toolboxv2/mods/WebSocketManager.py</code> <pre><code>async def create_pool(self, pool_id: str) -&gt; None:\n    \"\"\"Create a new WebSocket pool.\"\"\"\n    if pool_id not in self.pools:\n        self.pools[pool_id] = {\n            'connections': {},\n            'actions': {},\n            'global_actions': {}\n        }\n        self.logger.info(f\"Created new pool: {pool_id}\")\n    else:\n        self.logger.warning(f\"Pool {pool_id} already exists\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WebSocketManager.WebSocketPoolManager.get_all_pools","title":"<code>get_all_pools()</code>","text":"<p>Get a list of all pool IDs.</p> Source code in <code>toolboxv2/mods/WebSocketManager.py</code> <pre><code>def get_all_pools(self) -&gt; list[str]:\n    \"\"\"Get a list of all pool IDs.\"\"\"\n    return list(self.pools.keys())\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WebSocketManager.WebSocketPoolManager.get_pool_connections","title":"<code>get_pool_connections(pool_id)</code>","text":"<p>Get a list of all connection IDs in a pool.</p> Source code in <code>toolboxv2/mods/WebSocketManager.py</code> <pre><code>def get_pool_connections(self, pool_id: str) -&gt; list[str]:\n    \"\"\"Get a list of all connection IDs in a pool.\"\"\"\n    if pool_id in self.pools:\n        return list(self.pools[pool_id]['connections'].keys())\n    else:\n        self.logger.error(f\"Pool {pool_id} does not exist\")\n        return []\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WebSocketManager.WebSocketPoolManager.handle_message","title":"<code>handle_message(pool_id, connection_id, message)</code>  <code>async</code>","text":"<p>Handle incoming messages and route them to the appropriate action handler.</p> Source code in <code>toolboxv2/mods/WebSocketManager.py</code> <pre><code>async def handle_message(self, pool_id: str, connection_id: str, message: str) -&gt; None:\n    \"\"\"Handle incoming messages and route them to the appropriate action handler.\"\"\"\n    if pool_id not in self.pools or connection_id not in self.pools[pool_id]['connections']:\n        self.logger.error(f\"Invalid pool_id or connection_id: {pool_id}, {connection_id}\")\n        return\n\n    try:\n        data = json.loads(message)\n        action = data.get('action')\n\n        if action:\n            if action in self.pools[pool_id]['global_actions']:\n                await self.pools[pool_id]['global_actions'][action](pool_id, connection_id, data)\n            elif connection_id in self.pools[pool_id]['actions'] and action in self.pools[pool_id]['actions'][\n                connection_id]:\n                await self.pools[pool_id]['actions'][connection_id][action](pool_id, connection_id, data)\n            else:\n                self.logger.warning(f\"No handler found for action {action} in pool {pool_id}\")\n        else:\n            self.logger.warning(f\"No action specified in message from {connection_id} in pool {pool_id}\")\n    except json.JSONDecodeError:\n        self.logger.error(f\"Invalid JSON received from {connection_id} in pool {pool_id}\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WebSocketManager.WebSocketPoolManager.register_action","title":"<code>register_action(pool_id, action_name, handler, connection_ids=None)</code>","text":"<p>Register an action for specific connections or the entire pool.</p> Source code in <code>toolboxv2/mods/WebSocketManager.py</code> <pre><code>def register_action(self, pool_id: str, action_name: str, handler: Callable,\n                    connection_ids: list[str] = None) -&gt; None:\n    \"\"\"Register an action for specific connections or the entire pool.\"\"\"\n    if pool_id not in self.pools:\n        self.logger.error(f\"Pool {pool_id} does not exist\")\n        return\n\n    if connection_ids is None:\n        self.pools[pool_id]['global_actions'][action_name] = handler\n        self.logger.info(f\"Registered global action {action_name} for pool {pool_id}\")\n    else:\n        for conn_id in connection_ids:\n            if conn_id not in self.pools[pool_id]['actions']:\n                self.pools[pool_id]['actions'][conn_id] = {}\n            self.pools[pool_id]['actions'][conn_id][action_name] = handler\n        self.logger.info(f\"Registered action {action_name} for connections {connection_ids} in pool {pool_id}\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WebSocketManager.WebSocketPoolManager.remove_connection","title":"<code>remove_connection(pool_id, connection_id)</code>  <code>async</code>","text":"<p>Remove a WebSocket connection from a pool.</p> Source code in <code>toolboxv2/mods/WebSocketManager.py</code> <pre><code>async def remove_connection(self, pool_id: str, connection_id: str) -&gt; None:\n    \"\"\"Remove a WebSocket connection from a pool.\"\"\"\n    if pool_id in self.pools and connection_id in self.pools[pool_id]['connections']:\n        del self.pools[pool_id]['connections'][connection_id]\n        self.logger.info(f\"Removed connection {connection_id} from pool {pool_id}\")\n    else:\n        self.logger.warning(f\"Connection {connection_id} not found in pool {pool_id}\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WebSocketManager.WebSocketPoolManager.send_to_connection","title":"<code>send_to_connection(pool_id, connection_id, message)</code>  <code>async</code>","text":"<p>Send a message to a specific connection in a pool.</p> Source code in <code>toolboxv2/mods/WebSocketManager.py</code> <pre><code>async def send_to_connection(self, pool_id: str, connection_id: str, message: str) -&gt; None:\n    \"\"\"Send a message to a specific connection in a pool.\"\"\"\n    if pool_id in self.pools and connection_id in self.pools[pool_id]['connections']:\n        try:\n            await self.pools[pool_id]['connections'][connection_id].send_text(message)\n        except Exception as e:\n            self.logger.error(f\"Error sending message to {connection_id} in pool {pool_id}: {str(e)}\")\n    else:\n        self.logger.error(f\"Connection {connection_id} not found in pool {pool_id}\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb","title":"<code>WhatsAppTb</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client","title":"<code>client</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.DocumentSystem","title":"<code>DocumentSystem</code>","text":"Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>class DocumentSystem:\n    def __init__(self, storage: BlobStorage):\n        self.storage = storage\n        self.media_types = {\n            'document': ['pdf', 'doc', 'docx', 'txt'],\n            'image': ['jpg', 'jpeg', 'png', 'gif'],\n            'video': ['mp4', 'mov', 'avi']\n        }\n\n    def list_documents(self, filter_type: str = None) -&gt; list[dict]:\n        \"\"\"List all documents with metadata\"\"\"\n        docs = []\n        for blob_id in self.storage._get_all_blob_ids():\n            with BlobFile(blob_id, 'r', self.storage) as f:\n                metadata = f.read_json()\n                if metadata:\n                    docs.append({\n                        'id': blob_id,\n                        'name': metadata.get('filename', blob_id),\n                        'type': metadata.get('type', 'document'),\n                        'size': metadata.get('size', 0),\n                        'modified': metadata.get('timestamp', ''),\n                        'preview': metadata.get('preview', '')\n                    })\n        if filter_type:\n            return [d for d in docs if d['type'] == filter_type]\n        return docs\n\n    def save_document(self, file_data: bytes, filename: str, file_type: str) -&gt; str:\n        \"\"\"Save a document with metadata\"\"\"\n        blob_id = self.storage._generate_blob_id()\n        metadata = {\n            'filename': filename,\n            'type': file_type,\n            'size': len(file_data),\n            'timestamp': datetime.now().isoformat(),\n            'preview': self._generate_preview(file_data, file_type)\n        }\n\n        with BlobFile(blob_id, 'w', self.storage) as f:\n            f.write_json(metadata)\n            f.write(file_data)\n        return blob_id\n\n    def delete_document(self, blob_id: str) -&gt; bool:\n        \"\"\"Delete a document\"\"\"\n        try:\n            self.storage.delete_blob(blob_id)\n            return True\n        except Exception as e:\n            logging.error(f\"Delete failed: {str(e)}\")\n            return False\n\n    def search_documents(self, query: str) -&gt; list[dict]:\n        \"\"\"Search documents by filename or content\"\"\"\n        results = []\n        for doc in self.list_documents():\n            if query.lower() in doc['name'].lower() or self._search_in_content(doc['id'], query):\n                results.append(doc)\n        return results\n\n    def _generate_preview(self, data: bytes, file_type: str) -&gt; str:\n        \"\"\"Generate preview based on file type\"\"\"\n        if file_type in self.media_types['image']:\n            return f\"Image preview: {data[:100].hex()}\"\n        elif file_type in self.media_types['video']:\n            return \"Video preview unavailable\"\n        return data[:100].decode('utf-8', errors='ignore')\n\n    def _search_in_content(self, blob_id: str, query: str) -&gt; bool:\n        \"\"\"Search content within documents\"\"\"\n        try:\n            with BlobFile(blob_id, 'r', self.storage) as f:\n                content = f.read().decode('utf-8', errors='ignore')\n                return query.lower() in content.lower()\n        except:\n            return False\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.DocumentSystem.delete_document","title":"<code>delete_document(blob_id)</code>","text":"<p>Delete a document</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>def delete_document(self, blob_id: str) -&gt; bool:\n    \"\"\"Delete a document\"\"\"\n    try:\n        self.storage.delete_blob(blob_id)\n        return True\n    except Exception as e:\n        logging.error(f\"Delete failed: {str(e)}\")\n        return False\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.DocumentSystem.list_documents","title":"<code>list_documents(filter_type=None)</code>","text":"<p>List all documents with metadata</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>def list_documents(self, filter_type: str = None) -&gt; list[dict]:\n    \"\"\"List all documents with metadata\"\"\"\n    docs = []\n    for blob_id in self.storage._get_all_blob_ids():\n        with BlobFile(blob_id, 'r', self.storage) as f:\n            metadata = f.read_json()\n            if metadata:\n                docs.append({\n                    'id': blob_id,\n                    'name': metadata.get('filename', blob_id),\n                    'type': metadata.get('type', 'document'),\n                    'size': metadata.get('size', 0),\n                    'modified': metadata.get('timestamp', ''),\n                    'preview': metadata.get('preview', '')\n                })\n    if filter_type:\n        return [d for d in docs if d['type'] == filter_type]\n    return docs\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.DocumentSystem.save_document","title":"<code>save_document(file_data, filename, file_type)</code>","text":"<p>Save a document with metadata</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>def save_document(self, file_data: bytes, filename: str, file_type: str) -&gt; str:\n    \"\"\"Save a document with metadata\"\"\"\n    blob_id = self.storage._generate_blob_id()\n    metadata = {\n        'filename': filename,\n        'type': file_type,\n        'size': len(file_data),\n        'timestamp': datetime.now().isoformat(),\n        'preview': self._generate_preview(file_data, file_type)\n    }\n\n    with BlobFile(blob_id, 'w', self.storage) as f:\n        f.write_json(metadata)\n        f.write(file_data)\n    return blob_id\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.DocumentSystem.search_documents","title":"<code>search_documents(query)</code>","text":"<p>Search documents by filename or content</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>def search_documents(self, query: str) -&gt; list[dict]:\n    \"\"\"Search documents by filename or content\"\"\"\n    results = []\n    for doc in self.list_documents():\n        if query.lower() in doc['name'].lower() or self._search_in_content(doc['id'], query):\n            results.append(doc)\n    return results\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant","title":"<code>WhatsAppAssistant</code>  <code>dataclass</code>","text":"Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>@dataclass\nclass WhatsAppAssistant:\n    whc: WhClient\n    isaa: 'Tools'\n    agent: Optional['Agent'] = None\n    credentials: Credentials | None = None\n    state: AssistantState = AssistantState.OFFLINE\n\n    # Service clients\n    gmail_service: Any = None\n    calendar_service: Any = None\n\n    start_time: Any = None\n\n    blob_docs_system: Any = None\n    duration_minutes: int = 20\n    credentials_path: str = \"/root/Toolboxv2/credentials.json\"\n    # Progress messengers\n    progress_messengers: dict[str, 'ProgressMessenger'] = field(default_factory=dict)\n    buttons: dict[str, dict] = field(default_factory=dict)\n    history: FileCache = field(default_factory=FileCache)\n\n    pending_actions: dict[str, dict] = field(default_factory=dict)\n\n\n    def __post_init__(self):\n\n        self.start_time = datetime.now()\n        self.processed_messages = set()\n        self.message_lock = threading.Lock()\n        self.audio_processor = None\n        self.blob_docs_system = DocumentSystem(BlobStorage())\n        self.stt = get_app().run_any(TBEF.AUDIO.STT_GENERATE,\n                                     model=\"openai/whisper-small\",\n                                     row=False, device=1)\n\n        self.pending_actions[self.whc.progress_messenger0.recipient_phone] = {}\n\n        self.load_credentials()\n        self.setup_progress_messengers()\n        self.setup_interaction_buttons()\n        self.history = FileCache(folder=\".data/WhatsAppAssistant\")\n        self.state = AssistantState.ONLINE\n\n    async def generate_authorization_url(self, *a):\n        \"\"\"\n        Generate an authorization URL for user consent\n\n        :return: Authorization URL for the user to click and authorize access\n        \"\"\"\n        from google_auth_oauthlib.flow import Flow\n        # Define the scopes required for Gmail and Calendar\n        SCOPES = [\n            'https://www.googleapis.com/auth/gmail.modify',\n            'https://www.googleapis.com/auth/calendar'\n        ]\n\n        # Create a flow instance to manage the OAuth 2.0 authorization process\n        flow = Flow.from_client_secrets_file(\n            self.credentials_path,\n            scopes=SCOPES,\n            redirect_uri='urn:ietf:wg:oauth:2.0:oob'  # Use 'urn:ietf:wg:oauth:2.0:oob' for desktop apps\n        )\n\n        # Generate the authorization URL\n        authorization_url, _ = flow.authorization_url(\n            access_type='offline',  # Allows obtaining refresh token\n            prompt='consent'  # Ensures user is always prompted for consent\n        )\n        self.pending_actions[self.whc.progress_messenger0.recipient_phone] = {'type': 'auth',\n                                                                              'step': 'awaiting_key'}\n        return {\n            'type': 'quick_reply',\n            'text': f'Url to log in {authorization_url}',\n            'options': {'cancel': '\u274c Cancel Upload'}\n        }\n\n    def complete_authorization(self, message: Message):\n        \"\"\"\n        Complete the authorization process using the authorization code\n\n        :param authorization_code: Authorization code received from Google\n        \"\"\"\n        from google_auth_oauthlib.flow import Flow\n        authorization_code = message.content\n        # Define the scopes required for Gmail and Calendar\n        SCOPES = [\n            'https://www.googleapis.com/auth/gmail.modify',\n            'https://www.googleapis.com/auth/calendar'\n        ]\n\n        # Create a flow instance to manage the OAuth 2.0 authorization process\n        flow = Flow.from_client_secrets_file(\n            self.credentials_path,\n            scopes=SCOPES,\n            redirect_uri='urn:ietf:wg:oauth:2.0:oob'\n        )\n\n        # Exchange the authorization code for credentials\n        flow.fetch_token(code=authorization_code)\n        self.credentials = flow.credentials\n\n        # Save the credentials for future use\n        self.save_credentials()\n\n        # Initialize services\n        self.init_services()\n        return \"Done\"\n\n\n    def save_credentials(self):\n        \"\"\"\n        Save the obtained credentials to a file for future use\n        \"\"\"\n        if not os.path.exists('token'):\n            os.makedirs('token')\n\n        with open('token/google_token.json', 'w') as token_file:\n            token_file.write(self.credentials.to_json())\n\n\n    def load_credentials(self):\n        \"\"\"\n        Load previously saved credentials if available\n\n        :return: Whether credentials were successfully loaded\n        \"\"\"\n        try:\n            self.credentials = Credentials.from_authorized_user_file('token/google_token.json')\n            self.init_services()\n            return True\n        except FileNotFoundError:\n            return False\n\n\n    def init_services(self):\n        \"\"\"\n        Initialize Gmail and Calendar services\n        \"\"\"\n        from googleapiclient.discovery import build\n\n        self.gmail_service = build('gmail', 'v1', credentials=self.credentials)\n        self.calendar_service = build('calendar', 'v3', credentials=self.credentials)\n        self.pending_actions[self.whc.progress_messenger0.recipient_phone] = {}\n\n    def setup_progress_messengers(self):\n        \"\"\"Initialize progress messengers for different types of tasks\"\"\"\n        self.progress_messengers = {\n            'task': self.whc.progress_messenger0,\n            'email': self.whc.progress_messenger1,\n            'calendar': self.whc.progress_messenger2\n        }\n\n    def setup_interaction_buttons(self):\n        \"\"\"Define WhatsApp interaction buttons for different functionalities\"\"\"\n        self.buttons = {\n            'menu': {\n                'header': 'Digital Assistant',\n                'body': 'Please select an option:',\n                'footer': '-- + --',\n                'action': {\n                    'button': 'Menu',\n                    'sections': [\n                        {\n                            'title': 'Main Functions',\n                            'rows': [\n                                {'id': 'agent', 'title': 'Agent Controls', 'description': 'Manage your AI assistant'},\n                                {'id': 'email', 'title': 'Email Management', 'description': 'Handle your emails'},\n                                {'id': 'calendar', 'title': 'Calendar', 'description': 'Manage your schedule'},\n                                {'id': 'docs', 'title': 'Documents', 'description': 'Handle documents'},\n                                {'id': 'system', 'title': 'System', 'description': 'System controls and metrics'}\n                            ]\n                        }\n                    ]\n                }\n            },\n            'agent': self._create_agent_controls_buttons(),\n            'email': self._create_email_controls_buttons(),\n            'calendar': self._create_calendar_controls_buttons(),\n            'docs': self._create_docs_controls_buttons(),\n            'system': self._create_system_controls_buttons()\n        }\n\n    @staticmethod\n    def _create_agent_controls_buttons():\n        return {\n            'header': 'Agent Controls',\n            'body': 'Manage your AI assistant:',\n            'action': {\n                'button': 'Select',\n                'sections': [\n                    {\n                        'title': 'Basic Actions',\n                        'rows': [\n                            {'id': 'agent-task', 'title': 'Agent Task', 'description': 'Run the agent'},\n                            {'id': 'start', 'title': 'Start Agent', 'description': 'Run taskstack in background'},\n                            {'id': 'stop', 'title': 'Stop Agent', 'description': 'Stop taskstack execution'}\n                        ]\n                    },\n                    {\n                        'title': 'Advanced Actions',\n                        'rows': [\n                            {'id': 'system-task', 'title': 'System Task',\n                             'description': 'Run the Isaa Reasoning Agent system'},\n                            {'id': 'tasks', 'title': 'Task Stack', 'description': 'View and manage tasks'},\n                            {'id': 'memory', 'title': 'Clear Memory', 'description': 'Reset agent memory'}\n                        ]\n                    }\n                ]\n            }\n        }\n\n    @staticmethod\n    def _create_email_controls_buttons():\n        return {\n            'header': 'Email Management',\n            'body': 'Handle your emails:',\n            'action': {\n                'button': 'Select',\n                'sections': [\n                    {\n                        'title': 'Basic Actions',\n                        'rows': [\n                            {'id': 'check', 'title': 'Check Emails', 'description': 'View recent emails'},\n                            {'id': 'send', 'title': 'Send Email', 'description': 'Compose new email'},\n                            {'id': 'summary', 'title': 'Get Summary', 'description': 'Summarize emails'}\n                        ]\n                    },\n                    {\n                        'title': 'Advanced Actions',\n                        'rows': [\n                            {'id': 'search', 'title': 'Search', 'description': 'Search emails'}\n                        ]\n                    }\n                ]\n            }\n        }\n\n    @staticmethod\n    def _create_calendar_controls_buttons():\n        return {\n            'header': 'Calendar Management',\n            'body': 'Manage your schedule:',\n            'action': {\n                'button': 'Select',\n                'sections': [\n                    {\n                        'title': 'Basic Actions',\n                        'rows': [\n                            {'id': 'today', 'title': 'Today\\'s Events', 'description': 'View today\\'s schedule'},\n                            {'id': 'add', 'title': 'Add Event', 'description': 'Create new event'},\n                            {'id': 'upcoming', 'title': 'Upcoming', 'description': 'View upcoming events'}\n                        ]\n                    },\n                    {\n                        'title': 'Advanced Actions',\n                        'rows': [\n                            {'id': 'find_slot', 'title': 'Find Time Slot', 'description': 'Find available time'}\n                        ]\n                    }\n                ]\n            }\n        }\n\n    @staticmethod\n    def _create_docs_controls_buttons():\n        return {\n            'header': 'Document Management',\n            'body': 'Handle your documents:',\n            'action': {\n                'button': 'Select',\n                'sections': [\n                    {\n                        'title': 'Basic Actions',\n                        'rows': [\n                            {'id': 'upload', 'title': 'Upload', 'description': 'Add new document'},\n                            {'id': 'list', 'title': 'List Documents', 'description': 'View all documents'},\n                            {'id': 'search', 'title': 'Search', 'description': 'Search documents'}\n                        ]\n                    },\n                    {\n                        'title': 'Advanced Actions',\n                        'rows': [\n                            {'id': 'delete', 'title': 'Delete', 'description': 'Remove document'}\n                        ]\n                    }\n                ]\n            }\n        }\n\n    @staticmethod\n    def _create_system_controls_buttons():\n        return {\n            'header': 'System Controls',\n            'body': 'System management:',\n            'action': {\n                'button': 'Select',\n                'sections': [\n                    {\n                        'title': 'Basic Actions',\n                        'rows': [\n                            {'id': 'status', 'title': 'System Status', 'description': 'View current status'},\n                            {'id': 'restart', 'title': 'Restart', 'description': 'Restart system'},\n                            {'id': 'connect', 'title': 'Connect', 'description': 'Connect to Google Calendar and Email'}\n                        ]\n                    }\n                ]\n            }\n        }\n\n    async def handle_message(self, message: 'Message'):\n        \"\"\"Main message handler for incoming WhatsApp messages\"\"\"\n\n        # Deduplication check\n        with self.message_lock:\n            if message.id in self.processed_messages:\n                return\n            last_ts = time.time()\n            print(last_ts)\n            if len(self.processed_messages) &gt; 0:\n                m_id, last_ts = self.processed_messages.pop()\n                self.processed_messages.add((m_id, last_ts))\n\n            print(\"DUPLICATION P\", message.data.get('entry', [{}])[0].get('changes', [{}])[0].get('value', {}).get('messages', [{}])[0].get('timestamp', 0) , last_ts)\n            if float(message.data.get('entry', [{}])[0].get('changes', [{}])[0].get('value', {}).get('messages', [{}])[0].get('timestamp', 0)) &lt; last_ts - 120:\n                return\n            self.processed_messages.add((message.id, time.perf_counter()))\n\n        # Mark message as read\n        message.mark_as_read()\n\n        # Extract content and type\n        content_type = message.type\n        content = message.content\n\n        print(f\"message.content {content=} {content_type=} {message.data=}\")\n\n        try:\n            if content_type == 'interactive':\n                await self.handle_interactive(message)\n            elif content_type == 'audio':\n                await self.handle_audio_message(message)\n            elif content_type in ['document', 'image', 'video']:\n                response = await self.handle_media_message(message)\n                self.save_reply(message, response)\n            elif content_type == 'text':\n                if content.lower() == \"menu\":\n                    self.whc.messenger.send_button(\n                        recipient_id=self.whc.progress_messenger0.recipient_phone,\n                        button=self.buttons[content.lower()]\n                    )\n                else:\n                    await self.helper_text(message)\n            else:\n                message.reply(\"Unsupported message type\")\n        #except Exception as e:\n        #    logging.error(f\"Message handling error: {str(e)}\")\n        #   message.reply(\"\u274c Error processing request\")\n        finally:\n            # Cleanup old messages (keep 1 hour history)\n            with self.message_lock:\n                self._clean_processed_messages()\n\n    async def helper_text(self, message: 'Message', return_text=False):\n        if not isinstance(message.content, str) and not len(message.content) &gt; 0:\n            content = self.whc.messenger.get_message(message.data)\n            print(f\"contents {content=}, {message.content=}\")\n            message.content = content\n        self.history.set(message.id, message.content)\n        if len(self.pending_actions[self.whc.progress_messenger0.recipient_phone].keys()) != 0:\n            message.reply(\n                f\"Open Interaction : {json.dumps(self.pending_actions[self.whc.progress_messenger0.recipient_phone], indent=2)}\")\n            if self.pending_actions[self.whc.progress_messenger0.recipient_phone].get('type') == 'auth':\n                res = self.complete_authorization(message)\n                self.save_reply(message, res)\n            res = await self.handle_calendar_actions(message)\n            if res:\n                self.save_reply(message, res)\n                return\n            res2 = await self.handle_email_actions(message)\n            if res2:\n                self.save_reply(message, res2)\n                return\n            await self.handle_agent_actions(message)\n            return\n        await self.handle_agent_actions(message)\n\n    async def handle_interactive(self, message: Message):\n        \"\"\"Handle all interactive messages\"\"\"\n        content = self.whc.messenger.get_interactive_response(message.data)\n        if content.get(\"type\") == \"list_reply\":\n            await self.handle_button_interaction(content.get(\"list_reply\"), message)\n        elif content.get(\"type\") == \"button_reply\":\n            print(content)\n\n    async def handle_audio_message(self, message: 'Message'):\n        \"\"\"Process audio messages with STT and TTS\"\"\"\n        # Download audio\n        progress = self.progress_messengers['task']\n        stop_flag = threading.Event()\n        # message_id = progress.send_initial_message(mode=\"loading\")\n        progress.message_id = message.id\n        progress.start_loading_in_background(stop_flag)\n\n        content = self.whc.messenger.get_audio(message.data)\n        audio_file_name = self.whc.messenger.download_media(media_url=self.whc.messenger.query_media_url(media_id=content.get('id')), mime_type='audio/opus', file_path=\".data/temp\")\n        print(f\"audio_file_name {audio_file_name}\")\n        if audio_file_name is None:\n            message.reply(\"Could not process audio file\")\n            stop_flag.set()\n            return\n\n        text = self.stt(audio_file_name)['text']\n        if not text:\n            message.reply(\"Could not process audio\")\n            stop_flag.set()\n            return\n\n        message.reply(\"Transcription :\\n \"+ text)\n        message.content = text\n        agent_res = await self.helper_text(message, return_text=True)\n\n        if agent_res is not None:\n            pass\n\n        stop_flag.set()\n        # Process text and get response\n        # response = await self.process_input(text, message)\n\n        # Convert response to audio\n        #audio_file = self.audio_processor.tts(response)\n        #audio_file = None # TODO\n        #self.whc.messenger.send_audio(\n        #    audio=audio_file,\n        #    recipient_id=self.whc.progress_messenger0.recipient_phone,\n        #)\n\n    async def confirm(self, message: Message):\n        status = self.pending_actions[self.whc.progress_messenger0.recipient_phone]\n        if status.get('type') == \"create_event\":\n            if status.get('step') == \"confirm_envet\":\n                event = self._create_calendar_event(status.get('event_data'))\n                self.pending_actions[self.whc.progress_messenger0.recipient_phone] = {}\n                return f\"\u2705 Event created!\\n{event.get('htmlLink')}\"\n            return \"\u274c\"\n        elif status.get('type') == \"compose_email\":\n            if status.get('step') == \"confirm_email\":\n                # Send email\n                result = self.gmail_service.users().messages().send(\n                    userId='me',\n                    body=self._build_email_draft(status['draft'])\n                ).execute()\n                self.pending_actions[self.whc.progress_messenger0.recipient_phone] = {}\n                return f\"\u2705 Email sent! Message ID: {result['id']}\"\n            return \"\u274c\"\n        return \"\u274c Done\"\n\n    async def cancel(self, *a):\n        self.pending_actions[self.whc.progress_messenger0.recipient_phone] = {}\n        return \"\u2705 cancel Done\"\n\n    async def handle_button_interaction(self, content: dict, message: Message):\n        \"\"\"Handle button click interactions\"\"\"\n        button_id = content['id']\n\n        # First check if it's a main menu button\n        if button_id in self.buttons:\n            self.whc.messenger.send_button(\n                recipient_id=self.whc.progress_messenger0.recipient_phone,\n                button=self.buttons[button_id]\n            )\n            return\n\n        # Handle action buttons\n        action_handlers = {\n            # Agent controls\n            'start': self.start_agent,\n            'stop': self.stop_agent,\n            'tasks': self.show_task_stack,\n            'memory': self.clear_memory,\n            'system-task': self.system_task,\n            'agent-task': self.agent_task,\n\n            # Email controls\n            'check': self.check_emails,\n            'send': self.start_email_compose,\n            'summary': self.email_summary,\n            'search': self.email_search,\n\n            # Calendar controls\n            'today': self.show_today_events,\n            'add': self.start_event_create,\n            'upcoming': self.show_upcoming_events,\n            'find_slot': self.find_time_slot,\n\n            # Document controls\n            'upload': self.start_document_upload,\n            'list': self.list_documents,\n            'search_docs': self.search_documents,\n            'delete': self.delete_document,\n\n            # System controls\n            'status': self.system_status,\n            'restart': self.restart_system,\n            'connect': self.generate_authorization_url,\n\n            'cancel': self.cancel,\n            'confirm': self.confirm,\n        }\n        if button_id in action_handlers:\n            try:\n                # Start progress indicator\n                progress = self.progress_messengers['task']\n                stop_flag = threading.Event()\n                # message_id = progress.send_initial_message(mode=\"loading\")\n                progress.message_id = message.id\n                progress.start_loading_in_background(stop_flag)\n\n                # Execute handler\n\n                result = await action_handlers[button_id](message)\n\n\n                # Send result\n                if isinstance(result, str):\n                    self.save_reply(message, result)\n                elif isinstance(result, dict):  # For structured responses\n                    self.send_structured_response(result)\n\n                stop_flag.set()\n            finally:\n                #except Exception as e:\n                stop_flag.set()\n            #    message.reply(f\"\u274c Error processing {button_id}: {str(e)}\")\n        elif 'event_' in button_id:\n            res = await self.get_event_details(button_id.replace(\"event_\", ''))\n            if isinstance(res, str):\n                self.save_reply(message, res)\n                return\n            for r in res:\n                if isinstance(r, str):\n                    self.save_reply(message, r)\n                else:\n                    self.whc.messenger.send_location(**r)\n\n        elif 'email_' in button_id:\n            res = await self.get_email_details(button_id.replace(\"email_\", ''))\n            self.save_reply(message, res)\n        else:\n            message.reply(\"\u26a0\ufe0f Unknown command\")\n\n    def send_structured_response(self, result: dict):\n        \"\"\"Send complex responses using appropriate WhatsApp features\"\"\"\n        if result['type'] == 'list':\n            self.whc.messenger.send_button(\n                recipient_id=self.whc.progress_messenger0.recipient_phone,\n                button={\n                    'header': result.get('header', ''),\n                    'body': result.get('body', ''),\n                    'footer': result.get('footer', ''),\n                    'action': {\n                        'button': 'Action',\n                        'sections': result['sections']\n                    }\n                }\n            )\n        elif result['type'] == 'quick_reply':\n            self.whc.messenger.send_button(\n                recipient_id=self.whc.progress_messenger0.recipient_phone,\n                button={\n                    'header': \"Quick reply\",\n                    'body': result['text'],\n                    'footer': '',\n                    'action': {'button': 'Action', 'sections': [{\n                        'title': 'View',\n                        'rows': [{'id': k, 'title': v[:23]} for k, v in result['options'].items()]\n                    }]}\n                }\n            )\n\n        elif result['type'] == 'media':\n            if result['media_type'] == 'image':\n                self.whc.messenger.send_image(\n                    image=result['url'],\n                    recipient_id=self.whc.progress_messenger0.recipient_phone,\n                    caption=result.get('caption', '')\n                )\n            elif result['media_type'] == 'document':\n                self.whc.messenger.send_document(\n                    document=result['url'],\n                    recipient_id=self.whc.progress_messenger0.recipient_phone,\n                    caption=result.get('caption', '')\n                )\n\n    async def clear_memory(self, message):\n        self.agent.reset_context()\n        self.agent.taskstack.tasks = []\n        return \"\ud83e\udde0 Memory cleared successfully\"\n\n    async def system_task(self, message):\n        \"\"\"Initiate email search workflow\"\"\"\n        self.pending_actions[self.whc.progress_messenger0.recipient_phone] = {\n            'type': 'system',\n            'step': 'await_query'\n        }\n        return {\n            'type': 'quick_reply',\n            'text': \"Now prompt the \ud83e\udde0ISAA-System \ud83d\udcdd\",\n            'options': {'cancel': '\u274c Cancel Search'}\n        }\n\n    async def agent_task(self, message):\n        \"\"\"Initiate email search workflow\"\"\"\n        self.pending_actions[self.whc.progress_messenger0.recipient_phone] = {\n            'type': 'self-agent',\n            'step': 'await_query'\n        }\n        return {\n            'type': 'quick_reply',\n            'text': \"Now prompt the self-agent \ud83d\udcdd\",\n            'options': {'cancel': '\u274c Cancel Search'}\n        }\n\n    async def check_emails(self, message, query=\"\"):\n        \"\"\"Improved email checking with WhatsApp API formatting\"\"\"\n        if not self.gmail_service:\n            return \"\u26a0\ufe0f Gmail service not configured\"\n\n        try:\n            results = self.gmail_service.users().messages().list(\n                userId='me',\n                maxResults=10,\n                labelIds=['INBOX'],\n                q=query\n            ).execute()\n\n            emails = []\n            for msg in results.get('messages', [])[:10]:\n                email_data = self.gmail_service.users().messages().get(\n                    userId='me',\n                    id=msg['id'],\n                    format='metadata'\n                ).execute()\n\n                headers = {h['name']: h['value'] for h in email_data['payload']['headers']}\n                emails.append({\n                    'id': msg['id'],\n                    'from': headers.get('From', 'Unknown'),\n                    'subject': headers.get('Subject', 'No Subject'),\n                    'date': headers.get('Date', 'Unknown'),\n                    'snippet': email_data.get('snippet', ''),\n                    'unread': 'UNREAD' in email_data.get('labelIds', [])\n                })\n\n            return {\n                'type': 'list',\n                'header': '\ud83d\udce8 Recent Emails',\n                'body': 'Tap to view full email',\n                'footer': 'Email Manager',\n                'sections': [{\n                    'title': f\"Inbox ({len(emails)} emails)\",\n                    'rows': [{\n                        'id': f\"email_{email['id']}\",\n                        'title': f\"{'\ud83d\udcec' if email['unread'] else '\ud83d\udced'} {email['subject']}\"[:23],\n                        'description': f\"From: {email['from']}\\n{email['snippet']}\"[:45]\n                    } for email in emails]\n                }]\n            }\n        except Exception as e:\n            return f\"\u26a0\ufe0f Error fetching emails: {str(e)}\"\n\n    async def get_email_details(self, email_id):\n        \"\"\"Retrieve and format full email details\"\"\"\n        if not self.gmail_service:\n            return \"\u26a0\ufe0f Gmail service not configured\"\n\n        try:\n            email_data = self.gmail_service.users().messages().get(\n                userId='me',\n                id=email_id,\n                format='full'\n            ).execute()\n\n            headers = {h['name']: h['value'] for h in email_data['payload']['headers']}\n            body = \"\"\n            for part in email_data.get('payload', {}).get('parts', []):\n                if part['mimeType'] == 'text/plain':\n                    body = base64.urlsafe_b64decode(part['body']['data']).decode('utf-8')\n                    break\n\n            formatted_text = (\n                f\"\ud83d\udce7 *Email Details*\\n\\n\"\n                f\"From: {headers.get('From', 'Unknown')}\\n\"\n                f\"Subject: {headers.get('Subject', 'No Subject')}\\n\"\n                f\"Date: {headers.get('Date', 'Unknown')}\\n\\n\"\n                f\"{body[:15000]}{'...' if len(body) &gt; 15000 else ''}\"\n            )\n            return  self.agent.mini_task(\n                formatted_text , \"system\", \"Summarize the email in bullet points with key details\"\n            )\n        except Exception as e:\n            return f\"\u26a0\ufe0f Error fetching email: {str(e)}\"\n\n    async def email_summary(self, message):\n        \"\"\"Generate AI-powered email summaries\"\"\"\n        try:\n            messages = self.gmail_service.users().messages().list(\n                userId='me',\n                maxResults=3,\n                labelIds=['INBOX']\n            ).execute().get('messages', [])\n\n            email_contents = []\n            for msg in messages[:3]:\n                email_data = self.gmail_service.users().messages().get(\n                    userId='me',\n                    id=msg['id'],\n                    format='full'\n                ).execute()\n                email_contents.append(self._parse_email_content(email_data))\n\n            summary = self.agent.mini_task(\n                \"\\n\\n\".join(email_contents) , \"system\", \"Summarize these emails in bullet points with key details:\"\n            )\n\n            return f\"\ud83d\udccb Email Summary:\\n{summary}\\n\\n*Powered by AI*\"\n        except Exception as e:\n            logging.error(f\"Summary failed: {str(e)}\")\n            return f\"\u274c Could not generate summary: {str(e)}\"\n\n    async def email_search(self, message):\n        \"\"\"Initiate email search workflow\"\"\"\n        self.pending_actions[self.whc.progress_messenger0.recipient_phone] = {\n            'type': 'email_search',\n            'step': 'await_query'\n        }\n        return {\n            'type': 'quick_reply',\n            'text': \"\ud83d\udd0d What would you like to search for?\",\n            'options': {'cancel': '\u274c Cancel Search'}\n        }\n\n    async def start_email_compose(self, message):\n        \"\"\"Enhanced email composition workflow\"\"\"\n        self.pending_actions[self.whc.progress_messenger0.recipient_phone] = {\n            'type': 'compose_email',\n            'step': 'subject',\n            'draft': {'attachments': []}\n        }\n        return {\n            'type': 'quick_reply',\n            'text': \"\ud83d\udcdd Let's compose an email\\n\\nSubject:\",\n            'options': {'cancel': '\u274c Cancel Composition'}\n        }\n\n    async def handle_email_actions(self, message):\n        \"\"\"Handle multi-step email workflows\"\"\"\n        user_state = self.pending_actions.get(self.whc.progress_messenger0.recipient_phone, {})\n\n        if user_state.get('type') == 'compose_email':\n            return await self._handle_email_composition(message, user_state)\n        if user_state.get('type') == 'email_search':\n            return await self.check_emails(message, self.agent.mini_task(\"\"\"Conventire Pezise zu einer googel str only query using : Gmail Suchoperatoren!\n\nBasis-Operatoren:\n- from: Absender\n- to: Empf\u00e4nger\n- subject: Betreff\n- label: Gmail Label\n- has:attachment Anh\u00e4nge\n- newer_than:7d Zeitfilter\n- before: Datum vor\n- after: Datum nach\n\nErweiterte Operatoren:\n- in:inbox\n- in:sent\n- in:spam\n- cc: Kopie\n- bcc: Blindkopie\n- is:unread\n- is:read\n- larger:10M Gr\u00f6\u00dfenfilter\n- smaller:5M\n- filename:pdf Dateityp\n\nProfi-Tipps:\n- Kombinierbar mit UND/ODER\n- Anf\u00fchrungszeichen f\u00fcr exakte Suche\n- Negation mit -\n beispeile : 'Ungelesene Mails letzte Woche': -&gt; 'is:unread newer_than:7d'\n\n\"\"\", \"user\",message.content))\n\n\n        return None\n\n    async def _handle_email_composition(self, message, state):\n        if state['step'] == 'subject':\n            state['draft']['subject'] = message.content\n            state['step'] = 'body'\n            return {\n                'type': 'quick_reply',\n                'text': \"\u270d\ufe0f Email body:\",\n                'options': {'attach': '\ud83d\udcce Add Attachment', 'send': '\ud83d\udce4 Send Now'}\n            }\n\n        elif state['step'] == 'body':\n            if message.content == 'attach':\n                state['step'] = 'attachment'\n                return \"\ud83d\udcce Please send the file you want to attach\"\n\n            state['draft']['body'] = message.content\n            state['step'] = 'confirm_email'\n            return {\n                'type': 'quick_reply',\n                'text': f\"\ud83d\udce7 Ready to send?\\n\\nSubject: {state['draft']['subject']}\\n\\n{state['draft']['body']}\",\n                'options': {'confirm': '\u2705 Send', 'cancel': '\u274c cancel'}\n            }\n\n        elif state['step'] == 'attachment':\n            # Handle attachment upload\n            file_type = message.type\n            if file_type not in ['document', 'image']:\n                return \"\u274c Unsupported file type\"\n\n            media_url = getattr(message, file_type).id\n            media_data = self.whc.messenger.download_media(media_url=self.whc.messenger.query_media_url(media_id=media_url), mime_type=media_url.type, file_path=\".data/temp\")\n            state['draft']['attachments'].append(media_data)\n            state['step'] = 'body'\n            return \"\ud83d\udcce Attachment added! Add more or send the email\"\n\n\n    def _parse_email_content(self, email_data):\n        \"\"\"Extract readable content from email payload\"\"\"\n        parts = email_data.get('payload', {}).get('parts', [])\n        body = \"\"\n        for part in parts:\n            if part['mimeType'] == 'text/plain':\n                body += base64.urlsafe_b64decode(part['body']['data']).decode('utf-8')\n        return f\"Subject: {email_data.get('subject', '')}\\nFrom: {email_data.get('from', '')}\\n\\n{body}\"\n\n    def _build_email_draft(self, draft):\n        \"\"\"Create MIME message from draft data\"\"\"\n        message = MIMEMultipart()\n        message['to'] = draft.get('to', '')\n        message['subject'] = draft['subject']\n        message.attach(MIMEText(draft['body']))\n\n        for attachment in draft['attachments']:\n            part = MIMEBase('application', 'octet-stream')\n            part.set_payload(attachment)\n            encoders.encode_base64(part)\n            part.add_header('Content-Disposition', 'attachment')\n            message.attach(part)\n\n        return {'raw': base64.urlsafe_b64encode(message.as_bytes()).decode()}\n\n    def _get_email_subject(self, msg):\n        headers = msg.get('payload', {}).get('headers', [])\n        return next((h['value'] for h in headers if h['name'] == 'Subject'), 'No Subject')\n\n    def _get_email_sender(self, msg):\n        headers = msg.get('payload', {}).get('headers', [])\n        return next((h['value'] for h in headers if h['name'] == 'From'), 'Unknown Sender')\n\n    def _get_email_snippet(self, msg):\n        return msg.get('snippet', '')[:100] + '...'\n    # Calendar Handlers\n\n    # Calendar Functions\n    def _format_event_time(self, event):\n        \"\"\"Improved time formatting for calendar events\"\"\"\n        start = event['start'].get('dateTime', event['start'].get('date'))\n        end = event['end'].get('dateTime', event['end'].get('date'))\n\n        try:\n            start_dt = parser.parse(start)\n            end_dt = parser.parse(end)\n            if 'T' in start:\n                return f\"{start_dt.strftime('%a %d %b %H:%M')} - {end_dt.strftime('%H:%M')}\"\n            return f\"{start_dt.strftime('%d %b %Y')} (All Day)\"\n        except:\n            return \"Time not specified\"\n\n    async def get_event_details(self, event_id):\n        \"\"\"Retrieve and format calendar event details with location support\"\"\"\n        if not self.calendar_service:\n            return \"\u26a0\ufe0f Calendar service not configured\"\n\n        try:\n            event = self.calendar_service.events().get(\n                calendarId='primary',\n                eventId=event_id\n            ).execute()\n\n            response = [ (\n                    f\"\ud83d\udcc5 *Event Details*\\n\\n\"\n                    f\"Title: {event.get('summary', 'No title')}\\n\"\n                    f\"Time: {self._format_event_time(event)}\\n\"\n                    f\"Location: {event.get('location', 'Not specified')}\\n\\n\"\n                    f\"{event.get('description', 'No description')[:1000]}\"\n                )]\n\n            if 'geo' in event:\n                response.append({\n                    'lat': float(event['geo']['latitude']),\n                    'long': float(event['geo']['longitude']),\n                    'name': event.get('location', 'Event Location'),\n                    'address': event.get('location', ''),\n                    'recipient_id': self.whc.progress_messenger0.recipient_phone\n                })\n            return response\n        except Exception as e:\n            return f\"\u26a0\ufe0f Error fetching event: {str(e)}\"\n\n    async def show_today_events(self, message):\n        \"\"\"Show today's calendar events\"\"\"\n        if not self.calendar_service:\n            message.replay(\"service not online\")\n\n        now = datetime.utcnow().isoformat() + 'Z'\n        end_of_day = (datetime.now() + timedelta(days=1)).replace(\n            hour=0, minute=0, second=0).isoformat() + 'Z'\n\n        events_result = self.calendar_service.events().list(\n            calendarId='primary',\n            timeMin=now,\n            timeMax=end_of_day,\n            singleEvents=True,\n            orderBy='startTime'\n        ).execute()\n\n        events = events_result.get('items', [])\n        return self._format_calendar_response(events, \"Today's Events\")\n\n    # Updated Calendar List Handlers\n    async def show_upcoming_events(self, message):\n        \"\"\"Show upcoming events with interactive support\"\"\"\n        if not self.calendar_service:\n            return \"\u26a0\ufe0f Calendar service not configured\"\n\n        try:\n            now = datetime.utcnow().isoformat() + 'Z'\n            next_week = (datetime.now() + timedelta(days=7)).isoformat() + 'Z'\n\n            events_result = self.calendar_service.events().list(\n                calendarId='primary',\n                timeMin=now,\n                timeMax=next_week,\n                singleEvents=True,\n                orderBy='startTime',\n                maxResults=10\n            ).execute()\n\n            events = events_result.get('items', [])\n            return self._format_calendar_response(events, \"Upcoming Events\")\n        except Exception as e:\n            return f\"\u26a0\ufe0f Error fetching events: {str(e)}\"\n\n    async def start_event_create(self, message):\n        \"\"\"Initiate event creation workflow\"\"\"\n        self.pending_actions[self.whc.progress_messenger0.recipient_phone] = {\n            'type': 'create_event',\n            'step': 'title',\n            'event_data': {}\n        }\n        return {\n            'type': 'quick_reply',\n            'text': \"Let's create an event! What's the title?\",\n            'options': {'cancel': '\u274c Cancel'}\n        }\n\n    async def find_time_slot(self, message):\n        \"\"\"Find and display the next 5 available time slots with dynamic durations\"\"\"\n        if not self.calendar_service:\n            return \"\u26a0\ufe0f Calendar service not configured\"\n\n        try:\n            # Define the time range for the search (next 24 hours)\n            now = datetime.now(UTC)\n            end_time = now + timedelta(days=1)\n\n            # FreeBusy Request\n            freebusy_request = {\n                \"timeMin\": now.isoformat(),\n                \"timeMax\": end_time.isoformat(),\n                \"items\": [{\"id\": 'primary'}]\n            }\n\n            freebusy_response = self.calendar_service.freebusy().query(body=freebusy_request).execute()\n            busy_slots = freebusy_response['calendars']['primary']['busy']\n\n            # Slot-Berechnung\n            available_slots = self._calculate_efficient_slots(\n                busy_slots,\n                self.duration_minutes\n            )\n\n            # Format the response for WhatsApp\n            return {\n                'type': 'list',\n                'header': \"\u23f0 Available Time Slots\",\n                'body': \"Tap to select a time slot\",\n                'footer': \"Time Slot Finder\",\n                'sections': [{\n                    'title': \"Next 5 Available Slots\",\n                    'rows': [{\n                        'id': f\"slot_{slot['start'].timestamp()}\",\n                        'title': f\"\ud83d\udd52 {slot['start'].strftime('%H:%M')} - {slot['end'].strftime('%H:%M')}\",\n                        'description': f\"Duration: {slot['duration']}\"\n                    } for slot in available_slots[:5]]\n                }]\n            }\n        except Exception as e:\n            return f\"\u26a0\ufe0f Error finding time slots: {str(e)}\"\n\n    def _calculate_efficient_slots(self, busy_slots, duration_minutes):\n        \"\"\"Effiziente Slot-Berechnung\"\"\"\n        available_slots = []\n        current = datetime.now(UTC)\n        end_time = current + timedelta(days=1)\n\n        while current &lt; end_time:\n            slot_end = current + timedelta(minutes=duration_minutes)\n\n            if slot_end &gt; end_time:\n                break\n\n            is_available = all(\n                slot_end &lt;= parser.parse(busy['start']) or\n                current &gt;= parser.parse(busy['end'])\n                for busy in busy_slots\n            )\n\n            if is_available:\n                available_slots.append({\n                    'start': current,\n                    'end': slot_end,\n                    'duration': f\"{duration_minutes} min\"\n                })\n                current = slot_end\n            else:\n                current += timedelta(minutes=15)\n\n        return available_slots\n\n    async def handle_calendar_actions(self, message):\n        \"\"\"Handle calendar-related pending actions\"\"\"\n        user_state = self.pending_actions.get(self.whc.progress_messenger0.recipient_phone, {})\n\n        if user_state.get('type') == 'create_event':\n            return await self._handle_event_creation(message, user_state)\n\n        return None\n\n    async def _handle_event_creation(self, message, state):\n        step = state['step']\n        event_data = state['event_data']\n\n        if step == 'title':\n            event_data['summary'] = message.content\n            state['step'] = 'start_time'\n            return \"\ud83d\udcc5 When should it start? (e.g., 'tomorrow 2pm' or '2024-03-20 14:30')\"\n\n        elif step == 'start_time':\n            event_data['start'] = self._parse_time(message.content)\n            state['step'] = 'end_time'\n            return \"\u23f0 When should it end? (e.g., '3pm' or '2024-03-20 15:30')\"\n\n        elif step == 'end_time':\n            event_data['end'] = self._parse_time(message.content, reference=event_data['start'])\n            state['step'] = 'description'\n            return \"\ud83d\udcdd Add a description (or type 'skip')\"\n\n        elif step == 'description':\n            if message.content.lower() != 'skip':\n                event_data['description'] = message.content\n            state['step'] = 'confirm_envet'\n            return self._create_confirmation_message(event_data)\n\n    def _format_calendar_response(self, events, title):\n        \"\"\"Enhanced calendar formatting with interactive support\"\"\"\n        if not events:\n            return f\"\ud83d\udcc5 No {title.lower()} found\"\n\n        return {\n            'type': 'list',\n            'header': title,\n            'body': \"Tap to view event details\",\n            \"footer\": \"-- Calendar --\",\n            'sections': [{\n                'title': f\"{len(events)} Events\",\n                'rows': [{\n                    'id': f\"event_{event['id']}\",\n                    'title': f\"\ud83d\udcc5 {event['summary']}\"[:23],\n                    'description': self._format_event_time(event)[:45]\n                } for event in events[:5]]\n            }]\n        }\n\n    def _parse_iso_to_readable(self, iso_str):\n        \"\"\"Convert ISO datetime to readable format\"\"\"\n        dt = datetime.fromisoformat(iso_str.replace('Z', '+00:00'))\n        return dt.strftime(\"%a %d %b %Y %H:%M\")\n\n    def _parse_time(self, time_str, reference=None):\n        \"\"\"\n        Konvertiert nat\u00fcrliche Sprache zu pr\u00e4ziser Datetime\n\n        Unterst\u00fctzt:\n        - 'heute'\n        - 'morgen'\n        - 'in einer woche'\n        - '10 uhr'\n        - '10pm'\n        - 'n\u00e4chsten montag'\n        \"\"\"\n        if reference is None:\n            reference = datetime.now()\n\n        try:\n            import dateparser\n\n            # Dateparser f\u00fcr flexibel Zeitparsing\n            parsed_time = dateparser.parse(\n                time_str,\n                settings={\n                    'PREFER_DATES_FROM': 'future',\n                    'RELATIVE_BASE': reference,\n                    'TIMEZONE': 'Europe/Berlin'\n                }\n            )\n\n            if parsed_time is None:\n                # Fallback auf dateutil wenn dateparser scheitert\n                parsed_time = parser .parse(time_str, fuzzy=True, default=reference)\n\n            return parsed_time\n\n        except Exception as e:\n            print(f\"Zeitparsing-Fehler: {e}\")\n            return reference\n\n    def _calculate_free_slots(self, start, end, busy_slots):\n        \"\"\"Calculate free time slots between busy periods\"\"\"\n        # Implementation would calculate available windows\n        return [{\n            'start': \"09:00\",\n            'end': \"11:00\",\n            'duration': \"2 hours\"\n        }]\n\n    def _create_confirmation_message(self, event_data):\n        \"\"\"Create event confirmation message\"\"\"\n        details = [\n            f\"\ud83d\udccc Title: {event_data['summary']}\",\n            f\"\ud83d\udd52 Start: {self._parse_iso_to_readable(event_data['start'])}\",\n            f\"\u23f0 End: {self._parse_iso_to_readable(event_data['end'])}\",\n            f\"\ud83d\udcdd Description: {event_data.get('description', 'None')}\"\n        ]\n        return {\n            'type': 'quick_reply',\n            'text': \"\\n\".join(details),\n            'options': {'confirm': '\u2705 Confirm', 'cancel': '\u274c Cancel'}\n        }\n\n    def _create_calendar_event(self, event_data):\n        \"\"\"Create event through Calendar API\"\"\"\n        event = {\n            'summary': event_data['summary'],\n            'start': {'dateTime': event_data['start']},\n            'end': {'dateTime': event_data['end']},\n        }\n        if 'description' in event_data:\n            event['description'] = event_data['description']\n\n        return self.calendar_service.events().insert(\n            calendarId='primary',\n            body=event\n        ).execute()\n\n    async def system_status(self, message):\n        o = (datetime.now() - self.start_time)\n        o.microseconds = 0\n        status = {\n            \"\ud83e\udd16 Agent\": \"Online\" if self.agent else \"Offline\",\n            \"\ud83d\udce7 Email\": \"Connected\" if self.gmail_service else \"Disconnected\",\n            \"\ud83d\udcc5 Calendar\": \"Connected\" if self.calendar_service else \"Disconnected\",\n            \"\ud83d\udcc4 Documents\": \"Connected\" if self.blob_docs_system else \"Disconnected\",\n            \"\u23f3 Uptime\": f\"{str(o.isoformat())}\"\n        }\n        return \"\\n\".join([f\"{k}: {v}\" for k, v in status.items()])\n\n    async def restart_system(self, message):\n        message.reply(\"\ud83d\udd04 System restart initiated...\")\n        time.sleep(1)\n        await self.clear_memory(message)\n        time.sleep(1)\n        return  \"\u2705 System restarted\"\n\n    # Updated document handlers\n    async def list_documents(self, message, filter_type=None):\n        docs = self.blob_docs_system.list_documents(filter_type)\n        if len(docs) == 0:\n            return \"No docs found\"\n        else:\n            return str(docs)\n        return {\n            'type': 'list',\n            'body': 'Stored Documents',\n            'action': {\n                'sections': [{\n                    'title': 'Your Documents',\n                    'rows': [{\n                        'id': doc['id'],\n                        'title': f\"{self._get_icon(doc['type'])} {doc['name']}\"[:23],\n                        'description': f\"{doc['type'].title()} | {self._format_size(doc['size'])} | {doc['modified']}\"[:29]\n                    } for doc in docs[:10]]\n                }]}\n        }\n\n    async def start_document_upload(self, message):\n        \"\"\"Initiate document upload workflow\"\"\"\n        self.pending_actions[self.whc.progress_messenger0.recipient_phone] = {'type': 'document', 'step': 'awaiting_file'}\n        return {\n            'type': 'quick_reply',\n            'text': '\ud83d\udce4 Send me the file you want to upload',\n            'options': {'cancel': '\u274c Cancel Upload'}\n        }\n\n    async def search_documents(self, message):\n        \"\"\"Initiate document search workflow\"\"\"\n        self.pending_actions[self.whc.progress_messenger0.recipient_phone] = {'type': 'search', 'step': 'awaiting_query'}\n        return {\n            'type': 'quick_reply',\n            'text': '\ud83d\udd0d What are you looking for?',\n            'options': {'cancel': '\u274c Cancel Search'}\n        }\n\n    async def handle_media_message(self, message: 'Message'):\n        \"\"\"Handle document/image/video uploads\"\"\"\n        user_state = self.pending_actions.get(self.whc.progress_messenger0.recipient_phone, {})\n\n        if user_state.get('step') == 'awaiting_file':\n            file_type = message.type\n            if file_type not in ['document', 'image', 'video']:\n                return \"Unsupported file type\"\n\n            try:\n                # Download media\n                #media_url = message.document.url if hasattr(message, 'document') else \\\n                #    message.image.url if hasattr(message, 'image') else \\\n                #        message.video.url\n                if file_type =='video':\n                    content = self.whc.messenger.get_video(message.data)\n                if file_type =='image':\n                    content = self.whc.messenger.get_image(message.data)\n                if file_type =='document':\n                    content = self.whc.messenger.get_document(message.data)\n                print(\"Media content:\", content)\n                media_data = self.whc.messenger.download_media(media_url=self.whc.messenger.query_media_url(media_id=content.get('id')),  mime_type=content.get('mime_type'), file_path='.data/temp')\n                print(\"Media media_data:\", media_data)\n                # Save to blob storage\n                filename = f\"file_{file_type}_{datetime.now().isoformat()}_{content.get('sha256', '')}\"\n                blob_id = self.blob_docs_system.save_document(\n                    open(media_data, 'rb').read(),\n                    filename=filename,\n                    file_type=file_type\n                )\n\n                self.pending_actions[self.whc.progress_messenger0.recipient_phone] = {}\n                return f\"\u2705 File uploaded successfully!\\nID: {blob_id}\"\n\n            except Exception as e:\n                logging.error(f\"Upload failed: {str(e)}\")\n                return f\"\u274c Failed to upload file Error : {str(e)}\"\n\n        return \"No pending uploads\"\n\n    async def delete_document(self, message):\n        \"\"\"Delete document workflow\"\"\"\n        docs = self.blob_docs_system.list_documents()\n        return {\n            'type': 'quick_reply',\n            'text': 'Select document to delete:',\n            'options': {doc['id']: doc['name'] for doc in docs[:5]},\n            'handler': self._confirm_delete\n        }\n\n    async def _confirm_delete(self, doc_id, message):\n        \"\"\"Confirm deletion workflow\"\"\"\n        doc = next((d for d in self.blob_docs_system.list_documents() if d['id'] == doc_id), None)\n        if not doc:\n            return \"Document not found\"\n\n        if self.blob_docs_system.delete_document(doc_id):\n            return f\"\u2705 {doc['name']} deleted successfully\"\n        return \"\u274c Failed to delete document\"\n\n    # Helper methods\n    def _get_icon(self, file_type: str) -&gt; str:\n        icons = {\n            'document': '\ud83d\udcc4',\n            'image': '\ud83d\uddbc\ufe0f',\n            'video': '\ud83c\udfa5'\n        }\n        return icons.get(file_type, '\ud83d\udcc1')\n\n    def _format_size(self, size: int) -&gt; str:\n        if size &lt; 1024:\n            return f\"{size}B\"\n        elif size &lt; 1024 ** 2:\n            return f\"{size / 1024:.1f}KB\"\n        elif size &lt; 1024 ** 3:\n            return f\"{size / (1024 ** 2):.1f}MB\"\n        return f\"{size / (1024 ** 3):.1f}GB\"\n\n    # Utility Methods\n\n    def _clean_processed_messages(self):\n        \"\"\"Clean old messages from processed cache\"\"\"\n        now = time.time()\n        self.processed_messages = {\n            msg_id for msg_id, timestamp in self.processed_messages\n            if now - timestamp &lt; 3600  # 1 hour retention\n        }\n\n    def send_email(self, to, subject, body):\n        \"\"\"Actual email sending function to be called by agent\"\"\"\n        if not self.gmail_service:\n            return False\n\n        message = MIMEText(body)\n        message['to'] = to\n        message['subject'] = subject\n\n        encoded_message = base64.urlsafe_b64encode(message.as_bytes()).decode()\n        self.gmail_service.users().messages().send(\n            userId='me',\n            body={'raw': encoded_message}\n        ).execute()\n        return True\n\n    async def start_agent(self, *a):\n        \"\"\"Start the agent in background mode\"\"\"\n        if self.agent:\n            self.agent.run_in_background()\n            return True\n        return False\n\n    async def stop_agent(self, *b):\n        \"\"\"Stop the currently running agent\"\"\"\n        if self.agent:\n            self.agent.stop()\n            return True\n        return False\n\n    async def show_task_stack(self, *a):\n        \"\"\"Display current task stack\"\"\"\n        if self.agent and len(self.agent.taskstack.tasks) &gt; 0:\n            tasks = self.agent.taskstack.tasks\n            return self.agent.mini_task(\"\\n\".join([f\"Task {t.id}: {t.description}\" for t in tasks]), \"system\", \"Format to nice and clean whatsapp format\")\n        return \"No tasks in stack\"\n\n    def run(self):\n        \"\"\"Start the WhatsApp assistant\"\"\"\n        try:\n            self.state = AssistantState.ONLINE\n            # Send welcome message\n\n            mas = self.whc.messenger.create_message(\n                content=\"Digital Assistant is online! Send /help for available commands.\",to=self.whc.progress_messenger0.recipient_phone,\n            ).send(sender=0)\n            mas_id = mas.get(\"messages\", [{}])[0].get(\"id\")\n            print(mas_id)\n\n        except Exception as e:\n            logging.error(f\"Assistant error: {str(e)}\")\n            self.state = AssistantState.OFFLINE\n            raise\n\n    async def handle_agent_actions(self, message):\n        user_state = self.pending_actions.get(self.whc.progress_messenger0.recipient_phone, {})\n        def helper():\n\n            stop_flag = threading.Event()\n            try:\n                progress = self.progress_messengers['task']\n                # message_id = progress.send_initial_message(mode=\"loading\")\n                progress.message_id = message.id\n                progress.start_loading_in_background(stop_flag)\n                res = message.content\n                print(message.data.get('entry', [{}])[0].get('changes', [{}])[0].get('value', {}).get('messages', [{}])[0].get(\n                    'context'))\n                if context := message.data.get('entry', [{}])[0].get('changes', [{}])[0].get('value', {}).get('messages', [{}])[0].get(\n                    'context'):\n                    context_str = f\"Context : source {'USER' if context.get('from') in self.whc.progress_messenger0.recipient_phone else 'AGENT'}\"\n                    cd = self.history.get(context.get('id'))\n                    context_str += \"\\n\" + (cd if cd is not None else \"The ref Message is not in the history\")\n                    res += \"\\n\" + context_str\n                if user_state.get('type') == 'system':\n                    res = self.isaa.run(res)\n                    self.pending_actions[self.whc.progress_messenger0.recipient_phone] = {}\n                elif user_state.get('type') == 'self-agent':\n                    res = self.agent.run(res)\n                    self.pending_actions[self.whc.progress_messenger0.recipient_phone] = {}\n                self.agent.mode = LLMMode(\n                    name=\"Chatter\",\n                    description=\"whatsapp Chat LLM\",\n                    system_msg=\"Response precise and short style using whatsapp syntax!\",\n                    post_msg=None\n                )\n                response = self.agent.mini_task(res, \"user\", persist=True)\n                self.save_reply(message, response)\n            except Exception as e:\n                stop_flag.set()\n                message.reply(\"\u274c Error in agent \"+str(e))\n            finally:\n                self.agent.mode = None\n                stop_flag.set()\n        threading.Thread(target=helper, daemon=True).start()\n\n    def save_reply(self, message, content):\n        res = message.reply(content)\n        res_id = res.get(\"messages\", [{}])[0].get(\"id\")\n        if res_id is not None:\n            self.history.set(res_id, content)\n        else:\n            print(f\"No ID to add to history: {res}\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant.agent_task","title":"<code>agent_task(message)</code>  <code>async</code>","text":"<p>Initiate email search workflow</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>async def agent_task(self, message):\n    \"\"\"Initiate email search workflow\"\"\"\n    self.pending_actions[self.whc.progress_messenger0.recipient_phone] = {\n        'type': 'self-agent',\n        'step': 'await_query'\n    }\n    return {\n        'type': 'quick_reply',\n        'text': \"Now prompt the self-agent \ud83d\udcdd\",\n        'options': {'cancel': '\u274c Cancel Search'}\n    }\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant.check_emails","title":"<code>check_emails(message, query='')</code>  <code>async</code>","text":"<p>Improved email checking with WhatsApp API formatting</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>async def check_emails(self, message, query=\"\"):\n    \"\"\"Improved email checking with WhatsApp API formatting\"\"\"\n    if not self.gmail_service:\n        return \"\u26a0\ufe0f Gmail service not configured\"\n\n    try:\n        results = self.gmail_service.users().messages().list(\n            userId='me',\n            maxResults=10,\n            labelIds=['INBOX'],\n            q=query\n        ).execute()\n\n        emails = []\n        for msg in results.get('messages', [])[:10]:\n            email_data = self.gmail_service.users().messages().get(\n                userId='me',\n                id=msg['id'],\n                format='metadata'\n            ).execute()\n\n            headers = {h['name']: h['value'] for h in email_data['payload']['headers']}\n            emails.append({\n                'id': msg['id'],\n                'from': headers.get('From', 'Unknown'),\n                'subject': headers.get('Subject', 'No Subject'),\n                'date': headers.get('Date', 'Unknown'),\n                'snippet': email_data.get('snippet', ''),\n                'unread': 'UNREAD' in email_data.get('labelIds', [])\n            })\n\n        return {\n            'type': 'list',\n            'header': '\ud83d\udce8 Recent Emails',\n            'body': 'Tap to view full email',\n            'footer': 'Email Manager',\n            'sections': [{\n                'title': f\"Inbox ({len(emails)} emails)\",\n                'rows': [{\n                    'id': f\"email_{email['id']}\",\n                    'title': f\"{'\ud83d\udcec' if email['unread'] else '\ud83d\udced'} {email['subject']}\"[:23],\n                    'description': f\"From: {email['from']}\\n{email['snippet']}\"[:45]\n                } for email in emails]\n            }]\n        }\n    except Exception as e:\n        return f\"\u26a0\ufe0f Error fetching emails: {str(e)}\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant.complete_authorization","title":"<code>complete_authorization(message)</code>","text":"<p>Complete the authorization process using the authorization code</p> <p>:param authorization_code: Authorization code received from Google</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>def complete_authorization(self, message: Message):\n    \"\"\"\n    Complete the authorization process using the authorization code\n\n    :param authorization_code: Authorization code received from Google\n    \"\"\"\n    from google_auth_oauthlib.flow import Flow\n    authorization_code = message.content\n    # Define the scopes required for Gmail and Calendar\n    SCOPES = [\n        'https://www.googleapis.com/auth/gmail.modify',\n        'https://www.googleapis.com/auth/calendar'\n    ]\n\n    # Create a flow instance to manage the OAuth 2.0 authorization process\n    flow = Flow.from_client_secrets_file(\n        self.credentials_path,\n        scopes=SCOPES,\n        redirect_uri='urn:ietf:wg:oauth:2.0:oob'\n    )\n\n    # Exchange the authorization code for credentials\n    flow.fetch_token(code=authorization_code)\n    self.credentials = flow.credentials\n\n    # Save the credentials for future use\n    self.save_credentials()\n\n    # Initialize services\n    self.init_services()\n    return \"Done\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant.delete_document","title":"<code>delete_document(message)</code>  <code>async</code>","text":"<p>Delete document workflow</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>async def delete_document(self, message):\n    \"\"\"Delete document workflow\"\"\"\n    docs = self.blob_docs_system.list_documents()\n    return {\n        'type': 'quick_reply',\n        'text': 'Select document to delete:',\n        'options': {doc['id']: doc['name'] for doc in docs[:5]},\n        'handler': self._confirm_delete\n    }\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant.email_search","title":"<code>email_search(message)</code>  <code>async</code>","text":"<p>Initiate email search workflow</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>async def email_search(self, message):\n    \"\"\"Initiate email search workflow\"\"\"\n    self.pending_actions[self.whc.progress_messenger0.recipient_phone] = {\n        'type': 'email_search',\n        'step': 'await_query'\n    }\n    return {\n        'type': 'quick_reply',\n        'text': \"\ud83d\udd0d What would you like to search for?\",\n        'options': {'cancel': '\u274c Cancel Search'}\n    }\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant.email_summary","title":"<code>email_summary(message)</code>  <code>async</code>","text":"<p>Generate AI-powered email summaries</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>async def email_summary(self, message):\n    \"\"\"Generate AI-powered email summaries\"\"\"\n    try:\n        messages = self.gmail_service.users().messages().list(\n            userId='me',\n            maxResults=3,\n            labelIds=['INBOX']\n        ).execute().get('messages', [])\n\n        email_contents = []\n        for msg in messages[:3]:\n            email_data = self.gmail_service.users().messages().get(\n                userId='me',\n                id=msg['id'],\n                format='full'\n            ).execute()\n            email_contents.append(self._parse_email_content(email_data))\n\n        summary = self.agent.mini_task(\n            \"\\n\\n\".join(email_contents) , \"system\", \"Summarize these emails in bullet points with key details:\"\n        )\n\n        return f\"\ud83d\udccb Email Summary:\\n{summary}\\n\\n*Powered by AI*\"\n    except Exception as e:\n        logging.error(f\"Summary failed: {str(e)}\")\n        return f\"\u274c Could not generate summary: {str(e)}\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant.find_time_slot","title":"<code>find_time_slot(message)</code>  <code>async</code>","text":"<p>Find and display the next 5 available time slots with dynamic durations</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>async def find_time_slot(self, message):\n    \"\"\"Find and display the next 5 available time slots with dynamic durations\"\"\"\n    if not self.calendar_service:\n        return \"\u26a0\ufe0f Calendar service not configured\"\n\n    try:\n        # Define the time range for the search (next 24 hours)\n        now = datetime.now(UTC)\n        end_time = now + timedelta(days=1)\n\n        # FreeBusy Request\n        freebusy_request = {\n            \"timeMin\": now.isoformat(),\n            \"timeMax\": end_time.isoformat(),\n            \"items\": [{\"id\": 'primary'}]\n        }\n\n        freebusy_response = self.calendar_service.freebusy().query(body=freebusy_request).execute()\n        busy_slots = freebusy_response['calendars']['primary']['busy']\n\n        # Slot-Berechnung\n        available_slots = self._calculate_efficient_slots(\n            busy_slots,\n            self.duration_minutes\n        )\n\n        # Format the response for WhatsApp\n        return {\n            'type': 'list',\n            'header': \"\u23f0 Available Time Slots\",\n            'body': \"Tap to select a time slot\",\n            'footer': \"Time Slot Finder\",\n            'sections': [{\n                'title': \"Next 5 Available Slots\",\n                'rows': [{\n                    'id': f\"slot_{slot['start'].timestamp()}\",\n                    'title': f\"\ud83d\udd52 {slot['start'].strftime('%H:%M')} - {slot['end'].strftime('%H:%M')}\",\n                    'description': f\"Duration: {slot['duration']}\"\n                } for slot in available_slots[:5]]\n            }]\n        }\n    except Exception as e:\n        return f\"\u26a0\ufe0f Error finding time slots: {str(e)}\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant.generate_authorization_url","title":"<code>generate_authorization_url(*a)</code>  <code>async</code>","text":"<p>Generate an authorization URL for user consent</p> <p>:return: Authorization URL for the user to click and authorize access</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>async def generate_authorization_url(self, *a):\n    \"\"\"\n    Generate an authorization URL for user consent\n\n    :return: Authorization URL for the user to click and authorize access\n    \"\"\"\n    from google_auth_oauthlib.flow import Flow\n    # Define the scopes required for Gmail and Calendar\n    SCOPES = [\n        'https://www.googleapis.com/auth/gmail.modify',\n        'https://www.googleapis.com/auth/calendar'\n    ]\n\n    # Create a flow instance to manage the OAuth 2.0 authorization process\n    flow = Flow.from_client_secrets_file(\n        self.credentials_path,\n        scopes=SCOPES,\n        redirect_uri='urn:ietf:wg:oauth:2.0:oob'  # Use 'urn:ietf:wg:oauth:2.0:oob' for desktop apps\n    )\n\n    # Generate the authorization URL\n    authorization_url, _ = flow.authorization_url(\n        access_type='offline',  # Allows obtaining refresh token\n        prompt='consent'  # Ensures user is always prompted for consent\n    )\n    self.pending_actions[self.whc.progress_messenger0.recipient_phone] = {'type': 'auth',\n                                                                          'step': 'awaiting_key'}\n    return {\n        'type': 'quick_reply',\n        'text': f'Url to log in {authorization_url}',\n        'options': {'cancel': '\u274c Cancel Upload'}\n    }\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant.get_email_details","title":"<code>get_email_details(email_id)</code>  <code>async</code>","text":"<p>Retrieve and format full email details</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>async def get_email_details(self, email_id):\n    \"\"\"Retrieve and format full email details\"\"\"\n    if not self.gmail_service:\n        return \"\u26a0\ufe0f Gmail service not configured\"\n\n    try:\n        email_data = self.gmail_service.users().messages().get(\n            userId='me',\n            id=email_id,\n            format='full'\n        ).execute()\n\n        headers = {h['name']: h['value'] for h in email_data['payload']['headers']}\n        body = \"\"\n        for part in email_data.get('payload', {}).get('parts', []):\n            if part['mimeType'] == 'text/plain':\n                body = base64.urlsafe_b64decode(part['body']['data']).decode('utf-8')\n                break\n\n        formatted_text = (\n            f\"\ud83d\udce7 *Email Details*\\n\\n\"\n            f\"From: {headers.get('From', 'Unknown')}\\n\"\n            f\"Subject: {headers.get('Subject', 'No Subject')}\\n\"\n            f\"Date: {headers.get('Date', 'Unknown')}\\n\\n\"\n            f\"{body[:15000]}{'...' if len(body) &gt; 15000 else ''}\"\n        )\n        return  self.agent.mini_task(\n            formatted_text , \"system\", \"Summarize the email in bullet points with key details\"\n        )\n    except Exception as e:\n        return f\"\u26a0\ufe0f Error fetching email: {str(e)}\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant.get_event_details","title":"<code>get_event_details(event_id)</code>  <code>async</code>","text":"<p>Retrieve and format calendar event details with location support</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>async def get_event_details(self, event_id):\n    \"\"\"Retrieve and format calendar event details with location support\"\"\"\n    if not self.calendar_service:\n        return \"\u26a0\ufe0f Calendar service not configured\"\n\n    try:\n        event = self.calendar_service.events().get(\n            calendarId='primary',\n            eventId=event_id\n        ).execute()\n\n        response = [ (\n                f\"\ud83d\udcc5 *Event Details*\\n\\n\"\n                f\"Title: {event.get('summary', 'No title')}\\n\"\n                f\"Time: {self._format_event_time(event)}\\n\"\n                f\"Location: {event.get('location', 'Not specified')}\\n\\n\"\n                f\"{event.get('description', 'No description')[:1000]}\"\n            )]\n\n        if 'geo' in event:\n            response.append({\n                'lat': float(event['geo']['latitude']),\n                'long': float(event['geo']['longitude']),\n                'name': event.get('location', 'Event Location'),\n                'address': event.get('location', ''),\n                'recipient_id': self.whc.progress_messenger0.recipient_phone\n            })\n        return response\n    except Exception as e:\n        return f\"\u26a0\ufe0f Error fetching event: {str(e)}\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant.handle_audio_message","title":"<code>handle_audio_message(message)</code>  <code>async</code>","text":"<p>Process audio messages with STT and TTS</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>async def handle_audio_message(self, message: 'Message'):\n    \"\"\"Process audio messages with STT and TTS\"\"\"\n    # Download audio\n    progress = self.progress_messengers['task']\n    stop_flag = threading.Event()\n    # message_id = progress.send_initial_message(mode=\"loading\")\n    progress.message_id = message.id\n    progress.start_loading_in_background(stop_flag)\n\n    content = self.whc.messenger.get_audio(message.data)\n    audio_file_name = self.whc.messenger.download_media(media_url=self.whc.messenger.query_media_url(media_id=content.get('id')), mime_type='audio/opus', file_path=\".data/temp\")\n    print(f\"audio_file_name {audio_file_name}\")\n    if audio_file_name is None:\n        message.reply(\"Could not process audio file\")\n        stop_flag.set()\n        return\n\n    text = self.stt(audio_file_name)['text']\n    if not text:\n        message.reply(\"Could not process audio\")\n        stop_flag.set()\n        return\n\n    message.reply(\"Transcription :\\n \"+ text)\n    message.content = text\n    agent_res = await self.helper_text(message, return_text=True)\n\n    if agent_res is not None:\n        pass\n\n    stop_flag.set()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant.handle_button_interaction","title":"<code>handle_button_interaction(content, message)</code>  <code>async</code>","text":"<p>Handle button click interactions</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>async def handle_button_interaction(self, content: dict, message: Message):\n    \"\"\"Handle button click interactions\"\"\"\n    button_id = content['id']\n\n    # First check if it's a main menu button\n    if button_id in self.buttons:\n        self.whc.messenger.send_button(\n            recipient_id=self.whc.progress_messenger0.recipient_phone,\n            button=self.buttons[button_id]\n        )\n        return\n\n    # Handle action buttons\n    action_handlers = {\n        # Agent controls\n        'start': self.start_agent,\n        'stop': self.stop_agent,\n        'tasks': self.show_task_stack,\n        'memory': self.clear_memory,\n        'system-task': self.system_task,\n        'agent-task': self.agent_task,\n\n        # Email controls\n        'check': self.check_emails,\n        'send': self.start_email_compose,\n        'summary': self.email_summary,\n        'search': self.email_search,\n\n        # Calendar controls\n        'today': self.show_today_events,\n        'add': self.start_event_create,\n        'upcoming': self.show_upcoming_events,\n        'find_slot': self.find_time_slot,\n\n        # Document controls\n        'upload': self.start_document_upload,\n        'list': self.list_documents,\n        'search_docs': self.search_documents,\n        'delete': self.delete_document,\n\n        # System controls\n        'status': self.system_status,\n        'restart': self.restart_system,\n        'connect': self.generate_authorization_url,\n\n        'cancel': self.cancel,\n        'confirm': self.confirm,\n    }\n    if button_id in action_handlers:\n        try:\n            # Start progress indicator\n            progress = self.progress_messengers['task']\n            stop_flag = threading.Event()\n            # message_id = progress.send_initial_message(mode=\"loading\")\n            progress.message_id = message.id\n            progress.start_loading_in_background(stop_flag)\n\n            # Execute handler\n\n            result = await action_handlers[button_id](message)\n\n\n            # Send result\n            if isinstance(result, str):\n                self.save_reply(message, result)\n            elif isinstance(result, dict):  # For structured responses\n                self.send_structured_response(result)\n\n            stop_flag.set()\n        finally:\n            #except Exception as e:\n            stop_flag.set()\n        #    message.reply(f\"\u274c Error processing {button_id}: {str(e)}\")\n    elif 'event_' in button_id:\n        res = await self.get_event_details(button_id.replace(\"event_\", ''))\n        if isinstance(res, str):\n            self.save_reply(message, res)\n            return\n        for r in res:\n            if isinstance(r, str):\n                self.save_reply(message, r)\n            else:\n                self.whc.messenger.send_location(**r)\n\n    elif 'email_' in button_id:\n        res = await self.get_email_details(button_id.replace(\"email_\", ''))\n        self.save_reply(message, res)\n    else:\n        message.reply(\"\u26a0\ufe0f Unknown command\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant.handle_calendar_actions","title":"<code>handle_calendar_actions(message)</code>  <code>async</code>","text":"<p>Handle calendar-related pending actions</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>async def handle_calendar_actions(self, message):\n    \"\"\"Handle calendar-related pending actions\"\"\"\n    user_state = self.pending_actions.get(self.whc.progress_messenger0.recipient_phone, {})\n\n    if user_state.get('type') == 'create_event':\n        return await self._handle_event_creation(message, user_state)\n\n    return None\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant.handle_email_actions","title":"<code>handle_email_actions(message)</code>  <code>async</code>","text":"<p>Handle multi-step email workflows</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>    async def handle_email_actions(self, message):\n        \"\"\"Handle multi-step email workflows\"\"\"\n        user_state = self.pending_actions.get(self.whc.progress_messenger0.recipient_phone, {})\n\n        if user_state.get('type') == 'compose_email':\n            return await self._handle_email_composition(message, user_state)\n        if user_state.get('type') == 'email_search':\n            return await self.check_emails(message, self.agent.mini_task(\"\"\"Conventire Pezise zu einer googel str only query using : Gmail Suchoperatoren!\n\nBasis-Operatoren:\n- from: Absender\n- to: Empf\u00e4nger\n- subject: Betreff\n- label: Gmail Label\n- has:attachment Anh\u00e4nge\n- newer_than:7d Zeitfilter\n- before: Datum vor\n- after: Datum nach\n\nErweiterte Operatoren:\n- in:inbox\n- in:sent\n- in:spam\n- cc: Kopie\n- bcc: Blindkopie\n- is:unread\n- is:read\n- larger:10M Gr\u00f6\u00dfenfilter\n- smaller:5M\n- filename:pdf Dateityp\n\nProfi-Tipps:\n- Kombinierbar mit UND/ODER\n- Anf\u00fchrungszeichen f\u00fcr exakte Suche\n- Negation mit -\n beispeile : 'Ungelesene Mails letzte Woche': -&gt; 'is:unread newer_than:7d'\n\n\"\"\", \"user\",message.content))\n\n\n        return None\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant.handle_interactive","title":"<code>handle_interactive(message)</code>  <code>async</code>","text":"<p>Handle all interactive messages</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>async def handle_interactive(self, message: Message):\n    \"\"\"Handle all interactive messages\"\"\"\n    content = self.whc.messenger.get_interactive_response(message.data)\n    if content.get(\"type\") == \"list_reply\":\n        await self.handle_button_interaction(content.get(\"list_reply\"), message)\n    elif content.get(\"type\") == \"button_reply\":\n        print(content)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant.handle_media_message","title":"<code>handle_media_message(message)</code>  <code>async</code>","text":"<p>Handle document/image/video uploads</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>async def handle_media_message(self, message: 'Message'):\n    \"\"\"Handle document/image/video uploads\"\"\"\n    user_state = self.pending_actions.get(self.whc.progress_messenger0.recipient_phone, {})\n\n    if user_state.get('step') == 'awaiting_file':\n        file_type = message.type\n        if file_type not in ['document', 'image', 'video']:\n            return \"Unsupported file type\"\n\n        try:\n            # Download media\n            #media_url = message.document.url if hasattr(message, 'document') else \\\n            #    message.image.url if hasattr(message, 'image') else \\\n            #        message.video.url\n            if file_type =='video':\n                content = self.whc.messenger.get_video(message.data)\n            if file_type =='image':\n                content = self.whc.messenger.get_image(message.data)\n            if file_type =='document':\n                content = self.whc.messenger.get_document(message.data)\n            print(\"Media content:\", content)\n            media_data = self.whc.messenger.download_media(media_url=self.whc.messenger.query_media_url(media_id=content.get('id')),  mime_type=content.get('mime_type'), file_path='.data/temp')\n            print(\"Media media_data:\", media_data)\n            # Save to blob storage\n            filename = f\"file_{file_type}_{datetime.now().isoformat()}_{content.get('sha256', '')}\"\n            blob_id = self.blob_docs_system.save_document(\n                open(media_data, 'rb').read(),\n                filename=filename,\n                file_type=file_type\n            )\n\n            self.pending_actions[self.whc.progress_messenger0.recipient_phone] = {}\n            return f\"\u2705 File uploaded successfully!\\nID: {blob_id}\"\n\n        except Exception as e:\n            logging.error(f\"Upload failed: {str(e)}\")\n            return f\"\u274c Failed to upload file Error : {str(e)}\"\n\n    return \"No pending uploads\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant.handle_message","title":"<code>handle_message(message)</code>  <code>async</code>","text":"<p>Main message handler for incoming WhatsApp messages</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>async def handle_message(self, message: 'Message'):\n    \"\"\"Main message handler for incoming WhatsApp messages\"\"\"\n\n    # Deduplication check\n    with self.message_lock:\n        if message.id in self.processed_messages:\n            return\n        last_ts = time.time()\n        print(last_ts)\n        if len(self.processed_messages) &gt; 0:\n            m_id, last_ts = self.processed_messages.pop()\n            self.processed_messages.add((m_id, last_ts))\n\n        print(\"DUPLICATION P\", message.data.get('entry', [{}])[0].get('changes', [{}])[0].get('value', {}).get('messages', [{}])[0].get('timestamp', 0) , last_ts)\n        if float(message.data.get('entry', [{}])[0].get('changes', [{}])[0].get('value', {}).get('messages', [{}])[0].get('timestamp', 0)) &lt; last_ts - 120:\n            return\n        self.processed_messages.add((message.id, time.perf_counter()))\n\n    # Mark message as read\n    message.mark_as_read()\n\n    # Extract content and type\n    content_type = message.type\n    content = message.content\n\n    print(f\"message.content {content=} {content_type=} {message.data=}\")\n\n    try:\n        if content_type == 'interactive':\n            await self.handle_interactive(message)\n        elif content_type == 'audio':\n            await self.handle_audio_message(message)\n        elif content_type in ['document', 'image', 'video']:\n            response = await self.handle_media_message(message)\n            self.save_reply(message, response)\n        elif content_type == 'text':\n            if content.lower() == \"menu\":\n                self.whc.messenger.send_button(\n                    recipient_id=self.whc.progress_messenger0.recipient_phone,\n                    button=self.buttons[content.lower()]\n                )\n            else:\n                await self.helper_text(message)\n        else:\n            message.reply(\"Unsupported message type\")\n    #except Exception as e:\n    #    logging.error(f\"Message handling error: {str(e)}\")\n    #   message.reply(\"\u274c Error processing request\")\n    finally:\n        # Cleanup old messages (keep 1 hour history)\n        with self.message_lock:\n            self._clean_processed_messages()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant.init_services","title":"<code>init_services()</code>","text":"<p>Initialize Gmail and Calendar services</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>def init_services(self):\n    \"\"\"\n    Initialize Gmail and Calendar services\n    \"\"\"\n    from googleapiclient.discovery import build\n\n    self.gmail_service = build('gmail', 'v1', credentials=self.credentials)\n    self.calendar_service = build('calendar', 'v3', credentials=self.credentials)\n    self.pending_actions[self.whc.progress_messenger0.recipient_phone] = {}\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant.load_credentials","title":"<code>load_credentials()</code>","text":"<p>Load previously saved credentials if available</p> <p>:return: Whether credentials were successfully loaded</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>def load_credentials(self):\n    \"\"\"\n    Load previously saved credentials if available\n\n    :return: Whether credentials were successfully loaded\n    \"\"\"\n    try:\n        self.credentials = Credentials.from_authorized_user_file('token/google_token.json')\n        self.init_services()\n        return True\n    except FileNotFoundError:\n        return False\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant.run","title":"<code>run()</code>","text":"<p>Start the WhatsApp assistant</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>def run(self):\n    \"\"\"Start the WhatsApp assistant\"\"\"\n    try:\n        self.state = AssistantState.ONLINE\n        # Send welcome message\n\n        mas = self.whc.messenger.create_message(\n            content=\"Digital Assistant is online! Send /help for available commands.\",to=self.whc.progress_messenger0.recipient_phone,\n        ).send(sender=0)\n        mas_id = mas.get(\"messages\", [{}])[0].get(\"id\")\n        print(mas_id)\n\n    except Exception as e:\n        logging.error(f\"Assistant error: {str(e)}\")\n        self.state = AssistantState.OFFLINE\n        raise\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant.save_credentials","title":"<code>save_credentials()</code>","text":"<p>Save the obtained credentials to a file for future use</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>def save_credentials(self):\n    \"\"\"\n    Save the obtained credentials to a file for future use\n    \"\"\"\n    if not os.path.exists('token'):\n        os.makedirs('token')\n\n    with open('token/google_token.json', 'w') as token_file:\n        token_file.write(self.credentials.to_json())\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant.search_documents","title":"<code>search_documents(message)</code>  <code>async</code>","text":"<p>Initiate document search workflow</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>async def search_documents(self, message):\n    \"\"\"Initiate document search workflow\"\"\"\n    self.pending_actions[self.whc.progress_messenger0.recipient_phone] = {'type': 'search', 'step': 'awaiting_query'}\n    return {\n        'type': 'quick_reply',\n        'text': '\ud83d\udd0d What are you looking for?',\n        'options': {'cancel': '\u274c Cancel Search'}\n    }\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant.send_email","title":"<code>send_email(to, subject, body)</code>","text":"<p>Actual email sending function to be called by agent</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>def send_email(self, to, subject, body):\n    \"\"\"Actual email sending function to be called by agent\"\"\"\n    if not self.gmail_service:\n        return False\n\n    message = MIMEText(body)\n    message['to'] = to\n    message['subject'] = subject\n\n    encoded_message = base64.urlsafe_b64encode(message.as_bytes()).decode()\n    self.gmail_service.users().messages().send(\n        userId='me',\n        body={'raw': encoded_message}\n    ).execute()\n    return True\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant.send_structured_response","title":"<code>send_structured_response(result)</code>","text":"<p>Send complex responses using appropriate WhatsApp features</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>def send_structured_response(self, result: dict):\n    \"\"\"Send complex responses using appropriate WhatsApp features\"\"\"\n    if result['type'] == 'list':\n        self.whc.messenger.send_button(\n            recipient_id=self.whc.progress_messenger0.recipient_phone,\n            button={\n                'header': result.get('header', ''),\n                'body': result.get('body', ''),\n                'footer': result.get('footer', ''),\n                'action': {\n                    'button': 'Action',\n                    'sections': result['sections']\n                }\n            }\n        )\n    elif result['type'] == 'quick_reply':\n        self.whc.messenger.send_button(\n            recipient_id=self.whc.progress_messenger0.recipient_phone,\n            button={\n                'header': \"Quick reply\",\n                'body': result['text'],\n                'footer': '',\n                'action': {'button': 'Action', 'sections': [{\n                    'title': 'View',\n                    'rows': [{'id': k, 'title': v[:23]} for k, v in result['options'].items()]\n                }]}\n            }\n        )\n\n    elif result['type'] == 'media':\n        if result['media_type'] == 'image':\n            self.whc.messenger.send_image(\n                image=result['url'],\n                recipient_id=self.whc.progress_messenger0.recipient_phone,\n                caption=result.get('caption', '')\n            )\n        elif result['media_type'] == 'document':\n            self.whc.messenger.send_document(\n                document=result['url'],\n                recipient_id=self.whc.progress_messenger0.recipient_phone,\n                caption=result.get('caption', '')\n            )\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant.setup_interaction_buttons","title":"<code>setup_interaction_buttons()</code>","text":"<p>Define WhatsApp interaction buttons for different functionalities</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>def setup_interaction_buttons(self):\n    \"\"\"Define WhatsApp interaction buttons for different functionalities\"\"\"\n    self.buttons = {\n        'menu': {\n            'header': 'Digital Assistant',\n            'body': 'Please select an option:',\n            'footer': '-- + --',\n            'action': {\n                'button': 'Menu',\n                'sections': [\n                    {\n                        'title': 'Main Functions',\n                        'rows': [\n                            {'id': 'agent', 'title': 'Agent Controls', 'description': 'Manage your AI assistant'},\n                            {'id': 'email', 'title': 'Email Management', 'description': 'Handle your emails'},\n                            {'id': 'calendar', 'title': 'Calendar', 'description': 'Manage your schedule'},\n                            {'id': 'docs', 'title': 'Documents', 'description': 'Handle documents'},\n                            {'id': 'system', 'title': 'System', 'description': 'System controls and metrics'}\n                        ]\n                    }\n                ]\n            }\n        },\n        'agent': self._create_agent_controls_buttons(),\n        'email': self._create_email_controls_buttons(),\n        'calendar': self._create_calendar_controls_buttons(),\n        'docs': self._create_docs_controls_buttons(),\n        'system': self._create_system_controls_buttons()\n    }\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant.setup_progress_messengers","title":"<code>setup_progress_messengers()</code>","text":"<p>Initialize progress messengers for different types of tasks</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>def setup_progress_messengers(self):\n    \"\"\"Initialize progress messengers for different types of tasks\"\"\"\n    self.progress_messengers = {\n        'task': self.whc.progress_messenger0,\n        'email': self.whc.progress_messenger1,\n        'calendar': self.whc.progress_messenger2\n    }\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant.show_task_stack","title":"<code>show_task_stack(*a)</code>  <code>async</code>","text":"<p>Display current task stack</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>async def show_task_stack(self, *a):\n    \"\"\"Display current task stack\"\"\"\n    if self.agent and len(self.agent.taskstack.tasks) &gt; 0:\n        tasks = self.agent.taskstack.tasks\n        return self.agent.mini_task(\"\\n\".join([f\"Task {t.id}: {t.description}\" for t in tasks]), \"system\", \"Format to nice and clean whatsapp format\")\n    return \"No tasks in stack\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant.show_today_events","title":"<code>show_today_events(message)</code>  <code>async</code>","text":"<p>Show today's calendar events</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>async def show_today_events(self, message):\n    \"\"\"Show today's calendar events\"\"\"\n    if not self.calendar_service:\n        message.replay(\"service not online\")\n\n    now = datetime.utcnow().isoformat() + 'Z'\n    end_of_day = (datetime.now() + timedelta(days=1)).replace(\n        hour=0, minute=0, second=0).isoformat() + 'Z'\n\n    events_result = self.calendar_service.events().list(\n        calendarId='primary',\n        timeMin=now,\n        timeMax=end_of_day,\n        singleEvents=True,\n        orderBy='startTime'\n    ).execute()\n\n    events = events_result.get('items', [])\n    return self._format_calendar_response(events, \"Today's Events\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant.show_upcoming_events","title":"<code>show_upcoming_events(message)</code>  <code>async</code>","text":"<p>Show upcoming events with interactive support</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>async def show_upcoming_events(self, message):\n    \"\"\"Show upcoming events with interactive support\"\"\"\n    if not self.calendar_service:\n        return \"\u26a0\ufe0f Calendar service not configured\"\n\n    try:\n        now = datetime.utcnow().isoformat() + 'Z'\n        next_week = (datetime.now() + timedelta(days=7)).isoformat() + 'Z'\n\n        events_result = self.calendar_service.events().list(\n            calendarId='primary',\n            timeMin=now,\n            timeMax=next_week,\n            singleEvents=True,\n            orderBy='startTime',\n            maxResults=10\n        ).execute()\n\n        events = events_result.get('items', [])\n        return self._format_calendar_response(events, \"Upcoming Events\")\n    except Exception as e:\n        return f\"\u26a0\ufe0f Error fetching events: {str(e)}\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant.start_agent","title":"<code>start_agent(*a)</code>  <code>async</code>","text":"<p>Start the agent in background mode</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>async def start_agent(self, *a):\n    \"\"\"Start the agent in background mode\"\"\"\n    if self.agent:\n        self.agent.run_in_background()\n        return True\n    return False\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant.start_document_upload","title":"<code>start_document_upload(message)</code>  <code>async</code>","text":"<p>Initiate document upload workflow</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>async def start_document_upload(self, message):\n    \"\"\"Initiate document upload workflow\"\"\"\n    self.pending_actions[self.whc.progress_messenger0.recipient_phone] = {'type': 'document', 'step': 'awaiting_file'}\n    return {\n        'type': 'quick_reply',\n        'text': '\ud83d\udce4 Send me the file you want to upload',\n        'options': {'cancel': '\u274c Cancel Upload'}\n    }\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant.start_email_compose","title":"<code>start_email_compose(message)</code>  <code>async</code>","text":"<p>Enhanced email composition workflow</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>async def start_email_compose(self, message):\n    \"\"\"Enhanced email composition workflow\"\"\"\n    self.pending_actions[self.whc.progress_messenger0.recipient_phone] = {\n        'type': 'compose_email',\n        'step': 'subject',\n        'draft': {'attachments': []}\n    }\n    return {\n        'type': 'quick_reply',\n        'text': \"\ud83d\udcdd Let's compose an email\\n\\nSubject:\",\n        'options': {'cancel': '\u274c Cancel Composition'}\n    }\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant.start_event_create","title":"<code>start_event_create(message)</code>  <code>async</code>","text":"<p>Initiate event creation workflow</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>async def start_event_create(self, message):\n    \"\"\"Initiate event creation workflow\"\"\"\n    self.pending_actions[self.whc.progress_messenger0.recipient_phone] = {\n        'type': 'create_event',\n        'step': 'title',\n        'event_data': {}\n    }\n    return {\n        'type': 'quick_reply',\n        'text': \"Let's create an event! What's the title?\",\n        'options': {'cancel': '\u274c Cancel'}\n    }\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant.stop_agent","title":"<code>stop_agent(*b)</code>  <code>async</code>","text":"<p>Stop the currently running agent</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>async def stop_agent(self, *b):\n    \"\"\"Stop the currently running agent\"\"\"\n    if self.agent:\n        self.agent.stop()\n        return True\n    return False\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.client.WhatsAppAssistant.system_task","title":"<code>system_task(message)</code>  <code>async</code>","text":"<p>Initiate email search workflow</p> Source code in <code>toolboxv2/mods/WhatsAppTb/client.py</code> <pre><code>async def system_task(self, message):\n    \"\"\"Initiate email search workflow\"\"\"\n    self.pending_actions[self.whc.progress_messenger0.recipient_phone] = {\n        'type': 'system',\n        'step': 'await_query'\n    }\n    return {\n        'type': 'quick_reply',\n        'text': \"Now prompt the \ud83e\udde0ISAA-System \ud83d\udcdd\",\n        'options': {'cancel': '\u274c Cancel Search'}\n    }\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.server","title":"<code>server</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.server.AppManager","title":"<code>AppManager</code>","text":"Source code in <code>toolboxv2/mods/WhatsAppTb/server.py</code> <pre><code>class AppManager(metaclass=Singleton):\n    pepper = \"pepper0\"\n\n    def __init__(self, start_port: int = 8000, port_range: int = 10, em=None):\n        self.instances: dict[str, dict] = {}\n        self.start_port = start_port\n        self.port_range = port_range\n        self.threads: dict[str, Thread] = {}\n        self.stop_events: dict[str, Event] = {}\n        self.message_queue: asyncio.Queue = asyncio.Queue()\n        self.last_messages: dict[str, datetime] = {}\n        self.keys: dict[str, str] = {}\n        self.forwarders: dict[str, dict] = {}\n        self.runner = lambda :None\n\n        if em is None:\n            from toolboxv2 import get_app\n            em = get_app().get_mod(\"EventManager\")\n        from toolboxv2.mods import EventManager\n        self.event_manager: EventManager = em.get_manager()\n\n        # Set up signal handlers for graceful shutdown\n        try:\n            if threading.current_thread() is threading.main_thread():\n                signal.signal(signal.SIGINT, self.signal_handler)\n                signal.signal(signal.SIGTERM, self.signal_handler)\n        except Exception:\n            pass\n\n    def offline(self, instance_id):\n\n        def mark_as_offline():\n            self.forwarders[instance_id]['send'] = None\n            return 'done'\n\n        return mark_as_offline\n\n    def online(self, instance_id):\n\n        def mark_as_online():\n            return self.instances[instance_id]['app']\n\n        def set_callbacks(callback, e_callback=None):\n            if callback is not None:\n                self.forwarders[instance_id]['send'] = callback\n            if e_callback is not None:\n                self.forwarders[instance_id]['sende'] = e_callback\n\n        return mark_as_online(), set_callbacks\n\n    def get_next_available_port(self) -&gt; int:\n        \"\"\"Find the next available port in the range.\"\"\"\n        used_ports = {instance['port'] for instance in self.instances.values()}\n        for port in range(self.start_port, self.start_port + self.port_range):\n            if port not in used_ports:\n                return port\n        raise RuntimeError(\"No available ports in range\")\n\n    def add_instance(self, instance_id: str, **kwargs):\n        \"\"\"\n        Add a new app instance to the manager with automatic port assignment.\n        \"\"\"\n        if instance_id in self.instances:\n            raise ValueError(f\"Instance {instance_id} already exists\")\n\n        port = self.get_next_available_port()\n        app_instance = WhatsApp(**kwargs)\n\n        self.instances[instance_id] = {\n            'app': app_instance,\n            'port': port,\n            'kwargs': kwargs,\n            'phone_number_id': kwargs.get(\"phone_number_id\", {}),\n            'retry_count': 0,\n            'max_retries': 3,\n            'retry_delay': 5\n        }\n        self.keys[instance_id] = Code.one_way_hash(kwargs.get(\"phone_number_id\", {}).get(\"key\"), \"WhatsappAppManager\",\n                                                   self.pepper)\n        self.forwarders[instance_id] = {}\n\n        # Set up message handlers\n        @app_instance.on_message\n        async def message_handler(message):\n            await self.on_message(instance_id, message)\n\n        @app_instance.on_event\n        async def event_handler(event):\n            await self.on_event(instance_id, event)\n\n        @app_instance.on_verification\n        async def verification_handler(verification):\n            await self.on_verification(instance_id, verification)\n\n        # Create stop event for this instance Error parsing message1:\n        self.stop_events[instance_id] = Event()\n\n    def run_instance(self, instance_id: str):\n        \"\"\"Run a single instance in a separate thread with error handling and automatic restart.\"\"\"\n        instance_data = self.instances[instance_id]\n        stop_event = self.stop_events[instance_id]\n\n        while not stop_event.is_set():\n            try:\n                logger.info(f\"Starting instance {instance_id} on port {instance_data['port']}\")\n                instance_data['app'].run(host='0.0.0.0', port=instance_data['port'])\n\n            except Exception as e:\n                logger.error(f\"Error in instance {instance_id}: {str(e)}\")\n                instance_data['retry_count'] += 1\n\n                if instance_data['retry_count'] &gt; instance_data['max_retries']:\n                    logger.error(f\"Max retries exceeded for instance {instance_id}\")\n                    break\n\n                logger.info(f\"Restarting instance {instance_id} in {instance_data['retry_delay']} seconds...\")\n                time.sleep(instance_data['retry_delay'])\n\n                # Recreate the instance\n                instance_data['app'] = WhatsApp(**instance_data['kwargs'])\n                continue\n\n    async def on_message(self, instance_id: str, message: Message):\n        \"\"\"Handle and forward incoming messages.\"\"\"\n        logger.info(f\"Message from instance {instance_id}: {message}\")\n        if instance_id in self.forwarders and 'send' in self.forwarders[instance_id]:\n            await self.forwarders[instance_id]['send'](message)\n\n    async def on_event(self, instance_id: str, event):\n        \"\"\"Handle events.\"\"\"\n        logger.info(f\"Event from instance {instance_id}: {event}\")\n        if instance_id in self.forwarders and 'sende' in self.forwarders[instance_id] and self.forwarders[instance_id]['sende'] is not None:\n            self.forwarders[instance_id]['sende'](event)\n\n    async def on_verification(self, instance_id: str, verification):\n        \"\"\"Handle verification events.\"\"\"\n        logger.info(f\"Verification from instance {instance_id}: {verification}\")\n\n    def run_all_instances(self):\n        \"\"\"Start all instances in separate daemon threads.\"\"\"\n        # Start message forwarder\n\n        # Start all instances\n        for instance_id in self.instances:\n            thread = Thread(\n                target=self.run_instance,\n                args=(instance_id,),\n                daemon=True,\n                name=f\"WhatsApp-{instance_id}\"\n            )\n            self.threads[instance_id] = thread\n            thread.start()\n\n    def signal_handler(self, signum, frame):\n        \"\"\"Handle shutdown signals gracefully.\"\"\"\n        logger.info(\"Shutdown signal received, stopping all instances...\")\n        self.stop_all_instances()\n        sys.exit(0)\n\n    def stop_all_instances(self):\n        \"\"\"Stop all running instances gracefully.\"\"\"\n        for instance_id in self.stop_events:\n            self.stop_events[instance_id].set()\n\n        for thread in self.threads.values():\n            thread.join(timeout=5)\n\n    def create_manager_ui(self, start_assistant):\n        \"\"\"Enhanced WhatsApp Manager UI with instance configuration controls\"\"\"\n        self.runner = start_assistant\n        def ui_manager():\n            # Track instance states and messages\n            original_on_message = self.on_message\n\n            async def enhanced_on_message(instance_id: str, message):\n                self.last_messages[instance_id] = datetime.now()\n                await original_on_message(instance_id, message)\n\n            self.on_message = enhanced_on_message\n\n            def create_instance_card(instance_id: str):\n                \"\"\"Interactive instance control card\"\"\"\n                config = self.instances[instance_id]\n                with ui.card().classes('w-full p-4 mb-4 bg-gray-50 dark:bg-gray-800').style(\"background-color: var(--background-color) !important\"):\n                    # Header Section\n                    with ui.row().classes('w-full justify-between items-center'):\n                        ui.label(f'\ud83d\udcf1 {instance_id}').classes('text-xl font-bold')\n\n                        # Status Indicator\n                        ui.label().bind_text_from(\n                            self.threads, instance_id,\n                            lambda x: 'Running' if x and x.is_alive() else 'Stopped'\n                        )\n\n                    # Configuration Display\n                    with ui.grid(columns=2).classes('w-full mt-4 gap-2'):\n\n                        ui.label('port:').classes('font-bold')\n                        ui.label(config['port'])\n\n                        ui.label('Last Activity:').classes('font-bold')\n                        ui.label().bind_text_from(\n                            self.last_messages, instance_id,\n                            lambda x: x.strftime(\"%Y-%m-%d %H:%M:%S\") if x else 'Never'\n                        )\n\n                    # Action Controls\n                    with ui.row().classes('w-full mt-4 gap-2'):\n                        with ui.button(icon='settings', on_click=lambda: edit_dialog.open()).props('flat'):\n                            ui.tooltip('Configure')\n\n                        with ui.button(icon='refresh', color='orange',\n                                       on_click=lambda: self.restart_instance(instance_id)):\n                            ui.tooltip('Restart')\n\n                        with ui.button(icon='stop', color='red',\n                                       on_click=lambda: self.stop_instance(instance_id)):\n                            ui.tooltip('Stop')\n\n                    # Edit Configuration Dialog\n                    with ui.dialog() as edit_dialog, ui.card().classes('p-4 gap-4'):\n                        new_key = ui.input('API Key', value=config['phone_number_id'].get('key', ''))\n                        new_number = ui.input('Phone Number', value=config['phone_number_id'].get('number', ''))\n\n                        with ui.row().classes('w-full justify-end'):\n                            ui.button('Cancel', on_click=edit_dialog.close)\n                            ui.button('Save', color='primary', on_click=lambda: (\n                                self.update_instance_config(\n                                    instance_id,\n                                    new_key.value,\n                                    new_number.value\n                                ),\n                                edit_dialog.close()\n                            ))\n\n            # Main UI Layout\n            with ui.column().classes('w-full max-w-4xl mx-auto p-4'):\n                ui.label('WhatsApp Instance Manager').classes('text-2xl font-bold mb-6')\n\n                # Add Instance Section\n                with ui.expansion('\u2795 Add New Instance', icon='add').classes('w-full'):\n                    with ui.card().classes('w-full p-4 mt-2'):\n                        instance_id = ui.input('Instance ID').classes('w-full')\n                        token = ui.input('API Token').classes('w-full')\n                        phone_key = ui.input('Phone Number Key').classes('w-full')\n                        phone_number = ui.input('Phone Number').classes('w-full')\n\n                        with ui.row().classes('w-full justify-end gap-2'):\n                            ui.button('Clear', on_click=lambda: (\n                                instance_id.set_value(''),\n                                token.set_value(''),\n                                phone_key.set_value(''),\n                                phone_number.set_value('')\n                            ))\n                            ui.button('Create', color='positive', on_click=lambda: (\n                                self.add_update_instance(\n                                    instance_id.value,\n                                    token.value,\n                                    phone_key.value,\n                                    phone_number.value\n                                ),\n                                instances_container.refresh()\n                            ))\n\n                # Instances Display\n                instances_container = ui.column().classes('w-full')\n                with instances_container:\n                    for instance_id in self.instances:\n                        create_instance_card(instance_id)\n\n        return ui_manager\n\n    # Add to manager class\n    def add_update_instance(self, instance_id, token, phone_key, phone_number):\n        \"\"\"Add or update instance configuration\"\"\"\n        if instance_id in self.instances:\n            self.stop_instance(instance_id)\n            del self.instances[instance_id]\n\n        self.add_instance(\n            instance_id,\n            token=token,\n            phone_number_id={\n                'key': phone_key,\n                'number': phone_number\n            },\n            verify_token=os.getenv(\"WHATSAPP_VERIFY_TOKEN\")\n        )\n        self.start_instance(instance_id)\n\n    def update_instance_config(self, instance_id, new_key, new_number):\n        \"\"\"Update existing instance configuration\"\"\"\n        if instance_id in self.instances:\n            self.instances[instance_id]['phone_number_id'] = {\n                'key': new_key,\n                'number': new_number\n            }\n            self.restart_instance(instance_id)\n\n    def restart_instance(self, instance_id):\n        \"\"\"Safe restart of instance\"\"\"\n        self.stop_instance(instance_id)\n        self.start_instance(instance_id)\n\n    def stop_instance(self, instance_id):\n        \"\"\"Graceful stop of instance\"\"\"\n        if instance_id in self.threads:\n            self.stop_events[instance_id].set()\n            self.threads[instance_id].join(timeout=5)\n            del self.threads[instance_id]\n\n    def start_instance(self, instance_id):\n        \"\"\"Start instance thread\"\"\"\n        print(\"Starting Istance\")\n\n        self.stop_events[instance_id] = threading.Event()\n        self.threads[instance_id] = threading.Thread(\n            target=self.run_instance,\n            args=(instance_id,),\n            daemon=True\n        )\n        self.threads[instance_id].start()\n        print(\"Running starter\", self.runner())\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.server.AppManager.add_instance","title":"<code>add_instance(instance_id, **kwargs)</code>","text":"<p>Add a new app instance to the manager with automatic port assignment.</p> Source code in <code>toolboxv2/mods/WhatsAppTb/server.py</code> <pre><code>def add_instance(self, instance_id: str, **kwargs):\n    \"\"\"\n    Add a new app instance to the manager with automatic port assignment.\n    \"\"\"\n    if instance_id in self.instances:\n        raise ValueError(f\"Instance {instance_id} already exists\")\n\n    port = self.get_next_available_port()\n    app_instance = WhatsApp(**kwargs)\n\n    self.instances[instance_id] = {\n        'app': app_instance,\n        'port': port,\n        'kwargs': kwargs,\n        'phone_number_id': kwargs.get(\"phone_number_id\", {}),\n        'retry_count': 0,\n        'max_retries': 3,\n        'retry_delay': 5\n    }\n    self.keys[instance_id] = Code.one_way_hash(kwargs.get(\"phone_number_id\", {}).get(\"key\"), \"WhatsappAppManager\",\n                                               self.pepper)\n    self.forwarders[instance_id] = {}\n\n    # Set up message handlers\n    @app_instance.on_message\n    async def message_handler(message):\n        await self.on_message(instance_id, message)\n\n    @app_instance.on_event\n    async def event_handler(event):\n        await self.on_event(instance_id, event)\n\n    @app_instance.on_verification\n    async def verification_handler(verification):\n        await self.on_verification(instance_id, verification)\n\n    # Create stop event for this instance Error parsing message1:\n    self.stop_events[instance_id] = Event()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.server.AppManager.add_update_instance","title":"<code>add_update_instance(instance_id, token, phone_key, phone_number)</code>","text":"<p>Add or update instance configuration</p> Source code in <code>toolboxv2/mods/WhatsAppTb/server.py</code> <pre><code>def add_update_instance(self, instance_id, token, phone_key, phone_number):\n    \"\"\"Add or update instance configuration\"\"\"\n    if instance_id in self.instances:\n        self.stop_instance(instance_id)\n        del self.instances[instance_id]\n\n    self.add_instance(\n        instance_id,\n        token=token,\n        phone_number_id={\n            'key': phone_key,\n            'number': phone_number\n        },\n        verify_token=os.getenv(\"WHATSAPP_VERIFY_TOKEN\")\n    )\n    self.start_instance(instance_id)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.server.AppManager.create_manager_ui","title":"<code>create_manager_ui(start_assistant)</code>","text":"<p>Enhanced WhatsApp Manager UI with instance configuration controls</p> Source code in <code>toolboxv2/mods/WhatsAppTb/server.py</code> <pre><code>def create_manager_ui(self, start_assistant):\n    \"\"\"Enhanced WhatsApp Manager UI with instance configuration controls\"\"\"\n    self.runner = start_assistant\n    def ui_manager():\n        # Track instance states and messages\n        original_on_message = self.on_message\n\n        async def enhanced_on_message(instance_id: str, message):\n            self.last_messages[instance_id] = datetime.now()\n            await original_on_message(instance_id, message)\n\n        self.on_message = enhanced_on_message\n\n        def create_instance_card(instance_id: str):\n            \"\"\"Interactive instance control card\"\"\"\n            config = self.instances[instance_id]\n            with ui.card().classes('w-full p-4 mb-4 bg-gray-50 dark:bg-gray-800').style(\"background-color: var(--background-color) !important\"):\n                # Header Section\n                with ui.row().classes('w-full justify-between items-center'):\n                    ui.label(f'\ud83d\udcf1 {instance_id}').classes('text-xl font-bold')\n\n                    # Status Indicator\n                    ui.label().bind_text_from(\n                        self.threads, instance_id,\n                        lambda x: 'Running' if x and x.is_alive() else 'Stopped'\n                    )\n\n                # Configuration Display\n                with ui.grid(columns=2).classes('w-full mt-4 gap-2'):\n\n                    ui.label('port:').classes('font-bold')\n                    ui.label(config['port'])\n\n                    ui.label('Last Activity:').classes('font-bold')\n                    ui.label().bind_text_from(\n                        self.last_messages, instance_id,\n                        lambda x: x.strftime(\"%Y-%m-%d %H:%M:%S\") if x else 'Never'\n                    )\n\n                # Action Controls\n                with ui.row().classes('w-full mt-4 gap-2'):\n                    with ui.button(icon='settings', on_click=lambda: edit_dialog.open()).props('flat'):\n                        ui.tooltip('Configure')\n\n                    with ui.button(icon='refresh', color='orange',\n                                   on_click=lambda: self.restart_instance(instance_id)):\n                        ui.tooltip('Restart')\n\n                    with ui.button(icon='stop', color='red',\n                                   on_click=lambda: self.stop_instance(instance_id)):\n                        ui.tooltip('Stop')\n\n                # Edit Configuration Dialog\n                with ui.dialog() as edit_dialog, ui.card().classes('p-4 gap-4'):\n                    new_key = ui.input('API Key', value=config['phone_number_id'].get('key', ''))\n                    new_number = ui.input('Phone Number', value=config['phone_number_id'].get('number', ''))\n\n                    with ui.row().classes('w-full justify-end'):\n                        ui.button('Cancel', on_click=edit_dialog.close)\n                        ui.button('Save', color='primary', on_click=lambda: (\n                            self.update_instance_config(\n                                instance_id,\n                                new_key.value,\n                                new_number.value\n                            ),\n                            edit_dialog.close()\n                        ))\n\n        # Main UI Layout\n        with ui.column().classes('w-full max-w-4xl mx-auto p-4'):\n            ui.label('WhatsApp Instance Manager').classes('text-2xl font-bold mb-6')\n\n            # Add Instance Section\n            with ui.expansion('\u2795 Add New Instance', icon='add').classes('w-full'):\n                with ui.card().classes('w-full p-4 mt-2'):\n                    instance_id = ui.input('Instance ID').classes('w-full')\n                    token = ui.input('API Token').classes('w-full')\n                    phone_key = ui.input('Phone Number Key').classes('w-full')\n                    phone_number = ui.input('Phone Number').classes('w-full')\n\n                    with ui.row().classes('w-full justify-end gap-2'):\n                        ui.button('Clear', on_click=lambda: (\n                            instance_id.set_value(''),\n                            token.set_value(''),\n                            phone_key.set_value(''),\n                            phone_number.set_value('')\n                        ))\n                        ui.button('Create', color='positive', on_click=lambda: (\n                            self.add_update_instance(\n                                instance_id.value,\n                                token.value,\n                                phone_key.value,\n                                phone_number.value\n                            ),\n                            instances_container.refresh()\n                        ))\n\n            # Instances Display\n            instances_container = ui.column().classes('w-full')\n            with instances_container:\n                for instance_id in self.instances:\n                    create_instance_card(instance_id)\n\n    return ui_manager\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.server.AppManager.get_next_available_port","title":"<code>get_next_available_port()</code>","text":"<p>Find the next available port in the range.</p> Source code in <code>toolboxv2/mods/WhatsAppTb/server.py</code> <pre><code>def get_next_available_port(self) -&gt; int:\n    \"\"\"Find the next available port in the range.\"\"\"\n    used_ports = {instance['port'] for instance in self.instances.values()}\n    for port in range(self.start_port, self.start_port + self.port_range):\n        if port not in used_ports:\n            return port\n    raise RuntimeError(\"No available ports in range\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.server.AppManager.on_event","title":"<code>on_event(instance_id, event)</code>  <code>async</code>","text":"<p>Handle events.</p> Source code in <code>toolboxv2/mods/WhatsAppTb/server.py</code> <pre><code>async def on_event(self, instance_id: str, event):\n    \"\"\"Handle events.\"\"\"\n    logger.info(f\"Event from instance {instance_id}: {event}\")\n    if instance_id in self.forwarders and 'sende' in self.forwarders[instance_id] and self.forwarders[instance_id]['sende'] is not None:\n        self.forwarders[instance_id]['sende'](event)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.server.AppManager.on_message","title":"<code>on_message(instance_id, message)</code>  <code>async</code>","text":"<p>Handle and forward incoming messages.</p> Source code in <code>toolboxv2/mods/WhatsAppTb/server.py</code> <pre><code>async def on_message(self, instance_id: str, message: Message):\n    \"\"\"Handle and forward incoming messages.\"\"\"\n    logger.info(f\"Message from instance {instance_id}: {message}\")\n    if instance_id in self.forwarders and 'send' in self.forwarders[instance_id]:\n        await self.forwarders[instance_id]['send'](message)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.server.AppManager.on_verification","title":"<code>on_verification(instance_id, verification)</code>  <code>async</code>","text":"<p>Handle verification events.</p> Source code in <code>toolboxv2/mods/WhatsAppTb/server.py</code> <pre><code>async def on_verification(self, instance_id: str, verification):\n    \"\"\"Handle verification events.\"\"\"\n    logger.info(f\"Verification from instance {instance_id}: {verification}\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.server.AppManager.restart_instance","title":"<code>restart_instance(instance_id)</code>","text":"<p>Safe restart of instance</p> Source code in <code>toolboxv2/mods/WhatsAppTb/server.py</code> <pre><code>def restart_instance(self, instance_id):\n    \"\"\"Safe restart of instance\"\"\"\n    self.stop_instance(instance_id)\n    self.start_instance(instance_id)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.server.AppManager.run_all_instances","title":"<code>run_all_instances()</code>","text":"<p>Start all instances in separate daemon threads.</p> Source code in <code>toolboxv2/mods/WhatsAppTb/server.py</code> <pre><code>def run_all_instances(self):\n    \"\"\"Start all instances in separate daemon threads.\"\"\"\n    # Start message forwarder\n\n    # Start all instances\n    for instance_id in self.instances:\n        thread = Thread(\n            target=self.run_instance,\n            args=(instance_id,),\n            daemon=True,\n            name=f\"WhatsApp-{instance_id}\"\n        )\n        self.threads[instance_id] = thread\n        thread.start()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.server.AppManager.run_instance","title":"<code>run_instance(instance_id)</code>","text":"<p>Run a single instance in a separate thread with error handling and automatic restart.</p> Source code in <code>toolboxv2/mods/WhatsAppTb/server.py</code> <pre><code>def run_instance(self, instance_id: str):\n    \"\"\"Run a single instance in a separate thread with error handling and automatic restart.\"\"\"\n    instance_data = self.instances[instance_id]\n    stop_event = self.stop_events[instance_id]\n\n    while not stop_event.is_set():\n        try:\n            logger.info(f\"Starting instance {instance_id} on port {instance_data['port']}\")\n            instance_data['app'].run(host='0.0.0.0', port=instance_data['port'])\n\n        except Exception as e:\n            logger.error(f\"Error in instance {instance_id}: {str(e)}\")\n            instance_data['retry_count'] += 1\n\n            if instance_data['retry_count'] &gt; instance_data['max_retries']:\n                logger.error(f\"Max retries exceeded for instance {instance_id}\")\n                break\n\n            logger.info(f\"Restarting instance {instance_id} in {instance_data['retry_delay']} seconds...\")\n            time.sleep(instance_data['retry_delay'])\n\n            # Recreate the instance\n            instance_data['app'] = WhatsApp(**instance_data['kwargs'])\n            continue\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.server.AppManager.signal_handler","title":"<code>signal_handler(signum, frame)</code>","text":"<p>Handle shutdown signals gracefully.</p> Source code in <code>toolboxv2/mods/WhatsAppTb/server.py</code> <pre><code>def signal_handler(self, signum, frame):\n    \"\"\"Handle shutdown signals gracefully.\"\"\"\n    logger.info(\"Shutdown signal received, stopping all instances...\")\n    self.stop_all_instances()\n    sys.exit(0)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.server.AppManager.start_instance","title":"<code>start_instance(instance_id)</code>","text":"<p>Start instance thread</p> Source code in <code>toolboxv2/mods/WhatsAppTb/server.py</code> <pre><code>def start_instance(self, instance_id):\n    \"\"\"Start instance thread\"\"\"\n    print(\"Starting Istance\")\n\n    self.stop_events[instance_id] = threading.Event()\n    self.threads[instance_id] = threading.Thread(\n        target=self.run_instance,\n        args=(instance_id,),\n        daemon=True\n    )\n    self.threads[instance_id].start()\n    print(\"Running starter\", self.runner())\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.server.AppManager.stop_all_instances","title":"<code>stop_all_instances()</code>","text":"<p>Stop all running instances gracefully.</p> Source code in <code>toolboxv2/mods/WhatsAppTb/server.py</code> <pre><code>def stop_all_instances(self):\n    \"\"\"Stop all running instances gracefully.\"\"\"\n    for instance_id in self.stop_events:\n        self.stop_events[instance_id].set()\n\n    for thread in self.threads.values():\n        thread.join(timeout=5)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.server.AppManager.stop_instance","title":"<code>stop_instance(instance_id)</code>","text":"<p>Graceful stop of instance</p> Source code in <code>toolboxv2/mods/WhatsAppTb/server.py</code> <pre><code>def stop_instance(self, instance_id):\n    \"\"\"Graceful stop of instance\"\"\"\n    if instance_id in self.threads:\n        self.stop_events[instance_id].set()\n        self.threads[instance_id].join(timeout=5)\n        del self.threads[instance_id]\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.server.AppManager.update_instance_config","title":"<code>update_instance_config(instance_id, new_key, new_number)</code>","text":"<p>Update existing instance configuration</p> Source code in <code>toolboxv2/mods/WhatsAppTb/server.py</code> <pre><code>def update_instance_config(self, instance_id, new_key, new_number):\n    \"\"\"Update existing instance configuration\"\"\"\n    if instance_id in self.instances:\n        self.instances[instance_id]['phone_number_id'] = {\n            'key': new_key,\n            'number': new_number\n        }\n        self.restart_instance(instance_id)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.utils","title":"<code>utils</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.utils.ProgressMessenger","title":"<code>ProgressMessenger</code>","text":"Source code in <code>toolboxv2/mods/WhatsAppTb/utils.py</code> <pre><code>class ProgressMessenger:\n    def __init__(self, messenger, recipient_phone: str, max_steps: int = 5, emoji_set: list[str] = None, content=None):\n        self.messenger = messenger\n        self.recipient_phone = recipient_phone\n        self.max_steps = max_steps\n        self.emoji_set = emoji_set or [\"\u2b1c\", \"\u2b1b\", \"\ud83d\udfe9\", \"\ud83d\udfe8\", \"\ud83d\udfe6\"]\n        self.message_id = None\n        self.content = content\n\n    def send_initial_message(self, mode: str = \"progress\"):\n        \"\"\"\n        Sends the initial message. Modes can be 'progress' or 'loading'.\n        \"\"\"\n        if mode == \"progress\":\n            emoji_legend = \"\\n\".join(\n                f\"{emoji} - Step {i + 1}\" for i, emoji in enumerate(self.emoji_set)\n            )\n            content = (\n                \"Progress is being updated in real-time!\\n\\n\"\n                \"Legend:\\n\"\n                f\"{emoji_legend}\\n\\n\"\n                \"Stay tuned for updates!\"\n            )\n        elif mode == \"loading\":\n            content = (\n                \"Loading in progress! \ud83c\udf00\\n\"\n                \"The indicator will loop until work is done.\"\n            )\n        else:\n            raise ValueError(\"Invalid mode. Use 'progress' or 'loading'.\")\n\n        if self.content is not None:\n            content += '\\n'+self.content\n        message = self.messenger.create_message(content=content, to=self.recipient_phone)\n        response = message.send(sender=0)\n        self.message_id = response.get(\"messages\", [{}])[0].get(\"id\")\n        logging.info(f\"Initial message sent: {content}\")\n        return self.message_id\n\n    def update_progress(self, step_flag: threading.Event):\n        \"\"\"\n        Updates the reaction on the message to represent progress.\n        \"\"\"\n        if not self.message_id:\n            raise ValueError(\"Message ID not found. Ensure the initial message is sent first.\")\n        message = self.messenger.create_message(id=self.message_id, to=self.recipient_phone)\n        for step in range(self.max_steps):\n            emoji = self.emoji_set[step % len(self.emoji_set)]\n            message.react(emoji)\n            logging.info(f\"Progress updated: Step {step + 1}/{self.max_steps} with emoji {emoji}\")\n            while not step_flag.is_set():\n                time.sleep(0.5)\n            step_flag.clear()\n        # Final acknowledgment\n        message.react(\"\ud83d\udc4d\")\n        logging.info(\"Progress completed with final acknowledgment.\")\n\n    def update_loading(self, stop_flag: threading.Event):\n        \"\"\"\n        Continuously updates the reaction to represent a looping 'loading' indicator.\n        \"\"\"\n        if not self.message_id:\n            raise ValueError(\"Message ID not found. Ensure the initial message is sent first.\")\n        message = self.messenger.create_message(id=self.message_id, to=self.recipient_phone)\n        step = 0\n        while not stop_flag.is_set():\n            emoji = self.emoji_set[step % len(self.emoji_set)]\n            message.react(emoji)\n            logging.info(f\"Loading update: {emoji}\")\n            time.sleep(1)  # Faster updates for loading\n            step += 1\n        # Final acknowledgment\n        message.react(\"\u2705\")\n        logging.info(\"Loading completed with final acknowledgment.\")\n        message.reply(\"\u2705Done\u2705\")\n\n    def start_progress_in_background(self, step_flag):\n        \"\"\"\n        Starts the progress update in a separate thread.\n        \"\"\"\n        threading.Thread(target=self.update_progress, args=(step_flag, ), daemon=True).start()\n\n    def start_loading_in_background(self, stop_flag: threading.Event):\n        \"\"\"\n        Starts the loading update in a separate thread.\n        \"\"\"\n        threading.Thread(target=self.update_loading, args=(stop_flag,), daemon=True).start()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.utils.ProgressMessenger.send_initial_message","title":"<code>send_initial_message(mode='progress')</code>","text":"<p>Sends the initial message. Modes can be 'progress' or 'loading'.</p> Source code in <code>toolboxv2/mods/WhatsAppTb/utils.py</code> <pre><code>def send_initial_message(self, mode: str = \"progress\"):\n    \"\"\"\n    Sends the initial message. Modes can be 'progress' or 'loading'.\n    \"\"\"\n    if mode == \"progress\":\n        emoji_legend = \"\\n\".join(\n            f\"{emoji} - Step {i + 1}\" for i, emoji in enumerate(self.emoji_set)\n        )\n        content = (\n            \"Progress is being updated in real-time!\\n\\n\"\n            \"Legend:\\n\"\n            f\"{emoji_legend}\\n\\n\"\n            \"Stay tuned for updates!\"\n        )\n    elif mode == \"loading\":\n        content = (\n            \"Loading in progress! \ud83c\udf00\\n\"\n            \"The indicator will loop until work is done.\"\n        )\n    else:\n        raise ValueError(\"Invalid mode. Use 'progress' or 'loading'.\")\n\n    if self.content is not None:\n        content += '\\n'+self.content\n    message = self.messenger.create_message(content=content, to=self.recipient_phone)\n    response = message.send(sender=0)\n    self.message_id = response.get(\"messages\", [{}])[0].get(\"id\")\n    logging.info(f\"Initial message sent: {content}\")\n    return self.message_id\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.utils.ProgressMessenger.start_loading_in_background","title":"<code>start_loading_in_background(stop_flag)</code>","text":"<p>Starts the loading update in a separate thread.</p> Source code in <code>toolboxv2/mods/WhatsAppTb/utils.py</code> <pre><code>def start_loading_in_background(self, stop_flag: threading.Event):\n    \"\"\"\n    Starts the loading update in a separate thread.\n    \"\"\"\n    threading.Thread(target=self.update_loading, args=(stop_flag,), daemon=True).start()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.utils.ProgressMessenger.start_progress_in_background","title":"<code>start_progress_in_background(step_flag)</code>","text":"<p>Starts the progress update in a separate thread.</p> Source code in <code>toolboxv2/mods/WhatsAppTb/utils.py</code> <pre><code>def start_progress_in_background(self, step_flag):\n    \"\"\"\n    Starts the progress update in a separate thread.\n    \"\"\"\n    threading.Thread(target=self.update_progress, args=(step_flag, ), daemon=True).start()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.utils.ProgressMessenger.update_loading","title":"<code>update_loading(stop_flag)</code>","text":"<p>Continuously updates the reaction to represent a looping 'loading' indicator.</p> Source code in <code>toolboxv2/mods/WhatsAppTb/utils.py</code> <pre><code>def update_loading(self, stop_flag: threading.Event):\n    \"\"\"\n    Continuously updates the reaction to represent a looping 'loading' indicator.\n    \"\"\"\n    if not self.message_id:\n        raise ValueError(\"Message ID not found. Ensure the initial message is sent first.\")\n    message = self.messenger.create_message(id=self.message_id, to=self.recipient_phone)\n    step = 0\n    while not stop_flag.is_set():\n        emoji = self.emoji_set[step % len(self.emoji_set)]\n        message.react(emoji)\n        logging.info(f\"Loading update: {emoji}\")\n        time.sleep(1)  # Faster updates for loading\n        step += 1\n    # Final acknowledgment\n    message.react(\"\u2705\")\n    logging.info(\"Loading completed with final acknowledgment.\")\n    message.reply(\"\u2705Done\u2705\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.WhatsAppTb.utils.ProgressMessenger.update_progress","title":"<code>update_progress(step_flag)</code>","text":"<p>Updates the reaction on the message to represent progress.</p> Source code in <code>toolboxv2/mods/WhatsAppTb/utils.py</code> <pre><code>def update_progress(self, step_flag: threading.Event):\n    \"\"\"\n    Updates the reaction on the message to represent progress.\n    \"\"\"\n    if not self.message_id:\n        raise ValueError(\"Message ID not found. Ensure the initial message is sent first.\")\n    message = self.messenger.create_message(id=self.message_id, to=self.recipient_phone)\n    for step in range(self.max_steps):\n        emoji = self.emoji_set[step % len(self.emoji_set)]\n        message.react(emoji)\n        logging.info(f\"Progress updated: Step {step + 1}/{self.max_steps} with emoji {emoji}\")\n        while not step_flag.is_set():\n            time.sleep(0.5)\n        step_flag.clear()\n    # Final acknowledgment\n    message.react(\"\ud83d\udc4d\")\n    logging.info(\"Progress completed with final acknowledgment.\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.cli_functions","title":"<code>cli_functions</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.cli_functions.replace_bracketed_content","title":"<code>replace_bracketed_content(text, replacements, inlist=False)</code>","text":"<p>Ersetzt Inhalte in eckigen Klammern mit entsprechenden Werten aus einem W\u00f6rterbuch.</p> <p>:param text: Der zu verarbeitende Text als String. :param replacements: Ein W\u00f6rterbuch mit Schl\u00fcssel-Wert-Paaren f\u00fcr die Ersetzung. :return: Den modifizierten Text.</p> Source code in <code>toolboxv2/mods/cli_functions.py</code> <pre><code>def replace_bracketed_content(text, replacements, inlist=False):\n    \"\"\"\n    Ersetzt Inhalte in eckigen Klammern mit entsprechenden Werten aus einem W\u00f6rterbuch.\n\n    :param text: Der zu verarbeitende Text als String.\n    :param replacements: Ein W\u00f6rterbuch mit Schl\u00fcssel-Wert-Paaren f\u00fcr die Ersetzung.\n    :return: Den modifizierten Text.\n    \"\"\"\n    # Finde alle Vorkommen von Texten in eckigen Klammern\n    matches = re.findall(r'\\[([^\\]]+)\\]', text)\n\n    # Ersetze jeden gefundenen Text durch den entsprechenden Wert aus dem W\u00f6rterbuch\n    as_list = text.split(' ')\n    i = 0\n    for key in matches:\n        if key in replacements:\n            if not inlist:\n                text = text.replace(f'[{key}]', str(replacements[key]))\n            else:\n                as_list[i] = replacements[key]\n        i += 1\n    if not inlist:\n        return text\n    return as_list\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.helper","title":"<code>helper</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.helper.create_invitation","title":"<code>create_invitation(app, username)</code>","text":"<p>Creates a one-time invitation code for a user to link a new device.</p> Source code in <code>toolboxv2/mods/helper.py</code> <pre><code>@export(mod_name=Name, name=\"create-invitation\", test=False)\ndef create_invitation(app: App, username: str):\n    \"\"\"Creates a one-time invitation code for a user to link a new device.\"\"\"\n    print(f\"Creating invitation for user '{username}'...\")\n    app.load_mod(\"CloudM\")\n    result = app.run_any(TBEF.CLOUDM_AUTHMANAGER.GET_INVITATION,\n                         get_results=True,\n                         username=username)\n\n    if result.is_ok():\n        print(f\"\u2705 Invitation code for '{username}': {result.get()}\")\n    else:\n        print(\"\u274c Error creating invitation:\")\n        result.print()\n    return result\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.helper.create_user","title":"<code>create_user(app, username, email)</code>","text":"<p>Creates a new user with a generated key pair.</p> Source code in <code>toolboxv2/mods/helper.py</code> <pre><code>@export(mod_name=Name, name=\"create-user\", test=False)\ndef create_user(app: App, username: str, email: str):\n    \"\"\"Creates a new user with a generated key pair.\"\"\"\n    print(f\"Creating user '{username}' with email '{email}'...\")\n    app.load_mod(\"CloudM\")\n    # Generate an invitation on the fly\n    invitation_res = app.run_any(TBEF.CLOUDM_AUTHMANAGER.GET_INVITATION,\n                                 get_results=True,\n                                 username=username)\n    if invitation_res.is_error():\n        print(\"\u274c Error creating invitation:\")\n        invitation_res.print()\n        return invitation_res\n\n    result = app.run_any(TBEF.CLOUDM_AUTHMANAGER.CRATE_LOCAL_ACCOUNT,\n                         get_results=True,\n                         username=username,\n                         email=email,\n                         invitation=invitation_res.get(),\n                         create=True)\n\n    if result.is_ok():\n        print(f\"\u2705 User '{username}' created successfully.\")\n    else:\n        print(\"\u274c Error creating user:\")\n        result.print()\n    return result\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.helper.delete_user_cli","title":"<code>delete_user_cli(app, username)</code>","text":"<p>Deletes a user and all their associated data.</p> Source code in <code>toolboxv2/mods/helper.py</code> <pre><code>@export(mod_name=Name, name=\"delete-user\", test=False)\ndef delete_user_cli(app: App, username: str):\n    \"\"\"Deletes a user and all their associated data.\"\"\"\n    print(f\"Attempting to delete user '{username}'...\")\n    app.load_mod(\"CloudM\")\n    result = app.run_any(TBEF.CLOUDM_AUTHMANAGER.DELETE_USER, get_results=True, username=username)\n\n    if result.is_ok():\n        print(f\"\u2705 User '{username}' has been deleted.\")\n    else:\n        print(f\"\u274c Error deleting user: {result.info.get('help_text')}\")\n    return result\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.helper.init_system","title":"<code>init_system(app)</code>  <code>async</code>","text":"<p>Initializes the ToolBoxV2 system by creating the first administrative user. This is an interactive command.</p> Source code in <code>toolboxv2/mods/helper.py</code> <pre><code>@export(mod_name=Name, name=\"init_system\", test=False)\nasync def init_system(app: App):\n    \"\"\"\n    Initializes the ToolBoxV2 system by creating the first administrative user.\n    This is an interactive command.\n    \"\"\"\n    print(\"--- ToolBoxV2 System Initialization ---\")\n    print(\"This will guide you through creating the first administrator account.\")\n    print(\"This account will have the highest permission level.\\n\")\n\n    try:\n        username = input(\"Enter the administrator's username: \").strip()\n        if not username:\n            print(\"Username cannot be empty.\")\n            return Result.default_user_error(\"Username cannot be empty.\")\n\n        email = input(f\"Enter the email for '{username}': \").strip()\n        if not email: # A simple check, can be improved with regex\n            print(\"Email cannot be empty.\")\n            return Result.default_user_error(\"Email cannot be empty.\")\n\n        print(f\"\\nCreating user '{username}' with email '{email}'...\")\n        # Call the internal function to create the account\n        # The 'create=True' flag likely handles the initial key generation\n        result = await app.a_run_any(TBEF.CLOUDM.REGISTER_INITIAL_LOOT_USER,\n                                     user_name=username,\n                                     email=email,\n                                     get_results=True)\n\n        if result.is_ok():\n            print(\"\\n\u2705 Administrator account created successfully!\")\n            print(\"   A new cryptographic key pair has been generated for this user.\")\n            print(\"   Authentication is handled automatically using these keys.\")\n            print(\"   You can now use other CLI commands or log into the web UI.\")\n            return Result.ok(\"System initialized successfully.\")\n        else:\n            print(\"\\n\u274c Error creating administrator account:\")\n            result.print()\n            return result\n\n    except (KeyboardInterrupt, EOFError):\n        print(\"\\n\\nInitialization cancelled by user.\")\n        return Result.default_user_error(\"Initialization cancelled.\")\n    except Exception as e:\n        print(f\"\\nAn unexpected error occurred: {e}\")\n        return Result.default_internal_error(f\"An unexpected error occurred: {e}\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.helper.list_users_cli","title":"<code>list_users_cli(app)</code>","text":"<p>Lists all registered users.</p> Source code in <code>toolboxv2/mods/helper.py</code> <pre><code>@export(mod_name=Name, name=\"list-users\", test=False)\ndef list_users_cli(app: App):\n    \"\"\"Lists all registered users.\"\"\"\n    print(\"Fetching user list...\")\n    app.load_mod(\"CloudM\")\n    result = app.run_any(TBEF.CLOUDM_AUTHMANAGER.LIST_USERS, get_results=True)\n\n    if result.is_ok():\n        users = result.get()\n        if not users:\n            print(\"No users found.\")\n            return result\n\n        print(\"--- Registered Users ---\")\n        # Simple table formatting\n        print(f\"{'Username':&lt;25} {'Email':&lt;30} {'Level'}\")\n        print(\"------------------------\")\n        for user in users:\n            print(f\"{user['username']:&lt;25} {user['email']:&lt;30} {user['level']}\")\n        print(\"------------------------\")\n    else:\n        print(\"\u274c Error listing users:\")\n        result.print()\n\n    return result\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.helper.send_magic_link","title":"<code>send_magic_link(app, username)</code>","text":"<p>Sends a magic login link to the user's registered email address.</p> Source code in <code>toolboxv2/mods/helper.py</code> <pre><code>@export(mod_name=Name, name=\"send-magic-link\", test=False)\ndef send_magic_link(app: App, username: str):\n    \"\"\"Sends a magic login link to the user's registered email address.\"\"\"\n    print(f\"Sending magic link to user '{username}'...\")\n    app.load_mod(\"CloudM\")\n    result = app.run_any(TBEF.CLOUDM_AUTHMANAGER.GET_MAGIC_LINK_EMAIL,\n                         get_results=True,\n                         username=username)\n\n    if result.is_ok():\n        print(f\"\u2705 Magic link sent successfully to the email address associated with '{username}'.\")\n    else:\n        print(\"\u274c Error sending magic link:\")\n        result.print()\n    return result\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa","title":"<code>isaa</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.isaa.CodingAgent","title":"<code>CodingAgent</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.isaa.CodingAgent.live","title":"<code>live</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.isaa.CodingAgent.live.AsyncCodeDetector","title":"<code>AsyncCodeDetector</code>","text":"<p>               Bases: <code>NodeVisitor</code></p> <p>Detect async code and top-level await</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>class AsyncCodeDetector(ast.NodeVisitor):\n    \"\"\"Detect async code and top-level await\"\"\"\n    def __init__(self):\n        self.has_async = False\n        self.has_top_level_await = False\n        self.await_nodes = []\n\n    def visit_AsyncFunctionDef(self, node):\n        self.has_async = True\n        self.generic_visit(node)\n\n    def visit_Await(self, node):\n        self.has_async = True\n        # Track all await nodes\n        self.await_nodes.append(node)\n        # Check if this await is at top level\n        parent = node\n        while hasattr(parent, 'parent'):\n            parent = parent.parent\n            if isinstance(parent, ast.AsyncFunctionDef | ast.FunctionDef):\n                break\n        else:\n            self.has_top_level_await = True\n        self.generic_visit(node)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.CodingAgent.live.CargoRustInterface","title":"<code>CargoRustInterface</code>","text":"<p>Usage :</p>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.CodingAgent.live.CargoRustInterface--create-interface","title":"Create interface","text":"<p>cargo_interface = CargoRustInterface()</p>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.CodingAgent.live.CargoRustInterface--set-up-new-project","title":"Set up new project","text":"<p>await cargo_interface.setup_project(\"hello_rust\")</p>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.CodingAgent.live.CargoRustInterface--add-a-dependency","title":"Add a dependency","text":"<p>await cargo_interface.add_dependency(\"serde\", \"1.0\")</p>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.CodingAgent.live.CargoRustInterface--write-and-run-some-code","title":"Write and run some code","text":"<p>code = \"\"\" fn main() {     println!(\"Hello, Rust!\"); } \"\"\" result = await cargo_interface.run_code(code)</p>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.CodingAgent.live.CargoRustInterface--modify-code","title":"Modify code","text":"<p>new_function = \"\"\" fn main() {     println!(\"Modified Hello, Rust!\"); } \"\"\" await cargo_interface.modify_code(new_function, \"main()\")</p>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.CodingAgent.live.CargoRustInterface--build-and-test","title":"Build and test","text":"<p>await cargo_interface.build() await cargo_interface.test()</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>class CargoRustInterface:\n    '''Usage :\n# Create interface\ncargo_interface = CargoRustInterface()\n\n# Set up new project\nawait cargo_interface.setup_project(\"hello_rust\")\n\n# Add a dependency\nawait cargo_interface.add_dependency(\"serde\", \"1.0\")\n\n# Write and run some code\ncode = \"\"\"\nfn main() {\n    println!(\"Hello, Rust!\");\n}\n\"\"\"\nresult = await cargo_interface.run_code(code)\n\n# Modify code\nnew_function = \"\"\"\nfn main() {\n    println!(\"Modified Hello, Rust!\");\n}\n\"\"\"\nawait cargo_interface.modify_code(new_function, \"main()\")\n\n# Build and test\nawait cargo_interface.build()\nawait cargo_interface.test()\n\n    '''\n    def __init__(self, session_dir=None, auto_remove=True):\n        \"\"\"Initialize the Rust/Cargo interface\"\"\"\n        self.auto_remove = auto_remove\n        self._session_dir = session_dir or Path.home() / '.cargo_sessions'\n        self._session_dir.mkdir(exist_ok=True)\n        self.vfs = VirtualFileSystem(self._session_dir / 'virtual_fs')\n        self.output_history = {}\n        self._execution_count = 0\n        self.current_project = None\n\n    def reset(self):\n        \"\"\"Reset the interface state\"\"\"\n        if self.auto_remove and self.current_project:\n            shutil.rmtree(self.current_project, ignore_errors=True)\n        self.output_history.clear()\n        self._execution_count = 0\n        self.current_project = None\n\n    async def setup_project(self, name: str) -&gt; str:\n        \"\"\"Set up a new Cargo project\"\"\"\n        try:\n            project_path = self.vfs.base_dir / name\n            if project_path.exists():\n                shutil.rmtree(project_path)\n\n            result = subprocess.run(\n                ['cargo', 'new', str(project_path)],\n                capture_output=True,\n                text=True, check=True\n            )\n\n            if result.returncode != 0:\n                return f\"Error creating project: {result.stderr}\"\n\n            self.current_project = project_path\n            return f\"Created new project at {project_path}\"\n\n        except Exception as e:\n            return f\"Failed to create project: {str(e)}\"\n\n    async def add_dependency(self, name: str, version: str | None = None) -&gt; str:\n        \"\"\"Add a dependency to Cargo.toml\"\"\"\n        if not self.current_project:\n            return \"No active project\"\n\n        try:\n            cargo_toml = self.current_project / \"Cargo.toml\"\n            if not cargo_toml.exists():\n                return \"Cargo.toml not found\"\n\n            cmd = ['cargo', 'add', name]\n            if version:\n                cmd.extend(['--vers', version])\n\n            result = subprocess.run(\n                cmd,\n                cwd=self.current_project,\n                capture_output=True,\n                text=True,check=True\n            )\n\n            return result.stdout if result.returncode == 0 else f\"Error: {result.stderr}\"\n\n        except Exception as e:\n            return f\"Failed to add dependency: {str(e)}\"\n\n    async def build(self, release: bool = False) -&gt; str:\n        \"\"\"Build the project\"\"\"\n        if not self.current_project:\n            return \"No active project\"\n\n        try:\n            cmd = ['cargo', 'build']\n            if release:\n                cmd.append('--release')\n\n            result = subprocess.run(\n                cmd,\n                cwd=self.current_project,\n                capture_output=True,\n                text=True\n            )\n\n            return result.stdout if result.returncode == 0 else f\"Build error: {result.stderr}\"\n\n        except Exception as e:\n            return f\"Build failed: {str(e)}\"\n\n    async def test(self) -&gt; str:\n        \"\"\"Run project tests\"\"\"\n        if not self.current_project:\n            return \"No active project\"\n\n        try:\n            result = subprocess.run(\n                ['cargo', 'test'],\n                cwd=self.current_project,\n                capture_output=True,\n                text=True, check=True\n            )\n\n            return result.stdout if result.returncode == 0 else f\"Test error: {result.stderr}\"\n\n        except Exception as e:\n            return f\"Tests failed: {str(e)}\"\n\n    async def run_code(self, code: str) -&gt; str:\n        \"\"\"Run Rust code\"\"\"\n        if not self.current_project:\n            return \"No active project\"\n\n        try:\n            # Write code to main.rs\n            main_rs = self.current_project / \"src\" / \"main.rs\"\n            with open(main_rs, 'w') as f:\n                f.write(code)\n\n            # Build and run\n            build_result = subprocess.run(\n                ['cargo', 'build'],\n                cwd=self.current_project,\n                capture_output=True,\n                text=True\n            )\n\n            if build_result.returncode != 0:\n                return f\"Compilation error: {build_result.stderr}\"\n\n            run_result = subprocess.run(\n                ['cargo', 'run'],\n                cwd=self.current_project,\n                capture_output=True,\n                text=True\n            )\n\n            self._execution_count += 1\n            output = {\n                'code': code,\n                'stdout': run_result.stdout,\n                'stderr': run_result.stderr,\n                'result': run_result.returncode == 0\n            }\n            self.output_history[self._execution_count] = output\n\n            return run_result.stdout if run_result.returncode == 0 else f\"Runtime error: {run_result.stderr}\"\n\n        except Exception as e:\n            return f\"Execution failed: {str(e)}\"\n\n    async def modify_code(self, code: str, object_name: str, file: str = \"src/main.rs\") -&gt; str:\n        \"\"\"Modify existing Rust code\"\"\"\n        if not self.current_project:\n            return \"No active project\"\n\n        try:\n            file_path = self.current_project / file\n            if not file_path.exists():\n                return f\"File {file} not found\"\n\n            with open(file_path) as f:\n                content = f.read()\n\n            # Handle function modification\n            if object_name.endswith(\"()\"):\n                func_name = object_name[:-2]\n                # Find and replace function definition\n                pattern = f\"fn {func_name}.*?}}(?=\\n|$)\"\n                updated_content = re.sub(pattern, code.strip(), content, flags=re.DOTALL)\n            else:\n                # Handle other modifications (structs, constants, etc.)\n                pattern = f\"{object_name}.*?(?=\\n|$)\"\n                updated_content = re.sub(pattern, code.strip(), content)\n\n            with open(file_path, 'w') as f:\n                f.write(updated_content)\n\n            return f\"Modified {object_name} in {file}\"\n\n        except Exception as e:\n            return f\"Modification failed: {str(e)}\"\n\n    def save_session(self, name: str):\n        \"\"\"Save current session state\"\"\"\n        session_file = self._session_dir / f\"{name}.json\"\n        state = {\n            'output_history': self.output_history,\n            'current_project': str(self.current_project) if self.current_project else None\n        }\n\n        with open(session_file, 'w') as f:\n            json.dump(state, f)\n\n    def load_session(self, name: str):\n        \"\"\"Load saved session state\"\"\"\n        session_file = self._session_dir / f\"{name}.json\"\n        if session_file.exists():\n            with open(session_file) as f:\n                state = json.load(f)\n                self.output_history = state['output_history']\n                self.current_project = Path(state['current_project']) if state['current_project'] else None\n</code></pre> <code>__init__(session_dir=None, auto_remove=True)</code> \u00b6 <p>Initialize the Rust/Cargo interface</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>def __init__(self, session_dir=None, auto_remove=True):\n    \"\"\"Initialize the Rust/Cargo interface\"\"\"\n    self.auto_remove = auto_remove\n    self._session_dir = session_dir or Path.home() / '.cargo_sessions'\n    self._session_dir.mkdir(exist_ok=True)\n    self.vfs = VirtualFileSystem(self._session_dir / 'virtual_fs')\n    self.output_history = {}\n    self._execution_count = 0\n    self.current_project = None\n</code></pre> <code>add_dependency(name, version=None)</code> <code>async</code> \u00b6 <p>Add a dependency to Cargo.toml</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>async def add_dependency(self, name: str, version: str | None = None) -&gt; str:\n    \"\"\"Add a dependency to Cargo.toml\"\"\"\n    if not self.current_project:\n        return \"No active project\"\n\n    try:\n        cargo_toml = self.current_project / \"Cargo.toml\"\n        if not cargo_toml.exists():\n            return \"Cargo.toml not found\"\n\n        cmd = ['cargo', 'add', name]\n        if version:\n            cmd.extend(['--vers', version])\n\n        result = subprocess.run(\n            cmd,\n            cwd=self.current_project,\n            capture_output=True,\n            text=True,check=True\n        )\n\n        return result.stdout if result.returncode == 0 else f\"Error: {result.stderr}\"\n\n    except Exception as e:\n        return f\"Failed to add dependency: {str(e)}\"\n</code></pre> <code>build(release=False)</code> <code>async</code> \u00b6 <p>Build the project</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>async def build(self, release: bool = False) -&gt; str:\n    \"\"\"Build the project\"\"\"\n    if not self.current_project:\n        return \"No active project\"\n\n    try:\n        cmd = ['cargo', 'build']\n        if release:\n            cmd.append('--release')\n\n        result = subprocess.run(\n            cmd,\n            cwd=self.current_project,\n            capture_output=True,\n            text=True\n        )\n\n        return result.stdout if result.returncode == 0 else f\"Build error: {result.stderr}\"\n\n    except Exception as e:\n        return f\"Build failed: {str(e)}\"\n</code></pre> <code>load_session(name)</code> \u00b6 <p>Load saved session state</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>def load_session(self, name: str):\n    \"\"\"Load saved session state\"\"\"\n    session_file = self._session_dir / f\"{name}.json\"\n    if session_file.exists():\n        with open(session_file) as f:\n            state = json.load(f)\n            self.output_history = state['output_history']\n            self.current_project = Path(state['current_project']) if state['current_project'] else None\n</code></pre> <code>modify_code(code, object_name, file='src/main.rs')</code> <code>async</code> \u00b6 <p>Modify existing Rust code</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>async def modify_code(self, code: str, object_name: str, file: str = \"src/main.rs\") -&gt; str:\n    \"\"\"Modify existing Rust code\"\"\"\n    if not self.current_project:\n        return \"No active project\"\n\n    try:\n        file_path = self.current_project / file\n        if not file_path.exists():\n            return f\"File {file} not found\"\n\n        with open(file_path) as f:\n            content = f.read()\n\n        # Handle function modification\n        if object_name.endswith(\"()\"):\n            func_name = object_name[:-2]\n            # Find and replace function definition\n            pattern = f\"fn {func_name}.*?}}(?=\\n|$)\"\n            updated_content = re.sub(pattern, code.strip(), content, flags=re.DOTALL)\n        else:\n            # Handle other modifications (structs, constants, etc.)\n            pattern = f\"{object_name}.*?(?=\\n|$)\"\n            updated_content = re.sub(pattern, code.strip(), content)\n\n        with open(file_path, 'w') as f:\n            f.write(updated_content)\n\n        return f\"Modified {object_name} in {file}\"\n\n    except Exception as e:\n        return f\"Modification failed: {str(e)}\"\n</code></pre> <code>reset()</code> \u00b6 <p>Reset the interface state</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>def reset(self):\n    \"\"\"Reset the interface state\"\"\"\n    if self.auto_remove and self.current_project:\n        shutil.rmtree(self.current_project, ignore_errors=True)\n    self.output_history.clear()\n    self._execution_count = 0\n    self.current_project = None\n</code></pre> <code>run_code(code)</code> <code>async</code> \u00b6 <p>Run Rust code</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>async def run_code(self, code: str) -&gt; str:\n    \"\"\"Run Rust code\"\"\"\n    if not self.current_project:\n        return \"No active project\"\n\n    try:\n        # Write code to main.rs\n        main_rs = self.current_project / \"src\" / \"main.rs\"\n        with open(main_rs, 'w') as f:\n            f.write(code)\n\n        # Build and run\n        build_result = subprocess.run(\n            ['cargo', 'build'],\n            cwd=self.current_project,\n            capture_output=True,\n            text=True\n        )\n\n        if build_result.returncode != 0:\n            return f\"Compilation error: {build_result.stderr}\"\n\n        run_result = subprocess.run(\n            ['cargo', 'run'],\n            cwd=self.current_project,\n            capture_output=True,\n            text=True\n        )\n\n        self._execution_count += 1\n        output = {\n            'code': code,\n            'stdout': run_result.stdout,\n            'stderr': run_result.stderr,\n            'result': run_result.returncode == 0\n        }\n        self.output_history[self._execution_count] = output\n\n        return run_result.stdout if run_result.returncode == 0 else f\"Runtime error: {run_result.stderr}\"\n\n    except Exception as e:\n        return f\"Execution failed: {str(e)}\"\n</code></pre> <code>save_session(name)</code> \u00b6 <p>Save current session state</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>def save_session(self, name: str):\n    \"\"\"Save current session state\"\"\"\n    session_file = self._session_dir / f\"{name}.json\"\n    state = {\n        'output_history': self.output_history,\n        'current_project': str(self.current_project) if self.current_project else None\n    }\n\n    with open(session_file, 'w') as f:\n        json.dump(state, f)\n</code></pre> <code>setup_project(name)</code> <code>async</code> \u00b6 <p>Set up a new Cargo project</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>async def setup_project(self, name: str) -&gt; str:\n    \"\"\"Set up a new Cargo project\"\"\"\n    try:\n        project_path = self.vfs.base_dir / name\n        if project_path.exists():\n            shutil.rmtree(project_path)\n\n        result = subprocess.run(\n            ['cargo', 'new', str(project_path)],\n            capture_output=True,\n            text=True, check=True\n        )\n\n        if result.returncode != 0:\n            return f\"Error creating project: {result.stderr}\"\n\n        self.current_project = project_path\n        return f\"Created new project at {project_path}\"\n\n    except Exception as e:\n        return f\"Failed to create project: {str(e)}\"\n</code></pre> <code>test()</code> <code>async</code> \u00b6 <p>Run project tests</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>async def test(self) -&gt; str:\n    \"\"\"Run project tests\"\"\"\n    if not self.current_project:\n        return \"No active project\"\n\n    try:\n        result = subprocess.run(\n            ['cargo', 'test'],\n            cwd=self.current_project,\n            capture_output=True,\n            text=True, check=True\n        )\n\n        return result.stdout if result.returncode == 0 else f\"Test error: {result.stderr}\"\n\n    except Exception as e:\n        return f\"Tests failed: {str(e)}\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.CodingAgent.live.MockIPython","title":"<code>MockIPython</code>","text":"Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>class MockIPython:\n    def __init__(self, _session_dir=None, auto_remove=True):\n        self.auto_remove = auto_remove\n        self.output_history = {}\n        self._execution_count = 0\n        self._session_dir = _session_dir or Path(get_app().appdata) / '.pipeline_sessions'\n        self._session_dir.mkdir(exist_ok=True)\n        self.vfs = VirtualFileSystem(self._session_dir / 'virtual_fs')\n        self._venv_path = self._session_dir / 'venv'\n        self.user_ns: dict[str, Any] = {}\n        nest_asyncio.apply()\n        # Set up virtual environment if it doesn't exist\n        with Spinner(\"Starting virtual environment\"):\n            self._setup_venv()\n        self.reset()\n\n    def _setup_venv(self):\n        \"\"\"Create virtual environment if it doesn't exist\"\"\"\n        if not self._venv_path.exists():\n            try:\n                subprocess.run([sys.executable, \"-m\", \"venv\", str(self._venv_path)], check=True)\n            except subprocess.CalledProcessError as e:\n                raise RuntimeError(f\"Failed to create virtual environment: {str(e)}\")\n\n    def _virtual_open(self, filepath, mode='r', *args, **kwargs):\n        \"\"\"Custom open function that uses virtual filesystem\"\"\"\n        abs_path = self.vfs._resolve_path(filepath)\n\n        if 'w' in mode or 'a' in mode:\n            # Ensure parent directory exists\n            abs_path.parent.mkdir(parents=True, exist_ok=True)\n\n        # Use actual filesystem but track in virtual fs\n        real_file = open(abs_path, mode, *args, **kwargs)\n\n        if 'r' in mode:\n            # Track file content in virtual filesystem when reading\n            rel_path = str(abs_path.relative_to(self.vfs.base_dir))\n            if rel_path not in self.vfs.virtual_files:\n                try:\n                    self.vfs.virtual_files[rel_path] = real_file.read()\n                    real_file.seek(0)\n                except UnicodeDecodeError:\n                    # Handle binary files\n                    pass\n\n        return real_file\n\n    def reset(self):\n        \"\"\"Reset the interpreter state\"\"\"\n        self.user_ns = {\n            '__name__': '__main__',\n            '__builtins__': __builtins__,\n            'toolboxv2': toolboxv2,\n            '__file__': None,\n            '__path__': [str(self.vfs.current_dir)],\n            'auto_install': auto_install,\n            'modify_code': self.modify_code,\n        }\n        self.output_history.clear()\n        self._execution_count = 0\n        if self.auto_remove:\n            shutil.rmtree(self.vfs.base_dir, ignore_errors=True)\n\n    def get_namespace(self) -&gt; dict[str, Any]:\n        \"\"\"Get current namespace\"\"\"\n        return self.user_ns.copy()\n\n    def update_namespace(self, variables: dict[str, Any]):\n        \"\"\"Update namespace with new variables\"\"\"\n        self.user_ns.update(variables)\n\n    @staticmethod\n    def _parse_code(code: str) -&gt; tuple[Any, Any | None, bool, bool]:\n        \"\"\"Parse code and handle top-level await\"\"\"\n        code_ = \"\"\n        for line in code.split('\\n'):\n            if line.strip().startswith('#'):\n                continue\n            if line.strip().startswith('asyncio.run('):\n                line = (' ' *(len(line) - len(line.strip()))) + 'await ' + line.strip()[len('asyncio.run('):-1]\n            code_ += line + '\\n'\n        try:\n            tree = ast.parse(code)\n            # Add parent references\n            ParentNodeTransformer().visit(tree)\n\n            # Detect async features\n            detector = AsyncCodeDetector()\n            detector.visit(tree)\n\n            if detector.has_top_level_await:\n                # Wrap code in async function\n                wrapped_code = \"async def __wrapper():\\n\"\n                wrapped_code += \"    global result\\n\"  # Allow writing to global scope\n                wrapped_code += \"    result = None\\n\"\n                # add try:\n                wrapped_code +=\"    try:\\n\"\n                # Indent the original code\n                wrapped_code += \"\\n\".join(f\"        {line}\" for line in code.splitlines())\n                # Add return statement for last expression\n                wrapped_code +=\"\\n    except Exception as e:\\n\"\n                wrapped_code +=\"        import traceback\\n\"\n                wrapped_code +=\"        print(traceback.format_exc())\\n\"\n                wrapped_code +=\"        raise e\\n\"\n                if isinstance(tree.body[-1], ast.Expr):\n                    wrapped_code += \"\\n    return result\"\n\n                # Parse and compile wrapped code\n                wrapped_tree = ast.parse(wrapped_code)\n                return (\n                    compile(wrapped_tree, '&lt;exec&gt;', 'exec'),\n                    None,\n                    True,\n                    True\n                )\n\n            # Handle regular code\n            if isinstance(tree.body[-1], ast.Expr):\n                exec_code = ast.Module(\n                    body=tree.body[:-1],\n                    type_ignores=[]\n                )\n                eval_code = ast.Expression(\n                    body=tree.body[-1].value\n                )\n                return (\n                    compile(exec_code, '&lt;exec&gt;', 'exec'),\n                    compile(eval_code, '&lt;eval&gt;', 'eval'),\n                    detector.has_async,\n                    False\n                )\n\n            return (\n                compile(tree, '&lt;exec&gt;', 'exec'),\n                None,\n                detector.has_async,\n                False\n            )\n\n        except SyntaxError as e:\n            lines = code.splitlines()\n            if e.lineno and e.lineno &lt;= len(lines):\n                line = lines[e.lineno - 1]\n                arrow = ' ' * (e.offset - 1) + '^' if e.offset else ''\n                error_msg = (\n                    f\"Syntax error at line {e.lineno}:\\n\"\n                    f\"{line}\\n\"\n                    f\"{arrow}\\n\"\n                    f\"{e.msg}\"\n                )\n            else:\n                error_msg = str(e)\n\n            error_msg += traceback.format_exc()\n\n            raise SyntaxError(error_msg) from e\n\n    async def run_cell(self, code: str, live_output: bool = True) -&gt; Any:\n        \"\"\"Async version of run_cell that handles both sync and async code\"\"\"\n        result = None\n        error = None\n        tb = None\n        original_dir = os.getcwd()\n\n        if live_output:\n            stdout_buffer = io.StringIO()\n            stderr_buffer = io.StringIO()\n            stdout = TeeStream(sys.__stdout__, stdout_buffer)\n            stderr = TeeStream(sys.__stderr__, stderr_buffer)\n        else:\n            stdout = io.StringIO()\n            stderr = io.StringIO()\n\n        try:\n            # Check if a file is already specified\n            original_file = self.user_ns.get('__file__')\n            if original_file is None:\n                # Create temp file if no file specified\n                temp_file = self.vfs.write_file(\n                    f'src/temp/_temp_{self._execution_count}.py',\n                    code\n                )\n                # work_ns = self.user_ns.copy()\n                self.user_ns['__file__'] = str(temp_file)\n            else:\n                # Use existing file\n                temp_file = Path(original_file)\n                # Write code to the existing file\n                self.vfs.write_file(temp_file, code)\n                #work_ns = self.user_ns.copy()\n\n            self.user_ns['__builtins__'] = __builtins__\n            with VirtualEnvContext(self._venv_path) as python_exec:\n                try:\n                    exec_code, eval_code, is_async, has_top_level_await = self._parse_code(\n                        code.encode('utf-8', errors='replace').decode('utf-8')\n                    )\n                    if exec_code is None:\n                        return \"No executable code\"\n                    os.makedirs(str(temp_file.parent.absolute()), exist_ok=True)\n                    os.chdir(str(temp_file.parent.absolute()))\n                    self.user_ns['PYTHON_EXEC'] = python_exec\n\n                    with redirect_stdout(stdout), redirect_stderr(stderr):\n                        if has_top_level_await:\n                            try:\n                                # Execute wrapped code and await it\n                                exec(exec_code, self.user_ns)\n                                result = self.user_ns['__wrapper']()\n                                if asyncio.iscoroutine(result):\n                                    result = await result\n                            finally:\n                                self.user_ns.pop('__wrapper', None)\n                        elif is_async:\n                            # Execute async code\n                            exec(exec_code, self.user_ns)\n                            if eval_code:\n                                result = eval(eval_code, self.user_ns)\n                                if asyncio.iscoroutine(result):\n                                    result = await result\n                        else:\n                            # Execute sync code\n                            exec(exec_code, self.user_ns)\n                            if eval_code:\n                                result = eval(eval_code, self.user_ns)\n\n                        if result is not None:\n                            self.user_ns['_'] = result\n                except KeyboardInterrupt:\n                    print(\"Stop execution manuel!\")\n\n                except Exception as e:\n                    error = str(e)\n                    tb = traceback.format_exc()\n                    if live_output:\n                        sys.__stderr__.write(f\"{error}\\n{tb}\")\n                    stderr.write(f\"{error}\\n{tb}\")\n\n                finally:\n                    os.chdir(original_dir)\n                    self._execution_count += 1\n                    # self.user_ns = work_ns.copy()\n                    if live_output:\n                        stdout_value = stdout_buffer.getvalue()\n                        stderr_value = stderr_buffer.getvalue()\n                    else:\n                        stdout_value = stdout.getvalue()\n                        stderr_value = stderr.getvalue()\n\n                    output = {\n                        'code': code,\n                        'stdout': stdout_value,\n                        'stderr': stderr_value,\n                        'result': result if result else \"stdout\"\n                    }\n                    self.output_history[self._execution_count] = output\n\n        except Exception as e:\n            error_msg = f\"Error executing code: {str(e)}\\n{traceback.format_exc()}\"\n            if live_output:\n                sys.__stderr__.write(error_msg)\n            return error_msg\n\n        if not result:\n            result = \"\"\n        if output['stdout']:\n            result = f\"{result}\\nstdout:{output['stdout']}\"\n        if output['stderr']:\n            result = f\"{result}\\nstderr:{output['stderr']}\"\n\n        if self.auto_remove and original_file is None:\n            # Only remove temp files, not user-specified files\n            self.vfs.delete_file(temp_file)\n\n        return result\n\n    async def modify_code(self, code: str = None, object_name: str = None, file: str = None) -&gt; str:\n        '''\n        Modify existing code in memory (user namespace) and optionally in the corresponding file.\n\n        This method updates variables, functions, or methods in the current Python session and can\n        also update the corresponding source file if specified.\n\n        Args:\n            code: New value or implementation for the object\n            object_name: Name of the object to modify (variable, function, or method)\n            file: Path to the file to update (if None, only updates in memory)\n\n        Returns:\n            String describing the modification result\n\n        Examples:\n\n        # 1. Update a variable in memory\n        await ipython.modify_code(code=\"5\", object_name=\"x\")\n\n    # 2. Change a method implementation\n    await ipython.modify_code(\n        code='\"\"\"def sound(self):\\n        return \"Woof\"\"\"\"',\n        object_name=\"Dog.sound\"\n    )\n\n    # 3. Modify a function\n    await ipython.modify_code(\n        code='\"\"\"def calculate_age():\\n    return 25\"\"\"',\n        object_name=\"calculate_age\"\n    )\n\n    # 4. Update variable in memory and file\n    await ipython.modify_code(\n        code=\"100\",\n        object_name=\"MAX_SIZE\",\n        file=\"config.py\"\n    )\n\n    # 5. Modifying an attribute in __init__\n    await ipython.modify_code(\n        code='\"\"\"def __init__(self):\\n        self.name = \"Buddy\"\"\"\"',\n        object_name=\"Dog.__init__\"\n    )\n        '''\n        try:\n            if not object_name:\n                raise ValueError(\"Object name must be specified\")\n            if code is None:\n                raise ValueError(\"New code or value must be provided\")\n\n            # Process object name (handle methods with parentheses)\n            clean_object_name = object_name.replace(\"()\", \"\")\n\n            # Step 1: Update in memory (user namespace)\n            result_message = []\n\n            # Handle different types of objects\n            if \".\" in clean_object_name:\n                # For methods or class attributes\n                parts = clean_object_name.split(\".\")\n                base_obj_name = parts[0]\n                attr_name = parts[1]\n\n                if base_obj_name not in self.user_ns:\n                    raise ValueError(f\"Object '{base_obj_name}' not found in namespace\")\n\n                base_obj = self.user_ns[base_obj_name]\n\n                # Handle method definitions which are passed as docstrings\n                if code.split('\\n'):\n                    method_code = code\n\n                    # Parse the method code to extract its body\n                    method_ast = ast.parse(method_code).body[0]\n                    method_name = method_ast.name\n\n                    # Create a new function object from the code\n                    method_locals = {}\n                    exec(\n                        f\"def _temp_func{signature(getattr(base_obj.__class__, attr_name, None))}: {method_ast.body[0].value.s}\",\n                        globals(), method_locals)\n                    new_method = method_locals['_temp_func']\n\n                    # Set the method on the class\n                    setattr(base_obj.__class__, attr_name, new_method)\n                    result_message.append(f\"Updated method '{clean_object_name}' in memory\")\n                else:\n                    # For simple attributes\n                    setattr(base_obj, attr_name, eval(code, self.user_ns))\n                    result_message.append(f\"Updated attribute '{clean_object_name}' in memory\")\n            else:\n                # For variables and functions\n                if code.startswith('\"\"\"') and code.endswith('\"\"\"'):\n                    # Handle function definitions\n                    func_code = code.strip('\"\"\"')\n                    func_ast = ast.parse(func_code).body[0]\n                    func_name = func_ast.name\n\n                    # Create a new function object from the code\n                    func_locals = {}\n                    exec(f\"{func_code}\", globals(), func_locals)\n                    self.user_ns[clean_object_name] = func_locals[func_name]\n                    result_message.append(f\"Updated function '{clean_object_name}' in memory\")\n                else:\n                    # Simple variable assignment\n                    self.user_ns[clean_object_name] = eval(code, self.user_ns)\n                    result_message.append(f\"Updated variable '{clean_object_name}' in memory\")\n\n            # Step 2: Update in file if specified\n            if file is not None:\n                file_path = self.vfs._resolve_path(file)\n\n                if not file_path.exists():\n                    self.user_ns['__file__'] = str(file_path)\n                    return await self.run_cell(code)\n\n                # Read original content\n                original_content = self.vfs.read_file(file_path)\n                updated_content = original_content\n\n                # Handle different object types for file updates\n                if \".\" in clean_object_name:\n                    # For methods\n                    parts = clean_object_name.split(\".\")\n                    class_name = parts[0]\n                    method_name = parts[1]\n\n                    if code.startswith('\"\"\"') and code.endswith('\"\"\"'):\n                        method_code = code.strip('\"\"\"')\n\n                        # Use ast to parse the file and find the method to replace\n                        file_ast = ast.parse(original_content)\n                        for node in ast.walk(file_ast):\n                            if isinstance(node, ast.ClassDef) and node.name == class_name:\n                                for method in node.body:\n                                    if isinstance(method, ast.FunctionDef) and method.name == method_name:\n                                        # Find the method in the source code\n                                        method_pattern = fr\"def {method_name}.*?:(.*?)(?=\\n    \\w|\\n\\w|\\Z)\"\n                                        method_match = re.search(method_pattern, original_content, re.DOTALL)\n\n                                        if method_match:\n                                            indentation = re.match(r\"^(\\s*)\", method_match.group(0)).group(1)\n                                            method_indented = textwrap.indent(method_code, indentation)\n                                            updated_content = original_content.replace(\n                                                method_match.group(0),\n                                                method_indented\n                                            )\n                                            self.vfs.write_file(file_path, updated_content)\n                                            result_message.append(\n                                                f\"Updated method '{clean_object_name}' in file '{file}'\")\n                else:\n                    # For variables and functions\n                    if code.startswith('\"\"\"') and code.endswith('\"\"\"'):\n                        # Handle function updates\n                        func_code = code.strip('\"\"\"')\n                        func_pattern = fr\"def {clean_object_name}.*?:(.*?)(?=\\n\\w|\\Z)\"\n                        func_match = re.search(func_pattern, original_content, re.DOTALL)\n\n                        if func_match:\n                            indentation = re.match(r\"^(\\s*)\", func_match.group(0)).group(1)\n                            func_indented = textwrap.indent(func_code, indentation)\n                            updated_content = original_content.replace(\n                                func_match.group(0),\n                                func_indented\n                            )\n                            self.vfs.write_file(file_path, updated_content)\n                            result_message.append(f\"Updated function '{clean_object_name}' in file '{file}'\")\n                    else:\n                        # Handle variable updates\n                        var_pattern = fr\"{clean_object_name}\\s*=.*\"\n                        var_replacement = f\"{clean_object_name} = {code}\"\n                        updated_content = re.sub(var_pattern, var_replacement, original_content)\n\n                        if updated_content != original_content:\n                            self.vfs.write_file(file_path, updated_content)\n                            result_message.append(f\"Updated variable '{clean_object_name}' in file '{file}'\")\n                        else:\n                            result_message.append(f\"Could not find variable '{clean_object_name}' in file '{file}'\")\n\n            return \"\\n\".join(result_message)\n\n        except Exception as e:\n            return f\"Error during code modification: {str(e)}\\n{traceback.format_exc()}\"\n\n\n    def save_session(self, name: str):\n        \"\"\"Save session with UTF-8 encoding\"\"\"\n        session_file = self._session_dir / f\"{name}.pkl\"\n        user_ns = self.user_ns.copy()\n        output_history = self.output_history.copy()\n\n        # Ensure all strings are properly encoded\n        for key, value in user_ns.items():\n            try:\n                if isinstance(value, str):\n                    value = value.encode('utf-8').decode('utf-8')\n                pickle.dumps(value)\n            except Exception:\n                user_ns[key] = f\"not serializable: {str(value)}\"\n\n        for key, value in output_history.items():\n            try:\n                if isinstance(value, dict):\n                    for k, v in value.items():\n                        if isinstance(v, str):\n                            value[k] = v.encode('utf-8').decode('utf-8')\n                pickle.dumps(value)\n            except Exception:\n                output_history[key] = f\"not serializable: {str(value)}\"\n\n\n        session_data = {\n            'user_ns': user_ns,\n            'output_history': output_history,\n\n        }\n\n        with open(session_file, 'wb') as f:\n            pickle.dump(session_data, f)\n\n        # Save VFS state with UTF-8 encoding\n        vfs_state_file = self._session_dir / f\"{name}_vfs.json\"\n        with open(vfs_state_file, 'w', encoding='utf-8') as f:\n            json.dump(self.vfs.virtual_files, f, ensure_ascii=False)\n\n    def load_session(self, name: str):\n        \"\"\"Load session with UTF-8 encoding\"\"\"\n        session_file = self._session_dir / f\"{name}.pkl\"\n        if session_file.exists():\n            with open(session_file, 'rb') as f:\n                session_data = pickle.load(f)\n                # self.user_ns.update(session_data['user_ns'])\n                self.output_history.update(session_data['output_history'])\n\n        # Load VFS state with UTF-8 encoding\n        vfs_state_file = self._session_dir / f\"{name}_vfs.json\"\n        if vfs_state_file.exists():\n            with open(vfs_state_file, encoding='utf-8') as f:\n                self.vfs.virtual_files = json.load(f)\n\n    def __str__(self):\n        \"\"\"String representation of current session\"\"\"\n        output = []\n        for count, data in self.output_history.items():\n            output.append(f\"In [{count}]: {data['code']}\")\n            if data['stdout']:\n                output.append(data['stdout'])\n            if data['stderr']:\n                output.append(f\"Error: {data['stderr']}\")\n            if data['result'] is not None:\n                output.append(f\"Out[{count}]: {data['result']}\")\n        return \"\\n\".join(output)\n</code></pre> <code>__str__()</code> \u00b6 <p>String representation of current session</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>def __str__(self):\n    \"\"\"String representation of current session\"\"\"\n    output = []\n    for count, data in self.output_history.items():\n        output.append(f\"In [{count}]: {data['code']}\")\n        if data['stdout']:\n            output.append(data['stdout'])\n        if data['stderr']:\n            output.append(f\"Error: {data['stderr']}\")\n        if data['result'] is not None:\n            output.append(f\"Out[{count}]: {data['result']}\")\n    return \"\\n\".join(output)\n</code></pre> <code>get_namespace()</code> \u00b6 <p>Get current namespace</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>def get_namespace(self) -&gt; dict[str, Any]:\n    \"\"\"Get current namespace\"\"\"\n    return self.user_ns.copy()\n</code></pre> <code>load_session(name)</code> \u00b6 <p>Load session with UTF-8 encoding</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>def load_session(self, name: str):\n    \"\"\"Load session with UTF-8 encoding\"\"\"\n    session_file = self._session_dir / f\"{name}.pkl\"\n    if session_file.exists():\n        with open(session_file, 'rb') as f:\n            session_data = pickle.load(f)\n            # self.user_ns.update(session_data['user_ns'])\n            self.output_history.update(session_data['output_history'])\n\n    # Load VFS state with UTF-8 encoding\n    vfs_state_file = self._session_dir / f\"{name}_vfs.json\"\n    if vfs_state_file.exists():\n        with open(vfs_state_file, encoding='utf-8') as f:\n            self.vfs.virtual_files = json.load(f)\n</code></pre> <code>modify_code(code=None, object_name=None, file=None)</code> <code>async</code> \u00b6 <pre><code>Modify existing code in memory (user namespace) and optionally in the corresponding file.\n\nThis method updates variables, functions, or methods in the current Python session and can\nalso update the corresponding source file if specified.\n\nArgs:\n    code: New value or implementation for the object\n    object_name: Name of the object to modify (variable, function, or method)\n    file: Path to the file to update (if None, only updates in memory)\n\nReturns:\n    String describing the modification result\n\nExamples:\n\n# 1. Update a variable in memory\nawait ipython.modify_code(code=\"5\", object_name=\"x\")\n</code></pre> <code>reset()</code> \u00b6 <p>Reset the interpreter state</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>def reset(self):\n    \"\"\"Reset the interpreter state\"\"\"\n    self.user_ns = {\n        '__name__': '__main__',\n        '__builtins__': __builtins__,\n        'toolboxv2': toolboxv2,\n        '__file__': None,\n        '__path__': [str(self.vfs.current_dir)],\n        'auto_install': auto_install,\n        'modify_code': self.modify_code,\n    }\n    self.output_history.clear()\n    self._execution_count = 0\n    if self.auto_remove:\n        shutil.rmtree(self.vfs.base_dir, ignore_errors=True)\n</code></pre> <code>run_cell(code, live_output=True)</code> <code>async</code> \u00b6 <p>Async version of run_cell that handles both sync and async code</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>async def run_cell(self, code: str, live_output: bool = True) -&gt; Any:\n    \"\"\"Async version of run_cell that handles both sync and async code\"\"\"\n    result = None\n    error = None\n    tb = None\n    original_dir = os.getcwd()\n\n    if live_output:\n        stdout_buffer = io.StringIO()\n        stderr_buffer = io.StringIO()\n        stdout = TeeStream(sys.__stdout__, stdout_buffer)\n        stderr = TeeStream(sys.__stderr__, stderr_buffer)\n    else:\n        stdout = io.StringIO()\n        stderr = io.StringIO()\n\n    try:\n        # Check if a file is already specified\n        original_file = self.user_ns.get('__file__')\n        if original_file is None:\n            # Create temp file if no file specified\n            temp_file = self.vfs.write_file(\n                f'src/temp/_temp_{self._execution_count}.py',\n                code\n            )\n            # work_ns = self.user_ns.copy()\n            self.user_ns['__file__'] = str(temp_file)\n        else:\n            # Use existing file\n            temp_file = Path(original_file)\n            # Write code to the existing file\n            self.vfs.write_file(temp_file, code)\n            #work_ns = self.user_ns.copy()\n\n        self.user_ns['__builtins__'] = __builtins__\n        with VirtualEnvContext(self._venv_path) as python_exec:\n            try:\n                exec_code, eval_code, is_async, has_top_level_await = self._parse_code(\n                    code.encode('utf-8', errors='replace').decode('utf-8')\n                )\n                if exec_code is None:\n                    return \"No executable code\"\n                os.makedirs(str(temp_file.parent.absolute()), exist_ok=True)\n                os.chdir(str(temp_file.parent.absolute()))\n                self.user_ns['PYTHON_EXEC'] = python_exec\n\n                with redirect_stdout(stdout), redirect_stderr(stderr):\n                    if has_top_level_await:\n                        try:\n                            # Execute wrapped code and await it\n                            exec(exec_code, self.user_ns)\n                            result = self.user_ns['__wrapper']()\n                            if asyncio.iscoroutine(result):\n                                result = await result\n                        finally:\n                            self.user_ns.pop('__wrapper', None)\n                    elif is_async:\n                        # Execute async code\n                        exec(exec_code, self.user_ns)\n                        if eval_code:\n                            result = eval(eval_code, self.user_ns)\n                            if asyncio.iscoroutine(result):\n                                result = await result\n                    else:\n                        # Execute sync code\n                        exec(exec_code, self.user_ns)\n                        if eval_code:\n                            result = eval(eval_code, self.user_ns)\n\n                    if result is not None:\n                        self.user_ns['_'] = result\n            except KeyboardInterrupt:\n                print(\"Stop execution manuel!\")\n\n            except Exception as e:\n                error = str(e)\n                tb = traceback.format_exc()\n                if live_output:\n                    sys.__stderr__.write(f\"{error}\\n{tb}\")\n                stderr.write(f\"{error}\\n{tb}\")\n\n            finally:\n                os.chdir(original_dir)\n                self._execution_count += 1\n                # self.user_ns = work_ns.copy()\n                if live_output:\n                    stdout_value = stdout_buffer.getvalue()\n                    stderr_value = stderr_buffer.getvalue()\n                else:\n                    stdout_value = stdout.getvalue()\n                    stderr_value = stderr.getvalue()\n\n                output = {\n                    'code': code,\n                    'stdout': stdout_value,\n                    'stderr': stderr_value,\n                    'result': result if result else \"stdout\"\n                }\n                self.output_history[self._execution_count] = output\n\n    except Exception as e:\n        error_msg = f\"Error executing code: {str(e)}\\n{traceback.format_exc()}\"\n        if live_output:\n            sys.__stderr__.write(error_msg)\n        return error_msg\n\n    if not result:\n        result = \"\"\n    if output['stdout']:\n        result = f\"{result}\\nstdout:{output['stdout']}\"\n    if output['stderr']:\n        result = f\"{result}\\nstderr:{output['stderr']}\"\n\n    if self.auto_remove and original_file is None:\n        # Only remove temp files, not user-specified files\n        self.vfs.delete_file(temp_file)\n\n    return result\n</code></pre> <code>save_session(name)</code> \u00b6 <p>Save session with UTF-8 encoding</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>def save_session(self, name: str):\n    \"\"\"Save session with UTF-8 encoding\"\"\"\n    session_file = self._session_dir / f\"{name}.pkl\"\n    user_ns = self.user_ns.copy()\n    output_history = self.output_history.copy()\n\n    # Ensure all strings are properly encoded\n    for key, value in user_ns.items():\n        try:\n            if isinstance(value, str):\n                value = value.encode('utf-8').decode('utf-8')\n            pickle.dumps(value)\n        except Exception:\n            user_ns[key] = f\"not serializable: {str(value)}\"\n\n    for key, value in output_history.items():\n        try:\n            if isinstance(value, dict):\n                for k, v in value.items():\n                    if isinstance(v, str):\n                        value[k] = v.encode('utf-8').decode('utf-8')\n            pickle.dumps(value)\n        except Exception:\n            output_history[key] = f\"not serializable: {str(value)}\"\n\n\n    session_data = {\n        'user_ns': user_ns,\n        'output_history': output_history,\n\n    }\n\n    with open(session_file, 'wb') as f:\n        pickle.dump(session_data, f)\n\n    # Save VFS state with UTF-8 encoding\n    vfs_state_file = self._session_dir / f\"{name}_vfs.json\"\n    with open(vfs_state_file, 'w', encoding='utf-8') as f:\n        json.dump(self.vfs.virtual_files, f, ensure_ascii=False)\n</code></pre> <code>update_namespace(variables)</code> \u00b6 <p>Update namespace with new variables</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>def update_namespace(self, variables: dict[str, Any]):\n    \"\"\"Update namespace with new variables\"\"\"\n    self.user_ns.update(variables)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.CodingAgent.live.MockIPython.modify_code--2-change-a-method-implementation","title":"2. Change a method implementation","text":"<p>await ipython.modify_code(     code='\"\"\"def sound(self):     return \"Woof\"\"\"\"',     object_name=\"Dog.sound\" )</p>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.CodingAgent.live.MockIPython.modify_code--3-modify-a-function","title":"3. Modify a function","text":"<p>await ipython.modify_code(     code='\"\"\"def calculate_age(): return 25\"\"\"',     object_name=\"calculate_age\" )</p>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.CodingAgent.live.MockIPython.modify_code--4-update-variable-in-memory-and-file","title":"4. Update variable in memory and file","text":"<p>await ipython.modify_code(     code=\"100\",     object_name=\"MAX_SIZE\",     file=\"config.py\" )</p>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.CodingAgent.live.MockIPython.modify_code--5-modifying-an-attribute-in-init","title":"5. Modifying an attribute in init","text":"<p>await ipython.modify_code(     code='\"\"\"def init(self):     self.name = \"Buddy\"\"\"\"',     object_name=\"Dog.init\" )</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>async def modify_code(self, code: str = None, object_name: str = None, file: str = None) -&gt; str:\n    '''\n    Modify existing code in memory (user namespace) and optionally in the corresponding file.\n\n    This method updates variables, functions, or methods in the current Python session and can\n    also update the corresponding source file if specified.\n\n    Args:\n        code: New value or implementation for the object\n        object_name: Name of the object to modify (variable, function, or method)\n        file: Path to the file to update (if None, only updates in memory)\n\n    Returns:\n        String describing the modification result\n\n    Examples:\n\n    # 1. Update a variable in memory\n    await ipython.modify_code(code=\"5\", object_name=\"x\")\n\n# 2. Change a method implementation\nawait ipython.modify_code(\n    code='\"\"\"def sound(self):\\n        return \"Woof\"\"\"\"',\n    object_name=\"Dog.sound\"\n)\n\n# 3. Modify a function\nawait ipython.modify_code(\n    code='\"\"\"def calculate_age():\\n    return 25\"\"\"',\n    object_name=\"calculate_age\"\n)\n\n# 4. Update variable in memory and file\nawait ipython.modify_code(\n    code=\"100\",\n    object_name=\"MAX_SIZE\",\n    file=\"config.py\"\n)\n\n# 5. Modifying an attribute in __init__\nawait ipython.modify_code(\n    code='\"\"\"def __init__(self):\\n        self.name = \"Buddy\"\"\"\"',\n    object_name=\"Dog.__init__\"\n)\n    '''\n    try:\n        if not object_name:\n            raise ValueError(\"Object name must be specified\")\n        if code is None:\n            raise ValueError(\"New code or value must be provided\")\n\n        # Process object name (handle methods with parentheses)\n        clean_object_name = object_name.replace(\"()\", \"\")\n\n        # Step 1: Update in memory (user namespace)\n        result_message = []\n\n        # Handle different types of objects\n        if \".\" in clean_object_name:\n            # For methods or class attributes\n            parts = clean_object_name.split(\".\")\n            base_obj_name = parts[0]\n            attr_name = parts[1]\n\n            if base_obj_name not in self.user_ns:\n                raise ValueError(f\"Object '{base_obj_name}' not found in namespace\")\n\n            base_obj = self.user_ns[base_obj_name]\n\n            # Handle method definitions which are passed as docstrings\n            if code.split('\\n'):\n                method_code = code\n\n                # Parse the method code to extract its body\n                method_ast = ast.parse(method_code).body[0]\n                method_name = method_ast.name\n\n                # Create a new function object from the code\n                method_locals = {}\n                exec(\n                    f\"def _temp_func{signature(getattr(base_obj.__class__, attr_name, None))}: {method_ast.body[0].value.s}\",\n                    globals(), method_locals)\n                new_method = method_locals['_temp_func']\n\n                # Set the method on the class\n                setattr(base_obj.__class__, attr_name, new_method)\n                result_message.append(f\"Updated method '{clean_object_name}' in memory\")\n            else:\n                # For simple attributes\n                setattr(base_obj, attr_name, eval(code, self.user_ns))\n                result_message.append(f\"Updated attribute '{clean_object_name}' in memory\")\n        else:\n            # For variables and functions\n            if code.startswith('\"\"\"') and code.endswith('\"\"\"'):\n                # Handle function definitions\n                func_code = code.strip('\"\"\"')\n                func_ast = ast.parse(func_code).body[0]\n                func_name = func_ast.name\n\n                # Create a new function object from the code\n                func_locals = {}\n                exec(f\"{func_code}\", globals(), func_locals)\n                self.user_ns[clean_object_name] = func_locals[func_name]\n                result_message.append(f\"Updated function '{clean_object_name}' in memory\")\n            else:\n                # Simple variable assignment\n                self.user_ns[clean_object_name] = eval(code, self.user_ns)\n                result_message.append(f\"Updated variable '{clean_object_name}' in memory\")\n\n        # Step 2: Update in file if specified\n        if file is not None:\n            file_path = self.vfs._resolve_path(file)\n\n            if not file_path.exists():\n                self.user_ns['__file__'] = str(file_path)\n                return await self.run_cell(code)\n\n            # Read original content\n            original_content = self.vfs.read_file(file_path)\n            updated_content = original_content\n\n            # Handle different object types for file updates\n            if \".\" in clean_object_name:\n                # For methods\n                parts = clean_object_name.split(\".\")\n                class_name = parts[0]\n                method_name = parts[1]\n\n                if code.startswith('\"\"\"') and code.endswith('\"\"\"'):\n                    method_code = code.strip('\"\"\"')\n\n                    # Use ast to parse the file and find the method to replace\n                    file_ast = ast.parse(original_content)\n                    for node in ast.walk(file_ast):\n                        if isinstance(node, ast.ClassDef) and node.name == class_name:\n                            for method in node.body:\n                                if isinstance(method, ast.FunctionDef) and method.name == method_name:\n                                    # Find the method in the source code\n                                    method_pattern = fr\"def {method_name}.*?:(.*?)(?=\\n    \\w|\\n\\w|\\Z)\"\n                                    method_match = re.search(method_pattern, original_content, re.DOTALL)\n\n                                    if method_match:\n                                        indentation = re.match(r\"^(\\s*)\", method_match.group(0)).group(1)\n                                        method_indented = textwrap.indent(method_code, indentation)\n                                        updated_content = original_content.replace(\n                                            method_match.group(0),\n                                            method_indented\n                                        )\n                                        self.vfs.write_file(file_path, updated_content)\n                                        result_message.append(\n                                            f\"Updated method '{clean_object_name}' in file '{file}'\")\n            else:\n                # For variables and functions\n                if code.startswith('\"\"\"') and code.endswith('\"\"\"'):\n                    # Handle function updates\n                    func_code = code.strip('\"\"\"')\n                    func_pattern = fr\"def {clean_object_name}.*?:(.*?)(?=\\n\\w|\\Z)\"\n                    func_match = re.search(func_pattern, original_content, re.DOTALL)\n\n                    if func_match:\n                        indentation = re.match(r\"^(\\s*)\", func_match.group(0)).group(1)\n                        func_indented = textwrap.indent(func_code, indentation)\n                        updated_content = original_content.replace(\n                            func_match.group(0),\n                            func_indented\n                        )\n                        self.vfs.write_file(file_path, updated_content)\n                        result_message.append(f\"Updated function '{clean_object_name}' in file '{file}'\")\n                else:\n                    # Handle variable updates\n                    var_pattern = fr\"{clean_object_name}\\s*=.*\"\n                    var_replacement = f\"{clean_object_name} = {code}\"\n                    updated_content = re.sub(var_pattern, var_replacement, original_content)\n\n                    if updated_content != original_content:\n                        self.vfs.write_file(file_path, updated_content)\n                        result_message.append(f\"Updated variable '{clean_object_name}' in file '{file}'\")\n                    else:\n                        result_message.append(f\"Could not find variable '{clean_object_name}' in file '{file}'\")\n\n        return \"\\n\".join(result_message)\n\n    except Exception as e:\n        return f\"Error during code modification: {str(e)}\\n{traceback.format_exc()}\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.CodingAgent.live.ParentNodeTransformer","title":"<code>ParentNodeTransformer</code>","text":"<p>               Bases: <code>NodeTransformer</code></p> <p>Add parent references to AST nodes</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>class ParentNodeTransformer(ast.NodeTransformer):\n    \"\"\"Add parent references to AST nodes\"\"\"\n    def visit(self, node):\n        for child in ast.iter_child_nodes(node):\n            child.parent = node\n        return super().visit(node)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.CodingAgent.live.SyncReport","title":"<code>SyncReport</code>  <code>dataclass</code>","text":"<p>Report of variables synced from namespace to pipeline</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>@dataclass\nclass SyncReport:\n    \"\"\"Report of variables synced from namespace to pipeline\"\"\"\n    added: dict[str, str]\n    skipped: dict[str, str]  # var_name -&gt; reason\n    errors: dict[str, str]  # var_name -&gt; error message\n\n    def __str__(self) -&gt; str:\n        parts = []\n        if self.added:\n            parts.append(\"Added variables:\")\n            for name, type_ in self.added.items():\n                parts.append(f\"  - {name}: {type_}\")\n        if self.skipped:\n            parts.append(\"\\nSkipped variables:\")\n            for name, reason in self.skipped.items():\n                parts.append(f\"  - {name}: {reason}\")\n        if self.errors:\n            parts.append(\"\\nErrors:\")\n            for name, error in self.errors.items():\n                parts.append(f\"  - {name}: {error}\")\n        return \"\\n\".join(parts)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.CodingAgent.live.TeeStream","title":"<code>TeeStream</code>","text":"<p>Stream that writes to both console and buffer</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>class TeeStream:\n    \"\"\"Stream that writes to both console and buffer\"\"\"\n    def __init__(self, console_stream, buffer_stream):\n        self.console_stream = console_stream\n        self.buffer_stream = buffer_stream\n\n    def write(self, data):\n        self.console_stream.write(data)\n        self.buffer_stream.write(data)\n        self.console_stream.flush()  # Ensure immediate console output\n\n    def flush(self):\n        self.console_stream.flush()\n        self.buffer_stream.flush()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.CodingAgent.live.ToolsInterface","title":"<code>ToolsInterface</code>","text":"<p>Minimalistic tools interface for LLMs providing code execution, virtual file system, and browser interaction capabilities.</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>class ToolsInterface:\n    \"\"\"\n    Minimalistic tools interface for LLMs providing code execution,\n    virtual file system, and browser interaction capabilities.\n    \"\"\"\n\n    def __init__(self,\n                 session_dir: str | None = None,\n                 auto_remove: bool = True,\n                 variables: dict[str, Any] | None = None,\n                 variable_manager: Any | None = None):\n        \"\"\"\n        Initialize the tools interface.\n\n        Args:\n            session_dir: Directory for session storage\n            auto_remove: Whether to auto-remove temporary files\n            variables: Initial variables dictionary\n            variable_manager: External variable manager instance\n            web_llm: LLM model for web interactions\n        \"\"\"\n        self._session_dir = Path(session_dir) if session_dir else Path(get_app().appdata) / '.tools_sessions'\n        self._session_dir.mkdir(exist_ok=True)\n        self.auto_remove = auto_remove\n        self.variable_manager = variable_manager\n\n        # Initialize Python execution environment\n        self.ipython = MockIPython(self._session_dir, auto_remove=auto_remove)\n        if variables:\n            self.ipython.user_ns.update(variables)\n\n        # Initialize virtual file system\n        self.vfs = VirtualFileSystem(self._session_dir / 'virtual_fs')\n\n        # Initialize Rust interface\n        self.cargo = CargoRustInterface(self._session_dir, auto_remove=auto_remove)\n\n        # Track execution state\n        self._execution_history = []\n        self._current_file = None\n\n    async def execute_python(self, code: str) -&gt; str:\n        \"\"\"\n        Execute Python code in the virtual environment.\n\n        Args:\n            code: Python code to execute\n\n        Returns:\n            Execution result as string\n        \"\"\"\n        try:\n            result = await self.ipython.run_cell(code, live_output=False)\n\n            # Update variable manager if available\n            if self.variable_manager:\n                for key, value in self.ipython.user_ns.items():\n                    if not key.startswith('_') and key not in ['__name__', '__builtins__']:\n                        try:\n                            self.variable_manager.set(f\"python.{key}\", value)\n                        except:\n                            pass  # Ignore non-serializable variables\n\n            self._execution_history.append(('python', code, result))\n            return str(result) if result else \"Execution completed\"\n\n        except Exception as e:\n            error_msg = f\"Python execution error: {str(e)}\\n{traceback.format_exc()}\"\n            self._execution_history.append(('python', code, error_msg))\n            return error_msg\n\n    async def execute_rust(self, code: str) -&gt; str:\n        \"\"\"\n        Execute Rust code using Cargo.\n\n        Args:\n            code: Rust code to execute\n\n        Returns:\n            Execution result as string\n        \"\"\"\n        try:\n            # Setup project if needed\n            if not self.cargo.current_project:\n                await self.cargo.setup_project(\"temp_rust_project\")\n\n            result = await self.cargo.run_code(code)\n            self._execution_history.append(('rust', code, result))\n            return result\n\n        except Exception as e:\n            error_msg = f\"Rust execution error: {str(e)}\"\n            self._execution_history.append(('rust', code, error_msg))\n            return error_msg\n\n    async def write_file(self, filepath: str, content: str) -&gt; str:\n        \"\"\"\n        Write content to a file in the virtual file system.\n\n        Args:\n            filepath: Path to the file\n            content: Content to write\n\n        Returns:\n            Success message\n        \"\"\"\n        try:\n            abs_path = self.vfs.write_file(filepath, content)\n\n            # Update variable manager if available\n            if self.variable_manager:\n                self.variable_manager.set(f\"files.{filepath.replace('/', '.')}\", {\n                    'path': str(abs_path),\n                    'size': len(content),\n                    'content_preview': content[:100] + '...' if len(content) &gt; 100 else content\n                })\n\n            return f\"File written successfully: {abs_path}\"\n\n        except Exception as e:\n            return f\"File write error: {str(e)}\"\n\n    async def replace_in_file(self, filepath: str, old_content: str, new_content: str, precise: bool = True) -&gt; str:\n        \"\"\"\n        Replace exact content in file with new content.\n\n        Args:\n            filepath: Path to the file\n            old_content: Exact content to replace (empty string for insertion at start)\n            new_content: Content to replace with\n            precise: If True, requires exact match; if False, allows single occurrence replacement\n\n        Returns:\n            Success message or error\n        \"\"\"\n        try:\n            # Read current file content\n            try:\n                current_content = self.vfs.read_file(filepath)\n            except:\n                return f\"Error: File '{filepath}' not found or cannot be read\"\n\n            # Handle insertion at start (empty old_content)\n            if not old_content:\n                updated_content = new_content + current_content\n                self.vfs.write_file(filepath, updated_content)\n                return f\"Content inserted at start of '{filepath}'\"\n\n            # Check if old_content exists\n            if old_content not in current_content:\n                return f\"Error: Old content not found in '{filepath}' use read_file to check.\"\n\n            # Count occurrences\n            occurrences = current_content.count(old_content)\n\n            if precise and occurrences &gt; 1:\n                return f\"Error: Found {occurrences} occurrences of old content. Use precise=False to replace first occurrence.\"\n\n            # Replace content (first occurrence if multiple)\n            updated_content = current_content.replace(old_content, new_content, 1)\n\n            # Write updated content\n            self.vfs.write_file(filepath, updated_content)\n\n            return f\"Successfully replaced content in '{filepath}' ({occurrences} occurrence{'s' if occurrences &gt; 1 else ''} found, 1 replaced)\"\n\n        except Exception as e:\n            return f\"Replace error: {str(e)}\"\n\n    async def read_file(self, filepath: str) -&gt; str:\n        \"\"\"\n        Read content from a file in the virtual file system.\n\n        Args:\n            filepath: Path to the file\n\n        Returns:\n            File content or error message\n        \"\"\"\n        try:\n            content = self.vfs.read_file(filepath)\n\n            # Update variable manager if available\n            if self.variable_manager:\n                self.variable_manager.set(\"files.last_read\", {\n                    'path': filepath,\n                    'size': len(content),\n                    'content_preview': content[:200] + '...' if len(content) &gt; 200 else content\n                })\n\n            return content\n\n        except Exception as e:\n            return f\"File read error: {str(e)}\"\n\n    async def list_directory(self, dirpath: str = '.') -&gt; str:\n        \"\"\"\n        List contents of a directory.\n\n        Args:\n            dirpath: Directory path to list\n\n        Returns:\n            Directory listing as string\n        \"\"\"\n        try:\n            contents = self.vfs.list_directory(dirpath)\n            listing = \"\\n\".join(f\"- {item}\" for item in contents)\n\n            # Update variable manager if available\n            if self.variable_manager:\n                self.variable_manager.set(\"files.last_listing\", {\n                    'directory': dirpath,\n                    'items': contents,\n                    'count': len(contents)\n                })\n\n            return f\"Directory '{dirpath}' contents:\\n{listing}\"\n\n        except Exception as e:\n            return f\"Directory listing error: {str(e)}\"\n\n    async def create_directory(self, dirpath: str) -&gt; str:\n        \"\"\"\n        Create a new directory.\n\n        Args:\n            dirpath: Path of directory to create\n\n        Returns:\n            Success message\n        \"\"\"\n        try:\n            abs_path = self.vfs.create_directory(dirpath)\n            return f\"Directory created successfully: {abs_path}\"\n\n        except Exception as e:\n            return f\"Directory creation error: {str(e)}\"\n\n    async def set_base_directory(self, path: str) -&gt; str:\n        \"\"\"\n        Set the base directory for the virtual file system.\n\n        Args:\n            path: New base directory path\n\n        Returns:\n            Success message\n        \"\"\"\n        try:\n            new_path = Path(path)\n            new_path.mkdir(parents=True, exist_ok=True)\n            self.vfs.base_dir = new_path\n            self.vfs.current_dir = new_path\n\n            return f\"Base directory set to: {new_path}\"\n\n        except Exception as e:\n            return f\"Set base directory error: {str(e)}\"\n\n    async def set_current_file(self, filepath: str) -&gt; str:\n        \"\"\"\n        Set the current file for Python execution context.\n\n        Args:\n            filepath: Path to set as current file\n\n        Returns:\n            Success message\n        \"\"\"\n        try:\n            abs_path = self.vfs._resolve_path(filepath)\n            self.ipython.user_ns['__file__'] = str(abs_path)\n            self._current_file = str(abs_path)\n\n            return f\"Current file set to: {abs_path}\"\n\n        except Exception as e:\n            return f\"Set current file error: {str(e)}\"\n\n    async def install_package(self, package_name: str, version: str | None = None) -&gt; str:\n        \"\"\"\n        Install a Python package in the virtual environment.\n\n        Args:\n            package_name: Name of the package to install\n            version: Optional specific version to install\n\n        Returns:\n            Installation result\n        \"\"\"\n        try:\n            code = f\"\"\"\nauto_install('{package_name}'{f\", version='{version}'\" if version else \"\"})\nimport {package_name.split('[')[0]}  # Import base package name\nprint(f\"Successfully imported {package_name}\")\n\"\"\"\n            result = await self.execute_python(code)\n            return result\n\n        except Exception as e:\n            return f\"Package installation error: {str(e)}\"\n\n    async def get_execution_history(self) -&gt; str:\n        \"\"\"\n        Get the execution history.\n\n        Returns:\n            Execution history as formatted string\n        \"\"\"\n        if not self._execution_history:\n            return \"No execution history available.\"\n\n        history_lines = []\n        for i, (lang, code, result) in enumerate(self._execution_history[-10:], 1):\n            history_lines.append(f\"[{i}] {lang.upper()}:\")\n            history_lines.append(f\"    Code: {code[:100]}...\" if len(code) &gt; 100 else f\"    Code: {code}\")\n            history_lines.append(\n                f\"    Result: {str(result)[:200]}...\" if len(str(result)) &gt; 200 else f\"    Result: {result}\")\n            history_lines.append(\"\")\n\n        return \"\\n\".join(history_lines)\n\n    async def clear_session(self) -&gt; str:\n        \"\"\"\n        Clear the current session (variables, history, files).\n\n        Returns:\n            Success message\n        \"\"\"\n        try:\n            # Reset Python environment\n            self.ipython.reset()\n\n            # Clear execution history\n            self._execution_history.clear()\n\n            # Clear VFS if auto_remove is enabled\n            if self.auto_remove:\n                shutil.rmtree(self.vfs.base_dir, ignore_errors=True)\n                self.vfs.base_dir.mkdir(parents=True, exist_ok=True)\n                self.vfs.virtual_files.clear()\n\n            # Reset current file\n            self._current_file = None\n\n            return \"Session cleared successfully\"\n\n        except Exception as e:\n            return f\"Clear session error: {str(e)}\"\n\n    async def get_variables(self) -&gt; str:\n        \"\"\"\n        Get current variables in JSON format.\n\n        Returns:\n            Variables as JSON string\n        \"\"\"\n        try:\n            # Get Python variables\n            py_vars = {}\n            for key, value in self.ipython.user_ns.items():\n                if not key.startswith('_') and key not in ['__name__', '__builtins__']:\n                    try:\n                        # Try to serialize the value\n                        json.dumps(value, default=str)\n                        py_vars[key] = str(value)[:200] if len(str(value)) &gt; 200 else value\n                    except:\n                        py_vars[key] = f\"&lt;{type(value).__name__}&gt;\"\n\n            result = {\n                'python_variables': py_vars,\n                'current_file': self._current_file,\n                'vfs_base': str(self.vfs.base_dir),\n                'execution_count': len(self._execution_history)\n            }\n\n            return json.dumps(result, indent=2, default=str)\n\n        except Exception as e:\n            return f\"Get variables error: {str(e)}\"\n\n    def get_tools(self) -&gt; list[tuple[Any, str, str]]:\n        \"\"\"\n        Get all available tools as list of tuples (function, name, description).\n\n        Returns:\n            List of tool tuples\n        \"\"\"\n        tools = [\n            # Code execution tools\n            (self.execute_python, \"execute_python\",\n             \"Execute Python code in virtual environment. Args: code (str) -&gt; str\"),\n\n            (self.execute_rust, \"execute_rust\",\n             \"Execute Rust code using Cargo. Args: code (str) -&gt; str\"),\n\n            # File system tools\n            (self.write_file, \"write_file\",\n             \"Write content to file in virtual filesystem. Args: filepath (str), content (str) -&gt; str\"),\n\n            (self.write_file, \"create_file\",\n             \"Write content to file in virtual filesystem. Args: filepath (str), content (str) -&gt; str\"),\n\n            (self.replace_in_file, \"replace_in_file\",\n             \"Replace exact content in file. Args: filepath (str), old_content (str), new_content (str), precise (bool) = True -&gt; str\"),\n\n            (self.read_file, \"read_file\",\n             \"Read content from file in virtual filesystem. Args: filepath (str) -&gt; str\"),\n\n            (self.list_directory, \"list_directory\",\n             \"List directory contents. Args: dirpath (str) = '.' -&gt; str\"),\n\n            (self.create_directory, \"create_directory\",\n             \"Create new directory. Args: dirpath (str) -&gt; str\"),\n\n            # Configuration tools\n            (self.set_base_directory, \"set_base_directory\",\n             \"Set base directory for virtual filesystem. Args: path (str) -&gt; str\"),\n\n            (self.set_current_file, \"set_current_file\",\n             \"Set current file for Python execution context. Args: filepath (str) -&gt; str\"),\n\n            (self.install_package, \"install_package\",\n             \"Install Python package. Args: package_name (str), version (Optional[str]) -&gt; str\"),\n\n            # Session management tools\n            (self.get_execution_history, \"get_execution_history\",\n             \"Get execution history. Args: None -&gt; str\"),\n\n            (self.clear_session, \"clear_session\",\n             \"Clear current session. Args: None -&gt; str\"),\n\n            (self.get_variables, \"get_variables\",\n             \"Get current variables as JSON. Args: None -&gt; str\"),\n        ]\n\n        return tools\n\n    def __aenter__(self):\n        return self\n\n    async def __aexit__(self, *exe):\n        await asyncio.sleep(0.01)\n</code></pre> <code>__init__(session_dir=None, auto_remove=True, variables=None, variable_manager=None)</code> \u00b6 <p>Initialize the tools interface.</p> <p>Parameters:</p> Name Type Description Default <code>session_dir</code> <code>str | None</code> <p>Directory for session storage</p> <code>None</code> <code>auto_remove</code> <code>bool</code> <p>Whether to auto-remove temporary files</p> <code>True</code> <code>variables</code> <code>dict[str, Any] | None</code> <p>Initial variables dictionary</p> <code>None</code> <code>variable_manager</code> <code>Any | None</code> <p>External variable manager instance</p> <code>None</code> <code>web_llm</code> <p>LLM model for web interactions</p> required Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>def __init__(self,\n             session_dir: str | None = None,\n             auto_remove: bool = True,\n             variables: dict[str, Any] | None = None,\n             variable_manager: Any | None = None):\n    \"\"\"\n    Initialize the tools interface.\n\n    Args:\n        session_dir: Directory for session storage\n        auto_remove: Whether to auto-remove temporary files\n        variables: Initial variables dictionary\n        variable_manager: External variable manager instance\n        web_llm: LLM model for web interactions\n    \"\"\"\n    self._session_dir = Path(session_dir) if session_dir else Path(get_app().appdata) / '.tools_sessions'\n    self._session_dir.mkdir(exist_ok=True)\n    self.auto_remove = auto_remove\n    self.variable_manager = variable_manager\n\n    # Initialize Python execution environment\n    self.ipython = MockIPython(self._session_dir, auto_remove=auto_remove)\n    if variables:\n        self.ipython.user_ns.update(variables)\n\n    # Initialize virtual file system\n    self.vfs = VirtualFileSystem(self._session_dir / 'virtual_fs')\n\n    # Initialize Rust interface\n    self.cargo = CargoRustInterface(self._session_dir, auto_remove=auto_remove)\n\n    # Track execution state\n    self._execution_history = []\n    self._current_file = None\n</code></pre> <code>clear_session()</code> <code>async</code> \u00b6 <p>Clear the current session (variables, history, files).</p> <p>Returns:</p> Type Description <code>str</code> <p>Success message</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>async def clear_session(self) -&gt; str:\n    \"\"\"\n    Clear the current session (variables, history, files).\n\n    Returns:\n        Success message\n    \"\"\"\n    try:\n        # Reset Python environment\n        self.ipython.reset()\n\n        # Clear execution history\n        self._execution_history.clear()\n\n        # Clear VFS if auto_remove is enabled\n        if self.auto_remove:\n            shutil.rmtree(self.vfs.base_dir, ignore_errors=True)\n            self.vfs.base_dir.mkdir(parents=True, exist_ok=True)\n            self.vfs.virtual_files.clear()\n\n        # Reset current file\n        self._current_file = None\n\n        return \"Session cleared successfully\"\n\n    except Exception as e:\n        return f\"Clear session error: {str(e)}\"\n</code></pre> <code>create_directory(dirpath)</code> <code>async</code> \u00b6 <p>Create a new directory.</p> <p>Parameters:</p> Name Type Description Default <code>dirpath</code> <code>str</code> <p>Path of directory to create</p> required <p>Returns:</p> Type Description <code>str</code> <p>Success message</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>async def create_directory(self, dirpath: str) -&gt; str:\n    \"\"\"\n    Create a new directory.\n\n    Args:\n        dirpath: Path of directory to create\n\n    Returns:\n        Success message\n    \"\"\"\n    try:\n        abs_path = self.vfs.create_directory(dirpath)\n        return f\"Directory created successfully: {abs_path}\"\n\n    except Exception as e:\n        return f\"Directory creation error: {str(e)}\"\n</code></pre> <code>execute_python(code)</code> <code>async</code> \u00b6 <p>Execute Python code in the virtual environment.</p> <p>Parameters:</p> Name Type Description Default <code>code</code> <code>str</code> <p>Python code to execute</p> required <p>Returns:</p> Type Description <code>str</code> <p>Execution result as string</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>async def execute_python(self, code: str) -&gt; str:\n    \"\"\"\n    Execute Python code in the virtual environment.\n\n    Args:\n        code: Python code to execute\n\n    Returns:\n        Execution result as string\n    \"\"\"\n    try:\n        result = await self.ipython.run_cell(code, live_output=False)\n\n        # Update variable manager if available\n        if self.variable_manager:\n            for key, value in self.ipython.user_ns.items():\n                if not key.startswith('_') and key not in ['__name__', '__builtins__']:\n                    try:\n                        self.variable_manager.set(f\"python.{key}\", value)\n                    except:\n                        pass  # Ignore non-serializable variables\n\n        self._execution_history.append(('python', code, result))\n        return str(result) if result else \"Execution completed\"\n\n    except Exception as e:\n        error_msg = f\"Python execution error: {str(e)}\\n{traceback.format_exc()}\"\n        self._execution_history.append(('python', code, error_msg))\n        return error_msg\n</code></pre> <code>execute_rust(code)</code> <code>async</code> \u00b6 <p>Execute Rust code using Cargo.</p> <p>Parameters:</p> Name Type Description Default <code>code</code> <code>str</code> <p>Rust code to execute</p> required <p>Returns:</p> Type Description <code>str</code> <p>Execution result as string</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>async def execute_rust(self, code: str) -&gt; str:\n    \"\"\"\n    Execute Rust code using Cargo.\n\n    Args:\n        code: Rust code to execute\n\n    Returns:\n        Execution result as string\n    \"\"\"\n    try:\n        # Setup project if needed\n        if not self.cargo.current_project:\n            await self.cargo.setup_project(\"temp_rust_project\")\n\n        result = await self.cargo.run_code(code)\n        self._execution_history.append(('rust', code, result))\n        return result\n\n    except Exception as e:\n        error_msg = f\"Rust execution error: {str(e)}\"\n        self._execution_history.append(('rust', code, error_msg))\n        return error_msg\n</code></pre> <code>get_execution_history()</code> <code>async</code> \u00b6 <p>Get the execution history.</p> <p>Returns:</p> Type Description <code>str</code> <p>Execution history as formatted string</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>async def get_execution_history(self) -&gt; str:\n    \"\"\"\n    Get the execution history.\n\n    Returns:\n        Execution history as formatted string\n    \"\"\"\n    if not self._execution_history:\n        return \"No execution history available.\"\n\n    history_lines = []\n    for i, (lang, code, result) in enumerate(self._execution_history[-10:], 1):\n        history_lines.append(f\"[{i}] {lang.upper()}:\")\n        history_lines.append(f\"    Code: {code[:100]}...\" if len(code) &gt; 100 else f\"    Code: {code}\")\n        history_lines.append(\n            f\"    Result: {str(result)[:200]}...\" if len(str(result)) &gt; 200 else f\"    Result: {result}\")\n        history_lines.append(\"\")\n\n    return \"\\n\".join(history_lines)\n</code></pre> <code>get_tools()</code> \u00b6 <p>Get all available tools as list of tuples (function, name, description).</p> <p>Returns:</p> Type Description <code>list[tuple[Any, str, str]]</code> <p>List of tool tuples</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>def get_tools(self) -&gt; list[tuple[Any, str, str]]:\n    \"\"\"\n    Get all available tools as list of tuples (function, name, description).\n\n    Returns:\n        List of tool tuples\n    \"\"\"\n    tools = [\n        # Code execution tools\n        (self.execute_python, \"execute_python\",\n         \"Execute Python code in virtual environment. Args: code (str) -&gt; str\"),\n\n        (self.execute_rust, \"execute_rust\",\n         \"Execute Rust code using Cargo. Args: code (str) -&gt; str\"),\n\n        # File system tools\n        (self.write_file, \"write_file\",\n         \"Write content to file in virtual filesystem. Args: filepath (str), content (str) -&gt; str\"),\n\n        (self.write_file, \"create_file\",\n         \"Write content to file in virtual filesystem. Args: filepath (str), content (str) -&gt; str\"),\n\n        (self.replace_in_file, \"replace_in_file\",\n         \"Replace exact content in file. Args: filepath (str), old_content (str), new_content (str), precise (bool) = True -&gt; str\"),\n\n        (self.read_file, \"read_file\",\n         \"Read content from file in virtual filesystem. Args: filepath (str) -&gt; str\"),\n\n        (self.list_directory, \"list_directory\",\n         \"List directory contents. Args: dirpath (str) = '.' -&gt; str\"),\n\n        (self.create_directory, \"create_directory\",\n         \"Create new directory. Args: dirpath (str) -&gt; str\"),\n\n        # Configuration tools\n        (self.set_base_directory, \"set_base_directory\",\n         \"Set base directory for virtual filesystem. Args: path (str) -&gt; str\"),\n\n        (self.set_current_file, \"set_current_file\",\n         \"Set current file for Python execution context. Args: filepath (str) -&gt; str\"),\n\n        (self.install_package, \"install_package\",\n         \"Install Python package. Args: package_name (str), version (Optional[str]) -&gt; str\"),\n\n        # Session management tools\n        (self.get_execution_history, \"get_execution_history\",\n         \"Get execution history. Args: None -&gt; str\"),\n\n        (self.clear_session, \"clear_session\",\n         \"Clear current session. Args: None -&gt; str\"),\n\n        (self.get_variables, \"get_variables\",\n         \"Get current variables as JSON. Args: None -&gt; str\"),\n    ]\n\n    return tools\n</code></pre> <code>get_variables()</code> <code>async</code> \u00b6 <p>Get current variables in JSON format.</p> <p>Returns:</p> Type Description <code>str</code> <p>Variables as JSON string</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>async def get_variables(self) -&gt; str:\n    \"\"\"\n    Get current variables in JSON format.\n\n    Returns:\n        Variables as JSON string\n    \"\"\"\n    try:\n        # Get Python variables\n        py_vars = {}\n        for key, value in self.ipython.user_ns.items():\n            if not key.startswith('_') and key not in ['__name__', '__builtins__']:\n                try:\n                    # Try to serialize the value\n                    json.dumps(value, default=str)\n                    py_vars[key] = str(value)[:200] if len(str(value)) &gt; 200 else value\n                except:\n                    py_vars[key] = f\"&lt;{type(value).__name__}&gt;\"\n\n        result = {\n            'python_variables': py_vars,\n            'current_file': self._current_file,\n            'vfs_base': str(self.vfs.base_dir),\n            'execution_count': len(self._execution_history)\n        }\n\n        return json.dumps(result, indent=2, default=str)\n\n    except Exception as e:\n        return f\"Get variables error: {str(e)}\"\n</code></pre> <code>install_package(package_name, version=None)</code> <code>async</code> \u00b6 <p>Install a Python package in the virtual environment.</p> <p>Parameters:</p> Name Type Description Default <code>package_name</code> <code>str</code> <p>Name of the package to install</p> required <code>version</code> <code>str | None</code> <p>Optional specific version to install</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>Installation result</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>    async def install_package(self, package_name: str, version: str | None = None) -&gt; str:\n        \"\"\"\n        Install a Python package in the virtual environment.\n\n        Args:\n            package_name: Name of the package to install\n            version: Optional specific version to install\n\n        Returns:\n            Installation result\n        \"\"\"\n        try:\n            code = f\"\"\"\nauto_install('{package_name}'{f\", version='{version}'\" if version else \"\"})\nimport {package_name.split('[')[0]}  # Import base package name\nprint(f\"Successfully imported {package_name}\")\n\"\"\"\n            result = await self.execute_python(code)\n            return result\n\n        except Exception as e:\n            return f\"Package installation error: {str(e)}\"\n</code></pre> <code>list_directory(dirpath='.')</code> <code>async</code> \u00b6 <p>List contents of a directory.</p> <p>Parameters:</p> Name Type Description Default <code>dirpath</code> <code>str</code> <p>Directory path to list</p> <code>'.'</code> <p>Returns:</p> Type Description <code>str</code> <p>Directory listing as string</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>async def list_directory(self, dirpath: str = '.') -&gt; str:\n    \"\"\"\n    List contents of a directory.\n\n    Args:\n        dirpath: Directory path to list\n\n    Returns:\n        Directory listing as string\n    \"\"\"\n    try:\n        contents = self.vfs.list_directory(dirpath)\n        listing = \"\\n\".join(f\"- {item}\" for item in contents)\n\n        # Update variable manager if available\n        if self.variable_manager:\n            self.variable_manager.set(\"files.last_listing\", {\n                'directory': dirpath,\n                'items': contents,\n                'count': len(contents)\n            })\n\n        return f\"Directory '{dirpath}' contents:\\n{listing}\"\n\n    except Exception as e:\n        return f\"Directory listing error: {str(e)}\"\n</code></pre> <code>read_file(filepath)</code> <code>async</code> \u00b6 <p>Read content from a file in the virtual file system.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>Path to the file</p> required <p>Returns:</p> Type Description <code>str</code> <p>File content or error message</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>async def read_file(self, filepath: str) -&gt; str:\n    \"\"\"\n    Read content from a file in the virtual file system.\n\n    Args:\n        filepath: Path to the file\n\n    Returns:\n        File content or error message\n    \"\"\"\n    try:\n        content = self.vfs.read_file(filepath)\n\n        # Update variable manager if available\n        if self.variable_manager:\n            self.variable_manager.set(\"files.last_read\", {\n                'path': filepath,\n                'size': len(content),\n                'content_preview': content[:200] + '...' if len(content) &gt; 200 else content\n            })\n\n        return content\n\n    except Exception as e:\n        return f\"File read error: {str(e)}\"\n</code></pre> <code>replace_in_file(filepath, old_content, new_content, precise=True)</code> <code>async</code> \u00b6 <p>Replace exact content in file with new content.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>Path to the file</p> required <code>old_content</code> <code>str</code> <p>Exact content to replace (empty string for insertion at start)</p> required <code>new_content</code> <code>str</code> <p>Content to replace with</p> required <code>precise</code> <code>bool</code> <p>If True, requires exact match; if False, allows single occurrence replacement</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>Success message or error</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>async def replace_in_file(self, filepath: str, old_content: str, new_content: str, precise: bool = True) -&gt; str:\n    \"\"\"\n    Replace exact content in file with new content.\n\n    Args:\n        filepath: Path to the file\n        old_content: Exact content to replace (empty string for insertion at start)\n        new_content: Content to replace with\n        precise: If True, requires exact match; if False, allows single occurrence replacement\n\n    Returns:\n        Success message or error\n    \"\"\"\n    try:\n        # Read current file content\n        try:\n            current_content = self.vfs.read_file(filepath)\n        except:\n            return f\"Error: File '{filepath}' not found or cannot be read\"\n\n        # Handle insertion at start (empty old_content)\n        if not old_content:\n            updated_content = new_content + current_content\n            self.vfs.write_file(filepath, updated_content)\n            return f\"Content inserted at start of '{filepath}'\"\n\n        # Check if old_content exists\n        if old_content not in current_content:\n            return f\"Error: Old content not found in '{filepath}' use read_file to check.\"\n\n        # Count occurrences\n        occurrences = current_content.count(old_content)\n\n        if precise and occurrences &gt; 1:\n            return f\"Error: Found {occurrences} occurrences of old content. Use precise=False to replace first occurrence.\"\n\n        # Replace content (first occurrence if multiple)\n        updated_content = current_content.replace(old_content, new_content, 1)\n\n        # Write updated content\n        self.vfs.write_file(filepath, updated_content)\n\n        return f\"Successfully replaced content in '{filepath}' ({occurrences} occurrence{'s' if occurrences &gt; 1 else ''} found, 1 replaced)\"\n\n    except Exception as e:\n        return f\"Replace error: {str(e)}\"\n</code></pre> <code>set_base_directory(path)</code> <code>async</code> \u00b6 <p>Set the base directory for the virtual file system.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>New base directory path</p> required <p>Returns:</p> Type Description <code>str</code> <p>Success message</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>async def set_base_directory(self, path: str) -&gt; str:\n    \"\"\"\n    Set the base directory for the virtual file system.\n\n    Args:\n        path: New base directory path\n\n    Returns:\n        Success message\n    \"\"\"\n    try:\n        new_path = Path(path)\n        new_path.mkdir(parents=True, exist_ok=True)\n        self.vfs.base_dir = new_path\n        self.vfs.current_dir = new_path\n\n        return f\"Base directory set to: {new_path}\"\n\n    except Exception as e:\n        return f\"Set base directory error: {str(e)}\"\n</code></pre> <code>set_current_file(filepath)</code> <code>async</code> \u00b6 <p>Set the current file for Python execution context.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>Path to set as current file</p> required <p>Returns:</p> Type Description <code>str</code> <p>Success message</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>async def set_current_file(self, filepath: str) -&gt; str:\n    \"\"\"\n    Set the current file for Python execution context.\n\n    Args:\n        filepath: Path to set as current file\n\n    Returns:\n        Success message\n    \"\"\"\n    try:\n        abs_path = self.vfs._resolve_path(filepath)\n        self.ipython.user_ns['__file__'] = str(abs_path)\n        self._current_file = str(abs_path)\n\n        return f\"Current file set to: {abs_path}\"\n\n    except Exception as e:\n        return f\"Set current file error: {str(e)}\"\n</code></pre> <code>write_file(filepath, content)</code> <code>async</code> \u00b6 <p>Write content to a file in the virtual file system.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>Path to the file</p> required <code>content</code> <code>str</code> <p>Content to write</p> required <p>Returns:</p> Type Description <code>str</code> <p>Success message</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>async def write_file(self, filepath: str, content: str) -&gt; str:\n    \"\"\"\n    Write content to a file in the virtual file system.\n\n    Args:\n        filepath: Path to the file\n        content: Content to write\n\n    Returns:\n        Success message\n    \"\"\"\n    try:\n        abs_path = self.vfs.write_file(filepath, content)\n\n        # Update variable manager if available\n        if self.variable_manager:\n            self.variable_manager.set(f\"files.{filepath.replace('/', '.')}\", {\n                'path': str(abs_path),\n                'size': len(content),\n                'content_preview': content[:100] + '...' if len(content) &gt; 100 else content\n            })\n\n        return f\"File written successfully: {abs_path}\"\n\n    except Exception as e:\n        return f\"File write error: {str(e)}\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.CodingAgent.live.VirtualEnvContext","title":"<code>VirtualEnvContext</code>","text":"<p>Context manager for temporary virtual environment activation</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>class VirtualEnvContext:\n    \"\"\"Context manager for temporary virtual environment activation\"\"\"\n\n    def __init__(self, venv_path: Path):\n        self.venv_path = venv_path\n        self._original_path = None\n        self._original_sys_path = None\n        self._original_prefix = None\n        self._original_virtual_env = None\n\n    def _get_venv_paths(self):\n        \"\"\"Get virtual environment paths based on platform\"\"\"\n        if sys.platform == 'win32':\n            site_packages = self.venv_path / 'Lib' / 'site-packages'\n            scripts_dir = self.venv_path / 'Scripts'\n            python_path = scripts_dir / 'python.exe'\n        else:\n            python_version = f'python{sys.version_info.major}.{sys.version_info.minor}'\n            site_packages = self.venv_path / 'lib' / python_version / 'site-packages'\n            scripts_dir = self.venv_path / 'bin'\n            python_path = scripts_dir / 'python'\n\n        return site_packages, scripts_dir, python_path\n\n    def __enter__(self):\n        # Save original state\n        self._original_path = os.environ.get('PATH', '')\n        self._original_sys_path = sys.path.copy()\n        self._original_prefix = sys.prefix\n        self._original_virtual_env = os.environ.get('VIRTUAL_ENV')\n\n        # Get venv paths\n        site_packages, scripts_dir, python_path = self._get_venv_paths()\n\n        # Modify environment for venv\n        if scripts_dir.exists():\n            new_path = os.pathsep.join([str(scripts_dir), self._original_path])\n            os.environ['PATH'] = new_path\n\n        if site_packages.exists():\n            sys.path.insert(0, str(site_packages))\n\n        os.environ['VIRTUAL_ENV'] = str(self.venv_path)\n\n        # Return the python executable path for potential subprocess calls\n        return str(python_path)\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        # Restore original state\n        os.environ['PATH'] = self._original_path\n        sys.path = self._original_sys_path\n\n        if self._original_virtual_env is None:\n            os.environ.pop('VIRTUAL_ENV', None)\n        else:\n            os.environ['VIRTUAL_ENV'] = self._original_virtual_env\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.CodingAgent.live.VirtualFileSystem","title":"<code>VirtualFileSystem</code>","text":"Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>class VirtualFileSystem:\n    def __init__(self, base_dir: Path):\n        self.base_dir = base_dir\n        self.current_dir = base_dir\n        self.virtual_files: dict[str, str] = {}\n        self.base_dir.mkdir(parents=True, exist_ok=True)\n\n    def write_file(self, filepath: str | Path, content: str) -&gt; Path:\n        \"\"\"Write content to a virtual file and persist to disk using UTF-8\"\"\"\n        try:\n            abs_path = self._resolve_path(filepath)\n        except ValueError:\n            print(\"invalid :\", filepath)\n            filepath = \"src/temp_js/_temp_fix.py\"\n            abs_path = self._resolve_path(filepath)\n        abs_path.parent.mkdir(parents=True, exist_ok=True)\n\n        # Store in virtual filesystem\n        rel_path = str(abs_path.relative_to(self.base_dir))\n        self.virtual_files[rel_path] = content\n\n        # Write to actual filesystem with UTF-8 encoding\n        with open(abs_path, 'w', encoding='utf-8', errors='replace') as f:\n            f.write(content)\n\n        return abs_path\n\n    def read_file(self, filepath: str | Path) -&gt; str:\n        \"\"\"Read content from a virtual file using UTF-8\"\"\"\n        abs_path = self._resolve_path(filepath)\n        if not abs_path.exists():\n            raise FileNotFoundError(f\"File not found: {filepath}\")\n\n        rel_path = str(abs_path.relative_to(self.base_dir))\n\n        # Check virtual filesystem first\n        if rel_path in self.virtual_files:\n            return self.virtual_files[rel_path]\n\n        # Fall back to reading from disk with UTF-8 encoding\n        with open(abs_path, encoding='utf-8', errors='replace') as f:\n            content = f.read()\n            self.virtual_files[rel_path] = content\n            return content\n\n    def delete_file(self, filepath: str | Path):\n        \"\"\"Delete a virtual file\"\"\"\n        abs_path = self._resolve_path(filepath)\n        rel_path = str(abs_path.relative_to(self.base_dir))\n\n        if rel_path in self.virtual_files:\n            del self.virtual_files[rel_path]\n\n        if abs_path.exists():\n            abs_path.unlink()\n\n    def create_directory(self, dirpath: str | Path):\n        \"\"\"Create a new directory\"\"\"\n        abs_path = self._resolve_path(dirpath)\n        abs_path.mkdir(parents=True, exist_ok=True)\n        return abs_path\n\n\n    def list_directory(self, dirpath: str | Path = '.') -&gt; list:\n        \"\"\"List contents of a directory\"\"\"\n        abs_path = self._resolve_path(dirpath)\n        if not abs_path.exists():\n            raise FileNotFoundError(f\"Directory not found: {dirpath}\")\n        return [p.name for p in abs_path.iterdir()]\n\n    def change_directory(self, dirpath: str | Path):\n        \"\"\"Change current working directory\"\"\"\n        new_dir = self._resolve_path(dirpath)\n        if not new_dir.exists() or not new_dir.is_dir():\n            raise NotADirectoryError(f\"Directory not found: {dirpath}\")\n        self.current_dir = new_dir\n\n    def _resolve_path(self, filepath: str | Path) -&gt; Path:\n        \"\"\"Convert relative path to absolute path\"\"\"\n        filepath = Path(filepath)\n        if filepath.is_absolute():\n            if not str(filepath).startswith(str(self.base_dir)):\n                raise ValueError(\"Path must be within base directory\")\n            return filepath\n        return (self.current_dir / filepath).resolve()\n\n    def save_state(self, state_file: Path):\n        \"\"\"Save virtual filesystem state to disk\"\"\"\n        state = {\n            'current_dir': str(self.current_dir.relative_to(self.base_dir)),\n            'virtual_files': self.virtual_files\n        }\n        with open(state_file, 'w') as f:\n            json.dump(state, f)\n\n    def load_state(self, state_file: Path):\n        \"\"\"Load virtual filesystem state from disk\"\"\"\n        if not state_file.exists():\n            return\n\n        with open(state_file) as f:\n            state = json.load(f)\n            self.current_dir = self.base_dir / state['current_dir']\n            self.virtual_files = state['virtual_files']\n\n    def print_file_structure(self, start_path: str | Path = '.', indent: str = ''):\n        \"\"\"Print the file structure starting from the given path\"\"\"\n        start_path = self._resolve_path(start_path)\n        if not start_path.exists():\n            s = f\"Path not found: {start_path}\"\n            return s\n\n        s = f\"{indent}{start_path.name}/\"\n        for item in sorted(start_path.iterdir()):\n            if item.is_dir():\n               s+= self.print_file_structure(item, indent + '  ')\n            else:\n                s = f\"{indent}  {item.name}\"\n        return s\n</code></pre> <code>change_directory(dirpath)</code> \u00b6 <p>Change current working directory</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>def change_directory(self, dirpath: str | Path):\n    \"\"\"Change current working directory\"\"\"\n    new_dir = self._resolve_path(dirpath)\n    if not new_dir.exists() or not new_dir.is_dir():\n        raise NotADirectoryError(f\"Directory not found: {dirpath}\")\n    self.current_dir = new_dir\n</code></pre> <code>create_directory(dirpath)</code> \u00b6 <p>Create a new directory</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>def create_directory(self, dirpath: str | Path):\n    \"\"\"Create a new directory\"\"\"\n    abs_path = self._resolve_path(dirpath)\n    abs_path.mkdir(parents=True, exist_ok=True)\n    return abs_path\n</code></pre> <code>delete_file(filepath)</code> \u00b6 <p>Delete a virtual file</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>def delete_file(self, filepath: str | Path):\n    \"\"\"Delete a virtual file\"\"\"\n    abs_path = self._resolve_path(filepath)\n    rel_path = str(abs_path.relative_to(self.base_dir))\n\n    if rel_path in self.virtual_files:\n        del self.virtual_files[rel_path]\n\n    if abs_path.exists():\n        abs_path.unlink()\n</code></pre> <code>list_directory(dirpath='.')</code> \u00b6 <p>List contents of a directory</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>def list_directory(self, dirpath: str | Path = '.') -&gt; list:\n    \"\"\"List contents of a directory\"\"\"\n    abs_path = self._resolve_path(dirpath)\n    if not abs_path.exists():\n        raise FileNotFoundError(f\"Directory not found: {dirpath}\")\n    return [p.name for p in abs_path.iterdir()]\n</code></pre> <code>load_state(state_file)</code> \u00b6 <p>Load virtual filesystem state from disk</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>def load_state(self, state_file: Path):\n    \"\"\"Load virtual filesystem state from disk\"\"\"\n    if not state_file.exists():\n        return\n\n    with open(state_file) as f:\n        state = json.load(f)\n        self.current_dir = self.base_dir / state['current_dir']\n        self.virtual_files = state['virtual_files']\n</code></pre> <code>print_file_structure(start_path='.', indent='')</code> \u00b6 <p>Print the file structure starting from the given path</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>def print_file_structure(self, start_path: str | Path = '.', indent: str = ''):\n    \"\"\"Print the file structure starting from the given path\"\"\"\n    start_path = self._resolve_path(start_path)\n    if not start_path.exists():\n        s = f\"Path not found: {start_path}\"\n        return s\n\n    s = f\"{indent}{start_path.name}/\"\n    for item in sorted(start_path.iterdir()):\n        if item.is_dir():\n           s+= self.print_file_structure(item, indent + '  ')\n        else:\n            s = f\"{indent}  {item.name}\"\n    return s\n</code></pre> <code>read_file(filepath)</code> \u00b6 <p>Read content from a virtual file using UTF-8</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>def read_file(self, filepath: str | Path) -&gt; str:\n    \"\"\"Read content from a virtual file using UTF-8\"\"\"\n    abs_path = self._resolve_path(filepath)\n    if not abs_path.exists():\n        raise FileNotFoundError(f\"File not found: {filepath}\")\n\n    rel_path = str(abs_path.relative_to(self.base_dir))\n\n    # Check virtual filesystem first\n    if rel_path in self.virtual_files:\n        return self.virtual_files[rel_path]\n\n    # Fall back to reading from disk with UTF-8 encoding\n    with open(abs_path, encoding='utf-8', errors='replace') as f:\n        content = f.read()\n        self.virtual_files[rel_path] = content\n        return content\n</code></pre> <code>save_state(state_file)</code> \u00b6 <p>Save virtual filesystem state to disk</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>def save_state(self, state_file: Path):\n    \"\"\"Save virtual filesystem state to disk\"\"\"\n    state = {\n        'current_dir': str(self.current_dir.relative_to(self.base_dir)),\n        'virtual_files': self.virtual_files\n    }\n    with open(state_file, 'w') as f:\n        json.dump(state, f)\n</code></pre> <code>write_file(filepath, content)</code> \u00b6 <p>Write content to a virtual file and persist to disk using UTF-8</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>def write_file(self, filepath: str | Path, content: str) -&gt; Path:\n    \"\"\"Write content to a virtual file and persist to disk using UTF-8\"\"\"\n    try:\n        abs_path = self._resolve_path(filepath)\n    except ValueError:\n        print(\"invalid :\", filepath)\n        filepath = \"src/temp_js/_temp_fix.py\"\n        abs_path = self._resolve_path(filepath)\n    abs_path.parent.mkdir(parents=True, exist_ok=True)\n\n    # Store in virtual filesystem\n    rel_path = str(abs_path.relative_to(self.base_dir))\n    self.virtual_files[rel_path] = content\n\n    # Write to actual filesystem with UTF-8 encoding\n    with open(abs_path, 'w', encoding='utf-8', errors='replace') as f:\n        f.write(content)\n\n    return abs_path\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.CodingAgent.live.auto_install","title":"<code>auto_install(package_name, install_method='pip', upgrade=False, quiet=False, version=None, extra_args=None)</code>","text":"<p>Enhanced auto-save import with version and extra arguments support</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>def auto_install(package_name, install_method='pip', upgrade=False, quiet=False, version=None, extra_args=None):\n    '''\n    Enhanced auto-save import with version and extra arguments support\n    '''\n    try:\n        # Attempt to import the package\n        return importlib.import_module(package_name)\n    except ImportError:\n        # Package not found, prepare for installation\n        print(f\"Package '{package_name}' not found. Attempting to install...\")\n        try:\n            # Determine Python executable based on virtual environment\n            venv_path = os.environ.get('VIRTUAL_ENV')\n            if venv_path:\n                venv_path = Path(venv_path)\n                if sys.platform == 'win32':\n                    python_exec = str(venv_path / 'Scripts' / 'python.exe')\n                else:\n                    python_exec = str(venv_path / 'bin' / 'python')\n                # Check if the Python executable exists\n                if not Path(python_exec).exists():\n                    python_exec = sys.executable\n            else:\n                python_exec = sys.executable\n\n            # Construct installation command with more flexibility\n            install_cmd = [python_exec, \"-m\", install_method, \"install\"]\n            if upgrade:\n                install_cmd.append(\"--upgrade\")\n            # Support specific version installation\n            if version:\n                install_cmd.append(f\"{package_name}=={version}\")\n            else:\n                install_cmd.append(package_name)\n            # Add extra arguments if provided\n            if extra_args:\n                install_cmd.extend(extra_args)\n            # Run installation with appropriate verbosity\n            installation_output = subprocess.run(\n                install_cmd,\n                capture_output=quiet,\n                text=True\n            )\n            # Check installation status\n            if installation_output.returncode == 0:\n                print(f\"Successfully installed {package_name}\")\n                return importlib.import_module(package_name)\n            else:\n                raise Exception(f\"Installation failed: {installation_output.stderr}\")\n        except Exception as install_error:\n            print(f\"Error installing {package_name}: {install_error}\")\n            return None\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.CodingAgent.live.sync_globals_to_vars","title":"<code>sync_globals_to_vars(pipeline, namespace=None, prefix=None, include_types=None, exclude_patterns=None, exclude_private=True, deep_copy=False, only_serializable=False)</code>","text":"<pre><code>Sync global variables or a specific namespace to pipeline variables.\n\nArgs:\n    pipeline: Pipeline instance to sync variables to\n    namespace: Optional dictionary of variables (defaults to globals())\n    prefix: Optional prefix for variable names (e.g., 'global_')\n    include_types: Only include variables of these types\n    exclude_patterns: List of regex patterns to exclude\n    exclude_private: Exclude variables starting with underscore\n    deep_copy: Create deep copies of variables instead of references\n    only_serializable: Only include variables that can be serialized\n\nReturns:\n    SyncReport with details about added, skipped and error variables\n\nUsage example:\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.CodingAgent.live.sync_globals_to_vars--basic-usage-sync-all-globals","title":"Basic usage - sync all globals","text":"<p>report = sync_globals_to_vars(pipeline)</p>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.CodingAgent.live.sync_globals_to_vars--sync-only-numeric-types-with-prefix","title":"Sync only numeric types with prefix","text":"<p>report = sync_globals_to_vars(     pipeline,     include_types=[int, float],     prefix=\"global_\" )</p>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.CodingAgent.live.sync_globals_to_vars--sync-from-specific-namespace","title":"Sync from specific namespace","text":"<p>import numpy as np namespace = {\"arr\": np.array([1,2,3])} report = sync_globals_to_vars(pipeline, namespace=namespace)</p>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.CodingAgent.live.sync_globals_to_vars--sync-with-deep-copy-and-serialization-check","title":"Sync with deep copy and serialization check","text":"<p>report = sync_globals_to_vars(     pipeline,     deep_copy=True,     only_serializable=True )</p> Source code in <code>toolboxv2/mods/isaa/CodingAgent/live.py</code> <pre><code>def sync_globals_to_vars(\n    pipeline: Any,\n    namespace: dict[str, Any] | None = None,\n    prefix: str | None = None,\n    include_types: type | list[type] | None = None,\n    exclude_patterns: list[str] | None = None,\n    exclude_private: bool = True,\n    deep_copy: bool = False,\n    only_serializable: bool = False\n) -&gt; SyncReport:\n    \"\"\"\n    Sync global variables or a specific namespace to pipeline variables.\n\n    Args:\n        pipeline: Pipeline instance to sync variables to\n        namespace: Optional dictionary of variables (defaults to globals())\n        prefix: Optional prefix for variable names (e.g., 'global_')\n        include_types: Only include variables of these types\n        exclude_patterns: List of regex patterns to exclude\n        exclude_private: Exclude variables starting with underscore\n        deep_copy: Create deep copies of variables instead of references\n        only_serializable: Only include variables that can be serialized\n\n    Returns:\n        SyncReport with details about added, skipped and error variables\n\n    Usage example:\n# Basic usage - sync all globals\nreport = sync_globals_to_vars(pipeline)\n\n# Sync only numeric types with prefix\nreport = sync_globals_to_vars(\n    pipeline,\n    include_types=[int, float],\n    prefix=\"global_\"\n)\n\n# Sync from specific namespace\nimport numpy as np\nnamespace = {\"arr\": np.array([1,2,3])}\nreport = sync_globals_to_vars(pipeline, namespace=namespace)\n\n# Sync with deep copy and serialization check\nreport = sync_globals_to_vars(\n    pipeline,\n    deep_copy=True,\n    only_serializable=True\n)\n    \"\"\"\n    # Initialize report\n    report = SyncReport(\n        added={},\n        skipped={},\n        errors={}\n    )\n\n    # Get namespace\n    if namespace is None:\n        # Get caller's globals\n        namespace = currentframe().f_back.f_globals\n\n    # Compile exclude patterns\n    if exclude_patterns:\n        patterns = [re.compile(pattern) for pattern in exclude_patterns]\n    else:\n        patterns = []\n\n    # Normalize include_types\n    if include_types and not isinstance(include_types, list | tuple | set):\n        include_types = [include_types]\n    def get_type_info(var: Any) -&gt; str:\n        \"\"\"Helper to get detailed type information\"\"\"\n        if isinstance(var, type):\n            return f\"class '{var.__name__}'\"\n        elif isinstance(var, BaseModel):\n            return f\"Pydantic model '{var.__class__.__name__}'\"\n        elif hasattr(var, '__class__'):\n            type_name = var.__class__.__name__\n            module_name = var.__class__.__module__\n            if module_name != 'builtins':\n                return f\"{module_name}.{type_name}\"\n            return type_name\n        return type(var).__name__\n    # Process each variable\n    for name, value in namespace.items():\n        try:\n            # Skip if matches exclude criteria\n            if exclude_private and name.startswith('_'):\n                report.skipped[name] = \"private variable\"\n                continue\n\n            if any(pattern.match(name) for pattern in patterns):\n                report.skipped[name] = \"matched exclude pattern\"\n                continue\n\n            if include_types and not isinstance(value, tuple(include_types)):\n                report.skipped[name] = f\"type {type(value).__name__} not in include_types\"\n                continue\n\n            # Test serialization if required\n            if only_serializable:\n                try:\n                    import pickle\n                    pickle.dumps(value)\n                except Exception as e:\n                    report.skipped[name] = f\"not serializable: {str(e)}\"\n                    continue\n\n            # Prepare variable\n            var_value = deepcopy(value) if deep_copy else value\n            var_name = f\"{prefix}{name}\" if prefix else name\n\n            # Add to pipeline variables\n            pipeline.variables[var_name] = var_value\n            report.added[var_name] = get_type_info(value)\n\n        except Exception as e:\n            report.errors[name] = str(e)\n\n    return report\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base","title":"<code>base</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.Agent","title":"<code>Agent</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.Agent.agent","title":"<code>agent</code>","text":"<code>AgentCheckpoint</code> <code>dataclass</code> \u00b6 <p>Enhanced AgentCheckpoint with UnifiedContextManager and ChatSession integration</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>@dataclass\nclass AgentCheckpoint:\n    \"\"\"Enhanced AgentCheckpoint with UnifiedContextManager and ChatSession integration\"\"\"\n    timestamp: datetime\n    agent_state: dict[str, Any]\n    task_state: dict[str, Any]\n    world_model: dict[str, Any]\n    active_flows: list[str]\n    metadata: dict[str, Any] = field(default_factory=dict)\n\n    # NEUE: Enhanced checkpoint data for UnifiedContextManager integration\n    session_data: dict[str, Any] = field(default_factory=dict)\n    context_manager_state: dict[str, Any] = field(default_factory=dict)\n    conversation_history: list[dict[str, Any]] = field(default_factory=list)\n    variable_system_state: dict[str, Any] = field(default_factory=dict)\n    results_store: dict[str, Any] = field(default_factory=dict)\n    tool_capabilities: dict[str, Any] = field(default_factory=dict)\n    variable_scopes: dict[str, Any] = field(default_factory=dict)\n\n    # Optional: Additional system state\n    performance_metrics: dict[str, Any] = field(default_factory=dict)\n    execution_history: list[dict[str, Any]] = field(default_factory=list)\n\n    def get_checkpoint_summary(self) -&gt; str:\n        \"\"\"Get human-readable checkpoint summary\"\"\"\n        try:\n            summary_parts = []\n\n            # Basic info\n            if self.session_data:\n                session_count = len([s for s in self.session_data.values() if s.get(\"status\") != \"failed\"])\n                summary_parts.append(f\"{session_count} sessions\")\n\n            # Task info\n            if self.task_state:\n                completed_tasks = len([t for t in self.task_state.values() if t.get(\"status\") == \"completed\"])\n                total_tasks = len(self.task_state)\n                summary_parts.append(f\"{completed_tasks}/{total_tasks} tasks\")\n\n            # Conversation info\n            if self.conversation_history:\n                summary_parts.append(f\"{len(self.conversation_history)} messages\")\n\n            # Context info\n            if self.context_manager_state:\n                cache_count = self.context_manager_state.get(\"cache_entries\", 0)\n                if cache_count &gt; 0:\n                    summary_parts.append(f\"{cache_count} cached contexts\")\n\n            # Variable system info\n            if self.variable_system_state:\n                scopes = len(self.variable_system_state.get(\"scopes\", {}))\n                summary_parts.append(f\"{scopes} variable scopes\")\n\n            # Tool capabilities\n            if self.tool_capabilities:\n                summary_parts.append(f\"{len(self.tool_capabilities)} analyzed tools\")\n\n            return \"; \".join(summary_parts) if summary_parts else \"Basic checkpoint\"\n\n        except Exception as e:\n            return f\"Summary generation failed: {str(e)}\"\n\n    def get_storage_size_estimate(self) -&gt; dict[str, int]:\n        \"\"\"Estimate storage size of different checkpoint components\"\"\"\n        try:\n            sizes = {}\n\n            # Calculate sizes in bytes (approximate)\n            sizes[\"agent_state\"] = len(str(self.agent_state))\n            sizes[\"task_state\"] = len(str(self.task_state))\n            sizes[\"world_model\"] = len(str(self.world_model))\n            sizes[\"conversation_history\"] = len(str(self.conversation_history))\n            sizes[\"session_data\"] = len(str(self.session_data))\n            sizes[\"context_manager_state\"] = len(str(self.context_manager_state))\n            sizes[\"variable_system_state\"] = len(str(self.variable_system_state))\n            sizes[\"results_store\"] = len(str(self.results_store))\n            sizes[\"tool_capabilities\"] = len(str(self.tool_capabilities))\n\n            sizes[\"total_bytes\"] = sum(sizes.values())\n            sizes[\"total_kb\"] = sizes[\"total_bytes\"] / 1024\n            sizes[\"total_mb\"] = sizes[\"total_kb\"] / 1024\n\n            return sizes\n\n        except Exception as e:\n            return {\"error\": str(e)}\n\n    def validate_checkpoint_integrity(self) -&gt; dict[str, Any]:\n        \"\"\"Validate checkpoint integrity and completeness\"\"\"\n        validation = {\n            \"is_valid\": True,\n            \"errors\": [],\n            \"warnings\": [],\n            \"completeness_score\": 0.0,\n            \"components_present\": []\n        }\n\n        try:\n            # Check required components\n            required_components = [\"timestamp\", \"agent_state\", \"task_state\", \"world_model\", \"active_flows\"]\n            for component in required_components:\n                if hasattr(self, component) and getattr(self, component) is not None:\n                    validation[\"components_present\"].append(component)\n                else:\n                    validation[\"errors\"].append(f\"Missing required component: {component}\")\n                    validation[\"is_valid\"] = False\n\n            # Check optional enhanced components\n            enhanced_components = [\"session_data\", \"context_manager_state\", \"conversation_history\",\n                                   \"variable_system_state\", \"results_store\", \"tool_capabilities\"]\n\n            for component in enhanced_components:\n                if hasattr(self, component) and getattr(self, component):\n                    validation[\"components_present\"].append(component)\n\n            # Calculate completeness score\n            total_possible = len(required_components) + len(enhanced_components)\n            validation[\"completeness_score\"] = len(validation[\"components_present\"]) / total_possible\n\n            # Check timestamp validity\n            if isinstance(self.timestamp, datetime):\n                age_hours = (datetime.now() - self.timestamp).total_seconds() / 3600\n                if age_hours &gt; 24:\n                    validation[\"warnings\"].append(f\"Checkpoint is {age_hours:.1f} hours old\")\n            else:\n                validation[\"errors\"].append(\"Invalid timestamp format\")\n                validation[\"is_valid\"] = False\n\n            # Check session data consistency\n            if self.session_data and self.conversation_history:\n                session_ids_in_data = set(self.session_data.keys())\n                session_ids_in_conversation = set(\n                    msg.get(\"session_id\") for msg in self.conversation_history\n                    if msg.get(\"session_id\")\n                )\n\n                if session_ids_in_data != session_ids_in_conversation:\n                    validation[\"warnings\"].append(\"Session data and conversation history session IDs don't match\")\n\n            return validation\n\n        except Exception as e:\n            validation[\"errors\"].append(f\"Validation error: {str(e)}\")\n            validation[\"is_valid\"] = False\n            return validation\n\n    def get_version_info(self) -&gt; dict[str, str]:\n        \"\"\"Get checkpoint version information\"\"\"\n        return {\n            \"checkpoint_version\": self.metadata.get(\"checkpoint_version\", \"1.0\"),\n            \"data_format\": \"enhanced\" if self.session_data or self.context_manager_state else \"basic\",\n            \"context_system\": \"unified\" if self.context_manager_state else \"legacy\",\n            \"variable_system\": \"integrated\" if self.variable_system_state else \"basic\",\n            \"session_management\": \"chatsession\" if self.session_data else \"memory_only\",\n            \"created_with\": \"FlowAgent v2.0 Enhanced Context System\"\n        }\n</code></pre> <code>get_checkpoint_summary()</code> \u00b6 <p>Get human-readable checkpoint summary</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def get_checkpoint_summary(self) -&gt; str:\n    \"\"\"Get human-readable checkpoint summary\"\"\"\n    try:\n        summary_parts = []\n\n        # Basic info\n        if self.session_data:\n            session_count = len([s for s in self.session_data.values() if s.get(\"status\") != \"failed\"])\n            summary_parts.append(f\"{session_count} sessions\")\n\n        # Task info\n        if self.task_state:\n            completed_tasks = len([t for t in self.task_state.values() if t.get(\"status\") == \"completed\"])\n            total_tasks = len(self.task_state)\n            summary_parts.append(f\"{completed_tasks}/{total_tasks} tasks\")\n\n        # Conversation info\n        if self.conversation_history:\n            summary_parts.append(f\"{len(self.conversation_history)} messages\")\n\n        # Context info\n        if self.context_manager_state:\n            cache_count = self.context_manager_state.get(\"cache_entries\", 0)\n            if cache_count &gt; 0:\n                summary_parts.append(f\"{cache_count} cached contexts\")\n\n        # Variable system info\n        if self.variable_system_state:\n            scopes = len(self.variable_system_state.get(\"scopes\", {}))\n            summary_parts.append(f\"{scopes} variable scopes\")\n\n        # Tool capabilities\n        if self.tool_capabilities:\n            summary_parts.append(f\"{len(self.tool_capabilities)} analyzed tools\")\n\n        return \"; \".join(summary_parts) if summary_parts else \"Basic checkpoint\"\n\n    except Exception as e:\n        return f\"Summary generation failed: {str(e)}\"\n</code></pre> <code>get_storage_size_estimate()</code> \u00b6 <p>Estimate storage size of different checkpoint components</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def get_storage_size_estimate(self) -&gt; dict[str, int]:\n    \"\"\"Estimate storage size of different checkpoint components\"\"\"\n    try:\n        sizes = {}\n\n        # Calculate sizes in bytes (approximate)\n        sizes[\"agent_state\"] = len(str(self.agent_state))\n        sizes[\"task_state\"] = len(str(self.task_state))\n        sizes[\"world_model\"] = len(str(self.world_model))\n        sizes[\"conversation_history\"] = len(str(self.conversation_history))\n        sizes[\"session_data\"] = len(str(self.session_data))\n        sizes[\"context_manager_state\"] = len(str(self.context_manager_state))\n        sizes[\"variable_system_state\"] = len(str(self.variable_system_state))\n        sizes[\"results_store\"] = len(str(self.results_store))\n        sizes[\"tool_capabilities\"] = len(str(self.tool_capabilities))\n\n        sizes[\"total_bytes\"] = sum(sizes.values())\n        sizes[\"total_kb\"] = sizes[\"total_bytes\"] / 1024\n        sizes[\"total_mb\"] = sizes[\"total_kb\"] / 1024\n\n        return sizes\n\n    except Exception as e:\n        return {\"error\": str(e)}\n</code></pre> <code>get_version_info()</code> \u00b6 <p>Get checkpoint version information</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def get_version_info(self) -&gt; dict[str, str]:\n    \"\"\"Get checkpoint version information\"\"\"\n    return {\n        \"checkpoint_version\": self.metadata.get(\"checkpoint_version\", \"1.0\"),\n        \"data_format\": \"enhanced\" if self.session_data or self.context_manager_state else \"basic\",\n        \"context_system\": \"unified\" if self.context_manager_state else \"legacy\",\n        \"variable_system\": \"integrated\" if self.variable_system_state else \"basic\",\n        \"session_management\": \"chatsession\" if self.session_data else \"memory_only\",\n        \"created_with\": \"FlowAgent v2.0 Enhanced Context System\"\n    }\n</code></pre> <code>validate_checkpoint_integrity()</code> \u00b6 <p>Validate checkpoint integrity and completeness</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def validate_checkpoint_integrity(self) -&gt; dict[str, Any]:\n    \"\"\"Validate checkpoint integrity and completeness\"\"\"\n    validation = {\n        \"is_valid\": True,\n        \"errors\": [],\n        \"warnings\": [],\n        \"completeness_score\": 0.0,\n        \"components_present\": []\n    }\n\n    try:\n        # Check required components\n        required_components = [\"timestamp\", \"agent_state\", \"task_state\", \"world_model\", \"active_flows\"]\n        for component in required_components:\n            if hasattr(self, component) and getattr(self, component) is not None:\n                validation[\"components_present\"].append(component)\n            else:\n                validation[\"errors\"].append(f\"Missing required component: {component}\")\n                validation[\"is_valid\"] = False\n\n        # Check optional enhanced components\n        enhanced_components = [\"session_data\", \"context_manager_state\", \"conversation_history\",\n                               \"variable_system_state\", \"results_store\", \"tool_capabilities\"]\n\n        for component in enhanced_components:\n            if hasattr(self, component) and getattr(self, component):\n                validation[\"components_present\"].append(component)\n\n        # Calculate completeness score\n        total_possible = len(required_components) + len(enhanced_components)\n        validation[\"completeness_score\"] = len(validation[\"components_present\"]) / total_possible\n\n        # Check timestamp validity\n        if isinstance(self.timestamp, datetime):\n            age_hours = (datetime.now() - self.timestamp).total_seconds() / 3600\n            if age_hours &gt; 24:\n                validation[\"warnings\"].append(f\"Checkpoint is {age_hours:.1f} hours old\")\n        else:\n            validation[\"errors\"].append(\"Invalid timestamp format\")\n            validation[\"is_valid\"] = False\n\n        # Check session data consistency\n        if self.session_data and self.conversation_history:\n            session_ids_in_data = set(self.session_data.keys())\n            session_ids_in_conversation = set(\n                msg.get(\"session_id\") for msg in self.conversation_history\n                if msg.get(\"session_id\")\n            )\n\n            if session_ids_in_data != session_ids_in_conversation:\n                validation[\"warnings\"].append(\"Session data and conversation history session IDs don't match\")\n\n        return validation\n\n    except Exception as e:\n        validation[\"errors\"].append(f\"Validation error: {str(e)}\")\n        validation[\"is_valid\"] = False\n        return validation\n</code></pre> <code>AgentModelData</code> \u00b6 <p>               Bases: <code>BaseModel</code></p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>class AgentModelData(BaseModel):\n    name: str = \"FlowAgent\"\n    fast_llm_model: str = \"openrouter/anthropic/claude-3-haiku\"\n    complex_llm_model: str = \"openrouter/openai/gpt-4o\"\n    system_message: str = \"You are a production-ready autonomous agent.\"\n    temperature: float = 0.7\n    max_tokens: int = 2048\n    max_input_tokens: int = 32768\n    api_key: str | None  = None\n    api_base: str | None  = None\n    budget_manager: Any  = None\n    caching: bool = True\n    persona: PersonaConfig | None = True\n    use_fast_response: bool = True\n\n    def get_system_message_with_persona(self) -&gt; str:\n        \"\"\"Get system message with persona integration\"\"\"\n        base_message = self.system_message\n\n        if self.persona and self.persona.apply_method in [\"system_prompt\", \"both\"]:\n            persona_addition = self.persona.to_system_prompt_addition()\n            if persona_addition:\n                base_message += f\"\\n## Persona Instructions\\n{persona_addition}\"\n\n        return base_message\n</code></pre> <code>get_system_message_with_persona()</code> \u00b6 <p>Get system message with persona integration</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def get_system_message_with_persona(self) -&gt; str:\n    \"\"\"Get system message with persona integration\"\"\"\n    base_message = self.system_message\n\n    if self.persona and self.persona.apply_method in [\"system_prompt\", \"both\"]:\n        persona_addition = self.persona.to_system_prompt_addition()\n        if persona_addition:\n            base_message += f\"\\n## Persona Instructions\\n{persona_addition}\"\n\n    return base_message\n</code></pre> <code>ChainMetadata</code> <code>dataclass</code> \u00b6 <p>Metadata for stored chains</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>@dataclass\nclass ChainMetadata:\n    \"\"\"Metadata for stored chains\"\"\"\n    name: str\n    description: str = \"\"\n    created_at: datetime = field(default_factory=datetime.now)\n    modified_at: datetime = field(default_factory=datetime.now)\n    version: str = \"1.0.0\"\n    tags: list[str] = field(default_factory=list)\n    author: str = \"\"\n    complexity: str = \"simple\"  # simple, medium, complex\n    agent_count: int = 0\n    has_conditionals: bool = False\n    has_parallels: bool = False\n    has_error_handling: bool = False\n</code></pre> <code>CompletionCheckerNode</code> \u00b6 <p>               Bases: <code>AsyncNode</code></p> <p>Breaks infinite cycles by checking actual completion status</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>@with_progress_tracking\nclass CompletionCheckerNode(AsyncNode):\n    \"\"\"Breaks infinite cycles by checking actual completion status\"\"\"\n\n    def __init__(self):\n        super().__init__()\n        self.execution_count = 0\n        self.max_cycles = 5  # Prevent infinite loops\n\n    async def prep_async(self, shared):\n        current_plan = shared.get(\"current_plan\")\n        tasks = shared.get(\"tasks\", {})\n\n        return {\n            \"current_plan\": current_plan,\n            \"tasks\": tasks,\n            \"execution_count\": self.execution_count\n        }\n\n    async def exec_async(self, prep_res):\n        self.execution_count += 1\n\n        # Safety check: prevent infinite loops\n        if self.execution_count &gt; self.max_cycles:\n            wprint(f\"Max execution cycles ({self.max_cycles}) reached, terminating\")\n            return {\n                \"action\": \"force_terminate\",\n                \"reason\": \"Max cycles reached\"\n            }\n\n        current_plan = prep_res[\"current_plan\"]\n        tasks = prep_res[\"tasks\"]\n\n        if not current_plan:\n            return {\"action\": \"truly_complete\", \"reason\": \"No active plan\"}\n\n        # Check actual completion status\n        pending_tasks = [t for t in current_plan.tasks if tasks[t.id].status == \"pending\"]\n        running_tasks = [t for t in current_plan.tasks if tasks[t.id].status == \"running\"]\n        completed_tasks = [t for t in current_plan.tasks if tasks[t.id].status == \"completed\"]\n        failed_tasks = [t for t in current_plan.tasks if tasks[t.id].status == \"failed\"]\n\n        total_tasks = len(current_plan.tasks)\n\n        # Truly complete: all tasks done\n        if len(completed_tasks) + len(failed_tasks) == total_tasks:\n            if len(failed_tasks) == 0 or len(completed_tasks) &gt; len(failed_tasks):\n                return {\"action\": \"truly_complete\", \"reason\": \"All tasks completed\"}\n            else:\n                return {\"action\": \"truly_complete\", \"reason\": \"Plan failed but cannot continue\"}\n\n        # Has pending tasks that can run\n        if pending_tasks and not running_tasks:\n            return {\"action\": \"continue_execution\", \"reason\": f\"{len(pending_tasks)} tasks ready\"}\n\n        # Has running tasks, wait\n        if running_tasks:\n            return {\"action\": \"continue_execution\", \"reason\": f\"{len(running_tasks)} tasks running\"}\n\n        # Need reflection if tasks are stuck\n        if pending_tasks and not running_tasks:\n            return {\"action\": \"needs_reflection\", \"reason\": \"Tasks may be blocked\"}\n\n        # Default: we're done\n        return {\"action\": \"truly_complete\", \"reason\": \"No actionable tasks\"}\n\n    async def post_async(self, shared, prep_res, exec_res):\n        action = exec_res[\"action\"]\n\n        # Reset counter on true completion\n        if action == \"truly_complete\":\n            self.execution_count = 0\n            shared[\"flow_completion_reason\"] = exec_res[\"reason\"]\n        elif action == \"force_terminate\":  # HINZUGEF\u00dcGT\n            self.execution_count = 0\n            shared[\"flow_completion_reason\"] = f\"Force terminated: {exec_res['reason']}\"\n            shared[\"force_terminated\"] = True\n            wprint(f\"Flow force terminated: {exec_res['reason']}\")\n\n        return action\n</code></pre> <code>ContextAggregatorNode</code> \u00b6 <p>               Bases: <code>AsyncNode</code></p> <p>Vereinfachte Context-Aggregation \u00fcber UnifiedContextManager</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>@with_progress_tracking\nclass ContextAggregatorNode(AsyncNode):\n    \"\"\"Vereinfachte Context-Aggregation \u00fcber UnifiedContextManager\"\"\"\n\n    async def prep_async(self, shared):\n        \"\"\"Simplified preparation - delegate to UnifiedContextManager\"\"\"\n        return {\n            \"context_manager\": shared.get(\"context_manager\"),\n            \"session_id\": shared.get(\"session_id\", \"default\"),\n            \"original_query\": shared.get(\"current_query\", \"\"),\n            \"tasks\": shared.get(\"tasks\", {}),\n            \"current_plan\": shared.get(\"current_plan\"),\n            \"world_model\": shared.get(\"world_model\", {}),\n            \"results\": shared.get(\"results\", {})\n        }\n\n    async def exec_async(self, prep_res):\n        \"\"\"VEREINFACHT: Get aggregated context from UnifiedContextManager\"\"\"\n\n        context_manager = prep_res.get(\"context_manager\")\n        session_id = prep_res.get(\"session_id\", \"default\")\n        query = prep_res.get(\"original_query\", \"\")\n\n        if not context_manager:\n            # Fallback: Create basic aggregated context\n            return self._create_fallback_context(prep_res)\n\n        try:\n            #Get unified context from context manager\n            unified_context = await context_manager.build_unified_context(session_id, query, \"full\")\n\n            # Transform to expected aggregated_context format for compatibility\n            aggregated_context = {\n                \"original_query\": query,\n                \"successful_results\": self._extract_successful_results(unified_context),\n                \"failed_attempts\": self._extract_failed_attempts(prep_res[\"tasks\"]),\n                \"key_discoveries\": self._extract_key_discoveries(unified_context),\n                \"adaptation_summary\": self._extract_adaptation_summary(prep_res),\n                \"confidence_scores\": self._calculate_confidence_scores(unified_context),\n                \"unified_context\": unified_context,  # Include full unified context\n                \"context_source\": \"unified_context_manager\"\n            }\n\n            return aggregated_context\n\n        except Exception as e:\n            eprint(f\"UnifiedContextManager aggregation failed: {e}\")\n            return self._create_fallback_context(prep_res)\n\n    def _extract_successful_results(self, unified_context: dict[str, Any]) -&gt; dict[str, Any]:\n        \"\"\"Extract successful results from unified context\"\"\"\n        successful_results = {}\n\n        try:\n            # Get from variables context\n            variables = unified_context.get(\"variables\", {})\n            recent_results = variables.get(\"recent_results\", [])\n\n            for result in recent_results:\n                if result.get(\"success\"):\n                    task_id = result.get(\"task_id\", f\"result_{len(successful_results)}\")\n                    successful_results[task_id] = {\n                        \"task_description\": f\"Task {task_id}\",\n                        \"task_type\": \"unified_context_result\",\n                        \"result\": result.get(\"preview\", \"\"),\n                        \"metadata\": {\n                            \"timestamp\": result.get(\"timestamp\"),\n                            \"source\": \"unified_context\"\n                        }\n                    }\n\n            # Also check execution state for completions\n            execution_state = unified_context.get(\"execution_state\", {})\n            recent_completions = execution_state.get(\"recent_completions\", [])\n\n            for completion in recent_completions:\n                task_id = completion.get(\"id\", f\"completion_{len(successful_results)}\")\n                successful_results[task_id] = {\n                    \"task_description\": completion.get(\"description\", \"Completed task\"),\n                    \"task_type\": \"execution_completion\",\n                    \"result\": f\"Task completed at {completion.get('completed_at', 'unknown time')}\",\n                    \"metadata\": {\n                        \"completion_time\": completion.get(\"completed_at\"),\n                        \"source\": \"execution_state\"\n                    }\n                }\n\n            return successful_results\n\n        except Exception as e:\n            eprint(f\"Error extracting successful results: {e}\")\n            return {}\n\n    def _extract_failed_attempts(self, tasks: dict) -&gt; dict[str, Any]:\n        \"\"\"Extract failed attempts from tasks (existing functionality)\"\"\"\n        failed_attempts = {}\n\n        try:\n            for task_id, task in tasks.items():\n                if task.status == \"failed\":\n                    failed_attempts[task_id] = {\n                        \"description\": task.description,\n                        \"error\": task.error,\n                        \"retry_count\": task.retry_count\n                    }\n            return failed_attempts\n        except:\n            return {}\n\n    def _extract_key_discoveries(self, unified_context: dict[str, Any]) -&gt; list[dict[str, Any]]:\n        \"\"\"Extract key discoveries from unified context\"\"\"\n        discoveries = []\n\n        try:\n            # Extract from relevant facts\n            relevant_facts = unified_context.get(\"relevant_facts\", [])\n            for key, value in relevant_facts[:3]:  # Top 3 facts\n                discoveries.append({\n                    \"discovery\": f\"Fact discovered: {key}\",\n                    \"confidence\": 0.8,  # Default confidence for facts\n                    \"result\": value\n                })\n\n            # Extract from successful results\n            variables = unified_context.get(\"variables\", {})\n            recent_results = variables.get(\"recent_results\", [])\n\n            for result in recent_results[:2]:  # Top 2 results\n                if result.get(\"success\"):\n                    discoveries.append({\n                        \"discovery\": f\"Task result: {result.get('task_id', 'unknown')}\",\n                        \"confidence\": 0.7,\n                        \"result\": result.get(\"preview\", \"\")\n                    })\n\n            return discoveries\n\n        except Exception as e:\n            eprint(f\"Error extracting discoveries: {e}\")\n            return []\n\n    def _extract_adaptation_summary(self, prep_res: dict) -&gt; str:\n        \"\"\"Extract adaptation summary\"\"\"\n        try:\n            current_plan = prep_res.get(\"current_plan\")\n            if current_plan and hasattr(current_plan, 'metadata'):\n                adaptations = current_plan.metadata.get(\"adaptations\", 0)\n                if adaptations &gt; 0:\n                    return f\"Plan was adapted {adaptations} times to handle unexpected results.\"\n            return \"\"\n        except:\n            return \"\"\n\n    def _calculate_confidence_scores(self, unified_context: dict[str, Any]) -&gt; dict[str, float]:\n        \"\"\"Calculate confidence scores based on unified context\"\"\"\n        try:\n            scores = {\"overall\": 0.5}\n\n            # Base confidence on available data\n            chat_history = unified_context.get(\"chat_history\", [])\n            if chat_history:\n                scores[\"conversation_context\"] = min(len(chat_history) / 10, 1.0)\n\n            variables = unified_context.get(\"variables\", {})\n            recent_results = variables.get(\"recent_results\", [])\n            successful_results = [r for r in recent_results if r.get(\"success\")]\n\n            if recent_results:\n                scores[\"execution_results\"] = len(successful_results) / len(recent_results)\n\n            # Calculate overall confidence\n            scores[\"overall\"] = sum(scores.values()) / len(scores)\n\n            return scores\n\n        except:\n            return {\"overall\": 0.3}\n\n    def _create_fallback_context(self, prep_res: dict) -&gt; dict[str, Any]:\n        \"\"\"Create fallback context when UnifiedContextManager is unavailable\"\"\"\n        return {\n            \"original_query\": prep_res.get(\"original_query\", \"\"),\n            \"successful_results\": {},\n            \"failed_attempts\": self._extract_failed_attempts(prep_res.get(\"tasks\", {})),\n            \"key_discoveries\": [],\n            \"adaptation_summary\": \"Fallback context - UnifiedContextManager unavailable\",\n            \"confidence_scores\": {\"overall\": 0.2},\n            \"context_source\": \"fallback\"\n        }\n\n    async def post_async(self, shared, prep_res, exec_res):\n        \"\"\"Store aggregated context for downstream nodes\"\"\"\n        shared[\"aggregated_context\"] = exec_res\n\n        #Also store unified context reference for other nodes\n        if \"unified_context\" in exec_res:\n            shared[\"unified_context\"] = exec_res[\"unified_context\"]\n\n        if exec_res.get(\"successful_results\") or exec_res.get(\"key_discoveries\"):\n            return \"context_ready\"\n        else:\n            return \"no_context\"\n</code></pre> <code>exec_async(prep_res)</code> <code>async</code> \u00b6 <p>VEREINFACHT: Get aggregated context from UnifiedContextManager</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def exec_async(self, prep_res):\n    \"\"\"VEREINFACHT: Get aggregated context from UnifiedContextManager\"\"\"\n\n    context_manager = prep_res.get(\"context_manager\")\n    session_id = prep_res.get(\"session_id\", \"default\")\n    query = prep_res.get(\"original_query\", \"\")\n\n    if not context_manager:\n        # Fallback: Create basic aggregated context\n        return self._create_fallback_context(prep_res)\n\n    try:\n        #Get unified context from context manager\n        unified_context = await context_manager.build_unified_context(session_id, query, \"full\")\n\n        # Transform to expected aggregated_context format for compatibility\n        aggregated_context = {\n            \"original_query\": query,\n            \"successful_results\": self._extract_successful_results(unified_context),\n            \"failed_attempts\": self._extract_failed_attempts(prep_res[\"tasks\"]),\n            \"key_discoveries\": self._extract_key_discoveries(unified_context),\n            \"adaptation_summary\": self._extract_adaptation_summary(prep_res),\n            \"confidence_scores\": self._calculate_confidence_scores(unified_context),\n            \"unified_context\": unified_context,  # Include full unified context\n            \"context_source\": \"unified_context_manager\"\n        }\n\n        return aggregated_context\n\n    except Exception as e:\n        eprint(f\"UnifiedContextManager aggregation failed: {e}\")\n        return self._create_fallback_context(prep_res)\n</code></pre> <code>post_async(shared, prep_res, exec_res)</code> <code>async</code> \u00b6 <p>Store aggregated context for downstream nodes</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def post_async(self, shared, prep_res, exec_res):\n    \"\"\"Store aggregated context for downstream nodes\"\"\"\n    shared[\"aggregated_context\"] = exec_res\n\n    #Also store unified context reference for other nodes\n    if \"unified_context\" in exec_res:\n        shared[\"unified_context\"] = exec_res[\"unified_context\"]\n\n    if exec_res.get(\"successful_results\") or exec_res.get(\"key_discoveries\"):\n        return \"context_ready\"\n    else:\n        return \"no_context\"\n</code></pre> <code>prep_async(shared)</code> <code>async</code> \u00b6 <p>Simplified preparation - delegate to UnifiedContextManager</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def prep_async(self, shared):\n    \"\"\"Simplified preparation - delegate to UnifiedContextManager\"\"\"\n    return {\n        \"context_manager\": shared.get(\"context_manager\"),\n        \"session_id\": shared.get(\"session_id\", \"default\"),\n        \"original_query\": shared.get(\"current_query\", \"\"),\n        \"tasks\": shared.get(\"tasks\", {}),\n        \"current_plan\": shared.get(\"current_plan\"),\n        \"world_model\": shared.get(\"world_model\", {}),\n        \"results\": shared.get(\"results\", {})\n    }\n</code></pre> <code>DecisionTask</code> <code>dataclass</code> \u00b6 <p>               Bases: <code>Task</code></p> <p>Task f\u00fcr dynamisches Routing</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>@dataclass\nclass DecisionTask(Task):\n    \"\"\"Task f\u00fcr dynamisches Routing\"\"\"\n    decision_prompt: str = \"\"  # Kurze Frage an LLM\n    routing_map: dict[str, str] = field(default_factory=dict)  # Ergebnis -&gt; n\u00e4chster Task\n    decision_model: str = \"fast\"  # Welches LLM f\u00fcr Entscheidung\n</code></pre> <code>FlowAgent</code> \u00b6 <p>Production-ready agent system built on PocketFlow</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>class FlowAgent:\n    \"\"\"Production-ready agent system built on PocketFlow \"\"\"\n    def __init__(\n        self,\n        amd: AgentModelData,\n        world_model: dict[str, Any] = None,\n        verbose: bool = False,\n        enable_pause_resume: bool = True,\n        checkpoint_interval: int = 300,  # 5 minutes\n        max_parallel_tasks: int = 3,\n        progress_callback: callable = None,\n        **kwargs\n    ):\n        self.amd = amd\n        self.world_model = world_model or {}\n        self.verbose = verbose\n        self.enable_pause_resume = enable_pause_resume\n        self.checkpoint_interval = checkpoint_interval\n        self.max_parallel_tasks = max_parallel_tasks\n        self.progress_tracker = ProgressTracker(progress_callback, agent_name=amd.name)\n\n        # Core state\n        self.shared = {\n            \"world_model\": self.world_model,\n            \"tasks\": {},\n            \"task_plans\": {},\n            \"system_status\": \"idle\",\n            \"session_data\": {},\n            \"performance_metrics\": {},\n            \"conversation_history\": [],\n            \"available_tools\": [],\n            \"progress_tracker\": self.progress_tracker\n        }\n        self.context_manager = UnifiedContextManager(self)\n        self.variable_manager = VariableManager(self.shared[\"world_model\"], self.shared)\n        self.context_manager.variable_manager = self.variable_manager# Register default scopes\n\n        self.shared[\"context_manager\"] = self.context_manager\n        self.shared[\"variable_manager\"] = self.variable_manager\n        # Flows\n        self.task_flow = TaskManagementFlow(max_parallel_tasks=self.max_parallel_tasks)\n        self.response_flow = ResponseGenerationFlow()\n\n        if hasattr(self.task_flow, 'executor_node'):\n            self.task_flow.executor_node.agent_instance = self\n\n        # Agent state\n        self.is_running = False\n        self.is_paused = False\n        self.last_checkpoint = None\n        self.checkpoint_data = {}\n\n        # Threading\n        self.executor = ThreadPoolExecutor(max_workers=max_parallel_tasks)\n        self._shutdown_event = threading.Event()\n\n        # Server components\n        self.a2a_server: A2AServer = None\n        self.mcp_server: FastMCP = None\n\n        # Enhanced tool registry\n        self._tool_registry = {}\n        self._tool_capabilities = {}\n        self._tool_analysis_cache = {}\n\n        self.active_session = None\n        # Tool analysis file path\n        self.tool_analysis_file = self._get_tool_analysis_path()\n\n        self._tool_capabilities.update(self._load_tool_analysis())\n        if self.amd.budget_manager:\n            self.amd.budget_manager.load_data()\n\n        self._setup_variable_scopes()\n\n        rprint(f\"FlowAgent initialized: {amd.name}\")\n\n    @property\n    def progress_callback(self):\n        return self.progress_tracker.progress_callback\n\n    @progress_callback.setter\n    def progress_callback(self, value):\n        self.progress_tracker.progress_callback = value\n\n    def set_progress_callback(self, progress_callback: callable = None):\n        self.progress_callback = progress_callback\n\n    async def a_run_llm_completion(self, node_name=\"FlowAgentLLMCall\",task_id=\"unknown\",model_preference=\"fast\", with_context=True, **kwargs) -&gt; str:\n        if \"model\" not in kwargs:\n            kwargs[\"model\"] = self.amd.fast_llm_model if model_preference == \"fast\" else self.amd.complex_llm_model\n\n        llm_start = time.perf_counter()\n\n        if self.progress_tracker:\n            await self.progress_tracker.emit_event(ProgressEvent(\n                event_type=\"llm_call\",\n                node_name=node_name,\n                session_id=self.active_session,\n                task_id=task_id,\n                status=NodeStatus.RUNNING,\n                llm_model=kwargs[\"model\"],\n                llm_temperature=kwargs.get(\"temperature\", 0.7),\n                llm_input=kwargs.get(\"messages\", [{}])[-1].get(\"content\", \"\"),  # Prompt direkt erfassen\n                metadata={\n                    \"model_preference\": kwargs.get(\"model_preference\", \"fast\")\n                }\n            ))\n\n        # auto api key addition supports (google, openrouter, openai, anthropic, azure, aws, huggingface, replicate, togetherai, groq)\n        if \"api_key\" not in kwargs:\n            # litellm model-prefix apikey mapp\n            prefix = kwargs['model'].split(\"/\")[0]\n            model_prefix_map = {\n                \"openrouter\": os.getenv(\"OPENROUTER_API_KEY\"),\n                \"openai\": os.getenv(\"OPENAI_API_KEY\"),\n                \"anthropic\": os.getenv(\"ANTHROPIC_API_KEY\"),\n                \"google\": os.getenv(\"GOOGLE_API_KEY\"),\n                \"azure\": os.getenv(\"AZURE_API_KEY\"),\n                \"huggingface\": os.getenv(\"HUGGINGFACE_API_KEY\"),\n                \"replicate\": os.getenv(\"REPLICATE_API_KEY\"),\n                \"togetherai\": os.getenv(\"TOGETHERAI_API_KEY\"),\n                \"groq\": os.getenv(\"GROQ_API_KEY\"),\n            }\n            kwargs[\"api_key\"] = model_prefix_map.get(prefix)\n\n        if self.active_session and with_context:\n            # Add context to fist messages as system message\n            context_ = await self.get_context(self.active_session)\n            kwargs[\"messages\"] = [{\"role\": \"system\", \"content\": self.amd.get_system_message_with_persona()+'\\n\\nContext:\\n\\n'+context_}] + kwargs.get(\"messages\", [])\n\n        # build fallback dict using FALLBACKS_MODELS/PREM and _KEYS\n\n        if 'fallbacks' not in kwargs:\n            fallbacks_dict_list = []\n            fallbacks = os.getenv(\"FALLBACKS_MODELS\", '').split(',') if model_preference == \"fast\" else os.getenv(\n                \"FALLBACKS_MODELS_PREM\", '').split(',')\n            fallbacks_keys = os.getenv(\"FALLBACKS_MODELS_KEYS\", '').split(\n                ',') if model_preference == \"fast\" else os.getenv(\n                \"FALLBACKS_MODELS_KEYS_PREM\", '').split(',')\n            for model, key in zip(fallbacks, fallbacks_keys):\n                fallbacks_dict_list.append({\"model\": model, \"api_key\": key})\n            kwargs['fallbacks'] = fallbacks_dict_list\n        try:\n\n            response = await litellm.acompletion(**kwargs)\n\n            llm_duration = time.perf_counter() - llm_start\n            result = response.choices[0].message.content\n\n            if AGENT_VERBOSE and self.verbose:\n                kwargs[\"messages\"] += [{\"role\": \"assistant\", \"content\": result}]\n                print_prompt(kwargs)\n            # else:\n            #     print_prompt([{\"role\": \"assistant\", \"content\": result}])\n\n            # Extract token usage and cost\n            usage = response.usage\n            input_tokens = usage.prompt_tokens if usage else 0\n            output_tokens = usage.completion_tokens if usage else 0\n            total_tokens = usage.total_tokens if usage else 0\n\n            call_cost = self.progress_tracker.calculate_llm_cost(kwargs[\"model\"], input_tokens,\n                                                            output_tokens, response) if self.progress_tracker else 0.0\n\n            if self.progress_tracker:\n                await self.progress_tracker.emit_event(ProgressEvent(\n                    event_type=\"llm_call\",\n                    node_name=node_name,\n                    task_id=task_id,\n                    session_id=self.active_session,\n                    status=NodeStatus.COMPLETED,\n                    success=True,\n                    duration=llm_duration,\n                    llm_model=kwargs[\"model\"],\n                    llm_prompt_tokens=input_tokens,\n                    llm_completion_tokens=output_tokens,\n                    llm_total_tokens=total_tokens,\n                    llm_cost=call_cost,\n                    llm_temperature=kwargs.get(\"temperature\", 0.7),\n                    llm_output=result,\n                    llm_input=\"\",\n                ))\n\n            return result\n        except Exception as e:\n            llm_duration = time.perf_counter() - llm_start\n            import traceback\n            print(traceback.format_exc())\n\n            if self.progress_tracker:\n                await self.progress_tracker.emit_event(ProgressEvent(\n                    event_type=\"llm_call\",  # Event-Typ bleibt konsistent\n                    node_name=node_name,\n                    task_id=task_id,\n                    session_id=self.active_session,\n                    status=NodeStatus.FAILED,\n                    success=False,\n                    duration=llm_duration,\n                    llm_model=kwargs[\"model\"],\n                    error_details={\n                        \"message\": str(e),\n                        \"type\": type(e).__name__\n                    }\n                ))\n\n            raise\n\n    async def a_run(\n        self,\n        query: str,\n        session_id: str = \"default\",\n        user_id: str = None,\n        stream_callback: Callable = None,\n        remember: bool = True,\n        **kwargs\n    ) -&gt; str:\n        \"\"\"Main entry point f\u00fcr Agent-Ausf\u00fchrung mit UnifiedContextManager\"\"\"\n\n        execution_start = self.progress_tracker.start_timer(\"total_execution\")\n        self.active_session = session_id\n        result = None\n        await self.progress_tracker.emit_event(ProgressEvent(\n            event_type=\"execution_start\",\n            timestamp=time.time(),\n            status=NodeStatus.RUNNING,\n            node_name=\"FlowAgent\",\n            session_id=session_id,\n            metadata={\"query\": query, \"user_id\": user_id}\n        ))\n\n        try:\n            #Initialize or get session \u00fcber UnifiedContextManager\n            await self.initialize_session_context(session_id, max_history=200)\n\n            #Store user message immediately in ChatSession wenn remember=True\n            if remember:\n                await self.context_manager.add_interaction(\n                    session_id,\n                    'user',\n                    query,\n                    metadata={\"user_id\": user_id}\n                )\n\n            # Set user context variables\n            timestamp = datetime.now()\n            self.variable_manager.register_scope('user', {\n                'id': user_id,\n                'session': session_id,\n                'query': query,\n                'timestamp': timestamp.isoformat()\n            })\n\n            # Update system variables\n            self.variable_manager.set('system_context.timestamp', {'isoformat': timestamp.isoformat()})\n            self.variable_manager.set('system_context.current_session', session_id)\n            self.variable_manager.set('system_context.current_user', user_id)\n            self.variable_manager.set('system_context.last_query', query)\n\n            # Initialize with tool awareness\n            await self.initialize_context_awareness()\n\n            # VEREINFACHT: Prepare execution context - weniger Daten duplizieren\n            self.shared.update({\n                \"current_query\": query,\n                \"session_id\": session_id,\n                \"user_id\": user_id,\n                \"stream_callback\": stream_callback,\n                \"remember\": remember,\n                # CENTRAL: Context Manager ist die prim\u00e4re Context-Quelle\n                \"context_manager\": self.context_manager,\n                \"variable_manager\": self.variable_manager\n            })\n\n            # Set LLM models in shared context\n            self.shared['fast_llm_model'] = self.amd.fast_llm_model\n            self.shared['complex_llm_model'] = self.amd.complex_llm_model\n            self.shared['persona_config'] = self.amd.persona\n            self.shared['use_fast_response'] = self.amd.use_fast_response\n\n            # Set system status\n            self.shared[\"system_status\"] = \"running\"\n            self.is_running = True\n\n            # Execute main orchestration flow\n            result = await self._orchestrate_execution()\n\n            #Store assistant response in ChatSession wenn remember=True\n            if remember:\n                await self.context_manager.add_interaction(\n                    session_id,\n                    'assistant',\n                    result,\n                    metadata={\"user_id\": user_id, \"execution_duration\": time.time() - execution_start}\n                )\n\n            total_duration = self.progress_tracker.end_timer(\"total_execution\")\n\n            await self.progress_tracker.emit_event(ProgressEvent(\n                event_type=\"execution_complete\",\n                timestamp=time.time(),\n                node_name=\"FlowAgent\",\n                status=NodeStatus.COMPLETED,\n                node_duration=total_duration,\n                session_id=session_id,\n                metadata={\n                    \"result_length\": len(result),\n                    \"summary\": self.progress_tracker.get_summary(),\n                    \"remembered\": remember\n                }\n            ))\n\n            # Checkpoint if needed\n            if self.enable_pause_resume:\n                await self._maybe_checkpoint()\n\n            return result\n\n        except Exception as e:\n            eprint(f\"Agent execution failed: {e}\", exc_info=True)\n            error_response = f\"I encountered an error: {str(e)}\"\n            result = error_response\n            import traceback\n            print(traceback.format_exc())\n\n            # Store error in ChatSession wenn remember=True\n            if remember:\n                await self.context_manager.add_interaction(\n                    session_id,\n                    'assistant',\n                    error_response,\n                    metadata={\n                        \"user_id\": user_id,\n                        \"error\": True,\n                        \"error_type\": type(e).__name__\n                    }\n                )\n\n            total_duration = self.progress_tracker.end_timer(\"total_execution\")\n\n            await self.progress_tracker.emit_event(ProgressEvent(\n                event_type=\"error\",\n                timestamp=time.time(),\n                node_name=\"FlowAgent\",\n                status=NodeStatus.FAILED,\n                node_duration=total_duration,\n                session_id=session_id,\n                metadata={\"error\": str(e), \"error_type\": type(e).__name__}\n            ))\n\n            return error_response\n\n        finally:\n            self.shared[\"system_status\"] = \"idle\"\n            self.is_running = False\n            self.active_session = None\n\n    def set_response_format(\n        self,\n        response_format: str,\n        text_length: str,\n        custom_instructions: str = \"\",\n        quality_threshold: float = 0.7\n    ):\n        \"\"\"Dynamische Format- und L\u00e4ngen-Konfiguration\"\"\"\n\n        # Validiere Eingaben\n        try:\n            ResponseFormat(response_format)\n            TextLength(text_length)\n        except ValueError:\n            available_formats = [f.value for f in ResponseFormat]\n            available_lengths = [l.value for l in TextLength]\n            raise ValueError(\n                f\"Invalid format or length. \"\n                f\"Available formats: {available_formats}. \"\n                f\"Available lengths: {available_lengths}\"\n            )\n\n        # Erstelle oder aktualisiere Persona\n        if not self.amd.persona:\n            self.amd.persona = PersonaConfig(name=\"Assistant\")\n\n        # Erstelle Format-Konfiguration\n        format_config = FormatConfig(\n            response_format=ResponseFormat(response_format),\n            text_length=TextLength(text_length),\n            custom_instructions=custom_instructions,\n            quality_threshold=quality_threshold\n        )\n\n        self.amd.persona.format_config = format_config\n\n        # Aktualisiere Personality Traits mit Format-Hinweisen\n        self._update_persona_with_format(response_format, text_length)\n\n        # Update shared state\n        self.shared[\"persona_config\"] = self.amd.persona\n        self.shared[\"format_config\"] = format_config\n\n        rprint(f\"Response format set: {response_format}, length: {text_length}\")\n\n    def _update_persona_with_format(self, response_format: str, text_length: str):\n        \"\"\"Aktualisiere Persona-Traits basierend auf Format\"\"\"\n\n        # Format-spezifische Traits\n        format_traits = {\n            \"with-tables\": [\"structured\", \"data-oriented\", \"analytical\"],\n            \"with-bullet-points\": [\"organized\", \"clear\", \"systematic\"],\n            \"with-lists\": [\"methodical\", \"sequential\", \"thorough\"],\n            \"md-text\": [\"technical\", \"formatted\", \"detailed\"],\n            \"yaml-text\": [\"structured\", \"machine-readable\", \"precise\"],\n            \"json-text\": [\"technical\", \"API-focused\", \"structured\"],\n            \"text-only\": [\"conversational\", \"natural\", \"flowing\"],\n            \"pseudo-code\": [\"logical\", \"algorithmic\", \"step-by-step\"],\n            \"code-structure\": [\"technical\", \"systematic\", \"hierarchical\"]\n        }\n\n        # L\u00e4ngen-spezifische Traits\n        length_traits = {\n            \"mini-chat\": [\"concise\", \"quick\", \"to-the-point\"],\n            \"chat-conversation\": [\"conversational\", \"friendly\", \"balanced\"],\n            \"table-conversation\": [\"structured\", \"comparative\", \"organized\"],\n            \"detailed-indepth\": [\"thorough\", \"comprehensive\", \"analytical\"],\n            \"phd-level\": [\"academic\", \"scholarly\", \"authoritative\"]\n        }\n\n        # Kombiniere Traits\n        current_traits = set(self.amd.persona.personality_traits)\n\n        # Entferne alte Format-Traits\n        old_format_traits = set()\n        for traits in format_traits.values():\n            old_format_traits.update(traits)\n        for traits in length_traits.values():\n            old_format_traits.update(traits)\n\n        current_traits -= old_format_traits\n\n        # F\u00fcge neue Traits hinzu\n        new_traits = format_traits.get(response_format, [])\n        new_traits.extend(length_traits.get(text_length, []))\n\n        current_traits.update(new_traits)\n        self.amd.persona.personality_traits = list(current_traits)\n\n    def get_available_formats(self) -&gt; dict[str, list[str]]:\n        \"\"\"Erhalte verf\u00fcgbare Format- und L\u00e4ngen-Optionen\"\"\"\n        return {\n            \"formats\": [f.value for f in ResponseFormat],\n            \"lengths\": [l.value for l in TextLength],\n            \"format_descriptions\": {\n                f.value: FormatConfig(response_format=f).get_format_instructions()\n                for f in ResponseFormat\n            },\n            \"length_descriptions\": {\n                l.value: FormatConfig(text_length=l).get_length_instructions()\n                for l in TextLength\n            }\n        }\n\n    async def a_run_with_format(\n        self,\n        query: str,\n        response_format: str = \"frei-text\",\n        text_length: str = \"chat-conversation\",\n        custom_instructions: str = \"\",\n        **kwargs\n    ) -&gt; str:\n        \"\"\"F\u00fchre Agent mit spezifischem Format aus\"\"\"\n\n        # Tempor\u00e4re Format-Einstellung\n        original_persona = self.amd.persona\n\n        try:\n            self.set_response_format(response_format, text_length, custom_instructions)\n            response = await self.a_run(query, **kwargs)\n            return response\n        finally:\n            # Restore original persona\n            self.amd.persona = original_persona\n            self.shared[\"persona_config\"] = original_persona\n\n    def get_format_quality_report(self) -&gt; dict[str, Any]:\n        \"\"\"Erhalte detaillierten Format-Qualit\u00e4tsbericht\"\"\"\n        quality_assessment = self.shared.get(\"quality_assessment\", {})\n\n        if not quality_assessment:\n            return {\"status\": \"no_assessment\", \"message\": \"No recent quality assessment available\"}\n\n        quality_details = quality_assessment.get(\"quality_details\", {})\n\n        return {\n            \"overall_score\": quality_details.get(\"total_score\", 0.0),\n            \"format_adherence\": quality_details.get(\"format_adherence\", 0.0),\n            \"length_adherence\": quality_details.get(\"length_adherence\", 0.0),\n            \"content_quality\": quality_details.get(\"base_quality\", 0.0),\n            \"llm_assessment\": quality_details.get(\"llm_assessment\", 0.0),\n            \"suggestions\": quality_assessment.get(\"suggestions\", []),\n            \"assessment\": quality_assessment.get(\"quality_assessment\", \"unknown\"),\n            \"format_config_active\": quality_details.get(\"format_config_used\", False)\n        }\n\n    def get_variable_documentation(self) -&gt; str:\n        \"\"\"Get comprehensive variable system documentation\"\"\"\n        docs = []\n        docs.append(\"# Variable System Documentation\\n\")\n\n        # Available scopes\n        docs.append(\"## Available Scopes:\")\n        scope_info = self.variable_manager.get_scope_info()\n        for scope_name, info in scope_info.items():\n            docs.append(f\"- `{scope_name}`: {info['type']} with {info.get('keys', 'N/A')} keys\")\n\n        docs.append(\"\\n## Syntax Options:\")\n        docs.append(\"- `{{ variable.path }}` - Full path resolution\")\n        docs.append(\"- `{variable}` - Simple variable (no dots)\")\n        docs.append(\"- `$variable` - Shell-style variable\")\n\n        docs.append(\"\\n## Example Usage:\")\n        docs.append(\"- `{{ results.task_1.data }}` - Get result from task_1\")\n        docs.append(\"- `{{ user.name }}` - Get user name\")\n        docs.append(\"- `{agent_name}` - Simple agent name\")\n        docs.append(\"- `$timestamp` - System timestamp\")\n\n        # Available variables\n        docs.append(\"\\n## Available Variables:\")\n        variables = self.variable_manager.get_available_variables()\n        for scope_name, scope_vars in variables.items():\n            docs.append(f\"\\n### {scope_name}:\")\n            for _var_name, var_info in scope_vars.items():\n                docs.append(f\"- `{var_info['path']}`: {var_info['preview']} ({var_info['type']})\")\n\n        return \"\\n\".join(docs)\n\n    def _setup_variable_scopes(self):\n        \"\"\"Setup default variable scopes with enhanced structure\"\"\"\n        self.variable_manager.register_scope('agent', {\n            'name': self.amd.name,\n            'model_fast': self.amd.fast_llm_model,\n            'model_complex': self.amd.complex_llm_model\n        })\n\n        timestamp = datetime.now()\n        self.variable_manager.register_scope('system', {\n            'timestamp': timestamp.isoformat(),\n            'version': '2.0',\n            'capabilities': list(self._tool_capabilities.keys())\n        })\n\n        # ADDED: Initialize empty results and tasks scopes\n        self.variable_manager.register_scope('results', {})\n        self.variable_manager.register_scope('tasks', {})\n\n        # Update shared state\n        self.shared[\"variable_manager\"] = self.variable_manager\n\n    def set_variable(self, path: str, value: Any):\n        \"\"\"Set variable using unified system\"\"\"\n        self.variable_manager.set(path, value)\n\n    def get_variable(self, path: str, default=None):\n        \"\"\"Get variable using unified system\"\"\"\n        return self.variable_manager.get(path, default)\n\n    def format_text(self, text: str, **context) -&gt; str:\n        \"\"\"Format text with variables\"\"\"\n        return self.variable_manager.format_text(text, context)\n\n    async def initialize_session_context(self, session_id: str = \"default\", max_history: int = 200) -&gt; bool:\n        \"\"\"Vereinfachte Session-Initialisierung \u00fcber UnifiedContextManager\"\"\"\n        try:\n            # Delegation an UnifiedContextManager\n            session = await self.context_manager.initialize_session(session_id, max_history)\n\n            # Ensure Variable Manager integration\n            if not self.context_manager.variable_manager:\n                self.context_manager.variable_manager = self.variable_manager\n\n            # Update shared state (minimal - primary data now in context_manager)\n            self.shared[\"active_session_id\"] = session_id\n            self.shared[\"session_initialized\"] = True\n\n            # Legacy support: Keep session_managers reference in shared for backward compatibility\n            self.shared[\"session_managers\"] = self.context_manager.session_managers\n\n            rprint(f\"Session context initialized for {session_id} via UnifiedContextManager\")\n            return True\n\n        except Exception as e:\n            eprint(f\"Session context initialization failed: {e}\")\n            import traceback\n            print(traceback.format_exc())\n            return False\n\n    async def initialize_context_awareness(self):\n        \"\"\"Enhanced context awareness with session management\"\"\"\n\n        # Initialize session if not already done\n        session_id = self.shared.get(\"session_id\", self.active_session)\n        if not self.shared.get(\"session_initialized\"):\n            await self.initialize_session_context(session_id)\n\n        # Ensure tool capabilities are loaded\n        # add tqdm prigress bar\n\n        from tqdm import tqdm\n\n        if hasattr(self.task_flow, 'llm_reasoner'):\n            if \"read_from_variables\" not in self.shared[\"available_tools\"] and hasattr(self.task_flow.llm_reasoner, '_execute_read_from_variables'):\n                await self.add_tool(lambda scope, key, purpose: self.task_flow.llm_reasoner._execute_read_from_variables({\"scope\": scope, \"key\": key, \"purpose\": purpose}), \"read_from_variables\", \"Read from variables\")\n            if \"write_to_variables\" not in self.shared[\"available_tools\"] and hasattr(self.task_flow.llm_reasoner, '_execute_write_to_variables'):\n                await self.add_tool(lambda scope, key, value, description: self.task_flow.llm_reasoner._execute_write_to_variables({\"scope\": scope, \"key\": key, \"value\": value, \"description\": description}), \"write_to_variables\", \"Write to variables\")\n\n            if \"internal_reasoning\" not in self.shared[\"available_tools\"] and hasattr(self.task_flow.llm_reasoner, '_execute_internal_reasoning'):\n                async def internal_reasoning_tool(thought:str, thought_number:int, total_thoughts:int, next_thought_needed:bool, current_focus:str, key_insights:list[str], potential_issues:list[str], confidence_level:float):\n                    args = {\n                        \"thought\": thought,\n                        \"thought_number\": thought_number,\n                        \"total_thoughts\": total_thoughts,\n                        \"next_thought_needed\": next_thought_needed,\n                        \"current_focus\": current_focus,\n                        \"key_insights\": key_insights,\n                        \"potential_issues\": potential_issues,\n                        \"confidence_level\": confidence_level\n                    }\n                    return await self.task_flow.llm_reasoner._execute_internal_reasoning(args, self.shared)\n                await self.add_tool(internal_reasoning_tool, \"internal_reasoning\", \"Internal reasoning\")\n\n            if \"manage_internal_task_stack\" not in self.shared[\"available_tools\"] and hasattr(self.task_flow.llm_reasoner, '_execute_manage_task_stack'):\n                async def manage_internal_task_stack_tool(action:str, task_description:str, outline_step_ref:str):\n                    args = {\n                        \"action\": action,\n                        \"task_description\": task_description,\n                        \"outline_step_ref\": outline_step_ref\n                    }\n                    return await self.task_flow.llm_reasoner._execute_manage_task_stack(args, self.shared)\n                await self.add_tool(manage_internal_task_stack_tool, \"manage_internal_task_stack\", \"Manage internal task stack\")\n\n            if \"outline_step_completion\" not in self.shared[\"available_tools\"] and hasattr(self.task_flow.llm_reasoner, '_execute_outline_step_completion'):\n                async def outline_step_completion_tool(step_completed:bool, completion_evidence:str, next_step_focus:str):\n                    args = {\n                        \"step_completed\": step_completed,\n                        \"completion_evidence\": completion_evidence,\n                        \"next_step_focus\": next_step_focus\n                    }\n                    return await self.task_flow.llm_reasoner._execute_outline_step_completion(args, self.shared)\n                await self.add_tool(outline_step_completion_tool, \"outline_step_completion\", \"Outline step completion\")\n\n\n        registered_tools = set(self._tool_registry.keys())\n        cached_capabilities = list(self._tool_capabilities.keys())  # Create a copy of\n        for tool_name in cached_capabilities:\n            if tool_name in self._tool_capabilities and tool_name not in registered_tools:\n                del self._tool_capabilities[tool_name]\n                print(f\"Removed outdated capability for unavailable tool: {tool_name}\")\n\n        for tool_name in tqdm(self.shared[\"available_tools\"], desc=f\"Agent {self.amd.name} Analyzing Tools\", unit=\"tool\", colour=\"green\", total=len(self.shared[\"available_tools\"])):\n            if tool_name not in self._tool_capabilities:\n                tool_info = self._tool_registry.get(tool_name, {})\n                description = tool_info.get(\"description\", \"No description\")\n                with Spinner(f\"Analyzing tool {tool_name}\"):\n                    await self._analyze_tool_capabilities(tool_name, description, tool_info.get(\"args_schema\", \"()\"))\n\n            if tool_name in self._tool_capabilities:\n                function = self._tool_registry[tool_name][\"function\"]\n                self._tool_capabilities[tool_name][\"args_schema\"] = get_args_schema(function)\n\n        # Set enhanced system context\n        self.shared[\"system_context\"] = {\n            \"capabilities_summary\": self._build_capabilities_summary(),\n            \"tool_count\": len(self.shared[\"available_tools\"]),\n            \"analysis_loaded\": len(self._tool_capabilities),\n            \"intelligence_level\": \"high\" if self._tool_capabilities else \"basic\",\n            \"context_management\": \"advanced_session_aware\",\n            \"session_managers\": len(self.shared.get(\"session_managers\", {})),\n        }\n\n\n        rprint(\"Advanced context awareness initialized with session management\")\n\n    async def get_context(self, session_id: str = None, format_for_llm: bool = True) -&gt; str | dict[str, Any]:\n        \"\"\"\n        \u00dcBERARBEITET: Get context \u00fcber UnifiedContextManager statt verteilte Quellen\n        \"\"\"\n        try:\n            session_id = session_id or self.shared.get(\"session_id\", self.active_session)\n            query = self.shared.get(\"current_query\", \"\")\n\n            #Hole unified context \u00fcber Context Manager\n            unified_context = await self.context_manager.build_unified_context(session_id, query, \"full\")\n\n\n            if format_for_llm:\n                return self.context_manager.get_formatted_context_for_llm(unified_context)\n            else:\n                return unified_context\n\n        except Exception as e:\n            import traceback\n            print(traceback.format_exc())\n            eprint(f\"Failed to generate context via UnifiedContextManager: {e}\")\n\n            # FALLBACK: Fallback zu alter Methode falls UnifiedContextManager fehlschl\u00e4gt\n            if format_for_llm:\n                return f\"Error generating context: {str(e)}\"\n            else:\n                return {\n                    \"error\": str(e),\n                    \"generated_at\": datetime.now().isoformat(),\n                    \"fallback_mode\": True\n                }\n\n    def get_context_statistics(self) -&gt; dict[str, Any]:\n        \"\"\"Get comprehensive context management statistics\"\"\"\n        stats = {\n            \"context_system\": \"advanced_session_aware\",\n            \"compression_threshold\": 0.76,\n            \"max_tokens\": getattr(self, 'max_input_tokens', 8000),\n            \"session_managers\": {},\n            \"context_usage\": {},\n            \"compression_stats\": {}\n        }\n\n        # Session manager statistics\n        session_managers = self.shared.get(\"session_managers\", {})\n        for name, manager in session_managers.items():\n            stats[\"session_managers\"][name] = {\n                \"history_length\": len(manager.history),\n                \"max_length\": manager.max_length,\n                \"space_name\": manager.space_name\n            }\n\n        # Context node statistics if available\n        if hasattr(self.task_flow, 'context_manager'):\n            context_manager = self.task_flow.context_manager\n            stats[\"compression_stats\"] = {\n                \"compression_threshold\": context_manager.compression_threshold,\n                \"max_tokens\": context_manager.max_tokens,\n                \"active_sessions\": len(context_manager.session_managers)\n            }\n\n        # LLM call statistics from enhanced node\n        llm_stats = self.shared.get(\"llm_call_stats\", {})\n        if llm_stats:\n            stats[\"context_usage\"] = {\n                \"total_llm_calls\": llm_stats.get(\"total_calls\", 0),\n                \"context_compression_rate\": llm_stats.get(\"context_compression_rate\", 0.0),\n                \"average_context_tokens\": llm_stats.get(\"context_tokens_used\", 0) / max(llm_stats.get(\"total_calls\", 1),\n                                                                                        1)\n            }\n\n        return stats\n\n    def set_persona(self, name: str, style: str = \"professional\", tone: str = \"friendly\",\n                    personality_traits: list[str] = None, apply_method: str = \"system_prompt\",\n                    integration_level: str = \"light\", custom_instructions: str = \"\"):\n        \"\"\"Set agent persona mit erweiterten Konfigurationsm\u00f6glichkeiten\"\"\"\n        if personality_traits is None:\n            personality_traits = [\"helpful\", \"concise\"]\n\n        self.amd.persona = PersonaConfig(\n            name=name,\n            style=style,\n            tone=tone,\n            personality_traits=personality_traits,\n            custom_instructions=custom_instructions,\n            apply_method=apply_method,\n            integration_level=integration_level\n        )\n\n        rprint(f\"Persona set: {name} ({style}, {tone}) - Method: {apply_method}, Level: {integration_level}\")\n\n    def configure_persona_integration(self, apply_method: str = \"system_prompt\", integration_level: str = \"light\"):\n        \"\"\"Configure how persona is applied\"\"\"\n        if self.amd.persona:\n            self.amd.persona.apply_method = apply_method\n            self.amd.persona.integration_level = integration_level\n            rprint(f\"Persona integration updated: {apply_method}, {integration_level}\")\n        else:\n            wprint(\"No persona configured to update\")\n\n    def get_available_variables(self) -&gt; dict[str, str]:\n        \"\"\"Get available variables for dynamic formatting\"\"\"\n        return self.variable_manager.get_available_variables()\n\n    async def _orchestrate_execution(self) -&gt; str:\n        \"\"\"\n        Enhanced orchestration with LLMReasonerNode as strategic core.\n        The reasoner now handles both task management and response generation internally.\n        \"\"\"\n\n        self.shared[\"agent_instance\"] = self\n        self.shared[\"session_id\"] = self.active_session\n        # === UNIFIED REASONING AND EXECUTION CYCLE ===\n        rprint(\"Starting strategic reasoning and execution cycle\")\n\n        # The LLMReasonerNode now handles the complete cycle:\n        # 1. Strategic analysis of the query\n        # 2. Decision making about approach\n        # 3. Orchestration of sub-systems (LLMToolNode, TaskPlanner/Executor)\n        # 4. Response synthesis and formatting\n\n        # Execute the unified flow\n        task_management_result = await self.task_flow.run_async(self.shared)\n\n        # Check for various completion states\n        if self.shared.get(\"plan_halted\"):\n            error_response = f\"Task execution was halted: {self.shared.get('halt_reason', 'Unknown reason')}\"\n            self.shared[\"current_response\"] = error_response\n            return error_response\n\n        final_response = self.shared.get(\"current_response\", \"Task completed successfully.\")\n        # Execute ResponseGenerationFlow for persona application and formatting\n        response_result = await self.response_flow.run_async(self.shared)\n\n        # The reasoner provides the final response\n        final_response = self.shared.get(\"current_response\", \"Task completed successfully.\")\n\n        # Add reasoning artifacts to response if available\n        reasoning_artifacts = self.shared.get(\"reasoning_artifacts\", {})\n        if reasoning_artifacts and reasoning_artifacts.get(\"reasoning_loops\", 0) &gt; 1:\n            # For debugging/transparency, could add reasoning info to metadata\n            pass\n\n        # Log enhanced statistics\n        self._log_execution_stats()\n\n        return final_response\n\n    def _log_execution_stats(self):\n        \"\"\"Enhanced execution statistics with reasoning metrics\"\"\"\n        tasks = self.shared.get(\"tasks\", {})\n        adaptations = self.shared.get(\"plan_adaptations\", 0)\n        reasoning_artifacts = self.shared.get(\"reasoning_artifacts\", {})\n\n        completed_tasks = sum(1 for t in tasks.values() if t.status == \"completed\")\n        failed_tasks = sum(1 for t in tasks.values() if t.status == \"failed\")\n\n        # Enhanced logging with reasoning metrics\n        reasoning_loops = reasoning_artifacts.get(\"reasoning_loops\", 0)\n\n        stats_message = f\"Execution complete - Tasks: {completed_tasks} completed, {failed_tasks} failed\"\n\n        if adaptations &gt; 0:\n            stats_message += f\", {adaptations} adaptations\"\n\n        if reasoning_loops &gt; 0:\n            stats_message += f\", {reasoning_loops} reasoning loops\"\n\n            # Add reasoning efficiency metric\n            if completed_tasks &gt; 0:\n                efficiency = completed_tasks / max(reasoning_loops, 1)\n                stats_message += f\" (efficiency: {efficiency:.1f} tasks/loop)\"\n\n        rprint(stats_message)\n\n        # Log reasoning context if significant\n        if reasoning_loops &gt; 3:\n            internal_task_stack = reasoning_artifacts.get(\"internal_task_stack\", [])\n            completed_reasoning_tasks = len([t for t in internal_task_stack if t.get(\"status\") == \"completed\"])\n\n            if completed_reasoning_tasks &gt; 0:\n                rprint(f\"Strategic reasoning: {completed_reasoning_tasks} high-level tasks completed\")\n\n    def _build_capabilities_summary(self) -&gt; str:\n        \"\"\"Build summary of agent capabilities\"\"\"\n\n        if not self._tool_capabilities:\n            return \"Basic LLM capabilities only\"\n\n        summaries = []\n        for tool_name, cap in self._tool_capabilities.items():\n            primary = cap.get('primary_function', 'Unknown function')\n            summaries.append(f\"{tool_name}{cap.get('args_schema', '()')}: {primary}\")\n\n        return f\"Enhanced capabilities: {'; '.join(summaries)}\"\n\n    # Neue Hilfsmethoden f\u00fcr erweiterte Funktionalit\u00e4t\n\n    async def get_task_execution_summary(self) -&gt; dict[str, Any]:\n        \"\"\"Erhalte detaillierte Zusammenfassung der Task-Ausf\u00fchrung\"\"\"\n        tasks = self.shared.get(\"tasks\", {})\n        results_store = self.shared.get(\"results\", {})\n\n        summary = {\n            \"total_tasks\": len(tasks),\n            \"completed_tasks\": [],\n            \"failed_tasks\": [],\n            \"task_types_used\": {},\n            \"tools_used\": [],\n            \"adaptations\": self.shared.get(\"plan_adaptations\", 0),\n            \"execution_timeline\": []\n        }\n\n        for task_id, task in tasks.items():\n            task_info = {\n                \"id\": task_id,\n                \"type\": task.type,\n                \"description\": task.description,\n                \"status\": task.status,\n                \"duration\": None\n            }\n\n            if task.started_at and task.completed_at:\n                duration = (task.completed_at - task.started_at).total_seconds()\n                task_info[\"duration\"] = duration\n\n            if task.status == \"completed\":\n                summary[\"completed_tasks\"].append(task_info)\n                if isinstance(task, ToolTask):\n                    summary[\"tools_used\"].append(task.tool_name)\n            elif task.status == \"failed\":\n                task_info[\"error\"] = task.error\n                summary[\"failed_tasks\"].append(task_info)\n\n            # Task types counting\n            task_type = task.type\n            summary[\"task_types_used\"][task_type] = summary[\"task_types_used\"].get(task_type, 0) + 1\n\n        return summary\n\n    async def explain_reasoning_process(self) -&gt; str:\n        \"\"\"Erkl\u00e4re den Reasoning-Prozess des Agenten\"\"\"\n        if not LITELLM_AVAILABLE:\n            return \"Reasoning explanation requires LLM capabilities.\"\n\n        summary = await self.get_task_execution_summary()\n\n        prompt = f\"\"\"\nErkl\u00e4re den Reasoning-Prozess dieses AI-Agenten in verst\u00e4ndlicher Form:\n\n## Ausf\u00fchrungszusammenfassung\n- Total Tasks: {summary['total_tasks']}\n- Erfolgreich: {len(summary['completed_tasks'])}\n- Fehlgeschlagen: {len(summary['failed_tasks'])}\n- Plan-Adaptationen: {summary['adaptations']}\n- Verwendete Tools: {', '.join(set(summary['tools_used']))}\n- Task-Typen: {summary['task_types_used']}\n\n## Task-Details\nErfolgreiche Tasks:\n{self._format_tasks_for_explanation(summary['completed_tasks'])}\n\n## Anweisungen\nErkl\u00e4re in 2-3 Abs\u00e4tzen:\n1. Welche Strategie der Agent gew\u00e4hlt hat\n2. Wie er die Aufgabe in Tasks unterteilt hat\n3. Wie er auf unerwartete Ergebnisse reagiert hat (falls Adaptationen)\n4. Was die wichtigsten Erkenntnisse waren\n\nSchreibe f\u00fcr einen technischen Nutzer, aber verst\u00e4ndlich.\"\"\"\n\n        try:\n            response = await self.a_run_llm_completion(\n                model=self.amd.complex_llm_model,\n                messages=[{\"role\": \"user\", \"content\": prompt}],\n                temperature=0.5,\n                max_tokens=800,task_id=\"reasoning_explanation\"\n            )\n\n            return response\n\n        except Exception as e:\n            import traceback\n            print(traceback.format_exc())\n            return f\"Could not generate reasoning explanation: {e}\"\n\n    def _format_tasks_for_explanation(self, tasks: list[dict]) -&gt; str:\n        formatted = []\n        for task in tasks[:5]:  # Top 5 tasks\n            duration_info = f\" ({task['duration']:.1f}s)\" if task['duration'] else \"\"\n            formatted.append(f\"- {task['type']}: {task['description']}{duration_info}\")\n        return \"\\n\".join(formatted)\n\n    # ===== PAUSE/RESUME FUNCTIONALITY =====\n\n    async def pause(self) -&gt; bool:\n        \"\"\"Pause agent execution\"\"\"\n        if not self.is_running:\n            return False\n\n        self.is_paused = True\n        self.shared[\"system_status\"] = \"paused\"\n\n        # Create checkpoint\n        checkpoint = await self._create_checkpoint()\n        await self._save_checkpoint(checkpoint)\n\n        rprint(\"Agent execution paused\")\n        return True\n\n    async def resume(self) -&gt; bool:\n        \"\"\"Resume agent execution\"\"\"\n        if not self.is_paused:\n            return False\n\n        self.is_paused = False\n        self.shared[\"system_status\"] = \"running\"\n\n        rprint(\"Agent execution resumed\")\n        return True\n\n    # ===== CHECKPOINT MANAGEMENT =====\n\n    async def _create_checkpoint(self) -&gt; AgentCheckpoint:\n        \"\"\"Vereinfachte Checkpoint-Erstellung - fokussiert auf wesentliche Daten\"\"\"\n        try:\n            # Budget Manager Daten vor Checkpoint speichern\n            if hasattr(self.amd, 'budget_manager') and self.amd.budget_manager:\n                self.amd.budget_manager.save_data()\n\n            # Bereite AMD-Daten vor (ohne budget_manager f\u00fcr Serialisierung)\n            amd_data = self.amd.model_dump()\n            amd_data['budget_manager'] = None\n\n            # Sammle wesentliche Session-Daten (vereinfacht)\n            session_data = {}\n            if self.context_manager and self.context_manager.session_managers:\n                for session_id, session in self.context_manager.session_managers.items():\n                    try:\n                        if hasattr(session, 'history') and session.history:\n                            # Nur die letzten 20 Nachrichten pro Session f\u00fcr Checkpoint\n                            recent_history = session.history[-20:]\n                            session_data[session_id] = {\n                                \"history\": recent_history,\n                                \"session_type\": \"chatsession\",\n                                \"message_count\": len(session.history)\n                            }\n                        elif isinstance(session, dict) and session.get('history'):\n                            session_data[session_id] = {\n                                \"history\": session['history'][-20:],\n                                \"session_type\": \"fallback\",\n                                \"message_count\": len(session['history'])\n                            }\n                    except Exception as e:\n                        rprint(f\"Skipping session {session_id} in checkpoint: {e}\")\n\n            # Sammle serialisierbare Variable-Scopes\n            variable_scopes = {}\n            if self.variable_manager:\n                NON_SERIALIZABLE_KEYS = {\n                    \"tool_registry\", \"variable_manager\", \"context_manager\", \"agent_instance\",\n                    \"llm_tool_node_instance\", \"task_planner_instance\", \"task_executor_instance\",\n                    \"progress_tracker\", \"session_managers\", \"stream_callback\"\n                }\n\n                for scope_name, scope_data in self.variable_manager.scopes.items():\n                    if isinstance(scope_data, dict):\n                        # Filtere nicht-serialisierbare Objekte heraus\n                        clean_scope = {\n                            k: v for k, v in scope_data.items()\n                            if k not in NON_SERIALIZABLE_KEYS\n                        }\n                        variable_scopes[scope_name] = clean_scope\n                    else:\n                        try:\n                            # Teste Serialisierbarkeit\n                            pickle.dumps(scope_data)\n                            variable_scopes[scope_name] = scope_data\n                        except:\n                            # \u00dcberspringe nicht-serialisierbare Scopes\n                            pass\n\n            # Erstelle konsolidierten Checkpoint\n            checkpoint = AgentCheckpoint(\n                timestamp=datetime.now(),\n                agent_state={\n                    \"is_running\": self.is_running,\n                    \"is_paused\": self.is_paused,\n                    \"amd_data\": amd_data,\n                    \"active_session\": self.active_session,\n                    \"system_status\": self.shared.get(\"system_status\", \"idle\")\n                },\n                task_state={\n                    task_id: asdict(task) for task_id, task in self.shared.get(\"tasks\", {}).items()\n                },\n                world_model=self.shared.get(\"world_model\", {}),\n                active_flows=[\"task_flow\", \"response_flow\"],\n                metadata={\n                    \"session_id\": self.shared.get(\"session_id\", \"default\"),\n                    \"last_query\": self.shared.get(\"current_query\", \"\"),\n                    \"checkpoint_version\": \"3.0_simplified\",\n                    \"agent_name\": self.amd.name\n                },\n                # Konsolidierte Zusatzdaten\n                session_data=session_data,\n                variable_scopes=variable_scopes,\n                results_store=self.shared.get(\"results\", {}),\n                conversation_history=self.shared.get(\"conversation_history\", [])[-50:],  # Letzte 50 Nachrichten\n                tool_capabilities=self._tool_capabilities.copy()\n            )\n\n            rprint(f\"Vereinfachter Checkpoint erstellt mit {len(session_data)} Sessions\")\n            return checkpoint\n\n        except Exception as e:\n            eprint(f\"Checkpoint-Erstellung fehlgeschlagen: {e}\")\n            import traceback\n            print(traceback.format_exc())\n            raise\n\n    async def _save_checkpoint(self, checkpoint: AgentCheckpoint, filepath: str = None):\n        \"\"\"Vereinfachtes Checkpoint-Speichern - alles in eine Datei\"\"\"\n        try:\n            from toolboxv2 import get_app\n            folder = str(get_app().data_dir) + '/Agents/checkpoint/' + self.amd.name\n            if not os.path.exists(folder):\n                os.makedirs(folder, exist_ok=True)\n\n            if not filepath:\n                timestamp = checkpoint.timestamp.strftime(\"%Y%m%d_%H%M%S\")\n                filepath = f\"agent_checkpoint_{timestamp}.pkl\"\n            filepath = os.path.join(folder, filepath)\n\n            # Sessions vor dem Speichern synchronisieren\n            if self.context_manager and self.context_manager.session_managers:\n                for session_id, session in self.context_manager.session_managers.items():\n                    try:\n                        if hasattr(session, 'save'):\n                            await session.save()\n                        elif hasattr(session, '_save_to_memory'):\n                            session._save_to_memory()\n                    except Exception as e:\n                        rprint(f\"Session sync error f\u00fcr {session_id}: {e}\")\n\n            # Speichere Checkpoint direkt\n            with open(filepath, 'wb') as f:\n                pickle.dump(checkpoint, f)\n\n            self.last_checkpoint = checkpoint.timestamp\n\n            # Erstelle einfache Zusammenfassung\n            summary_parts = []\n            if hasattr(checkpoint, 'session_data') and checkpoint.session_data:\n                summary_parts.append(f\"{len(checkpoint.session_data)} sessions\")\n            if checkpoint.task_state:\n                completed_tasks = len([t for t in checkpoint.task_state.values() if t.get(\"status\") == \"completed\"])\n                summary_parts.append(f\"{completed_tasks} completed tasks\")\n            if hasattr(checkpoint, 'variable_scopes') and checkpoint.variable_scopes:\n                summary_parts.append(f\"{len(checkpoint.variable_scopes)} variable scopes\")\n\n            summary = \"; \".join(summary_parts) if summary_parts else \"Basic checkpoint\"\n            rprint(f\"Checkpoint gespeichert: {filepath} ({summary})\")\n            return True\n\n        except Exception as e:\n            eprint(f\"Checkpoint-Speicherung fehlgeschlagen: {e}\")\n            print(checkpoint)\n            return False\n\n    async def load_latest_checkpoint(self, auto_restore_history: bool = True, max_age_hours: int = 24) -&gt; dict[\n        str, Any]:\n        \"\"\"Vereinfachtes Checkpoint-Laden mit automatischer History-Wiederherstellung\"\"\"\n        try:\n            from toolboxv2 import get_app\n            folder = str(get_app().data_dir) + '/Agents/checkpoint/' + self.amd.name\n\n            if not os.path.exists(folder):\n                return {\"success\": False, \"error\": \"Kein Checkpoint-Verzeichnis gefunden\"}\n\n            # Finde neuesten Checkpoint\n            checkpoint_files = []\n            for file in os.listdir(folder):\n                if file.endswith('.pkl') and file.startswith('agent_checkpoint_'):\n                    filepath = os.path.join(folder, file)\n                    try:\n                        timestamp_str = file.replace('agent_checkpoint_', '').replace('.pkl', '')\n                        if timestamp_str == 'final_checkpoint':\n                            file_time = datetime.fromtimestamp(os.path.getmtime(filepath))\n                        else:\n                            file_time = datetime.strptime(timestamp_str, \"%Y%m%d_%H%M%S\")\n\n                        age_hours = (datetime.now() - file_time).total_seconds() / 3600\n                        if age_hours &lt;= max_age_hours:\n                            checkpoint_files.append((filepath, file_time, age_hours))\n                    except Exception:\n                        continue\n\n            if not checkpoint_files:\n                return {\"success\": False, \"error\": f\"Keine g\u00fcltigen Checkpoints in {max_age_hours} Stunden gefunden\"}\n\n            # Lade neuesten Checkpoint\n            checkpoint_files.sort(key=lambda x: x[1], reverse=True)\n            latest_checkpoint_path, latest_timestamp, age_hours = checkpoint_files[0]\n\n            rprint(f\"Lade Checkpoint: {latest_checkpoint_path} (Alter: {age_hours:.1f}h)\")\n\n            with open(latest_checkpoint_path, 'rb') as f:\n                checkpoint: AgentCheckpoint = pickle.load(f)\n\n            # Stelle Agent-Status wieder her\n            restore_stats = await self._restore_from_checkpoint_simplified(checkpoint, auto_restore_history)\n\n            # Re-initialisiere Kontext-Awareness\n            await self.initialize_context_awareness()\n\n            return {\n                \"success\": True,\n                \"checkpoint_file\": latest_checkpoint_path,\n                \"checkpoint_age_hours\": age_hours,\n                \"checkpoint_timestamp\": latest_timestamp.isoformat(),\n                \"available_checkpoints\": len(checkpoint_files),\n                \"restore_stats\": restore_stats\n            }\n\n        except Exception as e:\n            eprint(f\"Checkpoint-Laden fehlgeschlagen: {e}\")\n            import traceback\n            print(traceback.format_exc())\n            return {\"success\": False, \"error\": str(e)}\n\n    async def _restore_from_checkpoint_simplified(self, checkpoint: AgentCheckpoint, auto_restore_history: bool) -&gt; \\\n    dict[\n        str, Any]:\n        \"\"\"Vereinfachte Checkpoint-Wiederherstellung\"\"\"\n        restore_stats = {\n            \"agent_state_restored\": False,\n            \"world_model_restored\": False,\n            \"tasks_restored\": 0,\n            \"sessions_restored\": 0,\n            \"variables_restored\": 0,\n            \"conversation_restored\": 0,\n            \"errors\": []\n        }\n\n        try:\n            # 1. Agent-Status wiederherstellen\n            if checkpoint.agent_state:\n                self.is_running = checkpoint.agent_state.get(\"is_running\", False)\n                self.is_paused = checkpoint.agent_state.get(\"is_paused\", False)\n                self.active_session = checkpoint.agent_state.get(\"active_session\")\n\n                # AMD-Daten selektiv wiederherstellen\n                amd_data = checkpoint.agent_state.get(\"amd_data\", {})\n                if amd_data:\n                    # Nur sichere Felder wiederherstellen\n                    safe_fields = [\"name\", \"use_fast_response\", \"max_input_tokens\"]\n                    for field in safe_fields:\n                        if field in amd_data and hasattr(self.amd, field):\n                            setattr(self.amd, field, amd_data[field])\n\n                    # Persona wiederherstellen falls vorhanden\n                    if \"persona\" in amd_data and amd_data[\"persona\"]:\n                        try:\n                            persona_data = amd_data[\"persona\"]\n                            if isinstance(persona_data, dict):\n                                self.amd.persona = PersonaConfig(**persona_data)\n                        except Exception as e:\n                            restore_stats[\"errors\"].append(f\"Persona restore failed: {e}\")\n\n                restore_stats[\"agent_state_restored\"] = True\n\n            # 2. World Model wiederherstellen\n            if checkpoint.world_model:\n                self.shared[\"world_model\"] = checkpoint.world_model.copy()\n                self.world_model = checkpoint.world_model.copy()\n                restore_stats[\"world_model_restored\"] = True\n\n            # 3. Variable System wiederherstellen\n            if hasattr(checkpoint, 'variable_scopes') and checkpoint.variable_scopes:\n                # Variable Manager neu initialisieren\n                self.variable_manager = VariableManager(self.shared[\"world_model\"], self.shared)\n\n                # Basis-Scopes einrichten\n                self._setup_variable_scopes()\n\n                # Gespeicherte Scopes wiederherstellen\n                for scope_name, scope_data in checkpoint.variable_scopes.items():\n                    try:\n                        self.variable_manager.register_scope(scope_name, scope_data)\n                        restore_stats[\"variables_restored\"] += 1\n                    except Exception as e:\n                        restore_stats[\"errors\"].append(f\"Variable scope {scope_name}: {e}\")\n\n                # Runtime-Objekte wieder einsetzen\n                self.variable_manager.set(\"shared\", \"variable_manager\", self.variable_manager)\n                self.variable_manager.set(\"shared\", \"context_manager\", self.context_manager)\n                self.variable_manager.set(\"shared\", \"agent_instance\", self)\n\n                self.shared[\"variable_manager\"] = self.variable_manager\n\n            # 4. Tasks wiederherstellen\n            if checkpoint.task_state:\n                restored_tasks = {}\n                for task_id, task_data in checkpoint.task_state.items():\n                    try:\n                        task_type = task_data.get(\"type\", \"generic\")\n                        if task_type == \"LLMTask\":\n                            restored_tasks[task_id] = LLMTask(**task_data)\n                        elif task_type == \"ToolTask\":\n                            restored_tasks[task_id] = ToolTask(**task_data)\n                        elif task_type == \"DecisionTask\":\n                            restored_tasks[task_id] = DecisionTask(**task_data)\n                        else:\n                            restored_tasks[task_id] = Task(**task_data)\n\n                        restore_stats[\"tasks_restored\"] += 1\n                    except Exception as e:\n                        restore_stats[\"errors\"].append(f\"Task {task_id}: {e}\")\n\n                self.shared[\"tasks\"] = restored_tasks\n\n            # 5. Results Store wiederherstellen\n            if hasattr(checkpoint, 'results_store') and checkpoint.results_store:\n                self.shared[\"results\"] = checkpoint.results_store\n                if self.variable_manager:\n                    self.variable_manager.set_results_store(checkpoint.results_store)\n\n            # 6. Sessions und Conversation wiederherstellen (falls gew\u00fcnscht)\n            if auto_restore_history:\n                await self._restore_sessions_and_conversation_simplified(checkpoint, restore_stats)\n\n            # 7. Tool Capabilities wiederherstellen\n            if hasattr(checkpoint, 'tool_capabilities') and checkpoint.tool_capabilities:\n                self._tool_capabilities = checkpoint.tool_capabilities.copy()\n\n            # Status setzen\n            self.shared[\"system_status\"] = \"restored\"\n            restore_stats[\"restoration_timestamp\"] = datetime.now().isoformat()\n\n            rprint(\n                f\"Checkpoint wiederhergestellt: {restore_stats['tasks_restored']} Tasks, {restore_stats['sessions_restored']} Sessions, {len(restore_stats['errors'])} Fehler\")\n            return restore_stats\n\n        except Exception as e:\n            eprint(f\"Checkpoint-Wiederherstellung fehlgeschlagen: {e}\")\n            import traceback\n            print(traceback.format_exc())\n            restore_stats[\"errors\"].append(f\"Critical restore error: {e}\")\n            return restore_stats\n\n    async def _restore_sessions_and_conversation_simplified(self, checkpoint: AgentCheckpoint, restore_stats: dict):\n        \"\"\"Vereinfachte Session- und Conversation-Wiederherstellung\"\"\"\n        try:\n            # Context Manager sicherstellen\n            if not self.context_manager:\n                self.context_manager = UnifiedContextManager(self)\n                self.context_manager.variable_manager = self.variable_manager\n\n            # Sessions wiederherstellen\n            if hasattr(checkpoint, 'session_data') and checkpoint.session_data:\n                for session_id, session_info in checkpoint.session_data.items():\n                    try:\n                        # Session \u00fcber Context Manager initialisieren\n                        max_length = session_info.get(\"message_count\", 200)\n                        restored_session = await self.context_manager.initialize_session(session_id, max_length)\n\n                        # History wiederherstellen\n                        history = session_info.get(\"history\", [])\n                        if history and hasattr(restored_session, 'history'):\n                            # Direkt in Session-History einf\u00fcgen\n                            restored_session.history.extend(history)\n\n                        restore_stats[\"sessions_restored\"] += 1\n                    except Exception as e:\n                        restore_stats[\"errors\"].append(f\"Session {session_id}: {e}\")\n\n            # Conversation History wiederherstellen\n            if hasattr(checkpoint, 'conversation_history') and checkpoint.conversation_history:\n                self.shared[\"conversation_history\"] = checkpoint.conversation_history\n                restore_stats[\"conversation_restored\"] = len(checkpoint.conversation_history)\n\n            # Update shared context\n            self.shared[\"context_manager\"] = self.context_manager\n            if self.context_manager.session_managers:\n                self.shared[\"session_managers\"] = self.context_manager.session_managers\n                self.shared[\"session_initialized\"] = True\n\n        except Exception as e:\n            restore_stats[\"errors\"].append(f\"Session/conversation restore failed: {e}\")\n\n    async def _maybe_checkpoint(self):\n        \"\"\"Vereinfachtes automatisches Checkpointing\"\"\"\n        if not self.enable_pause_resume:\n            return\n\n        now = datetime.now()\n        if (not self.last_checkpoint or\n            (now - self.last_checkpoint).seconds &gt;= self.checkpoint_interval):\n\n            try:\n                checkpoint = await self._create_checkpoint()\n                await self._save_checkpoint(checkpoint)\n            except Exception as e:\n                eprint(f\"Automatic checkpoint failed: {e}\")\n\n\n    async def save_context_to_session(self, session_id: str = None, context_type: str = \"full\") -&gt; bool:\n        \"\"\"Save current context to ChatSession for persistent storage\"\"\"\n        try:\n            session_id = session_id or self.shared.get(\"session_id\", \"default\")\n\n            if not self.context_manager:\n                eprint(\"Context manager not available\")\n                return False\n\n            # Build comprehensive context\n            unified_context = await self.context_manager.build_unified_context(session_id, None, context_type)\n\n            # Create context message for session storage\n            context_message = {\n                \"role\": \"system\",\n                \"content\": f\"[CONTEXT_SNAPSHOT_{context_type.upper()}] \" + json.dumps(unified_context, default=str),\n                \"timestamp\": datetime.now().isoformat(),\n                \"context_type\": context_type,\n                \"metadata\": {\n                    \"is_context_snapshot\": True,\n                    \"context_version\": \"2.0\",\n                    \"agent_name\": self.amd.name,\n                    \"session_stats\": unified_context.get(\"session_stats\", {}),\n                    \"variables_count\": len(unified_context.get(\"variables\", {}).get(\"recent_results\", [])),\n                    \"execution_state\": unified_context.get(\"execution_state\", {}).get(\"system_status\", \"unknown\")\n                }\n            }\n\n            # Store in session\n            await self.context_manager.add_interaction(\n                session_id,\n                \"system\",\n                context_message[\"content\"],\n                metadata=context_message[\"metadata\"]\n            )\n\n            rprint(f\"Context snapshot saved to session {session_id} (type: {context_type})\")\n            return True\n\n        except Exception as e:\n            eprint(f\"Failed to save context to session: {e}\")\n            return False\n\n    async def load_context_from_session(self, session_id: str, context_type: str = \"full\") -&gt; dict[str, Any]:\n        \"\"\"Load context from ChatSession storage\"\"\"\n        try:\n            if not self.context_manager:\n                return {\"error\": \"Context manager not available\"}\n\n            session = self.context_manager.session_managers.get(session_id)\n            if not session:\n                return {\"error\": f\"Session {session_id} not found\"}\n\n            # Search for context snapshots in session history\n            context_snapshots = []\n\n            if hasattr(session, 'history'):\n                for message in reversed(session.history):  # Search from newest\n                    if (message.get(\"role\") == \"system\" and\n                        message.get(\"metadata\", {}).get(\"is_context_snapshot\") and\n                        message.get(\"metadata\", {}).get(\"context_type\") == context_type):\n\n                        try:\n                            # Extract context data\n                            content = message.get(\"content\", \"\")\n                            if content.startswith(f\"[CONTEXT_SNAPSHOT_{context_type.upper()}]\"):\n                                json_data = content.replace(f\"[CONTEXT_SNAPSHOT_{context_type.upper()}] \", \"\")\n                                context_data = json.loads(json_data)\n                                context_snapshots.append({\n                                    \"context\": context_data,\n                                    \"timestamp\": message.get(\"timestamp\"),\n                                    \"metadata\": message.get(\"metadata\", {})\n                                })\n                        except Exception as e:\n                            wprint(f\"Failed to parse context snapshot: {e}\")\n\n            if context_snapshots:\n                # Return most recent context snapshot\n                latest_context = context_snapshots[0]\n                rprint(f\"Loaded context snapshot from session {session_id} (timestamp: {latest_context['timestamp']})\")\n                return latest_context[\"context\"]\n            else:\n                return {\"error\": f\"No context snapshots of type '{context_type}' found in session {session_id}\"}\n\n        except Exception as e:\n            eprint(f\"Failed to load context from session: {e}\")\n            return {\"error\": str(e)}\n\n    async def cleanup_session_context(self, session_id: str = None, keep_count: int = 100,\n                                      remove_old_snapshots: bool = True) -&gt; dict[str, Any]:\n        \"\"\"Cleanup session context by removing old snapshots and entries\"\"\"\n        try:\n            session_id = session_id or self.shared.get(\"session_id\", \"default\")\n\n            if not self.context_manager:\n                return {\"error\": \"Context manager not available\"}\n\n            session = self.context_manager.session_managers.get(session_id)\n            if not session or not hasattr(session, 'history'):\n                return {\"error\": f\"Session {session_id} not found or has no history\"}\n\n            cleanup_stats = {\n                \"original_message_count\": len(session.history),\n                \"context_snapshots_removed\": 0,\n                \"context_entries_removed\": 0,\n                \"regular_messages_kept\": 0,\n                \"cleanup_performed\": False\n            }\n\n            if len(session.history) &lt;= keep_count:\n                return {**cleanup_stats, \"message\": \"No cleanup needed\"}\n\n            # Separate different types of messages\n            regular_messages = []\n            context_snapshots = []\n            context_entries = []\n\n            for message in session.history:\n                metadata = message.get(\"metadata\", {})\n\n                if metadata.get(\"is_context_snapshot\"):\n                    context_snapshots.append(message)\n                elif metadata.get(\"is_context_entry\"):\n                    context_entries.append(message)\n                else:\n                    regular_messages.append(message)\n\n            # Keep most recent regular messages\n            messages_to_keep = regular_messages[-keep_count:]\n            cleanup_stats[\"regular_messages_kept\"] = len(messages_to_keep)\n\n            # Keep most recent context snapshots (if not removing)\n            if not remove_old_snapshots:\n                recent_snapshots = context_snapshots[-5:]  # Keep last 5 snapshots\n                messages_to_keep.extend(recent_snapshots)\n            else:\n                cleanup_stats[\"context_snapshots_removed\"] = len(context_snapshots)\n\n            # Keep persistent context entries\n            persistent_entries = [\n                entry for entry in context_entries\n                if entry.get(\"persistent\", True)\n            ]\n            messages_to_keep.extend(persistent_entries)\n            cleanup_stats[\"context_entries_removed\"] = len(context_entries) - len(persistent_entries)\n\n            # Sort by timestamp and update session\n            messages_to_keep.sort(key=lambda x: x.get(\"timestamp\", \"\"))\n            session.history = messages_to_keep\n\n            cleanup_stats.update({\n                \"final_message_count\": len(session.history),\n                \"cleanup_performed\": True,\n                \"messages_removed\": cleanup_stats[\"original_message_count\"] - len(session.history)\n            })\n\n            rprint(f\"Session cleanup completed: {cleanup_stats['messages_removed']} messages removed\")\n            return cleanup_stats\n\n        except Exception as e:\n            eprint(f\"Failed to cleanup session context: {e}\")\n            return {\"error\": str(e)}\n\n    def get_session_storage_stats(self) -&gt; dict[str, Any]:\n        \"\"\"Get comprehensive session storage statistics\"\"\"\n        try:\n            stats = {\n                \"context_manager_active\": bool(self.context_manager),\n                \"total_sessions\": 0,\n                \"session_details\": {},\n                \"storage_summary\": {\n                    \"total_messages\": 0,\n                    \"context_snapshots\": 0,\n                    \"context_entries\": 0,\n                    \"regular_messages\": 0\n                }\n            }\n\n            if not self.context_manager:\n                return stats\n\n            stats[\"total_sessions\"] = len(self.context_manager.session_managers)\n\n            for session_id, session in self.context_manager.session_managers.items():\n                session_stats = {\n                    \"session_type\": \"chatsession\" if hasattr(session, 'history') else \"fallback\",\n                    \"message_count\": 0,\n                    \"context_snapshots\": 0,\n                    \"context_entries\": 0,\n                    \"regular_messages\": 0,\n                    \"storage_size_estimate\": 0\n                }\n\n                if hasattr(session, 'history'):\n                    session_stats[\"message_count\"] = len(session.history)\n\n                    for message in session.history:\n                        content_size = len(str(message))\n                        session_stats[\"storage_size_estimate\"] += content_size\n\n                        metadata = message.get(\"metadata\", {})\n                        if metadata.get(\"is_context_snapshot\"):\n                            session_stats[\"context_snapshots\"] += 1\n                        elif metadata.get(\"is_context_entry\"):\n                            session_stats[\"context_entries\"] += 1\n                        else:\n                            session_stats[\"regular_messages\"] += 1\n\n                elif isinstance(session, dict) and 'history' in session:\n                    session_stats[\"message_count\"] = len(session['history'])\n                    session_stats[\"regular_messages\"] = len(session['history'])\n                    session_stats[\"storage_size_estimate\"] = sum(len(str(msg)) for msg in session['history'])\n\n                stats[\"session_details\"][session_id] = session_stats\n\n                # Update totals\n                stats[\"storage_summary\"][\"total_messages\"] += session_stats[\"message_count\"]\n                stats[\"storage_summary\"][\"context_snapshots\"] += session_stats[\"context_snapshots\"]\n                stats[\"storage_summary\"][\"context_entries\"] += session_stats[\"context_entries\"]\n                stats[\"storage_summary\"][\"regular_messages\"] += session_stats[\"regular_messages\"]\n\n            # Estimate total storage size\n            stats[\"storage_summary\"][\"estimated_total_size_kb\"] = sum(\n                details[\"storage_size_estimate\"] for details in stats[\"session_details\"].values()\n            ) / 1024\n\n            return stats\n\n        except Exception as e:\n            eprint(f\"Failed to get session storage stats: {e}\")\n            return {\"error\": str(e)}\n\n    def list_available_checkpoints(self, max_age_hours: int = 168) -&gt; list[dict[str, Any]]:  # Default 1 week\n        \"\"\"List all available checkpoints with metadata\"\"\"\n        try:\n            from toolboxv2 import get_app\n            folder = str(get_app().data_dir) + '/Agents/checkpoint/' + self.amd.name\n\n            if not os.path.exists(folder):\n                return []\n\n            checkpoints = []\n            for file in os.listdir(folder):\n                if file.endswith('.pkl') and file.startswith('agent_checkpoint_'):\n                    filepath = os.path.join(folder, file)\n                    try:\n                        # Get file info\n                        file_stat = os.stat(filepath)\n                        file_size = file_stat.st_size\n                        modified_time = datetime.fromtimestamp(file_stat.st_mtime)\n\n                        # Extract timestamp from filename\n                        timestamp_str = file.replace('agent_checkpoint_', '').replace('.pkl', '')\n                        if timestamp_str == 'final_checkpoint':\n                            checkpoint_time = modified_time\n                            checkpoint_type = \"final\"\n                        else:\n                            checkpoint_time = datetime.strptime(timestamp_str, \"%Y%m%d_%H%M%S\")\n                            checkpoint_type = \"regular\"\n\n                        # Check age\n                        age_hours = (datetime.now() - checkpoint_time).total_seconds() / 3600\n                        if age_hours &lt;= max_age_hours:\n\n                            # Try to load checkpoint metadata without full loading\n                            metadata = {}\n                            try:\n                                with open(filepath, 'rb') as f:\n                                    checkpoint = pickle.load(f)\n                                metadata = {\n                                    \"tasks_count\": len(checkpoint.task_state) if checkpoint.task_state else 0,\n                                    \"world_model_entries\": len(checkpoint.world_model) if checkpoint.world_model else 0,\n                                    \"session_id\": checkpoint.metadata.get(\"session_id\", \"unknown\") if hasattr(\n                                        checkpoint, 'metadata') and checkpoint.metadata else \"unknown\",\n                                    \"last_query\": checkpoint.metadata.get(\"last_query\", \"unknown\")[:100] if hasattr(\n                                        checkpoint, 'metadata') and checkpoint.metadata else \"unknown\"\n                                }\n                            except:\n                                metadata = {\"load_error\": True}\n\n                            checkpoints.append({\n                                \"filepath\": filepath,\n                                \"filename\": file,\n                                \"checkpoint_type\": checkpoint_type,\n                                \"timestamp\": checkpoint_time.isoformat(),\n                                \"age_hours\": round(age_hours, 1),\n                                \"file_size_kb\": round(file_size / 1024, 1),\n                                \"metadata\": metadata\n                            })\n\n                    except Exception as e:\n                        import traceback\n                        print(traceback.format_exc())\n                        wprint(f\"Could not analyze checkpoint file {file}: {e}\")\n                        continue\n\n            # Sort by timestamp (newest first)\n            checkpoints.sort(key=lambda x: x[\"timestamp\"], reverse=True)\n\n            return checkpoints\n\n        except Exception as e:\n            import traceback\n            print(traceback.format_exc())\n            eprint(f\"Failed to list checkpoints: {e}\")\n            return []\n\n    async def delete_old_checkpoints(self, keep_count: int = 5, max_age_hours: int = 168) -&gt; dict[str, Any]:\n        \"\"\"Delete old checkpoints, keeping the most recent ones\"\"\"\n        try:\n            checkpoints = self.list_available_checkpoints(\n                max_age_hours=max_age_hours * 2)  # Look further back for deletion\n\n            deleted_count = 0\n            deleted_size_kb = 0\n            errors = []\n\n            if len(checkpoints) &gt; keep_count:\n                # Keep the newest, delete the rest (except final checkpoint)\n                to_delete = checkpoints[keep_count:]\n\n                for checkpoint in to_delete:\n                    if checkpoint[\"checkpoint_type\"] != \"final\":  # Never delete final checkpoint\n                        try:\n                            os.remove(checkpoint[\"filepath\"])\n                            deleted_count += 1\n                            deleted_size_kb += checkpoint[\"file_size_kb\"]\n                            rprint(f\"Deleted old checkpoint: {checkpoint['filename']}\")\n                        except Exception as e:\n                            import traceback\n                            print(traceback.format_exc())\n                            errors.append(f\"Failed to delete {checkpoint['filename']}: {e}\")\n\n            # Also delete checkpoints older than max_age_hours\n            old_checkpoints = [cp for cp in checkpoints if\n                               cp[\"age_hours\"] &gt; max_age_hours and cp[\"checkpoint_type\"] != \"final\"]\n            for checkpoint in old_checkpoints:\n                if checkpoint not in checkpoints[keep_count:]:  # Don't double-delete\n                    try:\n                        os.remove(checkpoint[\"filepath\"])\n                        deleted_count += 1\n                        deleted_size_kb += checkpoint[\"file_size_kb\"]\n                        rprint(f\"Deleted aged checkpoint: {checkpoint['filename']}\")\n                    except Exception as e:\n                        import traceback\n                        print(traceback.format_exc())\n                        errors.append(f\"Failed to delete {checkpoint['filename']}: {e}\")\n\n            return {\n                \"success\": True,\n                \"deleted_count\": deleted_count,\n                \"freed_space_kb\": round(deleted_size_kb, 1),\n                \"remaining_checkpoints\": len(checkpoints) - deleted_count,\n                \"errors\": errors\n            }\n\n        except Exception as e:\n            import traceback\n            print(traceback.format_exc())\n            eprint(f\"Failed to delete old checkpoints: {e}\")\n            return {\n                \"success\": False,\n                \"error\": str(e),\n                \"deleted_count\": 0\n            }\n\n    # ===== TOOL AND NODE MANAGEMENT =====\n    def _get_tool_analysis_path(self) -&gt; str:\n        \"\"\"Get path for tool analysis cache\"\"\"\n        from toolboxv2 import get_app\n        folder = str(get_app().data_dir) + '/Agents/capabilities/' + self.amd.name\n        os.makedirs(folder, exist_ok=True)\n        return folder + '/tool_capabilities.json'\n\n    def _get_context_path(self, session_id=None) -&gt; str:\n        \"\"\"Get path for tool analysis cache\"\"\"\n        from toolboxv2 import get_app\n        folder = str(get_app().data_dir) + '/Agents/context/' + self.amd.name\n        os.makedirs(folder, exist_ok=True)\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        session_suffix = f\"_session_{session_id}\" if session_id else \"\"\n        filepath = f\"agent_context_{self.amd.name}_{timestamp}{session_suffix}.json\"\n        return folder + f'/{filepath}'\n\n    def add_first_class_tool(self, tool_func: Callable, name: str, description: str):\n        \"\"\"\n        Add a first-class meta-tool that can be used by the LLMReasonerNode.\n        These are different from regular tools - they control agent sub-systems.\n\n        Args:\n            tool_func: The function to register as a meta-tool\n            name: Name of the meta-tool\n            description: Description of when and how to use it\n        \"\"\"\n\n        # Validate the tool function\n        if not callable(tool_func):\n            raise ValueError(\"Tool function must be callable\")\n\n        # Register in the reasoner's meta-tool registry (if reasoner exists)\n        if hasattr(self.task_flow, 'llm_reasoner'):\n            if not hasattr(self.task_flow.llm_reasoner, 'meta_tools_registry'):\n                self.task_flow.llm_reasoner.meta_tools_registry = {}\n\n            self.task_flow.llm_reasoner.meta_tools_registry[name] = {\n                \"function\": tool_func,\n                \"description\": description,\n                \"added_at\": datetime.now().isoformat()\n            }\n\n            rprint(f\"First-class meta-tool added: {name}\")\n        else:\n            wprint(\"LLMReasonerNode not available for first-class tool registration\")\n\n    async def add_tool(self, tool_func: Callable, name: str = None, description: str = None, is_new=False):\n        \"\"\"Enhanced tool addition with intelligent analysis\"\"\"\n        if not asyncio.iscoroutinefunction(tool_func):\n            @wraps(tool_func)\n            async def async_wrapper(*args, **kwargs):\n                return await asyncio.to_thread(tool_func, *args, **kwargs)\n\n            effective_func = async_wrapper\n        else:\n            effective_func = tool_func\n\n        tool_name = name or effective_func.__name__\n        tool_description = description or effective_func.__doc__ or \"No description\"\n\n        # Store in registry\n        self._tool_registry[tool_name] = {\n            \"function\": effective_func,\n            \"description\": tool_description,\n            \"args_schema\": get_args_schema(tool_func)\n        }\n\n        # Add to available tools list\n        if tool_name not in self.shared[\"available_tools\"]:\n            self.shared[\"available_tools\"].append(tool_name)\n\n        # Intelligent tool analysis\n        if is_new:\n            await self._analyze_tool_capabilities(tool_name, tool_description)\n\n        rprint(f\"Tool added with analysis: {tool_name}\")\n\n    async def _analyze_tool_capabilities(self, tool_name: str, description: str, tool_args:str):\n        \"\"\"Analyze tool capabilities with LLM for smart usage\"\"\"\n\n        # Try to load existing analysis\n        existing_analysis = self._load_tool_analysis()\n\n        if tool_name in existing_analysis:\n            try:\n                # Validate cached data against the Pydantic model\n                ToolAnalysis.model_validate(existing_analysis[tool_name])\n                self._tool_capabilities[tool_name] = existing_analysis[tool_name]\n                rprint(f\"Loaded and validated cached analysis for {tool_name}\")\n            except ValidationError as e:\n                wprint(f\"Cached data for {tool_name} is invalid and will be regenerated: {e}\")\n                del self._tool_capabilities[tool_name]\n\n        if not LITELLM_AVAILABLE:\n            # Fallback analysis\n            self._tool_capabilities[tool_name] = {\n                \"use_cases\": [description],\n                \"triggers\": [tool_name.lower().replace('_', ' ')],\n                \"complexity\": \"unknown\",\n                \"confidence\": 0.3\n            }\n            return\n\n        # LLM-based intelligent analysis\n        prompt = f\"\"\"\nAnalyze this tool and identify ALL possible use cases, triggers, and connections:\n\nTool Name: {tool_name}\nargs: {tool_args}\nDescription: {description}\n\n\nProvide a comprehensive analysis covering:\n\n1. OBVIOUS use cases (direct functionality)\n2. INDIRECT connections (when this tool might be relevant)\n3. TRIGGER PHRASES (what user queries would benefit from this tool)\n4. COMPLEX scenarios (non-obvious applications)\n5. CONTEXTUAL usage (when combined with other information)\n\nExample for a \"get_user_name\" tool:\n- Obvious: When user asks \"what is my name\"\n- Indirect: Personalization, greetings, user identification\n- Triggers: \"my name\", \"who am I\", \"hello\", \"introduce yourself\", \"personalize\"\n- Complex: User context in multi-step tasks, addressing user directly\n- Contextual: Any response that could be personalized\n\nRule! no additional comments or text in the format !\nschema:\n {yaml.dump(ToolAnalysis.model_json_schema())}\n\nRespond in YAML format:\nExample:\n```yaml\nprimary_function: \"Retrieves the current user's name.\"\nuse_cases:\n  - \"Responding to 'what is my name?'\"\n  - \"Personalizing greeting messages.\"\ntrigger_phrases:\n  - \"my name\"\n  - \"who am I\"\n  - \"introduce yourself\"\nindirect_connections:\n  - \"User identification in multi-factor authentication.\"\n  - \"Tagging user-generated content.\"\ncomplexity_scenarios:\n  - \"In a multi-step task, remembering the user's name to personalize the final output.\"\nuser_intent_categories:\n  - \"Personalization\"\n  - \"User Identification\"\nconfidence_triggers:\n  \"my name\": 0.95\n  \"who am I\": 0.9\ntool_complexity: low/medium/high\n```\n\"\"\"\n        model = os.getenv(\"BASEMODEL\", self.amd.fast_llm_model)\n        for i in range(3):\n            try:\n                response = await self.a_run_llm_completion(\n                    model=model,\n                    messages=[{\"role\": \"user\", \"content\": prompt}],\n                    with_context=False,\n                    temperature=0.3,\n                    max_tokens=1000,\n                    task_id=f\"tool_analysis_{tool_name}\"\n                )\n\n                content = response.strip()\n\n                # Extract JSON\n                if \"```yaml\" in content:\n                    yaml_str = content.split(\"```yaml\")[1].split(\"```\")[0].strip()\n                else:\n                    yaml_str = content\n\n                analysis = yaml.safe_load(yaml_str)\n\n                # Store analysis\n                self._tool_capabilities[tool_name] = analysis\n\n                # Save to cache\n                await self._save_tool_analysis()\n\n                validated_analysis = ToolAnalysis.model_validate(analysis)\n                rprint(f\"Generated intelligent analysis for {tool_name}\")\n                break\n\n            except Exception as e:\n                import traceback\n                print(traceback.format_exc())\n                model = self.amd.complex_llm_model if i &gt; 1 else self.amd.fast_llm_model\n                eprint(f\"Tool analysis failed for {tool_name}: {e}\")\n                # Fallback\n                self._tool_capabilities[tool_name] = {\n                    \"primary_function\": description,\n                    \"use_cases\": [description],\n                    \"trigger_phrases\": [tool_name.lower().replace('_', ' ')],\n                    \"tool_complexity\": \"medium\"\n                }\n\n    def _load_tool_analysis(self) -&gt; dict[str, Any]:\n        \"\"\"Load tool analysis from cache\"\"\"\n        try:\n            if os.path.exists(self.tool_analysis_file):\n                with open(self.tool_analysis_file) as f:\n                    return json.load(f)\n        except Exception as e:\n            wprint(f\"Could not load tool analysis: {e}\")\n        return {}\n\n\n    async def save_context_to_file(self, session_id: str = None) -&gt; bool:\n        \"\"\"Save current context to file\"\"\"\n        try:\n            context = await self.get_context(session_id=session_id, format_for_llm=False)\n\n            filepath = self._get_context_path(session_id)\n\n            with open(filepath, 'w', encoding='utf-8') as f:\n                json.dump(context, f, indent=2, ensure_ascii=False, default=str)\n\n            rprint(f\"Context saved to: {filepath}\")\n            return True\n\n        except Exception as e:\n            eprint(f\"Failed to save context: {e}\")\n            return False\n\n    async def _save_tool_analysis(self):\n        \"\"\"Save tool analysis to cache\"\"\"\n        try:\n            with open(self.tool_analysis_file, 'w') as f:\n                json.dump(self._tool_capabilities, f, indent=2)\n        except Exception as e:\n            eprint(f\"Could not save tool analysis: {e}\")\n\n    def add_custom_flow(self, flow: AsyncFlow, name: str):\n        \"\"\"Add a custom flow for dynamic execution\"\"\"\n        self.add_tool(flow.run_async, name=name, description=f\"Custom flow: {flow.__class__.__name__}\")\n        rprint(f\"Custom node added: {name}\")\n\n    def get_tool_by_name(self, tool_name: str) -&gt; Callable | None:\n        \"\"\"Get tool function by name\"\"\"\n        return self._tool_registry.get(tool_name, {}).get(\"function\")\n\n    async def arun_function(self, function_name: str, *args, **kwargs) -&gt; Any:\n        \"\"\"\n        Asynchronously finds a function by its string name, executes it with\n        the given arguments, and returns the result.\n        \"\"\"\n        rprint(f\"Attempting to run function: {function_name} with args: {args}, kwargs: {kwargs}\")\n        target_function = self.get_tool_by_name(function_name)\n\n        start_time = time.perf_counter()\n        if not target_function:\n            raise ValueError(f\"Function '{function_name}' not found in the {self.amd.name}'s registered tools.\")\n\n        try:\n            if asyncio.iscoroutinefunction(target_function):\n                result = await target_function(*args, **kwargs)\n            else:\n                # If the function is not async, run it in a thread pool\n                loop = asyncio.get_running_loop()\n                result = await loop.run_in_executor(None, lambda: target_function(*args, **kwargs))\n\n            if asyncio.iscoroutine(result):\n                result = await result\n\n            if self.progress_tracker:\n                await self.progress_tracker.emit_event(ProgressEvent(\n                    event_type=\"tool_call\",  # Vereinheitlicht zu tool_call\n                    node_name=\"FlowAgent\",\n                    status=NodeStatus.COMPLETED,\n                    success=True,\n                    duration=time.perf_counter() - start_time,\n                    tool_name=function_name,\n                    tool_args=kwargs,\n                    tool_result=result,\n                    is_meta_tool=False,  # Klarstellen, dass es kein Meta-Tool ist\n                    metadata={\n                        \"result_type\": type(result).__name__,\n                        \"result_length\": len(str(result))\n                    }\n                ))\n            rprint(f\"Function {function_name} completed successfully with result: {result}\")\n            return result\n\n        except Exception as e:\n            eprint(f\"Function {function_name} execution failed: {e}\")\n            raise\n\n    # ===== FORMATTING =====\n\n    async def a_format_class(self,\n                             pydantic_model: type[BaseModel],\n                             prompt: str,\n                             message_context: list[dict] = None,\n                             max_retries: int = 2, auto_context=True) -&gt; dict[str, Any]:\n        \"\"\"\n        State-of-the-art LLM-based structured data formatting using Pydantic models.\n\n        Args:\n            pydantic_model: The Pydantic model class to structure the response\n            prompt: The main prompt for the LLM\n            message_context: Optional conversation context messages\n            max_retries: Maximum number of retry attempts\n\n        Returns:\n            dict: Validated structured data matching the Pydantic model\n\n        Raises:\n            ValidationError: If the LLM response cannot be validated against the model\n            RuntimeError: If all retry attempts fail\n        \"\"\"\n\n        if not LITELLM_AVAILABLE:\n            raise RuntimeError(\"LiteLLM is required for structured formatting but not available\")\n\n        # Generate schema documentation\n        schema = pydantic_model.model_json_schema()\n        model_name = pydantic_model.__name__\n\n        # Create enhanced prompt with schema\n        enhanced_prompt = f\"\"\"\n    {prompt}\n\n    CRITICAL FORMATTING REQUIREMENTS:\n    1. Respond ONLY in valid YAML format\n    2. Follow the exact schema structure provided\n    3. Use appropriate data types (strings, lists, numbers, booleans)\n    4. Include ALL required fields\n    5. No additional comments, explanations, or text outside the YAML\n\n    SCHEMA FOR {model_name}:\n    {yaml.dump(schema, default_flow_style=False, indent=2)}\n\n    EXAMPLE OUTPUT FORMAT:\n    ```yaml\n    # Your response here following the schema exactly\n    field_name: \"value\"\n    list_field:\n      - \"item1\"\n      - \"item2\"\n    boolean_field: true\n    number_field: 42\nRespond in YAML format only:\n\"\"\"\n        # Prepare messages\n        messages = []\n        if message_context:\n            messages.extend(message_context)\n        messages.append({\"role\": \"user\", \"content\": enhanced_prompt})\n\n        # Retry logic with progressive adjustments\n        last_error = None\n\n        for attempt in range(max_retries + 1):\n            try:\n                # Adjust parameters based on attempt\n                temperature = 0.1 + (attempt * 0.1)  # Increase temperature slightly on retries\n                max_tokens = min(2000 + (attempt * 500), 4000)  # Increase token limit on retries\n\n                rprint(f\"[{model_name}] Attempt {attempt + 1}/{max_retries + 1} (temp: {temperature})\")\n\n                # Generate LLM response\n                response = await self.a_run_llm_completion(\n                    model=self.amd.complex_llm_model,\n                    messages=messages,\n                    with_context=auto_context,\n                    temperature=temperature,\n                    max_tokens=max_tokens,\n                    task_id=f\"format_{model_name.lower()}_{attempt}\"\n                )\n\n                if not response or not response.strip():\n                    raise ValueError(\"Empty response from LLM\")\n\n                # Extract YAML content with multiple fallback strategies\n                yaml_content = self._extract_yaml_content(response)\n\n                if not yaml_content:\n                    raise ValueError(\"No valid YAML content found in response\")\n\n                # Parse YAML\n                try:\n                    parsed_data = yaml.safe_load(yaml_content)\n                except yaml.YAMLError as e:\n                    raise ValueError(f\"Invalid YAML syntax: {e}\")\n\n                if not isinstance(parsed_data, dict):\n                    raise ValueError(f\"Expected dict, got {type(parsed_data)}\")\n\n                # Validate against Pydantic model\n                try:\n                    validated_instance = pydantic_model.model_validate(parsed_data)\n                    validated_data = validated_instance.model_dump()\n\n                    rprint(f\"\u2705 Successfully formatted {model_name} on attempt {attempt + 1}\")\n                    return validated_data\n\n                except ValidationError as e:\n                    detailed_errors = []\n                    for error in e.errors():\n                        field_path = \" -&gt; \".join(str(x) for x in error['loc'])\n                        detailed_errors.append(f\"Field '{field_path}': {error['msg']}\")\n\n                    error_msg = \"Validation failed:\\n\" + \"\\n\".join(detailed_errors)\n                    raise ValueError(error_msg)\n\n            except Exception as e:\n                last_error = e\n                wprint(f\"[{model_name}] Attempt {attempt + 1} failed: {str(e)}\")\n\n                if attempt &lt; max_retries:\n                    # Add error feedback for next attempt\n                    error_feedback = f\"\\n\\nPREVIOUS ATTEMPT FAILED: {str(e)}\\nPlease correct the issues and provide valid YAML matching the schema exactly.\"\n                    messages[-1][\"content\"] = enhanced_prompt + error_feedback\n\n                    # Brief delay before retry\n                    await asyncio.sleep(0.5 * (attempt + 1))\n                else:\n                    eprint(f\"[{model_name}] All {max_retries + 1} attempts failed\")\n\n        # All attempts failed\n        raise RuntimeError(f\"Failed to format {model_name} after {max_retries + 1} attempts. Last error: {last_error}\")\n\n    def _extract_yaml_content(self, response: str) -&gt; str:\n        \"\"\"Extract YAML content from LLM response with multiple strategies\"\"\"\n        # Strategy 1: Extract from code blocks\n        if \"```yaml\" in response:\n            try:\n                yaml_content = response.split(\"```yaml\")[1].split(\"```\")[0].strip()\n                if yaml_content:\n                    return yaml_content\n            except IndexError:\n                pass\n\n        # Strategy 2: Extract from generic code blocks\n        if \"```\" in response:\n            try:\n                parts = response.split(\"```\")\n                for i, part in enumerate(parts):\n                    if i % 2 == 1:  # Odd indices are inside code blocks\n                        # Skip if it starts with a language identifier\n                        lines = part.strip().split('\\n')\n                        if lines and not lines[0].strip().isalpha():\n                            return part.strip()\n                        elif len(lines) &gt; 1:\n                            # Try without first line\n                            return '\\n'.join(lines[1:]).strip()\n            except:\n                pass\n\n        # Strategy 3: Look for YAML-like patterns\n        lines = response.split('\\n')\n        yaml_lines = []\n        in_yaml = False\n\n        for line in lines:\n            stripped = line.strip()\n\n            # Detect start of YAML-like content\n            if ':' in stripped and not stripped.startswith('#'):\n                in_yaml = True\n                yaml_lines.append(line)\n            elif in_yaml:\n                if stripped == '' or stripped.startswith(' ') or stripped.startswith('-') or ':' in stripped:\n                    yaml_lines.append(line)\n                else:\n                    # Potential end of YAML\n                    break\n\n        if yaml_lines:\n            return '\\n'.join(yaml_lines).strip()\n\n        # Strategy 4: Return entire response if it looks like YAML\n        if ':' in response and not response.strip().startswith('&lt;'):\n            return response.strip()\n\n        return \"\"\n    # ===== SERVER SETUP =====\n\n    def setup_a2a_server(self, host: str = \"0.0.0.0\", port: int = 5000, **kwargs):\n        \"\"\"Setup A2A server for bidirectional communication\"\"\"\n        if not A2A_AVAILABLE:\n            wprint(\"A2A not available, cannot setup server\")\n            return\n\n        try:\n            self.a2a_server = A2AServer(\n                host=host,\n                port=port,\n                agent_card=AgentCard(\n                    name=self.amd.name,\n                    description=\"Production-ready PocketFlow agent\",\n                    version=\"1.0.0\"\n                ),\n                **kwargs\n            )\n\n            # Register agent methods\n            @self.a2a_server.route(\"/run\")\n            async def handle_run(request_data):\n                query = request_data.get(\"query\", \"\")\n                session_id = request_data.get(\"session_id\", \"a2a_session\")\n\n                response = await self.a_run(query, session_id=session_id)\n                return {\"response\": response}\n\n            rprint(f\"A2A server setup on {host}:{port}\")\n\n        except Exception as e:\n            eprint(f\"Failed to setup A2A server: {e}\")\n\n    def setup_mcp_server(self, host: str = \"0.0.0.0\", port: int = 8000, name: str = None, **kwargs):\n        \"\"\"Setup MCP server\"\"\"\n        if not MCP_AVAILABLE:\n            wprint(\"MCP not available, cannot setup server\")\n            return\n\n        try:\n            server_name = name or f\"{self.amd.name}_MCP\"\n            self.mcp_server = FastMCP(server_name)\n\n            # Register agent as MCP tool\n            @self.mcp_server.tool()\n            async def agent_run(query: str, session_id: str = \"mcp_session\") -&gt; str:\n                \"\"\"Execute agent with given query\"\"\"\n                return await self.a_run(query, session_id=session_id)\n\n            rprint(f\"MCP server setup: {server_name}\")\n\n        except Exception as e:\n            eprint(f\"Failed to setup MCP server: {e}\")\n\n    # ===== LIFECYCLE MANAGEMENT =====\n\n    async def start_servers(self):\n        \"\"\"Start all configured servers\"\"\"\n        tasks = []\n\n        if self.a2a_server:\n            tasks.append(asyncio.create_task(self.a2a_server.start()))\n\n        if self.mcp_server:\n            tasks.append(asyncio.create_task(self.mcp_server.run()))\n\n        if tasks:\n            rprint(f\"Starting {len(tasks)} servers...\")\n            await asyncio.gather(*tasks, return_exceptions=True)\n\n    def clear_context(self, session_id: str = None) -&gt; bool:\n        \"\"\"Clear context \u00fcber UnifiedContextManager mit Session-spezifischer Unterst\u00fctzung\"\"\"\n        try:\n            #Clear \u00fcber Context Manager\n            if session_id:\n                # Clear specific session\n                if session_id in self.context_manager.session_managers:\n                    session = self.context_manager.session_managers[session_id]\n                    if hasattr(session, 'history'):\n                        session.history = []\n                    elif isinstance(session, dict) and 'history' in session:\n                        session['history'] = []\n\n                    # Remove from session managers\n                    del self.context_manager.session_managers[session_id]\n\n                    # Clear variable manager scope for this session\n                    if self.variable_manager:\n                        scope_name = f'session_{session_id}'\n                        if scope_name in self.variable_manager.scopes:\n                            del self.variable_manager.scopes[scope_name]\n\n                    rprint(f\"Context cleared for session: {session_id}\")\n            else:\n                # Clear all sessions\n                for session_id, session in self.context_manager.session_managers.items():\n                    if hasattr(session, 'history'):\n                        session.history = []\n                    elif isinstance(session, dict) and 'history' in session:\n                        session['history'] = []\n\n                self.context_manager.session_managers = {}\n                rprint(\"Context cleared for all sessions\")\n\n            # Clear context cache\n            self.context_manager._invalidate_cache(session_id)\n\n            # Clear current execution context in shared\n            context_keys_to_clear = [\n                \"current_query\", \"current_response\", \"current_plan\", \"tasks\",\n                \"results\", \"task_plans\", \"session_data\", \"formatted_context\",\n                \"synthesized_response\", \"quality_assessment\", \"plan_adaptations\",\n                \"executor_performance\", \"llm_tool_conversation\", \"aggregated_context\"\n            ]\n\n            for key in context_keys_to_clear:\n                if key in self.shared:\n                    if isinstance(self.shared[key], dict):\n                        self.shared[key] = {}\n                    elif isinstance(self.shared[key], list):\n                        self.shared[key] = []\n                    else:\n                        self.shared[key] = None\n\n            # Clear variable manager scopes (except core system variables)\n            if hasattr(self, 'variable_manager'):\n                # Clear user, results, tasks scopes\n                self.variable_manager.register_scope('user', {})\n                self.variable_manager.register_scope('results', {})\n                self.variable_manager.register_scope('tasks', {})\n                # Reset cache\n                self.variable_manager._cache.clear()\n\n            # Reset execution state\n            self.is_running = False\n            self.is_paused = False\n            self.shared[\"system_status\"] = \"idle\"\n\n            # Clear progress tracking\n            if hasattr(self, 'progress_tracker'):\n                self.progress_tracker.reset_session_metrics()\n\n            return True\n\n        except Exception as e:\n            eprint(f\"Failed to clear context: {e}\")\n            return False\n\n    async def clean_memory(self, deep_clean: bool = False) -&gt; bool:\n        \"\"\"Clean memory and context of the agent\"\"\"\n        try:\n            # Clear current context first\n            self.clear_context()\n\n            # Clean world model\n            self.shared[\"world_model\"] = {}\n            self.world_model = {}\n\n            # Clean performance metrics\n            self.shared[\"performance_metrics\"] = {}\n\n            # Deep clean session storage\n            session_managers = self.shared.get(\"session_managers\", {})\n            if session_managers:\n                for _manager_name, manager in session_managers.items():\n                    if hasattr(manager, 'clear_all_history'):\n                        await manager.clear_all_history()\n                    elif hasattr(manager, 'clear_history'):\n                        manager.clear_history()\n\n            # Clear session managers entirely\n            self.shared[\"session_managers\"] = {}\n            self.shared[\"session_initialized\"] = False\n\n            # Clean variable manager completely\n            if hasattr(self, 'variable_manager'):\n                # Reinitialize with clean state\n                self.variable_manager = VariableManager({}, self.shared)\n                self._setup_variable_scopes()\n\n            # Clean tool analysis cache if deep clean\n            if deep_clean:\n                self._tool_capabilities = {}\n                self._tool_analysis_cache = {}\n\n                # Remove tool analysis file\n                if hasattr(self, 'tool_analysis_file') and os.path.exists(self.tool_analysis_file):\n                    try:\n                        os.remove(self.tool_analysis_file)\n                        rprint(\"Removed tool analysis cache file\")\n                    except:\n                        pass\n\n            # Clean checkpoint data\n            self.checkpoint_data = {}\n            self.last_checkpoint = None\n\n            # Clean execution history\n            if hasattr(self.task_flow, 'executor_node'):\n                self.task_flow.executor_node.execution_history = []\n                self.task_flow.executor_node.results_store = {}\n\n            # Clean context manager sessions\n            if hasattr(self.task_flow, 'context_manager'):\n                self.task_flow.context_manager.session_managers = {}\n\n            # Clean LLM call statistics\n            self.shared.pop(\"llm_call_stats\", None)\n\n            # Force garbage collection\n            import gc\n            gc.collect()\n\n            rprint(f\"Memory cleaned (deep_clean: {deep_clean})\")\n            return True\n\n        except Exception as e:\n            eprint(f\"Failed to clean memory: {e}\")\n            return False\n\n    async def close(self):\n        \"\"\"Clean shutdown\"\"\"\n        self.is_running = False\n        self._shutdown_event.set()\n\n        # Create final checkpoint\n        if self.enable_pause_resume:\n            checkpoint = await self._create_checkpoint()\n            await self._save_checkpoint(checkpoint, \"final_checkpoint.pkl\")\n\n        # Shutdown executor\n        self.executor.shutdown(wait=True)\n\n        # Close servers\n        if self.a2a_server:\n            await self.a2a_server.close()\n\n        if self.mcp_server:\n            await self.mcp_server.close()\n\n        if hasattr(self, '_mcp_session_manager'):\n            await self._mcp_session_manager.cleanup_all()\n\n        rprint(\"Agent shutdown complete\")\n\n    @property\n    def total_cost(self) -&gt; float:\n        \"\"\"Get total cost if budget manager available\"\"\"\n        if hasattr(self.amd, 'budget_manager') and self.amd.budget_manager:\n            return getattr(self.amd.budget_manager, 'total_cost', 0.0)\n        return 0.0\n\n    def status(self, pretty_print: bool = False) -&gt; dict[str, Any] | str:\n        \"\"\"Get comprehensive agent status with optional pretty printing\"\"\"\n\n        # Core status information\n        base_status = {\n            \"agent_info\": {\n                \"name\": self.amd.name,\n                \"version\": \"2.0\",\n                \"type\": \"FlowAgent\"\n            },\n            \"runtime_status\": {\n                \"status\": self.shared.get(\"system_status\", \"idle\"),\n                \"is_running\": self.is_running,\n                \"is_paused\": self.is_paused,\n                \"uptime_seconds\": (datetime.now() - getattr(self, '_start_time', datetime.now())).total_seconds()\n            },\n            \"task_execution\": {\n                \"total_tasks\": len(self.shared.get(\"tasks\", {})),\n                \"active_tasks\": len([t for t in self.shared.get(\"tasks\", {}).values() if t.status == \"running\"]),\n                \"completed_tasks\": len([t for t in self.shared.get(\"tasks\", {}).values() if t.status == \"completed\"]),\n                \"failed_tasks\": len([t for t in self.shared.get(\"tasks\", {}).values() if t.status == \"failed\"]),\n                \"plan_adaptations\": self.shared.get(\"plan_adaptations\", 0)\n            },\n            \"conversation\": {\n                \"turns\": len(self.shared.get(\"conversation_history\", [])),\n                \"session_id\": self.shared.get(\"session_id\", self.active_session),\n                \"current_user\": self.shared.get(\"user_id\"),\n                \"last_query\": self.shared.get(\"current_query\", \"\")[:100] + \"...\" if len(\n                    self.shared.get(\"current_query\", \"\")) &gt; 100 else self.shared.get(\"current_query\", \"\")\n            },\n            \"capabilities\": {\n                \"available_tools\": len(self.shared.get(\"available_tools\", [])),\n                \"tool_names\": list(self.shared.get(\"available_tools\", [])),\n                \"analyzed_tools\": len(self._tool_capabilities),\n                \"world_model_size\": len(self.shared.get(\"world_model\", {})),\n                \"intelligence_level\": \"high\" if self._tool_capabilities else \"basic\"\n            },\n            \"memory_context\": {\n                \"session_initialized\": self.shared.get(\"session_initialized\", False),\n                \"session_managers\": len(self.shared.get(\"session_managers\", {})),\n                \"context_system\": \"advanced_session_aware\" if self.shared.get(\"session_initialized\") else \"basic\",\n                \"variable_scopes\": len(self.variable_manager.get_scope_info()) if hasattr(self,\n                                                                                          'variable_manager') else 0\n            },\n            \"performance\": {\n                \"total_cost\": self.total_cost,\n                \"checkpoint_enabled\": self.enable_pause_resume,\n                \"last_checkpoint\": self.last_checkpoint.isoformat() if self.last_checkpoint else None,\n                \"max_parallel_tasks\": self.max_parallel_tasks\n            },\n            \"servers\": {\n                \"a2a_server\": self.a2a_server is not None,\n                \"mcp_server\": self.mcp_server is not None,\n                \"server_count\": sum([self.a2a_server is not None, self.mcp_server is not None])\n            },\n            \"configuration\": {\n                \"fast_llm_model\": self.amd.fast_llm_model,\n                \"complex_llm_model\": self.amd.complex_llm_model,\n                \"use_fast_response\": getattr(self.amd, 'use_fast_response', False),\n                \"max_input_tokens\": getattr(self.amd, 'max_input_tokens', 8000),\n                \"persona_configured\": self.amd.persona is not None,\n                \"format_config\": bool(getattr(self.amd.persona, 'format_config', None)) if self.amd.persona else False\n            }\n        }\n\n        # Add detailed execution summary if tasks exist\n        tasks = self.shared.get(\"tasks\", {})\n        if tasks:\n            task_types_used = {}\n            tools_used = []\n            execution_timeline = []\n\n            for task_id, task in tasks.items():\n                # Count task types\n                task_type = getattr(task, 'type', 'unknown')\n                task_types_used[task_type] = task_types_used.get(task_type, 0) + 1\n\n                # Collect tools used\n                if hasattr(task, 'tool_name') and task.tool_name:\n                    tools_used.append(task.tool_name)\n\n                # Timeline info\n                if hasattr(task, 'started_at') and task.started_at:\n                    timeline_entry = {\n                        \"task_id\": task_id,\n                        \"type\": task_type,\n                        \"started\": task.started_at.isoformat(),\n                        \"status\": getattr(task, 'status', 'unknown')\n                    }\n                    if hasattr(task, 'completed_at') and task.completed_at:\n                        timeline_entry[\"completed\"] = task.completed_at.isoformat()\n                        timeline_entry[\"duration\"] = (task.completed_at - task.started_at).total_seconds()\n                    execution_timeline.append(timeline_entry)\n\n            base_status[\"task_execution\"].update({\n                \"task_types_used\": task_types_used,\n                \"tools_used\": list(set(tools_used)),\n                \"execution_timeline\": execution_timeline[-5:]  # Last 5 tasks\n            })\n\n        # Add context statistics\n        if hasattr(self.task_flow, 'context_manager'):\n            context_manager = self.task_flow.context_manager\n            base_status[\"memory_context\"].update({\n                \"compression_threshold\": context_manager.compression_threshold,\n                \"max_tokens\": context_manager.max_tokens,\n                \"active_context_sessions\": len(getattr(context_manager, 'session_managers', {}))\n            })\n\n        # Add variable system info\n        if hasattr(self, 'variable_manager'):\n            available_vars = self.variable_manager.get_available_variables()\n            scope_info = self.variable_manager.get_scope_info()\n\n            base_status[\"variable_system\"] = {\n                \"total_scopes\": len(scope_info),\n                \"scope_names\": list(scope_info.keys()),\n                \"total_variables\": sum(len(vars) for vars in available_vars.values()),\n                \"scope_details\": {\n                    scope: {\"type\": info[\"type\"], \"variables\": len(available_vars.get(scope, {}))}\n                    for scope, info in scope_info.items()\n                }\n            }\n\n        # Add format quality info if available\n        quality_assessment = self.shared.get(\"quality_assessment\", {})\n        if quality_assessment:\n            quality_details = quality_assessment.get(\"quality_details\", {})\n            base_status[\"format_quality\"] = {\n                \"overall_score\": quality_details.get(\"total_score\", 0.0),\n                \"format_adherence\": quality_details.get(\"format_adherence\", 0.0),\n                \"length_adherence\": quality_details.get(\"length_adherence\", 0.0),\n                \"content_quality\": quality_details.get(\"base_quality\", 0.0),\n                \"assessment\": quality_assessment.get(\"quality_assessment\", \"unknown\"),\n                \"has_suggestions\": bool(quality_assessment.get(\"suggestions\", []))\n            }\n\n        # Add LLM usage statistics\n        llm_stats = self.shared.get(\"llm_call_stats\", {})\n        if llm_stats:\n            base_status[\"llm_usage\"] = {\n                \"total_calls\": llm_stats.get(\"total_calls\", 0),\n                \"context_compression_rate\": llm_stats.get(\"context_compression_rate\", 0.0),\n                \"average_context_tokens\": llm_stats.get(\"context_tokens_used\", 0) / max(llm_stats.get(\"total_calls\", 1),\n                                                                                        1),\n                \"total_tokens_used\": llm_stats.get(\"total_tokens_used\", 0)\n            }\n\n        # Add timestamp\n        base_status[\"timestamp\"] = datetime.now().isoformat()\n\n        if not pretty_print:\n            return base_status\n\n        # Pretty print using EnhancedVerboseOutput\n        try:\n            from toolboxv2.mods.isaa.extras.verbose_output import EnhancedVerboseOutput\n            verbose_output = EnhancedVerboseOutput(verbose=True)\n\n            # Header\n            verbose_output.log_header(f\"Agent Status: {base_status['agent_info']['name']}\")\n\n            # Runtime Status\n            status_color = {\n                \"running\": \"SUCCESS\",\n                \"paused\": \"WARNING\",\n                \"idle\": \"INFO\",\n                \"error\": \"ERROR\"\n            }.get(base_status[\"runtime_status\"][\"status\"], \"INFO\")\n\n            getattr(verbose_output, f\"print_{status_color.lower()}\")(\n                f\"Status: {base_status['runtime_status']['status'].upper()}\"\n            )\n\n            # Task Execution Summary\n            task_exec = base_status[\"task_execution\"]\n            if task_exec[\"total_tasks\"] &gt; 0:\n                verbose_output.formatter.print_section(\n                    \"Task Execution\",\n                    f\"Total: {task_exec['total_tasks']} | \"\n                    f\"Completed: {task_exec['completed_tasks']} | \"\n                    f\"Failed: {task_exec['failed_tasks']} | \"\n                    f\"Active: {task_exec['active_tasks']}\\n\"\n                    f\"Adaptations: {task_exec['plan_adaptations']}\"\n                )\n\n                if task_exec.get(\"tools_used\"):\n                    verbose_output.formatter.print_section(\n                        \"Tools Used\",\n                        \", \".join(task_exec[\"tools_used\"])\n                    )\n\n            # Capabilities\n            caps = base_status[\"capabilities\"]\n            verbose_output.formatter.print_section(\n                \"Capabilities\",\n                f\"Intelligence Level: {caps['intelligence_level']}\\n\"\n                f\"Available Tools: {caps['available_tools']}\\n\"\n                f\"Analyzed Tools: {caps['analyzed_tools']}\\n\"\n                f\"World Model Size: {caps['world_model_size']}\"\n            )\n\n            # Memory &amp; Context\n            memory = base_status[\"memory_context\"]\n            verbose_output.formatter.print_section(\n                \"Memory &amp; Context\",\n                f\"Context System: {memory['context_system']}\\n\"\n                f\"Session Managers: {memory['session_managers']}\\n\"\n                f\"Variable Scopes: {memory['variable_scopes']}\\n\"\n                f\"Session Initialized: {memory['session_initialized']}\"\n            )\n\n            # Configuration\n            config = base_status[\"configuration\"]\n            verbose_output.formatter.print_section(\n                \"Configuration\",\n                f\"Fast LLM: {config['fast_llm_model']}\\n\"\n                f\"Complex LLM: {config['complex_llm_model']}\\n\"\n                f\"Max Tokens: {config['max_input_tokens']}\\n\"\n                f\"Persona: {'Configured' if config['persona_configured'] else 'Default'}\\n\"\n                f\"Format Config: {'Active' if config['format_config'] else 'None'}\"\n            )\n\n            # Performance\n            perf = base_status[\"performance\"]\n            verbose_output.formatter.print_section(\n                \"Performance\",\n                f\"Total Cost: ${perf['total_cost']:.4f}\\n\"\n                f\"Checkpointing: {'Enabled' if perf['checkpoint_enabled'] else 'Disabled'}\\n\"\n                f\"Max Parallel Tasks: {perf['max_parallel_tasks']}\\n\"\n                f\"Last Checkpoint: {perf['last_checkpoint'] or 'None'}\"\n            )\n\n            # Variable System Details\n            if \"variable_system\" in base_status:\n                var_sys = base_status[\"variable_system\"]\n                scope_details = []\n                for scope, details in var_sys[\"scope_details\"].items():\n                    scope_details.append(f\"{scope}: {details['variables']} variables ({details['type']})\")\n\n                verbose_output.formatter.print_section(\n                    \"Variable System\",\n                    f\"Total Scopes: {var_sys['total_scopes']}\\n\"\n                    f\"Total Variables: {var_sys['total_variables']}\\n\" +\n                    \"\\n\".join(scope_details)\n                )\n\n            # Format Quality\n            if \"format_quality\" in base_status:\n                quality = base_status[\"format_quality\"]\n                verbose_output.formatter.print_section(\n                    \"Format Quality\",\n                    f\"Overall Score: {quality['overall_score']:.2f}\\n\"\n                    f\"Format Adherence: {quality['format_adherence']:.2f}\\n\"\n                    f\"Length Adherence: {quality['length_adherence']:.2f}\\n\"\n                    f\"Content Quality: {quality['content_quality']:.2f}\\n\"\n                    f\"Assessment: {quality['assessment']}\"\n                )\n\n            # LLM Usage\n            if \"llm_usage\" in base_status:\n                llm = base_status[\"llm_usage\"]\n                verbose_output.formatter.print_section(\n                    \"LLM Usage Statistics\",\n                    f\"Total Calls: {llm['total_calls']}\\n\"\n                    f\"Avg Context Tokens: {llm['average_context_tokens']:.1f}\\n\"\n                    f\"Total Tokens: {llm['total_tokens_used']}\\n\"\n                    f\"Compression Rate: {llm['context_compression_rate']:.2%}\"\n                )\n\n            # Servers\n            servers = base_status[\"servers\"]\n            if servers[\"server_count\"] &gt; 0:\n                server_status = []\n                if servers[\"a2a_server\"]:\n                    server_status.append(\"A2A Server: Active\")\n                if servers[\"mcp_server\"]:\n                    server_status.append(\"MCP Server: Active\")\n\n                verbose_output.formatter.print_section(\n                    \"Servers\",\n                    \"\\n\".join(server_status)\n                )\n\n            verbose_output.print_separator()\n            verbose_output.print_info(f\"Status generated at: {base_status['timestamp']}\")\n\n            return \"Status printed above\"\n\n        except Exception:\n            # Fallback to JSON if pretty print fails\n            import json\n            return json.dumps(base_status, indent=2, default=str)\n\n    @property\n    def tool_registry(self):\n        return self._tool_registry\n\n    def __rshift__(self, other):\n        return Chain(self) &gt;&gt; other\n\n    def __add__(self, other):\n        return Chain(self) + other\n\n    def __and__(self, other):\n        return Chain(self) &amp; other\n\n    def __mod__(self, other):\n        \"\"\"Implements % operator for conditional branching\"\"\"\n        return ConditionalChain(self, other)\n</code></pre> <code>total_cost</code> <code>property</code> \u00b6 <p>Get total cost if budget manager available</p> <code>__mod__(other)</code> \u00b6 <p>Implements % operator for conditional branching</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def __mod__(self, other):\n    \"\"\"Implements % operator for conditional branching\"\"\"\n    return ConditionalChain(self, other)\n</code></pre> <code>a_format_class(pydantic_model, prompt, message_context=None, max_retries=2, auto_context=True)</code> <code>async</code> \u00b6 <p>State-of-the-art LLM-based structured data formatting using Pydantic models.</p> <p>Parameters:</p> Name Type Description Default <code>pydantic_model</code> <code>type[BaseModel]</code> <p>The Pydantic model class to structure the response</p> required <code>prompt</code> <code>str</code> <p>The main prompt for the LLM</p> required <code>message_context</code> <code>list[dict]</code> <p>Optional conversation context messages</p> <code>None</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts</p> <code>2</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, Any]</code> <p>Validated structured data matching the Pydantic model</p> <p>Raises:</p> Type Description <code>ValidationError</code> <p>If the LLM response cannot be validated against the model</p> <code>RuntimeError</code> <p>If all retry attempts fail</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>    async def a_format_class(self,\n                             pydantic_model: type[BaseModel],\n                             prompt: str,\n                             message_context: list[dict] = None,\n                             max_retries: int = 2, auto_context=True) -&gt; dict[str, Any]:\n        \"\"\"\n        State-of-the-art LLM-based structured data formatting using Pydantic models.\n\n        Args:\n            pydantic_model: The Pydantic model class to structure the response\n            prompt: The main prompt for the LLM\n            message_context: Optional conversation context messages\n            max_retries: Maximum number of retry attempts\n\n        Returns:\n            dict: Validated structured data matching the Pydantic model\n\n        Raises:\n            ValidationError: If the LLM response cannot be validated against the model\n            RuntimeError: If all retry attempts fail\n        \"\"\"\n\n        if not LITELLM_AVAILABLE:\n            raise RuntimeError(\"LiteLLM is required for structured formatting but not available\")\n\n        # Generate schema documentation\n        schema = pydantic_model.model_json_schema()\n        model_name = pydantic_model.__name__\n\n        # Create enhanced prompt with schema\n        enhanced_prompt = f\"\"\"\n    {prompt}\n\n    CRITICAL FORMATTING REQUIREMENTS:\n    1. Respond ONLY in valid YAML format\n    2. Follow the exact schema structure provided\n    3. Use appropriate data types (strings, lists, numbers, booleans)\n    4. Include ALL required fields\n    5. No additional comments, explanations, or text outside the YAML\n\n    SCHEMA FOR {model_name}:\n    {yaml.dump(schema, default_flow_style=False, indent=2)}\n\n    EXAMPLE OUTPUT FORMAT:\n    ```yaml\n    # Your response here following the schema exactly\n    field_name: \"value\"\n    list_field:\n      - \"item1\"\n      - \"item2\"\n    boolean_field: true\n    number_field: 42\nRespond in YAML format only:\n\"\"\"\n        # Prepare messages\n        messages = []\n        if message_context:\n            messages.extend(message_context)\n        messages.append({\"role\": \"user\", \"content\": enhanced_prompt})\n\n        # Retry logic with progressive adjustments\n        last_error = None\n\n        for attempt in range(max_retries + 1):\n            try:\n                # Adjust parameters based on attempt\n                temperature = 0.1 + (attempt * 0.1)  # Increase temperature slightly on retries\n                max_tokens = min(2000 + (attempt * 500), 4000)  # Increase token limit on retries\n\n                rprint(f\"[{model_name}] Attempt {attempt + 1}/{max_retries + 1} (temp: {temperature})\")\n\n                # Generate LLM response\n                response = await self.a_run_llm_completion(\n                    model=self.amd.complex_llm_model,\n                    messages=messages,\n                    with_context=auto_context,\n                    temperature=temperature,\n                    max_tokens=max_tokens,\n                    task_id=f\"format_{model_name.lower()}_{attempt}\"\n                )\n\n                if not response or not response.strip():\n                    raise ValueError(\"Empty response from LLM\")\n\n                # Extract YAML content with multiple fallback strategies\n                yaml_content = self._extract_yaml_content(response)\n\n                if not yaml_content:\n                    raise ValueError(\"No valid YAML content found in response\")\n\n                # Parse YAML\n                try:\n                    parsed_data = yaml.safe_load(yaml_content)\n                except yaml.YAMLError as e:\n                    raise ValueError(f\"Invalid YAML syntax: {e}\")\n\n                if not isinstance(parsed_data, dict):\n                    raise ValueError(f\"Expected dict, got {type(parsed_data)}\")\n\n                # Validate against Pydantic model\n                try:\n                    validated_instance = pydantic_model.model_validate(parsed_data)\n                    validated_data = validated_instance.model_dump()\n\n                    rprint(f\"\u2705 Successfully formatted {model_name} on attempt {attempt + 1}\")\n                    return validated_data\n\n                except ValidationError as e:\n                    detailed_errors = []\n                    for error in e.errors():\n                        field_path = \" -&gt; \".join(str(x) for x in error['loc'])\n                        detailed_errors.append(f\"Field '{field_path}': {error['msg']}\")\n\n                    error_msg = \"Validation failed:\\n\" + \"\\n\".join(detailed_errors)\n                    raise ValueError(error_msg)\n\n            except Exception as e:\n                last_error = e\n                wprint(f\"[{model_name}] Attempt {attempt + 1} failed: {str(e)}\")\n\n                if attempt &lt; max_retries:\n                    # Add error feedback for next attempt\n                    error_feedback = f\"\\n\\nPREVIOUS ATTEMPT FAILED: {str(e)}\\nPlease correct the issues and provide valid YAML matching the schema exactly.\"\n                    messages[-1][\"content\"] = enhanced_prompt + error_feedback\n\n                    # Brief delay before retry\n                    await asyncio.sleep(0.5 * (attempt + 1))\n                else:\n                    eprint(f\"[{model_name}] All {max_retries + 1} attempts failed\")\n\n        # All attempts failed\n        raise RuntimeError(f\"Failed to format {model_name} after {max_retries + 1} attempts. Last error: {last_error}\")\n</code></pre> <code>a_run(query, session_id='default', user_id=None, stream_callback=None, remember=True, **kwargs)</code> <code>async</code> \u00b6 <p>Main entry point f\u00fcr Agent-Ausf\u00fchrung mit UnifiedContextManager</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def a_run(\n    self,\n    query: str,\n    session_id: str = \"default\",\n    user_id: str = None,\n    stream_callback: Callable = None,\n    remember: bool = True,\n    **kwargs\n) -&gt; str:\n    \"\"\"Main entry point f\u00fcr Agent-Ausf\u00fchrung mit UnifiedContextManager\"\"\"\n\n    execution_start = self.progress_tracker.start_timer(\"total_execution\")\n    self.active_session = session_id\n    result = None\n    await self.progress_tracker.emit_event(ProgressEvent(\n        event_type=\"execution_start\",\n        timestamp=time.time(),\n        status=NodeStatus.RUNNING,\n        node_name=\"FlowAgent\",\n        session_id=session_id,\n        metadata={\"query\": query, \"user_id\": user_id}\n    ))\n\n    try:\n        #Initialize or get session \u00fcber UnifiedContextManager\n        await self.initialize_session_context(session_id, max_history=200)\n\n        #Store user message immediately in ChatSession wenn remember=True\n        if remember:\n            await self.context_manager.add_interaction(\n                session_id,\n                'user',\n                query,\n                metadata={\"user_id\": user_id}\n            )\n\n        # Set user context variables\n        timestamp = datetime.now()\n        self.variable_manager.register_scope('user', {\n            'id': user_id,\n            'session': session_id,\n            'query': query,\n            'timestamp': timestamp.isoformat()\n        })\n\n        # Update system variables\n        self.variable_manager.set('system_context.timestamp', {'isoformat': timestamp.isoformat()})\n        self.variable_manager.set('system_context.current_session', session_id)\n        self.variable_manager.set('system_context.current_user', user_id)\n        self.variable_manager.set('system_context.last_query', query)\n\n        # Initialize with tool awareness\n        await self.initialize_context_awareness()\n\n        # VEREINFACHT: Prepare execution context - weniger Daten duplizieren\n        self.shared.update({\n            \"current_query\": query,\n            \"session_id\": session_id,\n            \"user_id\": user_id,\n            \"stream_callback\": stream_callback,\n            \"remember\": remember,\n            # CENTRAL: Context Manager ist die prim\u00e4re Context-Quelle\n            \"context_manager\": self.context_manager,\n            \"variable_manager\": self.variable_manager\n        })\n\n        # Set LLM models in shared context\n        self.shared['fast_llm_model'] = self.amd.fast_llm_model\n        self.shared['complex_llm_model'] = self.amd.complex_llm_model\n        self.shared['persona_config'] = self.amd.persona\n        self.shared['use_fast_response'] = self.amd.use_fast_response\n\n        # Set system status\n        self.shared[\"system_status\"] = \"running\"\n        self.is_running = True\n\n        # Execute main orchestration flow\n        result = await self._orchestrate_execution()\n\n        #Store assistant response in ChatSession wenn remember=True\n        if remember:\n            await self.context_manager.add_interaction(\n                session_id,\n                'assistant',\n                result,\n                metadata={\"user_id\": user_id, \"execution_duration\": time.time() - execution_start}\n            )\n\n        total_duration = self.progress_tracker.end_timer(\"total_execution\")\n\n        await self.progress_tracker.emit_event(ProgressEvent(\n            event_type=\"execution_complete\",\n            timestamp=time.time(),\n            node_name=\"FlowAgent\",\n            status=NodeStatus.COMPLETED,\n            node_duration=total_duration,\n            session_id=session_id,\n            metadata={\n                \"result_length\": len(result),\n                \"summary\": self.progress_tracker.get_summary(),\n                \"remembered\": remember\n            }\n        ))\n\n        # Checkpoint if needed\n        if self.enable_pause_resume:\n            await self._maybe_checkpoint()\n\n        return result\n\n    except Exception as e:\n        eprint(f\"Agent execution failed: {e}\", exc_info=True)\n        error_response = f\"I encountered an error: {str(e)}\"\n        result = error_response\n        import traceback\n        print(traceback.format_exc())\n\n        # Store error in ChatSession wenn remember=True\n        if remember:\n            await self.context_manager.add_interaction(\n                session_id,\n                'assistant',\n                error_response,\n                metadata={\n                    \"user_id\": user_id,\n                    \"error\": True,\n                    \"error_type\": type(e).__name__\n                }\n            )\n\n        total_duration = self.progress_tracker.end_timer(\"total_execution\")\n\n        await self.progress_tracker.emit_event(ProgressEvent(\n            event_type=\"error\",\n            timestamp=time.time(),\n            node_name=\"FlowAgent\",\n            status=NodeStatus.FAILED,\n            node_duration=total_duration,\n            session_id=session_id,\n            metadata={\"error\": str(e), \"error_type\": type(e).__name__}\n        ))\n\n        return error_response\n\n    finally:\n        self.shared[\"system_status\"] = \"idle\"\n        self.is_running = False\n        self.active_session = None\n</code></pre> <code>a_run_with_format(query, response_format='frei-text', text_length='chat-conversation', custom_instructions='', **kwargs)</code> <code>async</code> \u00b6 <p>F\u00fchre Agent mit spezifischem Format aus</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def a_run_with_format(\n    self,\n    query: str,\n    response_format: str = \"frei-text\",\n    text_length: str = \"chat-conversation\",\n    custom_instructions: str = \"\",\n    **kwargs\n) -&gt; str:\n    \"\"\"F\u00fchre Agent mit spezifischem Format aus\"\"\"\n\n    # Tempor\u00e4re Format-Einstellung\n    original_persona = self.amd.persona\n\n    try:\n        self.set_response_format(response_format, text_length, custom_instructions)\n        response = await self.a_run(query, **kwargs)\n        return response\n    finally:\n        # Restore original persona\n        self.amd.persona = original_persona\n        self.shared[\"persona_config\"] = original_persona\n</code></pre> <code>add_custom_flow(flow, name)</code> \u00b6 <p>Add a custom flow for dynamic execution</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def add_custom_flow(self, flow: AsyncFlow, name: str):\n    \"\"\"Add a custom flow for dynamic execution\"\"\"\n    self.add_tool(flow.run_async, name=name, description=f\"Custom flow: {flow.__class__.__name__}\")\n    rprint(f\"Custom node added: {name}\")\n</code></pre> <code>add_first_class_tool(tool_func, name, description)</code> \u00b6 <p>Add a first-class meta-tool that can be used by the LLMReasonerNode. These are different from regular tools - they control agent sub-systems.</p> <p>Parameters:</p> Name Type Description Default <code>tool_func</code> <code>Callable</code> <p>The function to register as a meta-tool</p> required <code>name</code> <code>str</code> <p>Name of the meta-tool</p> required <code>description</code> <code>str</code> <p>Description of when and how to use it</p> required Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def add_first_class_tool(self, tool_func: Callable, name: str, description: str):\n    \"\"\"\n    Add a first-class meta-tool that can be used by the LLMReasonerNode.\n    These are different from regular tools - they control agent sub-systems.\n\n    Args:\n        tool_func: The function to register as a meta-tool\n        name: Name of the meta-tool\n        description: Description of when and how to use it\n    \"\"\"\n\n    # Validate the tool function\n    if not callable(tool_func):\n        raise ValueError(\"Tool function must be callable\")\n\n    # Register in the reasoner's meta-tool registry (if reasoner exists)\n    if hasattr(self.task_flow, 'llm_reasoner'):\n        if not hasattr(self.task_flow.llm_reasoner, 'meta_tools_registry'):\n            self.task_flow.llm_reasoner.meta_tools_registry = {}\n\n        self.task_flow.llm_reasoner.meta_tools_registry[name] = {\n            \"function\": tool_func,\n            \"description\": description,\n            \"added_at\": datetime.now().isoformat()\n        }\n\n        rprint(f\"First-class meta-tool added: {name}\")\n    else:\n        wprint(\"LLMReasonerNode not available for first-class tool registration\")\n</code></pre> <code>add_tool(tool_func, name=None, description=None, is_new=False)</code> <code>async</code> \u00b6 <p>Enhanced tool addition with intelligent analysis</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def add_tool(self, tool_func: Callable, name: str = None, description: str = None, is_new=False):\n    \"\"\"Enhanced tool addition with intelligent analysis\"\"\"\n    if not asyncio.iscoroutinefunction(tool_func):\n        @wraps(tool_func)\n        async def async_wrapper(*args, **kwargs):\n            return await asyncio.to_thread(tool_func, *args, **kwargs)\n\n        effective_func = async_wrapper\n    else:\n        effective_func = tool_func\n\n    tool_name = name or effective_func.__name__\n    tool_description = description or effective_func.__doc__ or \"No description\"\n\n    # Store in registry\n    self._tool_registry[tool_name] = {\n        \"function\": effective_func,\n        \"description\": tool_description,\n        \"args_schema\": get_args_schema(tool_func)\n    }\n\n    # Add to available tools list\n    if tool_name not in self.shared[\"available_tools\"]:\n        self.shared[\"available_tools\"].append(tool_name)\n\n    # Intelligent tool analysis\n    if is_new:\n        await self._analyze_tool_capabilities(tool_name, tool_description)\n\n    rprint(f\"Tool added with analysis: {tool_name}\")\n</code></pre> <code>arun_function(function_name, *args, **kwargs)</code> <code>async</code> \u00b6 <p>Asynchronously finds a function by its string name, executes it with the given arguments, and returns the result.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def arun_function(self, function_name: str, *args, **kwargs) -&gt; Any:\n    \"\"\"\n    Asynchronously finds a function by its string name, executes it with\n    the given arguments, and returns the result.\n    \"\"\"\n    rprint(f\"Attempting to run function: {function_name} with args: {args}, kwargs: {kwargs}\")\n    target_function = self.get_tool_by_name(function_name)\n\n    start_time = time.perf_counter()\n    if not target_function:\n        raise ValueError(f\"Function '{function_name}' not found in the {self.amd.name}'s registered tools.\")\n\n    try:\n        if asyncio.iscoroutinefunction(target_function):\n            result = await target_function(*args, **kwargs)\n        else:\n            # If the function is not async, run it in a thread pool\n            loop = asyncio.get_running_loop()\n            result = await loop.run_in_executor(None, lambda: target_function(*args, **kwargs))\n\n        if asyncio.iscoroutine(result):\n            result = await result\n\n        if self.progress_tracker:\n            await self.progress_tracker.emit_event(ProgressEvent(\n                event_type=\"tool_call\",  # Vereinheitlicht zu tool_call\n                node_name=\"FlowAgent\",\n                status=NodeStatus.COMPLETED,\n                success=True,\n                duration=time.perf_counter() - start_time,\n                tool_name=function_name,\n                tool_args=kwargs,\n                tool_result=result,\n                is_meta_tool=False,  # Klarstellen, dass es kein Meta-Tool ist\n                metadata={\n                    \"result_type\": type(result).__name__,\n                    \"result_length\": len(str(result))\n                }\n            ))\n        rprint(f\"Function {function_name} completed successfully with result: {result}\")\n        return result\n\n    except Exception as e:\n        eprint(f\"Function {function_name} execution failed: {e}\")\n        raise\n</code></pre> <code>clean_memory(deep_clean=False)</code> <code>async</code> \u00b6 <p>Clean memory and context of the agent</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def clean_memory(self, deep_clean: bool = False) -&gt; bool:\n    \"\"\"Clean memory and context of the agent\"\"\"\n    try:\n        # Clear current context first\n        self.clear_context()\n\n        # Clean world model\n        self.shared[\"world_model\"] = {}\n        self.world_model = {}\n\n        # Clean performance metrics\n        self.shared[\"performance_metrics\"] = {}\n\n        # Deep clean session storage\n        session_managers = self.shared.get(\"session_managers\", {})\n        if session_managers:\n            for _manager_name, manager in session_managers.items():\n                if hasattr(manager, 'clear_all_history'):\n                    await manager.clear_all_history()\n                elif hasattr(manager, 'clear_history'):\n                    manager.clear_history()\n\n        # Clear session managers entirely\n        self.shared[\"session_managers\"] = {}\n        self.shared[\"session_initialized\"] = False\n\n        # Clean variable manager completely\n        if hasattr(self, 'variable_manager'):\n            # Reinitialize with clean state\n            self.variable_manager = VariableManager({}, self.shared)\n            self._setup_variable_scopes()\n\n        # Clean tool analysis cache if deep clean\n        if deep_clean:\n            self._tool_capabilities = {}\n            self._tool_analysis_cache = {}\n\n            # Remove tool analysis file\n            if hasattr(self, 'tool_analysis_file') and os.path.exists(self.tool_analysis_file):\n                try:\n                    os.remove(self.tool_analysis_file)\n                    rprint(\"Removed tool analysis cache file\")\n                except:\n                    pass\n\n        # Clean checkpoint data\n        self.checkpoint_data = {}\n        self.last_checkpoint = None\n\n        # Clean execution history\n        if hasattr(self.task_flow, 'executor_node'):\n            self.task_flow.executor_node.execution_history = []\n            self.task_flow.executor_node.results_store = {}\n\n        # Clean context manager sessions\n        if hasattr(self.task_flow, 'context_manager'):\n            self.task_flow.context_manager.session_managers = {}\n\n        # Clean LLM call statistics\n        self.shared.pop(\"llm_call_stats\", None)\n\n        # Force garbage collection\n        import gc\n        gc.collect()\n\n        rprint(f\"Memory cleaned (deep_clean: {deep_clean})\")\n        return True\n\n    except Exception as e:\n        eprint(f\"Failed to clean memory: {e}\")\n        return False\n</code></pre> <code>cleanup_session_context(session_id=None, keep_count=100, remove_old_snapshots=True)</code> <code>async</code> \u00b6 <p>Cleanup session context by removing old snapshots and entries</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def cleanup_session_context(self, session_id: str = None, keep_count: int = 100,\n                                  remove_old_snapshots: bool = True) -&gt; dict[str, Any]:\n    \"\"\"Cleanup session context by removing old snapshots and entries\"\"\"\n    try:\n        session_id = session_id or self.shared.get(\"session_id\", \"default\")\n\n        if not self.context_manager:\n            return {\"error\": \"Context manager not available\"}\n\n        session = self.context_manager.session_managers.get(session_id)\n        if not session or not hasattr(session, 'history'):\n            return {\"error\": f\"Session {session_id} not found or has no history\"}\n\n        cleanup_stats = {\n            \"original_message_count\": len(session.history),\n            \"context_snapshots_removed\": 0,\n            \"context_entries_removed\": 0,\n            \"regular_messages_kept\": 0,\n            \"cleanup_performed\": False\n        }\n\n        if len(session.history) &lt;= keep_count:\n            return {**cleanup_stats, \"message\": \"No cleanup needed\"}\n\n        # Separate different types of messages\n        regular_messages = []\n        context_snapshots = []\n        context_entries = []\n\n        for message in session.history:\n            metadata = message.get(\"metadata\", {})\n\n            if metadata.get(\"is_context_snapshot\"):\n                context_snapshots.append(message)\n            elif metadata.get(\"is_context_entry\"):\n                context_entries.append(message)\n            else:\n                regular_messages.append(message)\n\n        # Keep most recent regular messages\n        messages_to_keep = regular_messages[-keep_count:]\n        cleanup_stats[\"regular_messages_kept\"] = len(messages_to_keep)\n\n        # Keep most recent context snapshots (if not removing)\n        if not remove_old_snapshots:\n            recent_snapshots = context_snapshots[-5:]  # Keep last 5 snapshots\n            messages_to_keep.extend(recent_snapshots)\n        else:\n            cleanup_stats[\"context_snapshots_removed\"] = len(context_snapshots)\n\n        # Keep persistent context entries\n        persistent_entries = [\n            entry for entry in context_entries\n            if entry.get(\"persistent\", True)\n        ]\n        messages_to_keep.extend(persistent_entries)\n        cleanup_stats[\"context_entries_removed\"] = len(context_entries) - len(persistent_entries)\n\n        # Sort by timestamp and update session\n        messages_to_keep.sort(key=lambda x: x.get(\"timestamp\", \"\"))\n        session.history = messages_to_keep\n\n        cleanup_stats.update({\n            \"final_message_count\": len(session.history),\n            \"cleanup_performed\": True,\n            \"messages_removed\": cleanup_stats[\"original_message_count\"] - len(session.history)\n        })\n\n        rprint(f\"Session cleanup completed: {cleanup_stats['messages_removed']} messages removed\")\n        return cleanup_stats\n\n    except Exception as e:\n        eprint(f\"Failed to cleanup session context: {e}\")\n        return {\"error\": str(e)}\n</code></pre> <code>clear_context(session_id=None)</code> \u00b6 <p>Clear context \u00fcber UnifiedContextManager mit Session-spezifischer Unterst\u00fctzung</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def clear_context(self, session_id: str = None) -&gt; bool:\n    \"\"\"Clear context \u00fcber UnifiedContextManager mit Session-spezifischer Unterst\u00fctzung\"\"\"\n    try:\n        #Clear \u00fcber Context Manager\n        if session_id:\n            # Clear specific session\n            if session_id in self.context_manager.session_managers:\n                session = self.context_manager.session_managers[session_id]\n                if hasattr(session, 'history'):\n                    session.history = []\n                elif isinstance(session, dict) and 'history' in session:\n                    session['history'] = []\n\n                # Remove from session managers\n                del self.context_manager.session_managers[session_id]\n\n                # Clear variable manager scope for this session\n                if self.variable_manager:\n                    scope_name = f'session_{session_id}'\n                    if scope_name in self.variable_manager.scopes:\n                        del self.variable_manager.scopes[scope_name]\n\n                rprint(f\"Context cleared for session: {session_id}\")\n        else:\n            # Clear all sessions\n            for session_id, session in self.context_manager.session_managers.items():\n                if hasattr(session, 'history'):\n                    session.history = []\n                elif isinstance(session, dict) and 'history' in session:\n                    session['history'] = []\n\n            self.context_manager.session_managers = {}\n            rprint(\"Context cleared for all sessions\")\n\n        # Clear context cache\n        self.context_manager._invalidate_cache(session_id)\n\n        # Clear current execution context in shared\n        context_keys_to_clear = [\n            \"current_query\", \"current_response\", \"current_plan\", \"tasks\",\n            \"results\", \"task_plans\", \"session_data\", \"formatted_context\",\n            \"synthesized_response\", \"quality_assessment\", \"plan_adaptations\",\n            \"executor_performance\", \"llm_tool_conversation\", \"aggregated_context\"\n        ]\n\n        for key in context_keys_to_clear:\n            if key in self.shared:\n                if isinstance(self.shared[key], dict):\n                    self.shared[key] = {}\n                elif isinstance(self.shared[key], list):\n                    self.shared[key] = []\n                else:\n                    self.shared[key] = None\n\n        # Clear variable manager scopes (except core system variables)\n        if hasattr(self, 'variable_manager'):\n            # Clear user, results, tasks scopes\n            self.variable_manager.register_scope('user', {})\n            self.variable_manager.register_scope('results', {})\n            self.variable_manager.register_scope('tasks', {})\n            # Reset cache\n            self.variable_manager._cache.clear()\n\n        # Reset execution state\n        self.is_running = False\n        self.is_paused = False\n        self.shared[\"system_status\"] = \"idle\"\n\n        # Clear progress tracking\n        if hasattr(self, 'progress_tracker'):\n            self.progress_tracker.reset_session_metrics()\n\n        return True\n\n    except Exception as e:\n        eprint(f\"Failed to clear context: {e}\")\n        return False\n</code></pre> <code>close()</code> <code>async</code> \u00b6 <p>Clean shutdown</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def close(self):\n    \"\"\"Clean shutdown\"\"\"\n    self.is_running = False\n    self._shutdown_event.set()\n\n    # Create final checkpoint\n    if self.enable_pause_resume:\n        checkpoint = await self._create_checkpoint()\n        await self._save_checkpoint(checkpoint, \"final_checkpoint.pkl\")\n\n    # Shutdown executor\n    self.executor.shutdown(wait=True)\n\n    # Close servers\n    if self.a2a_server:\n        await self.a2a_server.close()\n\n    if self.mcp_server:\n        await self.mcp_server.close()\n\n    if hasattr(self, '_mcp_session_manager'):\n        await self._mcp_session_manager.cleanup_all()\n\n    rprint(\"Agent shutdown complete\")\n</code></pre> <code>configure_persona_integration(apply_method='system_prompt', integration_level='light')</code> \u00b6 <p>Configure how persona is applied</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def configure_persona_integration(self, apply_method: str = \"system_prompt\", integration_level: str = \"light\"):\n    \"\"\"Configure how persona is applied\"\"\"\n    if self.amd.persona:\n        self.amd.persona.apply_method = apply_method\n        self.amd.persona.integration_level = integration_level\n        rprint(f\"Persona integration updated: {apply_method}, {integration_level}\")\n    else:\n        wprint(\"No persona configured to update\")\n</code></pre> <code>delete_old_checkpoints(keep_count=5, max_age_hours=168)</code> <code>async</code> \u00b6 <p>Delete old checkpoints, keeping the most recent ones</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def delete_old_checkpoints(self, keep_count: int = 5, max_age_hours: int = 168) -&gt; dict[str, Any]:\n    \"\"\"Delete old checkpoints, keeping the most recent ones\"\"\"\n    try:\n        checkpoints = self.list_available_checkpoints(\n            max_age_hours=max_age_hours * 2)  # Look further back for deletion\n\n        deleted_count = 0\n        deleted_size_kb = 0\n        errors = []\n\n        if len(checkpoints) &gt; keep_count:\n            # Keep the newest, delete the rest (except final checkpoint)\n            to_delete = checkpoints[keep_count:]\n\n            for checkpoint in to_delete:\n                if checkpoint[\"checkpoint_type\"] != \"final\":  # Never delete final checkpoint\n                    try:\n                        os.remove(checkpoint[\"filepath\"])\n                        deleted_count += 1\n                        deleted_size_kb += checkpoint[\"file_size_kb\"]\n                        rprint(f\"Deleted old checkpoint: {checkpoint['filename']}\")\n                    except Exception as e:\n                        import traceback\n                        print(traceback.format_exc())\n                        errors.append(f\"Failed to delete {checkpoint['filename']}: {e}\")\n\n        # Also delete checkpoints older than max_age_hours\n        old_checkpoints = [cp for cp in checkpoints if\n                           cp[\"age_hours\"] &gt; max_age_hours and cp[\"checkpoint_type\"] != \"final\"]\n        for checkpoint in old_checkpoints:\n            if checkpoint not in checkpoints[keep_count:]:  # Don't double-delete\n                try:\n                    os.remove(checkpoint[\"filepath\"])\n                    deleted_count += 1\n                    deleted_size_kb += checkpoint[\"file_size_kb\"]\n                    rprint(f\"Deleted aged checkpoint: {checkpoint['filename']}\")\n                except Exception as e:\n                    import traceback\n                    print(traceback.format_exc())\n                    errors.append(f\"Failed to delete {checkpoint['filename']}: {e}\")\n\n        return {\n            \"success\": True,\n            \"deleted_count\": deleted_count,\n            \"freed_space_kb\": round(deleted_size_kb, 1),\n            \"remaining_checkpoints\": len(checkpoints) - deleted_count,\n            \"errors\": errors\n        }\n\n    except Exception as e:\n        import traceback\n        print(traceback.format_exc())\n        eprint(f\"Failed to delete old checkpoints: {e}\")\n        return {\n            \"success\": False,\n            \"error\": str(e),\n            \"deleted_count\": 0\n        }\n</code></pre> <code>explain_reasoning_process()</code> <code>async</code> \u00b6 <p>Erkl\u00e4re den Reasoning-Prozess des Agenten</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>    async def explain_reasoning_process(self) -&gt; str:\n        \"\"\"Erkl\u00e4re den Reasoning-Prozess des Agenten\"\"\"\n        if not LITELLM_AVAILABLE:\n            return \"Reasoning explanation requires LLM capabilities.\"\n\n        summary = await self.get_task_execution_summary()\n\n        prompt = f\"\"\"\nErkl\u00e4re den Reasoning-Prozess dieses AI-Agenten in verst\u00e4ndlicher Form:\n\n## Ausf\u00fchrungszusammenfassung\n- Total Tasks: {summary['total_tasks']}\n- Erfolgreich: {len(summary['completed_tasks'])}\n- Fehlgeschlagen: {len(summary['failed_tasks'])}\n- Plan-Adaptationen: {summary['adaptations']}\n- Verwendete Tools: {', '.join(set(summary['tools_used']))}\n- Task-Typen: {summary['task_types_used']}\n\n## Task-Details\nErfolgreiche Tasks:\n{self._format_tasks_for_explanation(summary['completed_tasks'])}\n\n## Anweisungen\nErkl\u00e4re in 2-3 Abs\u00e4tzen:\n1. Welche Strategie der Agent gew\u00e4hlt hat\n2. Wie er die Aufgabe in Tasks unterteilt hat\n3. Wie er auf unerwartete Ergebnisse reagiert hat (falls Adaptationen)\n4. Was die wichtigsten Erkenntnisse waren\n\nSchreibe f\u00fcr einen technischen Nutzer, aber verst\u00e4ndlich.\"\"\"\n\n        try:\n            response = await self.a_run_llm_completion(\n                model=self.amd.complex_llm_model,\n                messages=[{\"role\": \"user\", \"content\": prompt}],\n                temperature=0.5,\n                max_tokens=800,task_id=\"reasoning_explanation\"\n            )\n\n            return response\n\n        except Exception as e:\n            import traceback\n            print(traceback.format_exc())\n            return f\"Could not generate reasoning explanation: {e}\"\n</code></pre> <code>format_text(text, **context)</code> \u00b6 <p>Format text with variables</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def format_text(self, text: str, **context) -&gt; str:\n    \"\"\"Format text with variables\"\"\"\n    return self.variable_manager.format_text(text, context)\n</code></pre> <code>get_available_formats()</code> \u00b6 <p>Erhalte verf\u00fcgbare Format- und L\u00e4ngen-Optionen</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def get_available_formats(self) -&gt; dict[str, list[str]]:\n    \"\"\"Erhalte verf\u00fcgbare Format- und L\u00e4ngen-Optionen\"\"\"\n    return {\n        \"formats\": [f.value for f in ResponseFormat],\n        \"lengths\": [l.value for l in TextLength],\n        \"format_descriptions\": {\n            f.value: FormatConfig(response_format=f).get_format_instructions()\n            for f in ResponseFormat\n        },\n        \"length_descriptions\": {\n            l.value: FormatConfig(text_length=l).get_length_instructions()\n            for l in TextLength\n        }\n    }\n</code></pre> <code>get_available_variables()</code> \u00b6 <p>Get available variables for dynamic formatting</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def get_available_variables(self) -&gt; dict[str, str]:\n    \"\"\"Get available variables for dynamic formatting\"\"\"\n    return self.variable_manager.get_available_variables()\n</code></pre> <code>get_context(session_id=None, format_for_llm=True)</code> <code>async</code> \u00b6 <p>\u00dcBERARBEITET: Get context \u00fcber UnifiedContextManager statt verteilte Quellen</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def get_context(self, session_id: str = None, format_for_llm: bool = True) -&gt; str | dict[str, Any]:\n    \"\"\"\n    \u00dcBERARBEITET: Get context \u00fcber UnifiedContextManager statt verteilte Quellen\n    \"\"\"\n    try:\n        session_id = session_id or self.shared.get(\"session_id\", self.active_session)\n        query = self.shared.get(\"current_query\", \"\")\n\n        #Hole unified context \u00fcber Context Manager\n        unified_context = await self.context_manager.build_unified_context(session_id, query, \"full\")\n\n\n        if format_for_llm:\n            return self.context_manager.get_formatted_context_for_llm(unified_context)\n        else:\n            return unified_context\n\n    except Exception as e:\n        import traceback\n        print(traceback.format_exc())\n        eprint(f\"Failed to generate context via UnifiedContextManager: {e}\")\n\n        # FALLBACK: Fallback zu alter Methode falls UnifiedContextManager fehlschl\u00e4gt\n        if format_for_llm:\n            return f\"Error generating context: {str(e)}\"\n        else:\n            return {\n                \"error\": str(e),\n                \"generated_at\": datetime.now().isoformat(),\n                \"fallback_mode\": True\n            }\n</code></pre> <code>get_context_statistics()</code> \u00b6 <p>Get comprehensive context management statistics</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def get_context_statistics(self) -&gt; dict[str, Any]:\n    \"\"\"Get comprehensive context management statistics\"\"\"\n    stats = {\n        \"context_system\": \"advanced_session_aware\",\n        \"compression_threshold\": 0.76,\n        \"max_tokens\": getattr(self, 'max_input_tokens', 8000),\n        \"session_managers\": {},\n        \"context_usage\": {},\n        \"compression_stats\": {}\n    }\n\n    # Session manager statistics\n    session_managers = self.shared.get(\"session_managers\", {})\n    for name, manager in session_managers.items():\n        stats[\"session_managers\"][name] = {\n            \"history_length\": len(manager.history),\n            \"max_length\": manager.max_length,\n            \"space_name\": manager.space_name\n        }\n\n    # Context node statistics if available\n    if hasattr(self.task_flow, 'context_manager'):\n        context_manager = self.task_flow.context_manager\n        stats[\"compression_stats\"] = {\n            \"compression_threshold\": context_manager.compression_threshold,\n            \"max_tokens\": context_manager.max_tokens,\n            \"active_sessions\": len(context_manager.session_managers)\n        }\n\n    # LLM call statistics from enhanced node\n    llm_stats = self.shared.get(\"llm_call_stats\", {})\n    if llm_stats:\n        stats[\"context_usage\"] = {\n            \"total_llm_calls\": llm_stats.get(\"total_calls\", 0),\n            \"context_compression_rate\": llm_stats.get(\"context_compression_rate\", 0.0),\n            \"average_context_tokens\": llm_stats.get(\"context_tokens_used\", 0) / max(llm_stats.get(\"total_calls\", 1),\n                                                                                    1)\n        }\n\n    return stats\n</code></pre> <code>get_format_quality_report()</code> \u00b6 <p>Erhalte detaillierten Format-Qualit\u00e4tsbericht</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def get_format_quality_report(self) -&gt; dict[str, Any]:\n    \"\"\"Erhalte detaillierten Format-Qualit\u00e4tsbericht\"\"\"\n    quality_assessment = self.shared.get(\"quality_assessment\", {})\n\n    if not quality_assessment:\n        return {\"status\": \"no_assessment\", \"message\": \"No recent quality assessment available\"}\n\n    quality_details = quality_assessment.get(\"quality_details\", {})\n\n    return {\n        \"overall_score\": quality_details.get(\"total_score\", 0.0),\n        \"format_adherence\": quality_details.get(\"format_adherence\", 0.0),\n        \"length_adherence\": quality_details.get(\"length_adherence\", 0.0),\n        \"content_quality\": quality_details.get(\"base_quality\", 0.0),\n        \"llm_assessment\": quality_details.get(\"llm_assessment\", 0.0),\n        \"suggestions\": quality_assessment.get(\"suggestions\", []),\n        \"assessment\": quality_assessment.get(\"quality_assessment\", \"unknown\"),\n        \"format_config_active\": quality_details.get(\"format_config_used\", False)\n    }\n</code></pre> <code>get_session_storage_stats()</code> \u00b6 <p>Get comprehensive session storage statistics</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def get_session_storage_stats(self) -&gt; dict[str, Any]:\n    \"\"\"Get comprehensive session storage statistics\"\"\"\n    try:\n        stats = {\n            \"context_manager_active\": bool(self.context_manager),\n            \"total_sessions\": 0,\n            \"session_details\": {},\n            \"storage_summary\": {\n                \"total_messages\": 0,\n                \"context_snapshots\": 0,\n                \"context_entries\": 0,\n                \"regular_messages\": 0\n            }\n        }\n\n        if not self.context_manager:\n            return stats\n\n        stats[\"total_sessions\"] = len(self.context_manager.session_managers)\n\n        for session_id, session in self.context_manager.session_managers.items():\n            session_stats = {\n                \"session_type\": \"chatsession\" if hasattr(session, 'history') else \"fallback\",\n                \"message_count\": 0,\n                \"context_snapshots\": 0,\n                \"context_entries\": 0,\n                \"regular_messages\": 0,\n                \"storage_size_estimate\": 0\n            }\n\n            if hasattr(session, 'history'):\n                session_stats[\"message_count\"] = len(session.history)\n\n                for message in session.history:\n                    content_size = len(str(message))\n                    session_stats[\"storage_size_estimate\"] += content_size\n\n                    metadata = message.get(\"metadata\", {})\n                    if metadata.get(\"is_context_snapshot\"):\n                        session_stats[\"context_snapshots\"] += 1\n                    elif metadata.get(\"is_context_entry\"):\n                        session_stats[\"context_entries\"] += 1\n                    else:\n                        session_stats[\"regular_messages\"] += 1\n\n            elif isinstance(session, dict) and 'history' in session:\n                session_stats[\"message_count\"] = len(session['history'])\n                session_stats[\"regular_messages\"] = len(session['history'])\n                session_stats[\"storage_size_estimate\"] = sum(len(str(msg)) for msg in session['history'])\n\n            stats[\"session_details\"][session_id] = session_stats\n\n            # Update totals\n            stats[\"storage_summary\"][\"total_messages\"] += session_stats[\"message_count\"]\n            stats[\"storage_summary\"][\"context_snapshots\"] += session_stats[\"context_snapshots\"]\n            stats[\"storage_summary\"][\"context_entries\"] += session_stats[\"context_entries\"]\n            stats[\"storage_summary\"][\"regular_messages\"] += session_stats[\"regular_messages\"]\n\n        # Estimate total storage size\n        stats[\"storage_summary\"][\"estimated_total_size_kb\"] = sum(\n            details[\"storage_size_estimate\"] for details in stats[\"session_details\"].values()\n        ) / 1024\n\n        return stats\n\n    except Exception as e:\n        eprint(f\"Failed to get session storage stats: {e}\")\n        return {\"error\": str(e)}\n</code></pre> <code>get_task_execution_summary()</code> <code>async</code> \u00b6 <p>Erhalte detaillierte Zusammenfassung der Task-Ausf\u00fchrung</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def get_task_execution_summary(self) -&gt; dict[str, Any]:\n    \"\"\"Erhalte detaillierte Zusammenfassung der Task-Ausf\u00fchrung\"\"\"\n    tasks = self.shared.get(\"tasks\", {})\n    results_store = self.shared.get(\"results\", {})\n\n    summary = {\n        \"total_tasks\": len(tasks),\n        \"completed_tasks\": [],\n        \"failed_tasks\": [],\n        \"task_types_used\": {},\n        \"tools_used\": [],\n        \"adaptations\": self.shared.get(\"plan_adaptations\", 0),\n        \"execution_timeline\": []\n    }\n\n    for task_id, task in tasks.items():\n        task_info = {\n            \"id\": task_id,\n            \"type\": task.type,\n            \"description\": task.description,\n            \"status\": task.status,\n            \"duration\": None\n        }\n\n        if task.started_at and task.completed_at:\n            duration = (task.completed_at - task.started_at).total_seconds()\n            task_info[\"duration\"] = duration\n\n        if task.status == \"completed\":\n            summary[\"completed_tasks\"].append(task_info)\n            if isinstance(task, ToolTask):\n                summary[\"tools_used\"].append(task.tool_name)\n        elif task.status == \"failed\":\n            task_info[\"error\"] = task.error\n            summary[\"failed_tasks\"].append(task_info)\n\n        # Task types counting\n        task_type = task.type\n        summary[\"task_types_used\"][task_type] = summary[\"task_types_used\"].get(task_type, 0) + 1\n\n    return summary\n</code></pre> <code>get_tool_by_name(tool_name)</code> \u00b6 <p>Get tool function by name</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def get_tool_by_name(self, tool_name: str) -&gt; Callable | None:\n    \"\"\"Get tool function by name\"\"\"\n    return self._tool_registry.get(tool_name, {}).get(\"function\")\n</code></pre> <code>get_variable(path, default=None)</code> \u00b6 <p>Get variable using unified system</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def get_variable(self, path: str, default=None):\n    \"\"\"Get variable using unified system\"\"\"\n    return self.variable_manager.get(path, default)\n</code></pre> <code>get_variable_documentation()</code> \u00b6 <p>Get comprehensive variable system documentation</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def get_variable_documentation(self) -&gt; str:\n    \"\"\"Get comprehensive variable system documentation\"\"\"\n    docs = []\n    docs.append(\"# Variable System Documentation\\n\")\n\n    # Available scopes\n    docs.append(\"## Available Scopes:\")\n    scope_info = self.variable_manager.get_scope_info()\n    for scope_name, info in scope_info.items():\n        docs.append(f\"- `{scope_name}`: {info['type']} with {info.get('keys', 'N/A')} keys\")\n\n    docs.append(\"\\n## Syntax Options:\")\n    docs.append(\"- `{{ variable.path }}` - Full path resolution\")\n    docs.append(\"- `{variable}` - Simple variable (no dots)\")\n    docs.append(\"- `$variable` - Shell-style variable\")\n\n    docs.append(\"\\n## Example Usage:\")\n    docs.append(\"- `{{ results.task_1.data }}` - Get result from task_1\")\n    docs.append(\"- `{{ user.name }}` - Get user name\")\n    docs.append(\"- `{agent_name}` - Simple agent name\")\n    docs.append(\"- `$timestamp` - System timestamp\")\n\n    # Available variables\n    docs.append(\"\\n## Available Variables:\")\n    variables = self.variable_manager.get_available_variables()\n    for scope_name, scope_vars in variables.items():\n        docs.append(f\"\\n### {scope_name}:\")\n        for _var_name, var_info in scope_vars.items():\n            docs.append(f\"- `{var_info['path']}`: {var_info['preview']} ({var_info['type']})\")\n\n    return \"\\n\".join(docs)\n</code></pre> <code>initialize_context_awareness()</code> <code>async</code> \u00b6 <p>Enhanced context awareness with session management</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def initialize_context_awareness(self):\n    \"\"\"Enhanced context awareness with session management\"\"\"\n\n    # Initialize session if not already done\n    session_id = self.shared.get(\"session_id\", self.active_session)\n    if not self.shared.get(\"session_initialized\"):\n        await self.initialize_session_context(session_id)\n\n    # Ensure tool capabilities are loaded\n    # add tqdm prigress bar\n\n    from tqdm import tqdm\n\n    if hasattr(self.task_flow, 'llm_reasoner'):\n        if \"read_from_variables\" not in self.shared[\"available_tools\"] and hasattr(self.task_flow.llm_reasoner, '_execute_read_from_variables'):\n            await self.add_tool(lambda scope, key, purpose: self.task_flow.llm_reasoner._execute_read_from_variables({\"scope\": scope, \"key\": key, \"purpose\": purpose}), \"read_from_variables\", \"Read from variables\")\n        if \"write_to_variables\" not in self.shared[\"available_tools\"] and hasattr(self.task_flow.llm_reasoner, '_execute_write_to_variables'):\n            await self.add_tool(lambda scope, key, value, description: self.task_flow.llm_reasoner._execute_write_to_variables({\"scope\": scope, \"key\": key, \"value\": value, \"description\": description}), \"write_to_variables\", \"Write to variables\")\n\n        if \"internal_reasoning\" not in self.shared[\"available_tools\"] and hasattr(self.task_flow.llm_reasoner, '_execute_internal_reasoning'):\n            async def internal_reasoning_tool(thought:str, thought_number:int, total_thoughts:int, next_thought_needed:bool, current_focus:str, key_insights:list[str], potential_issues:list[str], confidence_level:float):\n                args = {\n                    \"thought\": thought,\n                    \"thought_number\": thought_number,\n                    \"total_thoughts\": total_thoughts,\n                    \"next_thought_needed\": next_thought_needed,\n                    \"current_focus\": current_focus,\n                    \"key_insights\": key_insights,\n                    \"potential_issues\": potential_issues,\n                    \"confidence_level\": confidence_level\n                }\n                return await self.task_flow.llm_reasoner._execute_internal_reasoning(args, self.shared)\n            await self.add_tool(internal_reasoning_tool, \"internal_reasoning\", \"Internal reasoning\")\n\n        if \"manage_internal_task_stack\" not in self.shared[\"available_tools\"] and hasattr(self.task_flow.llm_reasoner, '_execute_manage_task_stack'):\n            async def manage_internal_task_stack_tool(action:str, task_description:str, outline_step_ref:str):\n                args = {\n                    \"action\": action,\n                    \"task_description\": task_description,\n                    \"outline_step_ref\": outline_step_ref\n                }\n                return await self.task_flow.llm_reasoner._execute_manage_task_stack(args, self.shared)\n            await self.add_tool(manage_internal_task_stack_tool, \"manage_internal_task_stack\", \"Manage internal task stack\")\n\n        if \"outline_step_completion\" not in self.shared[\"available_tools\"] and hasattr(self.task_flow.llm_reasoner, '_execute_outline_step_completion'):\n            async def outline_step_completion_tool(step_completed:bool, completion_evidence:str, next_step_focus:str):\n                args = {\n                    \"step_completed\": step_completed,\n                    \"completion_evidence\": completion_evidence,\n                    \"next_step_focus\": next_step_focus\n                }\n                return await self.task_flow.llm_reasoner._execute_outline_step_completion(args, self.shared)\n            await self.add_tool(outline_step_completion_tool, \"outline_step_completion\", \"Outline step completion\")\n\n\n    registered_tools = set(self._tool_registry.keys())\n    cached_capabilities = list(self._tool_capabilities.keys())  # Create a copy of\n    for tool_name in cached_capabilities:\n        if tool_name in self._tool_capabilities and tool_name not in registered_tools:\n            del self._tool_capabilities[tool_name]\n            print(f\"Removed outdated capability for unavailable tool: {tool_name}\")\n\n    for tool_name in tqdm(self.shared[\"available_tools\"], desc=f\"Agent {self.amd.name} Analyzing Tools\", unit=\"tool\", colour=\"green\", total=len(self.shared[\"available_tools\"])):\n        if tool_name not in self._tool_capabilities:\n            tool_info = self._tool_registry.get(tool_name, {})\n            description = tool_info.get(\"description\", \"No description\")\n            with Spinner(f\"Analyzing tool {tool_name}\"):\n                await self._analyze_tool_capabilities(tool_name, description, tool_info.get(\"args_schema\", \"()\"))\n\n        if tool_name in self._tool_capabilities:\n            function = self._tool_registry[tool_name][\"function\"]\n            self._tool_capabilities[tool_name][\"args_schema\"] = get_args_schema(function)\n\n    # Set enhanced system context\n    self.shared[\"system_context\"] = {\n        \"capabilities_summary\": self._build_capabilities_summary(),\n        \"tool_count\": len(self.shared[\"available_tools\"]),\n        \"analysis_loaded\": len(self._tool_capabilities),\n        \"intelligence_level\": \"high\" if self._tool_capabilities else \"basic\",\n        \"context_management\": \"advanced_session_aware\",\n        \"session_managers\": len(self.shared.get(\"session_managers\", {})),\n    }\n\n\n    rprint(\"Advanced context awareness initialized with session management\")\n</code></pre> <code>initialize_session_context(session_id='default', max_history=200)</code> <code>async</code> \u00b6 <p>Vereinfachte Session-Initialisierung \u00fcber UnifiedContextManager</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def initialize_session_context(self, session_id: str = \"default\", max_history: int = 200) -&gt; bool:\n    \"\"\"Vereinfachte Session-Initialisierung \u00fcber UnifiedContextManager\"\"\"\n    try:\n        # Delegation an UnifiedContextManager\n        session = await self.context_manager.initialize_session(session_id, max_history)\n\n        # Ensure Variable Manager integration\n        if not self.context_manager.variable_manager:\n            self.context_manager.variable_manager = self.variable_manager\n\n        # Update shared state (minimal - primary data now in context_manager)\n        self.shared[\"active_session_id\"] = session_id\n        self.shared[\"session_initialized\"] = True\n\n        # Legacy support: Keep session_managers reference in shared for backward compatibility\n        self.shared[\"session_managers\"] = self.context_manager.session_managers\n\n        rprint(f\"Session context initialized for {session_id} via UnifiedContextManager\")\n        return True\n\n    except Exception as e:\n        eprint(f\"Session context initialization failed: {e}\")\n        import traceback\n        print(traceback.format_exc())\n        return False\n</code></pre> <code>list_available_checkpoints(max_age_hours=168)</code> \u00b6 <p>List all available checkpoints with metadata</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def list_available_checkpoints(self, max_age_hours: int = 168) -&gt; list[dict[str, Any]]:  # Default 1 week\n    \"\"\"List all available checkpoints with metadata\"\"\"\n    try:\n        from toolboxv2 import get_app\n        folder = str(get_app().data_dir) + '/Agents/checkpoint/' + self.amd.name\n\n        if not os.path.exists(folder):\n            return []\n\n        checkpoints = []\n        for file in os.listdir(folder):\n            if file.endswith('.pkl') and file.startswith('agent_checkpoint_'):\n                filepath = os.path.join(folder, file)\n                try:\n                    # Get file info\n                    file_stat = os.stat(filepath)\n                    file_size = file_stat.st_size\n                    modified_time = datetime.fromtimestamp(file_stat.st_mtime)\n\n                    # Extract timestamp from filename\n                    timestamp_str = file.replace('agent_checkpoint_', '').replace('.pkl', '')\n                    if timestamp_str == 'final_checkpoint':\n                        checkpoint_time = modified_time\n                        checkpoint_type = \"final\"\n                    else:\n                        checkpoint_time = datetime.strptime(timestamp_str, \"%Y%m%d_%H%M%S\")\n                        checkpoint_type = \"regular\"\n\n                    # Check age\n                    age_hours = (datetime.now() - checkpoint_time).total_seconds() / 3600\n                    if age_hours &lt;= max_age_hours:\n\n                        # Try to load checkpoint metadata without full loading\n                        metadata = {}\n                        try:\n                            with open(filepath, 'rb') as f:\n                                checkpoint = pickle.load(f)\n                            metadata = {\n                                \"tasks_count\": len(checkpoint.task_state) if checkpoint.task_state else 0,\n                                \"world_model_entries\": len(checkpoint.world_model) if checkpoint.world_model else 0,\n                                \"session_id\": checkpoint.metadata.get(\"session_id\", \"unknown\") if hasattr(\n                                    checkpoint, 'metadata') and checkpoint.metadata else \"unknown\",\n                                \"last_query\": checkpoint.metadata.get(\"last_query\", \"unknown\")[:100] if hasattr(\n                                    checkpoint, 'metadata') and checkpoint.metadata else \"unknown\"\n                            }\n                        except:\n                            metadata = {\"load_error\": True}\n\n                        checkpoints.append({\n                            \"filepath\": filepath,\n                            \"filename\": file,\n                            \"checkpoint_type\": checkpoint_type,\n                            \"timestamp\": checkpoint_time.isoformat(),\n                            \"age_hours\": round(age_hours, 1),\n                            \"file_size_kb\": round(file_size / 1024, 1),\n                            \"metadata\": metadata\n                        })\n\n                except Exception as e:\n                    import traceback\n                    print(traceback.format_exc())\n                    wprint(f\"Could not analyze checkpoint file {file}: {e}\")\n                    continue\n\n        # Sort by timestamp (newest first)\n        checkpoints.sort(key=lambda x: x[\"timestamp\"], reverse=True)\n\n        return checkpoints\n\n    except Exception as e:\n        import traceback\n        print(traceback.format_exc())\n        eprint(f\"Failed to list checkpoints: {e}\")\n        return []\n</code></pre> <code>load_context_from_session(session_id, context_type='full')</code> <code>async</code> \u00b6 <p>Load context from ChatSession storage</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def load_context_from_session(self, session_id: str, context_type: str = \"full\") -&gt; dict[str, Any]:\n    \"\"\"Load context from ChatSession storage\"\"\"\n    try:\n        if not self.context_manager:\n            return {\"error\": \"Context manager not available\"}\n\n        session = self.context_manager.session_managers.get(session_id)\n        if not session:\n            return {\"error\": f\"Session {session_id} not found\"}\n\n        # Search for context snapshots in session history\n        context_snapshots = []\n\n        if hasattr(session, 'history'):\n            for message in reversed(session.history):  # Search from newest\n                if (message.get(\"role\") == \"system\" and\n                    message.get(\"metadata\", {}).get(\"is_context_snapshot\") and\n                    message.get(\"metadata\", {}).get(\"context_type\") == context_type):\n\n                    try:\n                        # Extract context data\n                        content = message.get(\"content\", \"\")\n                        if content.startswith(f\"[CONTEXT_SNAPSHOT_{context_type.upper()}]\"):\n                            json_data = content.replace(f\"[CONTEXT_SNAPSHOT_{context_type.upper()}] \", \"\")\n                            context_data = json.loads(json_data)\n                            context_snapshots.append({\n                                \"context\": context_data,\n                                \"timestamp\": message.get(\"timestamp\"),\n                                \"metadata\": message.get(\"metadata\", {})\n                            })\n                    except Exception as e:\n                        wprint(f\"Failed to parse context snapshot: {e}\")\n\n        if context_snapshots:\n            # Return most recent context snapshot\n            latest_context = context_snapshots[0]\n            rprint(f\"Loaded context snapshot from session {session_id} (timestamp: {latest_context['timestamp']})\")\n            return latest_context[\"context\"]\n        else:\n            return {\"error\": f\"No context snapshots of type '{context_type}' found in session {session_id}\"}\n\n    except Exception as e:\n        eprint(f\"Failed to load context from session: {e}\")\n        return {\"error\": str(e)}\n</code></pre> <code>load_latest_checkpoint(auto_restore_history=True, max_age_hours=24)</code> <code>async</code> \u00b6 <p>Vereinfachtes Checkpoint-Laden mit automatischer History-Wiederherstellung</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def load_latest_checkpoint(self, auto_restore_history: bool = True, max_age_hours: int = 24) -&gt; dict[\n    str, Any]:\n    \"\"\"Vereinfachtes Checkpoint-Laden mit automatischer History-Wiederherstellung\"\"\"\n    try:\n        from toolboxv2 import get_app\n        folder = str(get_app().data_dir) + '/Agents/checkpoint/' + self.amd.name\n\n        if not os.path.exists(folder):\n            return {\"success\": False, \"error\": \"Kein Checkpoint-Verzeichnis gefunden\"}\n\n        # Finde neuesten Checkpoint\n        checkpoint_files = []\n        for file in os.listdir(folder):\n            if file.endswith('.pkl') and file.startswith('agent_checkpoint_'):\n                filepath = os.path.join(folder, file)\n                try:\n                    timestamp_str = file.replace('agent_checkpoint_', '').replace('.pkl', '')\n                    if timestamp_str == 'final_checkpoint':\n                        file_time = datetime.fromtimestamp(os.path.getmtime(filepath))\n                    else:\n                        file_time = datetime.strptime(timestamp_str, \"%Y%m%d_%H%M%S\")\n\n                    age_hours = (datetime.now() - file_time).total_seconds() / 3600\n                    if age_hours &lt;= max_age_hours:\n                        checkpoint_files.append((filepath, file_time, age_hours))\n                except Exception:\n                    continue\n\n        if not checkpoint_files:\n            return {\"success\": False, \"error\": f\"Keine g\u00fcltigen Checkpoints in {max_age_hours} Stunden gefunden\"}\n\n        # Lade neuesten Checkpoint\n        checkpoint_files.sort(key=lambda x: x[1], reverse=True)\n        latest_checkpoint_path, latest_timestamp, age_hours = checkpoint_files[0]\n\n        rprint(f\"Lade Checkpoint: {latest_checkpoint_path} (Alter: {age_hours:.1f}h)\")\n\n        with open(latest_checkpoint_path, 'rb') as f:\n            checkpoint: AgentCheckpoint = pickle.load(f)\n\n        # Stelle Agent-Status wieder her\n        restore_stats = await self._restore_from_checkpoint_simplified(checkpoint, auto_restore_history)\n\n        # Re-initialisiere Kontext-Awareness\n        await self.initialize_context_awareness()\n\n        return {\n            \"success\": True,\n            \"checkpoint_file\": latest_checkpoint_path,\n            \"checkpoint_age_hours\": age_hours,\n            \"checkpoint_timestamp\": latest_timestamp.isoformat(),\n            \"available_checkpoints\": len(checkpoint_files),\n            \"restore_stats\": restore_stats\n        }\n\n    except Exception as e:\n        eprint(f\"Checkpoint-Laden fehlgeschlagen: {e}\")\n        import traceback\n        print(traceback.format_exc())\n        return {\"success\": False, \"error\": str(e)}\n</code></pre> <code>pause()</code> <code>async</code> \u00b6 <p>Pause agent execution</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def pause(self) -&gt; bool:\n    \"\"\"Pause agent execution\"\"\"\n    if not self.is_running:\n        return False\n\n    self.is_paused = True\n    self.shared[\"system_status\"] = \"paused\"\n\n    # Create checkpoint\n    checkpoint = await self._create_checkpoint()\n    await self._save_checkpoint(checkpoint)\n\n    rprint(\"Agent execution paused\")\n    return True\n</code></pre> <code>resume()</code> <code>async</code> \u00b6 <p>Resume agent execution</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def resume(self) -&gt; bool:\n    \"\"\"Resume agent execution\"\"\"\n    if not self.is_paused:\n        return False\n\n    self.is_paused = False\n    self.shared[\"system_status\"] = \"running\"\n\n    rprint(\"Agent execution resumed\")\n    return True\n</code></pre> <code>save_context_to_file(session_id=None)</code> <code>async</code> \u00b6 <p>Save current context to file</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def save_context_to_file(self, session_id: str = None) -&gt; bool:\n    \"\"\"Save current context to file\"\"\"\n    try:\n        context = await self.get_context(session_id=session_id, format_for_llm=False)\n\n        filepath = self._get_context_path(session_id)\n\n        with open(filepath, 'w', encoding='utf-8') as f:\n            json.dump(context, f, indent=2, ensure_ascii=False, default=str)\n\n        rprint(f\"Context saved to: {filepath}\")\n        return True\n\n    except Exception as e:\n        eprint(f\"Failed to save context: {e}\")\n        return False\n</code></pre> <code>save_context_to_session(session_id=None, context_type='full')</code> <code>async</code> \u00b6 <p>Save current context to ChatSession for persistent storage</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def save_context_to_session(self, session_id: str = None, context_type: str = \"full\") -&gt; bool:\n    \"\"\"Save current context to ChatSession for persistent storage\"\"\"\n    try:\n        session_id = session_id or self.shared.get(\"session_id\", \"default\")\n\n        if not self.context_manager:\n            eprint(\"Context manager not available\")\n            return False\n\n        # Build comprehensive context\n        unified_context = await self.context_manager.build_unified_context(session_id, None, context_type)\n\n        # Create context message for session storage\n        context_message = {\n            \"role\": \"system\",\n            \"content\": f\"[CONTEXT_SNAPSHOT_{context_type.upper()}] \" + json.dumps(unified_context, default=str),\n            \"timestamp\": datetime.now().isoformat(),\n            \"context_type\": context_type,\n            \"metadata\": {\n                \"is_context_snapshot\": True,\n                \"context_version\": \"2.0\",\n                \"agent_name\": self.amd.name,\n                \"session_stats\": unified_context.get(\"session_stats\", {}),\n                \"variables_count\": len(unified_context.get(\"variables\", {}).get(\"recent_results\", [])),\n                \"execution_state\": unified_context.get(\"execution_state\", {}).get(\"system_status\", \"unknown\")\n            }\n        }\n\n        # Store in session\n        await self.context_manager.add_interaction(\n            session_id,\n            \"system\",\n            context_message[\"content\"],\n            metadata=context_message[\"metadata\"]\n        )\n\n        rprint(f\"Context snapshot saved to session {session_id} (type: {context_type})\")\n        return True\n\n    except Exception as e:\n        eprint(f\"Failed to save context to session: {e}\")\n        return False\n</code></pre> <code>set_persona(name, style='professional', tone='friendly', personality_traits=None, apply_method='system_prompt', integration_level='light', custom_instructions='')</code> \u00b6 <p>Set agent persona mit erweiterten Konfigurationsm\u00f6glichkeiten</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def set_persona(self, name: str, style: str = \"professional\", tone: str = \"friendly\",\n                personality_traits: list[str] = None, apply_method: str = \"system_prompt\",\n                integration_level: str = \"light\", custom_instructions: str = \"\"):\n    \"\"\"Set agent persona mit erweiterten Konfigurationsm\u00f6glichkeiten\"\"\"\n    if personality_traits is None:\n        personality_traits = [\"helpful\", \"concise\"]\n\n    self.amd.persona = PersonaConfig(\n        name=name,\n        style=style,\n        tone=tone,\n        personality_traits=personality_traits,\n        custom_instructions=custom_instructions,\n        apply_method=apply_method,\n        integration_level=integration_level\n    )\n\n    rprint(f\"Persona set: {name} ({style}, {tone}) - Method: {apply_method}, Level: {integration_level}\")\n</code></pre> <code>set_response_format(response_format, text_length, custom_instructions='', quality_threshold=0.7)</code> \u00b6 <p>Dynamische Format- und L\u00e4ngen-Konfiguration</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def set_response_format(\n    self,\n    response_format: str,\n    text_length: str,\n    custom_instructions: str = \"\",\n    quality_threshold: float = 0.7\n):\n    \"\"\"Dynamische Format- und L\u00e4ngen-Konfiguration\"\"\"\n\n    # Validiere Eingaben\n    try:\n        ResponseFormat(response_format)\n        TextLength(text_length)\n    except ValueError:\n        available_formats = [f.value for f in ResponseFormat]\n        available_lengths = [l.value for l in TextLength]\n        raise ValueError(\n            f\"Invalid format or length. \"\n            f\"Available formats: {available_formats}. \"\n            f\"Available lengths: {available_lengths}\"\n        )\n\n    # Erstelle oder aktualisiere Persona\n    if not self.amd.persona:\n        self.amd.persona = PersonaConfig(name=\"Assistant\")\n\n    # Erstelle Format-Konfiguration\n    format_config = FormatConfig(\n        response_format=ResponseFormat(response_format),\n        text_length=TextLength(text_length),\n        custom_instructions=custom_instructions,\n        quality_threshold=quality_threshold\n    )\n\n    self.amd.persona.format_config = format_config\n\n    # Aktualisiere Personality Traits mit Format-Hinweisen\n    self._update_persona_with_format(response_format, text_length)\n\n    # Update shared state\n    self.shared[\"persona_config\"] = self.amd.persona\n    self.shared[\"format_config\"] = format_config\n\n    rprint(f\"Response format set: {response_format}, length: {text_length}\")\n</code></pre> <code>set_variable(path, value)</code> \u00b6 <p>Set variable using unified system</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def set_variable(self, path: str, value: Any):\n    \"\"\"Set variable using unified system\"\"\"\n    self.variable_manager.set(path, value)\n</code></pre> <code>setup_a2a_server(host='0.0.0.0', port=5000, **kwargs)</code> \u00b6 <p>Setup A2A server for bidirectional communication</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def setup_a2a_server(self, host: str = \"0.0.0.0\", port: int = 5000, **kwargs):\n    \"\"\"Setup A2A server for bidirectional communication\"\"\"\n    if not A2A_AVAILABLE:\n        wprint(\"A2A not available, cannot setup server\")\n        return\n\n    try:\n        self.a2a_server = A2AServer(\n            host=host,\n            port=port,\n            agent_card=AgentCard(\n                name=self.amd.name,\n                description=\"Production-ready PocketFlow agent\",\n                version=\"1.0.0\"\n            ),\n            **kwargs\n        )\n\n        # Register agent methods\n        @self.a2a_server.route(\"/run\")\n        async def handle_run(request_data):\n            query = request_data.get(\"query\", \"\")\n            session_id = request_data.get(\"session_id\", \"a2a_session\")\n\n            response = await self.a_run(query, session_id=session_id)\n            return {\"response\": response}\n\n        rprint(f\"A2A server setup on {host}:{port}\")\n\n    except Exception as e:\n        eprint(f\"Failed to setup A2A server: {e}\")\n</code></pre> <code>setup_mcp_server(host='0.0.0.0', port=8000, name=None, **kwargs)</code> \u00b6 <p>Setup MCP server</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def setup_mcp_server(self, host: str = \"0.0.0.0\", port: int = 8000, name: str = None, **kwargs):\n    \"\"\"Setup MCP server\"\"\"\n    if not MCP_AVAILABLE:\n        wprint(\"MCP not available, cannot setup server\")\n        return\n\n    try:\n        server_name = name or f\"{self.amd.name}_MCP\"\n        self.mcp_server = FastMCP(server_name)\n\n        # Register agent as MCP tool\n        @self.mcp_server.tool()\n        async def agent_run(query: str, session_id: str = \"mcp_session\") -&gt; str:\n            \"\"\"Execute agent with given query\"\"\"\n            return await self.a_run(query, session_id=session_id)\n\n        rprint(f\"MCP server setup: {server_name}\")\n\n    except Exception as e:\n        eprint(f\"Failed to setup MCP server: {e}\")\n</code></pre> <code>start_servers()</code> <code>async</code> \u00b6 <p>Start all configured servers</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def start_servers(self):\n    \"\"\"Start all configured servers\"\"\"\n    tasks = []\n\n    if self.a2a_server:\n        tasks.append(asyncio.create_task(self.a2a_server.start()))\n\n    if self.mcp_server:\n        tasks.append(asyncio.create_task(self.mcp_server.run()))\n\n    if tasks:\n        rprint(f\"Starting {len(tasks)} servers...\")\n        await asyncio.gather(*tasks, return_exceptions=True)\n</code></pre> <code>status(pretty_print=False)</code> \u00b6 <p>Get comprehensive agent status with optional pretty printing</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def status(self, pretty_print: bool = False) -&gt; dict[str, Any] | str:\n    \"\"\"Get comprehensive agent status with optional pretty printing\"\"\"\n\n    # Core status information\n    base_status = {\n        \"agent_info\": {\n            \"name\": self.amd.name,\n            \"version\": \"2.0\",\n            \"type\": \"FlowAgent\"\n        },\n        \"runtime_status\": {\n            \"status\": self.shared.get(\"system_status\", \"idle\"),\n            \"is_running\": self.is_running,\n            \"is_paused\": self.is_paused,\n            \"uptime_seconds\": (datetime.now() - getattr(self, '_start_time', datetime.now())).total_seconds()\n        },\n        \"task_execution\": {\n            \"total_tasks\": len(self.shared.get(\"tasks\", {})),\n            \"active_tasks\": len([t for t in self.shared.get(\"tasks\", {}).values() if t.status == \"running\"]),\n            \"completed_tasks\": len([t for t in self.shared.get(\"tasks\", {}).values() if t.status == \"completed\"]),\n            \"failed_tasks\": len([t for t in self.shared.get(\"tasks\", {}).values() if t.status == \"failed\"]),\n            \"plan_adaptations\": self.shared.get(\"plan_adaptations\", 0)\n        },\n        \"conversation\": {\n            \"turns\": len(self.shared.get(\"conversation_history\", [])),\n            \"session_id\": self.shared.get(\"session_id\", self.active_session),\n            \"current_user\": self.shared.get(\"user_id\"),\n            \"last_query\": self.shared.get(\"current_query\", \"\")[:100] + \"...\" if len(\n                self.shared.get(\"current_query\", \"\")) &gt; 100 else self.shared.get(\"current_query\", \"\")\n        },\n        \"capabilities\": {\n            \"available_tools\": len(self.shared.get(\"available_tools\", [])),\n            \"tool_names\": list(self.shared.get(\"available_tools\", [])),\n            \"analyzed_tools\": len(self._tool_capabilities),\n            \"world_model_size\": len(self.shared.get(\"world_model\", {})),\n            \"intelligence_level\": \"high\" if self._tool_capabilities else \"basic\"\n        },\n        \"memory_context\": {\n            \"session_initialized\": self.shared.get(\"session_initialized\", False),\n            \"session_managers\": len(self.shared.get(\"session_managers\", {})),\n            \"context_system\": \"advanced_session_aware\" if self.shared.get(\"session_initialized\") else \"basic\",\n            \"variable_scopes\": len(self.variable_manager.get_scope_info()) if hasattr(self,\n                                                                                      'variable_manager') else 0\n        },\n        \"performance\": {\n            \"total_cost\": self.total_cost,\n            \"checkpoint_enabled\": self.enable_pause_resume,\n            \"last_checkpoint\": self.last_checkpoint.isoformat() if self.last_checkpoint else None,\n            \"max_parallel_tasks\": self.max_parallel_tasks\n        },\n        \"servers\": {\n            \"a2a_server\": self.a2a_server is not None,\n            \"mcp_server\": self.mcp_server is not None,\n            \"server_count\": sum([self.a2a_server is not None, self.mcp_server is not None])\n        },\n        \"configuration\": {\n            \"fast_llm_model\": self.amd.fast_llm_model,\n            \"complex_llm_model\": self.amd.complex_llm_model,\n            \"use_fast_response\": getattr(self.amd, 'use_fast_response', False),\n            \"max_input_tokens\": getattr(self.amd, 'max_input_tokens', 8000),\n            \"persona_configured\": self.amd.persona is not None,\n            \"format_config\": bool(getattr(self.amd.persona, 'format_config', None)) if self.amd.persona else False\n        }\n    }\n\n    # Add detailed execution summary if tasks exist\n    tasks = self.shared.get(\"tasks\", {})\n    if tasks:\n        task_types_used = {}\n        tools_used = []\n        execution_timeline = []\n\n        for task_id, task in tasks.items():\n            # Count task types\n            task_type = getattr(task, 'type', 'unknown')\n            task_types_used[task_type] = task_types_used.get(task_type, 0) + 1\n\n            # Collect tools used\n            if hasattr(task, 'tool_name') and task.tool_name:\n                tools_used.append(task.tool_name)\n\n            # Timeline info\n            if hasattr(task, 'started_at') and task.started_at:\n                timeline_entry = {\n                    \"task_id\": task_id,\n                    \"type\": task_type,\n                    \"started\": task.started_at.isoformat(),\n                    \"status\": getattr(task, 'status', 'unknown')\n                }\n                if hasattr(task, 'completed_at') and task.completed_at:\n                    timeline_entry[\"completed\"] = task.completed_at.isoformat()\n                    timeline_entry[\"duration\"] = (task.completed_at - task.started_at).total_seconds()\n                execution_timeline.append(timeline_entry)\n\n        base_status[\"task_execution\"].update({\n            \"task_types_used\": task_types_used,\n            \"tools_used\": list(set(tools_used)),\n            \"execution_timeline\": execution_timeline[-5:]  # Last 5 tasks\n        })\n\n    # Add context statistics\n    if hasattr(self.task_flow, 'context_manager'):\n        context_manager = self.task_flow.context_manager\n        base_status[\"memory_context\"].update({\n            \"compression_threshold\": context_manager.compression_threshold,\n            \"max_tokens\": context_manager.max_tokens,\n            \"active_context_sessions\": len(getattr(context_manager, 'session_managers', {}))\n        })\n\n    # Add variable system info\n    if hasattr(self, 'variable_manager'):\n        available_vars = self.variable_manager.get_available_variables()\n        scope_info = self.variable_manager.get_scope_info()\n\n        base_status[\"variable_system\"] = {\n            \"total_scopes\": len(scope_info),\n            \"scope_names\": list(scope_info.keys()),\n            \"total_variables\": sum(len(vars) for vars in available_vars.values()),\n            \"scope_details\": {\n                scope: {\"type\": info[\"type\"], \"variables\": len(available_vars.get(scope, {}))}\n                for scope, info in scope_info.items()\n            }\n        }\n\n    # Add format quality info if available\n    quality_assessment = self.shared.get(\"quality_assessment\", {})\n    if quality_assessment:\n        quality_details = quality_assessment.get(\"quality_details\", {})\n        base_status[\"format_quality\"] = {\n            \"overall_score\": quality_details.get(\"total_score\", 0.0),\n            \"format_adherence\": quality_details.get(\"format_adherence\", 0.0),\n            \"length_adherence\": quality_details.get(\"length_adherence\", 0.0),\n            \"content_quality\": quality_details.get(\"base_quality\", 0.0),\n            \"assessment\": quality_assessment.get(\"quality_assessment\", \"unknown\"),\n            \"has_suggestions\": bool(quality_assessment.get(\"suggestions\", []))\n        }\n\n    # Add LLM usage statistics\n    llm_stats = self.shared.get(\"llm_call_stats\", {})\n    if llm_stats:\n        base_status[\"llm_usage\"] = {\n            \"total_calls\": llm_stats.get(\"total_calls\", 0),\n            \"context_compression_rate\": llm_stats.get(\"context_compression_rate\", 0.0),\n            \"average_context_tokens\": llm_stats.get(\"context_tokens_used\", 0) / max(llm_stats.get(\"total_calls\", 1),\n                                                                                    1),\n            \"total_tokens_used\": llm_stats.get(\"total_tokens_used\", 0)\n        }\n\n    # Add timestamp\n    base_status[\"timestamp\"] = datetime.now().isoformat()\n\n    if not pretty_print:\n        return base_status\n\n    # Pretty print using EnhancedVerboseOutput\n    try:\n        from toolboxv2.mods.isaa.extras.verbose_output import EnhancedVerboseOutput\n        verbose_output = EnhancedVerboseOutput(verbose=True)\n\n        # Header\n        verbose_output.log_header(f\"Agent Status: {base_status['agent_info']['name']}\")\n\n        # Runtime Status\n        status_color = {\n            \"running\": \"SUCCESS\",\n            \"paused\": \"WARNING\",\n            \"idle\": \"INFO\",\n            \"error\": \"ERROR\"\n        }.get(base_status[\"runtime_status\"][\"status\"], \"INFO\")\n\n        getattr(verbose_output, f\"print_{status_color.lower()}\")(\n            f\"Status: {base_status['runtime_status']['status'].upper()}\"\n        )\n\n        # Task Execution Summary\n        task_exec = base_status[\"task_execution\"]\n        if task_exec[\"total_tasks\"] &gt; 0:\n            verbose_output.formatter.print_section(\n                \"Task Execution\",\n                f\"Total: {task_exec['total_tasks']} | \"\n                f\"Completed: {task_exec['completed_tasks']} | \"\n                f\"Failed: {task_exec['failed_tasks']} | \"\n                f\"Active: {task_exec['active_tasks']}\\n\"\n                f\"Adaptations: {task_exec['plan_adaptations']}\"\n            )\n\n            if task_exec.get(\"tools_used\"):\n                verbose_output.formatter.print_section(\n                    \"Tools Used\",\n                    \", \".join(task_exec[\"tools_used\"])\n                )\n\n        # Capabilities\n        caps = base_status[\"capabilities\"]\n        verbose_output.formatter.print_section(\n            \"Capabilities\",\n            f\"Intelligence Level: {caps['intelligence_level']}\\n\"\n            f\"Available Tools: {caps['available_tools']}\\n\"\n            f\"Analyzed Tools: {caps['analyzed_tools']}\\n\"\n            f\"World Model Size: {caps['world_model_size']}\"\n        )\n\n        # Memory &amp; Context\n        memory = base_status[\"memory_context\"]\n        verbose_output.formatter.print_section(\n            \"Memory &amp; Context\",\n            f\"Context System: {memory['context_system']}\\n\"\n            f\"Session Managers: {memory['session_managers']}\\n\"\n            f\"Variable Scopes: {memory['variable_scopes']}\\n\"\n            f\"Session Initialized: {memory['session_initialized']}\"\n        )\n\n        # Configuration\n        config = base_status[\"configuration\"]\n        verbose_output.formatter.print_section(\n            \"Configuration\",\n            f\"Fast LLM: {config['fast_llm_model']}\\n\"\n            f\"Complex LLM: {config['complex_llm_model']}\\n\"\n            f\"Max Tokens: {config['max_input_tokens']}\\n\"\n            f\"Persona: {'Configured' if config['persona_configured'] else 'Default'}\\n\"\n            f\"Format Config: {'Active' if config['format_config'] else 'None'}\"\n        )\n\n        # Performance\n        perf = base_status[\"performance\"]\n        verbose_output.formatter.print_section(\n            \"Performance\",\n            f\"Total Cost: ${perf['total_cost']:.4f}\\n\"\n            f\"Checkpointing: {'Enabled' if perf['checkpoint_enabled'] else 'Disabled'}\\n\"\n            f\"Max Parallel Tasks: {perf['max_parallel_tasks']}\\n\"\n            f\"Last Checkpoint: {perf['last_checkpoint'] or 'None'}\"\n        )\n\n        # Variable System Details\n        if \"variable_system\" in base_status:\n            var_sys = base_status[\"variable_system\"]\n            scope_details = []\n            for scope, details in var_sys[\"scope_details\"].items():\n                scope_details.append(f\"{scope}: {details['variables']} variables ({details['type']})\")\n\n            verbose_output.formatter.print_section(\n                \"Variable System\",\n                f\"Total Scopes: {var_sys['total_scopes']}\\n\"\n                f\"Total Variables: {var_sys['total_variables']}\\n\" +\n                \"\\n\".join(scope_details)\n            )\n\n        # Format Quality\n        if \"format_quality\" in base_status:\n            quality = base_status[\"format_quality\"]\n            verbose_output.formatter.print_section(\n                \"Format Quality\",\n                f\"Overall Score: {quality['overall_score']:.2f}\\n\"\n                f\"Format Adherence: {quality['format_adherence']:.2f}\\n\"\n                f\"Length Adherence: {quality['length_adherence']:.2f}\\n\"\n                f\"Content Quality: {quality['content_quality']:.2f}\\n\"\n                f\"Assessment: {quality['assessment']}\"\n            )\n\n        # LLM Usage\n        if \"llm_usage\" in base_status:\n            llm = base_status[\"llm_usage\"]\n            verbose_output.formatter.print_section(\n                \"LLM Usage Statistics\",\n                f\"Total Calls: {llm['total_calls']}\\n\"\n                f\"Avg Context Tokens: {llm['average_context_tokens']:.1f}\\n\"\n                f\"Total Tokens: {llm['total_tokens_used']}\\n\"\n                f\"Compression Rate: {llm['context_compression_rate']:.2%}\"\n            )\n\n        # Servers\n        servers = base_status[\"servers\"]\n        if servers[\"server_count\"] &gt; 0:\n            server_status = []\n            if servers[\"a2a_server\"]:\n                server_status.append(\"A2A Server: Active\")\n            if servers[\"mcp_server\"]:\n                server_status.append(\"MCP Server: Active\")\n\n            verbose_output.formatter.print_section(\n                \"Servers\",\n                \"\\n\".join(server_status)\n            )\n\n        verbose_output.print_separator()\n        verbose_output.print_info(f\"Status generated at: {base_status['timestamp']}\")\n\n        return \"Status printed above\"\n\n    except Exception:\n        # Fallback to JSON if pretty print fails\n        import json\n        return json.dumps(base_status, indent=2, default=str)\n</code></pre> <code>FormatConfig</code> <code>dataclass</code> \u00b6 <p>Konfiguration f\u00fcr Response-Format und -L\u00e4nge</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>@dataclass\nclass FormatConfig:\n    \"\"\"Konfiguration f\u00fcr Response-Format und -L\u00e4nge\"\"\"\n    response_format: ResponseFormat = ResponseFormat.FREE_TEXT\n    text_length: TextLength = TextLength.CHAT_CONVERSATION\n    custom_instructions: str = \"\"\n    strict_format_adherence: bool = True\n    quality_threshold: float = 0.7\n\n    def get_format_instructions(self) -&gt; str:\n        \"\"\"Generiere Format-spezifische Anweisungen\"\"\"\n        format_instructions = {\n            ResponseFormat.FREE_TEXT: \"Use natural continuous text without special formatting.\",\n            ResponseFormat.WITH_TABLES: \"Integrate tables for structured data representation. Use Markdown tables.\",\n            ResponseFormat.WITH_BULLET_POINTS: \"Structure information with bullet points (\u2022, -, *) for better readability.\",\n            ResponseFormat.WITH_LISTS: \"Use numbered and unnumbered lists to organize content.\",\n            ResponseFormat.TEXT_ONLY: \"Plain text only without formatting, symbols, or structural elements.\",\n            ResponseFormat.MD_TEXT: \"Full Markdown formatting with headings, code blocks, links, etc.\",\n            ResponseFormat.YAML_TEXT: \"Structure responses in YAML format for machine-readable output.\",\n            ResponseFormat.JSON_TEXT: \"Format responses as a JSON structure for API integration.\",\n            ResponseFormat.PSEUDO_CODE: \"Use pseudocode structure for algorithmic or logical explanations.\",\n            ResponseFormat.CODE_STRUCTURE: \"Structure like code with indentation, comments, and logical blocks.\"\n        }\n        return format_instructions.get(self.response_format, \"Standard-Formatierung.\")\n\n    def get_length_instructions(self) -&gt; str:\n        \"\"\"Generiere L\u00e4ngen-spezifische Anweisungen\"\"\"\n        length_instructions = {\n            TextLength.MINI_CHAT: \"Very short, concise answers (1\u20132 sentences, max 50 words). Chat style.\",\n            TextLength.CHAT_CONVERSATION: \"Moderate conversation length (2\u20134 sentences, 50\u2013150 words). Natural conversational style.\",\n            TextLength.TABLE_CONVERSATION: \"Structured, tabular presentation with compact explanations (100\u2013250 words).\",\n            TextLength.DETAILED_INDEPTH: \"Comprehensive, detailed explanations (300\u2013800 words) with depth and context.\",\n            TextLength.PHD_LEVEL: \"Academic depth with extensive explanations (800+ words), references, and technical terminology.\"\n        }\n        return length_instructions.get(self.text_length, \"Standard-L\u00e4nge.\")\n\n    def get_combined_instructions(self) -&gt; str:\n        \"\"\"Kombiniere Format- und L\u00e4ngen-Anweisungen\"\"\"\n        instructions = []\n        instructions.append(\"## Format-Anforderungen:\")\n        instructions.append(self.get_format_instructions())\n        instructions.append(\"\\n## L\u00e4ngen-Anforderungen:\")\n        instructions.append(self.get_length_instructions())\n\n        if self.custom_instructions:\n            instructions.append(\"\\n## Zus\u00e4tzliche Anweisungen:\")\n            instructions.append(self.custom_instructions)\n\n        if self.strict_format_adherence:\n            instructions.append(\"\\n## ATTENTION: STRICT FORMAT ADHERENCE REQUIRED!\")\n\n        return \"\\n\".join(instructions)\n\n    def get_expected_word_range(self) -&gt; tuple[int, int]:\n        \"\"\"Erwartete Wortanzahl f\u00fcr Qualit\u00e4tsbewertung\"\"\"\n        ranges = {\n            TextLength.MINI_CHAT: (10, 50),\n            TextLength.CHAT_CONVERSATION: (50, 150),\n            TextLength.TABLE_CONVERSATION: (100, 250),\n            TextLength.DETAILED_INDEPTH: (300, 800),\n            TextLength.PHD_LEVEL: (800, 2000)\n        }\n        return ranges.get(self.text_length, (50, 200))\n</code></pre> <code>get_combined_instructions()</code> \u00b6 <p>Kombiniere Format- und L\u00e4ngen-Anweisungen</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def get_combined_instructions(self) -&gt; str:\n    \"\"\"Kombiniere Format- und L\u00e4ngen-Anweisungen\"\"\"\n    instructions = []\n    instructions.append(\"## Format-Anforderungen:\")\n    instructions.append(self.get_format_instructions())\n    instructions.append(\"\\n## L\u00e4ngen-Anforderungen:\")\n    instructions.append(self.get_length_instructions())\n\n    if self.custom_instructions:\n        instructions.append(\"\\n## Zus\u00e4tzliche Anweisungen:\")\n        instructions.append(self.custom_instructions)\n\n    if self.strict_format_adherence:\n        instructions.append(\"\\n## ATTENTION: STRICT FORMAT ADHERENCE REQUIRED!\")\n\n    return \"\\n\".join(instructions)\n</code></pre> <code>get_expected_word_range()</code> \u00b6 <p>Erwartete Wortanzahl f\u00fcr Qualit\u00e4tsbewertung</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def get_expected_word_range(self) -&gt; tuple[int, int]:\n    \"\"\"Erwartete Wortanzahl f\u00fcr Qualit\u00e4tsbewertung\"\"\"\n    ranges = {\n        TextLength.MINI_CHAT: (10, 50),\n        TextLength.CHAT_CONVERSATION: (50, 150),\n        TextLength.TABLE_CONVERSATION: (100, 250),\n        TextLength.DETAILED_INDEPTH: (300, 800),\n        TextLength.PHD_LEVEL: (800, 2000)\n    }\n    return ranges.get(self.text_length, (50, 200))\n</code></pre> <code>get_format_instructions()</code> \u00b6 <p>Generiere Format-spezifische Anweisungen</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def get_format_instructions(self) -&gt; str:\n    \"\"\"Generiere Format-spezifische Anweisungen\"\"\"\n    format_instructions = {\n        ResponseFormat.FREE_TEXT: \"Use natural continuous text without special formatting.\",\n        ResponseFormat.WITH_TABLES: \"Integrate tables for structured data representation. Use Markdown tables.\",\n        ResponseFormat.WITH_BULLET_POINTS: \"Structure information with bullet points (\u2022, -, *) for better readability.\",\n        ResponseFormat.WITH_LISTS: \"Use numbered and unnumbered lists to organize content.\",\n        ResponseFormat.TEXT_ONLY: \"Plain text only without formatting, symbols, or structural elements.\",\n        ResponseFormat.MD_TEXT: \"Full Markdown formatting with headings, code blocks, links, etc.\",\n        ResponseFormat.YAML_TEXT: \"Structure responses in YAML format for machine-readable output.\",\n        ResponseFormat.JSON_TEXT: \"Format responses as a JSON structure for API integration.\",\n        ResponseFormat.PSEUDO_CODE: \"Use pseudocode structure for algorithmic or logical explanations.\",\n        ResponseFormat.CODE_STRUCTURE: \"Structure like code with indentation, comments, and logical blocks.\"\n    }\n    return format_instructions.get(self.response_format, \"Standard-Formatierung.\")\n</code></pre> <code>get_length_instructions()</code> \u00b6 <p>Generiere L\u00e4ngen-spezifische Anweisungen</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def get_length_instructions(self) -&gt; str:\n    \"\"\"Generiere L\u00e4ngen-spezifische Anweisungen\"\"\"\n    length_instructions = {\n        TextLength.MINI_CHAT: \"Very short, concise answers (1\u20132 sentences, max 50 words). Chat style.\",\n        TextLength.CHAT_CONVERSATION: \"Moderate conversation length (2\u20134 sentences, 50\u2013150 words). Natural conversational style.\",\n        TextLength.TABLE_CONVERSATION: \"Structured, tabular presentation with compact explanations (100\u2013250 words).\",\n        TextLength.DETAILED_INDEPTH: \"Comprehensive, detailed explanations (300\u2013800 words) with depth and context.\",\n        TextLength.PHD_LEVEL: \"Academic depth with extensive explanations (800+ words), references, and technical terminology.\"\n    }\n    return length_instructions.get(self.text_length, \"Standard-L\u00e4nge.\")\n</code></pre> <code>LLMReasonerNode</code> \u00b6 <p>               Bases: <code>AsyncNode</code></p> <p>Enhanced strategic reasoning core with outline-driven execution, context management, auto-recovery, and intensive variable system integration.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>@with_progress_tracking\nclass LLMReasonerNode(AsyncNode):\n    \"\"\"\n    Enhanced strategic reasoning core with outline-driven execution,\n    context management, auto-recovery, and intensive variable system integration.\n    \"\"\"\n\n    def __init__(self, max_reasoning_loops: int = 12, **kwargs):\n        super().__init__(**kwargs)\n        self.max_reasoning_loops = max_reasoning_loops\n        self.reasoning_context = []\n        self.internal_task_stack = []\n        self.meta_tools_registry = {}\n        self.current_loop_count = 0\n        self.current_reasoning_count = 0\n        self.agent_instance: FlowAgent = None\n\n        # Enhanced tracking systems\n        self.outline = None\n        self.current_outline_step = 0\n        self.step_completion_tracking = {}\n        self.loop_detection_memory = []\n        self.context_summary_threshold = 15\n        self.max_context_size = 30\n        self.performance_metrics = {\n                \"loop_times\": [],\n                \"progress_loops\": 0,\n                \"total_loops\": 0\n            }\n        self.auto_recovery_attempts = 0\n        self.max_auto_recovery = 8\n        self.variable_manager = None\n\n        # Anti-loop mechanisms\n        self.last_action_signatures = []\n        self.step_enforcement_active = True\n        self.mandatory_progress_check = True\n\n    async def prep_async(self, shared):\n        \"\"\"Enhanced initialization with variable system integration\"\"\"\n        # Reset for new execution\n        self.reasoning_context = []\n        self.internal_task_stack = []\n        self.current_loop_count = 0\n        self.current_reasoning_count = 0\n        self.outline = None\n        self.current_outline_step = 0\n        self.step_completion_tracking = {}\n        self.loop_detection_memory = []\n        self.performance_metrics = {\n            \"loop_times\": [],\n            \"progress_loops\": 0,\n            \"total_loops\": 0\n        }\n        self.auto_recovery_attempts = 0\n        self.last_action_signatures = []\n\n        self.agent_instance = shared.get(\"agent_instance\")\n\n        # Enhanced variable manager integration\n        self.variable_manager = shared.get(\"variable_manager\", self.agent_instance.variable_manager)\n        context_manager = shared.get(\"context_manager\")\n\n        if self.variable_manager:\n            # Store reasoning session context\n            session_context = {\n                \"session_id\": shared.get(\"session_id\", \"default\"),\n                \"start_time\": datetime.now().isoformat(),\n                \"query\": shared.get(\"current_query\", \"\"),\n                \"reasoning_mode\": \"outline_driven\"\n            }\n            self.variable_manager.set(\"reasoning.current_session\", session_context)\n            # Load previous successful patterns from variables\n            self._load_historical_patterns()\n\n        #Build comprehensive system context via UnifiedContextManager\n        system_context = await self._build_enhanced_system_context_unified(shared, context_manager)\n\n        return {\n            \"original_query\": shared.get(\"current_query\", \"\"),\n            \"session_id\": shared.get(\"session_id\", \"default\"),\n            \"agent_instance\": shared.get(\"agent_instance\"),\n            \"variable_manager\": self.variable_manager,\n            \"context_manager\": context_manager,  #Context Manager Reference\n            \"system_context\": system_context,\n            \"available_tools\": shared.get(\"available_tools\", []),\n            \"tool_capabilities\": shared.get(\"tool_capabilities\", {}),\n            \"fast_llm_model\": shared.get(\"fast_llm_model\"),\n            \"complex_llm_model\": shared.get(\"complex_llm_model\"),\n            \"progress_tracker\": shared.get(\"progress_tracker\"),\n            \"formatted_context\": shared.get(\"formatted_context\", {}),\n            \"historical_context\": await self._get_historical_context_unified(context_manager, shared.get(\"session_id\")),\n            \"capabilities_summary\": shared.get(\"capabilities_summary\", \"\"),\n            # Sub-system references\n            \"llm_tool_node\": shared.get(\"llm_tool_node_instance\"),\n            \"task_planner\": shared.get(\"task_planner_instance\"),\n            \"task_executor\": shared.get(\"task_executor_instance\"),\n        }\n\n    async def exec_async(self, prep_res):\n        \"\"\"Enhanced main reasoning loop with outline-driven execution\"\"\"\n        if not LITELLM_AVAILABLE:\n            return await self._fallback_direct_response(prep_res)\n\n        original_query = prep_res[\"original_query\"]\n        agent_instance = prep_res[\"agent_instance\"]\n        progress_tracker = prep_res.get(\"progress_tracker\")\n\n        # Initialize enhanced reasoning context\n        await self._initialize_reasoning_session(prep_res, original_query)\n\n        # STEP 1: MANDATORY OUTLINE CREATION\n        if not self.outline:\n            outline_result = await self._create_initial_outline(prep_res)\n            if not outline_result:\n                return await self._create_error_response(original_query, \"Failed to create initial outline\")\n\n        final_result = None\n        consecutive_no_progress = 0\n        max_no_progress = 3\n\n        # Enhanced main reasoning loop with strict progress tracking\n        while self.current_reasoning_count &lt; self.max_reasoning_loops:\n            self.current_loop_count += 1\n            loop_start_time = time.time()\n\n            # Check for infinite loops\n            if self._detect_infinite_loop():\n                await self._trigger_auto_recovery(prep_res)\n                if self.auto_recovery_attempts &gt;= self.max_auto_recovery:\n                    break\n\n            # Auto-context management\n            await self._manage_context_size()\n\n            # Progress tracking\n            if progress_tracker:\n                await progress_tracker.emit_event(ProgressEvent(\n                    event_type=\"reasoning_loop\",\n                    timestamp=time.time(),\n                    node_name=\"LLMReasonerNode\",\n                    status=NodeStatus.RUNNING,\n                    metadata={\n                        \"loop_number\": self.current_loop_count,\n                        \"outline_step\": self.current_outline_step,\n                        \"outline_total\": len(self.outline.get(\"steps\", [])) if self.outline else 0,\n                        \"context_size\": len(self.reasoning_context),\n                        \"task_stack_size\": len(self.internal_task_stack),\n                        \"auto_recovery_attempts\": self.auto_recovery_attempts,\n                        \"performance_metrics\": self.performance_metrics\n                    }\n                ))\n\n            try:\n                # Build enhanced reasoning prompt with outline context\n                reasoning_prompt = await self._build_outline_driven_prompt(prep_res)\n\n                # Force progress check if needed\n                if self.mandatory_progress_check and consecutive_no_progress &gt;= 2:\n                    reasoning_prompt += \"\\n\\n**MANDATORY**: You must either complete current outline step or move to next step. No more analysis without action!\"\n\n                # LLM reasoning call\n                model_to_use = prep_res.get(\"complex_llm_model\", \"openrouter/openai/gpt-4o\")\n\n                llm_response = await agent_instance.a_run_llm_completion(\n                    model=model_to_use,\n                    messages=[{\"role\": \"user\", \"content\": reasoning_prompt}],\n                    temperature=0.2,  # Lower temperature for more focused execution\n                    # max_tokens=3072,\n                    node_name=\"LLMReasonerNode\",\n                    stop=\"&lt;immediate_context&gt;\",\n                    task_id=f\"reasoning_loop_{self.current_loop_count}_step_{self.current_outline_step}\"\n                )\n\n                # Add LLM response to context\n                self.reasoning_context.append({\n                    \"type\": \"reasoning\",\n                    \"content\": llm_response,\n                    \"loop\": self.current_loop_count,\n                    \"outline_step\": self.current_outline_step,\n                    \"timestamp\": datetime.now().isoformat()\n                })\n\n                # Parse and execute meta-tool calls with enhanced tracking\n                progress_made = await self._parse_and_execute_meta_tools(llm_response, prep_res)\n\n                action_taken = progress_made.get(\"action_taken\", False)\n                actual_progress = progress_made.get(\"progress_made\", False)\n\n                # Update performance with correct progress indication\n                self._update_performance_metrics(loop_start_time, actual_progress)\n\n                if not action_taken:\n                    self.current_reasoning_count += 1\n                    if self.current_outline_step &gt; len(self.outline.get(\"steps\", [])):\n                        progress_made[\"final_result\"] = llm_response\n                        rprint(\"Final result reached forced by outline step count\")\n                    if self.current_outline_step &lt; len(self.outline.get(\"steps\", [])) and self.outline.get(\"steps\", [])[self.current_outline_step].get(\"is_final\", False):\n                        progress_made[\"final_result\"] = llm_response\n                        rprint(\"Final result reached forced by outline step count final step\")\n                else:\n                    self.current_reasoning_count -= 1\n\n                # Check for final result\n                if progress_made.get(\"final_result\"):\n                    final_result = progress_made[\"final_result\"]\n                    await self._finalize_reasoning_session(prep_res, final_result)\n                    break\n\n                # Progress monitoring\n                if progress_made.get(\"action_taken\"):\n                    consecutive_no_progress = 0\n                    self._update_performance_metrics(loop_start_time, True)\n                else:\n                    consecutive_no_progress += 1\n                    self._update_performance_metrics(loop_start_time, False)\n\n                # Check outline completion\n                if self.outline and self.current_outline_step &gt;= len(self.outline.get(\"steps\", []))+self.max_reasoning_loops:\n                    # All outline steps completed, force final response\n                    final_result = await self._create_outline_completion_response(prep_res)\n                    break\n\n                # Emergency break for excessive no-progress\n                if consecutive_no_progress &gt;= max_no_progress:\n                    await self._trigger_auto_recovery(prep_res)\n\n            except Exception as e:\n                await self._handle_reasoning_error(e, prep_res, progress_tracker)\n                import traceback\n                print(traceback.format_exc())\n                if self.auto_recovery_attempts &gt;= self.max_auto_recovery:\n                    final_result = await self._create_error_response(original_query, str(e))\n                    break\n\n\n        # If no final result after max loops, create a comprehensive summary\n        if not final_result:\n            final_result = await self._create_enhanced_timeout_response(original_query, prep_res)\n\n        return {\n            \"final_result\": final_result,\n            \"reasoning_loops\": self.current_loop_count,\n            \"reasoning_context\": self.reasoning_context.copy(),\n            \"internal_task_stack\": self.internal_task_stack.copy(),\n            \"outline\": self.outline,\n            \"outline_completion\": self.current_outline_step,\n            \"performance_metrics\": self.performance_metrics,\n            \"auto_recovery_attempts\": self.auto_recovery_attempts\n        }\n\n    async def _build_enhanced_system_context_unified(self, shared, context_manager) -&gt; str:\n        \"\"\"Build comprehensive system context mit UnifiedContextManager\"\"\"\n        context_parts = []\n\n        # Enhanced agent capabilities\n        available_tools = shared.get(\"available_tools\", [])\n        if available_tools:\n            context_parts.append(f\"Available external tools: {', '.join(available_tools)}\")\n\n        #Context Manager Status\n        if context_manager:\n            session_stats = context_manager.get_session_statistics()\n            context_parts.append(f\"Context System: Advanced with {session_stats['total_sessions']} active sessions\")\n            context_parts.append(f\"Cache Status: {session_stats['cache_entries']} cached contexts\")\n\n        # Variable system context\n        if self.variable_manager:\n            var_info = self.variable_manager.get_scope_info()\n            context_parts.append(f\"Variable System: {len(var_info)} scopes available\")\n\n            # Recent results availability\n            results_count = len(self.variable_manager.get(\"results\", {}))\n            if results_count:\n                context_parts.append(f\"Previous results: {results_count} task results available\")\n\n        #Enhanced system state mit Context-Awareness\n        session_id = shared.get(\"session_id\", \"default\")\n        if context_manager and session_id in context_manager.session_managers:\n            session = context_manager.session_managers[session_id]\n            if hasattr(session, 'history'):\n                context_parts.append(f\"Session History: {len(session.history)} conversation entries available\")\n            elif isinstance(session, dict) and 'history' in session:\n                context_parts.append(f\"Session History: {len(session['history'])} conversation entries (fallback mode)\")\n\n        # System state with enhanced details\n        tasks = shared.get(\"tasks\", {})\n        if tasks:\n            active_tasks = len([t for t in tasks.values() if t.status == \"running\"])\n            completed_tasks = len([t for t in tasks.values() if t.status == \"completed\"])\n            context_parts.append(f\"Execution state: {active_tasks} active, {completed_tasks} completed tasks\")\n\n        # Performance history\n        if hasattr(self, 'historical_successful_patterns'):\n            context_parts.append(\n                f\"Historical patterns: {len(self.historical_successful_patterns)} successful patterns loaded\")\n\n        return \"\\n\".join(context_parts) if context_parts else \"Basic system context available\"\n\n    async def _get_historical_context_unified(self, context_manager, session_id: str) -&gt; str:\n        \"\"\"Get historical context from UnifiedContextManager\"\"\"\n        if not context_manager:\n            return \"\"\n\n        try:\n            #Get unified context for historical analysis\n            unified_context = await context_manager.build_unified_context(session_id, None, \"historical\")\n\n            context_parts = []\n\n            # Chat history insights\n            chat_history = unified_context.get(\"chat_history\", [])\n            if chat_history:\n                context_parts.append(f\"Conversation History: {len(chat_history)} messages available\")\n\n                # Analyze conversation patterns\n                user_queries = [msg['content'] for msg in chat_history if msg.get('role') == 'user']\n                if user_queries:\n                    avg_query_length = sum(len(q) for q in user_queries) / len(user_queries)\n                    context_parts.append(f\"Query patterns: Avg length {avg_query_length:.0f} chars\")\n\n            # Execution history from variables\n            if self.variable_manager:\n                # Recent successful queries\n                recent_successes = self.variable_manager.get(\"reasoning.recent_successes\", [])\n                if recent_successes:\n                    context_parts.append(f\"Recent successful queries: {len(recent_successes)}\")\n\n                # Performance history\n                avg_loops = self.variable_manager.get(\"reasoning.performance.avg_loops\", 0)\n                if avg_loops:\n                    context_parts.append(f\"Average reasoning loops: {avg_loops}\")\n\n            # System insights from unified context\n            execution_state = unified_context.get(\"execution_state\", {})\n            if execution_state.get(\"recent_completions\"):\n                completions = execution_state[\"recent_completions\"]\n                context_parts.append(f\"Recent completions: {len(completions)} tasks finished\")\n\n            return \"\\n\".join(context_parts)\n\n        except Exception as e:\n            eprint(f\"Failed to get historical context: {e}\")\n            return \"Historical context unavailable\"\n\n    def _load_historical_patterns(self):\n        \"\"\"Load successful patterns from previous reasoning sessions\"\"\"\n        if not self.variable_manager:\n            return\n\n        # Load successful outline patterns\n        successful_outlines = self.variable_manager.get(\"reasoning.successful_patterns.outlines\", [])\n        failed_patterns = self.variable_manager.get(\"reasoning.failed_patterns\", [])\n\n        self.historical_successful_patterns = successful_outlines[-5:]  # Last 5 successful\n        self.historical_failed_patterns = failed_patterns[-10:]  # Last 10 failed\n\n    def _get_historical_context(self) -&gt; str:\n        \"\"\"Get historical context from variable system\"\"\"\n        if not self.variable_manager:\n            return \"\"\n\n        context_parts = []\n\n        # Recent successful queries\n        recent_successes = self.variable_manager.get(\"reasoning.recent_successes\", [])\n        if recent_successes:\n            context_parts.append(f\"Recent successful queries: {len(recent_successes)}\")\n\n        # Performance history\n        avg_loops = self.variable_manager.get(\"reasoning.performance.avg_loops\", 0)\n        if avg_loops:\n            context_parts.append(f\"Average reasoning loops: {avg_loops}\")\n\n        # Common failure patterns to avoid\n        failure_patterns = self.variable_manager.get(\"reasoning.failure_patterns\", [])\n        if failure_patterns:\n            context_parts.append(f\"Known failure patterns: {len(failure_patterns)}\")\n\n        return \"\\n\".join(context_parts)\n\n    async def _initialize_reasoning_session(self, prep_res, original_query):\n        \"\"\"Initialize enhanced reasoning session with variable tracking\"\"\"\n        # Initialize reasoning context\n        self.reasoning_context.append({\n            \"type\": \"session_start\",\n            \"content\": f\"Enhanced reasoning session started for: {original_query}\",\n            \"timestamp\": datetime.now().isoformat(),\n            \"session_id\": prep_res.get(\"session_id\")\n        })\n\n        # Store session in variables\n        if self.variable_manager:\n            session_data = {\n                \"query\": original_query,\n                \"start_time\": datetime.now().isoformat(),\n                \"max_loops\": self.max_reasoning_loops,\n                \"context_management\": \"auto_summary\",\n                \"outline_driven\": True\n            }\n            self.variable_manager.set(\"reasoning.current_session.data\", session_data)\n\n        # Add enhanced system context\n        self.reasoning_context.append({\n            \"type\": \"system_context\",\n            \"content\": prep_res[\"system_context\"],\n            \"timestamp\": datetime.now().isoformat()\n        })\n\n        # Add historical context if available\n        historical = prep_res.get(\"historical_context\")\n        if historical:\n            self.reasoning_context.append({\n                \"type\": \"historical_context\",\n                \"content\": historical,\n                \"timestamp\": datetime.now().isoformat()\n            })\n\n    async def _create_initial_outline(self, prep_res) -&gt; bool:\n        \"\"\"Create mandatory initial outline, with a fast path for simple queries.\"\"\"\n        original_query = prep_res[\"original_query\"]\n        agent_instance = prep_res[\"agent_instance\"]\n\n        outline_prompt = f\"\"\"You MUST create an initial execution outline for this query. This is mandatory.\n\n**Query:** {original_query}\n\n**Available Resources:**\n- Tools: {', '.join(prep_res.get('available_tools', []))}\n- Sub-systems: LLM Tool Node, Task Planner, Task Executor\n\nLLM Tool Node is for all tool calls!\nLLM Tool Node is best for simple multi-step tasks like fetching data from a tool and summarizing it.\nTask Planner is best for complex tasks with multiple dependencies and complex task flows.\n\n**Historical Context:** {prep_res.get('historical_context', 'None')}\n\n**Fast Path for Simple Queries:**\nIf the query is simple and can be answered directly without needing tools or complex reasoning, you MUST create a single-step outline using the `direct_response` method.\n\nCreate a structured outline using this EXACT format:\n\nOUTLINE_START\nStep 1: [Brief description of first step]\n- Method: [internal_reasoning | delegate_to_llm_tool_node | create_and_execute_plan | direct_response]\n- Expected outcome: [What this step should achieve]\n- Success criteria: [How to know this step is complete]\n\n[For complex queries, continue with more steps as needed.]\n\nFinal Step: Synthesize results and provide comprehensive response\n- Method: direct_response\n- Expected outcome: Complete answer to user query\n- Success criteria: User query fully addressed\nOUTLINE_END\n\n**Requirements:**\n1. Outline must have between 1 and 7 steps.\n2. For simple queries, a single \"Final Step\" using the 'direct_response' method is the correct approach.\n3. Each step must have clear success criteria and build logically toward the answer.\n4. Be specific about which meta-tools to use for each step. meta-tools ar not Tools ! avalabel meta-tools *Method* (internal_reasoning, delegate_to_llm_tool_node, create_and_execute_plan, direct_response) no exceptions\n\nCreate the outline now:\"\"\"\n\n        try:\n            llm_response = await agent_instance.a_run_llm_completion(\n                model=prep_res.get(\"complex_llm_model\", \"openrouter/openai/gpt-4o\"),\n                messages=[{\"role\": \"user\", \"content\": outline_prompt}],\n                temperature=0.2,  # Lower temperature for more deterministic outlining\n                max_tokens=2048,\n                node_name=\"LLMReasonerNode\",\n                task_id=\"create_initial_outline\"\n            )\n\n            # Parse outline from response\n            outline = self._parse_outline_from_response(llm_response)\n\n            if self.agent_instance and self.agent_instance.progress_tracker:\n                await self.agent_instance.progress_tracker.emit_event(ProgressEvent(\n                    event_type=\"outline_created\",\n                    timestamp=time.time(),\n                    node_name=\"LLMReasonerNode\",\n                    status=NodeStatus.COMPLETED,\n                    task_id=\"create_initial_outline\",\n                    metadata={\"outline\": outline}\n                ))\n\n            if outline:\n                self.outline = outline\n                self.current_outline_step = 0\n\n                # Store outline in variables\n                if self.variable_manager:\n                    self.variable_manager.set(\"reasoning.current_session.outline\", outline)\n\n                # Add to reasoning context\n                self.reasoning_context.append({\n                    \"type\": \"outline_created\",\n                    \"content\": f\"Created outline with {len(outline.get('steps', []))} steps\",\n                    \"outline\": outline,\n                    \"timestamp\": datetime.now().isoformat()\n                })\n\n                return True\n            else:\n                return False\n\n        except Exception as e:\n            eprint(f\"Failed to create initial outline: {e}\")\n            return False\n\n    def _parse_outline_from_response(self, response: str) -&gt; dict[str, Any]:\n        \"\"\"Parse structured outline from LLM response\"\"\"\n        import re\n\n        # Find outline section\n        outline_match = re.search(r'OUTLINE_START(.*?)OUTLINE_END', response, re.DOTALL)\n        if not outline_match:\n            return None\n\n        outline_text = outline_match.group(1).strip()\n\n        # Parse steps\n        steps = []\n        current_step = None\n\n        for line in outline_text.split('\\n'):\n            line = line.strip()\n            if not line:\n                continue\n\n            # New step\n            if re.match(r'^Step \\d+:', line):\n                if current_step:\n                    steps.append(current_step)\n\n                current_step = {\n                    \"description\": re.sub(r'^Step \\d+:\\s*', '', line),\n                    \"method\": \"\",\n                    \"expected_outcome\": \"\",\n                    \"success_criteria\": \"\",\n                    \"status\": \"pending\"\n                }\n            elif re.match(r'^Final Step:', line):\n                if current_step:\n                    steps.append(current_step)\n\n                current_step = {\n                    \"description\": re.sub(r'^Final Step:\\s*', '', line),\n                    \"method\": \"direct_response\",\n                    \"expected_outcome\": \"\",\n                    \"success_criteria\": \"\",\n                    \"status\": \"pending\",\n                    \"is_final\": True\n                }\n            elif current_step and line.startswith('- Method:'):\n                current_step[\"method\"] = line.replace('- Method:', '').strip()\n            elif current_step and line.startswith('- Expected outcome:'):\n                current_step[\"expected_outcome\"] = line.replace('- Expected outcome:', '').strip()\n            elif current_step and line.startswith('- Success criteria:'):\n                current_step[\"success_criteria\"] = line.replace('- Success criteria:', '').strip()\n\n        # Add final step if exists\n        if current_step:\n            steps.append(current_step)\n\n        if not steps:\n            return None\n\n        return {\n            \"steps\": steps,\n            \"created_at\": datetime.now().isoformat(),\n            \"total_steps\": len(steps)\n        }\n\n    def _build_enhanced_system_context(self, shared) -&gt; str:\n        \"\"\"Build comprehensive system context with variable system info\"\"\"\n        context_parts = []\n\n        # Enhanced agent capabilities\n        available_tools = shared.get(\"available_tools\", [])\n        if available_tools:\n            context_parts.append(f\"Available external tools: {', '.join(available_tools)}\")\n\n        # Variable system context\n        if self.variable_manager:\n            var_info = self.variable_manager.get_scope_info()\n            context_parts.append(f\"Variable System: {len(var_info)} scopes available\")\n\n            # Recent results availability\n            results_count = len(self.variable_manager.get(\"results\", {}))\n            if results_count:\n                context_parts.append(f\"Previous results: {results_count} task results available\")\n\n        # System state with enhanced details\n        tasks = shared.get(\"tasks\", {})\n        if tasks:\n            active_tasks = len([t for t in tasks.values() if t.status == \"running\"])\n            completed_tasks = len([t for t in tasks.values() if t.status == \"completed\"])\n            context_parts.append(f\"Execution state: {active_tasks} active, {completed_tasks} completed tasks\")\n\n        # Session context with history\n        formatted_context = shared.get(\"formatted_context\", {})\n        if formatted_context:\n            recent_interaction = formatted_context.get(\"recent_interaction\", \"\")\n            if recent_interaction:\n                context_parts.append(f\"Recent interaction: {recent_interaction[:100000]}...\")\n\n        # Performance history\n        if hasattr(self, 'historical_successful_patterns'):\n            context_parts.append(\n                f\"Historical patterns: {len(self.historical_successful_patterns)} successful patterns loaded\")\n\n        return \"\\n\".join(context_parts) if context_parts else \"Basic system context available\"\n\n    async def _manage_context_size(self):\n        \"\"\"Auto-manage context size with intelligent summarization\"\"\"\n        if len(self.reasoning_context) &lt;= self.context_summary_threshold:\n            return\n\n        # Trigger summarization\n        if len(self.reasoning_context) &gt;= self.max_context_size:\n            # Emergency summarization\n            await self._emergency_context_summary()\n        elif len(self.reasoning_context) &gt;= self.context_summary_threshold:\n            # Regular summarization\n            await self._regular_context_summary()\n\n    async def _regular_context_summary(self):\n        \"\"\"Regular context summarization when threshold is reached\"\"\"\n        # Keep last 10 entries, summarize the rest\n        keep_recent = self.reasoning_context[-10:]\n        to_summarize = self.reasoning_context[:-10]\n\n        summary = self._create_context_summary(to_summarize, \"regular\")\n\n        # Replace old context with summary + recent\n        self.reasoning_context = [\n                                     {\n                                         \"type\": \"context_summary\",\n                                         \"content\": summary,\n                                         \"summarized_entries\": len(to_summarize),\n                                         \"summary_type\": \"regular\",\n                                         \"timestamp\": datetime.now().isoformat()\n                                     }\n                                 ] + keep_recent\n\n    async def _emergency_context_summary(self):\n        \"\"\"Emergency context summarization when max size is reached\"\"\"\n        # Keep last 5 entries, summarize everything else\n        keep_recent = self.reasoning_context[-5:]\n        to_summarize = self.reasoning_context[:-5]\n\n        summary = self._create_context_summary(to_summarize, \"emergency\")\n\n        # Replace with emergency summary\n        self.reasoning_context = [\n                                     {\n                                         \"type\": \"context_summary\",\n                                         \"content\": summary,\n                                         \"summarized_entries\": len(to_summarize),\n                                         \"summary_type\": \"emergency\",\n                                         \"timestamp\": datetime.now().isoformat()\n                                     }\n                                 ] + keep_recent\n\n    def _create_context_summary(self, entries: list[dict], summary_type: str) -&gt; str:\n        \"\"\"Create intelligent context summary\"\"\"\n        if not entries:\n            return \"No context to summarize\"\n\n        summary_parts = []\n\n        # Group by type\n        by_type = {}\n        for entry in entries:\n            entry_type = entry.get(\"type\", \"unknown\")\n            if entry_type not in by_type:\n                by_type[entry_type] = []\n            by_type[entry_type].append(entry)\n\n        # Summarize each type\n        for entry_type, type_entries in by_type.items():\n            if entry_type == \"reasoning\":\n                reasoning_summary = f\"Completed {len(type_entries)} reasoning cycles\"\n                # Extract key insights\n                insights = []\n                for entry in type_entries[-3:]:  # Last 3 reasoning entries\n                    content = entry.get(\"content\", \"\")[:1000] + \"...\"\n                    insights.append(content)\n                if insights:\n                    reasoning_summary += f\"\\nKey recent reasoning: {'; '.join(insights)}\"\n                summary_parts.append(reasoning_summary)\n\n            elif entry_type == \"meta_tool_result\":\n                results_summary = f\"Executed {len(type_entries)} meta-tool operations\"\n                # Extract significant results\n                significant_results = [\n                    entry.get(\"content\", \"\")[:800]\n                    for entry in type_entries\n                    if len(entry.get(\"content\", \"\")) &gt; 50\n                ]\n                if significant_results:\n                    results_summary += f\"\\nSignificant results: {'; '.join(significant_results[-3:])}\"\n                summary_parts.append(results_summary)\n\n            else:\n                summary_parts.append(f\"{entry_type}: {len(type_entries)} entries\")\n\n        summary = f\"[{summary_type.upper()} SUMMARY] \" + \"; \".join(summary_parts)\n\n        # Store summary in variables for future reference\n        if self.variable_manager:\n            summary_data = {\n                \"type\": summary_type,\n                \"entries_summarized\": len(entries),\n                \"summary\": summary,\n                \"timestamp\": datetime.now().isoformat()\n            }\n            summaries = self.variable_manager.get(\"reasoning.context_summaries\", [])\n            summaries.append(summary_data)\n            self.variable_manager.set(\"reasoning.context_summaries\", summaries[-10:])  # Keep last 10\n\n        return summary\n\n    def _get_pending_tasks_summary(self) -&gt; str:\n        \"\"\"Get summary of pending tasks requiring attention\"\"\"\n        if not self.internal_task_stack:\n            return \"\u26a0\ufe0f NO TASKS IN STACK - You must create tasks from your outline immediately!\"\n\n        pending_tasks = [task for task in self.internal_task_stack if task.get(\"status\", \"pending\") == \"pending\"]\n\n        if not pending_tasks:\n            return \"\u2705 No pending tasks - ready for next outline step or completion\"\n\n        task_summaries = []\n        for i, task in enumerate(pending_tasks[:3], 1):\n            desc = task.get(\"description\", \"No description\")[:150] + \"...\" if len(\n                task.get(\"description\", \"\")) &gt; 50 else task.get(\"description\", \"\")\n            step_ref = task.get(\"outline_step_ref\", \"\")\n            step_info = f\" ({step_ref})\" if step_ref else \"\"\n            task_summaries.append(f\"{i}. {desc}{step_info}\")\n\n        if len(pending_tasks) &gt; 3:\n            task_summaries.append(f\"... +{len(pending_tasks) - 3} more pending tasks\")\n\n        return f\"\ud83d\udccb {len(pending_tasks)} pending tasks:\\n\" + \"\\n\".join(task_summaries)\n\n    async def _build_outline_driven_prompt(self, prep_res) -&gt; str:\n        \"\"\"Build outline-driven reasoning prompt mit UnifiedContextManager Integration\"\"\"\n\n        # Get current task with enhanced visibility\n        current_stack_task = self._get_current_stack_task()\n\n        #Enhanced context aus UnifiedContextManager\n        context_manager = prep_res.get(\"context_manager\")\n        session_id = prep_res.get(\"session_id\", \"default\")\n\n        # Build unified context sections\n        unified_context_summary = \"\"\n        recent_results_context = \"\"\n\n        if context_manager:\n            try:\n                # Get full unified context\n                unified_context = await  context_manager.build_unified_context(session_id, prep_res.get('original_query'))\n\n                unified_context_summary = self._format_unified_context_for_reasoning(unified_context)\n                recent_results_context = self._build_recent_results_from_unified_context(unified_context)\n            except Exception as e:\n                eprint(f\"Failed to get unified context in reasoning prompt: {e}\")\n                unified_context_summary = \"Unified context unavailable\"\n                recent_results_context = \"**No recent results available**\"\n\n        # Enhanced context summaries (keeping existing functionality)\n        context_summary = self._summarize_reasoning_context()\n        task_stack_summary = self._summarize_task_stack()\n        outline_status = self._get_current_step_requirements()\n        performance_context = self._get_performance_context()\n\n        # Enhanced variable system integration with better suggestions\n        variable_context = \"\"\n        variable_suggestions = []\n        if self.variable_manager:\n            variable_context = self.variable_manager.get_llm_variable_context()\n            query_text = prep_res.get('original_query', '')\n            if current_stack_task:\n                query_text += \" \" + current_stack_task.get('description', '')\n            variable_suggestions = self.variable_manager.get_variable_suggestions(query_text)\n\n        immediate_context = self._get_immediate_context_for_prompt()\n        # Detect if we're in a potential loop situation\n        loop_warning = self._generate_loop_warning()\n\n        prompt = f\"\"\"You are the enhanced strategic reasoning core operating in OUTLINE-DRIVEN MODE with MANDATORY TASK STACK enforcement.\n## ABSOLUTE REQUIREMENTS - VIOLATION = IMMEDIATE STOP:\n1. **WORK ONLY THROUGH TASK STACK** - No work outside the stack permitted\n2. **SEE CURRENT TASK DIRECTLY** - Your current task is shown below\n3. **USE VARIABLE SYSTEM** - All results are automatically stored and accessible\n4. **USE UNIFIED CONTEXT** - Rich conversation and execution history is available\n5. **MARK TASKS COMPLETE** - Every finished task must be marked complete\n6. **NO REPEATED ACTIONS** - Check variables first before re-doing work\n\n{loop_warning}\n\n## &lt;CURRENT SITUATION&gt;:\n**Original Query:** {prep_res['original_query']}\n\n**Unified Context Summary:**\n{unified_context_summary}\n\n**Current Context Summary:**\n{context_summary}\n\n**Current Outline Status:**\n{outline_status}\n\n** CURRENT TASK FROM STACK:**\n{current_stack_task}\n\n**Internal Task Stack:**\n{task_stack_summary}\n\n**Performance Metrics:**\n{performance_context}\n\n## ENHANCED CONTEXT INTEGRATION:\n{variable_context}\n\n** SUGGESTED VARIABLES for current task:**\n{', '.join(variable_suggestions[:10]) if variable_suggestions else 'tool_capabilities, query, model_complex, available_tools, timestamp, use_fast_response, tool_registry, name, current_query, current_session'}\n\n** UNIFIED CONTEXT RESULTS ACCESS:**\n{recent_results_context}\n\n&lt;/CURRENT SITUATION&gt;\n\n## MANDATORY TASK STACK ENFORCEMENT:\n**CRITICAL RULE**: You MUST work exclusively through your internal task stack.\n\n**TASK STACK WORKFLOW (MANDATORY):**\n1. **CHECK CURRENT TASK**: Your current task is: {current_stack_task.get('description', 'NO CURRENT TASK - ADD TASKS FROM OUTLINE!') if current_stack_task else 'NO CURRENT TASK - VIOLATION!'}\n\n2. **WORK ONLY ON STACK TASKS**: You can ONLY work on tasks that exist in your internal task stack\n   - The task you're working on MUST be in the stack with status \"pending\"\n   - Before any action: Verify the task exists in your stack\n\n3. **MANDATORY TASK COMPLETION**: After completing any work, you MUST mark the task as complete\n   - Use: META_TOOL_CALL: manage_internal_task_stack(action=\"complete\", task_description=\"[exact task description]\", outline_step_ref=\"step_X\")\n\n4. **CHECK UNIFIED CONTEXT FIRST**: Before any major action, focus your attention to the variable system to see if results already exist\n   - Avalabel results are automatically stored in the variable system\n   - The unified context above shows available conversation history and execution state\n\n**CURRENT TASK ANALYSIS:**\n{self._analyze_current_task(current_stack_task) if current_stack_task else \"\u274c NO CURRENT TASK - You must add tasks from your outline!\"}\n\n## AVAILABLE META-TOOLS:\nYou have access to these meta-tools to control sub-systems. Use the EXACT syntax shown:\n\n**META_TOOL_CALL: internal_reasoning(thought: str, thought_number: int, total_thoughts: int, next_thought_needed: bool, current_focus: str, key_insights: list[str], potential_issues: list[str], confidence_level: float)**\n- Purpose: Structure your thinking process explicitly\n- Use for: Any complex analysis, planning, or problem decomposition\n- Example: META_TOOL_CALL: internal_reasoning(thought=\"I need to break this down into steps\", thought_number=1, total_thoughts=3, next_thought_needed=true, current_focus=\"problem analysis\", key_insights=[\"Query requires multiple data sources\"], potential_issues=[\"Data might not be available\"], confidence_level=0.8)\n\n**META_TOOL_CALL: manage_internal_task_stack(action: str, task_description: str)**\n- Purpose: Manage your high-level to-do list\n- Actions: \"add\", \"remove\", \"complete\", \"get_current\"\n- Example: META_TOOL_CALL: manage_internal_task_stack(action=\"add\", task_description=\"Research competitor analysis data\")\n\n**META_TOOL_CALL: delegate_to_llm_tool_node(task_description: str, tools_list: list[str])**\n- Purpose: Delegate specific, self-contained tasks requiring external tools\n- Use for: Web searches, file operations, API calls, single-, two-, or three-step tool usage\n- Example: META_TOOL_CALL: delegate_to_llm_tool_node(task_description=\"Search for latest news about AI developments\", tools_list=[\"search_web\"])\n- Rule: always validate delegate_to_llm_tool_node result. will be available in &lt;immediate_context&gt; after execution!\n\n**META_TOOL_CALL: create_and_execute_plan(goals: list[str])**\n- Purpose: Handle complex, multi-step projects with dependencies\n- Use for: Tasks requiring coordination, parallel execution, or complex workflows\n- Example: META_TOOL_CALL: create_and_execute_plan(goals=[\"Research company A financial data\", \"Research company B financial data\", \"Compare {{results.task_1.data}} and {{results.task_2.data}} and create report\"])\n- Rule: always validate create_and_execute_plan result. will be available in &lt;immediate_context&gt; after execution!\n\n**META_TOOL_CALL: read_from_variables(scope: str, key: str, purpose: str)**\n- Unified context data is available in various scopes\n- Example: META_TOOL_CALL: read_from_variables(scope=\"user\", key=\"name\", purpose=\"Gather user information for later reference\")\n\n**META_TOOL_CALL: write_to_variables(scope: str, key: str, value: any, description: str)**\n- Store important findings immediately\n- Example: META_TOOL_CALL: write_to_variables(scope=\"user\", key=\"name\", value=\"User-Name\", description=\"The users name for later reference\")\n\n**META_TOOL_CALL: advance_outline_step(step_completed: bool, completion_evidence: str, next_step_focus: str)**\n- Mark outline steps complete when all related tasks done\n\n**META_TOOL_CALL: direct_response(final_answer: str, outline_completion: bool, steps_completed: list[str])**\n- ONLY when ALL outline steps complete or no META_TOOL_CALL needed\n- final_answer must contain the full final answer for the user with all necessary context and informations ( format in persona style )\n- Purpose: End reasoning and provide final answer to user\n- Use when: Query is complete or can be answered directly\n- Example: META_TOOL_CALL: direct_response(final_answer=\"Based on my analysis, here are the key findings...\")\n\nnote: in this interaction only META_TOOL_CALL ar avalabel. for other tools use META_TOOL_CALL: delegate_to_llm_tool_node with the appropriate tool names!\n\n## REASONING STRATEGY:\n1. **Start with internal_reasoning** to understand the query and plan approach\n2. **Use manage_internal_task_stack** to track high-level steps\n3. **Choose the right delegation strategy:**\n   - Simple queries \u2192 direct_response\n   - Up to 3 tool tasks with llm action \u2192 delegate_to_llm_tool_node\n   - Complex projects \u2192 create_and_execute_plan\n4. **Monitor progress** and adapt your approach\n5. **End with direct_response** when complete\n\n## EXAMPLES OF GOOD REASONING PATTERNS:\n\n**Simple Query Pattern:**\nMETA_TOOL_CALL: internal_reasoning(thought=\"This is a straightforward question I can answer directly\", thought_number=1, total_thoughts=1, next_thought_needed=false, current_focus=\"direct response\", key_insights=[\"No external data needed\"], potential_issues=[], confidence_level=0.9)\nMETA_TOOL_CALL: direct_response(final_answer=\"...\")\n\n**Research Task Pattern:**\nMETA_TOOL_CALL: internal_reasoning(thought=\"I need to gather information from external sources\", ...)\nMETA_TOOL_CALL: manage_internal_task_stack(action=\"add\", task_description=\"Research topic X\")\nMETA_TOOL_CALL: delegate_to_llm_tool_node(task_description=\"Search for information about X\", tools_list=[\"search_web\"])\n[Wait for result]\nMETA_TOOL_CALL: internal_reasoning(thought=\"I have the research data, now I can formulate response\", ...)\nMETA_TOOL_CALL: direct_response(final_answer=\"Based on my research: ...\")\n\n**Complex Project Pattern:**\nMETA_TOOL_CALL: internal_reasoning(thought=\"This requires multiple steps with dependencies\", ...)\nMETA_TOOL_CALL: create_and_execute_plan(goals=[\"Step 1: Gather data A\", \"Step 2: Gather data B\", \"Step 3: Analyze A and B together\", \"Step 4: Create final report\"])\n[Wait for plan completion]\nMETA_TOOL_CALL: direct_response(final_answer=\"I've completed your complex request...\")\n\n## ENHANCED ANTI-LOOP ENFORCEMENT:\n- Current Loop: {self.current_loop_count}/{self.max_reasoning_loops}\n- Auto-Recovery Attempts: {getattr(self, 'auto_recovery_attempts', 0)}/{getattr(self, 'max_auto_recovery', 3)}\n- Last Actions: {', '.join(getattr(self, 'last_action_signatures', [])[-3:]) if hasattr(self, 'last_action_signatures') else 'None'}\n\n**\u26a0\ufe0f LOOP PREVENTION RULES:**\n1. If you just read a variable, DO NOT read the same variable again\n2. If you completed a task, DO NOT repeat the same work\n3. If results exist in unified context, DO NOT recreate them\n4. Always advance to next logical step\n\n{self._get_current_step_requirements()}\n\n## YOUR NEXT ACTION (Choose ONE):\nBased on your current task, unified context, and available variables, what is your next concrete action?\n\n**DECISION TREE:**\n1. \u2753 No current task? \u2192 Add tasks from outline\n2. \ud83d\udcd6 Current task needs data? \u2192 Check variables and unified context first (read_from_variables)\n3. \ud83d\udd27 Need to execute tools and reason over up to 3 steps? \u2192 Use delegate_to_llm_tool_node\n4. \u2705 Task complete? \u2192 Mark complete and advance\n5. \ud83c\udfaf All outline done? \u2192 Provide direct_response\n\nLatest unified context: (note delegation results could be wrong or misleading)\n&lt;immediate_context&gt;\n{immediate_context}\n&lt;/immediate_context&gt;\n\nmust validate &lt;immediate_context&gt; output!\n- validate the &lt;immediate_context&gt; output! before proceeding with the outline!\n- output compleat fail -&gt; direct_response\n- informations missing or output recovery needed -&gt; repeat step with a different strategy\n- not enough structure -&gt; use create_and_execute_plan meta-tool call\n- output is valid -&gt; continue with the outline!\n- if dynamic Planing is needed, you must use the appropriate meta-tool call\n\n**Remember**:\n- work step by step max call 3 meta-tool calls in one run.\n- only use direct_response if the outline is complete and context from &lt;immediate_context&gt; is enough to answer the query!\n- Your job is to work systematically through your outline using your task stack, while leveraging the unified context system to avoid duplicate work and maintain context.\"\"\"\n\n        return prompt\n\n    def _format_unified_context_for_reasoning(self, unified_context: dict[str, Any]) -&gt; str:\n        \"\"\"Format unified context f\u00fcr reasoning prompt\"\"\"\n        try:\n            context_parts = []\n\n            # Session info\n            session_stats = unified_context.get('session_stats', {})\n            context_parts.append(\n                f\"Session: {unified_context.get('session_id', 'unknown')} with {session_stats.get('current_session_length', 0)} messages\")\n\n            # Chat history summary\n            chat_history = unified_context.get('chat_history', [])\n            if chat_history:\n                recent_messages = len([msg for msg in chat_history if msg.get('role') == 'user'])\n                context_parts.append(f\"Conversation: {recent_messages} user queries in current context\")\n\n                # Show last user message for reference\n                last_user_msg = None\n                for msg in reversed(chat_history):\n                    if msg.get('role') == 'user':\n                        last_user_msg = msg.get('content', '')[:100] + \"...\"\n                        break\n                if last_user_msg:\n                    context_parts.append(f\"Latest user query: {last_user_msg}\")\n\n            # Execution state\n            execution_state = unified_context.get('execution_state', {})\n            active_tasks = execution_state.get('active_tasks', [])\n            recent_completions = execution_state.get('recent_completions', [])\n            if active_tasks or recent_completions:\n                context_parts.append(\n                    f\"Execution: {len(active_tasks)} active, {len(recent_completions)} completed tasks\")\n\n            # Available data\n            variables = unified_context.get('variables', {})\n            recent_results = variables.get('recent_results', [])\n            if recent_results:\n                context_parts.append(f\"Available Results: {len(recent_results)} recent task results accessible\")\n\n            return \"\\n\".join(context_parts)\n\n        except Exception as e:\n            return f\"Error formatting unified context: {str(e)}\"\n\n    def _build_recent_results_from_unified_context(self, unified_context: dict[str, Any]) -&gt; str:\n        \"\"\"Build recent results context from unified context\"\"\"\n        try:\n            variables = unified_context.get('variables', {})\n            recent_results = variables.get('recent_results', [])\n\n            if not recent_results:\n                return \"**No recent results available from unified context**\"\n\n            result_context = \"\"\"**\ud83d\udd0d RECENT RESULTS FROM UNIFIED CONTEXT:**\"\"\"\n\n            for i, result in enumerate(recent_results[:3], 1):  # Top 3 results\n                task_id = result.get('task_id', f'result_{i}')\n                preview = result.get('preview', 'No preview')\n                success = result.get('success', False)\n                status_icon = \"\u2705\" if success else \"\u274c\"\n\n                result_context += f\"\\n{status_icon} {task_id}: {preview}\"\n\n            result_context += \"\\n\\n**Quick Access Keys Available:**\"\n            result_context += \"\\n- Use read_from_variables(scope='results', key='task_id.data') for specific results\"\n            result_context += \"\\n- Check delegation.latest for most recent delegation results\"\n\n            return result_context\n\n        except Exception as e:\n            return f\"**Error accessing recent results: {str(e)}**\"\n\n    def _generate_loop_warning(self) -&gt; str:\n        \"\"\"Generate loop warning if repetitive behavior detected\"\"\"\n        if len(self.last_action_signatures) &gt;= 3:\n            recent_actions = self.last_action_signatures[-3:]\n            if len(set(recent_actions)) &lt;= 2:\n                return \"\"\"\n\u26a0\ufe0f **LOOP WARNING DETECTED** \u26a0\ufe0f\nYou are repeating similar actions. MUST change approach:\n- If you just read variables, act on the results\n- If you delegated tasks, check the results\n- Complete current task and advance to next step\n- DO NOT repeat the same meta-tool calls\n    \"\"\"\n        return \"\"\n\n    def _get_current_stack_task(self) -&gt; dict[str, Any]:\n        \"\"\"Get current pending task from stack for direct visibility\"\"\"\n        if not self.internal_task_stack:\n            return {}\n\n        pending_tasks = [task for task in self.internal_task_stack if task.get(\"status\", \"pending\") == \"pending\"]\n        if pending_tasks:\n            current_task = pending_tasks[0]  # Get first pending task\n            return {\n                \"description\": current_task.get(\"description\", \"\"),\n                \"outline_step_ref\": current_task.get(\"outline_step_ref\", \"\"),\n                \"status\": current_task.get(\"status\", \"pending\"),\n                \"added_at\": current_task.get(\"added_at\", \"\"),\n                \"task_index\": self.internal_task_stack.index(current_task) + 1,\n                \"total_tasks\": len(self.internal_task_stack)\n            }\n\n        return {}\n\n    def _analyze_current_task(self, current_task: dict[str, Any]) -&gt; str:\n        \"\"\"Analyze current task and provide guidance\"\"\"\n        if not current_task:\n            return \"\u274c NO CURRENT TASK - Add tasks from your outline immediately!\"\n\n        description = current_task.get(\"description\", \"\")\n        outline_ref = current_task.get(\"outline_step_ref\", \"\")\n\n        analysis = f\"\"\"CURRENT TASK IDENTIFIED:\nTask: {description}\nOutline Reference: {outline_ref}\nPosition: {current_task.get('task_index', '?')}/{current_task.get('total_tasks', '?')}\n\nRECOMMENDED ACTION:\"\"\"\n\n        # Analyze task content for recommendations\n        if \"read\" in description.lower() or \"file\" in description.lower():\n            analysis += \"\\n1. Check if file content already exists in variables (read_from_variables)\"\n            analysis += \"\\n2. If not found, use delegate_to_llm_tool_node with read_file tool\"\n        elif \"write\" in description.lower() or \"create\" in description.lower():\n            analysis += \"\\n1. Check if content is ready in variables\"\n            analysis += \"\\n2. Use delegate_to_llm_tool_node with write_file tool\"\n        elif \"analyze\" in description.lower() or \"question\" in description.lower():\n            analysis += \"\\n1. Read existing data from variables\"\n            analysis += \"\\n2. Process the information and provide direct_response\"\n        else:\n            analysis += \"\\n1. Break down the task into specific actions\"\n            analysis += \"\\n2. Verify last Task Delegation results\"\n\n        return analysis\n\n    def _get_immediate_context_for_prompt(self) -&gt; str:\n        \"\"\"Get immediate context additions from recent meta-tool executions\"\"\"\n        recent_results = [\n            entry for entry in self.reasoning_context[-5:]  # Last 5 entries\n            if entry.get(\"type\") == \"meta_tool_result\"\n        ]\n\n        if not recent_results:\n            return \"No recent meta-tool results\"\n\n        context_parts = [\"\ud83d\udcca IMMEDIATE CONTEXT FROM RECENT ACTIONS:\"]\n\n        for result in recent_results:\n            meta_tool = result.get(\"meta_tool\", \"unknown\")\n            content = result.get(\"content\", \"\")\n            loop = result.get(\"loop\", \"?\")\n\n            # Format based on meta-tool type\n            if meta_tool == \"delegate_to_llm_tool_node\":\n                context_parts.append(f\"\u2705 DELEGATION RESULT (Loop {loop}):\")\n                context_parts.append(f\"   {content}\")\n            elif meta_tool == \"read_from_variables\":\n                context_parts.append(f\"\ud83d\udcd6 VARIABLE READ (Loop {loop}):\")\n                context_parts.append(f\"   {content}\")\n            elif meta_tool == \"manage_internal_task_stack\":\n                context_parts.append(f\"\ud83d\udccb TASK UPDATE (Loop {loop}):\")\n                context_parts.append(f\"   {content}\")\n            else:\n                context_parts.append(f\"\ud83d\udd27 {meta_tool.upper()} (Loop {loop}):\")\n                context_parts.append(f\"   {content}\")\n\n        return \"\\n\".join(context_parts)\n\n    def _summarize_reasoning_context(self) -&gt; str:\n        \"\"\"Enhanced reasoning context summary with immediate result visibility\"\"\"\n        if not self.reasoning_context:\n            return \"No previous reasoning steps\"\n\n        # Separate different types of context entries\n        reasoning_entries = []\n        meta_tool_results = []\n        errors = []\n\n        for entry in self.reasoning_context:\n            entry_type = entry.get(\"type\", \"unknown\")\n\n            if entry_type == \"reasoning\":\n                reasoning_entries.append(entry)\n            elif entry_type == \"meta_tool_result\":\n                meta_tool_results.append(entry)\n            elif entry_type == \"error\":\n                errors.append(entry)\n\n        summary_parts = []\n\n        # Show recent meta-tool results FIRST for immediate visibility\n        if meta_tool_results:\n            summary_parts.append(\"\ud83d\udd0d RECENT RESULTS:\")\n            for result in meta_tool_results[-3:]:  # Last 3 results\n                meta_tool = result.get(\"meta_tool\", \"unknown\")\n                content = result.get(\"content\", \"\")[:3000] + \"...\"\n                loop = result.get(\"loop\", \"?\")\n                summary_parts.append(f\"  [{meta_tool}] Loop {loop}: {content}\")\n\n        # Show reasoning summary\n        if reasoning_entries:\n            summary_parts.append(f\"\\n\ud83d\udcad REASONING: {len(reasoning_entries)} reasoning cycles completed\")\n\n        # Show errors if any\n        if errors:\n            summary_parts.append(f\"\\n\u26a0\ufe0f ERRORS: {len(errors)} errors encountered\")\n            for error in errors[-2:]:  # Last 2 errors\n                content = error.get(\"content\", \"\")[:1500]\n                summary_parts.append(f\"  Error: {content}\")\n\n        return \"\\n\".join(summary_parts)\n\n    def _get_current_step_requirements(self) -&gt; str:\n        \"\"\"Get requirements for current outline step\"\"\"\n        if not self.outline or not self.outline.get(\"steps\"):\n            return \"ERROR: No outline available\"\n\n        steps = self.outline[\"steps\"]\n        if self.current_outline_step &gt;= len(steps):\n            return \"All outline steps completed - must provide final response\"\n\n        current_step = steps[self.current_outline_step]\n\n        requirements = f\"\"\"CURRENT STEP FOCUS:\nDescription: {current_step.get('description', 'Unknown')}\nRequired Method: {current_step.get('method', 'Unknown')}\nExpected Outcome: {current_step.get('expected_outcome', 'Unknown')}\nSuccess Criteria: {current_step.get('success_criteria', 'Unknown')}\nCurrent Status: {current_step.get('status', 'pending')}\n\nYou MUST use the specified method and achieve the expected outcome before advancing.\"\"\"\n\n        return requirements\n\n    def _get_performance_context(self) -&gt; str:\n        \"\"\"Get performance context with accurate metrics\"\"\"\n        if not self.performance_metrics:\n            return \"No performance metrics available\"\n\n        metrics_parts = []\n\n        # Core metrics\n        avg_time = self.performance_metrics.get(\"avg_loop_time\", 0)\n        efficiency = self.performance_metrics.get(\"action_efficiency\", 0)\n        total_loops = self.performance_metrics.get(\"total_loops\", 0)\n        progress_loops = self.performance_metrics.get(\"progress_loops\", 0)\n\n        metrics_parts.append(f\"Avg Loop Time: {avg_time:.2f}s\")\n        metrics_parts.append(f\"Progress Rate: {efficiency:.1%}\")\n        metrics_parts.append(f\"Action Efficiency: {efficiency:.1%}\")\n\n        # Performance warnings\n        if total_loops &gt; 3 and efficiency &lt; 0.5:\n            metrics_parts.append(\"\u26a0\ufe0f LOW EFFICIENCY - Need more progress actions\")\n        elif total_loops &gt; 5 and efficiency &lt; 0.3:\n            metrics_parts.append(\"\ud83d\udd34 VERY LOW EFFICIENCY - Review approach\")\n\n        # Loop detection warning based on actual metrics\n        if len(self.last_action_signatures) &gt; 3:\n            unique_recent = len(set(self.last_action_signatures[-3:]))\n            if unique_recent &lt;= 1:\n                metrics_parts.append(\"\u26a0\ufe0f LOOP PATTERN DETECTED - Change approach required\")\n\n        return \"; \".join(metrics_parts)\n\n    def _track_action_type(self, action_type: str, success: bool = True):\n        \"\"\"Track specific action types for detailed performance analysis\"\"\"\n        if not hasattr(self, 'action_tracking'):\n            self.action_tracking = {}\n\n        if action_type not in self.action_tracking:\n            self.action_tracking[action_type] = {\"total\": 0, \"successful\": 0}\n\n        self.action_tracking[action_type][\"total\"] += 1\n        if success:\n            self.action_tracking[action_type][\"successful\"] += 1\n\n        # Update overall action efficiency based on all action types\n        total_actions = sum(stats[\"total\"] for stats in self.action_tracking.values())\n        successful_actions = sum(stats[\"successful\"] for stats in self.action_tracking.values())\n\n        if total_actions &gt; 0:\n            self.performance_metrics[\"detailed_action_efficiency\"] = successful_actions / total_actions\n\n\n    def _detect_infinite_loop(self) -&gt; bool:\n        \"\"\"Enhanced infinite loop detection with multiple patterns\"\"\"\n        if len(self.last_action_signatures) &lt; 3:\n            return False\n\n        # 1. Immediate repetition (same action 3+ times)\n        recent_actions = self.last_action_signatures[-3:]\n        if len(set(recent_actions)) == 1:\n            return True\n\n        # 2. Pattern repetition (AB-AB-AB pattern)\n        if len(self.last_action_signatures) &gt;= 6:\n            pattern1 = self.last_action_signatures[-6:-3]\n            pattern2 = self.last_action_signatures[-3:]\n            if pattern1 == pattern2:\n                return True\n\n        # 3. Variable read loops (multiple reads of same variable)\n        variable_reads = [sig for sig in self.last_action_signatures if sig.startswith(\"read_from_variables\")]\n        if len(variable_reads) &gt;= 3:\n            # Extract variable signatures from recent reads\n            recent_var_reads = variable_reads[-3:]\n            if len(set(recent_var_reads)) &lt;= 2:  # Repeated variable reads\n                return True\n\n        # 4. No outline progress for extended loops\n        if self.current_loop_count &gt; 5:\n            if not hasattr(self, '_last_step_progress_loop'):\n                self._last_step_progress_loop = {}\n\n            last_progress = self._last_step_progress_loop.get(self.current_outline_step, 0)\n            if self.current_loop_count - last_progress &gt; 4:  # No step progress for 4+ loops\n                return True\n\n        # 5. Same task stack state for multiple loops\n        if hasattr(self, '_task_stack_states'):\n            stack_signature = hash(\n                str([(t.get('status'), t.get('description')[:20]) for t in self.internal_task_stack]))\n            if stack_signature in self._task_stack_states:\n                repetitions = self._task_stack_states[stack_signature]\n                if repetitions &gt;= 4:\n                    return True\n                self._task_stack_states[stack_signature] = repetitions + 1\n            else:\n                self._task_stack_states[stack_signature] = 1\n        else:\n            self._task_stack_states = {}\n\n        return False\n\n    async def _trigger_auto_recovery(self, prep_res):\n        \"\"\"Trigger auto-recovery mechanism\"\"\"\n        self.auto_recovery_attempts += 1\n\n        # Store failure pattern\n        if self.variable_manager:\n            failure_data = {\n                \"timestamp\": datetime.now().isoformat(),\n                \"loop_count\": self.current_loop_count,\n                \"outline_step\": self.current_outline_step,\n                \"last_actions\": self.last_action_signatures[-5:],\n                \"recovery_attempt\": self.auto_recovery_attempts\n            }\n            failures = self.variable_manager.get(\"reasoning.failure_patterns\", [])\n            failures.append(failure_data)\n            self.variable_manager.set(\"reasoning.failure_patterns\", failures[-20:])  # Keep last 20\n\n        # Recovery strategies\n        if self.auto_recovery_attempts == 1:\n            # Force outline step advancement\n            await self._force_outline_advancement(prep_res)\n        elif self.auto_recovery_attempts == 2:\n            # Skip current step and move to next\n            await self._emergency_step_skip(prep_res)\n        else:\n            # Final emergency: force completion\n            await self._emergency_completion(prep_res)\n\n    async def _force_outline_advancement(self, prep_res):\n        \"\"\"Force advancement to next outline step\"\"\"\n        if self.outline and self.current_outline_step &lt; len(self.outline[\"steps\"]):\n            current_step = self.outline[\"steps\"][self.current_outline_step]\n            current_step[\"status\"] = \"force_completed\"\n            current_step[\"completion_method\"] = \"auto_recovery\"\n\n            self.current_outline_step += 1\n\n            # Add to context\n            self.reasoning_context.append({\n                \"type\": \"auto_recovery\",\n                \"content\": f\"Force advanced to step {self.current_outline_step + 1} due to loop detection\",\n                \"recovery_attempt\": self.auto_recovery_attempts,\n                \"timestamp\": datetime.now().isoformat()\n            })\n\n    async def _emergency_step_skip(self, prep_res):\n        \"\"\"Emergency skip of problematic step\"\"\"\n        if self.outline and self.current_outline_step &lt; len(self.outline[\"steps\"]) - 1:\n            current_step = self.outline[\"steps\"][self.current_outline_step]\n            current_step[\"status\"] = \"emergency_skipped\"\n            current_step[\"skip_reason\"] = \"loop_recovery\"\n\n            self.current_outline_step += 1\n\n            # Add to context\n            self.reasoning_context.append({\n                \"type\": \"emergency_skip\",\n                \"content\": f\"Emergency skipped step {self.current_outline_step} and advanced to step {self.current_outline_step + 1}\",\n                \"recovery_attempt\": self.auto_recovery_attempts,\n                \"timestamp\": datetime.now().isoformat()\n            })\n\n    async def _emergency_completion(self, prep_res):\n        \"\"\"Emergency completion of reasoning\"\"\"\n        # Mark all remaining steps as emergency completed\n        if self.outline:\n            for i in range(self.current_outline_step, len(self.outline[\"steps\"])):\n                self.outline[\"steps\"][i][\"status\"] = \"emergency_completed\"\n\n            self.current_outline_step = len(self.outline[\"steps\"])\n\n        # Add to context\n        self.reasoning_context.append({\n            \"type\": \"emergency_completion\",\n            \"content\": \"Emergency completion triggered due to excessive recovery attempts\",\n            \"recovery_attempt\": self.auto_recovery_attempts,\n            \"timestamp\": datetime.now().isoformat()\n        })\n\n    def _update_performance_metrics(self, loop_start_time: float, progress_made: bool):\n        \"\"\"Update performance metrics with accurate action efficiency tracking\"\"\"\n        loop_duration = time.time() - loop_start_time\n\n        # Initialize metrics if needed\n        if not hasattr(self, 'performance_metrics') or not self.performance_metrics:\n            self.performance_metrics = {\n                \"loop_times\": [],\n                \"progress_loops\": 0,\n                \"total_loops\": 0\n            }\n\n        # Update core metrics\n        self.performance_metrics[\"loop_times\"].append(loop_duration)\n        self.performance_metrics[\"total_loops\"] += 1\n\n        if progress_made:\n            self.performance_metrics[\"progress_loops\"] += 1\n\n        # Calculate derived metrics\n        total = self.performance_metrics[\"total_loops\"]\n        progress = self.performance_metrics[\"progress_loops\"]\n\n        self.performance_metrics[\"avg_loop_time\"] = sum(self.performance_metrics[\"loop_times\"]) / len(\n            self.performance_metrics[\"loop_times\"])\n        self.performance_metrics[\"action_efficiency\"] = progress / total if total &gt; 0 else 0.0\n        self.performance_metrics[\"progress_rate\"] = self.performance_metrics[\"action_efficiency\"]  # Same metric\n\n        # Keep only recent loop times for memory efficiency\n        if len(self.performance_metrics[\"loop_times\"]) &gt; 10:\n            self.performance_metrics[\"loop_times\"] = self.performance_metrics[\"loop_times\"][-10:]\n\n    def _add_context_to_reasoning(self, context_addition: str, meta_tool_name: str,\n                                  execution_details: dict = None) -&gt; None:\n        \"\"\"Add context addition to reasoning context for immediate visibility in next LLM prompt\"\"\"\n        if not context_addition:\n            return\n\n        # Create structured context entry\n        context_entry = {\n            \"type\": \"meta_tool_result\",\n            \"content\": context_addition,\n            \"meta_tool\": meta_tool_name,\n            \"loop\": self.current_loop_count,\n            \"outline_step\": getattr(self, 'current_outline_step', 0),\n            \"timestamp\": datetime.now().isoformat()\n        }\n\n        # Add execution details if provided\n        if execution_details:\n            context_entry[\"execution_details\"] = {\n                \"duration\": execution_details.get(\"execution_duration\", 0),\n                \"success\": execution_details.get(\"execution_success\", False),\n                \"tool_category\": execution_details.get(\"tool_category\", \"unknown\")\n            }\n\n        # Add to reasoning context for immediate visibility\n        self.reasoning_context.append(context_entry)\n\n        # Store in variables for persistent access\n        if self.agent_instance:\n            if not self.agent_instance.shared.get(\"system_context\"):\n                self.agent_instance.shared[\"system_context\"] = {}\n            if not self.agent_instance.shared[\"system_context\"].get(\"reasoning_context\"):\n                self.agent_instance.shared[\"system_context\"][\"reasoning_context\"] = {}\n\n            result_key = f\"reasoning.loop_{self.current_loop_count}_{meta_tool_name}\"\n            self.agent_instance.shared[\"system_context\"][\"reasoning_context\"][result_key] = {\n                \"context_addition\": context_addition,\n                \"meta_tool\": meta_tool_name,\n                \"timestamp\": datetime.now().isoformat(),\n                \"loop\": self.current_loop_count\n            }\n\n    async def _parse_and_execute_meta_tools(self, llm_response: str, prep_res: dict) -&gt; dict[str, Any]:\n        \"\"\"Enhanced meta-tool parsing with comprehensive progress tracking\"\"\"\n\n        result = {\n            \"final_result\": None,\n            \"action_taken\": None,\n            \"progress_made\": False,\n            \"context_addition\": None\n        }\n\n        progress_tracker = prep_res.get(\"progress_tracker\")\n        session_id = prep_res.get(\"session_id\")\n\n        # Pattern to match META_TOOL_CALL: tool_name(args...)\n        pattern = r'META_TOOL_CALL:'\n        matches = _extract_meta_tool_calls(llm_response, pattern)\n\n        if not matches and progress_tracker:\n            # No meta-tools found in response\n            await progress_tracker.emit_event(ProgressEvent(\n                event_type=\"meta_tool_analysis\",\n                node_name=\"LLMReasonerNode\",\n                session_id=session_id,\n                status=NodeStatus.COMPLETED,\n                success=True,  # Die Analyse selbst war erfolgreich\n                node_phase=\"analysis_complete\",  # Verwendung des dedizierten Feldes\n                llm_output=llm_response,  # Speichert die vollst\u00e4ndige analysierte Antwort\n                metadata={\n                    \"analysis_result\": \"no_meta_tools_detected\",\n                    \"reasoning_loop\": self.current_loop_count,\n                    \"outline_step\": self.current_outline_step if hasattr(self, 'current_outline_step') else 0,\n                    \"context_size\": len(self.reasoning_context),\n                    \"performance_warning\": len(self.reasoning_context) &gt; 10 and self.current_loop_count &gt; 5\n                }\n            ))\n            result[\"context_addition\"] = \"No action taken - this violates outline-driven execution requirements\"\n            self._add_context_to_reasoning(result[\"context_addition\"], \"invalid\", {})\n\n            return result\n\n        for i, (tool_name, args_str) in enumerate(matches):\n            meta_tool_start = time.perf_counter()\n\n            # Track action signature for loop detection\n            action_signature = f\"{tool_name}:{hash(args_str) % 1000}\"\n            self.last_action_signatures.append(action_signature)\n            if len(self.last_action_signatures) &gt; 10:\n                self.last_action_signatures = self.last_action_signatures[-10:]\n\n            try:\n                # Parse arguments with enhanced error handling\n                args = _parse_tool_args(args_str)\n                if progress_tracker:\n                    await progress_tracker.emit_event(ProgressEvent(\n                        event_type=\"tool_call\",  # Vereinheitlicht auf \"tool_call\"\n                        node_name=\"LLMReasonerNode\",\n                        session_id=session_id,\n                        status=NodeStatus.RUNNING,\n                        tool_name=tool_name,\n                        is_meta_tool=True,  # Klares Flag f\u00fcr Meta-Tools\n                        tool_args=args,\n                        task_id=f\"meta_tool_{tool_name}_{i + 1}\",\n                        metadata={\n                            \"reasoning_loop\": self.current_loop_count,\n                            \"outline_step\": self.current_outline_step if hasattr(self, 'current_outline_step') else 0\n                        }\n                    ))\n                rprint(f\"Parsed args: {args}\")\n\n                # Execute meta-tool with detailed tracking\n                meta_result = None\n                execution_details = {\n                    \"meta_tool_name\": tool_name,\n                    \"parsed_args\": args,\n                    \"execution_success\": False,\n                    \"execution_duration\": 0.0,\n                    \"reasoning_loop\": self.current_loop_count,\n                    \"outline_step\": self.current_outline_step if hasattr(self, 'current_outline_step') else 0,\n                    \"context_before_size\": len(self.reasoning_context),\n                    \"task_stack_before_size\": len(self.internal_task_stack),\n                    \"tool_category\": self._get_tool_category(tool_name),\n                    \"execution_phase\": \"executing\"\n                }\n\n                if tool_name == \"internal_reasoning\":\n                    meta_result = await self._execute_enhanced_internal_reasoning(args, prep_res)\n                    execution_details.update({\n                        \"thought_number\": args.get(\"thought_number\", 1),\n                        \"total_thoughts\": args.get(\"total_thoughts\", 1),\n                        \"current_focus\": args.get(\"current_focus\", \"\"),\n                        \"confidence_level\": args.get(\"confidence_level\", 0.5),\n                        \"key_insights\": args.get(\"key_insights\", []),\n                        \"key_insights_count\": len(args.get(\"key_insights\", [])),\n                        \"potential_issues_count\": len(args.get(\"potential_issues\", [])),\n                        \"next_thought_needed\": args.get(\"next_thought_needed\", False),\n                        \"internal_reasoning_log_size\": len(getattr(self, 'internal_reasoning_log', [])),\n                        \"reasoning_depth\": self._calculate_reasoning_depth(),\n                        \"outline_step_progress\": args.get(\"outline_step_progress\", \"\")\n                    })\n                    result[\"action_taken\"] = False\n\n                elif tool_name == \"manage_internal_task_stack\":\n                    meta_result = await self._execute_enhanced_task_stack(args, prep_res)\n                    execution_details.update({\n                        \"stack_action\": args.get(\"action\", \"unknown\"),\n                        \"task_description\": args.get(\"task_description\", \"\"),\n                        \"outline_step_ref\": args.get(\"outline_step_ref\", \"\"),\n                        \"stack_size_before\": len(self.internal_task_stack),\n                        \"stack_size_after\": 0  # Will be updated below\n                    })\n                    execution_details[\"stack_size_after\"] = len(self.internal_task_stack)\n                    execution_details[\"stack_change\"] = execution_details[\"stack_size_after\"] - execution_details[\n                        \"stack_size_before\"]\n                    result[\"action_taken\"] = True\n\n                elif tool_name == \"delegate_to_llm_tool_node\":\n                    meta_result = await self._execute_enhanced_delegate_llm_tool(args, prep_res)\n                    execution_details.update({\n                        \"delegated_task_description\": args.get(\"task_description\", \"\"),\n                        \"tools_list\": args.get(\"tools_list\", []),\n                        \"tools_count\": len(args.get(\"tools_list\", [])),\n                        \"delegation_target\": \"LLMToolNode\",\n                        \"sub_system_execution\": True,\n                        \"delegation_complexity\": self._assess_delegation_complexity(args),\n                        \"outline_step_completion\": args.get(\"outline_step_completion\", False)\n                    })\n                    result[\"action_taken\"] = True\n                    result[\"progress_made\"] = True\n\n                elif tool_name == \"create_and_execute_plan\":\n                    meta_result = await self._execute_enhanced_create_plan(args, prep_res)\n                    execution_details.update({\n                        \"goals_list\": args.get(\"goals\", []),\n                        \"goals_count\": len(args.get(\"goals\", [])),\n                        \"plan_execution_target\": \"TaskPlanner_TaskExecutor\",\n                        \"sub_system_execution\": True,\n                        \"complex_workflow\": True,\n                        \"estimated_complexity\": self._estimate_plan_complexity(args.get(\"goals\", [])),\n                        \"outline_step_completion\": args.get(\"outline_step_completion\", False)\n                    })\n                    result[\"action_taken\"] = True\n                    result[\"progress_made\"] = True\n\n                elif tool_name == \"advance_outline_step\":\n                    meta_result = await self._execute_advance_outline_step(args, prep_res)\n                    execution_details.update({\n                        \"step_completed\": args.get(\"step_completed\", False),\n                        \"completion_evidence\": args.get(\"completion_evidence\", \"\"),\n                        \"next_step_focus\": args.get(\"next_step_focus\", \"\"),\n                        \"outline_advancement\": True,\n                        \"step_progression\": f\"{self.current_outline_step}/{len(self.outline.get('steps', [])) if self.outline else 0}\"\n                    })\n                    result[\"action_taken\"] = True\n                    result[\"progress_made\"] = True\n\n                elif tool_name == \"write_to_variables\":\n                    meta_result = await self._execute_write_to_variables(args)\n                    execution_details.update({\n                        \"variable_scope\": args.get(\"scope\", \"reasoning\"),\n                        \"variable_key\": args.get(\"key\", \"\"),\n                        \"variable_description\": args.get(\"description\", \"\"),\n                        \"data_persistence\": True,\n                        \"variable_system_operation\": \"write\"\n                    })\n                    result[\"action_taken\"] = True\n\n                elif tool_name == \"read_from_variables\":\n                    meta_result = await self._execute_read_from_variables(args)\n                    execution_details.update({\n                        \"variable_scope\": args.get(\"scope\", \"reasoning\"),\n                        \"variable_key\": args.get(\"key\", \"\"),\n                        \"read_purpose\": args.get(\"purpose\", \"\"),\n                        \"variable_system_operation\": \"read\",\n                        \"data_retrieval\": True\n                    })\n                    result[\"action_taken\"] = True\n\n                elif tool_name == \"direct_response\":\n\n                    final_answer = args.get(\"final_answer\", \"Task completed.\").replace('\\\\n', '\\n').replace('\\\\t', '\\t')\n                    execution_details.update({\n                        \"final_answer\": final_answer,\n                        \"final_answer_length\": len(final_answer),\n                        \"reasoning_complete\": True,\n                        \"flow_termination\": True,\n                        \"reasoning_summary\": self._create_reasoning_summary(),\n                        \"total_reasoning_steps\": len(self.reasoning_context),\n                        \"outline_completion\": True,\n                        \"steps_completed\": args.get(\"steps_completed\", []),\n                        \"session_completion\": True\n                    })\n\n                    completion_context = f\"\u2705 REASONING COMPLETE: {final_answer}\"\n                    self._add_context_to_reasoning(completion_context, tool_name, execution_details)\n\n                    # Store successful completion\n                    await self._store_successful_completion(prep_res, final_answer)\n\n                    if progress_tracker:\n                        meta_tool_duration = time.perf_counter() - meta_tool_start\n                        execution_details[\"execution_duration\"] = meta_tool_duration\n                        execution_details[\"execution_success\"] = True\n\n                        await progress_tracker.emit_event(ProgressEvent(\n                            event_type=\"meta_tool_call\",\n                            timestamp=time.time(),\n                            node_name=\"LLMReasonerNode\",\n                            status=NodeStatus.COMPLETED,\n                            session_id=session_id,\n                            task_id=f\"meta_tool_{tool_name}_{i + 1}\",\n                            node_duration=meta_tool_duration,\n                            success=True,\n                            metadata=execution_details\n                        ))\n\n                    result[\"final_result\"] = final_answer\n                    result[\"action_taken\"] = True\n                    result[\"progress_made\"] = True\n                    return result\n\n                # test if tool name is in agent tools if so try to run it\n                elif tool_name in self.agent_instance.tool_registry:\n                    meta_result = await self.agent_instance.arun_function(tool_name, **args)\n                    result[\"action_taken\"] = True\n                    result[\"progress_made\"] = True\n                    execution_details.update({\n                        \"tool_name\": tool_name,\n                        \"tool_args\": args,\n                        \"tool_result\": meta_result\n                    })\n\n                else:\n                    execution_details.update({\n                        \"error_type\": \"unknown_meta_tool\",\n                        \"error_message\": f\"Unknown meta-tool: {tool_name}\",\n                        \"execution_success\": False,\n                        \"available_meta_tools\": [\"internal_reasoning\", \"manage_internal_task_stack\",\n                                            \"delegate_to_llm_tool_node\", \"create_and_execute_plan\",\n                                            \"advance_outline_step\", \"write_to_variables\", \"read_from_variables\",\n                                            \"direct_response\"]\n                    })\n\n                    if progress_tracker:\n                        meta_tool_duration = time.perf_counter() - meta_tool_start\n                        await progress_tracker.emit_event(ProgressEvent(\n                            event_type=\"meta_tool_call\",\n                            timestamp=time.time(),\n                            node_name=\"LLMReasonerNode\",\n                            status=NodeStatus.FAILED,\n                            session_id=session_id,\n                            task_id=f\"meta_tool_{tool_name}_{i + 1}\",\n                            node_duration=meta_tool_duration,\n                            success=False,\n                            metadata=execution_details\n                        ))\n\n                    error_context = f\"\u274c Unknown meta-tool: {tool_name}\"\n                    self._add_context_to_reasoning(error_context, tool_name, execution_details)\n                    wprint(f\"Unknown meta-tool: {tool_name}\")\n                    continue\n\n                # Update execution details with results\n                meta_tool_duration = time.perf_counter() - meta_tool_start\n                execution_details.update({\n                    \"execution_duration\": meta_tool_duration,\n                    \"execution_success\": True,\n                    \"context_after_size\": len(self.reasoning_context),\n                    \"task_stack_after_size\": len(self.internal_task_stack),\n                    \"performance_score\": self._calculate_tool_performance_score(meta_tool_duration, tool_name),\n                    \"execution_phase\": \"completed\"\n                })\n                self._track_action_type(tool_name, success=True)\n\n                # Add result to context\n                if meta_result and meta_result.get(\"context_addition\"):\n                    result[\"context_addition\"] = meta_result[\"context_addition\"]\n                    execution_details[\"context_addition_length\"] = len(meta_result[\"context_addition\"])\n\n                    self._add_context_to_reasoning(meta_result[\"context_addition\"], tool_name, execution_details)\n\n                # Emit success event\n                if progress_tracker:\n                    await progress_tracker.emit_event(ProgressEvent(\n                        event_type=\"meta_tool_call\",\n                        timestamp=time.time(),\n                        node_name=\"LLMReasonerNode\",\n                        status=NodeStatus.COMPLETED,\n                        session_id=session_id,\n                        task_id=f\"meta_tool_{tool_name}_{i + 1}\",\n                        node_duration=meta_tool_duration,\n                        success=True,\n                        metadata=execution_details\n                    ))\n\n            except Exception as e:\n                meta_tool_duration = time.perf_counter() - meta_tool_start\n                error_details = {\n                    \"meta_tool_name\": tool_name,\n                    \"execution_success\": False,\n                    \"execution_duration\": meta_tool_duration,\n                    \"error_type\": type(e).__name__,\n                    \"error_message\": str(e),\n                    \"reasoning_loop\": self.current_loop_count,\n                    \"outline_step\": self.current_outline_step if hasattr(self, 'current_outline_step') else 0,\n                    \"parsed_args\": args if 'args' in locals() else None,\n                    \"raw_args_string\": args_str,\n                    \"execution_phase\": \"meta_tool_error\",\n                    \"context_size_at_error\": len(self.reasoning_context),\n                    \"task_stack_size_at_error\": len(self.internal_task_stack),\n                    \"tool_category\": self._get_tool_category(tool_name),\n                    \"error_context\": self._get_error_context(e),\n                    \"recovery_recommended\": self.auto_recovery_attempts &lt; getattr(self, 'max_auto_recovery', 3)\n                }\n\n                if progress_tracker:\n                    await progress_tracker.emit_event(ProgressEvent(\n                        event_type=\"meta_tool_call\",\n                        timestamp=time.time(),\n                        node_name=\"LLMReasonerNode\",\n                        status=NodeStatus.FAILED,\n                        session_id=session_id,\n                        task_id=f\"meta_tool_{tool_name}_{i + 1}\",\n                        node_duration=meta_tool_duration,\n                        success=False,\n                        metadata=error_details\n                    ))\n\n                eprint(f\"Meta-tool execution failed for {tool_name}: {e}\")\n                result[\"context_addition\"] = f\"Error executing {tool_name}: {str(e)}\"\n\n                self._add_context_to_reasoning(result[\"context_addition\"], tool_name, execution_details)\n\n        # Final summary event if multiple meta-tools were processed\n        if len(matches) &gt; 1 and progress_tracker:\n            batch_performance = self._calculate_batch_performance(matches)\n            reasoning_progress = self._assess_reasoning_progress()\n\n            await progress_tracker.emit_event(ProgressEvent(\n                event_type=\"meta_tool_batch_complete\",\n                timestamp=time.time(),\n                node_name=\"LLMReasonerNode\",\n                status=NodeStatus.COMPLETED,\n                session_id=session_id,\n                metadata={\n                    \"total_meta_tools_processed\": len(matches),\n                    \"reasoning_loop\": self.current_loop_count,\n                    \"outline_step\": self.current_outline_step if hasattr(self, 'current_outline_step') else 0,\n                    \"batch_execution_complete\": True,\n                    \"final_context_size\": len(self.reasoning_context),\n                    \"final_task_stack_size\": len(self.internal_task_stack),\n                    \"meta_tools_executed\": [match[0] for match in matches],\n                    \"execution_phase\": \"meta_tool_batch_summary\",\n                    \"batch_performance\": batch_performance,\n                    \"reasoning_progress\": reasoning_progress,\n                    \"progress_made\": result[\"progress_made\"],\n                    \"action_taken\": result[\"action_taken\"],\n                    \"outline_status\": {\n                        \"current_step\": self.current_outline_step if hasattr(self, 'current_outline_step') else 0,\n                        \"total_steps\": len(self.outline.get('steps', [])) if self.outline else 0,\n                        \"completion_ratio\": (\n                                self.current_outline_step / len(self.outline.get('steps', [1]))) if self.outline else 0\n                    },\n                    \"performance_summary\": {\n                        \"loop_efficiency\": self.performance_metrics.get(\"action_efficiency\", 0) if hasattr(self,\n                                                                                                           'performance_metrics') else 0,\n                        \"recovery_attempts\": getattr(self, 'auto_recovery_attempts', 0),\n                        \"context_management_active\": len(self.reasoning_context) &gt;= getattr(self,\n                                                                                            'context_summary_threshold',\n                                                                                            15)\n                    }\n                }\n            ))\n\n        return result\n\n    async def _execute_enhanced_internal_reasoning(self, args: dict, prep_res: dict) -&gt; dict[str, Any]:\n        \"\"\"Enhanced internal reasoning with outline step tracking\"\"\"\n        # Standard internal reasoning execution\n        result = await self._execute_internal_reasoning(args, prep_res)\n\n        # Enhanced with outline step progress\n        outline_step_progress = args.get(\"outline_step_progress\", \"\")\n        if outline_step_progress and result:\n            result[\"context_addition\"] += f\"\\nOutline Step Progress: {outline_step_progress}\"\n\n        # Track reasoning depth for current step\n        if not hasattr(self, '_step_reasoning_depth'):\n            self._step_reasoning_depth = {}\n\n        current_step = self.current_outline_step\n        self._step_reasoning_depth[current_step] = self._step_reasoning_depth.get(current_step, 0) + 1\n\n        # Warn if too much reasoning without action\n        if self._step_reasoning_depth[current_step] &gt; 3:\n            result[\"context_addition\"] += \"\\n\u26a0\ufe0f WARNING: Too much reasoning without concrete action for current step\"\n\n        return result\n\n    async def _execute_enhanced_task_stack(self, args: dict, prep_res: dict) -&gt; dict[str, Any]:\n        \"\"\"Enhanced task stack management with outline step tracking\"\"\"\n        # Get outline step reference\n        outline_step_ref = args.get(\"outline_step_ref\", f\"step_{self.current_outline_step}\")\n\n        # Execute standard task stack management\n        result = await self._execute_manage_task_stack(args, prep_res)\n\n        # Enhanced with outline step reference\n        if result:\n            result[\"context_addition\"] += f\"\\n[Linked to: {outline_step_ref}]\"\n\n        return result\n\n    async def _execute_enhanced_delegate_llm_tool(self, args: dict, prep_res: dict) -&gt; dict[str, Any]:\n        \"\"\"Enhanced delegation with immediate result visibility and guaranteed storage\"\"\"\n        task_description = args.get(\"task_description\", \"\")\n        tools_list = args.get(\"tools_list\", [])\n        outline_step_completion = args.get(\"outline_step_completion\", False)\n\n        # Generate unique delegation ID for this execution\n        delegation_id = f\"delegation_loop_{self.current_loop_count}\"\n\n        # Prepare shared state for LLMToolNode with enhanced result capture\n        llm_tool_shared = {\n            \"current_task_description\": task_description,\n            \"current_query\": task_description,\n            \"formatted_context\": {\n                \"recent_interaction\": f\"Reasoner delegating task: {task_description}\",\n                \"session_summary\": self._get_reasoning_summary(),\n                \"task_context\": f\"Loop {self.current_loop_count} delegation - CAPTURE ALL RESULTS\"\n            },\n            \"variable_manager\": prep_res.get(\"variable_manager\"),\n            \"agent_instance\": prep_res.get(\"agent_instance\"),\n            \"available_tools\": tools_list,\n            \"tool_capabilities\": prep_res.get(\"tool_capabilities\", {}),\n            \"fast_llm_model\": prep_res.get(\"fast_llm_model\"),\n            \"complex_llm_model\": prep_res.get(\"complex_llm_model\"),\n            \"progress_tracker\": prep_res.get(\"progress_tracker\"),\n            \"session_id\": prep_res.get(\"session_id\"),\n            \"use_fast_response\": True\n        }\n\n        try:\n            # Execute LLMToolNode\n            llm_tool_node = LLMToolNode()\n            await llm_tool_node.run_async(llm_tool_shared)\n\n            # IMMEDIATE RESULT EXTRACTION - Critical for visibility\n            final_response = llm_tool_shared.get(\"current_response\", \"No response captured\")\n            tool_calls_made = llm_tool_shared.get(\"tool_calls_made\", 0)\n            tool_results = llm_tool_shared.get(\"results\", {})\n\n            # GUARANTEED STORAGE - Multiple storage patterns for reliability\n            delegation_result = {\n                \"task_description\": task_description,\n                \"tools_used\": tools_list,\n                \"tool_calls_made\": tool_calls_made,\n                \"final_response\": final_response,\n                \"results\": tool_results,\n                \"timestamp\": datetime.now().isoformat(),\n                \"delegation_id\": delegation_id,\n                \"outline_step\": self.current_outline_step,\n                \"reasoning_loop\": self.current_loop_count,\n                \"success\": True\n            }\n\n            # CRITICAL: Store immediately with multiple access patterns\n            if self.variable_manager:\n                # 1. Primary delegation storage\n                self.variable_manager.set(f\"delegation.loop_{self.current_loop_count}\", delegation_result)\n\n                # 2. Latest results quick access\n                self.variable_manager.set(\"delegation.latest\", delegation_result)\n\n                # 3. Store individual tool results with direct access\n                for result_id, result_data in tool_results.items():\n                    self.variable_manager.set(f\"results.{result_id}.data\", result_data.get(\"data\"))\n\n                # 4. Create smart access keys for common patterns\n                if \"read_file\" in tools_list and tool_results:\n                    file_content = next((res.get(\"data\") for res in tool_results.values()\n                                         if res.get(\"data\") and isinstance(res.get(\"data\"), str)), None)\n                    if file_content:\n                        self.variable_manager.set(\"var.file_content\", file_content)\n                        self.variable_manager.set(\"latest_file_content\", file_content)\n\n                # 5. Update delegation index for discovery\n                index = self.variable_manager.get(\"delegation.index\", [])\n                index.append({\n                    \"loop\": self.current_loop_count,\n                    \"task\": task_description[:100],\n                    \"tools\": tools_list,\n                    \"timestamp\": datetime.now().isoformat(),\n                    \"results_available\": len(tool_results) &gt; 0\n                })\n                self.variable_manager.set(\"delegation.index\", index[-20:])\n\n            # Create comprehensive context addition with IMMEDIATE VISIBILITY\n            context_addition = f\"\"\"DELEGATION COMPLETED (Loop {self.current_loop_count}):\nTask: {task_description}\nTools: {', '.join(tools_list)}\nCalls Made: {tool_calls_made}\nResults Captured: {len(tool_results)} items\n\nFINAL RESULT: {final_response}\n\n- reference variable: delegation.loop_{self.current_loop_count}\nDELEGATION END\n\"\"\"\n\n            # Mark outline step completion if specified\n            if outline_step_completion:\n                await self._mark_step_completion(prep_res, \"delegation_complete\", context_addition)\n\n            return {\"context_addition\": context_addition}\n\n        except Exception as e:\n            error_msg = f\"\u274c DELEGATION FAILED: {str(e)}\"\n            # Store error for debugging\n            if self.variable_manager:\n                error_data = {\n                    \"task\": task_description,\n                    \"error\": str(e),\n                    \"timestamp\": datetime.now().isoformat(),\n                    \"loop\": self.current_loop_count\n                }\n                self.variable_manager.set(f\"delegation.error.loop_{self.current_loop_count}\", error_data)\n\n            return {\"context_addition\": error_msg}\n\n    async def _execute_enhanced_create_plan(self, args: dict, prep_res: dict) -&gt; dict[str, Any]:\n        \"\"\"Enhanced plan creation with outline step completion tracking\"\"\"\n        # Check if this completes the outline step\n        outline_step_completion = args.get(\"outline_step_completion\", False)\n\n        # Execute standard plan creation\n        result = await self._execute_create_plan(args, prep_res)\n\n        # Enhanced with step completion tracking\n        if outline_step_completion and result:\n            await self._mark_step_completion(prep_res, \"create_and_execute_plan\", result[\"context_addition\"])\n            result[\"context_addition\"] += f\"\\n\u2713 OUTLINE STEP {self.current_outline_step + 1} COMPLETED\"\n\n        return result\n\n    async def _execute_advance_outline_step(self, args: dict, prep_res: dict) -&gt; dict[str, Any]:\n        \"\"\"Execute outline step advancement\"\"\"\n        step_completed = args.get(\"step_completed\", False)\n        completion_evidence = args.get(\"completion_evidence\", \"\")\n        next_step_focus = args.get(\"next_step_focus\", \"\")\n\n        if not self.outline or not self.outline.get(\"steps\"):\n            return {\"context_addition\": \"Cannot advance: No outline available\"}\n\n        steps = self.outline[\"steps\"]\n\n        if self.current_outline_step &gt;= len(steps):\n            return {\"context_addition\": \"Cannot advance: Already at final step\"}\n\n        if step_completed:\n            # Mark current step as completed\n            if self.current_outline_step &lt; len(steps):\n                current_step = steps[self.current_outline_step]\n                current_step[\"status\"] = \"completed\"\n                current_step[\"completion_evidence\"] = completion_evidence\n                current_step[\"completed_at\"] = datetime.now().isoformat()\n\n            # Advance to next step\n            self.current_outline_step += 1\n\n            # Store advancement in variables\n            if self.variable_manager:\n                advancement_data = {\n                    \"step_completed\": self.current_outline_step,\n                    \"completion_evidence\": completion_evidence,\n                    \"next_step_focus\": next_step_focus,\n                    \"timestamp\": datetime.now().isoformat()\n                }\n                self.variable_manager.set(f\"reasoning.step_completions.{self.current_outline_step - 1}\",\n                                          advancement_data)\n\n            context_addition = f\"\"\"\u2713 STEP {self.current_outline_step} COMPLETED\nEvidence: {completion_evidence}\nAdvanced to Step {self.current_outline_step + 1}/{len(steps)}\"\"\"\n\n            if next_step_focus:\n                context_addition += f\"\\nNext Step Focus: {next_step_focus}\"\n\n            if self.current_outline_step &gt;= len(steps):\n                context_addition += \"\\n\ud83c\udfaf ALL OUTLINE STEPS COMPLETED - Ready for direct_response\"\n\n        else:\n            context_addition = f\"Step {self.current_outline_step + 1} not yet completed - continue working on current step\"\n\n        return {\"context_addition\": context_addition}\n\n    async def _execute_read_from_variables(self, args: dict) -&gt; dict[str, Any]:\n        \"\"\"Enhanced variable reading with intelligent discovery and loop prevention\"\"\"\n        if not self.variable_manager:\n            return {\"context_addition\": \"\u274c Variable system not available\"}\n\n        scope = args.get(\"scope\", args.get(\"query\", \"reasoning\"))\n        key = args.get(\"key\", \"\")\n        purpose = args.get(\"purpose\", \"\")\n\n        # CRITICAL: Check for repeated reads - prevent infinite loops\n        read_signature = f\"{scope}.{key}\"\n        if not hasattr(self, '_variable_read_history'):\n            self._variable_read_history = []\n\n        # Prevent reading same variable multiple times in short succession\n        recent_reads = [r for r in self._variable_read_history if r['signature'] == read_signature]\n        if len(recent_reads) &gt;= 2:\n            self._variable_read_history.append({\n                'signature': read_signature,\n                'timestamp': time.time(),\n                'loop': self.current_loop_count\n            })\n            return {\n                \"context_addition\": f\"\u26a0\ufe0f LOOP PREVENTION: Already read {read_signature} {len(recent_reads)} times. Try different approach or advance to next task.\"\n            }\n\n        # Record this read attempt\n        self._variable_read_history.append({\n            'signature': read_signature,\n            'timestamp': time.time(),\n            'loop': self.current_loop_count\n        })\n\n        # Clean old read history (keep last 10)\n        if len(self._variable_read_history) &gt; 10:\n            self._variable_read_history = self._variable_read_history[-10:]\n\n        if not key:\n            return {\"context_addition\": \"\u274c Cannot read: No key provided\"}\n\n        try:\n            # Smart key resolution for common patterns\n            resolved_key = self._resolve_smart_key(scope, key)\n\n            # Try direct access first\n            value = self.variable_manager.get(resolved_key)\n\n            if value is not None:\n                # Format value for display\n                value_display = self._format_variable_value(value)\n\n                context_addition = f\"\"\"{resolved_key}={value_display}\nAccess: Successfully retrieved from variable system\"\"\"\n\n                return {\"context_addition\": context_addition}\n\n            else:\n                # Enhanced discovery when not found\n                discovery_result = self._perform_smart_variable_discovery(scope, key, purpose)\n                return {\"context_addition\": discovery_result}\n\n        except Exception as e:\n            return {\"context_addition\": f\"\u274c Variable read error: {str(e)}\"}\n\n    def _resolve_smart_key(self, scope: str, key: str) -&gt; str:\n        \"\"\"Resolve smart key patterns for common access cases\"\"\"\n        # Handle delegation results specially\n        if scope == \"delegation\" and \"loop_\" in key:\n            return f\"delegation.{key}\"\n        elif scope == \"results\" and key.endswith(\".data\"):\n            return f\"results.{key}\"\n        elif scope == \"var\" or key.startswith(\"var.\"):\n            return key if key.startswith(\"var.\") else f\"var.{key}\"\n        else:\n            return f\"{scope}.{key}\" if scope != \"reasoning\" else f\"reasoning.{key}\"\n\n    def _format_variable_value(self, value: any) -&gt; str:\n        \"\"\"Format variable value for display with intelligent truncation\"\"\"\n        if isinstance(value, dict | list):\n            value_str = json.dumps(value, default=str, indent=2)\n        else:\n            value_str = str(value)\n\n        # Smart truncation based on content type\n        if len(value_str) &gt; 200000:\n            if isinstance(value, dict) and \"results\" in str(value):\n                # For result dicts, show structure\n                return f\"RESULTS DICT ({len(value)} keys):\\n\" + value_str[:150000] + \"\\n... [TRUNCATED]\"\n            elif isinstance(value, str) and (value.startswith(\"# \") or \"markdown\" in value.lower()):\n                # For file content, show beginning\n                return f\"FILE CONTENT ({len(value_str)} chars):\\n\" + value_str[:100000] + \"\\n... [FULL CONTENT AVAILABLE]\"\n            else:\n                return value_str[:100000] + f\"\\n... [TRUNCATED - {len(value_str)} total chars]\"\n\n        return value_str\n\n    def _perform_smart_variable_discovery(self, scope: str, key: str, purpose: str) -&gt; str:\n        \"\"\"Perform intelligent variable discovery when key not found\"\"\"\n        # Check latest delegation results first\n        latest = self.variable_manager.get(\"delegation.latest\")\n        if latest:\n            discovery_msg = f\"\u274c Variable not found: {scope}.{key}\\n\\n\u2728 LATEST DELEGATION RESULTS AVAILABLE:\"\n            discovery_msg += f\"\\nTask: {latest.get('task_description', 'Unknown')[:100]}\"\n            discovery_msg += f\"\\nResults: {len(latest.get('results', {}))} items available\"\n            discovery_msg += \"\\nAccess with: delegation.latest\"\n\n            # Show actual keys available\n            if latest.get('results'):\n                discovery_msg += \"\\n\\n\ud83d\udd0d Available result keys:\"\n                for result_id in latest['results']:\n                    discovery_msg += f\"\\n\u2022 results.{result_id}.data\"\n\n            return discovery_msg\n\n        # Check delegation index for recent activity\n        index = self.variable_manager.get(\"delegation.index\", [])\n        if index:\n            recent = index[-3:]  # Last 3 delegations\n            discovery_msg = f\"\u274c Variable not found: {scope}.{key}\\n\\n\ud83d\udcda RECENT DELEGATIONS:\"\n            for entry in recent:\n                discovery_msg += f\"\\n\u2022 Loop {entry['loop']}: {entry['task'][:50]}...\"\n                discovery_msg += f\"  Access: delegation.loop_{entry['loop']}\"\n            return discovery_msg\n\n        # Fallback: show available scopes\n        available_vars = self.variable_manager.get_available_variables()\n        return f\"\u274c Variable not found: {scope}.{key}\\n\\n\ud83d\udccb Available scopes: {', '.join(available_vars.keys())}\"\n\n\n    async def _execute_write_to_variables(self, args: dict) -&gt; dict[str, Any]:\n        \"\"\"Enhanced variable writing with automatic result storage\"\"\"\n        if not self.variable_manager:\n            return {\"context_addition\": \"\u274c Variable system not available\"}\n\n        scope = args.get(\"scope\", \"reasoning\")\n        key = args.get(\"key\", \"\")\n        value = args.get(\"value\", \"\")\n        description = args.get(\"description\", \"\")\n\n        if not key:\n            return {\"context_addition\": \"\u274c Cannot write to variables: No key provided\"}\n\n        try:\n            # Create scoped key\n            full_key = f\"{scope}.{key}\" if scope != \"reasoning\" else f\"reasoning.{key}\"\n\n            # Write to variables\n            self.variable_manager.set(full_key, value)\n\n            # Store enhanced metadata\n            metadata = {\n                \"description\": description,\n                \"written_at\": datetime.now().isoformat(),\n                \"outline_step\": getattr(self, 'current_outline_step', 0),\n                \"reasoning_loop\": self.current_loop_count,\n                \"value_type\": type(value).__name__,\n                \"value_size\": len(str(value)) if value else 0,\n                \"auto_stored\": False  # Manual storage\n            }\n            self.variable_manager.set(f\"{full_key}_metadata\", metadata)\n\n            # Update storage index for easy discovery\n            storage_index = self.variable_manager.get(\"reasoning.storage_index\", [])\n            storage_entry = {\n                \"key\": full_key,\n                \"description\": description,\n                \"timestamp\": datetime.now().isoformat(),\n                \"loop\": self.current_loop_count\n            }\n            storage_index.append(storage_entry)\n            self.variable_manager.set(\"reasoning.storage_index\", storage_index[-20:])  # Keep last 20\n\n            context_addition = f\"\u2705 Stored in variables: {full_key}\"\n            if description:\n                context_addition += f\"\\n\ud83d\udcc4 Description: {description}\"\n\n            # Show how to access it\n            context_addition += f\"\\n\ud83d\udd0d Access with: read_from_variables(scope=\\\"{scope}\\\", key=\\\"{key}\\\", purpose=\\\"...\\\")\"\n\n            return {\"context_addition\": context_addition}\n\n        except Exception as e:\n            return {\"context_addition\": f\"\u274c Failed to write to variables: {str(e)}\"}\n\n    def _auto_store_delegation_results(self, delegation_result: dict, task_description: str) -&gt; str:\n        \"\"\"Automatically store delegation results with smart naming and comprehensive indexing\"\"\"\n        if not self.variable_manager:\n            return \"\\n\u274c Variable system not available for auto-storage\"\n\n        storage_summary = []\n\n        try:\n            # Store main delegation result with loop reference\n            main_key = f\"delegation.loop_{self.current_loop_count}\"\n            self.variable_manager.set(main_key, delegation_result)\n            storage_summary.append(f\"\u2022 {main_key}\")\n\n            # Store individual tool results with smart naming\n            results = delegation_result.get(\"results\", {})\n            smart_keys_created = []\n\n            for result_id, result_data in results.items():\n                # Smart naming based on task content and result type\n                smart_key = self._generate_smart_key(task_description, result_id, result_data)\n\n                # Store full result\n                self.variable_manager.set(smart_key, result_data)\n                storage_summary.append(f\"\u2022 {smart_key}\")\n                smart_keys_created.append(smart_key)\n\n                # Store data separately for direct access\n                if result_data.get(\"data\"):\n                    data_key = f\"{smart_key}.data\"\n                    self.variable_manager.set(data_key, result_data[\"data\"])\n                    storage_summary.append(f\"\u2022 {data_key} (direct access)\")\n\n                    # Store with generic access pattern\n                    generic_data_key = f\"results.{result_id}.data\"\n                    self.variable_manager.set(generic_data_key, result_data[\"data\"])\n                    storage_summary.append(f\"\u2022 {generic_data_key} (standard access)\")\n\n            # Update comprehensive quick access index\n            quick_access = {\n                \"latest_delegation\": main_key,\n                \"latest_task\": task_description,\n                \"timestamp\": datetime.now().isoformat(),\n                \"loop\": self.current_loop_count,\n                \"outline_step\": getattr(self, 'current_outline_step', 0),\n                \"stored_keys\": [item.replace(\"\u2022 \", \"\") for item in storage_summary],\n                \"smart_keys\": smart_keys_created,\n                \"access_patterns\": {\n                    \"main_result\": main_key,\n                    \"by_loop\": f\"delegation.loop_{self.current_loop_count}\",\n                    \"latest\": \"reasoning.latest_results\",\n                    \"data_direct\": [key for key in storage_summary if \".data\" in key]\n                }\n            }\n            self.variable_manager.set(\"reasoning.latest_results\", quick_access)\n\n            # Update global delegation index for easy discovery\n            delegation_index = self.variable_manager.get(\"delegation.index\", [])\n            index_entry = {\n                \"loop\": self.current_loop_count,\n                \"task\": task_description[:100] + (\"...\" if len(task_description) &gt; 100 else \"\"),\n                \"keys_created\": len(storage_summary),\n                \"timestamp\": datetime.now().isoformat(),\n                \"main_key\": main_key,\n                \"smart_keys\": smart_keys_created\n            }\n            delegation_index.append(index_entry)\n            self.variable_manager.set(\"delegation.index\", delegation_index[-50:])  # Keep last 50\n\n            # Store task-specific quick access\n            task_hash = hash(task_description) % 10000\n            self.variable_manager.set(f\"delegation.by_task.{task_hash}\", {\n                \"task_description\": task_description,\n                \"results\": quick_access,\n                \"created_at\": datetime.now().isoformat()\n            })\n\n            return f\"\\n\ud83d\udcca Auto-stored results ({len(storage_summary)} entries):\\n\" + \"\\n\".join(storage_summary[:8]) + (\n                f\"\\n... +{len(storage_summary) - 8} more\" if len(storage_summary) &gt; 8 else \"\")\n\n        except Exception as e:\n            return f\"\\n\u274c Auto-storage failed: {str(e)}\"\n\n    def _generate_smart_key(self, task_description: str, result_id: str, result_data: dict) -&gt; str:\n        \"\"\"Generate intelligent storage keys based on task content and result type\"\"\"\n        task_lower = task_description.lower()\n\n        # Analyze task type\n        if \"read\" in task_lower and \"file\" in task_lower:\n            prefix = \"file_content\"\n        elif \"write\" in task_lower and \"file\" in task_lower:\n            prefix = \"file_written\"\n        elif \"create\" in task_lower and \"file\" in task_lower:\n            prefix = \"file_created\"\n        elif \"search\" in task_lower or \"find\" in task_lower:\n            prefix = \"search_results\"\n        elif \"analyze\" in task_lower or \"analysis\" in task_lower:\n            prefix = \"analysis_results\"\n        elif \"list\" in task_lower or \"directory\" in task_lower:\n            prefix = \"directory_listing\"\n        elif \"download\" in task_lower or \"fetch\" in task_lower:\n            prefix = \"downloaded_content\"\n        else:\n            # Analyze result data for hints\n            result_str = str(result_data).lower()\n            if \"file\" in result_str and \"content\" in result_str:\n                prefix = \"file_content\"\n            elif \"search\" in result_str or \"results\" in result_str:\n                prefix = \"search_results\"\n            elif \"data\" in result_str:\n                prefix = \"task_data\"\n            else:\n                prefix = \"task_result\"\n\n        # Create unique key with loop and result ID\n        return f\"{prefix}.loop_{self.current_loop_count}_{result_id}\"\n\n    async def _mark_step_completion(self, prep_res: dict, method: str, evidence: str):\n        \"\"\"Mark current outline step as completed\"\"\"\n        if not self.outline or not self.outline.get(\"steps\"):\n            return\n\n        steps = self.outline[\"steps\"]\n        if self.current_outline_step &lt; len(steps):\n            current_step = steps[self.current_outline_step]\n            current_step[\"status\"] = \"completed\"\n            current_step[\"completion_method\"] = method\n            current_step[\"completion_evidence\"] = evidence\n            current_step[\"completed_at\"] = datetime.now().isoformat()\n\n            # Store in variables\n            if self.variable_manager:\n                completion_data = {\n                    \"step_number\": self.current_outline_step,\n                    \"description\": current_step.get(\"description\", \"\"),\n                    \"method\": method,\n                    \"evidence\": evidence,\n                    \"timestamp\": datetime.now().isoformat()\n                }\n                self.variable_manager.set(f\"reasoning.step_completions.{self.current_outline_step}\", completion_data)\n\n    async def _store_successful_completion(self, prep_res: dict, final_answer: str):\n        \"\"\"Store successful completion data for future learning\"\"\"\n        if not self.variable_manager:\n            return\n\n        success_data = {\n            \"query\": prep_res[\"original_query\"],\n            \"final_answer\": final_answer,\n            \"reasoning_loops\": self.current_loop_count,\n            \"outline\": self.outline,\n            \"performance_metrics\": self.performance_metrics,\n            \"auto_recovery_attempts\": self.auto_recovery_attempts,\n            \"completion_timestamp\": datetime.now().isoformat(),\n            \"session_id\": prep_res.get(\"session_id\", \"default\")\n        }\n\n        # Store in successful patterns\n        successes = self.variable_manager.get(\"reasoning.successful_patterns\", [])\n        successes.append(success_data)\n        self.variable_manager.set(\"reasoning.successful_patterns\", successes[-20:])  # Keep last 20\n\n        # Update performance statistics\n        self._update_success_statistics()\n\n    def _update_success_statistics(self):\n        \"\"\"Update success statistics in variables\"\"\"\n        if not self.variable_manager:\n            return\n\n        # Get current stats\n        current_stats = self.variable_manager.get(\"reasoning.performance.statistics\", {})\n\n        # Update stats\n        current_stats[\"total_successful_sessions\"] = current_stats.get(\"total_successful_sessions\", 0) + 1\n        current_stats[\"avg_loops_per_success\"] = current_stats.get(\"avg_loops_per_success\", 0)\n\n        # Calculate new average\n        total_sessions = current_stats[\"total_successful_sessions\"]\n        old_avg = current_stats[\"avg_loops_per_success\"] * (total_sessions - 1)\n        current_stats[\"avg_loops_per_success\"] = (old_avg + self.current_loop_count) / total_sessions\n\n        # Store updated stats\n        self.variable_manager.set(\"reasoning.performance.statistics\", current_stats)\n\n    async def _create_outline_completion_response(self, prep_res: dict) -&gt; str:\n        \"\"\"Create response when outline is completed\"\"\"\n        if not self.outline:\n            return \"Outline completion response requested but no outline available\"\n\n        steps = self.outline.get(\"steps\", [])\n        completed_steps = [s for s in steps if\n                           s.get(\"status\") in [\"completed\", \"force_completed\", \"emergency_completed\"]]\n\n        response_parts = []\n        response_parts.append(\"I have completed the structured approach outlined for your request:\")\n\n        # Summarize completed steps\n        for i, step in enumerate(completed_steps):\n            status_indicator = \"\u2713\" if step.get(\"status\") == \"completed\" else \"\u26a0\ufe0f\"\n            response_parts.append(f\"{status_indicator} Step {i + 1}: {step.get('description', 'Unknown step')}\")\n\n            # Add evidence if available\n            evidence = step.get(\"completion_evidence\", \"\")\n            if evidence and len(evidence) &lt; 200:\n                response_parts.append(f\"   Result: {evidence}\")\n\n        # Get final results from variables if available\n        if self.variable_manager:\n            final_results = self.variable_manager.get(\"reasoning.final_results\", {})\n            if final_results:\n                response_parts.append(\"\\nKey findings:\")\n                for key, value in final_results.items():\n                    if isinstance(value, str) and len(value) &lt; 300:\n                        response_parts.append(f\"- {key}: {value}\")\n\n        response_parts.append(\n            f\"\\nCompleted in {self.current_loop_count} reasoning cycles using outline-driven execution.\")\n\n        return \"\\n\".join(response_parts)\n\n    async def _create_enhanced_timeout_response(self, query: str, prep_res: dict) -&gt; str:\n        \"\"\"Create enhanced timeout response with comprehensive progress summary\"\"\"\n        response_parts = []\n        response_parts.append(\n            f\"I reached my reasoning limit of {self.max_reasoning_loops} steps while working on: {query}\")\n\n        # Outline progress\n        if self.outline:\n            steps = self.outline.get(\"steps\", [])\n            completed_steps = [s for s in steps if\n                               s.get(\"status\") in [\"completed\", \"force_completed\", \"emergency_completed\"]]\n            unfinished_steps = [s for s in steps if s not in completed_steps]\n\n            response_parts.append(f\"\\nOutline Progress: {len(completed_steps)}/{len(steps)} steps completed\")\n\n            if completed_steps:\n                response_parts.append(\"Completed steps:\")\n                for i, step in enumerate(completed_steps):\n                    response_parts.append(f\"\u2713 {step.get('description', f'Step {i + 1}')}\")\n\n            if unfinished_steps:\n                response_parts.append(\"Unfinished steps:\")\n                for i, step in enumerate(unfinished_steps):\n                    response_parts.append(f\"\u2717 {step.get('description', f'Step {i + 1}')}\")\n\n        # Task stack progress\n        if self.internal_task_stack:\n            completed_tasks = [t for t in self.internal_task_stack if t.get(\"status\") == \"completed\"]\n            pending_tasks = [t for t in self.internal_task_stack if t.get(\"status\") == \"pending\"]\n\n            response_parts.append(f\"\\nTask Progress: {len(completed_tasks)} completed, {len(pending_tasks)} pending\")\n\n        # Performance metrics\n        if self.performance_metrics:\n            response_parts.append(\n                f\"\\nPerformance: {self.performance_metrics.get('action_efficiency', 0):.1%} efficiency, {self.auto_recovery_attempts} recovery attempts\")\n\n        # Available results from variables\n        if self.variable_manager:\n            reasoning_results = self.variable_manager.get(\"reasoning\", {})\n            if reasoning_results:\n                response_parts.append(f\"\\nStored findings: {len(reasoning_results)} entries in reasoning variables\")\n\n        return \"\\n\".join(response_parts)\n\n    async def _finalize_reasoning_session(self, prep_res: dict, final_result: str):\n        \"\"\"Finalize reasoning session with comprehensive data storage\"\"\"\n        if not self.variable_manager:\n            return\n\n        # Store session completion data\n        session_data = {\n            \"query\": prep_res[\"original_query\"],\n            \"final_result\": final_result,\n            \"reasoning_loops\": self.current_loop_count,\n            \"outline_completion\": self.current_outline_step,\n            \"performance_metrics\": self.performance_metrics,\n            \"auto_recovery_attempts\": self.auto_recovery_attempts,\n            \"context_summaries\": len([c for c in self.reasoning_context if c.get(\"type\") == \"context_summary\"]),\n            \"completion_timestamp\": datetime.now().isoformat(),\n            \"session_duration\": time.time() - time.mktime(datetime.now().timetuple()),\n            \"success\": True\n        }\n\n        # Store in session history\n        session_history = self.variable_manager.get(\"reasoning.session_history\", [])\n        session_history.append(session_data)\n        self.variable_manager.set(\"reasoning.session_history\", session_history[-50:])  # Keep last 50 sessions\n\n        # Store outline pattern for reuse\n        if self.outline:\n            outline_pattern = {\n                \"query_type\": self._classify_query_type(prep_res[\"original_query\"]),\n                \"outline\": self.outline,\n                \"success\": True,\n                \"loops_used\": self.current_loop_count,\n                \"timestamp\": datetime.now().isoformat()\n            }\n            patterns = self.variable_manager.get(\"reasoning.successful_patterns.outlines\", [])\n            patterns.append(outline_pattern)\n            self.variable_manager.set(\"reasoning.successful_patterns.outlines\", patterns[-10:])\n\n    def _classify_query_type(self, query: str) -&gt; str:\n        \"\"\"Classify query type for pattern matching\"\"\"\n        query_lower = query.lower()\n\n        if any(word in query_lower for word in [\"search\", \"find\", \"look up\", \"research\"]):\n            return \"research\"\n        elif any(word in query_lower for word in [\"analyze\", \"compare\", \"evaluate\"]):\n            return \"analysis\"\n        elif any(word in query_lower for word in [\"create\", \"generate\", \"write\", \"build\"]):\n            return \"creation\"\n        elif any(word in query_lower for word in [\"plan\", \"strategy\", \"approach\"]):\n            return \"planning\"\n        else:\n            return \"general\"\n\n    async def _handle_reasoning_error(self, error: Exception, prep_res: dict, progress_tracker):\n        \"\"\"Enhanced error handling with auto-recovery\"\"\"\n        eprint(f\"Reasoning loop {self.current_loop_count} failed: {error}\")\n\n        # Store error in context\n        self.reasoning_context.append({\n            \"type\": \"error\",\n            \"content\": f\"Error in loop {self.current_loop_count}: {str(error)}\",\n            \"error_type\": type(error).__name__,\n            \"outline_step\": self.current_outline_step,\n            \"timestamp\": datetime.now().isoformat()\n        })\n\n        # Store in variables for learning\n        if self.variable_manager:\n            error_data = {\n                \"error\": str(error),\n                \"error_type\": type(error).__name__,\n                \"loop\": self.current_loop_count,\n                \"outline_step\": self.current_outline_step,\n                \"timestamp\": datetime.now().isoformat(),\n                \"query\": prep_res[\"original_query\"]\n            }\n            errors = self.variable_manager.get(\"reasoning.error_log\", [])\n            errors.append(error_data)\n            self.variable_manager.set(\"reasoning.error_log\", errors[-100:])  # Keep last 100 errors\n\n        # Trigger auto-recovery if not already in recovery\n        if self.auto_recovery_attempts &lt; self.max_auto_recovery:\n            await self._trigger_auto_recovery(prep_res)\n\n    # Keep all existing helper methods like _execute_internal_reasoning, etc.\n    # but update them to use the enhanced variable system...\n\n    async def post_async(self, shared, prep_res, exec_res):\n        \"\"\"Enhanced post-processing with comprehensive data storage\"\"\"\n        final_result = exec_res.get(\"final_result\", \"Task processing incomplete\")\n\n        # Store comprehensive reasoning artifacts\n        shared[\"reasoning_artifacts\"] = {\n            \"reasoning_loops\": exec_res.get(\"reasoning_loops\", 0),\n            \"reasoning_context\": exec_res.get(\"reasoning_context\", []),\n            \"internal_task_stack\": exec_res.get(\"internal_task_stack\", []),\n            \"outline\": exec_res.get(\"outline\"),\n            \"outline_completion\": exec_res.get(\"outline_completion\", 0),\n            \"performance_metrics\": exec_res.get(\"performance_metrics\", {}),\n            \"auto_recovery_attempts\": exec_res.get(\"auto_recovery_attempts\", 0)\n        }\n\n        # Enhanced variable system updates\n        if self.variable_manager:\n            # Store final session results\n            final_session_data = {\n                \"final_result\": final_result,\n                \"completion_timestamp\": datetime.now().isoformat(),\n                \"total_loops\": exec_res.get(\"reasoning_loops\", 0),\n                \"session_success\": final_result != \"Task processing incomplete\",\n                \"outline_driven_execution\": True\n            }\n            self.variable_manager.set(\"reasoning.current_session.final_data\", final_session_data)\n\n            # Update global performance statistics\n            self._update_global_performance_stats(exec_res)\n\n        # Set enhanced response data\n        shared[\"llm_reasoner_result\"] = final_result\n        shared[\"current_response\"] = final_result\n\n        # Provide enhanced synthesis metadata\n        shared[\"synthesized_response\"] = {\n            \"synthesized_response\": final_result,\n            \"confidence\": self._calculate_confidence(exec_res),\n            \"metadata\": {\n                \"synthesis_method\": \"outline_driven_reasoner\",\n                \"reasoning_loops\": exec_res.get(\"reasoning_loops\", 0),\n                \"outline_completion\": exec_res.get(\"outline_completion\", 0),\n                \"performance_score\": self._calculate_performance_score(exec_res),\n                \"auto_recovery_used\": exec_res.get(\"auto_recovery_attempts\", 0) &gt; 0\n            }\n        }\n\n        return \"reasoner_complete\"\n\n    def _update_global_performance_stats(self, exec_res: dict):\n        \"\"\"Update global performance statistics in variables\"\"\"\n        if not self.variable_manager:\n            return\n\n        stats = self.variable_manager.get(\"reasoning.global_performance\", {})\n\n        # Update counters\n        stats[\"total_sessions\"] = stats.get(\"total_sessions\", 0) + 1\n        stats[\"total_loops\"] = stats.get(\"total_loops\", 0) + exec_res.get(\"reasoning_loops\", 0)\n        stats[\"total_recoveries\"] = stats.get(\"total_recoveries\", 0) + exec_res.get(\"auto_recovery_attempts\", 0)\n\n        # Calculate averages\n        stats[\"avg_loops_per_session\"] = stats[\"total_loops\"] / stats[\"total_sessions\"]\n        stats[\"recovery_rate\"] = stats[\"total_recoveries\"] / stats[\"total_sessions\"]\n\n        # Success tracking\n        if exec_res.get(\"final_result\") != \"Task processing incomplete\":\n            stats[\"successful_sessions\"] = stats.get(\"successful_sessions\", 0) + 1\n            stats[\"success_rate\"] = stats[\"successful_sessions\"] / stats[\"total_sessions\"]\n\n        self.variable_manager.set(\"reasoning.global_performance\", stats)\n\n    def _calculate_confidence(self, exec_res: dict) -&gt; float:\n        \"\"\"Calculate confidence score based on execution results\"\"\"\n        base_confidence = 0.5\n\n        # Outline completion boosts confidence\n        outline = exec_res.get(\"outline\")\n        if outline:\n            completion_ratio = exec_res.get(\"outline_completion\", 0) / len(outline.get(\"steps\", [1]))\n            base_confidence += 0.3 * completion_ratio\n\n        # Low recovery attempts boost confidence\n        recovery_attempts = exec_res.get(\"auto_recovery_attempts\", 0)\n        if recovery_attempts == 0:\n            base_confidence += 0.15\n        elif recovery_attempts == 1:\n            base_confidence += 0.05\n\n        # Reasonable loop count boosts confidence\n        loops = exec_res.get(\"reasoning_loops\", 0)\n        if 3 &lt;= loops &lt;= 15:\n            base_confidence += 0.1\n\n        # Performance metrics\n        performance = exec_res.get(\"performance_metrics\", {})\n        if performance.get(\"action_efficiency\", 0) &gt; 0.7:\n            base_confidence += 0.1\n\n        return min(1.0, max(0.0, base_confidence))\n\n    def _calculate_performance_score(self, exec_res: dict) -&gt; float:\n        \"\"\"Calculate overall performance score\"\"\"\n        score = 0.5\n\n        # Efficiency score\n        performance = exec_res.get(\"performance_metrics\", {})\n        action_efficiency = performance.get(\"action_efficiency\", 0)\n        score += 0.3 * action_efficiency\n\n        # Completion score\n        outline = exec_res.get(\"outline\")\n        if outline:\n            completion_ratio = exec_res.get(\"outline_completion\", 0) / len(outline.get(\"steps\", [1]))\n            score += 0.4 * completion_ratio\n\n        # Recovery penalty\n        recovery_attempts = exec_res.get(\"auto_recovery_attempts\", 0)\n        score -= 0.1 * recovery_attempts\n\n        return min(1.0, max(0.0, score))\n\n\n    def _summarize_reasoning_context(self) -&gt; str:\n        \"\"\"Summarize the current reasoning context\"\"\"\n        if not self.reasoning_context:\n            return \"No previous reasoning steps\"\n\n        summary_parts = []\n        for entry in self.reasoning_context[-5:]:  # Last 5 entries\n            entry_type = entry.get(\"type\", \"unknown\")\n            content = entry.get(\"content\", \"\")\n\n            if entry_type == \"reasoning\":\n                # Truncate long reasoning content\n                content_preview = content[:20000] + \"...\" if len(content) &gt; 20000 else content\n                summary_parts.append(f\"Loop {entry.get('loop', '?')}: {content_preview}\")\n            elif entry_type == \"meta_tool_result\":\n                summary_parts.append(f\"Result: {content[:150]}...\")\n            elif entry_type == \"error\":\n                summary_parts.append(f\"Error: {content}\")\n\n        return \"\\n\".join(summary_parts)\n\n    def _summarize_task_stack(self) -&gt; str:\n        \"\"\"Summarize the internal task stack\"\"\"\n        if not self.internal_task_stack:\n            return \"No tasks in stack\"\n\n        summary_parts = []\n        for i, task in enumerate(self.internal_task_stack):\n            status = task.get(\"status\", \"pending\")\n            description = task.get(\"description\", \"No description\")\n            summary_parts.append(f\"{i + 1}. [{status.upper()}] {description}\")\n\n        return \"\\n\".join(summary_parts)\n\n    def _get_tool_category(self, tool_name: str) -&gt; str:\n        \"\"\"Get category for meta-tool\"\"\"\n        categories = {\n            \"internal_reasoning\": \"thinking\",\n            \"manage_internal_task_stack\": \"planning\",\n            \"delegate_to_llm_tool_node\": \"delegation\",\n            \"create_and_execute_plan\": \"orchestration\",\n            \"direct_response\": \"completion\"\n        }\n        return categories.get(tool_name, \"unknown\")\n\n    def _calculate_reasoning_depth(self) -&gt; int:\n        \"\"\"Calculate current reasoning depth\"\"\"\n        reasoning_entries = [entry for entry in self.reasoning_context if entry.get(\"type\") == \"reasoning\"]\n        return len(reasoning_entries)\n\n    def _assess_delegation_complexity(self, args: dict) -&gt; str:\n        \"\"\"Assess complexity of delegation task\"\"\"\n        task_desc = args.get(\"task_description\", \"\")\n        tools_count = len(args.get(\"tools_list\", []))\n\n        if tools_count &gt; 3 or len(task_desc) &gt; 100:\n            return \"high\"\n        elif tools_count &gt; 1 or len(task_desc) &gt; 50:\n            return \"medium\"\n        else:\n            return \"low\"\n\n    def _estimate_plan_complexity(self, goals: list) -&gt; str:\n        \"\"\"Estimate complexity of plan\"\"\"\n        goal_count = len(goals)\n        total_text = sum(len(str(goal)) for goal in goals)\n\n        if goal_count &gt; 5 or total_text &gt; 500:\n            return \"high\"\n        elif goal_count &gt; 2 or total_text &gt; 200:\n            return \"medium\"\n        else:\n            return \"low\"\n\n    def _calculate_tool_performance_score(self, duration: float, tool_name: str) -&gt; float:\n        \"\"\"Calculate performance score for tool execution\"\"\"\n        # Expected durations by tool type\n        expected_durations = {\n            \"internal_reasoning\": 0.1,\n            \"manage_internal_task_stack\": 0.05,\n            \"delegate_to_llm_tool_node\": 3.0,\n            \"create_and_execute_plan\": 10.0,\n            \"direct_response\": 0.1\n        }\n\n        expected = expected_durations.get(tool_name, 1.0)\n        if duration &lt;= expected:\n            return 1.0\n        else:\n            return max(0.0, expected / duration)\n\n    def _create_reasoning_summary(self) -&gt; str:\n        \"\"\"Create summary of reasoning process\"\"\"\n        reasoning_entries = [entry for entry in self.reasoning_context if entry.get(\"type\") == \"reasoning\"]\n        task_entries = len(self.internal_task_stack)\n\n        return f\"Completed {len(reasoning_entries)} reasoning steps with {task_entries} tasks tracked\"\n\n    def _calculate_batch_performance(self, matches: list) -&gt; dict[str, Any]:\n        \"\"\"Calculate performance metrics for batch execution\"\"\"\n        tool_types = [match[0] for match in matches]\n        return {\n            \"total_tools\": len(matches),\n            \"tool_diversity\": len(set(tool_types)),\n            \"most_used_tool\": max(set(tool_types), key=tool_types.count) if tool_types else \"none\"\n        }\n\n    def _assess_reasoning_progress(self) -&gt; str:\n        \"\"\"Assess overall reasoning progress\"\"\"\n        if len(self.reasoning_context) &lt; 3:\n            return \"early_stage\"\n        elif len(self.reasoning_context) &lt; 8:\n            return \"developing\"\n        elif len(self.reasoning_context) &lt; 15:\n            return \"mature\"\n        else:\n            return \"extensive\"\n\n    def _get_error_context(self, error: Exception) -&gt; dict[str, Any]:\n        \"\"\"Get contextual information about an error\"\"\"\n        return {\n            \"error_class\": type(error).__name__,\n            \"reasoning_stage\": f\"loop_{self.current_loop_count}\",\n            \"context_available\": len(self.reasoning_context) &gt; 0,\n            \"stack_state\": \"populated\" if self.internal_task_stack else \"empty\"\n        }\n\n    async def _execute_internal_reasoning(self, args: dict, prep_res: dict) -&gt; dict[str, Any]:\n        \"\"\"Execute internal reasoning meta-tool\"\"\"\n        thought = args.get(\"thought\", \"\")\n        thought_number = args.get(\"thought_number\", 1)\n        total_thoughts = args.get(\"total_thoughts\", 1)\n        next_thought_needed = args.get(\"next_thought_needed\", False)\n        current_focus = args.get(\"current_focus\", \"\")\n        key_insights = args.get(\"key_insights\", [])\n        potential_issues = args.get(\"potential_issues\", [])\n        confidence_level = args.get(\"confidence_level\", 0.5)\n\n        # Structure the reasoning entry\n        reasoning_entry = {\n            \"thought\": thought,\n            \"thought_number\": thought_number,\n            \"total_thoughts\": total_thoughts,\n            \"next_thought_needed\": next_thought_needed,\n            \"current_focus\": current_focus,\n            \"key_insights\": key_insights,\n            \"potential_issues\": potential_issues,\n            \"confidence_level\": confidence_level,\n            \"timestamp\": datetime.now().isoformat()\n        }\n\n        # Add to internal reasoning log\n        if not hasattr(self, 'internal_reasoning_log'):\n            self.internal_reasoning_log = []\n        self.internal_reasoning_log.append(reasoning_entry)\n\n        # Format for context\n        context_addition = f\"\"\"Internal Reasoning Step {thought_number}/{total_thoughts}:\nThought: {thought}\nFocus: {current_focus}\nKey Insights: {', '.join(key_insights) if key_insights else 'None'}\nPotential Issues: {', '.join(potential_issues) if potential_issues else 'None'}\nConfidence: {confidence_level}\nNext Thought Needed: {next_thought_needed}\"\"\"\n\n        return {\"context_addition\": context_addition}\n\n    async def _execute_manage_task_stack(self, args: dict, prep_res: dict) -&gt; dict[str, Any]:\n        \"\"\"Execute task stack management meta-tool\"\"\"\n        action = args.get(\"action\", \"get_current\").lower()\n        task_description = args.get(\"task_description\", \"\")\n\n        if action == \"add\":\n            self.internal_task_stack.append({\n                \"description\": task_description,\n                \"status\": \"pending\",\n                \"added_at\": datetime.now().isoformat()\n            })\n            context_addition = f\"Added to task stack: {task_description}\"\n\n        elif action == \"remove\":\n            # Remove task by description match\n            original_count = len(self.internal_task_stack)\n            self.internal_task_stack = [\n                task for task in self.internal_task_stack\n                if task_description.lower() not in task[\"description\"].lower()\n            ]\n            removed_count = original_count - len(self.internal_task_stack)\n            context_addition = f\"Removed {removed_count} task(s) matching: {task_description}\"\n\n        elif action == \"complete\":\n            # Mark task as completed\n            for task in self.internal_task_stack:\n                if task_description.lower() in task[\"description\"].lower():\n                    task[\"status\"] = \"completed\"\n                    task[\"completed_at\"] = datetime.now().isoformat()\n            context_addition = f\"Marked as completed: {task_description}\"\n\n        elif action == \"get_current\":\n            if self.internal_task_stack:\n                stack_summary = []\n                for i, task in enumerate(self.internal_task_stack):\n                    status = task[\"status\"]\n                    desc = task[\"description\"]\n                    stack_summary.append(f\"{i + 1}. [{status.upper()}] {desc}\")\n                context_addition = \"Current task stack:\\n\" + \"\\n\".join(stack_summary)\n            else:\n                context_addition = \"Task stack is empty\"\n\n        else:\n            context_addition = f\"Unknown task stack action: {action}\"\n\n        return {\"context_addition\": context_addition}\n\n    async def _execute_delegate_llm_tool(self, args: dict, prep_res: dict) -&gt; dict[str, Any]:\n        \"\"\"Execute delegation to LLMToolNode\"\"\"\n        task_description = args.get(\"task_description\", \"\")\n        tools_list = args.get(\"tools_list\", [])\n\n        # Prepare shared state for LLMToolNode\n        llm_tool_shared = {\n            \"current_task_description\": task_description + '\\nreturn all results in the final answer!',\n            \"current_query\": task_description,\n            \"formatted_context\": {\n                \"recent_interaction\": f\"Reasoner delegating task: {task_description}\",\n                \"session_summary\": self._get_reasoning_summary(),\n                \"task_context\": f\"Reasoning loop {self.current_loop_count}, delegated task. return all results!\"\n            },\n            \"variable_manager\": prep_res.get(\"variable_manager\"),\n            \"agent_instance\": prep_res.get(\"agent_instance\"),\n            \"available_tools\": tools_list,  # Restrict to specific tools\n            \"tool_capabilities\": prep_res.get(\"tool_capabilities\", {}),\n            \"fast_llm_model\": prep_res.get(\"fast_llm_model\"),\n            \"complex_llm_model\": prep_res.get(\"complex_llm_model\"),\n            \"progress_tracker\": prep_res.get(\"progress_tracker\"),\n            \"session_id\": prep_res.get(\"session_id\"),\n            \"use_fast_response\": True  # Use fast model for delegated tasks\n        }\n\n        # Execute LLMToolNode\n        try:\n            llm_tool_node = LLMToolNode()\n            await llm_tool_node.run_async(llm_tool_shared)\n\n            # Get results\n            final_response = llm_tool_shared.get(\"current_response\", \"Task completed without specific result\")\n            tool_calls_made = llm_tool_shared.get(\"tool_calls_made\", 0)\n\n            context_addition = f\"\"\"Delegated Task Completed:\nTask: {task_description}\nTools Available: {', '.join(tools_list)}\nTools Used: {tool_calls_made} tool calls made\nResult: {final_response}\"\"\"\n\n            return {\"context_addition\": context_addition}\n\n        except Exception as e:\n            context_addition = f\"Delegation failed for task '{task_description}': {str(e)}\"\n            return {\"context_addition\": context_addition}\n\n    async def _execute_create_plan(self, args: dict, prep_res: dict) -&gt; dict[str, Any]:\n        \"\"\"Execute plan creation and execution\"\"\"\n        goals = args.get(\"goals\", [])\n\n        if not goals:\n            return {\"context_addition\": \"No goals provided for plan creation\"}\n\n        try:\n            # Prepare shared state for TaskPlanner\n            planning_shared = prep_res.copy()\n            planning_shared.update({\n                \"replan_context\": {\n                    \"goals\": goals,\n                    \"triggered_by\": \"llm_reasoner\",\n                    \"reasoning_context\": self._get_reasoning_summary()\n                },\n                \"current_task_description\": f\"Execute plan with {len(goals)} goals\",\n                \"current_query\": f\"Complex task: {'; '.join(goals)}\"\n            })\n\n            # Execute TaskPlanner\n            planner_node = TaskPlannerNode()\n            plan_info = await planner_node.run_async(planning_shared)\n\n            if plan_info == \"planning_failed\":\n                return {\"context_addition\": f\"Plan creation failed: {planning_shared.get('planning_error', 'Unknown error')}\"}\n\n            plan = planning_shared.get(\"current_plan\")\n            # Execute the plan using TaskExecutor\n            executor_shared = planning_shared.copy()\n            executor_node = TaskExecutorNode()\n\n            # Execute plan to completion\n            max_execution_cycles = 10\n            execution_cycle = 0\n\n            while execution_cycle &lt; max_execution_cycles:\n                execution_cycle += 1\n\n                result = await executor_node.run_async(executor_shared)\n\n                # Check completion status\n                if result == \"plan_completed\" or result == \"execution_error\":\n                    break\n                elif result in [\"continue_execution\", \"waiting\"]:\n                    continue\n                else:\n                    # Handle other results like reflection needs\n                    if result in [\"needs_dynamic_replan\", \"needs_plan_append\"]:\n                        # For now, just continue - could add reflection logic here\n                        continue\n                    break\n\n            # Collect results\n            completed_tasks = [\n                task for task in plan.tasks\n                if executor_shared[\"tasks\"][task.id].status == \"completed\"\n            ]\n\n            failed_tasks = [\n                task for task in plan.tasks\n                if executor_shared[\"tasks\"][task.id].status == \"failed\"\n            ]\n\n            # Build context addition with results\n            results_summary = []\n            results_store = executor_shared.get(\"results\", {})\n\n            for task in completed_tasks:\n                task_result = results_store.get(task.id, {})\n                if task_result.get(\"data\"):\n                    result_preview = str(task_result[\"data\"])[:150] + \"...\"\n                    results_summary.append(f\"- {task.description}: {result_preview}\")\n\n            context_addition = f\"\"\"Plan Execution Completed:\nGoals: {len(goals)} goals processed\nTasks Created: {len(plan.tasks)}\nTasks Completed: {len(completed_tasks)}\nTasks Failed: {len(failed_tasks)}\nExecution Cycles: {execution_cycle}\n\nResults Summary:\n{chr(10).join(results_summary) if results_summary else 'No specific results captured'}\"\"\"\n\n            return {\"context_addition\": context_addition}\n\n        except Exception as e:\n            import traceback\n            print(traceback.format_exc())\n            context_addition = f\"Plan execution failed: {str(e)}\"\n            return {\"context_addition\": context_addition}\n\n    def _get_reasoning_summary(self) -&gt; str:\n        \"\"\"Get a summary of the reasoning process so far\"\"\"\n        if not self.reasoning_context:\n            return \"No reasoning context available\"\n\n        summary_parts = []\n        reasoning_entries = [entry for entry in self.reasoning_context if entry.get(\"type\") == \"reasoning\"]\n\n        for entry in reasoning_entries[-3:]:  # Last 3 reasoning steps\n            content = entry.get(\"content\", \"\")[:50000] + \"...\"\n            loop_num = entry.get(\"loop\", \"?\")\n            summary_parts.append(f\"Loop {loop_num}: {content}\")\n\n        return \"\\n\".join(summary_parts)\n\n    async def _create_error_response(self, query: str, error: str) -&gt; str:\n        \"\"\"Create an error response\"\"\"\n        return f\"I encountered an error while processing your request: {error}. I was working on: {query}\"\n\n    async def _fallback_direct_response(self, prep_res: dict) -&gt; dict[str, Any]:\n        \"\"\"Fallback when LLM is not available\"\"\"\n        query = prep_res[\"original_query\"]\n        fallback_response = f\"I received your request: {query}. However, I'm currently unable to process complex requests due to limited capabilities.\"\n\n        return {\n            \"final_result\": fallback_response,\n            \"reasoning_loops\": 0,\n            \"reasoning_context\": [{\"type\": \"fallback\", \"content\": \"LLM unavailable\"}],\n            \"internal_task_stack\": []\n        }\n</code></pre> <code>exec_async(prep_res)</code> <code>async</code> \u00b6 <p>Enhanced main reasoning loop with outline-driven execution</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def exec_async(self, prep_res):\n    \"\"\"Enhanced main reasoning loop with outline-driven execution\"\"\"\n    if not LITELLM_AVAILABLE:\n        return await self._fallback_direct_response(prep_res)\n\n    original_query = prep_res[\"original_query\"]\n    agent_instance = prep_res[\"agent_instance\"]\n    progress_tracker = prep_res.get(\"progress_tracker\")\n\n    # Initialize enhanced reasoning context\n    await self._initialize_reasoning_session(prep_res, original_query)\n\n    # STEP 1: MANDATORY OUTLINE CREATION\n    if not self.outline:\n        outline_result = await self._create_initial_outline(prep_res)\n        if not outline_result:\n            return await self._create_error_response(original_query, \"Failed to create initial outline\")\n\n    final_result = None\n    consecutive_no_progress = 0\n    max_no_progress = 3\n\n    # Enhanced main reasoning loop with strict progress tracking\n    while self.current_reasoning_count &lt; self.max_reasoning_loops:\n        self.current_loop_count += 1\n        loop_start_time = time.time()\n\n        # Check for infinite loops\n        if self._detect_infinite_loop():\n            await self._trigger_auto_recovery(prep_res)\n            if self.auto_recovery_attempts &gt;= self.max_auto_recovery:\n                break\n\n        # Auto-context management\n        await self._manage_context_size()\n\n        # Progress tracking\n        if progress_tracker:\n            await progress_tracker.emit_event(ProgressEvent(\n                event_type=\"reasoning_loop\",\n                timestamp=time.time(),\n                node_name=\"LLMReasonerNode\",\n                status=NodeStatus.RUNNING,\n                metadata={\n                    \"loop_number\": self.current_loop_count,\n                    \"outline_step\": self.current_outline_step,\n                    \"outline_total\": len(self.outline.get(\"steps\", [])) if self.outline else 0,\n                    \"context_size\": len(self.reasoning_context),\n                    \"task_stack_size\": len(self.internal_task_stack),\n                    \"auto_recovery_attempts\": self.auto_recovery_attempts,\n                    \"performance_metrics\": self.performance_metrics\n                }\n            ))\n\n        try:\n            # Build enhanced reasoning prompt with outline context\n            reasoning_prompt = await self._build_outline_driven_prompt(prep_res)\n\n            # Force progress check if needed\n            if self.mandatory_progress_check and consecutive_no_progress &gt;= 2:\n                reasoning_prompt += \"\\n\\n**MANDATORY**: You must either complete current outline step or move to next step. No more analysis without action!\"\n\n            # LLM reasoning call\n            model_to_use = prep_res.get(\"complex_llm_model\", \"openrouter/openai/gpt-4o\")\n\n            llm_response = await agent_instance.a_run_llm_completion(\n                model=model_to_use,\n                messages=[{\"role\": \"user\", \"content\": reasoning_prompt}],\n                temperature=0.2,  # Lower temperature for more focused execution\n                # max_tokens=3072,\n                node_name=\"LLMReasonerNode\",\n                stop=\"&lt;immediate_context&gt;\",\n                task_id=f\"reasoning_loop_{self.current_loop_count}_step_{self.current_outline_step}\"\n            )\n\n            # Add LLM response to context\n            self.reasoning_context.append({\n                \"type\": \"reasoning\",\n                \"content\": llm_response,\n                \"loop\": self.current_loop_count,\n                \"outline_step\": self.current_outline_step,\n                \"timestamp\": datetime.now().isoformat()\n            })\n\n            # Parse and execute meta-tool calls with enhanced tracking\n            progress_made = await self._parse_and_execute_meta_tools(llm_response, prep_res)\n\n            action_taken = progress_made.get(\"action_taken\", False)\n            actual_progress = progress_made.get(\"progress_made\", False)\n\n            # Update performance with correct progress indication\n            self._update_performance_metrics(loop_start_time, actual_progress)\n\n            if not action_taken:\n                self.current_reasoning_count += 1\n                if self.current_outline_step &gt; len(self.outline.get(\"steps\", [])):\n                    progress_made[\"final_result\"] = llm_response\n                    rprint(\"Final result reached forced by outline step count\")\n                if self.current_outline_step &lt; len(self.outline.get(\"steps\", [])) and self.outline.get(\"steps\", [])[self.current_outline_step].get(\"is_final\", False):\n                    progress_made[\"final_result\"] = llm_response\n                    rprint(\"Final result reached forced by outline step count final step\")\n            else:\n                self.current_reasoning_count -= 1\n\n            # Check for final result\n            if progress_made.get(\"final_result\"):\n                final_result = progress_made[\"final_result\"]\n                await self._finalize_reasoning_session(prep_res, final_result)\n                break\n\n            # Progress monitoring\n            if progress_made.get(\"action_taken\"):\n                consecutive_no_progress = 0\n                self._update_performance_metrics(loop_start_time, True)\n            else:\n                consecutive_no_progress += 1\n                self._update_performance_metrics(loop_start_time, False)\n\n            # Check outline completion\n            if self.outline and self.current_outline_step &gt;= len(self.outline.get(\"steps\", []))+self.max_reasoning_loops:\n                # All outline steps completed, force final response\n                final_result = await self._create_outline_completion_response(prep_res)\n                break\n\n            # Emergency break for excessive no-progress\n            if consecutive_no_progress &gt;= max_no_progress:\n                await self._trigger_auto_recovery(prep_res)\n\n        except Exception as e:\n            await self._handle_reasoning_error(e, prep_res, progress_tracker)\n            import traceback\n            print(traceback.format_exc())\n            if self.auto_recovery_attempts &gt;= self.max_auto_recovery:\n                final_result = await self._create_error_response(original_query, str(e))\n                break\n\n\n    # If no final result after max loops, create a comprehensive summary\n    if not final_result:\n        final_result = await self._create_enhanced_timeout_response(original_query, prep_res)\n\n    return {\n        \"final_result\": final_result,\n        \"reasoning_loops\": self.current_loop_count,\n        \"reasoning_context\": self.reasoning_context.copy(),\n        \"internal_task_stack\": self.internal_task_stack.copy(),\n        \"outline\": self.outline,\n        \"outline_completion\": self.current_outline_step,\n        \"performance_metrics\": self.performance_metrics,\n        \"auto_recovery_attempts\": self.auto_recovery_attempts\n    }\n</code></pre> <code>post_async(shared, prep_res, exec_res)</code> <code>async</code> \u00b6 <p>Enhanced post-processing with comprehensive data storage</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def post_async(self, shared, prep_res, exec_res):\n    \"\"\"Enhanced post-processing with comprehensive data storage\"\"\"\n    final_result = exec_res.get(\"final_result\", \"Task processing incomplete\")\n\n    # Store comprehensive reasoning artifacts\n    shared[\"reasoning_artifacts\"] = {\n        \"reasoning_loops\": exec_res.get(\"reasoning_loops\", 0),\n        \"reasoning_context\": exec_res.get(\"reasoning_context\", []),\n        \"internal_task_stack\": exec_res.get(\"internal_task_stack\", []),\n        \"outline\": exec_res.get(\"outline\"),\n        \"outline_completion\": exec_res.get(\"outline_completion\", 0),\n        \"performance_metrics\": exec_res.get(\"performance_metrics\", {}),\n        \"auto_recovery_attempts\": exec_res.get(\"auto_recovery_attempts\", 0)\n    }\n\n    # Enhanced variable system updates\n    if self.variable_manager:\n        # Store final session results\n        final_session_data = {\n            \"final_result\": final_result,\n            \"completion_timestamp\": datetime.now().isoformat(),\n            \"total_loops\": exec_res.get(\"reasoning_loops\", 0),\n            \"session_success\": final_result != \"Task processing incomplete\",\n            \"outline_driven_execution\": True\n        }\n        self.variable_manager.set(\"reasoning.current_session.final_data\", final_session_data)\n\n        # Update global performance statistics\n        self._update_global_performance_stats(exec_res)\n\n    # Set enhanced response data\n    shared[\"llm_reasoner_result\"] = final_result\n    shared[\"current_response\"] = final_result\n\n    # Provide enhanced synthesis metadata\n    shared[\"synthesized_response\"] = {\n        \"synthesized_response\": final_result,\n        \"confidence\": self._calculate_confidence(exec_res),\n        \"metadata\": {\n            \"synthesis_method\": \"outline_driven_reasoner\",\n            \"reasoning_loops\": exec_res.get(\"reasoning_loops\", 0),\n            \"outline_completion\": exec_res.get(\"outline_completion\", 0),\n            \"performance_score\": self._calculate_performance_score(exec_res),\n            \"auto_recovery_used\": exec_res.get(\"auto_recovery_attempts\", 0) &gt; 0\n        }\n    }\n\n    return \"reasoner_complete\"\n</code></pre> <code>prep_async(shared)</code> <code>async</code> \u00b6 <p>Enhanced initialization with variable system integration</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def prep_async(self, shared):\n    \"\"\"Enhanced initialization with variable system integration\"\"\"\n    # Reset for new execution\n    self.reasoning_context = []\n    self.internal_task_stack = []\n    self.current_loop_count = 0\n    self.current_reasoning_count = 0\n    self.outline = None\n    self.current_outline_step = 0\n    self.step_completion_tracking = {}\n    self.loop_detection_memory = []\n    self.performance_metrics = {\n        \"loop_times\": [],\n        \"progress_loops\": 0,\n        \"total_loops\": 0\n    }\n    self.auto_recovery_attempts = 0\n    self.last_action_signatures = []\n\n    self.agent_instance = shared.get(\"agent_instance\")\n\n    # Enhanced variable manager integration\n    self.variable_manager = shared.get(\"variable_manager\", self.agent_instance.variable_manager)\n    context_manager = shared.get(\"context_manager\")\n\n    if self.variable_manager:\n        # Store reasoning session context\n        session_context = {\n            \"session_id\": shared.get(\"session_id\", \"default\"),\n            \"start_time\": datetime.now().isoformat(),\n            \"query\": shared.get(\"current_query\", \"\"),\n            \"reasoning_mode\": \"outline_driven\"\n        }\n        self.variable_manager.set(\"reasoning.current_session\", session_context)\n        # Load previous successful patterns from variables\n        self._load_historical_patterns()\n\n    #Build comprehensive system context via UnifiedContextManager\n    system_context = await self._build_enhanced_system_context_unified(shared, context_manager)\n\n    return {\n        \"original_query\": shared.get(\"current_query\", \"\"),\n        \"session_id\": shared.get(\"session_id\", \"default\"),\n        \"agent_instance\": shared.get(\"agent_instance\"),\n        \"variable_manager\": self.variable_manager,\n        \"context_manager\": context_manager,  #Context Manager Reference\n        \"system_context\": system_context,\n        \"available_tools\": shared.get(\"available_tools\", []),\n        \"tool_capabilities\": shared.get(\"tool_capabilities\", {}),\n        \"fast_llm_model\": shared.get(\"fast_llm_model\"),\n        \"complex_llm_model\": shared.get(\"complex_llm_model\"),\n        \"progress_tracker\": shared.get(\"progress_tracker\"),\n        \"formatted_context\": shared.get(\"formatted_context\", {}),\n        \"historical_context\": await self._get_historical_context_unified(context_manager, shared.get(\"session_id\")),\n        \"capabilities_summary\": shared.get(\"capabilities_summary\", \"\"),\n        # Sub-system references\n        \"llm_tool_node\": shared.get(\"llm_tool_node_instance\"),\n        \"task_planner\": shared.get(\"task_planner_instance\"),\n        \"task_executor\": shared.get(\"task_executor_instance\"),\n    }\n</code></pre> <code>LLMTask</code> <code>dataclass</code> \u00b6 <p>               Bases: <code>Task</code></p> <p>Spezialisierter Task f\u00fcr LLM-Aufrufe</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>@dataclass\nclass LLMTask(Task):\n    \"\"\"Spezialisierter Task f\u00fcr LLM-Aufrufe\"\"\"\n    llm_config: dict[str, Any] = field(default_factory=lambda: {\n        \"model_preference\": \"fast\",  # \"fast\" | \"complex\"\n        \"temperature\": 0.7,\n        \"max_tokens\": 1024\n    })\n    prompt_template: str = \"\"\n    context_keys: list[str] = field(default_factory=list)  # Keys aus shared state\n    output_schema: dict  = None  # JSON Schema f\u00fcr Validierung\n</code></pre> <code>LLMToolNode</code> \u00b6 <p>               Bases: <code>AsyncNode</code></p> <p>Enhanced LLM tool with automatic tool calling and agent loop integration</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>@with_progress_tracking\nclass LLMToolNode(AsyncNode):\n    \"\"\"Enhanced LLM tool with automatic tool calling and agent loop integration\"\"\"\n\n    def __init__(self, model: str = None, max_tool_calls: int = 5, **kwargs):\n        super().__init__(**kwargs)\n        self.model = model or os.getenv(\"COMPLEXMODEL\", \"openrouter/qwen/qwen3-code\")\n        self.max_tool_calls = max_tool_calls\n        self.call_log = []\n\n    async def prep_async(self, shared):\n        context = shared.get(\"formatted_context\", {})\n        task_description = shared.get(\"current_task_description\", shared.get(\"current_query\", \"\"))\n\n        # Variable Manager integration\n        variable_manager = shared.get(\"variable_manager\")\n        agent_instance = shared.get(\"agent_instance\")\n\n        return {\n            \"task_description\": task_description,\n            \"context\": context,\n            \"context_manager\": shared.get(\"context_manager\"),\n            \"session_id\": shared.get(\"session_id\"),\n            \"variable_manager\": variable_manager,\n            \"agent_instance\": agent_instance,\n            \"available_tools\": shared.get(\"available_tools\", []),\n            \"tool_capabilities\": shared.get(\"tool_capabilities\", {}),\n            \"persona_config\": shared.get(\"persona_config\"),\n            \"base_system_message\": variable_manager.format_text(agent_instance.amd.get_system_message_with_persona()),\n            \"recent_interaction\": context.get(\"recent_interaction\", \"\"),\n            \"session_summary\": context.get(\"session_summary\", \"\"),\n            \"task_context\": context.get(\"task_context\", \"\"),\n            \"fast_llm_model\": shared.get(\"fast_llm_model\"),\n            \"complex_llm_model\": shared.get(\"complex_llm_model\"),\n            \"progress_tracker\": shared.get(\"progress_tracker\"),\n            \"tool_call_count\": 0\n        }\n\n    async def exec_async(self, prep_res):\n        \"\"\"Main execution with tool calling loop\"\"\"\n        if not LITELLM_AVAILABLE:\n            return await self._fallback_response(prep_res)\n\n        progress_tracker = prep_res.get(\"progress_tracker\")\n\n        conversation_history = []\n        tool_call_count = 0\n        final_response = None\n        model_to_use = \"auto\"\n        total_llm_calls = 0\n        total_cost = 0.0\n        total_tokens = 0\n\n        # Initial system message with tool awareness\n        system_message = self._build_tool_aware_system_message(prep_res)\n\n        # Initial user prompt with variable resolution\n        initial_prompt = await self._build_context_aware_prompt(prep_res)\n        conversation_history.append({\"role\": \"user\", \"content\":  prep_res[\"variable_manager\"].format_text(initial_prompt)})\n        runs = 0\n        while tool_call_count &lt; self.max_tool_calls:\n            runs += 1\n            # Get LLM response\n            messages = [{\"role\": \"system\", \"content\": system_message + ( \"\\nfist look at the context and reason over you intal step.\" if runs == 1 else \"\")}] + conversation_history\n\n            model_to_use = self._select_optimal_model(prep_res[\"task_description\"], prep_res)\n\n            llm_start = time.perf_counter()\n\n            try:\n                agent_instance = prep_res[\"agent_instance\"]\n                response = await agent_instance.a_run_llm_completion(\n                    model=model_to_use,\n                    messages=messages,\n                    temperature=0.7,\n                    # max_tokens=2048,\n                    node_name=\"LLMToolNode\", task_id=\"llm_phase_\" + str(runs)\n                )\n\n                llm_response = response\n                if not llm_response:\n                    final_response = \"I encountered an error while processing your request.\"\n                    break\n\n\n                # Check for tool calls\n                tool_calls = self._extract_tool_calls(llm_response)\n\n                llm_response = prep_res[\"variable_manager\"].format_text(llm_response)\n                conversation_history.append({\"role\": \"assistant\", \"content\": llm_response})\n\n\n                if not tool_calls:\n                    # No more tool calls, this is the final response\n                    final_response = llm_response\n                    break\n\n                # Execute tool calls\n                tool_results = await self._execute_tool_calls(tool_calls, prep_res)\n                tool_call_count += len(tool_calls)\n\n                # Add tool results to conversation\n                tool_results_text = self._format_tool_results(tool_results)\n                conversation_history.append({\"role\": \"user\",\n                                             \"content\": f\"Tool results:\\n{tool_results_text}\\n\\nPlease continue with the next action do nor repeat or provide your final response.\"})\n\n                # Update variable manager with tool results\n                self._update_variables_with_results(tool_results, prep_res[\"variable_manager\"])\n\n            except Exception as e:\n                llm_duration = time.perf_counter() - llm_start\n\n                if progress_tracker:\n                    await progress_tracker.emit_event(ProgressEvent(\n                        event_type=\"llm_call\",  # Konsistenter Event-Typ\n                        node_name=\"LLMToolNode\",\n                        session_id=prep_res.get(\"session_id\"),\n                        status=NodeStatus.FAILED,\n                        success=False,\n                        duration=llm_duration,\n                        llm_model=model_to_use,\n                        error_details={\n                            \"message\": str(e),\n                            \"type\": type(e).__name__\n                        },\n                        metadata={\"call_number\": total_llm_calls + 1}\n                    ))\n                eprint(f\"LLM tool execution failed: {e}\")\n                final_response = f\"I encountered an error while processing: {str(e)}\"\n                import traceback\n                print(traceback.format_exc())\n                break\n\n\n        return {\n            \"success\": True,\n            \"final_response\": final_response or \"I was unable to complete the request.\",\n            \"tool_calls_made\": tool_call_count,\n            \"conversation_history\": conversation_history,\n            \"model_used\": model_to_use,\n            \"llm_statistics\": {\n                \"total_calls\": total_llm_calls,\n                \"total_cost\": total_cost,\n                \"total_tokens\": total_tokens\n            }\n        }\n\n    def _build_tool_aware_system_message(self, prep_res: dict) -&gt; str:\n        \"\"\"Build a unified intelligent, tool-aware system message with context and relevance analysis.\"\"\"\n\n        # Base system message\n        base_message = prep_res.get(\"base_system_message\", \"You are a helpful AI assistant.\")\n        available_tools = prep_res.get(\"available_tools\", [])\n        tool_capabilities = prep_res.get(\"tool_capabilities\", {})\n        variable_manager = prep_res.get(\"variable_manager\")\n        context = prep_res.get(\"context\", {})\n        agent_instance = prep_res.get(\"agent_instance\")\n        query = prep_res.get('task_description', '').lower()\n\n        base_message += (\"\\n\\nAlways follow this action pattern\"\n                         \"**THINK** -&gt; **PLAN** -&gt; (**ADJUST**) and (**UPDATE**) or **ACT** using tools!\\n\"\n                         \"all progress must be stored to ( variable system, memory, external services )!\\n\"\n                         \"if working on code or file based tasks, update and crate the files!\\n\"\n                         \"all text only steps ar discarded and not stored! only the final response is stored! \")\n\n        # --- Part 1: List available tools &amp; capabilities ---\n        if available_tools:\n            base_message += f\"\\n\\n## Available Tools\\nYou have access to these tools: {', '.join(available_tools)}\\n\"\n            base_message += \"Results will be stored to results.{tool_name}.data\"\n\n            for tool_name in available_tools:\n                if tool_name in tool_capabilities:\n                    cap = tool_capabilities[tool_name]\n                    base_message += f\"\\n**{tool_name}**: {cap.get('primary_function', 'No description')}\"\n                    use_cases = cap.get('use_cases', [])\n                    if use_cases:\n                        base_message += f\"\\n  Use cases: {', '.join(use_cases[:3])}\"\n\n            # base_message += \"\\n\\n## Tool Usage\\nTo use tools, respond with:\\nTOOL_CALL: tool_name(arg1='value1', arg2='value2')\\nYou can make multiple tool calls in one response.\"\n            base_message += \"\"\"\n## Tool Usage\nTo use tools, respond with a YAML block:\n```yaml\nTOOL_CALLS:\n  - tool: tool_name\n    args:\n      arg1: value1\n      arg2: value2\n  - tool: another_tool\n    args:\n      code: |\n        def example():\n            return \"multi-line code\"\n      text: |\n        Multi-line text\n        with arbitrary content\n```\nYou can call multiple tools in one response. Use | for multi-line strings containing code or complex text.\"\"\"\n\n        # --- Part 2: Add variable context ---\n        if variable_manager:\n            var_context = variable_manager.get_llm_variable_context()\n            if var_context:\n                base_message += f\"\\n\\n## Variable Context\\n{var_context}\"\n\n        # --- Part 3: Intelligent tool analysis ---\n        if not agent_instance or not hasattr(agent_instance, '_tool_capabilities'):\n            return base_message + \"\\n\\n\u26a0 No intelligent tool analysis available.\"\n\n        capabilities = agent_instance._tool_capabilities\n        analysis_parts = [\"\\n\\n## Intelligent Tool Analysis\"]\n\n        for tool_name, cap in capabilities.items():\n            analysis_parts.append(f\"\\n{tool_name}{cap.get('args_schema', '()')}:\")\n            analysis_parts.append(f\"- Function: {cap.get('primary_function', 'Unknown')}\")\n\n            # Calculate relevance score\n            relevance_score = self._calculate_tool_relevance(query, cap)\n            analysis_parts.append(f\"- Query relevance: {relevance_score:.2f}\")\n\n            if relevance_score &gt; 0.65:\n                analysis_parts.append(\"- \u2b50 HIGHLY RELEVANT - SHOULD USE THIS TOOL!\")\n\n            # Trigger phrase matching\n            triggers = cap.get('trigger_phrases', [])\n            matched_triggers = [t for t in triggers if t.lower() in query]\n            if matched_triggers:\n                analysis_parts.append(f\"- Matched triggers: {matched_triggers}\")\n\n            # Show top use cases\n            use_cases = cap.get('use_cases', [])[:3]\n            if use_cases:\n                analysis_parts.append(f\"- Use cases: {', '.join(use_cases)}\")\n\n        # Combine everything into a final message\n        return base_message + \"\\n\"+ \"\\n\".join(analysis_parts)\n\n    def _calculate_tool_relevance(self, query: str, capabilities: dict) -&gt; float:\n        \"\"\"Calculate how relevant a tool is to the current query\"\"\"\n\n        query_words = set(query.lower().split())\n\n        # Check trigger phrases\n        trigger_score = 0.0\n        triggers = capabilities.get('trigger_phrases', [])\n        for trigger in triggers:\n            trigger_words = set(trigger.lower().split())\n            if trigger_words.intersection(query_words):\n                trigger_score += 0.04\n        # Check confidence triggers if available\n        conf_triggers = capabilities.get('confidence_triggers', {})\n        for phrase, confidence in conf_triggers.items():\n            if phrase.lower() in query:\n                trigger_score += confidence/10\n        # Check indirect connections\n        indirect = capabilities.get('indirect_connections', [])\n        for connection in indirect:\n            connection_words = set(connection.lower().split())\n            if connection_words.intersection(query_words):\n                trigger_score += 0.02\n        return min(1.0, trigger_score)\n\n    @staticmethod\n    def _extract_tool_calls_custom(text: str) -&gt; list[dict]:\n        \"\"\"Extract tool calls from LLM response\"\"\"\n\n        tool_calls = []\n\n        pattern = r'TOOL_CALL:'\n        matches = _extract_meta_tool_calls(text, pattern)\n\n        for tool_name, args_str in matches:\n            try:\n                # Parse arguments\n                args = _parse_tool_args(args_str)\n                tool_calls.append({\n                    \"tool_name\": tool_name,\n                    \"arguments\": args\n                })\n            except Exception as e:\n                wprint(f\"Failed to parse tool call {tool_name}: {e}\")\n\n        return tool_calls\n\n    @staticmethod\n    def _extract_tool_calls(text: str) -&gt; list[dict]:\n        \"\"\"Extract tool calls from LLM response using YAML format\"\"\"\n        import re\n\n        import yaml\n\n        tool_calls = []\n\n        # Pattern to find YAML blocks with TOOL_CALLS\n        yaml_pattern = r'```yaml\\s*\\n(.*?TOOL_CALLS:.*?)\\n```'\n        yaml_matches = re.findall(yaml_pattern, text, re.DOTALL | re.IGNORECASE)\n\n        # Also try without code blocks for simpler cases\n        if not yaml_matches:\n            simple_pattern = r'TOOL_CALLS:\\s*\\n((?:.*\\n)*?)(?=\\n\\S|\\Z)'\n            simple_matches = re.findall(simple_pattern, text, re.MULTILINE)\n            if simple_matches:\n                yaml_matches = [f\"TOOL_CALLS:\\n{match}\" for match in simple_matches]\n\n        for yaml_content in yaml_matches:\n            try:\n                # Parse YAML content\n                parsed_yaml = yaml.safe_load(yaml_content)\n\n                if not isinstance(parsed_yaml, dict) or 'TOOL_CALLS' not in parsed_yaml:\n                    continue\n\n                calls = parsed_yaml['TOOL_CALLS']\n                if not isinstance(calls, list):\n                    calls = [calls]  # Handle single tool call\n\n                for call in calls:\n                    if isinstance(call, dict) and 'tool' in call:\n                        tool_call = {\n                            \"tool_name\": call['tool'],\n                            \"arguments\": call.get('args', {})\n                        }\n                        tool_calls.append(tool_call)\n\n            except yaml.YAMLError as e:\n                wprint(f\"Failed to parse YAML tool calls: {e}\")\n            except Exception as e:\n                wprint(f\"Error processing tool calls: {e}\")\n\n        return tool_calls\n\n    def _select_optimal_model(self, task_description: str, prep_res: dict) -&gt; str:\n        \"\"\"Select optimal model based on task complexity and available resources\"\"\"\n        complexity_score = self._estimate_task_complexity(task_description, prep_res)\n        if complexity_score &gt; 0.7:\n            return prep_res.get(\"complex_llm_model\", \"openrouter/openai/gpt-4o\")\n        else:\n            return prep_res.get(\"fast_llm_model\", \"openrouter/anthropic/claude-3-haiku\")\n\n    def _estimate_task_complexity(self, task_description: str, prep_res: dict) -&gt; float:\n        \"\"\"Estimate task complexity based on description, length, and available tools\"\"\"\n        # Simple heuristic: length + keyword matching + tool availability\n        description_length_score = min(len(task_description) / 500, 1.0)  # cap at 1.0\n        keywords = [\"analyze\", \"research\", \"generate\", \"simulate\", \"complex\", \"deep\", \"strategy\"]\n        keyword_score = sum(1 for k in keywords if k in task_description.lower()) / len(keywords)\n        tool_score = min(len(prep_res.get(\"available_tools\", [])) / 10, 1.0)\n\n        # Weighted sum\n        complexity_score = (0.5 * description_length_score) + (0.3 * keyword_score) + (0.2 * tool_score)\n        return round(complexity_score, 2)\n\n    async def _fallback_response(self, prep_res: dict) -&gt; dict:\n        \"\"\"Fallback response if LiteLLM is not available\"\"\"\n        wprint(\"LiteLLM not available \u2014 using fallback response.\")\n        return {\n            \"success\": False,\n            \"final_response\": (\n                \"I'm unable to process this request fully right now because the LLM interface \"\n                \"is not available. Please try again later or check system configuration.\"\n            ),\n            \"tool_calls_made\": 0,\n            \"conversation_history\": [],\n            \"model_used\": None\n        }\n\n    async def _execute_tool_calls(self, tool_calls: list[dict], prep_res: dict) -&gt; list[dict]:\n        \"\"\"Execute tool calls via agent\"\"\"\n        agent_instance = prep_res.get(\"agent_instance\")\n        variable_manager = prep_res.get(\"variable_manager\")\n        progress_tracker = prep_res.get(\"progress_tracker\")\n\n        results = []\n\n        for tool_call in tool_calls:\n            tool_name = tool_call[\"tool_name\"]\n            arguments = tool_call[\"arguments\"]\n\n            # Start tool tracking\n            tool_start = time.perf_counter()\n\n            if progress_tracker:\n                await progress_tracker.emit_event(ProgressEvent(\n                    event_type=\"tool_call\",\n                    timestamp=time.time(),\n                    status=NodeStatus.RUNNING,\n                    node_name=\"LLMToolNode\",\n                    tool_name=tool_name,\n                    tool_args=arguments,\n                    session_id=prep_res.get(\"session_id\"),\n                    metadata={\"tool_call_initiated\": True}\n                ))\n\n            try:\n                # Resolve variables in arguments\n                if variable_manager:\n                    resolved_args = {}\n                    for key, value in arguments.items():\n                        if isinstance(value, str):\n                            resolved_args[key] = variable_manager.format_text(value)\n                        else:\n                            resolved_args[key] = value\n                else:\n                    resolved_args = arguments\n\n                # Execute via agent\n                result = await agent_instance.arun_function(tool_name, **resolved_args)\n                tool_duration = time.perf_counter() - tool_start\n                variable_manager.set(f\"results.{tool_name}.data\", result)\n                if progress_tracker:\n                    await progress_tracker.emit_event(ProgressEvent(\n                        event_type=\"tool_call\",\n                        timestamp=time.time(),\n                        node_name=\"LLMToolNode\",\n                        status=NodeStatus.COMPLETED,\n                        tool_name=tool_name,\n                        tool_args=resolved_args,\n                        tool_result=result,\n                        duration=tool_duration,\n                        success=True,\n                        session_id=prep_res.get(\"session_id\"),\n                        metadata={\n                            \"result_type\": type(result).__name__,\n                            \"result_length\": len(str(result))\n                        }\n                    ))\n                results.append({\n                    \"tool_name\": tool_name,\n                    \"arguments\": resolved_args,\n                    \"success\": True,\n                    \"result\": result\n                })\n\n            except Exception as e:\n                tool_duration = time.perf_counter() - tool_start\n                error_message = str(e)\n                error_type = type(e).__name__\n                import traceback\n                print(traceback.format_exc())\n\n\n                if progress_tracker:\n                    await progress_tracker.emit_event(ProgressEvent(\n                        event_type=\"tool_call\",\n                        timestamp=time.time(),\n                        node_name=\"LLMToolNode\",\n                        status=NodeStatus.FAILED,\n                        tool_name=tool_name,\n                        tool_args=arguments,\n                        duration=tool_duration,\n                        success=False,\n                        tool_error=error_message,\n                        session_id=prep_res.get(\"session_id\"),\n                        metadata={\n                            \"error\": error_message,\n                            \"error_message\": error_message,\n                            \"error_type\": error_type\n                        }\n                    ))\n\n                    # FIXED: Also send generic error event for error log\n                    await progress_tracker.emit_event(ProgressEvent(\n                        event_type=\"error\",\n                        timestamp=time.time(),\n                        node_name=\"LLMToolNode\",\n                        status=NodeStatus.FAILED,\n                        success=False,\n                        tool_name=tool_name,\n                        metadata={\n                            \"error\": error_message,\n                            \"error_message\": error_message,\n                            \"error_type\": error_type,\n                            \"source\": \"tool_execution\",\n                            \"tool_name\": tool_name,\n                            \"tool_args\": arguments\n                        }\n                    ))\n                eprint(f\"Tool execution failed {tool_name}: {e}\")\n                results.append({\n                    \"tool_name\": tool_name,\n                    \"arguments\": arguments,\n                    \"success\": False,\n                    \"error\": str(e)\n                })\n\n        return results\n\n    def _format_tool_results(self, results: list[dict]) -&gt; str:\n        \"\"\"Format tool results for LLM\"\"\"\n        formatted = []\n\n        for result in results:\n            if result[\"success\"]:\n                formatted.append(f\"\u2713 {result['tool_name']}: {result['result']}\")\n            else:\n                formatted.append(f\"\u2717 {result['tool_name']}: ERROR - {result['error']}\")\n\n        return \"\\n\".join(formatted)\n\n    def _update_variables_with_results(self, results: list[dict], variable_manager):\n        \"\"\"Update variable manager with tool results\"\"\"\n        if not variable_manager:\n            return\n\n        for i, result in enumerate(results):\n            if result[\"success\"]:\n                tool_name = result['tool_name']\n                result_data = result['result']\n\n                # FIXED: Store result in proper variable paths\n                variable_manager.set(f\"results.{tool_name}.data\", result_data)\n                variable_manager.set(f\"tools.{tool_name}.result\", result_data)\n\n                # Also store with index for multiple calls to same tool\n                var_key = f\"tool_result_{tool_name}_{i}\"\n                variable_manager.set(var_key, result_data)\n\n    async def _build_context_aware_prompt(self, prep_res: dict) -&gt; str:\n        \"\"\"Build context-aware prompt mit UnifiedContextManager Integration\"\"\"\n        variable_manager = prep_res.get(\"variable_manager\")\n        agent_instance = prep_res.get(\"agent_instance\")\n        context = prep_res.get(\"context\", {})\n\n        #Get unified context if available\n        context_manager = prep_res.get(\"context_manager\")\n        session_id = prep_res.get(\"session_id\", \"default\")\n\n        unified_context_parts = []\n\n        if context_manager:\n            try:\n                # Get unified context f\u00fcr LLM Tool usage\n                unified_context = await context_manager.build_unified_context(session_id, prep_res.get(\"task_description\", \"\"))\n\n                # Format unified context for LLM consumption\n                chat_history = unified_context.get(\"chat_history\", [])\n                if chat_history:\n                    unified_context_parts.append(\"## Recent Conversation from Session\")\n                    for msg in chat_history[-5:]:  # Last 5 messages\n                        timestamp = msg.get('timestamp', '')[:19]\n                        role = msg.get('role', 'unknown')\n                        content = msg.get('content', '')[:300] + (\"...\" if len(msg.get('content', '')) &gt; 300 else \"\")\n                        unified_context_parts.append(f\"[{timestamp}] {role}: {content}\")\n\n                # Execution state from unified context\n                execution_state = unified_context.get(\"execution_state\", {})\n                if execution_state:\n                    system_status = execution_state.get('system_status', 'unknown')\n                    active_tasks = execution_state.get('active_tasks', [])\n                    recent_completions = execution_state.get('recent_completions', [])\n\n                    unified_context_parts.append(\"\\n## Current System State\")\n                    unified_context_parts.append(f\"Status: {system_status}\")\n                    if active_tasks:\n                        unified_context_parts.append(f\"Active Tasks: {len(active_tasks)}\")\n                    if recent_completions:\n                        unified_context_parts.append(f\"Recent Completions: {len(recent_completions)}\")\n\n                # Available results from unified context\n                variables_context = unified_context.get(\"variables\", {})\n                recent_results = variables_context.get(\"recent_results\", [])\n                if recent_results:\n                    unified_context_parts.append(\"\\n## Available Results\")\n                    for result in recent_results[:3]:  # Top 3 results\n                        task_id = result.get(\"task_id\", \"unknown\")\n                        preview = result.get(\"preview\", \"\")[:100] + \"...\"\n                        success = \"\u2705\" if result.get(\"success\") else \"\u274c\"\n                        unified_context_parts.append(f\"{success} {task_id}: {preview}\")\n\n                # World model facts from unified context\n                relevant_facts = unified_context.get(\"relevant_facts\", [])\n                if relevant_facts:\n                    unified_context_parts.append(\"\\n## Relevant Known Facts\")\n                    for key, value in relevant_facts[:3]:  # Top 3 facts\n                        fact_preview = str(value)[:100] + (\"...\" if len(str(value)) &gt; 100 else \"\")\n                        unified_context_parts.append(f\"- {key}: {fact_preview}\")\n\n            except Exception as e:\n                unified_context_parts.append(f\"## Context Error\\nUnified context unavailable: {str(e)}\")\n\n        # EXISTIEREND: Keep existing context building (backwards compatibility)\n        prompt_parts = []\n\n        # Add unified context first (primary)\n        if unified_context_parts:\n            prompt_parts.extend(unified_context_parts)\n\n        # Add existing context sections (secondary)\n        recent_interaction = prep_res.get(\"recent_interaction\", \"\")\n        session_summary = prep_res.get(\"session_summary\", \"\")\n        task_context = prep_res.get(\"task_context\", \"\")\n\n        if recent_interaction:\n            prompt_parts.append(f\"\\n## Recent Interaction Context\\n{recent_interaction}\")\n            prompt_parts.append(\"\\n**Important**: NO META_TOOL_CALLs needed in this section! and not avalabel\\n use tools from Intelligent Tool Analysis only!\")\n        if session_summary:\n            prompt_parts.append(f\"\\n## Session Summary\\n{session_summary}\")\n        if task_context:\n            prompt_parts.append(f\"\\n## Task Context\\n{task_context}\")\n\n        # Add main task\n        task_description = prep_res.get(\"task_description\", \"\")\n        if task_description:\n            prompt_parts.append(f\"\\n## Current Request\\n{task_description}\")\n\n        # Variable suggestions (existing functionality)\n        if variable_manager and task_description:\n            suggestions = variable_manager.get_variable_suggestions(task_description)\n            if suggestions:\n                prompt_parts.append(f\"\\n## Available Variables\\nYou can use: {', '.join(suggestions)}\")\n\n        # Final variable resolution\n        final_prompt = \"\\n\".join(prompt_parts)\n        if variable_manager:\n            final_prompt = variable_manager.format_text(final_prompt)\n\n        return final_prompt\n\n    async def post_async(self, shared, prep_res, exec_res):\n        shared[\"current_response\"] = exec_res.get(\"final_response\", \"Task completed.\")\n        shared[\"tool_calls_made\"] = exec_res.get(\"tool_calls_made\", 0)\n        shared[\"llm_tool_conversation\"] = exec_res.get(\"conversation_history\", [])\n        shared[\"synthesized_response\"] = {\"synthesized_response\":exec_res.get(\"final_response\", \"Task completed.\"),\n                                          \"confidence\": (0.7 if exec_res.get(\"model_used\") == prep_res.get(\"complex_llm_model\") else 0.6) if exec_res.get(\"success\", False) else 0,\n                                          \"metadata\": exec_res.get(\"metadata\", {\"model_used\": exec_res.get(\"model_used\")}),\n                                          \"synthesis_method\": \"llm_tool\"}\n        return \"llm_tool_complete\"\n</code></pre> <code>exec_async(prep_res)</code> <code>async</code> \u00b6 <p>Main execution with tool calling loop</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def exec_async(self, prep_res):\n    \"\"\"Main execution with tool calling loop\"\"\"\n    if not LITELLM_AVAILABLE:\n        return await self._fallback_response(prep_res)\n\n    progress_tracker = prep_res.get(\"progress_tracker\")\n\n    conversation_history = []\n    tool_call_count = 0\n    final_response = None\n    model_to_use = \"auto\"\n    total_llm_calls = 0\n    total_cost = 0.0\n    total_tokens = 0\n\n    # Initial system message with tool awareness\n    system_message = self._build_tool_aware_system_message(prep_res)\n\n    # Initial user prompt with variable resolution\n    initial_prompt = await self._build_context_aware_prompt(prep_res)\n    conversation_history.append({\"role\": \"user\", \"content\":  prep_res[\"variable_manager\"].format_text(initial_prompt)})\n    runs = 0\n    while tool_call_count &lt; self.max_tool_calls:\n        runs += 1\n        # Get LLM response\n        messages = [{\"role\": \"system\", \"content\": system_message + ( \"\\nfist look at the context and reason over you intal step.\" if runs == 1 else \"\")}] + conversation_history\n\n        model_to_use = self._select_optimal_model(prep_res[\"task_description\"], prep_res)\n\n        llm_start = time.perf_counter()\n\n        try:\n            agent_instance = prep_res[\"agent_instance\"]\n            response = await agent_instance.a_run_llm_completion(\n                model=model_to_use,\n                messages=messages,\n                temperature=0.7,\n                # max_tokens=2048,\n                node_name=\"LLMToolNode\", task_id=\"llm_phase_\" + str(runs)\n            )\n\n            llm_response = response\n            if not llm_response:\n                final_response = \"I encountered an error while processing your request.\"\n                break\n\n\n            # Check for tool calls\n            tool_calls = self._extract_tool_calls(llm_response)\n\n            llm_response = prep_res[\"variable_manager\"].format_text(llm_response)\n            conversation_history.append({\"role\": \"assistant\", \"content\": llm_response})\n\n\n            if not tool_calls:\n                # No more tool calls, this is the final response\n                final_response = llm_response\n                break\n\n            # Execute tool calls\n            tool_results = await self._execute_tool_calls(tool_calls, prep_res)\n            tool_call_count += len(tool_calls)\n\n            # Add tool results to conversation\n            tool_results_text = self._format_tool_results(tool_results)\n            conversation_history.append({\"role\": \"user\",\n                                         \"content\": f\"Tool results:\\n{tool_results_text}\\n\\nPlease continue with the next action do nor repeat or provide your final response.\"})\n\n            # Update variable manager with tool results\n            self._update_variables_with_results(tool_results, prep_res[\"variable_manager\"])\n\n        except Exception as e:\n            llm_duration = time.perf_counter() - llm_start\n\n            if progress_tracker:\n                await progress_tracker.emit_event(ProgressEvent(\n                    event_type=\"llm_call\",  # Konsistenter Event-Typ\n                    node_name=\"LLMToolNode\",\n                    session_id=prep_res.get(\"session_id\"),\n                    status=NodeStatus.FAILED,\n                    success=False,\n                    duration=llm_duration,\n                    llm_model=model_to_use,\n                    error_details={\n                        \"message\": str(e),\n                        \"type\": type(e).__name__\n                    },\n                    metadata={\"call_number\": total_llm_calls + 1}\n                ))\n            eprint(f\"LLM tool execution failed: {e}\")\n            final_response = f\"I encountered an error while processing: {str(e)}\"\n            import traceback\n            print(traceback.format_exc())\n            break\n\n\n    return {\n        \"success\": True,\n        \"final_response\": final_response or \"I was unable to complete the request.\",\n        \"tool_calls_made\": tool_call_count,\n        \"conversation_history\": conversation_history,\n        \"model_used\": model_to_use,\n        \"llm_statistics\": {\n            \"total_calls\": total_llm_calls,\n            \"total_cost\": total_cost,\n            \"total_tokens\": total_tokens\n        }\n    }\n</code></pre> <code>PersonaConfig</code> <code>dataclass</code> \u00b6 Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>@dataclass\nclass PersonaConfig:\n    name: str\n    style: str = \"professional\"\n    personality_traits: list[str] = field(default_factory=lambda: [\"helpful\", \"concise\"])\n    tone: str = \"friendly\"\n    response_format: str = \"direct\"\n    custom_instructions: str = \"\"\n\n    format_config: FormatConfig  = None\n\n    apply_method: str = \"system_prompt\"  # \"system_prompt\" | \"post_process\" | \"both\"\n    integration_level: str = \"light\"  # \"light\" | \"medium\" | \"heavy\"\n\n    def to_system_prompt_addition(self) -&gt; str:\n        \"\"\"Convert persona to system prompt addition with format integration\"\"\"\n        if self.apply_method in [\"system_prompt\", \"both\"]:\n            additions = []\n            additions.append(f\"You are {self.name}.\")\n            additions.append(f\"Your communication style is {self.style} with a {self.tone} tone.\")\n\n            if self.personality_traits:\n                traits_str = \", \".join(self.personality_traits)\n                additions.append(f\"Your key traits are: {traits_str}.\")\n\n            if self.custom_instructions:\n                additions.append(self.custom_instructions)\n\n            # Format-spezifische Anweisungen hinzuf\u00fcgen\n            if self.format_config:\n                additions.append(\"\\n\" + self.format_config.get_combined_instructions())\n\n            return \" \".join(additions)\n        return \"\"\n\n    def update_format(self, response_format: ResponseFormat|str, text_length: TextLength|str, custom_instructions: str = \"\"):\n        \"\"\"Dynamische Format-Aktualisierung\"\"\"\n        try:\n            format_enum = ResponseFormat(response_format) if isinstance(response_format, str) else response_format\n            length_enum = TextLength(text_length) if isinstance(text_length, str) else text_length\n\n            if not self.format_config:\n                self.format_config = FormatConfig()\n\n            self.format_config.response_format = format_enum\n            self.format_config.text_length = length_enum\n\n            if custom_instructions:\n                self.format_config.custom_instructions = custom_instructions\n\n\n        except ValueError:\n            raise ValueError(f\"Invalid format '{response_format}' or length '{text_length}'\")\n\n    def should_post_process(self) -&gt; bool:\n        \"\"\"Check if post-processing should be applied\"\"\"\n        return self.apply_method in [\"post_process\", \"both\"]\n</code></pre> <code>should_post_process()</code> \u00b6 <p>Check if post-processing should be applied</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def should_post_process(self) -&gt; bool:\n    \"\"\"Check if post-processing should be applied\"\"\"\n    return self.apply_method in [\"post_process\", \"both\"]\n</code></pre> <code>to_system_prompt_addition()</code> \u00b6 <p>Convert persona to system prompt addition with format integration</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def to_system_prompt_addition(self) -&gt; str:\n    \"\"\"Convert persona to system prompt addition with format integration\"\"\"\n    if self.apply_method in [\"system_prompt\", \"both\"]:\n        additions = []\n        additions.append(f\"You are {self.name}.\")\n        additions.append(f\"Your communication style is {self.style} with a {self.tone} tone.\")\n\n        if self.personality_traits:\n            traits_str = \", \".join(self.personality_traits)\n            additions.append(f\"Your key traits are: {traits_str}.\")\n\n        if self.custom_instructions:\n            additions.append(self.custom_instructions)\n\n        # Format-spezifische Anweisungen hinzuf\u00fcgen\n        if self.format_config:\n            additions.append(\"\\n\" + self.format_config.get_combined_instructions())\n\n        return \" \".join(additions)\n    return \"\"\n</code></pre> <code>update_format(response_format, text_length, custom_instructions='')</code> \u00b6 <p>Dynamische Format-Aktualisierung</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def update_format(self, response_format: ResponseFormat|str, text_length: TextLength|str, custom_instructions: str = \"\"):\n    \"\"\"Dynamische Format-Aktualisierung\"\"\"\n    try:\n        format_enum = ResponseFormat(response_format) if isinstance(response_format, str) else response_format\n        length_enum = TextLength(text_length) if isinstance(text_length, str) else text_length\n\n        if not self.format_config:\n            self.format_config = FormatConfig()\n\n        self.format_config.response_format = format_enum\n        self.format_config.text_length = length_enum\n\n        if custom_instructions:\n            self.format_config.custom_instructions = custom_instructions\n\n\n    except ValueError:\n        raise ValueError(f\"Invalid format '{response_format}' or length '{text_length}'\")\n</code></pre> <code>ProgressEvent</code> <code>dataclass</code> \u00b6 <p>Enhanced progress event with better error handling</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>@dataclass\nclass ProgressEvent:\n\n    \"\"\"Enhanced progress event with better error handling\"\"\"\n\n    # === 1. Kern-Attribute (F\u00fcr jedes Event) ===\n    event_type: str\n    node_name: str\n    timestamp: float = field(default_factory=time.time)\n    event_id: str = field(default_factory=lambda: str(uuid.uuid4()))\n    session_id: Optional[str] = None\n\n    # === 2. Status und Ergebnis-Attribute ===\n    status: Optional[NodeStatus] = None\n    success: Optional[bool] = None\n    duration: Optional[float] = None\n    error_details: dict[str, Any] = field(default_factory=dict)  # Strukturiert: message, type, traceback\n\n    # === 3. LLM-spezifische Attribute ===\n    llm_model: Optional[str] = None\n    llm_prompt_tokens: Optional[int] = None\n    llm_completion_tokens: Optional[int] = None\n    llm_total_tokens: Optional[int] = None\n    llm_cost: Optional[float] = None\n    llm_input: Optional[Any] = None  # Optional f\u00fcr Debugging, kann gro\u00df sein\n    llm_output: Optional[str] = None # Optional f\u00fcr Debugging, kann gro\u00df sein\n\n    # === 4. Tool-spezifische Attribute ===\n    tool_name: Optional[str] = None\n    is_meta_tool: Optional[bool] = None\n    tool_args: Optional[dict[str, Any]] = None\n    tool_result: Optional[Any] = None\n    tool_error: Optional[str] = None\n    llm_temperature: Optional[float]  = None\n\n    # === 5. Strategie- und Kontext-Attribute ===\n    agent_name: Optional[str] = None\n    task_id: Optional[str] = None\n    plan_id: Optional[str] = None\n\n\n    # Node/Routing data\n    routing_decision: Optional[str] = None\n    node_phase: Optional[str] = None\n    node_duration: Optional[float] = None\n\n    # === 6. Metadaten (F\u00fcr alles andere) ===\n    metadata: dict[str, Any] = field(default_factory=dict)\n\n\n    def __post_init__(self):\n\n        if self.timestamp is None:\n            self.timestamp = time.time()\n\n        if self.metadata is None:\n            self.metadata = {}\n        if not self.event_id:\n            self.event_id = f\"{self.node_name}_{self.event_type}_{int(self.timestamp * 1000000)}\"\n        if 'error' in self.metadata or 'error_type' in self.metadata:\n            if self.error_details is None:\n                self.error_details = {}\n            self.error_details['error'] = self.metadata.get('error')\n            self.error_details['error_type'] = self.metadata.get('error_type')\n            self.status = NodeStatus.FAILED\n        if self.status == NodeStatus.FAILED:\n            self.success = False\n        if self.status == NodeStatus.COMPLETED:\n            self.success = True\n\n    def _to_dict(self) -&gt; dict[str, Any]:\n        \"\"\"Convert ProgressEvent to dictionary with proper handling of all field types\"\"\"\n        result = {}\n\n        # Get all fields from the dataclass\n        for field in fields(self):\n            value = getattr(self, field.name)\n\n            # Handle None values\n            if value is None:\n                result[field.name] = None\n                continue\n\n            # Handle NodeStatus enum\n            if isinstance(value, NodeStatus | Enum):\n                result[field.name] = value.value\n            # Handle dataclass objects\n            elif is_dataclass(value):\n                result[field.name] = asdict(value)\n            # Handle dictionaries (recursively process nested enums/dataclasses)\n            elif isinstance(value, dict):\n                result[field.name] = self._process_dict(value)\n            # Handle lists (recursively process nested items)\n            elif isinstance(value, list):\n                result[field.name] = self._process_list(value)\n            # Handle primitive types\n            else:\n                result[field.name] = value\n\n        return result\n\n    def _process_dict(self, d: dict[str, Any]) -&gt; dict[str, Any]:\n        \"\"\"Recursively process dictionary values\"\"\"\n        result = {}\n        for k, v in d.items():\n            if isinstance(v, Enum):\n                result[k] = v.value\n            elif is_dataclass(v):\n                result[k] = asdict(v)\n            elif isinstance(v, dict):\n                result[k] = self._process_dict(v)\n            elif isinstance(v, list):\n                result[k] = self._process_list(v)\n            else:\n                result[k] = v\n        return result\n\n    def _process_list(self, lst: list[Any]) -&gt; list[Any]:\n        \"\"\"Recursively process list items\"\"\"\n        result = []\n        for item in lst:\n            if isinstance(item, Enum):\n                result.append(item.value)\n            elif is_dataclass(item):\n                result.append(asdict(item))\n            elif isinstance(item, dict):\n                result.append(self._process_dict(item))\n            elif isinstance(item, list):\n                result.append(self._process_list(item))\n            else:\n                result.append(item)\n        return result\n\n    @classmethod\n    def from_dict(cls, data: dict[str, Any]) -&gt; 'ProgressEvent':\n        \"\"\"Create ProgressEvent from dictionary\"\"\"\n        # Create a copy to avoid modifying the original\n        data_copy = dict(data)\n\n        # Handle NodeStatus enum conversion from string back to enum\n        if 'status' in data_copy and data_copy['status'] is not None:\n            if isinstance(data_copy['status'], str):\n                try:\n                    data_copy['status'] = NodeStatus(data_copy['status'])\n                except (ValueError, TypeError):\n                    # If invalid status value, set to None\n                    data_copy['status'] = None\n\n        # Filter out any keys that aren't valid dataclass fields\n        field_names = {field.name for field in fields(cls)}\n        filtered_data = {k: v for k, v in data_copy.items() if k in field_names}\n\n        # Ensure metadata is properly initialized\n        if 'metadata' not in filtered_data or filtered_data['metadata'] is None:\n            filtered_data['metadata'] = {}\n\n        return cls(**filtered_data)\n\n    def to_dict(self) -&gt; dict[str, Any]:\n        \"\"\"Return event data with None values removed for compact display\"\"\"\n        data = self._to_dict()\n\n        def clean_dict(d):\n            if isinstance(d, dict):\n                return {k: clean_dict(v) for k, v in d.items()\n                        if v is not None and v != {} and v != [] and v != ''}\n            elif isinstance(d, list):\n                cleaned_list = [clean_dict(item) for item in d if item is not None]\n                return [item for item in cleaned_list if item != {} and item != []]\n            return d\n\n        return clean_dict(data)\n\n    def get_chat_display_data(self) -&gt; dict[str, Any]:\n        \"\"\"Get data optimized for chat view display\"\"\"\n        filtered = self.filter_none_values()\n\n        # Core fields always shown\n        core_data = {\n            'event_type': filtered.get('event_type'),\n            'node_name': filtered.get('node_name'),\n            'timestamp': filtered.get('timestamp'),\n            'event_id': filtered.get('event_id'),\n            'status': filtered.get('status')\n        }\n\n        # Add specific fields based on event type\n        if self.event_type == 'outline_created':\n            if 'metadata' in filtered:\n                core_data['outline_steps'] = len(filtered['metadata'].get('outline', []))\n        elif self.event_type == 'reasoning_loop':\n            if 'metadata' in filtered:\n                core_data.update({\n                    'loop_number': filtered['metadata'].get('loop_number'),\n                    'outline_step': filtered['metadata'].get('outline_step'),\n                    'context_size': filtered['metadata'].get('context_size')\n                })\n        elif self.event_type == 'tool_call':\n            core_data.update({\n                'tool_name': filtered.get('tool_name'),\n                'is_meta_tool': filtered.get('is_meta_tool')\n            })\n        elif self.event_type == 'llm_call':\n            core_data.update({\n                'llm_model': filtered.get('llm_model'),\n                'llm_total_tokens': filtered.get('llm_total_tokens'),\n                'llm_cost': filtered.get('llm_cost')\n            })\n\n        # Remove None values from core_data\n        return {k: v for k, v in core_data.items() if v is not None}\n\n    def get_detailed_display_data(self) -&gt; dict[str, Any]:\n        \"\"\"Get complete filtered data for detailed popup view\"\"\"\n        return self.filter_none_values()\n\n    def get_progress_summary(self) -&gt; str:\n        \"\"\"Get a brief summary for progress sidebar\"\"\"\n        if self.event_type == 'reasoning_loop' and 'metadata' in self.filter_none_values():\n            metadata = self.filter_none_values()['metadata']\n            loop_num = metadata.get('loop_number', '?')\n            step = metadata.get('outline_step', '?')\n            return f\"Loop {loop_num}, Step {step}\"\n        elif self.event_type == 'tool_call':\n            tool_name = self.tool_name or 'Unknown Tool'\n            return f\"{'Meta ' if self.is_meta_tool else ''}{tool_name}\"\n        elif self.event_type == 'llm_call':\n            model = self.llm_model or 'Unknown Model'\n            tokens = self.llm_total_tokens\n            return f\"{model} ({tokens} tokens)\" if tokens else model\n        else:\n            return self.event_type.replace('_', ' ').title()\n</code></pre> <code>from_dict(data)</code> <code>classmethod</code> \u00b6 <p>Create ProgressEvent from dictionary</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: dict[str, Any]) -&gt; 'ProgressEvent':\n    \"\"\"Create ProgressEvent from dictionary\"\"\"\n    # Create a copy to avoid modifying the original\n    data_copy = dict(data)\n\n    # Handle NodeStatus enum conversion from string back to enum\n    if 'status' in data_copy and data_copy['status'] is not None:\n        if isinstance(data_copy['status'], str):\n            try:\n                data_copy['status'] = NodeStatus(data_copy['status'])\n            except (ValueError, TypeError):\n                # If invalid status value, set to None\n                data_copy['status'] = None\n\n    # Filter out any keys that aren't valid dataclass fields\n    field_names = {field.name for field in fields(cls)}\n    filtered_data = {k: v for k, v in data_copy.items() if k in field_names}\n\n    # Ensure metadata is properly initialized\n    if 'metadata' not in filtered_data or filtered_data['metadata'] is None:\n        filtered_data['metadata'] = {}\n\n    return cls(**filtered_data)\n</code></pre> <code>get_chat_display_data()</code> \u00b6 <p>Get data optimized for chat view display</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def get_chat_display_data(self) -&gt; dict[str, Any]:\n    \"\"\"Get data optimized for chat view display\"\"\"\n    filtered = self.filter_none_values()\n\n    # Core fields always shown\n    core_data = {\n        'event_type': filtered.get('event_type'),\n        'node_name': filtered.get('node_name'),\n        'timestamp': filtered.get('timestamp'),\n        'event_id': filtered.get('event_id'),\n        'status': filtered.get('status')\n    }\n\n    # Add specific fields based on event type\n    if self.event_type == 'outline_created':\n        if 'metadata' in filtered:\n            core_data['outline_steps'] = len(filtered['metadata'].get('outline', []))\n    elif self.event_type == 'reasoning_loop':\n        if 'metadata' in filtered:\n            core_data.update({\n                'loop_number': filtered['metadata'].get('loop_number'),\n                'outline_step': filtered['metadata'].get('outline_step'),\n                'context_size': filtered['metadata'].get('context_size')\n            })\n    elif self.event_type == 'tool_call':\n        core_data.update({\n            'tool_name': filtered.get('tool_name'),\n            'is_meta_tool': filtered.get('is_meta_tool')\n        })\n    elif self.event_type == 'llm_call':\n        core_data.update({\n            'llm_model': filtered.get('llm_model'),\n            'llm_total_tokens': filtered.get('llm_total_tokens'),\n            'llm_cost': filtered.get('llm_cost')\n        })\n\n    # Remove None values from core_data\n    return {k: v for k, v in core_data.items() if v is not None}\n</code></pre> <code>get_detailed_display_data()</code> \u00b6 <p>Get complete filtered data for detailed popup view</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def get_detailed_display_data(self) -&gt; dict[str, Any]:\n    \"\"\"Get complete filtered data for detailed popup view\"\"\"\n    return self.filter_none_values()\n</code></pre> <code>get_progress_summary()</code> \u00b6 <p>Get a brief summary for progress sidebar</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def get_progress_summary(self) -&gt; str:\n    \"\"\"Get a brief summary for progress sidebar\"\"\"\n    if self.event_type == 'reasoning_loop' and 'metadata' in self.filter_none_values():\n        metadata = self.filter_none_values()['metadata']\n        loop_num = metadata.get('loop_number', '?')\n        step = metadata.get('outline_step', '?')\n        return f\"Loop {loop_num}, Step {step}\"\n    elif self.event_type == 'tool_call':\n        tool_name = self.tool_name or 'Unknown Tool'\n        return f\"{'Meta ' if self.is_meta_tool else ''}{tool_name}\"\n    elif self.event_type == 'llm_call':\n        model = self.llm_model or 'Unknown Model'\n        tokens = self.llm_total_tokens\n        return f\"{model} ({tokens} tokens)\" if tokens else model\n    else:\n        return self.event_type.replace('_', ' ').title()\n</code></pre> <code>to_dict()</code> \u00b6 <p>Return event data with None values removed for compact display</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Return event data with None values removed for compact display\"\"\"\n    data = self._to_dict()\n\n    def clean_dict(d):\n        if isinstance(d, dict):\n            return {k: clean_dict(v) for k, v in d.items()\n                    if v is not None and v != {} and v != [] and v != ''}\n        elif isinstance(d, list):\n            cleaned_list = [clean_dict(item) for item in d if item is not None]\n            return [item for item in cleaned_list if item != {} and item != []]\n        return d\n\n    return clean_dict(data)\n</code></pre> <code>ProgressTracker</code> \u00b6 <p>Advanced progress tracking with cost calculation</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>class ProgressTracker:\n    \"\"\"Advanced progress tracking with cost calculation\"\"\"\n\n    def __init__(self, progress_callback: callable  = None, agent_name=\"unknown\"):\n        self.progress_callback = progress_callback\n        self.events: list[ProgressEvent] = []\n        self.active_timers: dict[str, float] = {}\n\n        # Cost tracking (simplified - would need actual provider pricing)\n        self.token_costs = {\n            \"input\": 0.00001,  # $0.01/1K tokens input\n            \"output\": 0.00003,  # $0.03/1K tokens output\n        }\n        self.agent_name = agent_name\n\n    async def emit_event(self, event: ProgressEvent):\n        \"\"\"Emit progress event with callback and storage\"\"\"\n        self.events.append(event)\n        event.agent_name = self.agent_name\n\n        if self.progress_callback:\n            try:\n                if asyncio.iscoroutinefunction(self.progress_callback):\n                    await self.progress_callback(event)\n                else:\n                    self.progress_callback(event)\n            except Exception:\n                import traceback\n                print(traceback.format_exc())\n\n\n    def start_timer(self, key: str) -&gt; float:\n        \"\"\"Start timing operation\"\"\"\n        start_time = time.perf_counter()\n        self.active_timers[key] = start_time\n        return start_time\n\n    def end_timer(self, key: str) -&gt; float:\n        \"\"\"End timing operation and return duration\"\"\"\n        if key not in self.active_timers:\n            return 0.0\n        duration = time.perf_counter() - self.active_timers[key]\n        del self.active_timers[key]\n        return duration\n\n    def calculate_llm_cost(self, model: str, input_tokens: int, output_tokens: int,completion_response:Any=None) -&gt; float:\n        \"\"\"Calculate approximate LLM cost\"\"\"\n        try:\n            import litellm\n            cost = litellm.completion_cost(model=model, completion_response=completion_response)\n            return cost\n        except ImportError:\n            cost = 0.0\n        # Simplified cost calculation - would need actual provider pricing\n        input_cost = (input_tokens / 1000) * self.token_costs[\"input\"]\n        output_cost = (output_tokens / 1000) * self.token_costs[\"output\"]\n        return input_cost + output_cost\n\n    def get_summary(self) -&gt; dict[str, Any]:\n        \"\"\"Get comprehensive progress summary\"\"\"\n        summary = {\n            \"total_events\": len(self.events),\n            \"llm_calls\": len([e for e in self.events if e.event_type == \"llm_call\"]),\n            \"tool_calls\": len([e for e in self.events if e.event_type == \"tool_call\"]),\n            \"total_cost\": sum(e.llm_cost for e in self.events if e.llm_cost),\n            \"total_tokens\": sum(e.llm_total_tokens for e in self.events if e.llm_total_tokens),\n            \"total_duration\": sum(e.node_duration for e in self.events if e.node_duration),\n            \"nodes_visited\": list(set(e.node_name for e in self.events)),\n            \"tools_used\": list(set(e.tool_name for e in self.events if e.tool_name)),\n            \"models_used\": list(set(e.llm_model for e in self.events if e.llm_model))\n        }\n        return summary\n</code></pre> <code>calculate_llm_cost(model, input_tokens, output_tokens, completion_response=None)</code> \u00b6 <p>Calculate approximate LLM cost</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def calculate_llm_cost(self, model: str, input_tokens: int, output_tokens: int,completion_response:Any=None) -&gt; float:\n    \"\"\"Calculate approximate LLM cost\"\"\"\n    try:\n        import litellm\n        cost = litellm.completion_cost(model=model, completion_response=completion_response)\n        return cost\n    except ImportError:\n        cost = 0.0\n    # Simplified cost calculation - would need actual provider pricing\n    input_cost = (input_tokens / 1000) * self.token_costs[\"input\"]\n    output_cost = (output_tokens / 1000) * self.token_costs[\"output\"]\n    return input_cost + output_cost\n</code></pre> <code>emit_event(event)</code> <code>async</code> \u00b6 <p>Emit progress event with callback and storage</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>async def emit_event(self, event: ProgressEvent):\n    \"\"\"Emit progress event with callback and storage\"\"\"\n    self.events.append(event)\n    event.agent_name = self.agent_name\n\n    if self.progress_callback:\n        try:\n            if asyncio.iscoroutinefunction(self.progress_callback):\n                await self.progress_callback(event)\n            else:\n                self.progress_callback(event)\n        except Exception:\n            import traceback\n            print(traceback.format_exc())\n</code></pre> <code>end_timer(key)</code> \u00b6 <p>End timing operation and return duration</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def end_timer(self, key: str) -&gt; float:\n    \"\"\"End timing operation and return duration\"\"\"\n    if key not in self.active_timers:\n        return 0.0\n    duration = time.perf_counter() - self.active_timers[key]\n    del self.active_timers[key]\n    return duration\n</code></pre> <code>get_summary()</code> \u00b6 <p>Get comprehensive progress summary</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def get_summary(self) -&gt; dict[str, Any]:\n    \"\"\"Get comprehensive progress summary\"\"\"\n    summary = {\n        \"total_events\": len(self.events),\n        \"llm_calls\": len([e for e in self.events if e.event_type == \"llm_call\"]),\n        \"tool_calls\": len([e for e in self.events if e.event_type == \"tool_call\"]),\n        \"total_cost\": sum(e.llm_cost for e in self.events if e.llm_cost),\n        \"total_tokens\": sum(e.llm_total_tokens for e in self.events if e.llm_total_tokens),\n        \"total_duration\": sum(e.node_duration for e in self.events if e.node_duration),\n        \"nodes_visited\": list(set(e.node_name for e in self.events)),\n        \"tools_used\": list(set(e.tool_name for e in self.events if e.tool_name)),\n        \"models_used\": list(set(e.llm_model for e in self.events if e.llm_model))\n    }\n    return summary\n</code></pre> <code>start_timer(key)</code> \u00b6 <p>Start timing operation</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def start_timer(self, key: str) -&gt; float:\n    \"\"\"Start timing operation\"\"\"\n    start_time = time.perf_counter()\n    self.active_timers[key] = start_time\n    return start_time\n</code></pre> <code>ResponseFinalProcessorNode</code> \u00b6 <p>               Bases: <code>AsyncNode</code></p> <p>Finale Verarbeitung mit Persona-System</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>@with_progress_tracking\nclass ResponseFinalProcessorNode(AsyncNode):\n    \"\"\"Finale Verarbeitung mit Persona-System\"\"\"\n\n    async def prep_async(self, shared):\n        return {\n            \"formatted_response\": shared.get(\"formatted_response\", {}),\n            \"quality_assessment\": shared.get(\"quality_assessment\", {}),\n            \"conversation_history\": shared.get(\"conversation_history\", []),\n            \"persona\": shared.get(\"persona_config\"),\n            \"fast_llm_model\": shared.get(\"fast_llm_model\"),\n            \"use_fast_response\": shared.get(\"use_fast_response\", True),\n            \"agent_instance\": shared.get(\"agent_instance\"),\n        }\n\n    async def exec_async(self, prep_res):\n        response_data = prep_res[\"formatted_response\"]\n        raw_response = response_data.get(\"formatted_response\", \"I apologize, but I couldn't generate a response.\")\n\n        # Persona-basierte Anpassung\n        if prep_res.get(\"persona\") and LITELLM_AVAILABLE:\n            final_response = await self._apply_persona_style(raw_response, prep_res)\n        else:\n            final_response = raw_response\n\n        # Finale Metadaten\n        processing_metadata = {\n            \"response_confidence\": response_data.get(\"confidence\", 0.0),\n            \"quality_score\": prep_res.get(\"quality_assessment\", {}).get(\"quality_score\", 0.0),\n            \"processing_timestamp\": datetime.now().isoformat(),\n            \"response_length\": len(final_response),\n            \"persona_applied\": prep_res.get(\"persona\") is not None\n        }\n\n        return {\n            \"final_response\": final_response,\n            \"metadata\": processing_metadata,\n            \"status\": \"completed\"\n        }\n\n    async def _apply_persona_style(self, response: str, prep_res: dict) -&gt; str:\n        \"\"\"Optimized persona styling mit Konfiguration\"\"\"\n        persona = prep_res[\"persona\"]\n\n        # Nur anwenden wenn post-processing konfiguriert\n        if not persona.should_post_process():\n            return response\n\n        # Je nach Integration Level unterschiedliche Prompts\n        if persona.integration_level == \"light\":\n            style_prompt = f\"Make this {persona.tone} and {persona.style}: {response}\"\n            max_tokens = 400\n        elif persona.integration_level == \"medium\":\n            style_prompt = f\"\"\"\n    Apply {persona.name} persona (style: {persona.style}, tone: {persona.tone}) to:\n    {response}\n\n    Keep the same information, adjust presentation:\"\"\"\n            max_tokens = 600\n        else:  # heavy\n            style_prompt = f\"\"\"\nCompletely transform as {persona.name}:\nStyle: {persona.style}, Tone: {persona.tone}\nTraits: {', '.join(persona.personality_traits)}\nInstructions: {persona.custom_instructions}\n\nOriginal: {response}\n\nAs {persona.name}:\"\"\"\n            max_tokens = 1000\n\n        try:\n            model_to_use = prep_res.get(\"fast_llm_model\", \"openrouter/anthropic/claude-3-haiku\")\n            agent_instance = prep_res[\"agent_instance\"]\n            if prep_res.get(\"use_fast_response\", True):\n                response = await agent_instance.a_run_llm_completion(\n                    model=model_to_use,\n                    messages=[{\"role\": \"user\", \"content\": style_prompt}],\n                    temperature=0.5,\n                    max_tokens=max_tokens, node_name=\"PersonaStylingNode\", task_id=\"persona_styling_fast\"\n                )\n            else:\n                response = await agent_instance.a_run_llm_completion(\n                    model=model_to_use,\n                    messages=[{\"role\": \"user\", \"content\": style_prompt}],\n                    temperature=0.6,\n                    max_tokens=max_tokens + 200, node_name=\"PersonaStylingNode\", task_id=\"persona_styling_ritch\"\n                )\n\n            return response.strip()\n\n        except Exception as e:\n            wprint(f\"Persona styling failed: {e}\")\n            return response\n\n    async def post_async(self, shared, prep_res, exec_res):\n        shared[\"current_response\"] = exec_res[\"final_response\"]\n        shared[\"response_metadata\"] = exec_res[\"metadata\"]\n        return \"response_ready\"\n</code></pre> <code>ResponseFormatterNode</code> \u00b6 <p>               Bases: <code>AsyncNode</code></p> <p>Formatiere finale Antwort f\u00fcr Benutzer</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>@with_progress_tracking\nclass ResponseFormatterNode(AsyncNode):\n    \"\"\"Formatiere finale Antwort f\u00fcr Benutzer\"\"\"\n\n    async def prep_async(self, shared):\n        return {\n            \"synthesized_response\": shared.get(\"synthesized_response\", {}),\n            \"original_query\": shared.get(\"current_query\", \"\"),\n            \"user_preferences\": shared.get(\"user_preferences\", {})\n        }\n\n    async def exec_async(self, prep_res):\n        synthesis_data = prep_res[\"synthesized_response\"]\n        raw_response = synthesis_data.get(\"synthesized_response\", \"\")\n\n        if not raw_response:\n            return {\n                \"formatted_response\": \"I apologize, but I was unable to generate a meaningful response to your query.\"}\n\n        # Basis-Formatierung\n        formatted_response = raw_response.strip()\n\n        # F\u00fcge Metadaten hinzu falls gew\u00fcnscht (f\u00fcr debugging/transparency)\n        confidence = synthesis_data.get(\"confidence\", 0.0)\n        if confidence &lt; 0.4:\n            formatted_response += \"\\n\\n*Note: This response has low confidence due to limited information.*\"\n\n        adaptation_note = \"\"\n        synthesis_method = synthesis_data.get(\"synthesis_method\", \"unknown\")\n        if synthesis_method == \"fallback\":\n            adaptation_note = \"\\n\\n*Note: Response generated with limited processing capabilities.*\"\n\n        return {\n            \"formatted_response\": formatted_response + adaptation_note,\n            \"confidence\": confidence,\n            \"metadata\": {\n                \"synthesis_method\": synthesis_method,\n                \"response_length\": len(formatted_response)\n            }\n        }\n\n    async def post_async(self, shared, prep_res, exec_res):\n        shared[\"formatted_response\"] = exec_res\n        return \"formatted\"\n</code></pre> <code>ResponseGenerationFlow</code> \u00b6 <p>               Bases: <code>AsyncFlow</code></p> <p>Intelligente Antwortgenerierung basierend auf Task-Ergebnissen</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>@with_progress_tracking\nclass ResponseGenerationFlow(AsyncFlow):\n    \"\"\"Intelligente Antwortgenerierung basierend auf Task-Ergebnissen\"\"\"\n\n    def __init__(self, tools=None):\n        # Nodes f\u00fcr Response-Pipeline\n        self.context_aggregator = ContextAggregatorNode()\n        self.result_synthesizer = ResultSynthesizerNode()\n        self.response_formatter = ResponseFormatterNode()\n        self.quality_checker = ResponseQualityNode()\n        self.final_processor = ResponseFinalProcessorNode()\n\n        # === RESPONSE GENERATION PIPELINE ===\n\n        # Context Aggregation -&gt; Synthesis\n        self.context_aggregator - \"context_ready\" &gt;&gt; self.result_synthesizer\n        self.context_aggregator - \"no_context\" &gt;&gt; self.response_formatter  # Fallback\n\n        # Synthesis -&gt; Formatting\n        self.result_synthesizer - \"synthesized\" &gt;&gt; self.response_formatter\n        self.result_synthesizer - \"synthesis_failed\" &gt;&gt; self.response_formatter\n\n        # Formatting -&gt; Quality Check\n        self.response_formatter - \"formatted\" &gt;&gt; self.quality_checker\n        self.response_formatter - \"format_failed\" &gt;&gt; self.final_processor  # Skip quality check\n\n        # Quality Check -&gt; Final Processing oder Retry\n        self.quality_checker - \"quality_good\" &gt;&gt; self.final_processor\n        self.quality_checker - \"quality_poor\" &gt;&gt; self.result_synthesizer  # Retry synthesis\n        self.quality_checker - \"quality_acceptable\" &gt;&gt; self.final_processor\n\n        super().__init__(start=self.context_aggregator)\n</code></pre> <code>ResponseQualityNode</code> \u00b6 <p>               Bases: <code>AsyncNode</code></p> <p>Pr\u00fcfe Qualit\u00e4t der generierten Antwort</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>@with_progress_tracking\nclass ResponseQualityNode(AsyncNode):\n    \"\"\"Pr\u00fcfe Qualit\u00e4t der generierten Antwort\"\"\"\n\n    async def prep_async(self, shared):\n        return {\n            \"formatted_response\": shared.get(\"formatted_response\", {}),\n            \"original_query\": shared.get(\"current_query\", \"\"),\n            \"format_config\": self._get_format_config(shared),\n            \"fast_llm_model\": shared.get(\"fast_llm_model\"),\n            \"persona_config\": shared.get(\"persona_config\"),\n            \"agent_instance\": shared.get(\"agent_instance\"),\n        }\n\n    def _get_format_config(self, shared) -&gt; FormatConfig | None:\n        \"\"\"Extrahiere Format-Konfiguration\"\"\"\n        persona = shared.get(\"persona_config\")\n        if persona and hasattr(persona, 'format_config'):\n            return persona.format_config\n        return None\n\n    async def exec_async(self, prep_res):\n        response_data = prep_res[\"formatted_response\"]\n        response_text = response_data.get(\"formatted_response\", \"\")\n        original_query = prep_res[\"original_query\"]\n        format_config = prep_res[\"format_config\"]\n\n        # Basis-Qualit\u00e4tspr\u00fcfung\n        base_quality = self._heuristic_quality_check(response_text, original_query)\n\n        # Format-spezifische Bewertung\n        format_quality = await self._evaluate_format_adherence(response_text, format_config)\n\n        # L\u00e4ngen-spezifische Bewertung\n        length_quality = self._evaluate_length_adherence(response_text, format_config)\n\n        # LLM-basierte Gesamtbewertung\n        llm_quality = 0.5\n        if LITELLM_AVAILABLE and len(response_text) &gt; 500:\n            llm_quality = await self._llm_format_quality_check(\n                response_text, original_query, format_config, prep_res\n            )\n\n        # Gewichtete Gesamtbewertung\n        total_quality = (\n            base_quality * 0.3 +\n            format_quality * 0.3 +\n            length_quality * 0.2 +\n            llm_quality * 0.2\n        )\n\n        quality_details = {\n            \"total_score\": total_quality,\n            \"base_quality\": base_quality,\n            \"format_adherence\": format_quality,\n            \"length_adherence\": length_quality,\n            \"llm_assessment\": llm_quality,\n            \"format_config_used\": format_config is not None\n        }\n\n        return {\n            \"quality_score\": total_quality,\n            \"quality_assessment\": self._score_to_assessment(total_quality),\n            \"quality_details\": quality_details,\n            \"suggestions\": self._generate_format_quality_suggestions(\n                total_quality, response_text, format_config, quality_details\n            )\n        }\n\n    async def _evaluate_format_adherence(self, response: str, format_config: FormatConfig | None) -&gt; float:\n        \"\"\"Bewerte Format-Einhaltung\"\"\"\n        if not format_config:\n            return 0.8  # Neutral wenn kein Format vorgegeben\n\n        format_type = format_config.response_format\n        score = 0.5\n\n        # Format-spezifische Checks\n        if format_type == ResponseFormat.WITH_TABLES:\n            if '|' in response or 'Table:' in response or '| ' in response:\n                score += 0.4\n\n        elif format_type == ResponseFormat.WITH_BULLET_POINTS:\n            bullet_count = response.count('\u2022') + response.count('-') + response.count('*')\n            if bullet_count &gt;= 2:\n                score += 0.4\n            elif bullet_count &gt;= 1:\n                score += 0.2\n\n        elif format_type == ResponseFormat.WITH_LISTS:\n            list_patterns = ['1.', '2.', '3.', 'a)', 'b)', 'c)']\n            list_score = sum(1 for pattern in list_patterns if pattern in response)\n            score += min(0.4, list_score * 0.1)\n\n        elif format_type == ResponseFormat.MD_TEXT:\n            md_elements = ['#', '**', '*', '`', '```', '[', ']', '(', ')']\n            md_score = sum(1 for element in md_elements if element in response)\n            score += min(0.4, md_score * 0.05)\n\n        elif format_type == ResponseFormat.YAML_TEXT:\n            if response.strip().startswith(('```yaml', '---')) or ': ' in response:\n                score += 0.4\n\n        elif format_type == ResponseFormat.JSON_TEXT:\n            if response.strip().startswith(('{', '[')):\n                try:\n                    json.loads(response)\n                    score += 0.4\n                except:\n                    score += 0.1  # Partial credit for JSON-like structure\n\n        elif format_type == ResponseFormat.TEXT_ONLY:\n            # Penalize if formatting elements are present\n            format_elements = ['#', '*', '|', '```', '1.', '\u2022', '-']\n            format_count = sum(1 for element in format_elements if element in response)\n            score += max(0.1, 0.5 - format_count * 0.05)\n\n        elif format_type == ResponseFormat.PSEUDO_CODE:\n            code_indicators = ['if ', 'for ', 'while ', 'def ', 'return ', 'function', 'BEGIN', 'END']\n            code_score = sum(1 for indicator in code_indicators if indicator in response)\n            score += min(0.4, code_score * 0.1)\n\n        return max(0.0, min(1.0, score))\n\n    def _evaluate_length_adherence(self, response: str, format_config: FormatConfig | None) -&gt; float:\n        \"\"\"Bewerte L\u00e4ngen-Einhaltung\"\"\"\n        if not format_config:\n            return 0.8\n\n        word_count = len(response.split())\n        min_words, max_words = format_config.get_expected_word_range()\n\n        if min_words &lt;= word_count &lt;= max_words:\n            return 1.0\n        elif word_count &lt; min_words:\n            # Zu kurz - sanfte Bestrafung\n            ratio = word_count / min_words\n            return max(0.3, ratio * 0.8)\n        else:  # word_count &gt; max_words\n            # Zu lang - weniger Bestrafung als zu kurz\n            excess_ratio = (word_count - max_words) / max_words\n            return max(0.4, 1.0 - excess_ratio * 0.3)\n\n    async def _llm_format_quality_check(\n        self,\n        response: str,\n        query: str,\n        format_config: FormatConfig | None,\n        prep_res: dict\n    ) -&gt; float:\n        \"\"\"LLM-basierte Format- und Qualit\u00e4tsbewertung\"\"\"\n        if not format_config:\n            return await self._standard_llm_quality_check(response, query, prep_res)\n\n        format_desc = format_config.get_format_instructions()\n        length_desc = format_config.get_length_instructions()\n\n        prompt = f\"\"\"\nBewerte diese Antwort auf einer Skala von 0.0 bis 1.0 basierend auf Format-Einhaltung und Qualit\u00e4t:\n\nBenutzer-Anfrage: {query}\n\nAntwort: {response}\n\nErwartetes Format: {format_desc}\nErwartete L\u00e4nge: {length_desc}\n\nBewertungskriterien:\n1. Format-Einhaltung (40%): Entspricht die Antwort dem geforderten Format?\n2. L\u00e4ngen-Angemessenheit (25%): Ist die L\u00e4nge angemessen?\n3. Inhaltliche Qualit\u00e4t (25%): Beantwortet die Anfrage vollst\u00e4ndig?\n4. Lesbarkeit und Struktur (10%): Ist die Antwort gut strukturiert?\n\nAntworte nur mit einer Zahl zwischen 0.0 und 1.0:\"\"\"\n\n        try:\n            model_to_use = prep_res.get(\"fast_llm_model\", \"openrouter/anthropic/claude-3-haiku\")\n            agent_instance = prep_res[\"agent_instance\"]\n            score_text = (await agent_instance.a_run_llm_completion(\n                model=model_to_use,\n                messages=[{\"role\": \"user\", \"content\": prompt}],\n                temperature=0.1,\n                max_tokens=10,\n                node_name=\"QualityAssessmentNode\", task_id=\"format_quality_assessment\"\n            )).strip()\n\n            return float(score_text)\n\n        except Exception as e:\n            wprint(f\"LLM format quality check failed: {e}\")\n            return 0.6  # Neutral fallback\n\n    def _generate_format_quality_suggestions(\n        self,\n        score: float,\n        response: str,\n        format_config: FormatConfig | None,\n        quality_details: dict\n    ) -&gt; list[str]:\n        \"\"\"Generiere Format-spezifische Verbesserungsvorschl\u00e4ge\"\"\"\n        suggestions = []\n\n        if not format_config:\n            return [\"Consider defining a specific response format for better consistency\"]\n\n        # Format-spezifische Vorschl\u00e4ge\n        if quality_details[\"format_adherence\"] &lt; 0.6:\n            format_type = format_config.response_format\n\n            if format_type == ResponseFormat.WITH_TABLES:\n                suggestions.append(\"Add tables using markdown format (| Column | Column |)\")\n            elif format_type == ResponseFormat.WITH_BULLET_POINTS:\n                suggestions.append(\"Use bullet points (\u2022, -, *) to structure information\")\n            elif format_type == ResponseFormat.MD_TEXT:\n                suggestions.append(\"Use markdown formatting (headers, bold, code blocks)\")\n            elif format_type == ResponseFormat.YAML_TEXT:\n                suggestions.append(\"Format response as valid YAML structure\")\n            elif format_type == ResponseFormat.JSON_TEXT:\n                suggestions.append(\"Format response as valid JSON\")\n\n        # L\u00e4ngen-spezifische Vorschl\u00e4ge\n        if quality_details[\"length_adherence\"] &lt; 0.6:\n            word_count = len(response.split())\n            min_words, max_words = format_config.get_expected_word_range()\n\n            if word_count &lt; min_words:\n                suggestions.append(f\"Response too short ({word_count} words). Aim for {min_words}-{max_words} words\")\n            else:\n                suggestions.append(f\"Response too long ({word_count} words). Aim for {min_words}-{max_words} words\")\n\n        # Qualit\u00e4ts-spezifische Vorschl\u00e4ge\n        if score &lt; 0.5:\n            suggestions.append(\"Overall quality needs improvement - consider regenerating\")\n        elif score &lt; 0.7:\n            suggestions.append(\"Good response but could be enhanced with better format adherence\")\n\n        return suggestions\n\n    async def _standard_llm_quality_check(self, response: str, query: str, prep_res: dict) -&gt; float:\n        \"\"\"Standard LLM-Qualit\u00e4tspr\u00fcfung ohne Format-Fokus\"\"\"\n        # Bestehende Implementierung beibehalten\n        return await self._llm_quality_check(response, query, prep_res)\n\n    def _heuristic_quality_check(self, response: str, query: str) -&gt; float:\n        \"\"\"Heuristische Qualit\u00e4tspr\u00fcfung\"\"\"\n        score = 0.5  # Base score\n\n        # Length check\n        if len(response) &lt; 50:\n            score -= 0.3\n        elif len(response) &gt; 100:\n            score += 0.2\n\n        # Query term coverage\n        query_terms = set(query.lower().split())\n        response_terms = set(response.lower().split())\n        coverage = len(query_terms.intersection(response_terms)) / max(len(query_terms), 1)\n        score += coverage * 0.3\n\n        # Structure indicators\n        if any(indicator in response for indicator in [\":\", \"-\", \"1.\", \"\u2022\"]):\n            score += 0.1  # Structured response bonus\n\n        return max(0.0, min(1.0, score))\n\n    async def _llm_quality_check(self, response: str, query: str, prep_res: dict) -&gt; float:\n        \"\"\"LLM-basierte Qualit\u00e4tspr\u00fcfung\"\"\"\n        try:\n            prompt = f\"\"\"\nRate the quality of this response to the user's query on a scale of 0.0 to 1.0.\n\nUser Query: {query}\n\nResponse: {response}\n\nConsider:\n- Relevance to the query\n- Completeness of information\n- Clarity and readability\n- Accuracy (if verifiable)\n\nRespond with just a number between 0.0 and 1.0:\"\"\"\n\n            model_to_use = prep_res.get(\"fast_llm_model\", \"openrouter/anthropic/claude-3-haiku\")\n            agent_instance = prep_res[\"agent_instance\"]\n            score_text = (await agent_instance.a_run_llm_completion(\n                model=model_to_use,\n                messages=[{\"role\": \"user\", \"content\": prompt}],\n                temperature=0.1,\n                max_tokens=10,\n                node_name=\"QualityAssessmentNode\", task_id=\"quality_assessment\"\n            )).strip()\n\n            return float(score_text)\n\n        except:\n            return 0.5  # Fallback score\n\n    def _score_to_assessment(self, score: float) -&gt; str:\n        if score &gt;= 0.8:\n            return \"quality_good\"\n        elif score &gt;= 0.5:\n            return \"quality_acceptable\"\n        else:\n            return \"quality_poor\"\n\n    async def post_async(self, shared, prep_res, exec_res):\n        shared[\"quality_assessment\"] = exec_res\n        return exec_res[\"quality_assessment\"]\n</code></pre> <code>ResultSynthesizerNode</code> \u00b6 <p>               Bases: <code>AsyncNode</code></p> <p>Synthetisiere finale Antwort aus allen Ergebnissen</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>@with_progress_tracking\nclass ResultSynthesizerNode(AsyncNode):\n    \"\"\"Synthetisiere finale Antwort aus allen Ergebnissen\"\"\"\n\n    async def prep_async(self, shared):\n        return {\n            \"aggregated_context\": shared.get(\"aggregated_context\", {}),\n            \"fast_llm_model\": shared.get(\"fast_llm_model\"),\n            \"complex_llm_model\": shared.get(\"complex_llm_model\"),\n            \"agent_instance\": shared.get(\"agent_instance\")\n        }\n\n    async def exec_async(self, prep_res):\n        if not LITELLM_AVAILABLE:\n            return await self._fallback_synthesis(prep_res)\n\n        context = prep_res[\"aggregated_context\"]\n        persona = (prep_res['agent_instance'].amd.persona.to_system_prompt_addition() if not prep_res['agent_instance'].amd.persona.should_post_process() else '') if prep_res['agent_instance'].amd.persona else None\n        prompt = f\"\"\"\nDu bist ein Experte f\u00fcr Informationssynthese. Erstelle eine umfassende, hilfreiche Antwort basierend auf den gesammelten Ergebnissen.\n\n## Urspr\u00fcngliche Anfrage\n{context.get('original_query', '')}\n\n## Erfolgreiche Ergebnisse\n{self._format_successful_results(context.get('successful_results', {}))}\n\n## Wichtige Entdeckungen\n{self._format_key_discoveries(context.get('key_discoveries', []))}\n\n## Plan-Adaptationen\n{context.get('adaptation_summary', 'No adaptations were needed.')}\n\n## Fehlgeschlagene Versuche\n{self._format_failed_attempts(context.get('failed_attempts', {}))}\n\n{persona}\n\n## Anweisungen\n1. Gib eine direkte, hilfreiche Antwort auf die urspr\u00fcngliche Anfrage\n2. Integriere alle relevanten gefundenen Informationen\n3. Erkl\u00e4re kurz den Prozess, falls Adaptationen n\u00f6tig waren\n4. Sei ehrlich \u00fcber Limitationen oder fehlende Informationen\n5. Strukturiere die Antwort logisch und lesbar\n\nErstelle eine finale Antwort:\"\"\"\n\n        try:\n            # Verwende complex model f\u00fcr finale Synthesis\n            model_to_use = prep_res.get(\"complex_llm_model\", \"openrouter/openai/gpt-4o\")\n            agent_instance = prep_res[\"agent_instance\"]\n            synthesized_response = await agent_instance.a_run_llm_completion(\n                model=model_to_use,\n                messages=[{\"role\": \"user\", \"content\": prompt}],\n                temperature=0.3,\n                max_tokens=1500,\n                node_name=\"ResultSynthesizerNode\", task_id=\"response_synthesis\"\n            )\n\n            return {\n                \"synthesized_response\": synthesized_response,\n                \"synthesis_method\": \"llm\",\n                \"model_used\": model_to_use,\n                \"confidence\": self._estimate_synthesis_confidence(context)\n            }\n\n        except Exception as e:\n            eprint(f\"LLM synthesis failed: {e}\")\n            return await self._fallback_synthesis(prep_res)\n\n    def _format_successful_results(self, results: dict) -&gt; str:\n        formatted = []\n        for _task_id, result_info in results.items():\n            formatted.append(f\"- {result_info['task_description']}: {str(result_info['result'])[:20000]}...\")\n        return \"\\n\".join(formatted) if formatted else \"No successful results to report.\"\n\n    def _format_key_discoveries(self, discoveries: list) -&gt; str:\n        formatted = []\n        for discovery in discoveries:\n            confidence = discovery.get('confidence', 0.0)\n            formatted.append(f\"- {discovery['discovery']} (Confidence: {confidence:.2f})\")\n        return \"\\n\".join(formatted) if formatted else \"No key discoveries.\"\n\n    def _format_failed_attempts(self, failed: dict) -&gt; str:\n        if not failed:\n            return \"No significant failures.\"\n        formatted = [f\"- {info['description']}: {info['error']}\" for info in failed.values()]\n        return \"\\n\".join(formatted)\n\n    async def _fallback_synthesis(self, prep_res) -&gt; dict:\n        \"\"\"Fallback synthesis ohne LLM\"\"\"\n        context = prep_res[\"aggregated_context\"]\n\n        # Einfache Template-basierte Synthese\n        response_parts = []\n\n        if context.get(\"key_discoveries\"):\n            response_parts.append(\"Based on my analysis, I found:\")\n            for discovery in context[\"key_discoveries\"][:3]:  # Top 3\n                response_parts.append(f\"- {discovery['discovery']}\")\n\n        if context.get(\"successful_results\"):\n            response_parts.append(\"\\nDetailed results:\")\n            for _task_id, result in list(context[\"successful_results\"].items())[:2]:  # Top 2\n                response_parts.append(f\"- {result['task_description']}: {str(result['result'])[:150]}\")\n\n        if context.get(\"adaptation_summary\"):\n            response_parts.append(f\"\\n{context['adaptation_summary']}\")\n\n        fallback_response = \"\\n\".join(\n            response_parts) if response_parts else \"I was unable to complete the requested task effectively.\"\n\n        return {\n            \"synthesized_response\": fallback_response,\n            \"synthesis_method\": \"fallback\",\n            \"confidence\": 0.3\n        }\n\n    def _estimate_synthesis_confidence(self, context: dict) -&gt; float:\n        \"\"\"Sch\u00e4tze Confidence der Synthese\"\"\"\n        confidence = 0.5  # Base confidence\n\n        # Boost f\u00fcr erfolgreiche Ergebnisse\n        successful_count = len(context.get(\"successful_results\", {}))\n        confidence += min(successful_count * 0.15, 0.3)\n\n        # Boost f\u00fcr key discoveries mit hoher confidence\n        for discovery in context.get(\"key_discoveries\", []):\n            discovery_conf = discovery.get(\"confidence\", 0.0)\n            confidence += discovery_conf * 0.1\n\n        # Penalty f\u00fcr viele fehlgeschlagene Versuche\n        failed_count = len(context.get(\"failed_attempts\", {}))\n        confidence -= min(failed_count * 0.1, 0.2)\n\n        return max(0.1, min(1.0, confidence))\n\n    async def post_async(self, shared, prep_res, exec_res):\n        shared[\"synthesized_response\"] = exec_res\n        if exec_res.get(\"synthesized_response\"):\n            return \"synthesized\"\n        else:\n            return \"synthesis_failed\"\n</code></pre> <code>StateSyncNode</code> \u00b6 <p>               Bases: <code>AsyncNode</code></p> <p>Synchronize state between world model and shared store</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>@with_progress_tracking\nclass StateSyncNode(AsyncNode):\n    \"\"\"Synchronize state between world model and shared store\"\"\"\n    async def prep_async(self, shared):\n        world_model = shared.get(\"world_model\", {})\n        session_data = shared.get(\"session_data\", {})\n        tasks = shared.get(\"tasks\", {})\n        system_status = shared.get(\"system_status\", \"idle\")\n\n        return {\n            \"world_model\": world_model,\n            \"session_data\": session_data,\n            \"tasks\": tasks,\n            \"system_status\": system_status,\n            \"sync_timestamp\": datetime.now().isoformat()\n        }\n\n    async def exec_async(self, prep_res):\n        # Perform intelligent state synchronization\n        sync_result = {\n            \"world_model_updates\": {},\n            \"session_updates\": {},\n            \"task_updates\": {},\n            \"conflicts_resolved\": [],\n            \"sync_successful\": True\n        }\n\n        # Update world model with new information\n        if \"current_response\" in prep_res:\n            # Extract learnable facts from responses\n            extracted_facts = self._extract_facts(prep_res.get(\"current_response\", \"\"))\n            sync_result[\"world_model_updates\"].update(extracted_facts)\n\n        # Sync task states\n        for task_id, task in prep_res[\"tasks\"].items():\n            if task.status == \"completed\" and task.result:\n                # Store task results in world model\n                fact_key = f\"task_{task_id}_result\"\n                sync_result[\"world_model_updates\"][fact_key] = task.result\n\n        return sync_result\n\n    def _extract_facts(self, text: str) -&gt; dict[str, Any]:\n        \"\"\"Extract learnable facts from text\"\"\"\n        facts = {}\n        lines = text.split('\\n')\n\n        for line in lines:\n            line = line.strip()\n            # Look for definitive statements\n            if ' is ' in line and not line.startswith('I ') and not '?' in line:\n                parts = line.split(' is ', 1)\n                if len(parts) == 2:\n                    subject = parts[0].strip().lower()\n                    predicate = parts[1].strip().rstrip('.')\n                    if len(subject.split()) &lt;= 3:  # Keep subjects simple\n                        facts[subject] = predicate\n\n        return facts\n\n    async def post_async(self, shared, prep_res, exec_res):\n        # Apply the synchronization results\n        if exec_res[\"sync_successful\"]:\n            shared[\"world_model\"].update(exec_res[\"world_model_updates\"])\n            shared[\"session_data\"].update(exec_res[\"session_updates\"])\n            shared[\"last_sync\"] = datetime.now()\n            return \"sync_complete\"\n        else:\n            wprint(\"State synchronization failed\")\n            return \"sync_failed\"\n</code></pre> <code>Task</code> <code>dataclass</code> \u00b6 Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>@dataclass\nclass Task:\n    id: str\n    type: str\n    description: str\n    status: str = \"pending\"  # pending, running, completed, failed, paused\n    priority: int = 1\n    dependencies: list[str] = field(default_factory=list)\n    subtasks: list[str] = field(default_factory=list)\n    result: Any = None\n    error: str = None\n    created_at: datetime = field(default_factory=datetime.now)\n    started_at: datetime  = None\n    completed_at: datetime  = None\n    metadata: dict[str, Any] = field(default_factory=dict)\n    retry_count: int = 0\n    max_retries: int = 3\n    critical: bool = False\n\n    task_identification_attr: bool = True\n\n\n    def __post_init__(self):\n        \"\"\"Ensure all mutable defaults are properly initialized\"\"\"\n        if self.metadata is None:\n            self.metadata = {}\n        if self.dependencies is None:\n            self.dependencies = []\n        if self.subtasks is None:\n            self.subtasks = []\n\n    def __getitem__(self, key):\n        return getattr(self, key)\n\n    def __setitem__(self, key, value):\n        setattr(self, key, value)\n</code></pre> <code>__post_init__()</code> \u00b6 <p>Ensure all mutable defaults are properly initialized</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def __post_init__(self):\n    \"\"\"Ensure all mutable defaults are properly initialized\"\"\"\n    if self.metadata is None:\n        self.metadata = {}\n    if self.dependencies is None:\n        self.dependencies = []\n    if self.subtasks is None:\n        self.subtasks = []\n</code></pre> <code>TaskExecutorNode</code> \u00b6 <p>               Bases: <code>AsyncNode</code></p> <p>Vollst\u00e4ndige Task-Ausf\u00fchrung als unabh\u00e4ngige Node mit LLM-unterst\u00fctzter Planung</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>@with_progress_tracking\nclass TaskExecutorNode(AsyncNode):\n    \"\"\"Vollst\u00e4ndige Task-Ausf\u00fchrung als unabh\u00e4ngige Node mit LLM-unterst\u00fctzter Planung\"\"\"\n\n    def __init__(self, max_parallel: int = 3, **kwargs):\n        super().__init__(**kwargs)\n        self.max_parallel = max_parallel\n        self.results_store = {}  # F\u00fcr {{ }} Referenzen\n        self.execution_history = []  # F\u00fcr LLM-basierte Optimierung\n        self.agent_instance = None  # Wird gesetzt vom FlowAgent\n        self.variable_manager = None\n        self.fast_llm_model = None\n        self.complex_llm_model = None\n        self.progress_tracker = None\n\n    async def prep_async(self, shared):\n        \"\"\"Enhanced preparation with unified variable system\"\"\"\n        current_plan = shared.get(\"current_plan\")\n        tasks = shared.get(\"tasks\", {})\n\n        # Get unified variable manager\n        self.variable_manager = shared.get(\"variable_manager\")\n        self.progress_tracker = shared.get(\"progress_tracker\")\n        if not self.variable_manager:\n            self.variable_manager = VariableManager(shared.get(\"world_model\", {}), shared)\n\n        # Register all necessary scopes\n        self.variable_manager.set_results_store(self.results_store)\n        self.variable_manager.set_tasks_store(tasks)\n        self.variable_manager.register_scope('user', shared.get('user_context', {}))\n        self.variable_manager.register_scope('system', {\n            'timestamp': datetime.now().isoformat(),\n            'agent_name': shared.get('agent_instance', {}).amd.name if shared.get('agent_instance') else 'unknown'\n        })\n\n        # Stelle sicher, dass Agent-Referenz verf\u00fcgbar ist\n        if not self.agent_instance:\n            self.agent_instance = shared.get(\"agent_instance\")\n\n        if not current_plan:\n            return {\"error\": \"No active plan\", \"tasks\": tasks}\n\n        # Rest of existing prep_async logic...\n        ready_tasks = self._find_ready_tasks(current_plan, tasks)\n        blocked_tasks = self._find_blocked_tasks(current_plan, tasks)\n\n        execution_plan = await self._create_intelligent_execution_plan(\n            ready_tasks, blocked_tasks, current_plan, shared\n        )\n        self.complex_llm_model = shared.get(\"complex_llm_model\")\n        self.fast_llm_model = shared.get(\"fast_llm_model\")\n\n        return {\n            \"plan\": current_plan,\n            \"ready_tasks\": ready_tasks,\n            \"blocked_tasks\": blocked_tasks,\n            \"all_tasks\": tasks,\n            \"execution_plan\": execution_plan,\n            \"fast_llm_model\": self.fast_llm_model,\n            \"complex_llm_model\": self.complex_llm_model,\n            \"available_tools\": shared.get(\"available_tools\", []),\n            \"world_model\": shared.get(\"world_model\", {}),\n            \"results\": self.results_store,\n            \"variable_manager\": self.variable_manager,\n            \"progress_tracker\": self.progress_tracker ,\n        }\n\n    def _find_ready_tasks(self, plan: TaskPlan, all_tasks: dict[str, Task]) -&gt; list[Task]:\n        \"\"\"Finde Tasks die zur Ausf\u00fchrung bereit sind\"\"\"\n        ready = []\n        for task in plan.tasks:\n            if task.status == \"pending\" and self._dependencies_satisfied(task, all_tasks):\n                ready.append(task)\n        return ready\n\n    def _find_blocked_tasks(self, plan: TaskPlan, all_tasks: dict[str, Task]) -&gt; list[Task]:\n        \"\"\"Finde blockierte Tasks f\u00fcr Analyse\"\"\"\n        blocked = []\n        for task in plan.tasks:\n            if task.status == \"pending\" and not self._dependencies_satisfied(task, all_tasks):\n                blocked.append(task)\n        return blocked\n\n    def _dependencies_satisfied(self, task: Task, all_tasks: dict[str, Task]) -&gt; bool:\n        \"\"\"Pr\u00fcfe ob alle Dependencies erf\u00fcllt sind\"\"\"\n        for dep_id in task.dependencies:\n            if dep_id in all_tasks:\n                dep_task = all_tasks[dep_id]\n                if dep_task.status not in [\"completed\"]:\n                    return False\n            else:\n                # Dependency existiert nicht - k\u00f6nnte Problem sein\n                wprint(f\"Task {task.id} has missing dependency: {dep_id}\")\n                return False\n        return True\n\n    async def _create_intelligent_execution_plan(\n        self,\n        ready_tasks: list[Task],\n        blocked_tasks: list[Task],\n        plan: TaskPlan,\n        shared: dict\n    ) -&gt; dict[str, Any]:\n        \"\"\"LLM-unterst\u00fctzte intelligente Ausf\u00fchrungsplanung\"\"\"\n\n        if not ready_tasks:\n            return {\n                \"strategy\": \"waiting\",\n                \"reason\": \"No ready tasks\",\n                \"blocked_count\": len(blocked_tasks),\n                \"recommendations\": []\n            }\n\n        # Einfache Planung f\u00fcr wenige Tasks\n        if len(ready_tasks) &lt;= 2 and not LITELLM_AVAILABLE:\n            return self._create_simple_execution_plan(ready_tasks, plan)\n\n        # LLM-basierte intelligente Planung\n        return await self._llm_execution_planning(ready_tasks, blocked_tasks, plan, shared)\n\n    def _create_simple_execution_plan(self, ready_tasks: list[Task], plan: TaskPlan) -&gt; dict[str, Any]:\n        \"\"\"Einfache heuristische Ausf\u00fchrungsplanung\"\"\"\n\n        # Priorit\u00e4ts-basierte Sortierung\n        sorted_tasks = sorted(ready_tasks, key=lambda t: (t.priority, t.created_at))\n\n        # Parallelisierbare Tasks identifizieren\n        parallel_groups = []\n        current_group = []\n\n        for task in sorted_tasks:\n            # ToolTasks k\u00f6nnen oft parallel laufen\n            if isinstance(task, ToolTask) and len(current_group) &lt; self.max_parallel:\n                current_group.append(task)\n            else:\n                if current_group:\n                    parallel_groups.append(current_group)\n                    current_group = []\n                current_group.append(task)\n\n        if current_group:\n            parallel_groups.append(current_group)\n\n        strategy = \"parallel\" if len(parallel_groups) &gt; 1 or len(parallel_groups[0]) &gt; 1 else \"sequential\"\n\n        return {\n            \"strategy\": strategy,\n            \"execution_groups\": parallel_groups,\n            \"total_groups\": len(parallel_groups),\n            \"reasoning\": \"Simple heuristic: priority-based with tool parallelization\",\n            \"estimated_duration\": self._estimate_duration(sorted_tasks)\n        }\n\n    async def _llm_execution_planning(\n        self,\n        ready_tasks: list[Task],\n        blocked_tasks: list[Task],\n        plan: TaskPlan,\n        shared: dict\n    ) -&gt; dict[str, Any]:\n        \"\"\"Erweiterte LLM-basierte Ausf\u00fchrungsplanung\"\"\"\n\n        try:\n            # Erstelle detaillierte Task-Analyse f\u00fcr LLM\n            task_analysis = self._analyze_tasks_for_llm(ready_tasks, blocked_tasks)\n            execution_context = self._build_execution_context(shared)\n\n            prompt = f\"\"\"\nDu bist ein Experte f\u00fcr Task-Ausf\u00fchrungsplanung. Analysiere die verf\u00fcgbaren Tasks und erstelle einen optimalen Ausf\u00fchrungsplan.\n\n## Verf\u00fcgbare Tasks zur Ausf\u00fchrung\n{task_analysis['ready_tasks_summary']}\n\n## Blockierte Tasks (zur Information)\n{task_analysis['blocked_tasks_summary']}\n\n## Ausf\u00fchrungskontext\n- Max parallele Tasks: {self.max_parallel}\n- Plan-Strategie: {plan.execution_strategy}\n- Verf\u00fcgbare Tools: {', '.join(shared.get('available_tools', []))}\n- Bisherige Ergebnisse: {len(self.results_store)} Tasks abgeschlossen\n- Execution History: {len(self.execution_history)} vorherige Zyklen\n\n## Bisherige Performance\n{execution_context}\n\n## Aufgabe\nErstelle einen optimierten Ausf\u00fchrungsplan. Ber\u00fccksichtige:\n1. Task-Abh\u00e4ngigkeiten und Priorit\u00e4ten\n2. Parallelisierungsm\u00f6glichkeiten\n3. Resource-Optimierung (Tools, LLM-Aufrufe)\n4. Fehlerwahrscheinlichkeit und Retry-Strategien\n5. Dynamische Argument-Aufl\u00f6sung zwischen Tasks\n\nAntworte mit YAML:\n\n```yaml\nstrategy: \"parallel\"  # \"parallel\" | \"sequential\" | \"hybrid\"\nexecution_groups:\n  - group_id: 1\n    tasks: [\"task_1\", \"task_2\"]  # Task IDs\n    execution_mode: \"parallel\"\n    priority: \"high\"\n    estimated_duration: 30  # seconds\n    risk_level: \"low\"  # low | medium | high\n    dependencies_resolved: true\n  - group_id: 2\n    tasks: [\"task_3\"]\n    execution_mode: \"sequential\"\n    priority: \"medium\"\n    estimated_duration: 15\n    depends_on_groups: [1]\nreasoning: \"Detailed explanation of the execution strategy\"\noptimization_suggestions:\n  - \"Specific optimization 1\"\n  - \"Specific optimization 2\"\nrisk_mitigation:\n  - risk: \"Tool timeout\"\n    mitigation: \"Use shorter timeout for parallel calls\"\n  - risk: \"Argument resolution failure\"\n    mitigation: \"Validate references before execution\"\ntotal_estimated_duration: 45\nconfidence: 0.85\n```\"\"\"\n\n            model_to_use = shared.get(\"complex_llm_model\", \"openrouter/openai/gpt-4o\")\n\n            content = await self.agent_instance.a_run_llm_completion(\n                model=model_to_use,\n                messages=[{\"role\": \"user\", \"content\": prompt}],\n                temperature=0.3,\n                max_tokens=2000,\n                node_name=\"TaskExecutorNode\", task_id=\"llm_execution_planning\"\n            )\n\n            yaml_match = re.search(r\"```yaml\\s*(.*?)\\s*```\", content, re.DOTALL)\n            yaml_str = yaml_match.group(1) if yaml_match else content.strip()\n\n            execution_plan = yaml.safe_load(yaml_str)\n\n            # Validiere und erweitere den Plan\n            validated_plan = self._validate_execution_plan(execution_plan, ready_tasks)\n\n            rprint(\n                f\"LLM execution plan created: {validated_plan.get('strategy')} with {len(validated_plan.get('execution_groups', []))} groups\")\n            return validated_plan\n\n        except Exception as e:\n            eprint(f\"LLM execution planning failed: {e}\")\n            return self._create_simple_execution_plan(ready_tasks, plan)\n\n    def _analyze_tasks_for_llm(self, ready_tasks: list[Task], blocked_tasks: list[Task]) -&gt; dict[str, str]:\n        \"\"\"Analysiere Tasks f\u00fcr LLM-Prompt\"\"\"\n\n        ready_summary = []\n        for task in ready_tasks:\n            task_info = f\"- {task.id} ({task.type}): {task.description}\"\n            if hasattr(task, 'priority'):\n                task_info += f\" [Priority: {task.priority}]\"\n            if isinstance(task, ToolTask):\n                task_info += f\" [Tool: {task.tool_name}]\"\n                if task.arguments:\n                    # Zeige dynamische Referenzen\n                    dynamic_refs = [arg for arg in task.arguments.values() if isinstance(arg, str) and \"{{\" in arg]\n                    if dynamic_refs:\n                        task_info += f\" [Dynamic refs: {len(dynamic_refs)}]\"\n            ready_summary.append(task_info)\n\n        blocked_summary = []\n        for task in blocked_tasks:\n            deps = \", \".join(task.dependencies) if task.dependencies else \"None\"\n            blocked_summary.append(f\"- {task.id}: waiting for [{deps}]\")\n\n        return {\n            \"ready_tasks_summary\": \"\\n\".join(ready_summary) or \"No ready tasks\",\n            \"blocked_tasks_summary\": \"\\n\".join(blocked_summary) or \"No blocked tasks\"\n        }\n\n    def _build_execution_context(self, shared: dict) -&gt; str:\n        \"\"\"Baue Kontext f\u00fcr LLM-Planung\"\"\"\n        context_parts = []\n\n        # Performance der letzten Executions\n        if self.execution_history:\n            recent = self.execution_history[-3:]  # Last 3 executions\n            avg_duration = sum(h.get(\"duration\", 0) for h in recent) / len(recent)\n            success_rate = sum(1 for h in recent if h.get(\"success\", False)) / len(recent)\n            context_parts.append(f\"Recent performance: {avg_duration:.1f}s avg, {success_rate:.1%} success rate\")\n\n        # Resource utilization\n        if self.results_store:\n            tool_usage = {}\n            for task_result in self.results_store.values():\n                metadata = task_result.get(\"metadata\", {})\n                task_type = metadata.get(\"task_type\", \"unknown\")\n                tool_usage[task_type] = tool_usage.get(task_type, 0) + 1\n            context_parts.append(f\"Resource usage: {tool_usage}\")\n\n        return \"\\n\".join(context_parts) if context_parts else \"No previous execution history\"\n\n    def _validate_execution_plan(self, plan: dict, ready_tasks: list[Task]) -&gt; dict:\n        \"\"\"Validiere und korrigiere LLM-generierten Ausf\u00fchrungsplan\"\"\"\n\n        # Standard-Werte setzen\n        validated = {\n            \"strategy\": plan.get(\"strategy\", \"sequential\"),\n            \"execution_groups\": [],\n            \"reasoning\": plan.get(\"reasoning\", \"LLM-generated plan\"),\n            \"total_estimated_duration\": plan.get(\"total_estimated_duration\", 60),\n            \"confidence\": min(1.0, max(0.0, plan.get(\"confidence\", 0.5)))\n        }\n\n        # Validiere execution groups\n        task_ids_available = [t.id for t in ready_tasks]\n\n        for group_data in plan.get(\"execution_groups\", []):\n            group_tasks = group_data.get(\"tasks\", [])\n            # Filtere nur verf\u00fcgbare Tasks\n            valid_tasks = [tid for tid in group_tasks if tid in task_ids_available]\n\n            if valid_tasks:\n                validated[\"execution_groups\"].append({\n                    \"group_id\": group_data.get(\"group_id\", len(validated[\"execution_groups\"]) + 1),\n                    \"tasks\": valid_tasks,\n                    \"execution_mode\": group_data.get(\"execution_mode\", \"sequential\"),\n                    \"priority\": group_data.get(\"priority\", \"medium\"),\n                    \"estimated_duration\": group_data.get(\"estimated_duration\", 30),\n                    \"risk_level\": group_data.get(\"risk_level\", \"medium\")\n                })\n\n        # Falls keine validen Groups, erstelle Fallback\n        if not validated[\"execution_groups\"]:\n            validated[\"execution_groups\"] = [{\n                \"group_id\": 1,\n                \"tasks\": task_ids_available[:self.max_parallel],\n                \"execution_mode\": \"parallel\",\n                \"priority\": \"high\"\n            }]\n\n        return validated\n\n    def _estimate_duration(self, tasks: list[Task]) -&gt; int:\n        \"\"\"Sch\u00e4tze Ausf\u00fchrungsdauer in Sekunden\"\"\"\n        duration = 0\n        for task in tasks:\n            if isinstance(task, ToolTask):\n                duration += 10  # Tool calls meist schneller\n            elif isinstance(task, LLMTask):\n                duration += 20  # LLM calls brauchen l\u00e4nger\n            else:\n                duration += 15  # Standard\n        return duration\n\n    async def exec_async(self, prep_res):\n        \"\"\"Hauptausf\u00fchrungslogik mit intelligentem Routing\"\"\"\n\n        if \"error\" in prep_res:\n            return {\"error\": prep_res[\"error\"]}\n\n        execution_plan = prep_res[\"execution_plan\"]\n\n        if execution_plan[\"strategy\"] == \"waiting\":\n            return {\n                \"status\": \"waiting\",\n                \"message\": execution_plan[\"reason\"],\n                \"blocked_count\": execution_plan.get(\"blocked_count\", 0)\n            }\n\n        # Starte Ausf\u00fchrung basierend auf Plan\n        execution_start = datetime.now()\n\n        try:\n            if execution_plan[\"strategy\"] == \"parallel\":\n                results = await self._execute_parallel_plan(execution_plan, prep_res)\n            elif execution_plan[\"strategy\"] == \"sequential\":\n                results = await self._execute_sequential_plan(execution_plan, prep_res)\n            else:  # hybrid\n                results = await self._execute_hybrid_plan(execution_plan, prep_res)\n\n            execution_duration = (datetime.now() - execution_start).total_seconds()\n\n            # Speichere Execution-History f\u00fcr LLM-Optimierung\n            self.execution_history.append({\n                \"timestamp\": execution_start.isoformat(),\n                \"strategy\": execution_plan[\"strategy\"],\n                \"duration\": execution_duration,\n                \"tasks_executed\": len(results),\n                \"success\": all(r.get(\"status\") == \"completed\" for r in results),\n                \"plan_confidence\": execution_plan.get(\"confidence\", 0.5)\n            })\n\n            # Behalte nur letzte 10 Executions\n            if len(self.execution_history) &gt; 10:\n                self.execution_history = self.execution_history[-10:]\n\n            return {\n                \"status\": \"executed\",\n                \"results\": results,\n                \"execution_duration\": execution_duration,\n                \"strategy_used\": execution_plan[\"strategy\"],\n                \"completed_tasks\": len([r for r in results if r.get(\"status\") == \"completed\"]),\n                \"failed_tasks\": len([r for r in results if r.get(\"status\") == \"failed\"])\n            }\n\n        except Exception as e:\n            eprint(f\"Execution plan failed: {e}\")\n            return {\n                \"status\": \"execution_failed\",\n                \"error\": str(e),\n                \"results\": []\n            }\n\n    async def _execute_parallel_plan(self, plan: dict, prep_res: dict) -&gt; list[dict]:\n        \"\"\"F\u00fchre Plan mit parallelen Gruppen aus\"\"\"\n        all_results = []\n\n        for group in plan[\"execution_groups\"]:\n            group_tasks = self._get_tasks_by_ids(group[\"tasks\"], prep_res)\n\n            if group.get(\"execution_mode\") == \"parallel\":\n                # Parallele Ausf\u00fchrung innerhalb der Gruppe\n                batch_results = await self._execute_parallel_batch(group_tasks)\n            else:\n                # Sequenzielle Ausf\u00fchrung innerhalb der Gruppe\n                batch_results = await self._execute_sequential_batch(group_tasks)\n\n            all_results.extend(batch_results)\n\n            # Pr\u00fcfe ob kritische Tasks fehlgeschlagen sind\n            critical_failures = [\n                r for r in batch_results\n                if r.get(\"status\") == \"failed\" and self._is_critical_task(r.get(\"task_id\"), prep_res)\n            ]\n\n            if critical_failures:\n                eprint(f\"Critical task failures in group {group['group_id']}, stopping execution\")\n                break\n\n        return all_results\n\n    async def _execute_sequential_plan(self, plan: dict, prep_res: dict) -&gt; list[dict]:\n        \"\"\"F\u00fchre Plan sequenziell aus\"\"\"\n        all_results = []\n\n        for group in plan[\"execution_groups\"]:\n            group_tasks = self._get_tasks_by_ids(group[\"tasks\"], prep_res)\n            batch_results = await self._execute_sequential_batch(group_tasks)\n            all_results.extend(batch_results)\n\n            # Stoppe bei kritischen Fehlern\n            critical_failures = [\n                r for r in batch_results\n                if r.get(\"status\") == \"failed\" and self._is_critical_task(r.get(\"task_id\"), prep_res)\n            ]\n\n            if critical_failures:\n                break\n\n        return all_results\n\n    async def _execute_hybrid_plan(self, plan: dict, prep_res: dict) -&gt; list[dict]:\n        \"\"\"Hybride Ausf\u00fchrung - Groups parallel, innerhalb je nach Mode\"\"\"\n\n        # F\u00fchre Gruppen parallel aus (wenn m\u00f6glich)\n        group_tasks_list = []\n        for group in plan[\"execution_groups\"]:\n            group_tasks = self._get_tasks_by_ids(group[\"tasks\"], prep_res)\n            group_tasks_list.append((group, group_tasks))\n\n        # F\u00fchre bis zu max_parallel Gruppen parallel aus\n        batch_size = min(len(group_tasks_list), self.max_parallel)\n        all_results = []\n\n        for i in range(0, len(group_tasks_list), batch_size):\n            batch = group_tasks_list[i:i + batch_size]\n\n            # Erstelle Coroutines f\u00fcr jede Gruppe\n            group_coroutines = []\n            for group, tasks in batch:\n                if group.get(\"execution_mode\") == \"parallel\":\n                    coro = self._execute_parallel_batch(tasks)\n                else:\n                    coro = self._execute_sequential_batch(tasks)\n                group_coroutines.append(coro)\n\n            # F\u00fchre Gruppen-Batch parallel aus\n            batch_results = await asyncio.gather(*group_coroutines, return_exceptions=True)\n\n            # Flache Liste der Ergebnisse\n            for result_group in batch_results:\n                if isinstance(result_group, Exception):\n                    eprint(f\"Group execution failed: {result_group}\")\n                    continue\n                all_results.extend(result_group)\n\n        return all_results\n\n    def _get_tasks_by_ids(self, task_ids: list[str], prep_res: dict) -&gt; list[Task]:\n        \"\"\"Hole Task-Objekte basierend auf IDs\"\"\"\n        all_tasks = prep_res[\"all_tasks\"]\n        return [all_tasks[tid] for tid in task_ids if tid in all_tasks]\n\n    def _is_critical_task(self, task_id: str, prep_res: dict) -&gt; bool:\n        \"\"\"Pr\u00fcfe ob Task kritisch ist\"\"\"\n        task = prep_res[\"all_tasks\"].get(task_id)\n        if not task:\n            return False\n        return getattr(task, 'critical', False) or task.priority == 1\n\n    async def _execute_parallel_batch(self, tasks: list[Task]) -&gt; list[dict]:\n        \"\"\"F\u00fchre Tasks parallel aus\"\"\"\n        if not tasks:\n            return []\n\n        # Limitiere auf max_parallel\n        batch_size = min(len(tasks), self.max_parallel)\n        batches = [tasks[i:i + batch_size] for i in range(0, len(tasks), batch_size)]\n\n        all_results = []\n        for batch in batches:\n            batch_results = await asyncio.gather(\n                *[self._execute_single_task(task) for task in batch],\n                return_exceptions=True\n            )\n\n            # Handle exceptions\n            processed_results = []\n            for i, result in enumerate(batch_results):\n                if isinstance(result, Exception):\n                    eprint(f\"Task {batch[i].id} failed with exception: {result}\")\n                    processed_results.append({\n                        \"task_id\": batch[i].id,\n                        \"status\": \"failed\",\n                        \"error\": str(result)\n                    })\n                else:\n                    processed_results.append(result)\n\n            all_results.extend(processed_results)\n\n        return all_results\n\n    async def _execute_sequential_batch(self, tasks: list[Task]) -&gt; list[dict]:\n        \"\"\"F\u00fchre Tasks sequenziell aus\"\"\"\n        results = []\n\n        for task in tasks:\n            try:\n                result = await self._execute_single_task(task)\n                results.append(result)\n\n                # Stoppe bei kritischen Fehlern in sequenzieller Ausf\u00fchrung\n                if result.get(\"status\") == \"failed\" and getattr(task, 'critical', False):\n                    eprint(f\"Critical task {task.id} failed, stopping sequential execution\")\n                    break\n\n            except Exception as e:\n                eprint(f\"Sequential task {task.id} failed: {e}\")\n                results.append({\n                    \"task_id\": task.id,\n                    \"status\": \"failed\",\n                    \"error\": str(e)\n                })\n\n                if getattr(task, 'critical', False):\n                    break\n\n        return results\n\n    async def _execute_single_task(self, task: Task) -&gt; dict:\n        \"\"\"Enhanced task execution with unified LLMToolNode usage\"\"\"\n        if self.progress_tracker:\n            await self.progress_tracker.emit_event(ProgressEvent(\n                event_type=\"task_start\",\n                node_name=\"TaskExecutorNode\",\n                status=NodeStatus.RUNNING,\n                task_id=task.id,\n                plan_id=self.variable_manager.get(\"shared.current_plan.id\"),\n                metadata={\n                    \"description\": task.description,\n                    \"type\": task.type,\n                    \"priority\": task.priority,\n                    \"dependencies\": task.dependencies\n                }\n            ))\n\n        task_start = time.perf_counter()\n        try:\n            task.status = \"running\"\n            task.started_at = datetime.now()\n\n            # Ensure metadata is initialized\n            if not hasattr(task, 'metadata') or task.metadata is None:\n                task.metadata = {}\n\n            # Pre-process task with variable resolution\n            if isinstance(task, ToolTask):\n                resolved_args = self._resolve_task_variables(task.arguments)\n                result = await self._execute_tool_task_with_validation(task, resolved_args)\n            elif isinstance(task, LLMTask):\n                # Use LLMToolNode for LLM tasks instead of direct execution\n                result = await self._execute_llm_via_llmtool(task)\n            elif isinstance(task, DecisionTask):\n                # Enhanced decision task with context awareness\n                result = await self._execute_decision_task_enhanced(task)\n            else:\n                # Use LLMToolNode for generic tasks as well\n                result = await self._execute_generic_via_llmtool(task)\n\n            # Store result in unified system\n            self._store_task_result(task.id, result, True)\n\n            task.result = result\n            task.status = \"completed\"\n            task.completed_at = datetime.now()\n\n            task_duration = time.perf_counter() - task_start\n\n            if self.progress_tracker:\n                await self.progress_tracker.emit_event(ProgressEvent(\n                    event_type=\"task_complete\",\n                    node_name=\"TaskExecutorNode\",\n                    task_id=task.id,\n                    plan_id=self.variable_manager.get(\"shared.current_plan.id\"),\n                    status=NodeStatus.COMPLETED,\n                    success=True,\n                    duration=task_duration,\n                    metadata={\n                        \"result_type\": type(result).__name__,\n                        \"description\": task.description\n                    }\n                ))\n\n            return {\n                \"task_id\": task.id,\n                \"status\": \"completed\",\n                \"result\": result\n            }\n\n        except Exception as e:\n            task.error = str(e)\n            task.status = \"failed\"\n            task.retry_count += 1\n\n            # Store error in unified system\n            self._store_task_result(task.id, None, False, str(e))\n            task_duration = time.perf_counter() - task_start\n\n            if self.progress_tracker:\n                await self.progress_tracker.emit_event(ProgressEvent(\n                    event_type=\"task_error\",  # Klarer Event-Typ\n                    node_name=\"TaskExecutorNode\",\n                    task_id=task.id,\n                    plan_id=self.variable_manager.get(\"shared.current_plan.id\"),\n                    status=NodeStatus.FAILED,\n                    success=False,\n                    duration=task_duration,\n                    error_details={\n                        \"message\": str(e),\n                        \"type\": type(e).__name__\n                    },\n                    metadata={\n                        \"retry_count\": task.retry_count,\n                        \"description\": task.description\n                    }\n                ))\n\n            eprint(f\"Task {task.id} failed: {e}\")\n            return {\n                \"task_id\": task.id,\n                \"status\": \"failed\",\n                \"error\": str(e),\n                \"retry_count\": task.retry_count\n            }\n\n    async def _resolve_dynamic_arguments(self, arguments: dict[str, Any]) -&gt; dict[str, Any]:\n        \"\"\"Enhanced dynamic argument resolution with full variable system\"\"\"\n        resolved = {}\n\n        for key, value in arguments.items():\n            if isinstance(value, str):\n                # FIXED: Use unified variable manager for all resolution\n                resolved_value = self.variable_manager.format_text(value)\n\n                # Log if variables weren't resolved (debugging)\n                if \"{{\" in resolved_value and \"}}\" in resolved_value:\n                    wprint(f\"Unresolved variables in argument '{key}': {resolved_value}\")\n\n                resolved[key] = resolved_value\n            else:\n                resolved[key] = value\n\n        return resolved\n\n    async def _execute_tool_task_with_validation(self, task: ToolTask, resolved_args: dict[str, Any]) -&gt; Any:\n        \"\"\"Tool execution with improved error detection and validation\"\"\"\n\n        if not task.tool_name:\n            raise ValueError(f\"ToolTask {task.id} missing tool_name\")\n\n        agent = self.agent_instance\n        if not agent:\n            raise ValueError(\"Agent instance not available for tool execution\")\n\n        tool_start = time.perf_counter()\n\n        # Track tool call start\n        if self.progress_tracker:\n            await self.progress_tracker.emit_event(ProgressEvent(\n                event_type=\"tool_call\",\n                timestamp=time.time(),\n                node_name=\"TaskExecutorNode\",\n                status=NodeStatus.RUNNING,\n                task_id=task.id,\n                tool_name=task.tool_name,\n                tool_args=resolved_args,\n                metadata={\n                    \"task_type\": \"ToolTask\",\n                    \"hypothesis\": task.hypothesis,\n                    \"validation_criteria\": task.validation_criteria\n                }\n            ))\n\n        try:\n            rprint(f\"Executing tool {task.tool_name} with resolved args: {resolved_args}\")\n\n            # Execute tool with timeout and retry logic\n            result = await self._execute_tool_with_retries(task.tool_name, resolved_args, agent)\n\n            tool_duration = time.perf_counter() - tool_start\n\n            # Validate result before marking as success\n            is_valid_result = self._validate_tool_result(result, task)\n\n            if not is_valid_result:\n                raise ValueError(f\"Tool {task.tool_name} returned invalid result: {type(result).__name__}\")\n\n            # Track successful tool call\n            if self.progress_tracker:\n                await self.progress_tracker.emit_event(ProgressEvent(\n                    event_type=\"tool_call\",\n                    timestamp=time.time(),\n                    node_name=\"TaskExecutorNode\",\n                    task_id=task.id,\n                    status=NodeStatus.COMPLETED,\n                    tool_name=task.tool_name,\n                    tool_args=resolved_args,\n                    tool_result=result,\n                    duration=tool_duration,\n                    success=True,\n                    metadata={\n                        \"task_type\": \"ToolTask\",\n                        \"result_type\": type(result).__name__,\n                        \"result_length\": len(str(result)),\n                        \"validation_passed\": is_valid_result\n                    }\n                ))\n\n            # FIXED: Store in variable manager with correct path structure\n            if self.variable_manager:\n                self.variable_manager.set(f\"results.{task.id}.data\", result)\n                self.variable_manager.set(f\"tasks.{task.id}.result\", result)\n\n            return result\n\n        except Exception as e:\n            tool_duration = time.perf_counter() - tool_start\n            import traceback\n            print(traceback.format_exc())\n\n            # Detailed error tracking\n            if self.progress_tracker:\n                await self.progress_tracker.emit_event(ProgressEvent(\n                    event_type=\"tool_call\",\n                    timestamp=time.time(),\n                    node_name=\"TaskExecutorNode\",\n                    task_id=task.id,\n                    status=NodeStatus.FAILED,\n                    tool_name=task.tool_name,\n                    tool_args=resolved_args,\n                    duration=tool_duration,\n                    success=False,\n                    tool_error=str(e),\n                    metadata={\n                        \"task_type\": \"ToolTask\",\n                        \"error_type\": type(e).__name__,\n                        \"retry_attempted\": hasattr(self, '_retry_count')\n                    }\n                ))\n\n            eprint(f\"Tool execution failed for {task.tool_name}: {e}\")\n            raise\n    async def _execute_llm_via_llmtool(self, task: LLMTask) -&gt; Any:\n        \"\"\"Execute LLM task via LLMToolNode for consistency\"\"\"\n\n        # Prepare context for LLMToolNode\n        llm_shared = {\n            \"current_task_description\": task.description,\n            \"formatted_context\": {\n                \"recent_interaction\": f\"Executing LLM task: {task.description}\",\n                \"session_summary\": \"\",\n                \"task_context\": f\"Task ID: {task.id}, Priority: {task.priority}\"\n            },\n            \"variable_manager\": self.variable_manager,\n            \"agent_instance\": self.agent_instance,\n            \"available_tools\": self.agent_instance.shared.get(\"available_tools\", []) if self.agent_instance else [],\n            \"tool_capabilities\": self.agent_instance._tool_capabilities if self.agent_instance else {},\n            \"fast_llm_model\": self.fast_llm_model,\n            \"complex_llm_model\": self.complex_llm_model,\n            \"progress_tracker\": self.progress_tracker,\n            \"session_id\": getattr(self, 'session_id', 'task_executor'),\n            \"use_fast_response\": task.llm_config.get(\"model_preference\", \"fast\") == \"fast\"\n        }\n\n        # Create LLMToolNode instance\n        llm_node = LLMToolNode()\n\n        # Execute via LLMToolNode\n        try:\n            result = await llm_node.run_async(llm_shared)\n            # shared[\"current_response\"]\n            # shared[\"tool_calls_made\"]\n            # shared[\"llm_tool_conversation\"]\n            # shared[\"synthesized_response\"]\n            return llm_shared[\"current_response\"]\n        except Exception as e:\n            eprint(f\"LLMToolNode execution failed for task {task.id}: {e}\")\n            # Fallback to direct execution\n            import traceback\n            print(traceback.format_exc())\n            return await self._execute_llm_task_enhanced(task)\n\n    async def _execute_llm_task_enhanced(self, task: LLMTask) -&gt; Any:\n        \"\"\"Enhanced LLM task execution with unified variable system\"\"\"\n        if not LITELLM_AVAILABLE:\n            raise Exception(\"LiteLLM not available for LLM tasks\")\n\n        # Get model preference with variable support\n        llm_config = task.llm_config\n        model_preference = llm_config.get(\"model_preference\", \"fast\")\n\n        if model_preference == \"complex\":\n            model_to_use = self.variable_manager.get(\"system.complex_llm_model\", \"openrouter/openai/gpt-4o\")\n        else:\n            model_to_use = self.variable_manager.get(\"system.fast_llm_model\", \"openrouter/anthropic/claude-3-haiku\")\n\n        # Build context for prompt\n        context_data = {}\n        for context_key in task.context_keys:\n            value = self.variable_manager.get(context_key)\n            if value is not None:\n                context_data[context_key] = value\n\n        # Resolve prompt template with full variable system\n        final_prompt = self.variable_manager.format_text(\n            task.prompt_template,\n            context=context_data\n        )\n\n        llm_start = time.perf_counter()\n\n        try:\n\n            response = await litellm.acompletion(\n                model=model_to_use,\n                messages=[{\"role\": \"user\", \"content\": final_prompt}],\n                temperature=llm_config.get(\"temperature\", 0.7),\n                max_tokens=llm_config.get(\"max_tokens\", 2048)\n            )\n\n            result = response\n\n\n            # Store intermediate result for other tasks\n            self.variable_manager.set(f\"tasks.{task.id}.result\", result)\n\n            # Output schema validation if present\n            if task.output_schema:\n                stripped = result.strip()\n\n                try:\n                    # Try JSON first if it looks like JSON\n                    if stripped.startswith('{') or stripped.startswith('['):\n                        parsed = json.loads(stripped)\n                    else:\n                        parsed = yaml.safe_load(stripped)\n\n                    # Ensure metadata is a dict before updating\n                    if not isinstance(task.metadata, dict):\n                        task.metadata = {}\n\n                    # Save parsed result\n                    task.metadata[\"parsed_output\"] = parsed\n\n                except (json.JSONDecodeError, yaml.YAMLError):\n                    # Save info about failure without logging output\n                    if not isinstance(task.metadata, dict):\n                        task.metadata = {}\n                    task.metadata[\"parsed_output_error\"] = \"Invalid JSON/YAML format\"\n\n                except Exception as e:\n                    if not isinstance(task.metadata, dict):\n                        task.metadata = {}\n                    task.metadata[\"parsed_output_error\"] = f\"Unexpected error: {str(e)}\"\n\n            return result\n        except Exception as e:\n            llm_duration = time.perf_counter() - llm_start\n\n            if self.progress_tracker:\n                await self.progress_tracker.emit_event(ProgressEvent(\n                    event_type=\"llm_call\",\n                    node_name=\"TaskExecutorNode\",\n                    task_id=task.id,\n                    status=NodeStatus.FAILED,\n                    success=False,\n                    duration=llm_duration,\n                    llm_model=model_to_use,\n                    error_details={\n                        \"message\": str(e),\n                        \"type\": type(e).__name__\n                    }\n                ))\n\n            raise\n\n    async def _execute_generic_via_llmtool(self, task: Task) -&gt; Any:\n        \"\"\"\n        Execute a generic task by treating its description as a query for the LLMToolNode.\n        This provides a flexible fallback for undefined task types, leveraging the full\n        reasoning and tool-use capabilities of the LLMToolNode.\n        \"\"\"\n        # Prepare a shared context dictionary for the LLMToolNode, treating the\n        # generic task's description as the primary query.\n        llm_shared = {\n            \"current_task_description\": task.description,\n            \"current_query\": task.description,\n            \"formatted_context\": {\n                \"recent_interaction\": f\"Executing generic task: {task.description}\",\n                \"session_summary\": f\"The system needs to complete the following task: {task.description}\",\n                \"task_context\": f\"Task ID: {task.id}, Priority: {task.priority}, Type: Generic\"\n            },\n            \"variable_manager\": self.variable_manager,\n            \"agent_instance\": self.agent_instance,\n            # Generic tasks might require tools, so provide full tool context.\n            \"available_tools\": self.agent_instance.shared.get(\"available_tools\", []) if self.agent_instance else [],\n            \"tool_capabilities\": self.agent_instance._tool_capabilities if self.agent_instance else {},\n            \"fast_llm_model\": self.fast_llm_model,\n            \"complex_llm_model\": self.complex_llm_model,\n            \"progress_tracker\": self.progress_tracker,\n            \"session_id\": getattr(self, 'session_id', 'task_executor_generic'),\n            # Default to a fast model, assuming generic tasks are often straightforward.\n            \"use_fast_response\": True\n        }\n\n        # Instantiate the LLMToolNode for this specific execution.\n        llm_node = LLMToolNode()\n\n        try:\n            # Execute the node. It will run its internal loop for reasoning, tool calling, and response generation.\n            # The results of the execution will be populated back into the `llm_shared` dictionary.\n            await llm_node.run_async(llm_shared)\n\n            # Extract the final response from the shared context populated by the node.\n            # Prioritize the structured 'synthesized_response' but fall back to 'current_response'.\n            final_response = llm_shared.get(\"synthesized_response\", {}).get(\"synthesized_response\")\n            if not final_response:\n                final_response = llm_shared.get(\"current_response\", f\"Generic task '{task.id}' processed.\")\n\n            return final_response\n\n        except Exception as e:\n            eprint(f\"LLMToolNode execution for generic task {task.id} failed: {e}\")\n            # Re-raise the exception to allow the higher-level execution loop in\n            # _execute_single_task to catch and handle it appropriately (e.g., for retries).\n            raise\n\n    async def _execute_decision_task_enhanced(self, task: DecisionTask) -&gt; str:\n        \"\"\"Enhanced DecisionTask with intelligent replan assessment\"\"\"\n\n        if not LITELLM_AVAILABLE:\n            raise Exception(\"LiteLLM not available for decision tasks\")\n\n        # Build comprehensive context for decision\n        decision_context = self._build_decision_context(task)\n\n        # Enhanced decision prompt with full context\n        enhanced_prompt = f\"\"\"\nYou are making a critical routing decision for task execution. Analyze all context carefully.\n\n## Current Situation\n{task.decision_prompt}\n\n## Execution Context\n{decision_context}\n\n## Available Routing Options\n{json.dumps(task.routing_map, indent=2)}\n\n## Decision Guidelines\n1. Only trigger \"replan_from_here\" if there's a genuine failure that cannot be recovered\n2. Use \"route_to_task\" for normal flow continuation\n3. Consider the full context, not just immediate results\n4. Be conservative with replanning - it's expensive and can cause loops\n\nBased on ALL the context above, what is your decision?\nRespond with EXACTLY one of these options: {', '.join(task.routing_map.keys())}\n\nYour decision:\"\"\"\n\n        model_to_use = self.fast_llm_model if hasattr(self, 'fast_llm_model') else \"openrouter/anthropic/claude-3-haiku\"\n\n        try:\n            response = await litellm.acompletion(\n                model=model_to_use,\n                messages=[{\"role\": \"user\", \"content\": enhanced_prompt}],\n                temperature=0.1,\n                max_tokens=50\n            )\n\n            decision = response.choices[0].message.content.strip().lower().split('\\n')[0]\n\n            # Find matching key (case-insensitive)\n            matched_key = None\n            for key in task.routing_map:\n                if key.lower() == decision:\n                    matched_key = key\n                    break\n\n            if not matched_key:\n                wprint(f\"Decision '{decision}' not in routing map, using first option\")\n                matched_key = list(task.routing_map.keys())[0] if task.routing_map else \"continue\"\n\n            routing_instruction = task.routing_map.get(matched_key, matched_key)\n\n            # Enhanced metadata with decision reasoning\n            if not hasattr(task, 'metadata'):\n                task.metadata = {}\n\n            task.metadata.update({\n                \"decision_made\": matched_key,\n                \"routing_instruction\": routing_instruction,\n                \"decision_context\": decision_context,\n                \"replan_justified\": self._assess_replan_necessity(matched_key, routing_instruction, decision_context)\n            })\n\n            # Handle dynamic planning instructions\n            if isinstance(routing_instruction, dict) and \"action\" in routing_instruction:\n                action = routing_instruction[\"action\"]\n\n                if action == \"replan_from_here\":\n                    # Add extensive context for replanning\n                    task.metadata[\"replan_context\"] = {\n                        \"new_goal\": routing_instruction.get(\"new_goal\", \"Continue with alternative approach\"),\n                        \"failure_reason\": f\"Decision task {task.id} determined: {matched_key}\",\n                        \"original_task\": task.id,\n                        \"context\": routing_instruction.get(\"context\", \"\"),\n                        \"execution_history\": self._get_execution_history_summary(),\n                        \"failed_approaches\": self._identify_failed_approaches(),\n                        \"success_indicators\": self._identify_success_patterns()\n                    }\n\n                self.variable_manager.set(f\"tasks.{task.id}.result\", {\n                    \"decision\": matched_key,\n                    \"action\": action,\n                    \"instruction\": routing_instruction,\n                    \"confidence\": self._calculate_decision_confidence(decision_context)\n                })\n\n                return action\n\n            else:\n                # Traditional routing\n                next_task_id = routing_instruction if isinstance(routing_instruction, str) else str(routing_instruction)\n\n                task.metadata.update({\n                    \"next_task_id\": next_task_id,\n                    \"routing_action\": \"route_to_task\"\n                })\n\n                self.variable_manager.set(f\"tasks.{task.id}.result\", {\n                    \"decision\": matched_key,\n                    \"next_task\": next_task_id\n                })\n\n                return matched_key\n\n        except Exception as e:\n            eprint(f\"Enhanced decision task failed: {e}\")\n            raise\n\n    async def post_async(self, shared, prep_res, exec_res):\n        \"\"\"Erweiterte Post-Processing mit dynamischer Plan-Anpassung\"\"\"\n\n        # Results store in shared state integrieren\n        shared[\"results\"] = self.results_store\n\n        if exec_res is None or \"error\" in exec_res:\n            shared[\"executor_performance\"] = {\"status\": \"error\", \"last_error\": exec_res.get(\"error\")}\n            return \"execution_error\"\n\n        if exec_res[\"status\"] == \"waiting\":\n            shared[\"executor_status\"] = \"waiting_for_dependencies\"\n            return \"waiting\"\n\n        # Performance-Metriken speichern\n        performance_data = {\n            \"execution_duration\": exec_res.get(\"execution_duration\", 0),\n            \"strategy_used\": exec_res.get(\"strategy_used\", \"unknown\"),\n            \"completed_tasks\": exec_res.get(\"completed_tasks\", 0),\n            \"failed_tasks\": exec_res.get(\"failed_tasks\", 0),\n            \"success_rate\": exec_res.get(\"completed_tasks\", 0) / max(len(exec_res.get(\"results\", [])), 1),\n            \"timestamp\": datetime.now().isoformat()\n        }\n        shared[\"executor_performance\"] = performance_data\n\n        # Check for dynamic planning actions\n        planning_action_detected = False\n\n        for result in exec_res.get(\"results\", []):\n            task_id = result[\"task_id\"]\n            if task_id in shared[\"tasks\"]:\n                task = shared[\"tasks\"][task_id]\n                task.status = result[\"status\"]\n\n                if result[\"status\"] == \"completed\":\n                    task.result = result[\"result\"]\n\n                    # Check for planning actions from DecisionTasks\n                    if hasattr(task, 'metadata') and task.metadata:\n                        routing_action = task.metadata.get(\"routing_action\")\n\n                        if routing_action == \"replan_from_here\":\n                            shared[\"needs_dynamic_replan\"] = True\n                            shared[\"replan_context\"] = task.metadata.get(\"replan_context\", {})\n                            planning_action_detected = True\n                            rprint(f\"Dynamic replan triggered by task {task_id}\")\n\n                        elif routing_action == \"append_plan\":\n                            shared[\"needs_plan_append\"] = True\n                            shared[\"append_context\"] = task.metadata.get(\"append_context\", {})\n                            planning_action_detected = True\n                            rprint(f\"Plan append triggered by task {task_id}\")\n\n                    # Store verification results if available\n                    if result.get(\"verification\"):\n                        if not hasattr(task, 'metadata'):\n                            task.metadata = {}\n                        task.metadata[\"verification\"] = result[\"verification\"]\n\n                elif result[\"status\"] == \"failed\":\n                    task.error = result.get(\"error\", \"Unknown error\")\n\n        # Return appropriate status based on planning actions\n        if planning_action_detected:\n            if shared.get(\"needs_dynamic_replan\"):\n                return \"needs_dynamic_replan\"  # Goes to PlanReflectorNode\n            elif shared.get(\"needs_plan_append\"):\n                return \"needs_plan_append\"  # Goes to PlanReflectorNode\n\n        # Regular completion checking\n        current_plan = shared[\"current_plan\"]\n        if current_plan:\n            all_finished = all(\n                shared[\"tasks\"][task.id].status in [\"completed\", \"failed\"]\n                for task in current_plan.tasks\n            )\n\n            if all_finished:\n                current_plan.status = \"completed\"\n                shared[\"plan_completion_time\"] = datetime.now().isoformat()\n                rprint(f\"Plan {current_plan.id} finished\")\n                return \"plan_completed\"\n            else:\n                ready_tasks = [\n                    task for task in current_plan.tasks\n                    if shared[\"tasks\"][task.id].status == \"pending\"\n                ]\n\n                if ready_tasks:\n                    return \"continue_execution\"\n                else:\n                    return \"waiting\"\n\n        return \"execution_complete\"\n\n    def get_execution_statistics(self) -&gt; dict[str, Any]:\n        \"\"\"Erhalte detaillierte Ausf\u00fchrungsstatistiken\"\"\"\n        if not self.execution_history:\n            return {\"message\": \"No execution history available\"}\n\n        history = self.execution_history\n\n        return {\n            \"total_executions\": len(history),\n            \"average_duration\": sum(h[\"duration\"] for h in history) / len(history),\n            \"success_rate\": sum(1 for h in history if h[\"success\"]) / len(history),\n            \"strategy_usage\": {\n                strategy: sum(1 for h in history if h[\"strategy\"] == strategy)\n                for strategy in set(h[\"strategy\"] for h in history)\n            },\n            \"total_tasks_executed\": sum(h[\"tasks_executed\"] for h in history),\n            \"average_confidence\": sum(h[\"plan_confidence\"] for h in history) / len(history),\n            \"recent_performance\": history[-3:] if len(history) &gt;= 3 else history\n        }\n\n    def _resolve_task_variables(self, data):\n        \"\"\"Unified variable resolution for any task data\"\"\"\n        if isinstance(data, str):\n            res = self.variable_manager.format_text(data)\n            return res\n        elif isinstance(data, dict):\n            resolved = {}\n            for key, value in data.items():\n                resolved[key] = self._resolve_task_variables(value)\n            return resolved\n        elif isinstance(data, list):\n            return [self._resolve_task_variables(item) for item in data]\n        else:\n            return data\n\n    def _store_task_result(self, task_id: str, result: Any, success: bool, error: str = None):\n        \"\"\"Store task result in unified variable system\"\"\"\n        result_data = {\n            \"data\": result,\n            \"metadata\": {\n                \"task_type\": \"task\",\n                \"completed_at\": datetime.now().isoformat(),\n                \"success\": success\n            }\n        }\n\n        if error:\n            result_data[\"error\"] = error\n            result_data[\"metadata\"][\"success\"] = False\n\n        # Store in results_store and update variable manager\n        self.results_store[task_id] = result_data\n        self.variable_manager.set_results_store(self.results_store)\n\n        # FIXED: Store actual result data, not the wrapper object\n        self.variable_manager.set(f\"results.{task_id}.data\", result)\n        self.variable_manager.set(f\"results.{task_id}.metadata\", result_data[\"metadata\"])\n        if error:\n            self.variable_manager.set(f\"results.{task_id}.error\", error)\n\n    def _build_decision_context(self, task: DecisionTask) -&gt; str:\n        \"\"\"Build comprehensive context for decision making\"\"\"\n\n        context_parts = []\n\n        # Recent execution results\n        recent_results = []\n        for task_id, result_data in list(self.results_store.items())[-3:]:\n            success = result_data.get(\"metadata\", {}).get(\"success\", False)\n            status = \"\u2713\" if success else \"\u2717\"\n            data_preview = str(result_data.get(\"data\", \"\"))[:100] + \"...\"\n            recent_results.append(f\"{status} {task_id}: {data_preview}\")\n\n        if recent_results:\n            context_parts.append(\"Recent Results:\\n\" + \"\\n\".join(recent_results))\n\n        # Variable context\n        if self.variable_manager:\n            available_vars = list(self.variable_manager.get_available_variables().keys())[:10]\n            context_parts.append(f\"Available Variables: {', '.join(available_vars)}\")\n\n        # Execution history\n        execution_summary = self._get_execution_history_summary()\n        if execution_summary:\n            context_parts.append(f\"Execution Summary: {execution_summary}\")\n\n        # Current world model insights\n        world_insights = self._get_world_model_insights()\n        if world_insights:\n            context_parts.append(f\"Known Facts: {world_insights}\")\n\n        return \"\\n\\n\".join(context_parts)\n\n    def _assess_replan_necessity(self, decision: str, routing_instruction: Any, context: str) -&gt; bool:\n        \"\"\"Assess if replanning is truly necessary\"\"\"\n\n        if not isinstance(routing_instruction, dict):\n            return False\n\n        action = routing_instruction.get(\"action\", \"\")\n        if action != \"replan_from_here\":\n            return False\n\n        # Check if we have genuine failures\n        genuine_failures = \"error\" in context.lower() or \"failed\" in context.lower()\n        alternative_available = len(self.results_store) &gt; 0  # Have some results to work with\n\n        # Be conservative - only replan if really necessary\n        return genuine_failures and not alternative_available\n\n    async def _execute_tool_with_retries(self, tool_name: str, args: dict, agent, max_retries: int = 2) -&gt; Any:\n        \"\"\"Execute tool with retry logic\"\"\"\n\n        last_exception = None\n\n        for attempt in range(max_retries + 1):\n            try:\n                result = await agent.arun_function(tool_name, **args)\n\n                # Additional validation - check if result indicates success\n                if self._is_tool_result_success(result):\n                    return result\n                elif attempt &lt; max_retries:\n                    wprint(f\"Tool {tool_name} returned unclear result, retrying...\")\n                    continue\n                else:\n                    return result\n\n            except Exception as e:\n                last_exception = e\n                if attempt &lt; max_retries:\n                    wprint(f\"Tool {tool_name} failed (attempt {attempt + 1}), retrying: {e}\")\n                    await asyncio.sleep(0.5 * (attempt + 1))  # Progressive delay\n                else:\n                    eprint(f\"Tool {tool_name} failed after {max_retries + 1} attempts\")\n\n        if last_exception:\n            raise last_exception\n        else:\n            raise RuntimeError(f\"Tool {tool_name} failed without exception\")\n\n    def _validate_tool_result(self, result: Any, task: ToolTask) -&gt; bool:\n        \"\"\"Validate tool result to prevent false failures\"\"\"\n\n        # Basic validation\n        if result is None:\n            return False\n\n        # Check for common error indicators\n        if isinstance(result, str):\n            error_indicators = [\"error\", \"failed\", \"exception\", \"timeout\", \"not found\"]\n            result_lower = result.lower()\n\n            # If result contains error indicators but also has substantial content, it might still be valid\n            has_errors = any(indicator in result_lower for indicator in error_indicators)\n            has_content = len(result.strip()) &gt; 20\n\n            if has_errors and not has_content:\n                return False\n\n        # Check against expectation if provided\n        if hasattr(task, 'expectation') and task.expectation:\n            expectation_keywords = task.expectation.lower().split()\n            result_text = str(result).lower()\n\n            # At least one expectation keyword should be present\n            if not any(keyword in result_text for keyword in expectation_keywords):\n                wprint(f\"Tool result doesn't match expectation: {task.expectation}\")\n\n        return True\n\n    def _is_tool_result_success(self, result: Any) -&gt; bool:\n        \"\"\"Determine if a tool result indicates success\"\"\"\n\n        if result is None:\n            return False\n\n        if isinstance(result, bool):\n            return result\n\n        if isinstance(result, list | dict):\n            return len(result) &gt; 0\n\n        if isinstance(result, str):\n            # Check for explicit success/failure indicators\n            result_lower = result.lower()\n\n            success_indicators = [\"success\", \"completed\", \"found\", \"retrieved\", \"generated\"]\n            failure_indicators = [\"error\", \"failed\", \"not found\", \"timeout\", \"exception\"]\n\n            has_success = any(indicator in result_lower for indicator in success_indicators)\n            has_failure = any(indicator in result_lower for indicator in failure_indicators)\n\n            if has_success and not has_failure:\n                return True\n            elif has_failure and not has_success:\n                return False\n            else:\n                # Ambiguous - assume success if there's substantial content\n                return len(result.strip()) &gt; 10\n\n        # For other types, assume success if not None\n        return True\n\n    def _get_execution_history_summary(self) -&gt; str:\n        \"\"\"Get concise execution history summary\"\"\"\n\n        if not hasattr(self, 'execution_history') or not self.execution_history:\n            return \"No execution history\"\n\n        recent = self.execution_history[-3:]  # Last 3 executions\n        summaries = []\n\n        for hist in recent:\n            status = \"Success\" if hist.get(\"success\", False) else \"Failed\"\n            duration = hist.get(\"duration\", 0)\n            strategy = hist.get(\"strategy\", \"Unknown\")\n            summaries.append(f\"{strategy}: {status} ({duration:.1f}s)\")\n\n        return \"; \".join(summaries)\n\n    def _identify_failed_approaches(self) -&gt; list[str]:\n        \"\"\"Identify approaches that have consistently failed\"\"\"\n\n        failed_approaches = []\n\n        # Analyze failed tasks\n        for _task_id, result_data in self.results_store.items():\n            if not result_data.get(\"metadata\", {}).get(\"success\", True):\n                error = result_data.get(\"error\", \"\")\n                if \"tool\" in error.lower():\n                    failed_approaches.append(\"direct_tool_approach\")\n                elif \"search\" in error.lower():\n                    failed_approaches.append(\"search_based_approach\")\n                elif \"llm\" in error.lower():\n                    failed_approaches.append(\"llm_direct_approach\")\n\n        return list(set(failed_approaches))\n\n    def _identify_success_patterns(self) -&gt; list[str]:\n        \"\"\"Identify patterns that have led to success\"\"\"\n\n        success_patterns = []\n\n        # Analyze successful tasks\n        successful_results = [\n            r for r in self.results_store.values()\n            if r.get(\"metadata\", {}).get(\"success\", False)\n        ]\n\n        if successful_results:\n            # Identify common patterns\n            if len(successful_results) &gt; 1:\n                success_patterns.append(\"multi_step_approach\")\n\n            for result in successful_results:\n                data = result.get(\"data\", \"\")\n                if isinstance(data, str) and len(data) &gt; 100:\n                    success_patterns.append(\"detailed_information_retrieval\")\n\n        return list(set(success_patterns))\n\n    def _get_world_model_insights(self) -&gt; str:\n        \"\"\"Get relevant insights from world model\"\"\"\n\n        if not self.variable_manager:\n            return \"\"\n\n        world_data = self.variable_manager.scopes.get(\"world\", {})\n        if not world_data:\n            return \"No world model data\"\n\n        # Get most recent or relevant facts\n        recent_facts = []\n        for key, value in list(world_data.items())[:5]:  # Top 5 facts\n            recent_facts.append(f\"{key}: {str(value)[:50]}...\")\n\n        return \"; \".join(recent_facts)\n\n    def _calculate_decision_confidence(self, context: str) -&gt; float:\n        \"\"\"Calculate confidence in decision based on context\"\"\"\n\n        # Simple heuristic based on context richness\n        base_confidence = 0.5\n\n        # Boost confidence if we have rich context\n        if len(context) &gt; 200:\n            base_confidence += 0.2\n\n        # Boost if we have recent results\n        if \"Recent Results:\" in context:\n            base_confidence += 0.2\n\n        # Reduce if there are many failures\n        failure_count = context.lower().count(\"failed\") + context.lower().count(\"error\")\n        base_confidence -= min(failure_count * 0.1, 0.3)\n\n        return max(0.1, min(1.0, base_confidence))\n</code></pre> <code>exec_async(prep_res)</code> <code>async</code> \u00b6 <p>Hauptausf\u00fchrungslogik mit intelligentem Routing</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def exec_async(self, prep_res):\n    \"\"\"Hauptausf\u00fchrungslogik mit intelligentem Routing\"\"\"\n\n    if \"error\" in prep_res:\n        return {\"error\": prep_res[\"error\"]}\n\n    execution_plan = prep_res[\"execution_plan\"]\n\n    if execution_plan[\"strategy\"] == \"waiting\":\n        return {\n            \"status\": \"waiting\",\n            \"message\": execution_plan[\"reason\"],\n            \"blocked_count\": execution_plan.get(\"blocked_count\", 0)\n        }\n\n    # Starte Ausf\u00fchrung basierend auf Plan\n    execution_start = datetime.now()\n\n    try:\n        if execution_plan[\"strategy\"] == \"parallel\":\n            results = await self._execute_parallel_plan(execution_plan, prep_res)\n        elif execution_plan[\"strategy\"] == \"sequential\":\n            results = await self._execute_sequential_plan(execution_plan, prep_res)\n        else:  # hybrid\n            results = await self._execute_hybrid_plan(execution_plan, prep_res)\n\n        execution_duration = (datetime.now() - execution_start).total_seconds()\n\n        # Speichere Execution-History f\u00fcr LLM-Optimierung\n        self.execution_history.append({\n            \"timestamp\": execution_start.isoformat(),\n            \"strategy\": execution_plan[\"strategy\"],\n            \"duration\": execution_duration,\n            \"tasks_executed\": len(results),\n            \"success\": all(r.get(\"status\") == \"completed\" for r in results),\n            \"plan_confidence\": execution_plan.get(\"confidence\", 0.5)\n        })\n\n        # Behalte nur letzte 10 Executions\n        if len(self.execution_history) &gt; 10:\n            self.execution_history = self.execution_history[-10:]\n\n        return {\n            \"status\": \"executed\",\n            \"results\": results,\n            \"execution_duration\": execution_duration,\n            \"strategy_used\": execution_plan[\"strategy\"],\n            \"completed_tasks\": len([r for r in results if r.get(\"status\") == \"completed\"]),\n            \"failed_tasks\": len([r for r in results if r.get(\"status\") == \"failed\"])\n        }\n\n    except Exception as e:\n        eprint(f\"Execution plan failed: {e}\")\n        return {\n            \"status\": \"execution_failed\",\n            \"error\": str(e),\n            \"results\": []\n        }\n</code></pre> <code>get_execution_statistics()</code> \u00b6 <p>Erhalte detaillierte Ausf\u00fchrungsstatistiken</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def get_execution_statistics(self) -&gt; dict[str, Any]:\n    \"\"\"Erhalte detaillierte Ausf\u00fchrungsstatistiken\"\"\"\n    if not self.execution_history:\n        return {\"message\": \"No execution history available\"}\n\n    history = self.execution_history\n\n    return {\n        \"total_executions\": len(history),\n        \"average_duration\": sum(h[\"duration\"] for h in history) / len(history),\n        \"success_rate\": sum(1 for h in history if h[\"success\"]) / len(history),\n        \"strategy_usage\": {\n            strategy: sum(1 for h in history if h[\"strategy\"] == strategy)\n            for strategy in set(h[\"strategy\"] for h in history)\n        },\n        \"total_tasks_executed\": sum(h[\"tasks_executed\"] for h in history),\n        \"average_confidence\": sum(h[\"plan_confidence\"] for h in history) / len(history),\n        \"recent_performance\": history[-3:] if len(history) &gt;= 3 else history\n    }\n</code></pre> <code>post_async(shared, prep_res, exec_res)</code> <code>async</code> \u00b6 <p>Erweiterte Post-Processing mit dynamischer Plan-Anpassung</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def post_async(self, shared, prep_res, exec_res):\n    \"\"\"Erweiterte Post-Processing mit dynamischer Plan-Anpassung\"\"\"\n\n    # Results store in shared state integrieren\n    shared[\"results\"] = self.results_store\n\n    if exec_res is None or \"error\" in exec_res:\n        shared[\"executor_performance\"] = {\"status\": \"error\", \"last_error\": exec_res.get(\"error\")}\n        return \"execution_error\"\n\n    if exec_res[\"status\"] == \"waiting\":\n        shared[\"executor_status\"] = \"waiting_for_dependencies\"\n        return \"waiting\"\n\n    # Performance-Metriken speichern\n    performance_data = {\n        \"execution_duration\": exec_res.get(\"execution_duration\", 0),\n        \"strategy_used\": exec_res.get(\"strategy_used\", \"unknown\"),\n        \"completed_tasks\": exec_res.get(\"completed_tasks\", 0),\n        \"failed_tasks\": exec_res.get(\"failed_tasks\", 0),\n        \"success_rate\": exec_res.get(\"completed_tasks\", 0) / max(len(exec_res.get(\"results\", [])), 1),\n        \"timestamp\": datetime.now().isoformat()\n    }\n    shared[\"executor_performance\"] = performance_data\n\n    # Check for dynamic planning actions\n    planning_action_detected = False\n\n    for result in exec_res.get(\"results\", []):\n        task_id = result[\"task_id\"]\n        if task_id in shared[\"tasks\"]:\n            task = shared[\"tasks\"][task_id]\n            task.status = result[\"status\"]\n\n            if result[\"status\"] == \"completed\":\n                task.result = result[\"result\"]\n\n                # Check for planning actions from DecisionTasks\n                if hasattr(task, 'metadata') and task.metadata:\n                    routing_action = task.metadata.get(\"routing_action\")\n\n                    if routing_action == \"replan_from_here\":\n                        shared[\"needs_dynamic_replan\"] = True\n                        shared[\"replan_context\"] = task.metadata.get(\"replan_context\", {})\n                        planning_action_detected = True\n                        rprint(f\"Dynamic replan triggered by task {task_id}\")\n\n                    elif routing_action == \"append_plan\":\n                        shared[\"needs_plan_append\"] = True\n                        shared[\"append_context\"] = task.metadata.get(\"append_context\", {})\n                        planning_action_detected = True\n                        rprint(f\"Plan append triggered by task {task_id}\")\n\n                # Store verification results if available\n                if result.get(\"verification\"):\n                    if not hasattr(task, 'metadata'):\n                        task.metadata = {}\n                    task.metadata[\"verification\"] = result[\"verification\"]\n\n            elif result[\"status\"] == \"failed\":\n                task.error = result.get(\"error\", \"Unknown error\")\n\n    # Return appropriate status based on planning actions\n    if planning_action_detected:\n        if shared.get(\"needs_dynamic_replan\"):\n            return \"needs_dynamic_replan\"  # Goes to PlanReflectorNode\n        elif shared.get(\"needs_plan_append\"):\n            return \"needs_plan_append\"  # Goes to PlanReflectorNode\n\n    # Regular completion checking\n    current_plan = shared[\"current_plan\"]\n    if current_plan:\n        all_finished = all(\n            shared[\"tasks\"][task.id].status in [\"completed\", \"failed\"]\n            for task in current_plan.tasks\n        )\n\n        if all_finished:\n            current_plan.status = \"completed\"\n            shared[\"plan_completion_time\"] = datetime.now().isoformat()\n            rprint(f\"Plan {current_plan.id} finished\")\n            return \"plan_completed\"\n        else:\n            ready_tasks = [\n                task for task in current_plan.tasks\n                if shared[\"tasks\"][task.id].status == \"pending\"\n            ]\n\n            if ready_tasks:\n                return \"continue_execution\"\n            else:\n                return \"waiting\"\n\n    return \"execution_complete\"\n</code></pre> <code>prep_async(shared)</code> <code>async</code> \u00b6 <p>Enhanced preparation with unified variable system</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def prep_async(self, shared):\n    \"\"\"Enhanced preparation with unified variable system\"\"\"\n    current_plan = shared.get(\"current_plan\")\n    tasks = shared.get(\"tasks\", {})\n\n    # Get unified variable manager\n    self.variable_manager = shared.get(\"variable_manager\")\n    self.progress_tracker = shared.get(\"progress_tracker\")\n    if not self.variable_manager:\n        self.variable_manager = VariableManager(shared.get(\"world_model\", {}), shared)\n\n    # Register all necessary scopes\n    self.variable_manager.set_results_store(self.results_store)\n    self.variable_manager.set_tasks_store(tasks)\n    self.variable_manager.register_scope('user', shared.get('user_context', {}))\n    self.variable_manager.register_scope('system', {\n        'timestamp': datetime.now().isoformat(),\n        'agent_name': shared.get('agent_instance', {}).amd.name if shared.get('agent_instance') else 'unknown'\n    })\n\n    # Stelle sicher, dass Agent-Referenz verf\u00fcgbar ist\n    if not self.agent_instance:\n        self.agent_instance = shared.get(\"agent_instance\")\n\n    if not current_plan:\n        return {\"error\": \"No active plan\", \"tasks\": tasks}\n\n    # Rest of existing prep_async logic...\n    ready_tasks = self._find_ready_tasks(current_plan, tasks)\n    blocked_tasks = self._find_blocked_tasks(current_plan, tasks)\n\n    execution_plan = await self._create_intelligent_execution_plan(\n        ready_tasks, blocked_tasks, current_plan, shared\n    )\n    self.complex_llm_model = shared.get(\"complex_llm_model\")\n    self.fast_llm_model = shared.get(\"fast_llm_model\")\n\n    return {\n        \"plan\": current_plan,\n        \"ready_tasks\": ready_tasks,\n        \"blocked_tasks\": blocked_tasks,\n        \"all_tasks\": tasks,\n        \"execution_plan\": execution_plan,\n        \"fast_llm_model\": self.fast_llm_model,\n        \"complex_llm_model\": self.complex_llm_model,\n        \"available_tools\": shared.get(\"available_tools\", []),\n        \"world_model\": shared.get(\"world_model\", {}),\n        \"results\": self.results_store,\n        \"variable_manager\": self.variable_manager,\n        \"progress_tracker\": self.progress_tracker ,\n    }\n</code></pre> <code>TaskManagementFlow</code> \u00b6 <p>               Bases: <code>AsyncFlow</code></p> <p>Enhanced Task-Management-Flow with LLMReasonerNode as strategic core. The flow now starts with strategic reasoning and delegates to specialized sub-systems.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>@with_progress_tracking\nclass TaskManagementFlow(AsyncFlow):\n    \"\"\"\n    Enhanced Task-Management-Flow with LLMReasonerNode as strategic core.\n    The flow now starts with strategic reasoning and delegates to specialized sub-systems.\n    \"\"\"\n\n    def __init__(self, max_parallel_tasks: int = 3):\n        # Create the strategic reasoning core (new primary node)\n        self.llm_reasoner = LLMReasonerNode()\n\n        # Create specialized sub-system nodes (now supporting nodes)\n        self.planner_node = TaskPlannerNode()\n        self.executor_node = TaskExecutorNode(max_parallel=max_parallel_tasks)\n        self.sync_node = StateSyncNode()\n        self.llm_tool_node = LLMToolNode()\n\n        # Store references for the reasoner to access sub-systems\n        # These will be injected into shared state during execution\n\n        # === NEW HIERARCHICAL FLOW STRUCTURE ===\n\n        # Primary flow: LLMReasonerNode is the main orchestrator\n        # It makes strategic decisions and routes to appropriate sub-systems\n\n        # The reasoner can internally call any of these sub-systems:\n        # - LLMToolNode for direct tool usage\n        # - TaskPlanner + TaskExecutor for complex project management\n        # - Direct response for simple queries\n\n        # Only one main connection: reasoner completes -&gt; response generation\n        self.llm_reasoner - \"reasoner_complete\" &gt;&gt; self.sync_node\n\n        # Fallback connections for error handling\n        self.llm_reasoner - \"error\" &gt;&gt; self.sync_node\n        self.llm_reasoner - \"timeout\" &gt;&gt; self.sync_node\n\n        # The old linear connections are removed - the reasoner now controls the flow internally\n\n        super().__init__(start=self.llm_reasoner)\n\n    async def run_async(self, shared):\n        \"\"\"Enhanced run with sub-system injection\"\"\"\n\n        # Inject sub-system references into shared state so reasoner can access them\n        shared[\"llm_tool_node_instance\"] = self.llm_tool_node\n        shared[\"task_planner_instance\"] = self.planner_node\n        shared[\"task_executor_instance\"] = self.executor_node\n\n        # Store tool registry access for the reasoner\n        agent_instance = shared.get(\"agent_instance\")\n        if agent_instance:\n            shared[\"tool_registry\"] = agent_instance._tool_registry\n            shared[\"tool_capabilities\"] = agent_instance._tool_capabilities\n\n        # Execute the flow with the reasoner as starting point\n        return await super().run_async(shared)\n</code></pre> <code>run_async(shared)</code> <code>async</code> \u00b6 <p>Enhanced run with sub-system injection</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def run_async(self, shared):\n    \"\"\"Enhanced run with sub-system injection\"\"\"\n\n    # Inject sub-system references into shared state so reasoner can access them\n    shared[\"llm_tool_node_instance\"] = self.llm_tool_node\n    shared[\"task_planner_instance\"] = self.planner_node\n    shared[\"task_executor_instance\"] = self.executor_node\n\n    # Store tool registry access for the reasoner\n    agent_instance = shared.get(\"agent_instance\")\n    if agent_instance:\n        shared[\"tool_registry\"] = agent_instance._tool_registry\n        shared[\"tool_capabilities\"] = agent_instance._tool_capabilities\n\n    # Execute the flow with the reasoner as starting point\n    return await super().run_async(shared)\n</code></pre> <code>TaskPlannerNode</code> \u00b6 <p>               Bases: <code>AsyncNode</code></p> <p>Erweiterte Aufgabenplanung mit dynamischen Referenzen und Tool-Integration</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>@with_progress_tracking\nclass TaskPlannerNode(AsyncNode):\n    \"\"\"Erweiterte Aufgabenplanung mit dynamischen Referenzen und Tool-Integration\"\"\"\n\n    async def prep_async(self, shared):\n        \"\"\"Enhanced preparation with goals-based planning support\"\"\"\n\n        # Check if this is a goals-based call from LLMReasonerNode\n        replan_context = shared.get(\"replan_context\", {})\n        goals_list = replan_context.get(\"goals\", [])\n\n        if goals_list:\n            # Goals-based planning (called by LLMReasonerNode)\n            return {\n                \"goals\": goals_list,\n                \"planning_mode\": \"goals_based\",\n                \"query\": shared.get(\"current_query\", \"\"),\n                \"reasoning_context\": replan_context.get(\"reasoning_context\", \"\"),\n                \"triggered_by\": replan_context.get(\"triggered_by\", \"unknown\"),\n                \"tasks\": shared.get(\"tasks\", {}),\n                \"system_status\": shared.get(\"system_status\", \"idle\"),\n                \"tool_capabilities\": shared.get(\"tool_capabilities\", {}),\n                \"available_tools_names\": shared.get(\"available_tools\", []),\n                \"strategy\": \"goals_decomposition\",  # New strategy type\n                \"fast_llm_model\": shared.get(\"fast_llm_model\"),\n                \"complex_llm_model\": shared.get(\"complex_llm_model\"),\n                \"agent_instance\": shared.get(\"agent_instance\"),\n                \"variable_manager\": shared.get(\"variable_manager\"),\n            }\n        else:\n            # Legacy planning (original query-based approach)\n            return {\n                \"query\": shared.get(\"current_query\", \"\"),\n                \"tasks\": shared.get(\"tasks\", {}),\n                \"system_status\": shared.get(\"system_status\", \"idle\"),\n                \"tool_capabilities\": shared.get(\"tool_capabilities\", {}),\n                \"available_tools_names\": shared.get(\"available_tools\", []),\n                \"strategy\": shared.get(\"selected_strategy\", \"direct_response\"),\n                \"fast_llm_model\": shared.get(\"fast_llm_model\"),\n                \"complex_llm_model\": shared.get(\"complex_llm_model\"),\n                \"agent_instance\": shared.get(\"agent_instance\"),\n                \"variable_manager\": shared.get(\"variable_manager\"),\n                \"planning_mode\": \"legacy\"\n            }\n\n    async def exec_async(self, prep_res):\n        if prep_res[\"strategy\"] == \"fast_simple_planning\":\n            return await self._create_simple_plan(prep_res)\n        else:\n            return await self._advanced_llm_decomposition(prep_res)\n\n    async def post_async(self, shared, prep_res, exec_res):\n        \"\"\"Post-processing nach Plan-Erstellung\"\"\"\n\n        if exec_res is None:\n            shared[\"planning_error\"] = \"Plan creation returned None\"\n            return \"planning_failed\"\n\n        if isinstance(exec_res, TaskPlan):\n\n            progress_tracker = shared.get(\"progress_tracker\")\n            if progress_tracker:\n                await progress_tracker.emit_event(ProgressEvent(\n                    event_type=\"plan_created\",\n                    node_name=\"TaskPlannerNode\",\n                    session_id=shared.get(\"session_id\"),\n                    status=NodeStatus.COMPLETED,\n                    success=True,\n                    plan_id=exec_res.id,\n                    metadata={\n                        \"plan_name\": exec_res.name,\n                        \"task_count\": len(exec_res.tasks),\n                        \"strategy\": exec_res.execution_strategy\n                    }\n                ))\n                await asyncio.sleep(0.1)\n\n            # Erfolgreicher Plan\n            shared[\"current_plan\"] = exec_res\n\n            # Tasks in shared state f\u00fcr Executor verf\u00fcgbar machen\n            task_dict = {task.id: task for task in exec_res.tasks}\n            if \"tasks\" not in shared:\n                shared[\"tasks\"] = task_dict\n            else:\n                shared[\"tasks\"].update(task_dict)\n\n            # Plan-Metadaten setzen\n            shared[\"plan_created_at\"] = datetime.now().isoformat()\n            shared[\"plan_strategy\"] = exec_res.execution_strategy\n            shared[\"total_tasks_planned\"] = len(exec_res.tasks)\n\n            rprint(f\"Plan created successfully: {exec_res.name} with {len(exec_res.tasks)} tasks\")\n            return \"planned\"\n\n        else:\n            # Plan creation failed\n            shared[\"planning_error\"] = \"Invalid plan format returned\"\n            shared[\"current_plan\"] = None\n            eprint(\"Plan creation failed - invalid format\")\n            return \"planning_failed\"\n\n    async def _create_simple_plan(self, prep_res) -&gt; TaskPlan:\n        \"\"\"Fast lightweight planning for direct or simple multi-step queries.\"\"\"\n        taw = self._build_tool_intelligence(prep_res)\n        rprint(\"You are a FAST \"+ taw)\n        prompt = f\"\"\"\nYou are a FAST abstract pattern recognizer and task planner.\nIdentify if the query needs a **single-step LLM answer** or a **simple 2\u20133 task plan** using available tools.\nOutput ONLY YAML.\n\n## User Query\n{prep_res['query']}\n\n## Available Tools\n{taw}\n\n## Pattern Recognition (Internal Only)\n- Detect if query is informational, action-based, or tool-eligible.\n- Map to minimal plan type: \"direct_llm\" or \"simple_tool_plus_llm\".\n\n## YAML Schema\n```yaml\nplan_name: string\ndescription: string\nexecution_strategy: \"sequential\" | \"parallel\"\ntasks:\n  - id: string\n    type: \"LLMTask\" | \"ToolTask\"\n    description: string\n    priority: int\n    dependencies: [list]\nExample 1 \u2014 Direct LLM\n```yaml\nplan_name: Direct Response\ndescription: Quick answer from LLM\nexecution_strategy: sequential\ntasks:\n  - id: answer\n    type: LLMTask\n    description: Respond to query\n    priority: 1\n    dependencies: []\n    prompt_template: Respond concisely to: {prep_res['query']}\n    llm_config:\n      model_preference: fast\n      temperature: 0.3\n```\nExample 2 \u2014 Tool + LLM\n```yaml\nplan_name: Fetch and Answer\ndescription: Get info from tool and summarize\nexecution_strategy: sequential\ntasks:\n  - id: fetch_info\n    type: ToolTask\n    description: Get required data\n    priority: 1\n    dependencies: []\n    tool_name: info_api\n    arguments:\n      query: \"{prep_res['query']}\"\n  - id: summarize\n    type: LLMTask\n    description: Summarize fetched data\n    priority: 2\n    dependencies: [\"fetch_info\"]\n    prompt_template: Summarize: {{ results.fetch_info.data }}\n    llm_config:\n      model_preference: fast\n      temperature: 0.3\n```\nOutput Requirements\nUse ONLY YAML for the final output\nPick minimal plan type for fastest completion!\nfocus on correct quotation and correct yaml format!\n    \"\"\"\n\n        try:\n            agent_instance = prep_res[\"agent_instance\"]\n            content = await agent_instance.a_run_llm_completion(\n                model=prep_res.get(\"complex_llm_model\", \"openrouter/anthropic/claude-3-haiku\"),\n                messages=[{\"role\": \"user\", \"content\": prompt}],\n                temperature=0.3,\n                max_tokens=4512,\n                node_name=\"TaskPlannerNode\", task_id=\"fast_simple_planning\"\n            )\n\n            yaml_content = content.split(\"```yaml\")[1].split(\"```\")[0].strip() if \"```yaml\" in content else content\n            plan_data = yaml.safe_load(yaml_content)\n            # print(\"Simple\", json.dumps(plan_data, indent=2))\n            return TaskPlan(\n                id=str(uuid.uuid4()),\n                name=plan_data.get(\"plan_name\", \"Generated Plan\"),\n                description=plan_data.get(\"description\", f\"Plan for: {prep_res['query']}\"),\n                tasks=[\n                    [LLMTask, ToolTask, DecisionTask, Task][[\"LLMTask\", \"ToolTask\", \"DecisionTask\", \"Task\"].index(t.get(\"type\"))](**t)\n                    for t in plan_data.get(\"tasks\", [])\n                ],\n                execution_strategy=plan_data.get(\"execution_strategy\", \"sequential\")\n            )\n\n        except Exception as e:\n            eprint(f\"Simple plan creation failed: {e}\")\n            import traceback\n            print(traceback.format_exc())\n            return TaskPlan(\n                id=str(uuid.uuid4()),\n                name=\"Fallback Plan\",\n                description=\"Direct response only\",\n                tasks=[\n                    LLMTask(\n                        id=\"fast_simple_planning\",\n                        type=\"LLMTask\",\n                        description=\"Generate direct response\",\n                        priority=1,\n                        dependencies=[],\n                        prompt_template=f\"Respond to the query: {prep_res['query']}\",\n                        llm_config={\"model_preference\": \"fast\"}\n                    )\n                ]\n            )\n\n    async def _advanced_llm_decomposition(self, prep_res) -&gt; TaskPlan:\n        \"\"\"Enhanced LLM-based decomposition with goals-based planning support\"\"\"\n\n        planning_mode = prep_res.get(\"planning_mode\", \"legacy\")\n        variable_manager = prep_res.get(\"variable_manager\")\n        tool_intelligence = self._build_tool_intelligence(prep_res)\n\n        if planning_mode == \"goals_based\":\n            # Goals-based planning from LLMReasonerNode\n            goals_list = prep_res.get(\"goals\", [])\n            reasoning_context = prep_res.get(\"reasoning_context\", \"\")\n\n            prompt = f\"\"\"\nYou are an expert task planner specialized in creating execution plans from strategic goals.\nCreate a comprehensive plan that addresses all goals with proper dependencies and parallelization.\n\n## Strategic Goals from Reasoner\n{chr(10).join([f\"{i + 1}. {goal}\" for i, goal in enumerate(goals_list)])}\n\n## Reasoning Context\n{reasoning_context}\n\n## Your Available Tools &amp; Intelligence\n{tool_intelligence}\n\n{variable_manager.get_llm_variable_context() if variable_manager else \"\"}\n\n## Goals-Based Planning Instructions\n1. Analyze each goal for dependencies on other goals\n2. Identify goals that can be executed in parallel\n3. Create tasks that address each goal effectively\n4. Use variable references {{ results.task_id.data }} for dependencies\n5. Ensure proper sequencing and coordination\n\n## YAML Schema\n```yaml\nplan_name: string\ndescription: string\nexecution_strategy: \"sequential\" | \"parallel\" | \"mixed\"\ntasks:\n  - id: string\n    type: \"LLMTask\" | \"ToolTask\" | \"DecisionTask\"\n    description: string\n    priority: int\n    dependencies: [list of task ids]\n    # Type-specific fields as needed\nGoals Decomposition Strategy\n\nIndependent Goals: Create parallel tasks\nSequential Goals: Use dependencies array\nComplex Goals: Break into sub-tasks with DecisionTask routing\nData Dependencies: Use variable references between tasks\n\nExample for Multi-Goal Plan\nyamlCopyplan_name: \"Multi-Goal Strategic Plan\"\ndescription: \"Execute multiple strategic objectives with proper coordination\"\nexecution_strategy: \"mixed\"\ntasks:\n  - id: \"goal_1_research\"\n    type: \"ToolTask\"\n    description: \"Research data for Goal 1\"\n    priority: 1\n    dependencies: []\n    tool_name: \"search_web\"\n    arguments:\n      query: \"research topic for goal 1\"\n\n  - id: \"goal_2_research\"\n    type: \"ToolTask\"\n    description: \"Research data for Goal 2\"\n    priority: 1\n    dependencies: []\n    tool_name: \"search_web\"\n    arguments:\n      query: \"research topic for goal 2\"\n\n  - id: \"analyze_combined\"\n    type: \"LLMTask\"\n    description: \"Analyze combined research results\"\n    priority: 2\n    dependencies: [\"goal_1_research\", \"goal_2_research\"]\n    prompt_template: |\n      Analyze these research results:\n      Goal 1 Data: {{ results.goal_1_research.data }}\n      Goal 2 Data: {{ results.goal_2_research.data }}\n\n      Provide comprehensive analysis addressing both goals.\n    llm_config:\n      model_preference: \"complex\"\n      temperature: 0.3\nGenerate the execution plan for the strategic goals:\n    \"\"\"\n\n        else:\n            # Legacy single-query planning\n            base_query = prep_res['query']\n            prompt = f\"\"\"\nYou are an expert task planner with dynamic adaptation capabilities.\nCreate intelligent, adaptive execution plans for the user query.\nUser Query\n{base_query}\nYour Available Tools &amp; Intelligence\n{tool_intelligence}\n{variable_manager.get_llm_variable_context() if variable_manager else \"\"}\nTASK TYPES (Dataclass-Aligned)\n\nLLMTask: Step that uses a language model\nToolTask: Step that calls an available tool\nDecisionTask: Step that decides routing between tasks\n\nYAML SCHEMA\nyamlCopyplan_name: string\ndescription: string\nexecution_strategy: \"sequential\" | \"parallel\" | \"mixed\"\ntasks:\n  - id: string\n    type: \"LLMTask\" | \"ToolTask\" | \"DecisionTask\"\n    description: string\n    priority: int\n    dependencies: [list of task ids]\n    # Additional fields depending on type\nGenerate the adaptive execution plan:\n            \"\"\"\n\n        try:\n            model_to_use = prep_res.get(\"complex_llm_model\", \"openrouter/openai/gpt-4o\")\n            agent_instance = prep_res[\"agent_instance\"]\n\n            content = await agent_instance.a_run_llm_completion(\n                model=model_to_use,\n                messages=[{\"role\": \"user\", \"content\": prompt}],\n                temperature=0.3,\n                #max_tokens=2048,\n                node_name=\"TaskPlannerNode\",\n                task_id=\"goals_based_planning\" if planning_mode == \"goals_based\" else \"adaptive_planning\"\n            )\n\n            if \"```yaml\" in content:\n                yaml_content = content.split(\"```yaml\")[1].split(\"```\")[0].strip()\n            else:\n                yaml_content = content\n\n            plan_data = yaml.safe_load(yaml_content)\n\n            # Create specialized tasks\n            tasks = []\n            for task_data in plan_data.get(\"tasks\", []):\n                task_type = task_data.pop(\"type\", \"generic\")\n                task = create_task(task_type, **task_data)\n                tasks.append(task)\n\n            plan = TaskPlan(\n                id=str(uuid.uuid4()),\n                name=plan_data.get(\"plan_name\", \"Generated Plan\"),\n                description=plan_data.get(\"description\",\n                                          \"Plan for goals-based execution\" if planning_mode == \"goals_based\" else f\"Plan for: {base_query}\"),\n                tasks=tasks,\n                execution_strategy=plan_data.get(\"execution_strategy\", \"sequential\"),\n                metadata={\n                    \"planning_mode\": planning_mode,\n                    \"goals_count\": len(prep_res.get(\"goals\", [])) if planning_mode == \"goals_based\" else 1\n                }\n            )\n\n            rprint(f\"Created {planning_mode} plan with {len(tasks)} tasks\")\n            return plan\n\n        except Exception as e:\n            eprint(f\"Advanced planning failed: {e}\")\n            import traceback\n\n            print(traceback.format_exc())\n            return await self._create_simple_plan(prep_res)\n\n    def _build_tool_intelligence(self, prep_res: dict) -&gt; str:\n        \"\"\"Build detailed tool intelligence for planning\"\"\"\n\n        agent_instance = prep_res.get(\"agent_instance\")\n        if not agent_instance or not hasattr(agent_instance, '_tool_capabilities'):\n            return \"No tool intelligence available.\"\n\n        capabilities = agent_instance._tool_capabilities\n        query = prep_res.get('query', '').lower()\n\n        context_parts = []\n        context_parts.append(\"### Intelligent Tool Analysis:\")\n\n        for tool_name, cap in capabilities.items():\n            context_parts.append(f\"\\n{tool_name}:\")\n            context_parts.append(f\"- Function: {cap.get('primary_function', 'Unknown')}\")\n            context_parts.append(f\"- Arguments: {yaml.dump(cap.get('args_schema', 'takes no arguments!'), default_flow_style=False)}\")\n\n            # Check relevance to current query\n            relevance_score = self._calculate_tool_relevance(query, cap)\n            context_parts.append(f\"- Query relevance: {relevance_score:.2f}\")\n\n            if relevance_score &gt; 0.4:\n                context_parts.append(\"- \u2b50 HIGHLY RELEVANT - SHOULD USE THIS TOOL!\")\n\n            # Show trigger analysis\n            triggers = cap.get('trigger_phrases', [])\n            matched_triggers = [t for t in triggers if t.lower() in query]\n            if matched_triggers:\n                context_parts.append(f\"- Matched triggers: {matched_triggers}\")\n\n            # Show use cases\n            use_cases = cap.get('use_cases', [])[:3]\n            context_parts.append(f\"- Use cases: {', '.join(use_cases)}\")\n\n        return \"\\n\".join(context_parts)\n\n    def _calculate_tool_relevance(self, query: str, capabilities: dict) -&gt; float:\n        \"\"\"Calculate how relevant a tool is to the current query\"\"\"\n\n        query_words = set(query.lower().split())\n\n        # Check trigger phrases\n        trigger_score = 0.0\n        triggers = capabilities.get('trigger_phrases', [])\n        for trigger in triggers:\n            trigger_words = set(trigger.lower().split())\n            if trigger_words.intersection(query_words):\n                trigger_score += 0.04\n        # Check confidence triggers if available\n        conf_triggers = capabilities.get('confidence_triggers', {})\n        for phrase, confidence in conf_triggers.items():\n            if phrase.lower() in query:\n                trigger_score += confidence/10\n        # Check indirect connections\n        indirect = capabilities.get('indirect_connections', [])\n        for connection in indirect:\n            connection_words = set(connection.lower().split())\n            if connection_words.intersection(query_words):\n                trigger_score += 0.02\n        return min(1.0, trigger_score)\n</code></pre> <code>post_async(shared, prep_res, exec_res)</code> <code>async</code> \u00b6 <p>Post-processing nach Plan-Erstellung</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def post_async(self, shared, prep_res, exec_res):\n    \"\"\"Post-processing nach Plan-Erstellung\"\"\"\n\n    if exec_res is None:\n        shared[\"planning_error\"] = \"Plan creation returned None\"\n        return \"planning_failed\"\n\n    if isinstance(exec_res, TaskPlan):\n\n        progress_tracker = shared.get(\"progress_tracker\")\n        if progress_tracker:\n            await progress_tracker.emit_event(ProgressEvent(\n                event_type=\"plan_created\",\n                node_name=\"TaskPlannerNode\",\n                session_id=shared.get(\"session_id\"),\n                status=NodeStatus.COMPLETED,\n                success=True,\n                plan_id=exec_res.id,\n                metadata={\n                    \"plan_name\": exec_res.name,\n                    \"task_count\": len(exec_res.tasks),\n                    \"strategy\": exec_res.execution_strategy\n                }\n            ))\n            await asyncio.sleep(0.1)\n\n        # Erfolgreicher Plan\n        shared[\"current_plan\"] = exec_res\n\n        # Tasks in shared state f\u00fcr Executor verf\u00fcgbar machen\n        task_dict = {task.id: task for task in exec_res.tasks}\n        if \"tasks\" not in shared:\n            shared[\"tasks\"] = task_dict\n        else:\n            shared[\"tasks\"].update(task_dict)\n\n        # Plan-Metadaten setzen\n        shared[\"plan_created_at\"] = datetime.now().isoformat()\n        shared[\"plan_strategy\"] = exec_res.execution_strategy\n        shared[\"total_tasks_planned\"] = len(exec_res.tasks)\n\n        rprint(f\"Plan created successfully: {exec_res.name} with {len(exec_res.tasks)} tasks\")\n        return \"planned\"\n\n    else:\n        # Plan creation failed\n        shared[\"planning_error\"] = \"Invalid plan format returned\"\n        shared[\"current_plan\"] = None\n        eprint(\"Plan creation failed - invalid format\")\n        return \"planning_failed\"\n</code></pre> <code>prep_async(shared)</code> <code>async</code> \u00b6 <p>Enhanced preparation with goals-based planning support</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def prep_async(self, shared):\n    \"\"\"Enhanced preparation with goals-based planning support\"\"\"\n\n    # Check if this is a goals-based call from LLMReasonerNode\n    replan_context = shared.get(\"replan_context\", {})\n    goals_list = replan_context.get(\"goals\", [])\n\n    if goals_list:\n        # Goals-based planning (called by LLMReasonerNode)\n        return {\n            \"goals\": goals_list,\n            \"planning_mode\": \"goals_based\",\n            \"query\": shared.get(\"current_query\", \"\"),\n            \"reasoning_context\": replan_context.get(\"reasoning_context\", \"\"),\n            \"triggered_by\": replan_context.get(\"triggered_by\", \"unknown\"),\n            \"tasks\": shared.get(\"tasks\", {}),\n            \"system_status\": shared.get(\"system_status\", \"idle\"),\n            \"tool_capabilities\": shared.get(\"tool_capabilities\", {}),\n            \"available_tools_names\": shared.get(\"available_tools\", []),\n            \"strategy\": \"goals_decomposition\",  # New strategy type\n            \"fast_llm_model\": shared.get(\"fast_llm_model\"),\n            \"complex_llm_model\": shared.get(\"complex_llm_model\"),\n            \"agent_instance\": shared.get(\"agent_instance\"),\n            \"variable_manager\": shared.get(\"variable_manager\"),\n        }\n    else:\n        # Legacy planning (original query-based approach)\n        return {\n            \"query\": shared.get(\"current_query\", \"\"),\n            \"tasks\": shared.get(\"tasks\", {}),\n            \"system_status\": shared.get(\"system_status\", \"idle\"),\n            \"tool_capabilities\": shared.get(\"tool_capabilities\", {}),\n            \"available_tools_names\": shared.get(\"available_tools\", []),\n            \"strategy\": shared.get(\"selected_strategy\", \"direct_response\"),\n            \"fast_llm_model\": shared.get(\"fast_llm_model\"),\n            \"complex_llm_model\": shared.get(\"complex_llm_model\"),\n            \"agent_instance\": shared.get(\"agent_instance\"),\n            \"variable_manager\": shared.get(\"variable_manager\"),\n            \"planning_mode\": \"legacy\"\n        }\n</code></pre> <code>ToolAnalysis</code> \u00b6 <p>               Bases: <code>BaseModel</code></p> <p>Defines the structure for a valid tool analysis.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>class ToolAnalysis(BaseModel):\n    \"\"\"Defines the structure for a valid tool analysis.\"\"\"\n    primary_function: str = Field(..., description=\"The main purpose of the tool.\")\n    use_cases: list[str] = Field(..., description=\"Specific use cases for the tool.\")\n    trigger_phrases: list[str] = Field(..., description=\"Phrases that should trigger the tool.\")\n    indirect_connections: list[str] = Field(..., description=\"Non-obvious connections or applications.\")\n    complexity_scenarios: list[str] = Field(..., description=\"Complex scenarios where the tool can be applied.\")\n    user_intent_categories: list[str] = Field(..., description=\"Categories of user intent the tool addresses.\")\n    confidence_triggers: dict[str, float] = Field(..., description=\"Phrases mapped to confidence scores.\")\n    tool_complexity: str = Field(..., description=\"The complexity of the tool, rated as low, medium, or high.\")\n    args_schema: dict[str, Any] | None = Field(..., description=\"The schema for the tool's arguments.\")\n</code></pre> <code>ToolTask</code> <code>dataclass</code> \u00b6 <p>               Bases: <code>Task</code></p> <p>Spezialisierter Task f\u00fcr Tool-Aufrufe</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>@dataclass\nclass ToolTask(Task):\n    \"\"\"Spezialisierter Task f\u00fcr Tool-Aufrufe\"\"\"\n    tool_name: str = \"\"\n    arguments: dict[str, Any] = field(default_factory=dict)  # Kann {{ }} Referenzen enthalten\n    hypothesis: str = \"\"  # Was erwarten wir von diesem Tool?\n    validation_criteria: str = \"\"  # Wie validieren wir das Ergebnis?\n    expectation: str = \"\"  # Wie sollte das Ergebnis aussehen?\n</code></pre> <code>UnifiedContextManager</code> \u00b6 <p>Zentrale Orchestrierung aller Context-Quellen f\u00fcr einheitlichen und effizienten Datenzugriff. Vereinigt ChatSession, VariableManager, World Model und Task Results.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>class UnifiedContextManager:\n    \"\"\"\n    Zentrale Orchestrierung aller Context-Quellen f\u00fcr einheitlichen und effizienten Datenzugriff.\n    Vereinigt ChatSession, VariableManager, World Model und Task Results.\n    \"\"\"\n\n    def __init__(self, agent):\n        self.agent = agent\n        self.session_managers: dict[str, ChatSession | dict] = {}  # ChatSession objects\n        self.variable_manager: VariableManager = None\n        self.compression_threshold = 15  # Messages before compression\n        self._context_cache: dict[str, tuple[float, Any]] = {}  # (timestamp, data)\n        self.cache_ttl = 300  # 5 minutes\n        self._memory_instance = None\n\n    async def initialize_session(self, session_id: str, max_history: int = 200):\n        \"\"\"Initialisiere oder lade existierende ChatSession als prim\u00e4re Context-Quelle\"\"\"\n        if session_id not in self.session_managers:\n            try:\n                # Get memory instance\n                if not self._memory_instance:\n                    from toolboxv2 import get_app\n                    self._memory_instance = get_app().get_mod(\"isaa\").get_memory()\n\n                # Create ChatSession as PRIMARY memory source\n                session = ChatSession(\n                    self._memory_instance,\n                    max_length=max_history,\n                    space_name=f\"ChatSession/{self.agent.amd.name}.{session_id}.unified\"\n                )\n                self.session_managers[session_id] = session\n\n                # Integration mit VariableManager wenn verf\u00fcgbar\n                if self.variable_manager:\n                    self.variable_manager.register_scope(f'session_{session_id}', {\n                        'chat_session_active': True,\n                        'history_length': len(session.history),\n                        'last_interaction': None,\n                        'session_id': session_id\n                    })\n\n                rprint(f\"Unified session context initialized for {session_id}\")\n                return session\n\n            except Exception as e:\n                eprint(f\"Failed to create ChatSession for {session_id}: {e}\")\n                # Fallback: Create minimal session manager\n                self.session_managers[session_id] = {\n                    'history': [],\n                    'session_id': session_id,\n                    'fallback_mode': True\n                }\n                return self.session_managers[session_id]\n\n        return self.session_managers[session_id]\n\n    async def add_interaction(self, session_id: str, role: str, content: str, metadata: dict = None) -&gt; None:\n        \"\"\"Einheitlicher Weg um Interaktionen in ChatSession zu speichern\"\"\"\n        session = await self.initialize_session(session_id)\n\n        message = {\n            'role': role,\n            'content': content,\n            'timestamp': datetime.now().isoformat(),\n            'session_id': session_id,\n            'metadata': metadata or {}\n        }\n\n        # PRIMARY: Store in ChatSession\n        if hasattr(session, 'add_message'):\n            await session.add_message(message, direct=False)\n        elif isinstance(session, dict) and 'history' in session:\n            # Fallback mode\n            session['history'].append(message)\n            # Keep max length\n            max_len = 200\n            if len(session['history']) &gt; max_len:\n                session['history'] = session['history'][-max_len:]\n\n        # SECONDARY: Update VariableManager\n        if self.variable_manager:\n            self.variable_manager.set(f'session_{session_id}.last_interaction', message)\n            if hasattr(session, 'history'):\n                self.variable_manager.set(f'session_{session_id}.history_length', len(session.history))\n            elif isinstance(session, dict):\n                self.variable_manager.set(f'session_{session_id}.history_length', len(session.get('history', [])))\n\n        # Clear context cache for this session\n        self._invalidate_cache(session_id)\n\n    async def get_contextual_history(self, session_id: str, query: str = \"\", max_entries: int = 10) -&gt; list[dict]:\n        \"\"\"Intelligente Auswahl relevanter Geschichte aus ChatSession\"\"\"\n        session = self.session_managers.get(session_id)\n        if not session:\n            return []\n\n        try:\n            # ChatSession mode\n            if hasattr(session, 'get_past_x'):\n                recent_history = session.get_past_x(max_entries * 2, last_u=False)\n                # await session.get_reference(query, limit=5)\n\n                return recent_history[:max_entries]\n\n            # Fallback mode\n            elif isinstance(session, dict) and 'history' in session:\n                history = session['history']\n                # Return last max_entries, starting with last user message\n                result = []\n                for msg in reversed(history[-max_entries * 2:]):\n                    result.append(msg)\n                    if msg.get('role') == 'user' and len(result) &gt;= max_entries:\n                        break\n                return list(reversed(result))[:max_entries]\n\n        except Exception as e:\n            eprint(f\"Error getting contextual history: {e}\")\n\n        return []\n\n    async def build_unified_context(self, session_id: str, query: str = None, context_type: str = \"full\") -&gt; dict[\n        str, Any]:\n        \"\"\"ZENTRALE Methode f\u00fcr vollst\u00e4ndigen Context-Aufbau aus allen Quellen\"\"\"\n\n        # Cache check\n        cache_key = f\"{session_id}_{hash(query or '')}_{context_type}\"\n        cached = self._get_cached_context(cache_key)\n        if cached:\n            return cached\n\n        context = {\n            'timestamp': datetime.now().isoformat(),\n            'session_id': session_id,\n            'query': query,\n            'context_type': context_type\n        }\n\n        try:\n            # 1. CHAT HISTORY (Primary - from ChatSession)\n            context['chat_history'] = await self.get_contextual_history(\n                session_id, query or \"\", max_entries=15\n            )\n\n            # 2. VARIABLE SYSTEM STATE\n            if self.variable_manager:\n                context['variables'] = {\n                    'available_scopes': list(self.variable_manager.scopes.keys()),\n                    'total_variables': len(self.variable_manager.get_available_variables()),\n                    'recent_results': self._get_recent_results(5)\n                }\n            else:\n                context['variables'] = {'status': 'variable_manager_not_available'}\n\n            # 3. WORLD MODEL FACTS\n            if self.variable_manager:\n                world_model = self.variable_manager.get('world', {})\n                if world_model and query:\n                    context['relevant_facts'] = self._extract_relevant_facts(world_model, query)\n                else:\n                    context['relevant_facts'] = list(world_model.items())[:5]  # Top 5 facts\n\n            # 4. EXECUTION STATE\n            context['execution_state'] = {\n                'active_tasks': self._get_active_tasks(),\n                'recent_completions': self._get_recent_completions(3),\n                'system_status': self.agent.shared.get('system_status', 'idle')\n            }\n\n            # 5. SESSION STATISTICS\n            context['session_stats'] = {\n                'total_sessions': len(self.session_managers),\n                'current_session_length': len(context['chat_history']),\n                'cache_enabled': bool(self._context_cache)\n            }\n\n        except Exception as e:\n            eprint(f\"Error building unified context: {e}\")\n            context['error'] = str(e)\n            context['fallback_mode'] = True\n\n        # Cache result\n        self._cache_context(cache_key, context)\n        return context\n\n    def get_formatted_context_for_llm(self, unified_context: dict[str, Any]) -&gt; str:\n        \"\"\"Formatiere unified context f\u00fcr LLM consumption\"\"\"\n        try:\n            parts = []\n\n            # Recent Chat History\n            chat_history = unified_context.get('chat_history', [])\n            if chat_history:\n                parts.append(\"## Recent Conversation\")\n                for msg in chat_history[-5:]:  # Last 5 messages\n                    timestamp = msg.get('timestamp', '')[:19]  # Remove microseconds\n                    role = msg.get('role', 'unknown')\n                    content = msg.get('content', '')[:500] + (\"...\" if len(msg.get('content', '')) &gt; 500 else \"\")\n                    parts.append(f\"[{timestamp}] {role}: {content}\")\n\n            # System Status\n            execution_state = unified_context.get('execution_state', {})\n            if execution_state:\n                parts.append(\"\\n## Current System State\")\n                parts.append(f\"Status: {execution_state.get('system_status', 'unknown')}\")\n\n                active_tasks = execution_state.get('active_tasks', [])\n                if active_tasks:\n                    parts.append(f\"Active Tasks: {len(active_tasks)}\")\n\n                recent_completions = execution_state.get('recent_completions', [])\n                if recent_completions:\n                    parts.append(f\"Recent Completions: {len(recent_completions)}\")\n\n            # Available Data\n            variables = unified_context.get('variables', {})\n            if variables and variables.get('recent_results'):\n                parts.append(\"\\n## Available Results\")\n                recent_results = variables['recent_results']\n                for result in recent_results[:3]:  # Top 3 results\n                    parts.append(f\"- {result.get('task_id', 'unknown')}: {str(result.get('preview', ''))[:100]}...\")\n\n            # World Model Facts\n            relevant_facts = unified_context.get('relevant_facts', [])\n            if relevant_facts:\n                parts.append(\"\\n## Known Facts\")\n                for key, value in relevant_facts[:5]:  # Top 5 facts\n                    fact_preview = str(value)[:100] + (\"...\" if len(str(value)) &gt; 100 else \"\")\n                    parts.append(f\"- {key}: {fact_preview}\")\n\n            parts.append(f\"\\n---\\nContext generated at: {unified_context.get('timestamp', 'unknown')}\")\n\n            return \"\\n\".join(parts)\n\n        except Exception as e:\n            eprint(f\"Error formatting context for LLM: {e}\")\n            return f\"Context formatting error: {str(e)}\"\n\n    def _merge_and_dedupe_history(self, recent_history: list[dict], relevant_refs: list) -&gt; list[dict]:\n        \"\"\"Merge und dedupliziere History-Eintr\u00e4ge\"\"\"\n        try:\n            merged = recent_history.copy()\n\n            # Add relevant references if they're not already in recent history\n            for ref in relevant_refs:\n                # Convert ref to message format if needed\n                if isinstance(ref, dict) and 'content' in ref:\n                    # Check if not already in recent_history\n                    is_duplicate = any(\n                        msg.get('content', '') == ref.get('content', '') and\n                        msg.get('timestamp', '') == ref.get('timestamp', '')\n                        for msg in merged\n                    )\n                    if not is_duplicate:\n                        merged.append(ref)\n\n            # Sort by timestamp\n            merged.sort(key=lambda x: x.get('timestamp', ''))\n\n            return merged\n        except:\n            return recent_history\n\n    def _get_recent_results(self, limit: int = 5) -&gt; list[dict]:\n        \"\"\"Hole recent results aus dem shared state\"\"\"\n        try:\n            results_store = self.agent.shared.get(\"results\", {})\n            recent_results = []\n\n            for task_id, result_data in list(results_store.items())[-limit:]:\n                if result_data and result_data.get(\"data\"):\n                    preview = str(result_data[\"data\"])[:150] + \"...\"\n                    recent_results.append({\n                        \"task_id\": task_id,\n                        \"preview\": preview,\n                        \"success\": result_data.get(\"metadata\", {}).get(\"success\", False),\n                        \"timestamp\": result_data.get(\"metadata\", {}).get(\"completed_at\")\n                    })\n\n            return recent_results\n        except:\n            return []\n\n    def _extract_relevant_facts(self, world_model: dict, query: str) -&gt; list[tuple[str, Any]]:\n        \"\"\"Extrahiere relevante Facts basierend auf Query\"\"\"\n        try:\n            query_words = set(query.lower().split())\n            relevant_facts = []\n\n            for key, value in world_model.items():\n                # Simple relevance scoring\n                key_words = set(key.lower().split())\n                value_words = set(str(value).lower().split())\n\n                # Check for word overlap\n                key_overlap = len(query_words.intersection(key_words))\n                value_overlap = len(query_words.intersection(value_words))\n\n                if key_overlap &gt; 0 or value_overlap &gt; 0:\n                    relevance_score = key_overlap * 2 + value_overlap  # Key matches weighted higher\n                    relevant_facts.append((relevance_score, key, value))\n\n            # Sort by relevance and return top facts\n            relevant_facts.sort(key=lambda x: x[0], reverse=True)\n            return [(key, value) for _, key, value in relevant_facts[:5]]\n        except:\n            return list(world_model.items())[:5]\n\n    def _get_active_tasks(self) -&gt; list[dict]:\n        \"\"\"Hole aktive Tasks\"\"\"\n        try:\n            tasks = self.agent.shared.get(\"tasks\", {})\n            return [\n                {\"id\": task_id, \"description\": task.description, \"status\": task.status}\n                for task_id, task in tasks.items()\n                if task.status == \"running\"\n            ]\n        except:\n            return []\n\n    def _get_recent_completions(self, limit: int = 3) -&gt; list[dict]:\n        \"\"\"Hole recent completions\"\"\"\n        try:\n            tasks = self.agent.shared.get(\"tasks\", {})\n            completed = [\n                {\"id\": task_id, \"description\": task.description, \"completed_at\": task.completed_at}\n                for task_id, task in tasks.items()\n                if task.status == \"completed\" and hasattr(task, 'completed_at') and task.completed_at\n            ]\n            # Sort by completion time\n            completed.sort(key=lambda x: x.get('completed_at', ''), reverse=True)\n            return completed[:limit]\n        except:\n            return []\n\n    def _get_cached_context(self, cache_key: str) -&gt; dict[str, Any] | None:\n        \"\"\"Hole Context aus Cache wenn noch g\u00fcltig\"\"\"\n        if cache_key in self._context_cache:\n            timestamp, data = self._context_cache[cache_key]\n            if time.time() - timestamp &lt; self.cache_ttl:\n                return data\n            else:\n                del self._context_cache[cache_key]\n        return None\n\n    def _cache_context(self, cache_key: str, context: dict[str, Any]):\n        \"\"\"Speichere Context in Cache\"\"\"\n        self._context_cache[cache_key] = (time.time(), context.copy())\n\n        # Cleanup old cache entries\n        if len(self._context_cache) &gt; 50:  # Keep max 50 entries\n            oldest_key = min(self._context_cache.keys(),\n                             key=lambda k: self._context_cache[k][0])\n            del self._context_cache[oldest_key]\n\n    def _invalidate_cache(self, session_id: str = None):\n        \"\"\"Invalidate cache for specific session or all\"\"\"\n        if session_id:\n            # Remove all cache entries for this session\n            keys_to_remove = [k for k in self._context_cache if session_id in k]\n            for key in keys_to_remove:\n                del self._context_cache[key]\n        else:\n            self._context_cache.clear()\n\n    def get_session_statistics(self) -&gt; dict[str, Any]:\n        \"\"\"Hole Statistiken \u00fcber alle Sessions\"\"\"\n        stats = {\n            \"total_sessions\": len(self.session_managers),\n            \"active_sessions\": [],\n            \"cache_entries\": len(self._context_cache),\n            \"cache_hit_rate\": 0.0  # Could be tracked if needed\n        }\n\n        for session_id, session in self.session_managers.items():\n            session_info = {\n                \"session_id\": session_id,\n                \"fallback_mode\": isinstance(session, dict) and session.get('fallback_mode', False)\n            }\n\n            if hasattr(session, 'history'):\n                session_info[\"message_count\"] = len(session.history)\n            elif isinstance(session, dict) and 'history' in session:\n                session_info[\"message_count\"] = len(session['history'])\n\n            stats[\"active_sessions\"].append(session_info)\n\n        return stats\n\n    async def cleanup_old_sessions(self, max_age_hours: int = 168) -&gt; int:\n        \"\"\"Cleanup alte Sessions (default: 1 Woche)\"\"\"\n        try:\n            cutoff_time = datetime.now() - timedelta(hours=max_age_hours)\n            removed_count = 0\n\n            sessions_to_remove = []\n            for session_id, session in self.session_managers.items():\n                should_remove = False\n\n                # Check last activity\n                if hasattr(session, 'history') and session.history:\n                    last_msg = session.history[-1]\n                    last_timestamp = last_msg.get('timestamp')\n                    if last_timestamp:\n                        try:\n                            last_time = datetime.fromisoformat(last_timestamp.replace('Z', '+00:00'))\n                            if last_time &lt; cutoff_time:\n                                should_remove = True\n                        except:\n                            pass\n                elif isinstance(session, dict) and session.get('history'):\n                    last_msg = session['history'][-1]\n                    last_timestamp = last_msg.get('timestamp')\n                    if last_timestamp:\n                        try:\n                            last_time = datetime.fromisoformat(last_timestamp.replace('Z', '+00:00'))\n                            if last_time &lt; cutoff_time:\n                                should_remove = True\n                        except:\n                            pass\n\n                if should_remove:\n                    sessions_to_remove.append(session_id)\n\n            # Remove old sessions\n            for session_id in sessions_to_remove:\n                session = self.session_managers[session_id]\n                if hasattr(session, 'on_exit'):\n                    session.on_exit()  # Save ChatSession data\n                del self.session_managers[session_id]\n                removed_count += 1\n\n                # Remove from variable manager\n                if self.variable_manager:\n                    scope_name = f'session_{session_id}'\n                    if scope_name in self.variable_manager.scopes:\n                        del self.variable_manager.scopes[scope_name]\n\n            # Clear related cache entries\n            self._invalidate_cache()\n\n            return removed_count\n        except Exception as e:\n            eprint(f\"Error cleaning up old sessions: {e}\")\n            return 0\n</code></pre> <code>add_interaction(session_id, role, content, metadata=None)</code> <code>async</code> \u00b6 <p>Einheitlicher Weg um Interaktionen in ChatSession zu speichern</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def add_interaction(self, session_id: str, role: str, content: str, metadata: dict = None) -&gt; None:\n    \"\"\"Einheitlicher Weg um Interaktionen in ChatSession zu speichern\"\"\"\n    session = await self.initialize_session(session_id)\n\n    message = {\n        'role': role,\n        'content': content,\n        'timestamp': datetime.now().isoformat(),\n        'session_id': session_id,\n        'metadata': metadata or {}\n    }\n\n    # PRIMARY: Store in ChatSession\n    if hasattr(session, 'add_message'):\n        await session.add_message(message, direct=False)\n    elif isinstance(session, dict) and 'history' in session:\n        # Fallback mode\n        session['history'].append(message)\n        # Keep max length\n        max_len = 200\n        if len(session['history']) &gt; max_len:\n            session['history'] = session['history'][-max_len:]\n\n    # SECONDARY: Update VariableManager\n    if self.variable_manager:\n        self.variable_manager.set(f'session_{session_id}.last_interaction', message)\n        if hasattr(session, 'history'):\n            self.variable_manager.set(f'session_{session_id}.history_length', len(session.history))\n        elif isinstance(session, dict):\n            self.variable_manager.set(f'session_{session_id}.history_length', len(session.get('history', [])))\n\n    # Clear context cache for this session\n    self._invalidate_cache(session_id)\n</code></pre> <code>build_unified_context(session_id, query=None, context_type='full')</code> <code>async</code> \u00b6 <p>ZENTRALE Methode f\u00fcr vollst\u00e4ndigen Context-Aufbau aus allen Quellen</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def build_unified_context(self, session_id: str, query: str = None, context_type: str = \"full\") -&gt; dict[\n    str, Any]:\n    \"\"\"ZENTRALE Methode f\u00fcr vollst\u00e4ndigen Context-Aufbau aus allen Quellen\"\"\"\n\n    # Cache check\n    cache_key = f\"{session_id}_{hash(query or '')}_{context_type}\"\n    cached = self._get_cached_context(cache_key)\n    if cached:\n        return cached\n\n    context = {\n        'timestamp': datetime.now().isoformat(),\n        'session_id': session_id,\n        'query': query,\n        'context_type': context_type\n    }\n\n    try:\n        # 1. CHAT HISTORY (Primary - from ChatSession)\n        context['chat_history'] = await self.get_contextual_history(\n            session_id, query or \"\", max_entries=15\n        )\n\n        # 2. VARIABLE SYSTEM STATE\n        if self.variable_manager:\n            context['variables'] = {\n                'available_scopes': list(self.variable_manager.scopes.keys()),\n                'total_variables': len(self.variable_manager.get_available_variables()),\n                'recent_results': self._get_recent_results(5)\n            }\n        else:\n            context['variables'] = {'status': 'variable_manager_not_available'}\n\n        # 3. WORLD MODEL FACTS\n        if self.variable_manager:\n            world_model = self.variable_manager.get('world', {})\n            if world_model and query:\n                context['relevant_facts'] = self._extract_relevant_facts(world_model, query)\n            else:\n                context['relevant_facts'] = list(world_model.items())[:5]  # Top 5 facts\n\n        # 4. EXECUTION STATE\n        context['execution_state'] = {\n            'active_tasks': self._get_active_tasks(),\n            'recent_completions': self._get_recent_completions(3),\n            'system_status': self.agent.shared.get('system_status', 'idle')\n        }\n\n        # 5. SESSION STATISTICS\n        context['session_stats'] = {\n            'total_sessions': len(self.session_managers),\n            'current_session_length': len(context['chat_history']),\n            'cache_enabled': bool(self._context_cache)\n        }\n\n    except Exception as e:\n        eprint(f\"Error building unified context: {e}\")\n        context['error'] = str(e)\n        context['fallback_mode'] = True\n\n    # Cache result\n    self._cache_context(cache_key, context)\n    return context\n</code></pre> <code>cleanup_old_sessions(max_age_hours=168)</code> <code>async</code> \u00b6 <p>Cleanup alte Sessions (default: 1 Woche)</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def cleanup_old_sessions(self, max_age_hours: int = 168) -&gt; int:\n    \"\"\"Cleanup alte Sessions (default: 1 Woche)\"\"\"\n    try:\n        cutoff_time = datetime.now() - timedelta(hours=max_age_hours)\n        removed_count = 0\n\n        sessions_to_remove = []\n        for session_id, session in self.session_managers.items():\n            should_remove = False\n\n            # Check last activity\n            if hasattr(session, 'history') and session.history:\n                last_msg = session.history[-1]\n                last_timestamp = last_msg.get('timestamp')\n                if last_timestamp:\n                    try:\n                        last_time = datetime.fromisoformat(last_timestamp.replace('Z', '+00:00'))\n                        if last_time &lt; cutoff_time:\n                            should_remove = True\n                    except:\n                        pass\n            elif isinstance(session, dict) and session.get('history'):\n                last_msg = session['history'][-1]\n                last_timestamp = last_msg.get('timestamp')\n                if last_timestamp:\n                    try:\n                        last_time = datetime.fromisoformat(last_timestamp.replace('Z', '+00:00'))\n                        if last_time &lt; cutoff_time:\n                            should_remove = True\n                    except:\n                        pass\n\n            if should_remove:\n                sessions_to_remove.append(session_id)\n\n        # Remove old sessions\n        for session_id in sessions_to_remove:\n            session = self.session_managers[session_id]\n            if hasattr(session, 'on_exit'):\n                session.on_exit()  # Save ChatSession data\n            del self.session_managers[session_id]\n            removed_count += 1\n\n            # Remove from variable manager\n            if self.variable_manager:\n                scope_name = f'session_{session_id}'\n                if scope_name in self.variable_manager.scopes:\n                    del self.variable_manager.scopes[scope_name]\n\n        # Clear related cache entries\n        self._invalidate_cache()\n\n        return removed_count\n    except Exception as e:\n        eprint(f\"Error cleaning up old sessions: {e}\")\n        return 0\n</code></pre> <code>get_contextual_history(session_id, query='', max_entries=10)</code> <code>async</code> \u00b6 <p>Intelligente Auswahl relevanter Geschichte aus ChatSession</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def get_contextual_history(self, session_id: str, query: str = \"\", max_entries: int = 10) -&gt; list[dict]:\n    \"\"\"Intelligente Auswahl relevanter Geschichte aus ChatSession\"\"\"\n    session = self.session_managers.get(session_id)\n    if not session:\n        return []\n\n    try:\n        # ChatSession mode\n        if hasattr(session, 'get_past_x'):\n            recent_history = session.get_past_x(max_entries * 2, last_u=False)\n            # await session.get_reference(query, limit=5)\n\n            return recent_history[:max_entries]\n\n        # Fallback mode\n        elif isinstance(session, dict) and 'history' in session:\n            history = session['history']\n            # Return last max_entries, starting with last user message\n            result = []\n            for msg in reversed(history[-max_entries * 2:]):\n                result.append(msg)\n                if msg.get('role') == 'user' and len(result) &gt;= max_entries:\n                    break\n            return list(reversed(result))[:max_entries]\n\n    except Exception as e:\n        eprint(f\"Error getting contextual history: {e}\")\n\n    return []\n</code></pre> <code>get_formatted_context_for_llm(unified_context)</code> \u00b6 <p>Formatiere unified context f\u00fcr LLM consumption</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def get_formatted_context_for_llm(self, unified_context: dict[str, Any]) -&gt; str:\n    \"\"\"Formatiere unified context f\u00fcr LLM consumption\"\"\"\n    try:\n        parts = []\n\n        # Recent Chat History\n        chat_history = unified_context.get('chat_history', [])\n        if chat_history:\n            parts.append(\"## Recent Conversation\")\n            for msg in chat_history[-5:]:  # Last 5 messages\n                timestamp = msg.get('timestamp', '')[:19]  # Remove microseconds\n                role = msg.get('role', 'unknown')\n                content = msg.get('content', '')[:500] + (\"...\" if len(msg.get('content', '')) &gt; 500 else \"\")\n                parts.append(f\"[{timestamp}] {role}: {content}\")\n\n        # System Status\n        execution_state = unified_context.get('execution_state', {})\n        if execution_state:\n            parts.append(\"\\n## Current System State\")\n            parts.append(f\"Status: {execution_state.get('system_status', 'unknown')}\")\n\n            active_tasks = execution_state.get('active_tasks', [])\n            if active_tasks:\n                parts.append(f\"Active Tasks: {len(active_tasks)}\")\n\n            recent_completions = execution_state.get('recent_completions', [])\n            if recent_completions:\n                parts.append(f\"Recent Completions: {len(recent_completions)}\")\n\n        # Available Data\n        variables = unified_context.get('variables', {})\n        if variables and variables.get('recent_results'):\n            parts.append(\"\\n## Available Results\")\n            recent_results = variables['recent_results']\n            for result in recent_results[:3]:  # Top 3 results\n                parts.append(f\"- {result.get('task_id', 'unknown')}: {str(result.get('preview', ''))[:100]}...\")\n\n        # World Model Facts\n        relevant_facts = unified_context.get('relevant_facts', [])\n        if relevant_facts:\n            parts.append(\"\\n## Known Facts\")\n            for key, value in relevant_facts[:5]:  # Top 5 facts\n                fact_preview = str(value)[:100] + (\"...\" if len(str(value)) &gt; 100 else \"\")\n                parts.append(f\"- {key}: {fact_preview}\")\n\n        parts.append(f\"\\n---\\nContext generated at: {unified_context.get('timestamp', 'unknown')}\")\n\n        return \"\\n\".join(parts)\n\n    except Exception as e:\n        eprint(f\"Error formatting context for LLM: {e}\")\n        return f\"Context formatting error: {str(e)}\"\n</code></pre> <code>get_session_statistics()</code> \u00b6 <p>Hole Statistiken \u00fcber alle Sessions</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def get_session_statistics(self) -&gt; dict[str, Any]:\n    \"\"\"Hole Statistiken \u00fcber alle Sessions\"\"\"\n    stats = {\n        \"total_sessions\": len(self.session_managers),\n        \"active_sessions\": [],\n        \"cache_entries\": len(self._context_cache),\n        \"cache_hit_rate\": 0.0  # Could be tracked if needed\n    }\n\n    for session_id, session in self.session_managers.items():\n        session_info = {\n            \"session_id\": session_id,\n            \"fallback_mode\": isinstance(session, dict) and session.get('fallback_mode', False)\n        }\n\n        if hasattr(session, 'history'):\n            session_info[\"message_count\"] = len(session.history)\n        elif isinstance(session, dict) and 'history' in session:\n            session_info[\"message_count\"] = len(session['history'])\n\n        stats[\"active_sessions\"].append(session_info)\n\n    return stats\n</code></pre> <code>initialize_session(session_id, max_history=200)</code> <code>async</code> \u00b6 <p>Initialisiere oder lade existierende ChatSession als prim\u00e4re Context-Quelle</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>async def initialize_session(self, session_id: str, max_history: int = 200):\n    \"\"\"Initialisiere oder lade existierende ChatSession als prim\u00e4re Context-Quelle\"\"\"\n    if session_id not in self.session_managers:\n        try:\n            # Get memory instance\n            if not self._memory_instance:\n                from toolboxv2 import get_app\n                self._memory_instance = get_app().get_mod(\"isaa\").get_memory()\n\n            # Create ChatSession as PRIMARY memory source\n            session = ChatSession(\n                self._memory_instance,\n                max_length=max_history,\n                space_name=f\"ChatSession/{self.agent.amd.name}.{session_id}.unified\"\n            )\n            self.session_managers[session_id] = session\n\n            # Integration mit VariableManager wenn verf\u00fcgbar\n            if self.variable_manager:\n                self.variable_manager.register_scope(f'session_{session_id}', {\n                    'chat_session_active': True,\n                    'history_length': len(session.history),\n                    'last_interaction': None,\n                    'session_id': session_id\n                })\n\n            rprint(f\"Unified session context initialized for {session_id}\")\n            return session\n\n        except Exception as e:\n            eprint(f\"Failed to create ChatSession for {session_id}: {e}\")\n            # Fallback: Create minimal session manager\n            self.session_managers[session_id] = {\n                'history': [],\n                'session_id': session_id,\n                'fallback_mode': True\n            }\n            return self.session_managers[session_id]\n\n    return self.session_managers[session_id]\n</code></pre> <code>VariableManager</code> \u00b6 <p>Unified variable management system with advanced features</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>class VariableManager:\n    \"\"\"Unified variable management system with advanced features\"\"\"\n\n    def __init__(self, world_model: dict, shared_state: dict = None):\n        self.world_model = world_model\n        self.shared_state = shared_state or {}\n        self.scopes = {\n            'world': world_model,\n            'shared': self.shared_state,\n            'results': {},\n            'tasks': {},\n            'user': {},\n            'system': {}\n        }\n        self._cache = {}\n\n    def register_scope(self, name: str, data: dict):\n        \"\"\"Register a new variable scope\"\"\"\n        self.scopes[name] = data\n        self._cache.clear()\n\n    def set_results_store(self, results_store: dict):\n        \"\"\"Set the results store for task result references\"\"\"\n        self.scopes['results'] = results_store\n        self._cache.clear()\n\n    def set_tasks_store(self, tasks_store: dict):\n        \"\"\"Set tasks store for task metadata access\"\"\"\n        self.scopes['tasks'] = tasks_store\n        self._cache.clear()\n\n    def _resolve_path(self, path: str):\n        \"\"\"\n        Internal helper to navigate a path that can contain both\n        dictionary keys and list indices.\n        \"\"\"\n        parts = path.split('.')\n\n        # Determine the starting point\n        if len(parts) == 1:\n            # Simple key in the top-level world_model\n            current = self.world_model\n        else:\n            scope_name = parts[0]\n            if scope_name not in self.scopes:\n                raise KeyError(f\"Scope '{scope_name}' not found\")\n            current = self.scopes[scope_name]\n            parts = parts[1:]  # Continue with the rest of the path\n\n        # Navigate through the parts\n        for part in parts:\n            if isinstance(current, list):\n                try:\n                    # It's a list, so the part must be an integer index\n                    index = int(part)\n                    current = current[index]\n                except (ValueError, IndexError):\n                    raise KeyError(f\"Invalid list index '{part}' in path '{path}'\")\n            elif isinstance(current, dict):\n                try:\n                    # It's a dictionary, so the part is a key\n                    current = current[part]\n                except KeyError:\n                    raise KeyError(f\"Key '{part}' not found in path '{path}'\")\n            else:\n                # We've hit a non-collection type (int, str, etc.) but the path continues\n                raise KeyError(f\"Path cannot descend into non-collection type at '{part}' in path '{path}'\")\n\n        return current\n\n    def get(self, path: str, default=None, use_cache: bool = True):\n        \"\"\"Get variable with dot notation path support for dicts and lists.\"\"\"\n        if use_cache and path in self._cache:\n            return self._cache[path]\n\n        try:\n            value = self._resolve_path(path)\n            if use_cache:\n                self._cache[path] = value\n            return value\n        except (KeyError, IndexError):\n            # A KeyError or IndexError during resolution means the path is invalid\n            return default\n\n    def set(self, path: str, value, create_scope: bool = True):\n        \"\"\"Set variable with dot notation path support for dicts and lists.\"\"\"\n        # Invalidate cache for this path\n        if path in self._cache:\n            del self._cache[path]\n\n        parts = path.split('.')\n\n        if len(parts) == 1:\n            # Simple key in world_model\n            self.world_model[path] = value\n            return\n\n        scope_name = parts[0]\n        if scope_name not in self.scopes:\n            if create_scope:\n                self.scopes[scope_name] = {}\n            else:\n                raise KeyError(f\"Scope '{scope_name}' not found\")\n\n        current = self.scopes[scope_name]\n\n        # Iterate to the second-to-last part to get the container\n        for i, part in enumerate(parts[1:-1]):\n            next_part = parts[i + 2]  # Look ahead to the next part in the path\n\n            # Determine if the current part is a dictionary key or a list index\n            try:\n                # Try to treat it as a list index\n                key = int(part)\n                if not isinstance(current, list):\n                    # If current is not a list, we can't use an integer index\n                    raise TypeError(f\"Attempted to use integer index '{key}' on non-list for path '{path}'\")\n\n                # Ensure list is long enough\n                while len(current) &lt;= key:\n                    current.append(None)  # Pad with None\n\n                # If the next level doesn't exist, create it based on the next part\n                if current[key] is None:\n                    current[key] = [] if next_part.isdigit() else {}\n\n                current = current[key]\n\n            except ValueError:\n                # It's a dictionary key\n                key = part\n                if not isinstance(current, dict):\n                    raise TypeError(f\"Attempted to use string key '{key}' on non-dict for path '{path}'\")\n\n                if key not in current:\n                    # Create the next level: a list if the next part is a number, else a dict\n                    current[key] = [] if next_part.isdigit() else {}\n\n                current = current[key]\n\n        # Handle the final part (the actual assignment)\n        last_part = parts[-1]\n\n        if isinstance(current, list):\n            try:\n                key = int(last_part)\n                while len(current) &lt;= key:\n                    current.append(None)\n                current[key] = value\n            except ValueError:\n                current.append(value)\n        elif isinstance(current, dict):\n            current[last_part] = value\n        elif scope_name == 'tasks' and hasattr(current, 'task_identification_attr'):# from tasks like Tooltask ... model dump and acces\n            dict_data = asdict(current)\n            dict_data[last_part] = value\n            current = dict_data\n            # update self.scopes['tasks'] with the updated task\n            self.scopes['tasks'][parts[1]][last_part] = current\n        else:\n            raise TypeError(f\"Final container is not a list or dictionary for path '{path}' its a {type(current)}\")\n\n        self._cache.clear()\n\n    def format_text(self, text: str, context: dict = None) -&gt; str:\n        \"\"\"Enhanced text formatting with multiple syntaxes\"\"\"\n        if not text or not isinstance(text, str):\n            return str(text) if text is not None else \"\"\n\n        # Temporary context overlay\n        if context:\n            original_scopes = self.scopes.copy()\n            self.scopes['context'] = context\n\n        try:\n            # Handle {{ variable }} syntax\n            formatted = self._format_double_braces(text)\n\n            # Handle {variable} syntax\n            formatted = self._format_single_braces(formatted)\n\n            # Handle $variable syntax\n            formatted = self._format_dollar_syntax(formatted)\n\n            return formatted\n\n        finally:\n            if context:\n                self.scopes = original_scopes\n\n    def _format_double_braces(self, text: str) -&gt; str:\n        \"\"\"Handle {{ variable.path }} syntax with improved debugging\"\"\"\n        import re\n\n        def replace_var(match):\n            var_path = match.group(1).strip()\n            value = self.get(var_path)\n\n            if value is None:\n                # IMPROVED: Log missing variables for debugging\n                available_vars = list(self.get_available_variables().keys())\n                wprint(f\"Variable '{var_path}' not found. Available: {available_vars[:10]}\")\n                return match.group(0)  # Keep original if not found\n\n            return self._value_to_string(value)\n\n        return re.sub(r'\\{\\{\\s*([^}]+)\\s*\\}\\}', replace_var, text)\n\n    def _format_single_braces(self, text: str) -&gt; str:\n        \"\"\"Handle {variable.path} syntax, including with spaces like { variable.path }.\"\"\"\n        import re\n\n        def replace_var(match):\n            # Extrahiert den Variablennamen und entfernt f\u00fchrende/nachfolgende Leerzeichen\n            var_path = match.group(1).strip()\n\n            # Ruft den Wert \u00fcber die get-Methode ab, die die Punktnotation bereits verarbeitet\n            value = self.get(var_path)\n\n            # Gibt den konvertierten Wert oder das Original-Tag zur\u00fcck, wenn der Wert nicht gefunden wurde\n            return self._value_to_string(value) if value is not None else match.group(0)\n\n        # Dieser Regex findet {beliebiger.inhalt} und erlaubt Leerzeichen um den Inhalt\n        # Er schlie\u00dft verschachtelte oder leere Klammern wie {} oder { {var} } aus.\n        return re.sub(r'\\{([^{}]+)\\}', replace_var, text)\n\n    def _format_dollar_syntax(self, text: str) -&gt; str:\n        \"\"\"Handle $variable syntax\"\"\"\n        import re\n\n        def replace_var(match):\n            var_name = match.group(1)\n            value = self.get(var_name)\n            return self._value_to_string(value) if value is not None else match.group(0)\n\n        return re.sub(r'\\$([a-zA-Z_][a-zA-Z0-9_]*)', replace_var, text)\n\n    def _value_to_string(self, value) -&gt; str:\n        \"\"\"Convert value to string representation\"\"\"\n        if isinstance(value, str):\n            return value\n        elif isinstance(value, dict | list):\n            return json.dumps(value, default=str)\n        else:\n            return str(value)\n\n    def validate_references(self, text: str) -&gt; dict[str, bool]:\n        \"\"\"Validate all variable references in text\"\"\"\n        import re\n\n        references = {}\n\n        # Find all {{ }} references\n        double_brace_refs = re.findall(r'\\{\\{\\s*([^}]+)\\s*\\}\\}', text)\n        for ref in double_brace_refs:\n            references[\"{{\"+ref+\"}}\"] = self.get(ref.strip()) is not None\n\n        # Find all {} references\n        single_brace_refs = re.findall(r'\\{([^{}\\s]+)\\}', text)\n        for ref in single_brace_refs:\n            if '.' not in ref:  # Only simple vars\n                references[\"{\"+ref+\"}\"] = self.get(ref.strip()) is not None\n\n        # Find all $ references\n        dollar_refs = re.findall(r'\\$([a-zA-Z_][a-zA-Z0-9_]*)', text)\n        for ref in dollar_refs:\n            references[f\"${ref}\"] = self.get(ref) is not None\n\n        return references\n\n    def get_scope_info(self) -&gt; dict[str, Any]:\n        \"\"\"Get information about all available scopes\"\"\"\n        info = {}\n        for scope_name, scope_data in self.scopes.items():\n            if isinstance(scope_data, dict):\n                info[scope_name] = {\n                    'type': 'dict',\n                    'keys': len(scope_data),\n                    'sample_keys': list(scope_data.keys())[:5]\n                }\n            else:\n                info[scope_name] = {\n                    'type': type(scope_data).__name__,\n                    'value': str(scope_data)[:100]\n                }\n        return info\n\n    def _validate_task_references(self, task: Task) -&gt; dict[str, Any]:\n        \"\"\"Validate all variable references in a task\"\"\"\n        validation_results = {\n            'valid': True,\n            'errors': [],\n            'warnings': []\n        }\n\n        # Check different task types\n        if isinstance(task, LLMTask):\n            if task.prompt_template:\n                refs = self.validate_references(task.prompt_template)\n                for ref, is_valid in refs.items():\n                    if not is_valid:\n                        validation_results['errors'].append(f\"Invalid reference in prompt: {ref}\")\n                        validation_results['valid'] = False\n\n        elif isinstance(task, ToolTask):\n            for key, value in task.arguments.items():\n                if isinstance(value, str):\n                    refs = self.validate_references(value)\n                    for ref, is_valid in refs.items():\n                        if not is_valid:\n                            validation_results['warnings'].append(f\"Invalid reference in {key}: {ref}\")\n\n        return validation_results\n\n    def get_variable_suggestions(self, query: str) -&gt; list[str]:\n        \"\"\"Get variable suggestions based on query content\"\"\"\n\n        query_lower = query.lower()\n        suggestions = []\n\n        # Check all variables for relevance\n        for scope in self.scopes.values():\n            for name, var_def in scope.items():\n                if name in [\"system_context\", \"task_executor_instance\",\n                            \"index\", \"tool_capabilities\", \"use_fast_response\", \"task_planner_instance\"]:\n                    continue\n                # Name similarity\n                if any(word in name.lower() for word in query_lower.split()):\n                    suggestions.append(name)\n                    continue\n\n                # Description similarity\n                if var_def and any(word in str(var_def).lower() for word in query_lower.split()):\n                    suggestions.append(name)\n                    continue\n\n\n        return list(set(suggestions))[:10]\n\n    def _document_structure(self, data: Any, path_prefix: str, docs: dict[str, dict]):\n        \"\"\"A recursive helper to document nested dictionaries and lists.\"\"\"\n        if isinstance(data, dict):\n            for key, value in data.items():\n                # Construct the full path for the current item\n                current_path = f\"{path_prefix}.{key}\" if path_prefix else key\n\n                # Generate a preview for the value\n                if isinstance(value, str):\n                    preview = value[:70] + \"...\" if len(value) &gt; 70 else value\n                elif isinstance(value, dict):\n                    preview = f\"Object with keys: {list(value.keys())[:3]}\" + (\"...\" if len(value.keys()) &gt; 3 else \"\")\n                elif isinstance(value, list):\n                    preview = f\"List with {len(value)} items\"\n                else:\n                    preview = str(value)\n\n                # Store the documentation for the current path\n                docs[current_path] = {\n                    'preview': preview,\n                    'type': type(value).__name__\n                }\n\n                # Recurse into nested structures\n                if isinstance(value, dict | list):\n                    self._document_structure(value, current_path, docs)\n\n        elif isinstance(data, list):\n            for i, item in enumerate(data):\n                # Construct the full path for the list item\n                current_path = f\"{path_prefix}.{i}\"\n\n                # Generate a preview for the item\n                if isinstance(item, str):\n                    preview = item[:70] + \"...\" if len(item) &gt; 70 else item\n                elif isinstance(item, dict):\n                    preview = f\"Object with keys: {list(item.keys())[:3]}\" + (\"...\" if len(item.keys()) &gt; 3 else \"\")\n                elif isinstance(item, list):\n                    preview = f\"List with {len(item)} items\"\n                else:\n                    preview = str(item)\n\n                docs[current_path] = {\n                    'preview': preview,\n                    'type': type(item).__name__\n                }\n\n                # Recurse into nested structures\n                if isinstance(item, dict | list):\n                    self._document_structure(item, current_path, docs)\n\n    def get_available_variables(self) -&gt; dict[str, dict]:\n        \"\"\"\n        Recursively documents all available variables from world_model and scopes\n        to provide a comprehensive overview for an LLM.\n        \"\"\"\n        all_vars_docs = {}\n\n        # 1. Document the world_model (top-level variables)\n        self._document_structure(self.world_model, \"\", all_vars_docs)\n\n        # 2. Document each scope\n        for scope_name, scope_data in self.scopes.items():\n            # Add documentation for the scope root itself\n            if scope_name == \"shared\":\n                continue\n            if isinstance(scope_data, dict):\n                preview = f\"Object with keys: {list(scope_data.keys())[:3]}\" + (\n                    \"...\" if len(scope_data.keys()) &gt; 3 else \"\")\n            elif isinstance(scope_data, list):\n                preview = f\"List with {len(scope_data)} items\"\n            elif isinstance(scope_data, str | int):\n                preview = str(scope_data)\n            else:\n                continue\n\n            all_vars_docs[scope_name] = {'preview': preview, 'type': type(scope_data).__name__}\n\n            # Recurse into the scope's data\n            self._document_structure(scope_data, scope_name, all_vars_docs)\n\n        return all_vars_docs\n\n    def get_llm_variable_context(self) -&gt; str:\n        \"\"\"\n        Generates a detailed variable context formatted for LLM consumption,\n        explaining structure, access patterns, and listing all available variables.\n        \"\"\"\n        context_parts = [\n            \"## Variable System Reference\",\n            \"You can access a state management system to retrieve data using dot notation.\",\n            \"Syntax: `{{ path.to.variable }}` or `$path.to.variable`.\",\n            \"\",\n            \"### How to Access Data\",\n            \"The system contains nested objects (dictionaries) and lists (arrays).\",\n            \"\",\n            \"**1. Object (Dictionary) Access (Primary Usage):**\",\n            \"Use a dot (`.`) to access values inside an object. This is the most common way to get data.\",\n            \"Example: If a `user` object exists with a `profile`, you can get the name with `{{ user.profile.name }}`.\",\n            \"\",\n            \"**2. List (Array) Access:**\",\n            \"If a variable is a list, use a dot (`.`) followed by a zero-based number (index) to access a specific item.\",\n            \"Example: To get the first email from a user's email list, use `{{ user.emails.0 }}`.\",\n            \"You can chain these access methods: `{{ user.emails.0.address }}`.\",\n            \"\",\n            \"### Available Variables\",\n            \"Below is a list of all currently available variable paths, their type, and a preview of their content. (Note: Previews may be truncated).\",\n        ]\n\n        variables = self.get_available_variables()\n        if not variables:\n            context_parts.append(\"- No variables are currently set.\")\n            return \"\\n\".join(context_parts)\n\n        if \"shared\" in variables:\n            variables[\"shared\"] = {'preview': \"Shared state variables\", 'type': \"dict\"}\n\n        # yaml dump preview\n        context_parts.append(\"```yaml\")\n        context_parts.append(yaml.dump(variables, default_flow_style=False, sort_keys=False))\n        context_parts.append(\"```\")\n\n        # Add any final complex examples or notes\n        context_parts.extend([\n            \"\",\n            \"**Note on Task Results:**\",\n            \"All task results are stored in the `results` scope. To access the data from a task, append `.data`.\",\n            \"Example: `{{ results.'task-id-123'.data }}`\"\n        ])\n\n        return \"\\n\".join(context_parts)\n</code></pre> <code>format_text(text, context=None)</code> \u00b6 <p>Enhanced text formatting with multiple syntaxes</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def format_text(self, text: str, context: dict = None) -&gt; str:\n    \"\"\"Enhanced text formatting with multiple syntaxes\"\"\"\n    if not text or not isinstance(text, str):\n        return str(text) if text is not None else \"\"\n\n    # Temporary context overlay\n    if context:\n        original_scopes = self.scopes.copy()\n        self.scopes['context'] = context\n\n    try:\n        # Handle {{ variable }} syntax\n        formatted = self._format_double_braces(text)\n\n        # Handle {variable} syntax\n        formatted = self._format_single_braces(formatted)\n\n        # Handle $variable syntax\n        formatted = self._format_dollar_syntax(formatted)\n\n        return formatted\n\n    finally:\n        if context:\n            self.scopes = original_scopes\n</code></pre> <code>get(path, default=None, use_cache=True)</code> \u00b6 <p>Get variable with dot notation path support for dicts and lists.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def get(self, path: str, default=None, use_cache: bool = True):\n    \"\"\"Get variable with dot notation path support for dicts and lists.\"\"\"\n    if use_cache and path in self._cache:\n        return self._cache[path]\n\n    try:\n        value = self._resolve_path(path)\n        if use_cache:\n            self._cache[path] = value\n        return value\n    except (KeyError, IndexError):\n        # A KeyError or IndexError during resolution means the path is invalid\n        return default\n</code></pre> <code>get_available_variables()</code> \u00b6 <p>Recursively documents all available variables from world_model and scopes to provide a comprehensive overview for an LLM.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def get_available_variables(self) -&gt; dict[str, dict]:\n    \"\"\"\n    Recursively documents all available variables from world_model and scopes\n    to provide a comprehensive overview for an LLM.\n    \"\"\"\n    all_vars_docs = {}\n\n    # 1. Document the world_model (top-level variables)\n    self._document_structure(self.world_model, \"\", all_vars_docs)\n\n    # 2. Document each scope\n    for scope_name, scope_data in self.scopes.items():\n        # Add documentation for the scope root itself\n        if scope_name == \"shared\":\n            continue\n        if isinstance(scope_data, dict):\n            preview = f\"Object with keys: {list(scope_data.keys())[:3]}\" + (\n                \"...\" if len(scope_data.keys()) &gt; 3 else \"\")\n        elif isinstance(scope_data, list):\n            preview = f\"List with {len(scope_data)} items\"\n        elif isinstance(scope_data, str | int):\n            preview = str(scope_data)\n        else:\n            continue\n\n        all_vars_docs[scope_name] = {'preview': preview, 'type': type(scope_data).__name__}\n\n        # Recurse into the scope's data\n        self._document_structure(scope_data, scope_name, all_vars_docs)\n\n    return all_vars_docs\n</code></pre> <code>get_llm_variable_context()</code> \u00b6 <p>Generates a detailed variable context formatted for LLM consumption, explaining structure, access patterns, and listing all available variables.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def get_llm_variable_context(self) -&gt; str:\n    \"\"\"\n    Generates a detailed variable context formatted for LLM consumption,\n    explaining structure, access patterns, and listing all available variables.\n    \"\"\"\n    context_parts = [\n        \"## Variable System Reference\",\n        \"You can access a state management system to retrieve data using dot notation.\",\n        \"Syntax: `{{ path.to.variable }}` or `$path.to.variable`.\",\n        \"\",\n        \"### How to Access Data\",\n        \"The system contains nested objects (dictionaries) and lists (arrays).\",\n        \"\",\n        \"**1. Object (Dictionary) Access (Primary Usage):**\",\n        \"Use a dot (`.`) to access values inside an object. This is the most common way to get data.\",\n        \"Example: If a `user` object exists with a `profile`, you can get the name with `{{ user.profile.name }}`.\",\n        \"\",\n        \"**2. List (Array) Access:**\",\n        \"If a variable is a list, use a dot (`.`) followed by a zero-based number (index) to access a specific item.\",\n        \"Example: To get the first email from a user's email list, use `{{ user.emails.0 }}`.\",\n        \"You can chain these access methods: `{{ user.emails.0.address }}`.\",\n        \"\",\n        \"### Available Variables\",\n        \"Below is a list of all currently available variable paths, their type, and a preview of their content. (Note: Previews may be truncated).\",\n    ]\n\n    variables = self.get_available_variables()\n    if not variables:\n        context_parts.append(\"- No variables are currently set.\")\n        return \"\\n\".join(context_parts)\n\n    if \"shared\" in variables:\n        variables[\"shared\"] = {'preview': \"Shared state variables\", 'type': \"dict\"}\n\n    # yaml dump preview\n    context_parts.append(\"```yaml\")\n    context_parts.append(yaml.dump(variables, default_flow_style=False, sort_keys=False))\n    context_parts.append(\"```\")\n\n    # Add any final complex examples or notes\n    context_parts.extend([\n        \"\",\n        \"**Note on Task Results:**\",\n        \"All task results are stored in the `results` scope. To access the data from a task, append `.data`.\",\n        \"Example: `{{ results.'task-id-123'.data }}`\"\n    ])\n\n    return \"\\n\".join(context_parts)\n</code></pre> <code>get_scope_info()</code> \u00b6 <p>Get information about all available scopes</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def get_scope_info(self) -&gt; dict[str, Any]:\n    \"\"\"Get information about all available scopes\"\"\"\n    info = {}\n    for scope_name, scope_data in self.scopes.items():\n        if isinstance(scope_data, dict):\n            info[scope_name] = {\n                'type': 'dict',\n                'keys': len(scope_data),\n                'sample_keys': list(scope_data.keys())[:5]\n            }\n        else:\n            info[scope_name] = {\n                'type': type(scope_data).__name__,\n                'value': str(scope_data)[:100]\n            }\n    return info\n</code></pre> <code>get_variable_suggestions(query)</code> \u00b6 <p>Get variable suggestions based on query content</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def get_variable_suggestions(self, query: str) -&gt; list[str]:\n    \"\"\"Get variable suggestions based on query content\"\"\"\n\n    query_lower = query.lower()\n    suggestions = []\n\n    # Check all variables for relevance\n    for scope in self.scopes.values():\n        for name, var_def in scope.items():\n            if name in [\"system_context\", \"task_executor_instance\",\n                        \"index\", \"tool_capabilities\", \"use_fast_response\", \"task_planner_instance\"]:\n                continue\n            # Name similarity\n            if any(word in name.lower() for word in query_lower.split()):\n                suggestions.append(name)\n                continue\n\n            # Description similarity\n            if var_def and any(word in str(var_def).lower() for word in query_lower.split()):\n                suggestions.append(name)\n                continue\n\n\n    return list(set(suggestions))[:10]\n</code></pre> <code>register_scope(name, data)</code> \u00b6 <p>Register a new variable scope</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def register_scope(self, name: str, data: dict):\n    \"\"\"Register a new variable scope\"\"\"\n    self.scopes[name] = data\n    self._cache.clear()\n</code></pre> <code>set(path, value, create_scope=True)</code> \u00b6 <p>Set variable with dot notation path support for dicts and lists.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def set(self, path: str, value, create_scope: bool = True):\n    \"\"\"Set variable with dot notation path support for dicts and lists.\"\"\"\n    # Invalidate cache for this path\n    if path in self._cache:\n        del self._cache[path]\n\n    parts = path.split('.')\n\n    if len(parts) == 1:\n        # Simple key in world_model\n        self.world_model[path] = value\n        return\n\n    scope_name = parts[0]\n    if scope_name not in self.scopes:\n        if create_scope:\n            self.scopes[scope_name] = {}\n        else:\n            raise KeyError(f\"Scope '{scope_name}' not found\")\n\n    current = self.scopes[scope_name]\n\n    # Iterate to the second-to-last part to get the container\n    for i, part in enumerate(parts[1:-1]):\n        next_part = parts[i + 2]  # Look ahead to the next part in the path\n\n        # Determine if the current part is a dictionary key or a list index\n        try:\n            # Try to treat it as a list index\n            key = int(part)\n            if not isinstance(current, list):\n                # If current is not a list, we can't use an integer index\n                raise TypeError(f\"Attempted to use integer index '{key}' on non-list for path '{path}'\")\n\n            # Ensure list is long enough\n            while len(current) &lt;= key:\n                current.append(None)  # Pad with None\n\n            # If the next level doesn't exist, create it based on the next part\n            if current[key] is None:\n                current[key] = [] if next_part.isdigit() else {}\n\n            current = current[key]\n\n        except ValueError:\n            # It's a dictionary key\n            key = part\n            if not isinstance(current, dict):\n                raise TypeError(f\"Attempted to use string key '{key}' on non-dict for path '{path}'\")\n\n            if key not in current:\n                # Create the next level: a list if the next part is a number, else a dict\n                current[key] = [] if next_part.isdigit() else {}\n\n            current = current[key]\n\n    # Handle the final part (the actual assignment)\n    last_part = parts[-1]\n\n    if isinstance(current, list):\n        try:\n            key = int(last_part)\n            while len(current) &lt;= key:\n                current.append(None)\n            current[key] = value\n        except ValueError:\n            current.append(value)\n    elif isinstance(current, dict):\n        current[last_part] = value\n    elif scope_name == 'tasks' and hasattr(current, 'task_identification_attr'):# from tasks like Tooltask ... model dump and acces\n        dict_data = asdict(current)\n        dict_data[last_part] = value\n        current = dict_data\n        # update self.scopes['tasks'] with the updated task\n        self.scopes['tasks'][parts[1]][last_part] = current\n    else:\n        raise TypeError(f\"Final container is not a list or dictionary for path '{path}' its a {type(current)}\")\n\n    self._cache.clear()\n</code></pre> <code>set_results_store(results_store)</code> \u00b6 <p>Set the results store for task result references</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def set_results_store(self, results_store: dict):\n    \"\"\"Set the results store for task result references\"\"\"\n    self.scopes['results'] = results_store\n    self._cache.clear()\n</code></pre> <code>set_tasks_store(tasks_store)</code> \u00b6 <p>Set tasks store for task metadata access</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def set_tasks_store(self, tasks_store: dict):\n    \"\"\"Set tasks store for task metadata access\"\"\"\n    self.scopes['tasks'] = tasks_store\n    self._cache.clear()\n</code></pre> <code>validate_references(text)</code> \u00b6 <p>Validate all variable references in text</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def validate_references(self, text: str) -&gt; dict[str, bool]:\n    \"\"\"Validate all variable references in text\"\"\"\n    import re\n\n    references = {}\n\n    # Find all {{ }} references\n    double_brace_refs = re.findall(r'\\{\\{\\s*([^}]+)\\s*\\}\\}', text)\n    for ref in double_brace_refs:\n        references[\"{{\"+ref+\"}}\"] = self.get(ref.strip()) is not None\n\n    # Find all {} references\n    single_brace_refs = re.findall(r'\\{([^{}\\s]+)\\}', text)\n    for ref in single_brace_refs:\n        if '.' not in ref:  # Only simple vars\n            references[\"{\"+ref+\"}\"] = self.get(ref.strip()) is not None\n\n    # Find all $ references\n    dollar_refs = re.findall(r'\\$([a-zA-Z_][a-zA-Z0-9_]*)', text)\n    for ref in dollar_refs:\n        references[f\"${ref}\"] = self.get(ref) is not None\n\n    return references\n</code></pre> <code>auto_unescape(args)</code> \u00b6 <p>Automatically unescape all strings in nested data structure.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def auto_unescape(args: Any) -&gt; Any:\n    \"\"\"Automatically unescape all strings in nested data structure.\"\"\"\n    return process_nested(args)\n</code></pre> <code>create_task(task_type, **kwargs)</code> \u00b6 <p>Factory f\u00fcr Task-Erstellung mit korrektem Typ</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def create_task(task_type: str, **kwargs) -&gt; Task:\n    \"\"\"Factory f\u00fcr Task-Erstellung mit korrektem Typ\"\"\"\n    task_classes = {\n        \"llm_call\": LLMTask,\n        \"tool_call\": ToolTask,\n        \"decision\": DecisionTask,\n        \"generic\": Task,\n        \"LLMTask\": LLMTask,\n        \"ToolTask\": ToolTask,\n        \"DecisionTask\": DecisionTask,\n        \"Task\": Task,\n    }\n\n    task_class = task_classes.get(task_type, Task)\n\n    # Standard-Felder setzen\n    if \"id\" not in kwargs:\n        kwargs[\"id\"] = str(uuid.uuid4())\n    if \"type\" not in kwargs:\n        kwargs[\"type\"] = task_type\n    if \"critical\" not in kwargs:\n        kwargs[\"critical\"] = task_type in [\"llm_call\", \"decision\"]\n\n    # Ensure metadata is initialized\n    if \"metadata\" not in kwargs:\n        kwargs[\"metadata\"] = {}\n\n    # Create task and ensure post_init is called\n    task = task_class(**kwargs)\n\n    # Double-check metadata initialization\n    if not hasattr(task, 'metadata') or task.metadata is None:\n        task.metadata = {}\n\n    return task\n</code></pre> <code>get_args_schema(func)</code> \u00b6 <p>Generate a string representation of a function's arguments and annotations. Keeps args and *kwargs indicators and handles modern Python type hints.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def get_args_schema(func: Callable) -&gt; str:\n    \"\"\"\n    Generate a string representation of a function's arguments and annotations.\n    Keeps *args and **kwargs indicators and handles modern Python type hints.\n    \"\"\"\n    sig = inspect.signature(func)\n    parts = []\n\n    for name, param in sig.parameters.items():\n        ann = \"\"\n        if param.annotation is not inspect._empty:\n            ann = f\": {_annotation_to_str(param.annotation)}\"\n\n        default = \"\"\n        if param.default is not inspect._empty:\n            default = f\" = {repr(param.default)}\"\n\n        prefix = \"\"\n        if param.kind == inspect.Parameter.VAR_POSITIONAL:\n            prefix = \"*\"\n        elif param.kind == inspect.Parameter.VAR_KEYWORD:\n            prefix = \"**\"\n\n        parts.append(f\"{prefix}{name}{ann}{default}\")\n\n    return f\"({', '.join(parts)})\"\n</code></pre> <code>get_progress_summary(self)</code> \u00b6 <p>Get comprehensive progress summary from the agent</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def get_progress_summary(self) -&gt; dict[str, Any]:\n    \"\"\"Get comprehensive progress summary from the agent\"\"\"\n    if hasattr(self, 'progress_tracker'):\n        return self.progress_tracker.get_summary()\n    return {\"error\": \"No progress tracker available\"}\n</code></pre> <code>needs_unescaping(text)</code> \u00b6 <p>Detect if string likely needs unescaping.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def needs_unescaping(text: str) -&gt; bool:\n    \"\"\"Detect if string likely needs unescaping.\"\"\"\n    return bool(re.search(r'\\\\[ntr\"\\'\\\\]', text)) or len(text) &gt; 50\n</code></pre> <code>process_nested(data, max_depth=20)</code> \u00b6 <p>Recursively process nested structures, unescaping strings that need it.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def process_nested(data: Any, max_depth: int = 20) -&gt; Any:\n    \"\"\"Recursively process nested structures, unescaping strings that need it.\"\"\"\n    if max_depth &lt;= 0:\n        return data\n\n    if isinstance(data, dict):\n        return {k: process_nested(v, max_depth - 1) for k, v in data.items()}\n\n    elif isinstance(data, list | tuple):\n        processed = [process_nested(item, max_depth - 1) for item in data]\n        return type(data)(processed)\n\n    elif isinstance(data, str) and needs_unescaping(data):\n        return unescape_string(data)\n\n    return data\n</code></pre> <code>unescape_string(text)</code> \u00b6 <p>Universal string unescaping for any programming language.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def unescape_string(text: str) -&gt; str:\n    \"\"\"Universal string unescaping for any programming language.\"\"\"\n    if not isinstance(text, str) or len(text) &lt; 2:\n        return text\n\n    # Remove outer quotes if wrapped\n    if (text.startswith('\"') and text.endswith('\"')) or (text.startswith(\"'\") and text.endswith(\"'\")):\n        text = text[1:-1]\n\n    # Universal escape sequences\n    escapes = {\n        '\\\\n': '\\n', '\\\\t': '\\t', '\\\\r': '\\r',\n        '\\\\\"': '\"', \"\\\\'\": \"'\", '\\\\\\\\': '\\\\'\n    }\n\n    for escaped, unescaped in escapes.items():\n        text = text.replace(escaped, unescaped)\n\n    return text\n</code></pre> <code>with_progress_tracking(cls)</code> \u00b6 <p>Ein Klassendekorator, der die Methoden run_async, prep_async, exec_async, und exec_fallback_async automatisch mit umfassendem Progress-Tracking umwickelt.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/agent.py</code> <pre><code>def with_progress_tracking(cls):\n    \"\"\"\n    Ein Klassendekorator, der die Methoden run_async, prep_async, exec_async,\n    und exec_fallback_async automatisch mit umfassendem Progress-Tracking umwickelt.\n    \"\"\"\n\n    # --- Wrapper f\u00fcr run_async ---\n    original_run = getattr(cls, 'run_async', None)\n    if original_run:\n        @functools.wraps(original_run)\n        async def wrapped_run_async(self, shared):\n            progress_tracker = shared.get(\"progress_tracker\")\n            node_name = self.__class__.__name__\n\n            if not progress_tracker:\n                return await original_run(self, shared)\n\n            timer_key = f\"{node_name}_total\"\n            progress_tracker.start_timer(timer_key)\n            await progress_tracker.emit_event(ProgressEvent(\n                event_type=\"node_enter\",\n                timestamp=time.time(),\n                node_name=node_name,\n                session_id=shared.get(\"session_id\"),\n                task_id=shared.get(\"current_task_id\"),\n                plan_id=shared.get(\"current_plan\", TaskPlan(id=\"none\", name=\"none\", description=\"none\")).id if shared.get(\"current_plan\") else None,\n                status=NodeStatus.RUNNING,\n                success=None\n            ))\n\n            try:\n                # Hier wird die urspr\u00fcngliche Methode aufgerufen\n                result = await original_run(self, shared)\n\n                total_duration = progress_tracker.end_timer(timer_key)\n                await progress_tracker.emit_event(ProgressEvent(\n                    event_type=\"node_exit\",\n                    timestamp=time.time(),\n                    node_name=node_name,\n                    status=NodeStatus.COMPLETED,\n                    success=True,\n                    node_duration=total_duration,\n                    routing_decision=result,\n                    session_id=shared.get(\"session_id\"),\n                    task_id=shared.get(\"current_task_id\"),\n                    metadata={\"success\": True}\n                ))\n\n                return result\n            except Exception as e:\n                total_duration = progress_tracker.end_timer(timer_key)\n                await progress_tracker.emit_event(ProgressEvent(\n                    event_type=\"error\",\n                    timestamp=time.time(),\n                    node_name=node_name,\n                    status=NodeStatus.FAILED,\n                    success=False,\n                    node_duration=total_duration,\n                    session_id=shared.get(\"session_id\"),\n                    metadata={\"error\": str(e), \"error_type\": type(e).__name__}\n                ))\n                raise\n\n        cls.run_async = wrapped_run_async\n\n    # --- Wrapper f\u00fcr prep_async ---\n    original_prep = getattr(cls, 'prep_async', None)\n    if original_prep:\n        @functools.wraps(original_prep)\n        async def wrapped_prep_async(self, shared):\n            progress_tracker = shared.get(\"progress_tracker\")\n            node_name = self.__class__.__name__\n\n            if not progress_tracker:\n                return await original_prep(self, shared)\n            timer_key = f\"{node_name}_total_p\"\n            progress_tracker.start_timer(timer_key)\n            timer_key = f\"{node_name}_prep\"\n            progress_tracker.start_timer(timer_key)\n            await progress_tracker.emit_event(ProgressEvent(\n                event_type=\"node_phase\",\n                timestamp=time.time(),\n                node_name=node_name,\n                status=NodeStatus.STARTING,\n                node_phase=\"prep\",\n                session_id=shared.get(\"session_id\")\n            ))\n\n            try:\n                result = await original_prep(self, shared)\n\n                prep_duration = progress_tracker.end_timer(timer_key)\n                await progress_tracker.emit_event(ProgressEvent(\n                    event_type=\"node_phase\",\n                    timestamp=time.time(),\n                    status=NodeStatus.RUNNING,\n                    success=True,\n                    node_name=node_name,\n                    node_phase=\"prep_complete\",\n                    node_duration=prep_duration,\n                    session_id=shared.get(\"session_id\")\n                ))\n                return result\n            except Exception as e:\n                progress_tracker.end_timer(timer_key)\n                await progress_tracker.emit_event(ProgressEvent(\n                    event_type=\"error\",\n                    timestamp=time.time(),\n                    node_name=node_name,\n                    status=NodeStatus.FAILED,\n                    success=False,\n                    metadata={\"error\": str(e), \"error_type\": type(e).__name__},\n                    node_phase=\"prep_failed\"\n                ))\n                raise\n\n\n        cls.prep_async = wrapped_prep_async\n\n    # --- Wrapper f\u00fcr exec_async ---\n    original_exec = getattr(cls, 'exec_async', None)\n    if original_exec:\n        @functools.wraps(original_exec)\n        async def wrapped_exec_async(self, prep_res):\n            progress_tracker = prep_res.get(\"progress_tracker\") if isinstance(prep_res, dict) else None\n            node_name = self.__class__.__name__\n\n            if not progress_tracker:\n                return await original_exec(self, prep_res)\n\n            timer_key = f\"{node_name}_exec\"\n            progress_tracker.start_timer(timer_key)\n            await progress_tracker.emit_event(ProgressEvent(\n                event_type=\"node_phase\",\n                timestamp=time.time(),\n                node_name=node_name,\n                status=NodeStatus.RUNNING,\n                node_phase=\"exec\",\n                session_id=prep_res.get(\"session_id\") if isinstance(prep_res, dict) else None\n            ))\n\n            # In exec gibt es normalerweise keine Fehlerbehandlung, da diese von run_async \u00fcbernommen wird\n            result = await original_exec(self, prep_res)\n\n            exec_duration = progress_tracker.end_timer(timer_key)\n            await progress_tracker.emit_event(ProgressEvent(\n                event_type=\"node_phase\",\n                timestamp=time.time(),\n                node_name=node_name,\n                status=NodeStatus.RUNNING,\n                success=True,\n                node_phase=\"exec_complete\",\n                node_duration=exec_duration,\n                session_id=prep_res.get(\"session_id\") if isinstance(prep_res, dict) else None\n            ))\n            return result\n\n        cls.exec_async = wrapped_exec_async\n\n    # --- Wrapper f\u00fcr post_async ---\n    original_post = getattr(cls, 'post_async', None)\n    if original_post:\n        @functools.wraps(original_post)\n        async def wrapped_post_async(self, shared, prep_res, exec_res):\n            if isinstance(exec_res, str):\n                print(\"exec_res is string:\", exec_res)\n            progress_tracker = shared.get(\"progress_tracker\")\n            node_name = self.__class__.__name__\n\n            if not progress_tracker:\n                return await original_post(self, shared, prep_res, exec_res)\n\n            timer_key_post = f\"{node_name}_post\"\n            progress_tracker.start_timer(timer_key_post)\n            await progress_tracker.emit_event(ProgressEvent(\n                event_type=\"node_phase\",\n                timestamp=time.time(),\n                node_name=node_name,\n                status=NodeStatus.COMPLETING,  # Neue Phase \"completing\"\n                node_phase=\"post\",\n                session_id=shared.get(\"session_id\")\n            ))\n\n            try:\n                # Die eigentliche post_async Methode aufrufen\n                result = await original_post(self, shared, prep_res, exec_res)\n\n                post_duration = progress_tracker.end_timer(timer_key_post)\n                total_duration = progress_tracker.end_timer(f\"{node_name}_total_p\")  # Gesamtdauer stoppen\n\n                # Sende das entscheidende \"node_exit\" Event nach erfolgreicher post-Phase\n                await progress_tracker.emit_event(ProgressEvent(\n                    event_type=\"node_exit\",\n                    timestamp=time.time(),\n                    node_name=node_name,\n                    status=NodeStatus.COMPLETED,\n                    success=True,\n                    node_duration=total_duration,\n                    routing_decision=result,\n                    session_id=shared.get(\"session_id\"),\n                    task_id=shared.get(\"current_task_id\"),\n                    metadata={\n                        \"success\": True,\n                        \"post_duration\": post_duration\n                    }\n                ))\n\n                return result\n            except Exception as e:\n                # Fehler in der post-Phase\n\n                post_duration = progress_tracker.end_timer(timer_key_post)\n                total_duration = progress_tracker.end_timer(f\"{node_name}_total\")\n                await progress_tracker.emit_event(ProgressEvent(\n                    event_type=\"error\",\n                    timestamp=time.time(),\n                    node_name=node_name,\n                    status=NodeStatus.FAILED,\n                    success=False,\n                    node_duration=total_duration,\n                    metadata={\"error\": str(e), \"error_type\": type(e).__name__, \"phase\": \"post\"},\n                    node_phase=\"post_failed\"\n                ))\n                raise\n\n        cls.post_async = wrapped_post_async\n\n    # --- Wrapper f\u00fcr exec_fallback_async ---\n    original_fallback = getattr(cls, 'exec_fallback_async', None)\n    if original_fallback:\n        @functools.wraps(original_fallback)\n        async def wrapped_fallback_async(self, prep_res, exc):\n            progress_tracker = prep_res.get(\"progress_tracker\") if isinstance(prep_res, dict) else None\n            node_name = self.__class__.__name__\n\n            if progress_tracker:\n                timer_key = f\"{node_name}_exec\"\n                exec_duration = progress_tracker.end_timer(timer_key)\n                await progress_tracker.emit_event(ProgressEvent(\n                    event_type=\"node_phase\",\n                    timestamp=time.time(),\n                    node_name=node_name,\n                    node_phase=\"exec_fallback\",\n                    node_duration=exec_duration,\n                    status=NodeStatus.FAILED,\n                    success=False,\n                    session_id=prep_res.get(\"session_id\") if isinstance(prep_res, dict) else None,\n                    metadata={\"error\": str(exc), \"error_type\": type(exc).__name__},\n                ))\n\n            return await original_fallback(self, prep_res, exc)\n\n        cls.exec_fallback_async = wrapped_fallback_async\n\n    return cls\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.Agent.builder","title":"<code>builder</code>","text":"<code>A2AConfig</code> \u00b6 <p>               Bases: <code>BaseModel</code></p> <p>A2A server configuration</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>class A2AConfig(BaseModel):\n    \"\"\"A2A server configuration\"\"\"\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    enabled: bool = False\n    host: str = \"0.0.0.0\"\n    port: int = 5000\n    agent_name: str = None\n    agent_description: str = None\n    agent_version: str = \"1.0.0\"\n    expose_tools_as_skills: bool = True\n</code></pre> <code>AgentConfig</code> \u00b6 <p>               Bases: <code>BaseModel</code></p> <p>Complete agent configuration for loading/saving</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>class AgentConfig(BaseModel):\n    \"\"\"Complete agent configuration for loading/saving\"\"\"\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    # Basic settings\n    name: str = \"ProductionAgent\"\n    description: str = \"Production-ready PocketFlow agent\"\n    version: str = \"2.0.0\"\n\n    # LLM settings\n    fast_llm_model: str = \"openrouter/anthropic/claude-3-haiku\"\n    complex_llm_model: str = \"openrouter/openai/gpt-4o\"\n    system_message: str = \"\"\"You are a production-ready autonomous agent with advanced capabilities including:\n- Native MCP tool integration for extensible functionality\n- A2A compatibility for agent-to-agent communication\n- Dynamic task planning and execution with adaptive reflection\n- Advanced context management with session awareness\n- Variable system for dynamic content generation\n- Checkpoint/resume capabilities for reliability\n\nAlways utilize available tools when they can help solve the user's request efficiently.\"\"\"\n\n    temperature: float = 0.7\n    max_tokens_output: int = 2048\n    max_tokens_input: int = 32768\n    api_key_env_var: str | None = \"OPENROUTER_API_KEY\"\n    use_fast_response: bool = True\n\n    # Features\n    mcp: MCPConfig = Field(default_factory=MCPConfig)\n    a2a: A2AConfig = Field(default_factory=A2AConfig)\n    telemetry: TelemetryConfig = Field(default_factory=TelemetryConfig)\n    checkpoint: CheckpointConfig = Field(default_factory=CheckpointConfig)\n\n    # Agent behavior\n    max_parallel_tasks: int = 3\n    verbose_logging: bool = False\n\n    # Persona and formatting\n    active_persona: str = None\n    persona_profiles: dict[str, dict[str, Any]] = Field(default_factory=dict)\n    default_format_config: dict[str, Any] = None\n\n    # Custom variables and world model\n    custom_variables: dict[str, Any] = Field(default_factory=dict)\n    initial_world_model: dict[str, Any] = Field(default_factory=dict)\n</code></pre> <code>CheckpointConfig</code> \u00b6 <p>               Bases: <code>BaseModel</code></p> <p>Checkpoint configuration</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>class CheckpointConfig(BaseModel):\n    \"\"\"Checkpoint configuration\"\"\"\n    enabled: bool = True\n    interval_seconds: int = 300  # 5 minutes\n    max_checkpoints: int = 10\n    checkpoint_dir: str = \"./checkpoints\"\n    auto_save_on_exit: bool = True\n</code></pre> <code>FlowAgentBuilder</code> \u00b6 <p>Production-ready FlowAgent builder focused on MCP, A2A, and robust deployment</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>class FlowAgentBuilder:\n    \"\"\"Production-ready FlowAgent builder focused on MCP, A2A, and robust deployment\"\"\"\n\n    def __init__(self, config: AgentConfig = None, config_path: str = None):\n        \"\"\"Initialize builder with configuration\"\"\"\n\n        if config and config_path:\n            raise ValueError(\"Provide either config object or config_path, not both\")\n\n        if config_path:\n            self.config = self.load_config(config_path)\n        elif config:\n            self.config = config\n        else:\n            self.config = AgentConfig()\n\n        # Runtime components\n        self._custom_tools: dict[str, tuple[Callable, str]] = {}\n        self._mcp_tools: dict[str, dict] = {}\n        self._mcp_session_manager = MCPSessionManager()\n\n        self._budget_manager: BudgetManager = None\n        self._tracer_provider: TracerProvider = None\n        self._a2a_server: Any = None\n\n        # Set logging level\n        if self.config.verbose_logging:\n            logging.getLogger().setLevel(logging.DEBUG)\n\n        iprint(f\"FlowAgent Builder initialized: {self.config.name}\")\n\n    # ===== CONFIGURATION MANAGEMENT =====\n\n    def load_config(self, config_path: str) -&gt; AgentConfig:\n        \"\"\"Load agent configuration from file\"\"\"\n        path = Path(config_path)\n        if not path.exists():\n            raise FileNotFoundError(f\"Config file not found: {config_path}\")\n\n        try:\n            with open(path, encoding='utf-8') as f:\n                if path.suffix.lower() in ['.yaml', '.yml']:\n                    data = yaml.safe_load(f)\n                else:\n                    data = json.load(f)\n\n            return AgentConfig(**data)\n\n        except Exception as e:\n            eprint(f\"Failed to load config from {config_path}: {e}\")\n            raise\n\n    def save_config(self, config_path: str, format: str = 'yaml'):\n        \"\"\"Save current configuration to file\"\"\"\n        path = Path(config_path)\n        path.parent.mkdir(parents=True, exist_ok=True)\n\n        try:\n            data = self.config.model_dump()\n\n            with open(path, 'w', encoding='utf-8') as f:\n                if format.lower() == 'yaml':\n                    yaml.dump(data, f, default_flow_style=False, indent=2)\n                else:\n                    json.dump(data, f, indent=2)\n\n            iprint(f\"Configuration saved to {config_path}\")\n\n        except Exception as e:\n            eprint(f\"Failed to save config to {config_path}: {e}\")\n            raise\n\n    @classmethod\n    def from_config_file(cls, config_path: str) -&gt; 'FlowAgentBuilder':\n        \"\"\"Create builder from configuration file\"\"\"\n        return cls(config_path=config_path)\n\n    # ===== FLUENT BUILDER API =====\n\n    def with_name(self, name: str) -&gt; 'FlowAgentBuilder':\n        \"\"\"Set agent name\"\"\"\n        self.config.name = name\n        return self\n\n    def with_models(self, fast_model: str, complex_model: str = None) -&gt; 'FlowAgentBuilder':\n        \"\"\"Set LLM models\"\"\"\n        self.config.fast_llm_model = fast_model\n        if complex_model:\n            self.config.complex_llm_model = complex_model\n        return self\n\n    def with_system_message(self, message: str) -&gt; 'FlowAgentBuilder':\n        \"\"\"Set system message\"\"\"\n        self.config.system_message = message\n        return self\n\n    def with_temperature(self, temp: float) -&gt; 'FlowAgentBuilder':\n        \"\"\"Set temperature\"\"\"\n        self.config.temperature = temp\n        return self\n\n    def with_budget_manager(self, max_cost: float = 10.0) -&gt; 'FlowAgentBuilder':\n        \"\"\"Enable budget management\"\"\"\n        if LITELLM_AVAILABLE:\n            self._budget_manager = BudgetManager(\"agent\")\n            iprint(f\"Budget manager enabled: ${max_cost}\")\n        else:\n            wprint(\"LiteLLM not available, budget manager disabled\")\n        return self\n\n    def verbose(self, enable: bool = True) -&gt; 'FlowAgentBuilder':\n        \"\"\"Enable verbose logging\"\"\"\n        self.config.verbose_logging = enable\n        if enable:\n            logging.getLogger().setLevel(logging.DEBUG)\n        return self\n\n    # ===== MCP INTEGRATION =====\n\n    def enable_mcp_server(self, host: str = \"0.0.0.0\", port: int = 8000,\n                          server_name: str = None) -&gt; 'FlowAgentBuilder':\n        \"\"\"Enable MCP server\"\"\"\n        if not MCP_AVAILABLE:\n            wprint(\"MCP not available, cannot enable server\")\n            return self\n\n        self.config.mcp.enabled = True\n        self.config.mcp.host = host\n        self.config.mcp.port = port\n        self.config.mcp.server_name = server_name or f\"{self.config.name}_MCP\"\n\n        iprint(f\"MCP server enabled: {host}:{port}\")\n        return self\n\n    async def _load_mcp_server_capabilities(self, server_name: str, server_config: dict[str, Any]):\n        \"\"\"Load all capabilities from MCP server with persistent session\"\"\"\n        try:\n            # Get or create persistent session\n            session = await self._mcp_session_manager.get_session(server_name, server_config)\n            if not session:\n                eprint(f\"Failed to create session for MCP server: {server_name}\")\n                return\n\n            # Extract all capabilities\n            capabilities = await self._mcp_session_manager.extract_capabilities(session, server_name)\n\n            # Create tool wrappers\n            for tool_name, tool_info in capabilities['tools'].items():\n                wrapper_name = f\"{server_name}_{tool_name}\"\n                tool_wrapper = self._create_tool_wrapper(server_name, tool_name, tool_info, session)\n                self._mcp_tools[wrapper_name] = {\n                    'function': tool_wrapper,\n                    'description': tool_info['description'],\n                    'type': 'tool',\n                    'server': server_name,\n                    'original_name': tool_name,\n                    'input_schema': tool_info.get('input_schema'),\n                    'output_schema': tool_info.get('output_schema')\n                }\n\n            # Create resource wrappers\n            for resource_uri, resource_info in capabilities['resources'].items():\n                wrapper_name = f\"{server_name}_resource_{resource_info['name'].replace('/', '_')}\"\n                resource_wrapper = self._create_resource_wrapper(server_name, resource_uri, resource_info, session)\n\n                self._mcp_tools[wrapper_name] = {\n                    'function': resource_wrapper,\n                    'description': f\"Read resource: {resource_info['description']}\",\n                    'type': 'resource',\n                    'server': server_name,\n                    'original_uri': resource_uri\n                }\n\n            # Create resource template wrappers\n            for template_uri, template_info in capabilities['resource_templates'].items():\n                wrapper_name = f\"{server_name}_template_{template_info['name'].replace('/', '_')}\"\n                template_wrapper = self._create_resource_template_wrapper(server_name, template_uri, template_info,\n                                                                          session)\n\n                self._mcp_tools[wrapper_name] = {\n                    'function': template_wrapper,\n                    'description': f\"Access resource template: {template_info['description']}\",\n                    'type': 'resource_template',\n                    'server': server_name,\n                    'original_template': template_uri\n                }\n\n            # Create prompt wrappers\n            for prompt_name, prompt_info in capabilities['prompts'].items():\n                wrapper_name = f\"{server_name}_prompt_{prompt_name}\"\n                prompt_wrapper = self._create_prompt_wrapper(server_name, prompt_name, prompt_info, session)\n\n                self._mcp_tools[wrapper_name] = {\n                    'function': prompt_wrapper,\n                    'description': f\"Execute prompt: {prompt_info['description']}\",\n                    'type': 'prompt',\n                    'server': server_name,\n                    'original_name': prompt_name,\n                    'arguments': prompt_info.get('arguments', [])\n                }\n\n            total_capabilities = (len(capabilities['tools']) +\n                                  len(capabilities['resources']) +\n                                  len(capabilities['resource_templates']) +\n                                  len(capabilities['prompts']))\n\n            iprint(f\"Created {total_capabilities} capability wrappers for server: {server_name}\")\n\n        except Exception as e:\n            eprint(f\"Failed to load capabilities from MCP server {server_name}: {e}\")\n\n    def _create_tool_wrapper(self, server_name: str, tool_name: str, tool_info: dict, session: ClientSession):\n        \"\"\"Create wrapper function for MCP tool with dynamic signature based on schema\"\"\"\n        import inspect\n\n        # Extract parameter information from input schema\n        input_schema = tool_info.get('input_schema', {})\n        output_schema = tool_info.get('output_schema', {})\n\n        # Build parameter list\n        parameters = []\n        required_params = set(input_schema.get('required', []))\n        properties = input_schema.get('properties', {})\n\n        # Create parameters with proper types\n        for param_name, param_info in properties.items():\n            param_type = param_info.get('type', 'string')\n            python_type = {\n                'string': str,\n                'integer': int,\n                'number': float,\n                'boolean': bool,\n                'array': list,\n                'object': dict\n            }.get(param_type, str)\n\n            # Determine if parameter is required\n            if param_name in required_params:\n                param = inspect.Parameter(param_name, inspect.Parameter.POSITIONAL_OR_KEYWORD, annotation=python_type)\n            else:\n                # Optional parameters get default None\n                param = inspect.Parameter(param_name, inspect.Parameter.POSITIONAL_OR_KEYWORD,\n                                          annotation=python_type, default=None)\n            parameters.append(param)\n\n        # Determine return type from output schema\n        return_type = str  # Default\n        if output_schema and 'properties' in output_schema:\n            output_props = output_schema['properties']\n            if len(output_props) == 1:\n                # Single property, return its type directly\n                prop_info = list(output_props.values())[0]\n                prop_type = prop_info.get('type', 'string')\n                return_type = {\n                    'string': str,\n                    'integer': int,\n                    'number': float,\n                    'boolean': bool,\n                    'array': list,\n                    'object': dict\n                }.get(prop_type, str)\n            else:\n                # Multiple properties, return dict\n                return_type = dict\n\n        # Create the actual function\n        async def tool_wrapper(*args, **kwargs):\n            try:\n                # Map arguments to schema parameters\n                arguments = {}\n                param_names = list(properties.keys())\n\n                # Map positional args\n                for i, arg in enumerate(args):\n                    if i &lt; len(param_names):\n                        arguments[param_names[i]] = arg\n\n                # Add keyword arguments, filtering out None for optional params\n                for key, value in kwargs.items():\n                    if value is not None or key in required_params:\n                        arguments[key] = value\n\n                # Validate required parameters\n                missing_required = required_params - set(arguments.keys())\n                if missing_required:\n                    raise ValueError(f\"Missing required parameters: {missing_required}\")\n\n                # Call the actual MCP tool\n                result = await session.call_tool(tool_name, arguments)\n\n                # Handle structured vs unstructured results\n                if hasattr(result, 'structuredContent') and result.structuredContent:\n                    structured_data = result.structuredContent\n\n                    # If output schema expects single property, extract it\n                    if output_schema and 'properties' in output_schema:\n                        output_props = output_schema['properties']\n                        if len(output_props) == 1:\n                            prop_name = list(output_props.keys())[0]\n                            if isinstance(structured_data, dict) and prop_name in structured_data:\n                                return structured_data[prop_name]\n\n                    return structured_data\n\n                # Fallback to content extraction\n                if result.content:\n                    content = result.content[0]\n                    if hasattr(content, 'text'):\n                        return content.text\n                    elif hasattr(content, 'data'):\n                        return content.data\n                    else:\n                        return str(content)\n\n                return \"No content returned\"\n\n            except Exception as e:\n                eprint(f\"MCP tool {server_name}.{tool_name} failed: {e}\")\n                raise RuntimeError(f\"Error executing {tool_name}: {str(e)}\")\n\n        # Set dynamic signature\n        signature = inspect.Signature(parameters, return_annotation=return_type)\n        tool_wrapper.__signature__ = signature\n        tool_wrapper.__name__ = f\"{server_name}_{tool_name}\"\n        tool_wrapper.__doc__ = tool_info.get('description', f\"MCP tool: {tool_name}\")\n        tool_wrapper.__annotations__ = {'return': return_type}\n\n        # Add parameter annotations\n        for param in parameters:\n            tool_wrapper.__annotations__[param.name] = param.annotation\n\n        return tool_wrapper\n\n    def _create_resource_wrapper(self, server_name: str, resource_uri: str, resource_info: dict,\n                                 session: ClientSession):\n        \"\"\"Create wrapper function for MCP resource with proper signature\"\"\"\n        import inspect\n\n        # Resources typically don't take parameters, return string content\n        async def resource_wrapper() -&gt; str:\n            \"\"\"Read MCP resource content\"\"\"\n            try:\n                from pydantic import AnyUrl\n                result = await session.read_resource(AnyUrl(resource_uri))\n\n                if result.contents:\n                    content = result.contents[0]\n                    if hasattr(content, 'text'):\n                        return content.text\n                    elif hasattr(content, 'data'):\n                        # Handle binary data\n                        if isinstance(content.data, bytes):\n                            return content.data.decode('utf-8', errors='ignore')\n                        return str(content.data)\n                    else:\n                        return str(content)\n\n                return \"\"\n\n            except Exception as e:\n                eprint(f\"MCP resource {resource_uri} failed: {e}\")\n                raise RuntimeError(f\"Error reading resource: {str(e)}\")\n\n        # Set signature and metadata\n        signature = inspect.Signature([], return_annotation=str)\n        resource_wrapper.__signature__ = signature\n        resource_wrapper.__name__ = f\"{server_name}_resource_{resource_info['name'].replace('/', '_').replace(':', '_')}\"\n        resource_wrapper.__doc__ = f\"Read MCP resource: {resource_info.get('description', resource_uri)}\"\n        resource_wrapper.__annotations__ = {'return': str}\n\n        return resource_wrapper\n\n    def _create_resource_template_wrapper(self, server_name: str, template_uri: str, template_info: dict,\n                                          session: ClientSession):\n        \"\"\"Create wrapper function for MCP resource template with dynamic parameters\"\"\"\n        import inspect\n        import re\n\n        # Extract template variables from URI (e.g., {owner}, {repo})\n        template_vars = re.findall(r'\\{(\\w+)\\}', template_uri)\n\n        # Create parameters for each template variable\n        parameters = []\n        for var_name in template_vars:\n            param = inspect.Parameter(var_name, inspect.Parameter.POSITIONAL_OR_KEYWORD, annotation=str)\n            parameters.append(param)\n\n        async def template_wrapper(*args, **kwargs) -&gt; str:\n            \"\"\"Access MCP resource template with parameters\"\"\"\n            try:\n                from pydantic import AnyUrl\n\n                # Map arguments to template variables\n                template_args = {}\n                for i, arg in enumerate(args):\n                    if i &lt; len(template_vars):\n                        template_args[template_vars[i]] = arg\n\n                template_args.update(kwargs)\n\n                # Validate all required template variables are provided\n                missing_vars = set(template_vars) - set(template_args.keys())\n                if missing_vars:\n                    raise ValueError(f\"Missing required template variables: {missing_vars}\")\n\n                # Replace template variables in URI\n                actual_uri = template_uri\n                for var_name, value in template_args.items():\n                    actual_uri = actual_uri.replace(f\"{{{var_name}}}\", str(value))\n\n                result = await session.read_resource(AnyUrl(actual_uri))\n\n                if result.contents:\n                    content = result.contents[0]\n                    if hasattr(content, 'text'):\n                        return content.text\n                    elif hasattr(content, 'data'):\n                        if isinstance(content.data, bytes):\n                            return content.data.decode('utf-8', errors='ignore')\n                        return str(content.data)\n                    else:\n                        return str(content)\n\n                return \"\"\n\n            except Exception as e:\n                eprint(f\"MCP resource template {template_uri} failed: {e}\")\n                raise RuntimeError(f\"Error accessing resource template: {str(e)}\")\n\n        # Set dynamic signature\n        signature = inspect.Signature(parameters, return_annotation=str)\n        template_wrapper.__signature__ = signature\n        template_wrapper.__name__ = f\"{server_name}_template_{template_info['name'].replace('/', '_').replace(':', '_')}\"\n        template_wrapper.__doc__ = f\"Access MCP resource template: {template_info.get('description', template_uri)}\\nTemplate variables: {', '.join(template_vars)}\"\n        template_wrapper.__annotations__ = {'return': str}\n\n        # Add parameter annotations\n        for param in parameters:\n            template_wrapper.__annotations__[param.name] = str\n\n        return template_wrapper\n\n    def _create_prompt_wrapper(self, server_name: str, prompt_name: str, prompt_info: dict, session: ClientSession):\n        \"\"\"Create wrapper function for MCP prompt with dynamic parameters\"\"\"\n        import inspect\n\n        # Extract parameter information from prompt arguments\n        prompt_args = prompt_info.get('arguments', [])\n\n        # Create parameters\n        parameters = []\n        for arg_info in prompt_args:\n            arg_name = arg_info['name']\n            is_required = arg_info.get('required', False)\n\n            if is_required:\n                param = inspect.Parameter(arg_name, inspect.Parameter.POSITIONAL_OR_KEYWORD, annotation=str)\n            else:\n                param = inspect.Parameter(arg_name, inspect.Parameter.POSITIONAL_OR_KEYWORD,\n                                          annotation=str, default=None)\n            parameters.append(param)\n\n        async def prompt_wrapper(*args, **kwargs) -&gt; str:\n            \"\"\"Execute MCP prompt with parameters\"\"\"\n            try:\n                # Map arguments\n                prompt_arguments = {}\n                arg_names = [arg['name'] for arg in prompt_args]\n\n                # Map positional args\n                for i, arg in enumerate(args):\n                    if i &lt; len(arg_names):\n                        prompt_arguments[arg_names[i]] = arg\n\n                # Add keyword arguments, filtering None for optional params\n                required_args = {arg['name'] for arg in prompt_args if arg.get('required', False)}\n                for key, value in kwargs.items():\n                    if value is not None or key in required_args:\n                        prompt_arguments[key] = value\n\n                # Validate required parameters\n                missing_required = required_args - set(prompt_arguments.keys())\n                if missing_required:\n                    raise ValueError(f\"Missing required prompt arguments: {missing_required}\")\n\n                result = await session.get_prompt(prompt_name, prompt_arguments)\n\n                # Extract and combine messages\n                messages = []\n                for message in result.messages:\n                    if hasattr(message.content, 'text'):\n                        messages.append(message.content.text)\n                    else:\n                        messages.append(str(message.content))\n\n                return \"\\n\".join(messages) if messages else \"\"\n\n            except Exception as e:\n                eprint(f\"MCP prompt {prompt_name} failed: {e}\")\n                raise RuntimeError(f\"Error executing prompt: {str(e)}\")\n\n        # Set dynamic signature\n        signature = inspect.Signature(parameters, return_annotation=str)\n        prompt_wrapper.__signature__ = signature\n        prompt_wrapper.__name__ = f\"{server_name}_prompt_{prompt_name}\"\n\n        # Build docstring with parameter info\n        param_docs = []\n        for arg_info in prompt_args:\n            required_str = \"required\" if arg_info.get('required', False) else \"optional\"\n            param_docs.append(\n                f\"    {arg_info['name']} ({required_str}): {arg_info.get('description', 'No description')}\")\n\n        docstring = f\"Execute MCP prompt: {prompt_info.get('description', prompt_name)}\"\n        if param_docs:\n            docstring += \"\\n\\nParameters:\\n\" + \"\\n\".join(param_docs)\n\n        prompt_wrapper.__doc__ = docstring\n        prompt_wrapper.__annotations__ = {'return': str}\n\n        # Add parameter annotations\n        for param in parameters:\n            prompt_wrapper.__annotations__[param.name] = str\n\n        return prompt_wrapper\n\n    def load_mcp_tools_from_config(self, config_path: str) -&gt; 'FlowAgentBuilder':\n        \"\"\"Enhanced MCP config loading with automatic session management and full capability extraction\"\"\"\n        if not MCP_AVAILABLE:\n            wprint(\"MCP not available, skipping tool loading\")\n            return self\n\n        config_path = Path(config_path)\n        if not config_path.exists():\n            raise FileNotFoundError(f\"MCP config not found: {config_path}\")\n\n        try:\n            with open(config_path, encoding='utf-8') as f:\n                if config_path.suffix.lower() in ['.yaml', '.yml']:\n                    mcp_config = yaml.safe_load(f)\n                else:\n                    mcp_config = json.load(f)\n\n            # Store config for async processing\n            self._mcp_config_data = mcp_config\n            self.config.mcp.config_path = str(config_path)\n\n            # Mark for processing during build\n            self._mcp_needs_loading = True\n\n            iprint(f\"MCP config loaded from {config_path}, will process during build\")\n\n        except Exception as e:\n            eprint(f\"Failed to load MCP config from {config_path}: {e}\")\n            raise\n\n        return self\n\n    async def _process_mcp_config(self):\n        \"\"\"Process MCP configuration with proper task management\"\"\"\n        if not hasattr(self, '_mcp_config_data') or not self._mcp_config_data:\n            return\n\n        mcp_config = self._mcp_config_data\n\n        # Handle standard MCP server configuration with sequential processing to avoid task issues\n        if 'mcpServers' in mcp_config:\n            servers_to_load = []\n\n            # Validate all servers first\n            for server_name, server_config in mcp_config['mcpServers'].items():\n                if self._validate_mcp_server_config(server_name, server_config):\n                    servers_to_load.append((server_name, server_config))\n                else:\n                    wprint(f\"Skipping invalid MCP server config: {server_name}\")\n\n            if servers_to_load:\n                iprint(f\"Processing {len(servers_to_load)} MCP servers sequentially...\")\n\n                # Process servers sequentially to avoid task boundary issues\n                successful_loads = 0\n                for server_name, server_config in servers_to_load:\n                    try:\n                        result = await asyncio.wait_for(\n                            self._load_single_mcp_server(server_name, server_config),\n                            timeout=5.0  # Per-server timeout\n                        )\n\n                        if result:\n                            successful_loads += 1\n                            iprint(f\"\u2713 Successfully loaded MCP server: {server_name}\")\n                        else:\n                            wprint(f\"\u26a0 MCP server {server_name} loaded with issues\")\n\n                    except TimeoutError:\n                        eprint(f\"\u2717 MCP server {server_name} timed out after 15 seconds\")\n                    except Exception as e:\n                        eprint(f\"\u2717 Failed to load MCP server {server_name}: {e}\")\n\n                iprint(\n                    f\"MCP processing complete: {successful_loads}/{len(servers_to_load)} servers loaded successfully\")\n\n        # Handle direct tools configuration (legacy)\n        elif 'tools' in mcp_config:\n            for tool_config in mcp_config['tools']:\n                try:\n                    self._load_direct_mcp_tool(tool_config)\n                except Exception as e:\n                    eprint(f\"Failed to load direct MCP tool: {e}\")\n\n    async def _load_single_mcp_server(self, server_name: str, server_config: dict[str, Any]) -&gt; bool:\n        \"\"\"Load a single MCP server with timeout and error handling\"\"\"\n        try:\n            iprint(f\"\ud83d\udd04 Processing MCP server: {server_name}\")\n\n            # Get session with timeout\n            session = await self._mcp_session_manager.get_session_with_timeout(server_name, server_config)\n            if not session:\n                eprint(f\"\u2717 Failed to create session for MCP server: {server_name}\")\n                return False\n\n            # Extract capabilities with timeout\n            capabilities = await self._mcp_session_manager.extract_capabilities_with_timeout(session, server_name)\n            if not any(capabilities.values()):\n                wprint(f\"\u26a0 No capabilities found for MCP server: {server_name}\")\n                return False\n\n            # Create wrappers for all capabilities\n            await self._create_capability_wrappers(server_name, capabilities, session)\n\n            total_caps = sum(len(caps) for caps in capabilities.values())\n            iprint(f\"\u2713 Created {total_caps} capability wrappers for: {server_name}\")\n\n            return True\n\n        except Exception as e:\n            eprint(f\"\u2717 Error loading MCP server {server_name}: {e}\")\n            return False\n\n    async def _create_capability_wrappers(self, server_name: str, capabilities: dict, session: ClientSession):\n        \"\"\"Create wrappers for all capabilities with error handling\"\"\"\n\n        # Create tool wrappers\n        for tool_name, tool_info in capabilities['tools'].items():\n            try:\n                wrapper_name = f\"{server_name}_{tool_name}\"\n                tool_wrapper = self._create_tool_wrapper(server_name, tool_name, tool_info, session)\n\n                self._mcp_tools[wrapper_name] = {\n                    'function': tool_wrapper,\n                    'description': tool_info['description'],\n                    'type': 'tool',\n                    'server': server_name,\n                    'original_name': tool_name,\n                    'input_schema': tool_info.get('input_schema'),\n                    'output_schema': tool_info.get('output_schema')\n                }\n            except Exception as e:\n                eprint(f\"Failed to create tool wrapper {tool_name}: {e}\")\n\n        # Create resource wrappers\n        for resource_uri, resource_info in capabilities['resources'].items():\n            try:\n                safe_name = resource_info['name'].replace('/', '_').replace(':', '_')\n                wrapper_name = f\"{server_name}_resource_{safe_name}\"\n                resource_wrapper = self._create_resource_wrapper(server_name, resource_uri, resource_info, session)\n\n                self._mcp_tools[wrapper_name] = {\n                    'function': resource_wrapper,\n                    'description': f\"Read resource: {resource_info['description']}\",\n                    'type': 'resource',\n                    'server': server_name,\n                    'original_uri': resource_uri\n                }\n            except Exception as e:\n                eprint(f\"Failed to create resource wrapper {resource_uri}: {e}\")\n\n        # Create resource template wrappers\n        for template_uri, template_info in capabilities['resource_templates'].items():\n            try:\n                safe_name = template_info['name'].replace('/', '_').replace(':', '_')\n                wrapper_name = f\"{server_name}_template_{safe_name}\"\n                template_wrapper = self._create_resource_template_wrapper(server_name, template_uri, template_info,\n                                                                          session)\n\n                self._mcp_tools[wrapper_name] = {\n                    'function': template_wrapper,\n                    'description': f\"Access resource template: {template_info['description']}\",\n                    'type': 'resource_template',\n                    'server': server_name,\n                    'original_template': template_uri\n                }\n            except Exception as e:\n                eprint(f\"Failed to create template wrapper {template_uri}: {e}\")\n\n        # Create prompt wrappers\n        for prompt_name, prompt_info in capabilities['prompts'].items():\n            try:\n                wrapper_name = f\"{server_name}_prompt_{prompt_name}\"\n                prompt_wrapper = self._create_prompt_wrapper(server_name, prompt_name, prompt_info, session)\n\n                self._mcp_tools[wrapper_name] = {\n                    'function': prompt_wrapper,\n                    'description': f\"Execute prompt: {prompt_info['description']}\",\n                    'type': 'prompt',\n                    'server': server_name,\n                    'original_name': prompt_name,\n                    'arguments': prompt_info.get('arguments', [])\n                }\n            except Exception as e:\n                eprint(f\"Failed to create prompt wrapper {prompt_name}: {e}\")\n\n    @staticmethod\n    def _validate_mcp_server_config(server_name: str, server_config: dict[str, Any]) -&gt; bool:\n        \"\"\"Validate MCP server configuration\"\"\"\n        command = server_config.get('command')\n        if not command:\n            eprint(f\"MCP server {server_name} missing 'command' field\")\n            return False\n\n        # Check if command exists and is executable\n        if command in ['npx', 'node', 'python', 'python3', 'docker']:\n            # These are common commands, assume they exist\n            return True\n\n        if server_config.get('transport') in ['http', 'streamable-http'] and server_config.get('url'):\n            return True\n\n        # For other commands, check if they exist\n        import shutil\n        if not shutil.which(command):\n            wprint(f\"MCP server {server_name}: command '{command}' not found in PATH\")\n            # Don't fail completely, just warn - the command might be available at runtime\n\n        args = server_config.get('args', [])\n        if not isinstance(args, list):\n            eprint(f\"MCP server {server_name}: 'args' must be a list\")\n            return False\n\n        env = server_config.get('env', {})\n        if not isinstance(env, dict):\n            eprint(f\"MCP server {server_name}: 'env' must be a dictionary\")\n            return False\n\n        iprint(f\"Validated MCP server config: {server_name}\")\n        return True\n\n    def _load_direct_mcp_tool(self, tool_config: dict[str, Any]):\n        \"\"\"Load tool from direct configuration\"\"\"\n        name = tool_config.get('name')\n        description = tool_config.get('description', '')\n        function_code = tool_config.get('function_code')\n\n        if not name or not function_code:\n            wprint(f\"Incomplete tool config: {tool_config}\")\n            return\n\n        # Create function from code\n        try:\n            namespace = {\"__builtins__\": __builtins__}\n            exec(function_code, namespace)\n\n            # Find the function\n            func = None\n            for obj in namespace.values():\n                if callable(obj) and not getattr(obj, '__name__', '').startswith('_'):\n                    func = obj\n                    break\n\n            if func:\n                self._mcp_tools[name] = {\n                    'function': func,\n                    'description': description,\n                    'source': 'code'\n                }\n                iprint(f\"Loaded MCP tool from code: {name}\")\n\n        except Exception as e:\n            eprint(f\"Failed to load MCP tool {name}: {e}\")\n\n    def add_mcp_tool_from_code(self, name: str, code: str, description: str = \"\") -&gt; 'FlowAgentBuilder':\n        \"\"\"Add MCP tool from code string\"\"\"\n        tool_config = {\n            'name': name,\n            'description': description,\n            'function_code': code\n        }\n        self._load_direct_mcp_tool(tool_config)\n        return self\n\n    # ===== A2A INTEGRATION =====\n\n    def enable_a2a_server(self, host: str = \"0.0.0.0\", port: int = 5000,\n                          agent_name: str = None, agent_description: str = None) -&gt; 'FlowAgentBuilder':\n        \"\"\"Enable A2A server for agent-to-agent communication\"\"\"\n        if not A2A_AVAILABLE:\n            wprint(\"A2A not available, cannot enable server\")\n            return self\n\n        self.config.a2a.enabled = True\n        self.config.a2a.host = host\n        self.config.a2a.port = port\n        self.config.a2a.agent_name = agent_name or self.config.name\n        self.config.a2a.agent_description = agent_description or self.config.description\n\n        iprint(f\"A2A server enabled: {host}:{port}\")\n        return self\n\n    # ===== TELEMETRY INTEGRATION =====\n\n    def enable_telemetry(self, service_name: str = None, endpoint: str = None,\n                         console_export: bool = True) -&gt; 'FlowAgentBuilder':\n        \"\"\"Enable OpenTelemetry tracing\"\"\"\n        if not OTEL_AVAILABLE:\n            wprint(\"OpenTelemetry not available, cannot enable telemetry\")\n            return self\n\n        self.config.telemetry.enabled = True\n        self.config.telemetry.service_name = service_name or self.config.name\n        self.config.telemetry.endpoint = endpoint\n        self.config.telemetry.console_export = console_export\n\n        # Initialize tracer provider\n        self._tracer_provider = TracerProvider()\n        trace.set_tracer_provider(self._tracer_provider)\n\n        # Add exporters\n        if console_export:\n            console_exporter = ConsoleSpanExporter()\n            span_processor = BatchSpanProcessor(console_exporter)\n            self._tracer_provider.add_span_processor(span_processor)\n\n        if endpoint:\n            try:\n                otlp_exporter = OTLPSpanExporter(endpoint=endpoint)\n                otlp_processor = BatchSpanProcessor(otlp_exporter)\n                self._tracer_provider.add_span_processor(otlp_processor)\n            except Exception as e:\n                wprint(f\"Failed to setup OTLP exporter: {e}\")\n\n        iprint(f\"Telemetry enabled for service: {service_name}\")\n        return self\n\n    # ===== CHECKPOINT CONFIGURATION =====\n\n    def with_checkpointing(self, enabled: bool = True, interval_seconds: int = 300,\n                           checkpoint_dir: str = \"./checkpoints\", max_checkpoints: int = 10) -&gt; 'FlowAgentBuilder':\n        \"\"\"Configure checkpointing\"\"\"\n        self.config.checkpoint.enabled = enabled\n        self.config.checkpoint.interval_seconds = interval_seconds\n        self.config.checkpoint.checkpoint_dir = checkpoint_dir\n        self.config.checkpoint.max_checkpoints = max_checkpoints\n\n        if enabled:\n            # Ensure checkpoint directory exists\n            Path(checkpoint_dir).mkdir(parents=True, exist_ok=True)\n            iprint(f\"Checkpointing enabled: {checkpoint_dir} (every {interval_seconds}s)\")\n\n        return self\n\n    # ===== TOOL MANAGEMENT =====\n\n    def add_tool(self, func: Callable, name: str = None, description: str = None) -&gt; 'FlowAgentBuilder':\n        \"\"\"Add custom tool function\"\"\"\n        tool_name = name or func.__name__\n        self._custom_tools[tool_name] = (func, description or func.__doc__)\n\n        iprint(f\"Tool added: {tool_name}\")\n        return self\n\n    def add_tools_from_module(self, module, prefix: str = \"\", exclude: list[str] = None) -&gt; 'FlowAgentBuilder':\n        \"\"\"Add all functions from a module as tools\"\"\"\n        exclude = exclude or []\n\n        for name, obj in inspect.getmembers(module, inspect.isfunction):\n            if name in exclude or name.startswith('_'):\n                continue\n\n            tool_name = f\"{prefix}{name}\" if prefix else name\n            self.add_tool(obj, name=tool_name)\n\n        iprint(f\"Added tools from module {module.__name__}\")\n        return self\n\n    # ===== PERSONA MANAGEMENT =====\n\n    def add_persona_profile(self, profile_name: str, name: str, style: str = \"professional\",\n                            tone: str = \"friendly\", personality_traits: list[str] = None,\n                            custom_instructions: str = \"\", response_format: str = None,\n                            text_length: str = None) -&gt; 'FlowAgentBuilder':\n        \"\"\"Add a persona profile with optional format configuration\"\"\"\n\n        if personality_traits is None:\n            personality_traits = [\"helpful\", \"concise\"]\n\n        # Create persona config\n        persona_data = {\n            \"name\": name,\n            \"style\": style,\n            \"tone\": tone,\n            \"personality_traits\": personality_traits,\n            \"custom_instructions\": custom_instructions,\n            \"apply_method\": \"system_prompt\",\n            \"integration_level\": \"light\"\n        }\n\n        # Add format config if specified\n        if response_format or text_length:\n            format_config = {\n                \"response_format\": response_format or \"frei-text\",\n                \"text_length\": text_length or \"chat-conversation\",\n                \"custom_instructions\": \"\",\n                \"strict_format_adherence\": True,\n                \"quality_threshold\": 0.7\n            }\n            persona_data[\"format_config\"] = format_config\n\n        self.config.persona_profiles[profile_name] = persona_data\n        iprint(f\"Persona profile added: {profile_name}\")\n        return self\n\n    def set_active_persona(self, profile_name: str) -&gt; 'FlowAgentBuilder':\n        \"\"\"Set active persona profile\"\"\"\n        if profile_name in self.config.persona_profiles:\n            self.config.active_persona = profile_name\n            iprint(f\"Active persona set: {profile_name}\")\n        else:\n            wprint(f\"Persona profile not found: {profile_name}\")\n        return self\n\n    def with_developer_persona(self, name: str = \"Senior Developer\") -&gt; 'FlowAgentBuilder':\n        \"\"\"Add and set a pre-built developer persona\"\"\"\n        return (self\n                .add_persona_profile(\n            \"developer\",\n            name=name,\n            style=\"technical\",\n            tone=\"professional\",\n            personality_traits=[\"precise\", \"thorough\", \"security_conscious\", \"best_practices\"],\n            custom_instructions=\"Focus on code quality, maintainability, and security. Always consider edge cases.\",\n            response_format=\"code-structure\",\n            text_length=\"detailed-indepth\"\n        )\n                .set_active_persona(\"developer\"))\n\n    def with_analyst_persona(self, name: str = \"Data Analyst\") -&gt; 'FlowAgentBuilder':\n        \"\"\"Add and set a pre-built analyst persona\"\"\"\n        return (self\n                .add_persona_profile(\n            \"analyst\",\n            name=name,\n            style=\"analytical\",\n            tone=\"objective\",\n            personality_traits=[\"methodical\", \"insight_driven\", \"evidence_based\"],\n            custom_instructions=\"Focus on statistical rigor and actionable recommendations.\",\n            response_format=\"with-tables\",\n            text_length=\"detailed-indepth\"\n        )\n                .set_active_persona(\"analyst\"))\n\n    def with_assistant_persona(self, name: str = \"AI Assistant\") -&gt; 'FlowAgentBuilder':\n        \"\"\"Add and set a pre-built general assistant persona\"\"\"\n        return (self\n                .add_persona_profile(\n            \"assistant\",\n            name=name,\n            style=\"friendly\",\n            tone=\"helpful\",\n            personality_traits=[\"helpful\", \"patient\", \"clear\", \"adaptive\"],\n            custom_instructions=\"Be helpful and adapt communication to user expertise level.\",\n            response_format=\"with-bullet-points\",\n            text_length=\"chat-conversation\"\n        )\n                .set_active_persona(\"assistant\"))\n\n    def with_creative_persona(self, name: str = \"Creative Assistant\") -&gt; 'FlowAgentBuilder':\n        \"\"\"Add and set a pre-built creative persona\"\"\"\n        return (self\n                .add_persona_profile(\n            \"creative\",\n            name=name,\n            style=\"creative\",\n            tone=\"inspiring\",\n            personality_traits=[\"imaginative\", \"expressive\", \"innovative\", \"engaging\"],\n            custom_instructions=\"Think outside the box and provide creative, inspiring solutions.\",\n            response_format=\"md-text\",\n            text_length=\"detailed-indepth\"\n        )\n                .set_active_persona(\"creative\"))\n\n    def with_executive_persona(self, name: str = \"Executive Assistant\") -&gt; 'FlowAgentBuilder':\n        \"\"\"Add and set a pre-built executive persona\"\"\"\n        return (self\n                .add_persona_profile(\n            \"executive\",\n            name=name,\n            style=\"professional\",\n            tone=\"authoritative\",\n            personality_traits=[\"strategic\", \"decisive\", \"results_oriented\", \"efficient\"],\n            custom_instructions=\"Provide strategic insights with executive-level clarity and focus on outcomes.\",\n            response_format=\"with-bullet-points\",\n            text_length=\"table-conversation\"\n        )\n                .set_active_persona(\"executive\"))\n\n    # ===== VARIABLE MANAGEMENT =====\n\n    def with_custom_variables(self, variables: dict[str, Any]) -&gt; 'FlowAgentBuilder':\n        \"\"\"Add custom variables\"\"\"\n        self.config.custom_variables.update(variables)\n        return self\n\n    def with_world_model(self, world_model: dict[str, Any]) -&gt; 'FlowAgentBuilder':\n        \"\"\"Set initial world model\"\"\"\n        self.config.initial_world_model.update(world_model)\n        return self\n\n    # ===== VALIDATION =====\n\n    def validate_config(self) -&gt; dict[str, list[str]]:\n        \"\"\"Validate the current configuration\"\"\"\n        issues = {\"errors\": [], \"warnings\": []}\n\n        # Validate required settings\n        if not self.config.fast_llm_model:\n            issues[\"errors\"].append(\"Fast LLM model not specified\")\n        if not self.config.complex_llm_model:\n            issues[\"errors\"].append(\"Complex LLM model not specified\")\n\n        # Validate MCP configuration\n        if self.config.mcp.enabled and not MCP_AVAILABLE:\n            issues[\"errors\"].append(\"MCP enabled but MCP not available\")\n\n        # Validate A2A configuration\n        if self.config.a2a.enabled and not A2A_AVAILABLE:\n            issues[\"errors\"].append(\"A2A enabled but A2A not available\")\n\n        # Validate telemetry\n        if self.config.telemetry.enabled and not OTEL_AVAILABLE:\n            issues[\"errors\"].append(\"Telemetry enabled but OpenTelemetry not available\")\n\n        # Validate personas\n        if self.config.active_persona and self.config.active_persona not in self.config.persona_profiles:\n            issues[\"errors\"].append(f\"Active persona '{self.config.active_persona}' not found in profiles\")\n\n        # Validate checkpoint directory\n        if self.config.checkpoint.enabled:\n            try:\n                Path(self.config.checkpoint.checkpoint_dir).mkdir(parents=True, exist_ok=True)\n            except Exception as e:\n                issues[\"warnings\"].append(f\"Cannot create checkpoint directory: {e}\")\n\n        return issues\n\n    # ===== MAIN BUILD METHOD =====\n\n    async def build(self) -&gt; FlowAgent:\n        \"\"\"Build the production-ready FlowAgent\"\"\"\n\n        with Spinner(message=f\"Building Agent {self.config.name}\", symbols='c'):\n            iprint(f\"Building production FlowAgent: {self.config.name}\")\n\n            # Validate configuration\n            validation_issues = self.validate_config()\n            if validation_issues[\"errors\"]:\n                error_msg = f\"Configuration validation failed: {', '.join(validation_issues['errors'])}\"\n                eprint(error_msg)\n                raise ValueError(error_msg)\n\n            # Log warnings\n            for warning in validation_issues[\"warnings\"]:\n                wprint(f\"Configuration warning: {warning}\")\n\n            try:\n                # 1. Setup API configuration\n                api_key = None\n                if self.config.api_key_env_var:\n                    api_key = os.getenv(self.config.api_key_env_var)\n                    if not api_key:\n                        wprint(f\"API key env var {self.config.api_key_env_var} not set\")\n\n                # 2. Create persona if configured\n                active_persona = None\n                if self.config.active_persona and self.config.active_persona in self.config.persona_profiles:\n                    persona_data = self.config.persona_profiles[self.config.active_persona]\n\n                    # Create FormatConfig if present\n                    format_config = None\n                    if \"format_config\" in persona_data:\n                        fc_data = persona_data.pop(\"format_config\")\n                        format_config = FormatConfig(\n                            response_format=ResponseFormat(fc_data.get(\"response_format\", \"frei-text\")),\n                            text_length=TextLength(fc_data.get(\"text_length\", \"chat-conversation\")),\n                            custom_instructions=fc_data.get(\"custom_instructions\", \"\"),\n                            strict_format_adherence=fc_data.get(\"strict_format_adherence\", True),\n                            quality_threshold=fc_data.get(\"quality_threshold\", 0.7)\n                        )\n\n                    active_persona = PersonaConfig(**persona_data)\n                    active_persona.format_config = format_config\n\n                    iprint(f\"Using persona: {active_persona.name}\")\n\n                # 3. Create AgentModelData\n                amd = AgentModelData(\n                    name=self.config.name,\n                    fast_llm_model=self.config.fast_llm_model,\n                    complex_llm_model=self.config.complex_llm_model,\n                    system_message=self.config.system_message,\n                    temperature=self.config.temperature,\n                    max_tokens=self.config.max_tokens_output,\n                    max_input_tokens=self.config.max_tokens_input,\n                    api_key=api_key,\n                    budget_manager=self._budget_manager,\n                    persona=active_persona,\n                    use_fast_response=self.config.use_fast_response\n                )\n\n                # 4. Create FlowAgent\n                agent = FlowAgent(\n                    amd=amd,\n                    world_model=self.config.initial_world_model.copy(),\n                    verbose=self.config.verbose_logging,\n                    enable_pause_resume=self.config.checkpoint.enabled,\n                    checkpoint_interval=self.config.checkpoint.interval_seconds,\n                    max_parallel_tasks=self.config.max_parallel_tasks\n                )\n\n                # 5. Add custom variables\n                for key, value in self.config.custom_variables.items():\n                    agent.set_variable(key, value)\n\n                # 6. Add custom tools\n                tools_added = 0\n                for tool_name, (tool_func, tool_description) in self._custom_tools.items():\n                    try:\n                        await agent.add_tool(tool_func, tool_name, tool_description)\n                        tools_added += 1\n                    except Exception as e:\n                        eprint(f\"Failed to add tool {tool_name}: {e}\")\n\n                with Spinner(message=\"Loading MCP\", symbols='w'):\n                    # 6a. Process MCP configuration if needed\n                    if hasattr(self, '_mcp_needs_loading') and self._mcp_needs_loading:\n                        await self._process_mcp_config()\n\n                # 7. Add MCP tools\n                for tool_name, tool_info in self._mcp_tools.items():\n                    try:\n                        await agent.add_tool(\n                            tool_info['function'],\n                            tool_name,\n                            tool_info['description']\n                        )\n                        tools_added += 1\n                    except Exception as e:\n                        eprint(f\"Failed to add MCP tool {tool_name}: {e}\")\n\n                agent._mcp_session_manager = self._mcp_session_manager\n\n                # 8. Setup MCP server\n                if self.config.mcp.enabled and MCP_AVAILABLE:\n                    try:\n                        agent.setup_mcp_server(\n                            host=self.config.mcp.host,\n                            port=self.config.mcp.port,\n                            name=self.config.mcp.server_name\n                        )\n                        iprint(\"MCP server configured\")\n                    except Exception as e:\n                        eprint(f\"Failed to setup MCP server: {e}\")\n\n                # 9. Setup A2A server\n                if self.config.a2a.enabled and A2A_AVAILABLE:\n                    try:\n                        agent.setup_a2a_server(\n                            host=self.config.a2a.host,\n                            port=self.config.a2a.port\n                        )\n                        iprint(\"A2A server configured\")\n                    except Exception as e:\n                        eprint(f\"Failed to setup A2A server: {e}\")\n\n                # 10. Initialize enhanced session context\n                try:\n                    await agent.initialize_session_context(max_history=200)\n                    iprint(\"Enhanced session context initialized\")\n                except Exception as e:\n                    wprint(f\"Session context initialization failed: {e}\")\n\n\n                # Final summary\n                iprint(\"ok FlowAgent built successfully!\")\n                iprint(f\"   Agent: {agent.amd.name}\")\n                iprint(f\"   Tools: {tools_added}\")\n                iprint(f\"   MCP: {'ok' if self.config.mcp.enabled else 'F'}\")\n                iprint(f\"   A2A: {'ok' if self.config.a2a.enabled else 'F'}\")\n                iprint(f\"   Telemetry: {'ok' if self.config.telemetry.enabled else 'F'}\")\n                iprint(f\"   Checkpoints: {'ok' if self.config.checkpoint.enabled else 'F'}\")\n                iprint(f\"   Persona: {active_persona.name if active_persona else 'Default'}\")\n\n                return agent\n\n            except Exception as e:\n                eprint(f\"Failed to build FlowAgent: {e}\")\n                raise\n\n    # ===== FACTORY METHODS =====\n\n    @classmethod\n    def create_developer_agent(cls, name: str = \"DeveloperAgent\",\n                               with_mcp: bool = True, with_a2a: bool = False) -&gt; 'FlowAgentBuilder':\n        \"\"\"Create a pre-configured developer agent\"\"\"\n        builder = (cls()\n                   .with_name(name)\n                   .with_developer_persona()\n                   .with_checkpointing(enabled=True, interval_seconds=300)\n                   .verbose(True))\n\n        if with_mcp:\n            builder.enable_mcp_server(port=8001)\n        if with_a2a:\n            builder.enable_a2a_server(port=5001)\n\n        return builder\n\n    @classmethod\n    def create_analyst_agent(cls, name: str = \"AnalystAgent\",\n                             with_telemetry: bool = True) -&gt; 'FlowAgentBuilder':\n        \"\"\"Create a pre-configured data analyst agent\"\"\"\n        builder = (cls()\n                   .with_name(name)\n                   .with_analyst_persona()\n                   .with_checkpointing(enabled=True)\n                   .verbose(False))\n\n        if with_telemetry:\n            builder.enable_telemetry(console_export=True)\n\n        return builder\n\n    @classmethod\n    def create_general_assistant(cls, name: str = \"AssistantAgent\",\n                                 full_integration: bool = True) -&gt; 'FlowAgentBuilder':\n        \"\"\"Create a general-purpose assistant with full integration\"\"\"\n        builder = (cls()\n                   .with_name(name)\n                   .with_assistant_persona()\n                   .with_checkpointing(enabled=True))\n\n        if full_integration:\n            builder.enable_mcp_server()\n            builder.enable_a2a_server()\n            builder.enable_telemetry()\n\n        return builder\n\n    @classmethod\n    def create_creative_agent(cls, name: str = \"CreativeAgent\") -&gt; 'FlowAgentBuilder':\n        \"\"\"Create a creative assistant agent\"\"\"\n        return (cls()\n                .with_name(name)\n                .with_creative_persona()\n                .with_temperature(0.8)  # More creative\n                .with_checkpointing(enabled=True))\n\n    @classmethod\n    def create_executive_agent(cls, name: str = \"ExecutiveAgent\",\n                               with_integrations: bool = True) -&gt; 'FlowAgentBuilder':\n        \"\"\"Create an executive assistant agent\"\"\"\n        builder = (cls()\n                   .with_name(name)\n                   .with_executive_persona()\n                   .with_checkpointing(enabled=True))\n\n        if with_integrations:\n            builder.enable_a2a_server()  # Executives need A2A for delegation\n            builder.enable_telemetry()  # Need metrics\n\n        return builder\n</code></pre> <code>__init__(config=None, config_path=None)</code> \u00b6 <p>Initialize builder with configuration</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>def __init__(self, config: AgentConfig = None, config_path: str = None):\n    \"\"\"Initialize builder with configuration\"\"\"\n\n    if config and config_path:\n        raise ValueError(\"Provide either config object or config_path, not both\")\n\n    if config_path:\n        self.config = self.load_config(config_path)\n    elif config:\n        self.config = config\n    else:\n        self.config = AgentConfig()\n\n    # Runtime components\n    self._custom_tools: dict[str, tuple[Callable, str]] = {}\n    self._mcp_tools: dict[str, dict] = {}\n    self._mcp_session_manager = MCPSessionManager()\n\n    self._budget_manager: BudgetManager = None\n    self._tracer_provider: TracerProvider = None\n    self._a2a_server: Any = None\n\n    # Set logging level\n    if self.config.verbose_logging:\n        logging.getLogger().setLevel(logging.DEBUG)\n\n    iprint(f\"FlowAgent Builder initialized: {self.config.name}\")\n</code></pre> <code>add_mcp_tool_from_code(name, code, description='')</code> \u00b6 <p>Add MCP tool from code string</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>def add_mcp_tool_from_code(self, name: str, code: str, description: str = \"\") -&gt; 'FlowAgentBuilder':\n    \"\"\"Add MCP tool from code string\"\"\"\n    tool_config = {\n        'name': name,\n        'description': description,\n        'function_code': code\n    }\n    self._load_direct_mcp_tool(tool_config)\n    return self\n</code></pre> <code>add_persona_profile(profile_name, name, style='professional', tone='friendly', personality_traits=None, custom_instructions='', response_format=None, text_length=None)</code> \u00b6 <p>Add a persona profile with optional format configuration</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>def add_persona_profile(self, profile_name: str, name: str, style: str = \"professional\",\n                        tone: str = \"friendly\", personality_traits: list[str] = None,\n                        custom_instructions: str = \"\", response_format: str = None,\n                        text_length: str = None) -&gt; 'FlowAgentBuilder':\n    \"\"\"Add a persona profile with optional format configuration\"\"\"\n\n    if personality_traits is None:\n        personality_traits = [\"helpful\", \"concise\"]\n\n    # Create persona config\n    persona_data = {\n        \"name\": name,\n        \"style\": style,\n        \"tone\": tone,\n        \"personality_traits\": personality_traits,\n        \"custom_instructions\": custom_instructions,\n        \"apply_method\": \"system_prompt\",\n        \"integration_level\": \"light\"\n    }\n\n    # Add format config if specified\n    if response_format or text_length:\n        format_config = {\n            \"response_format\": response_format or \"frei-text\",\n            \"text_length\": text_length or \"chat-conversation\",\n            \"custom_instructions\": \"\",\n            \"strict_format_adherence\": True,\n            \"quality_threshold\": 0.7\n        }\n        persona_data[\"format_config\"] = format_config\n\n    self.config.persona_profiles[profile_name] = persona_data\n    iprint(f\"Persona profile added: {profile_name}\")\n    return self\n</code></pre> <code>add_tool(func, name=None, description=None)</code> \u00b6 <p>Add custom tool function</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>def add_tool(self, func: Callable, name: str = None, description: str = None) -&gt; 'FlowAgentBuilder':\n    \"\"\"Add custom tool function\"\"\"\n    tool_name = name or func.__name__\n    self._custom_tools[tool_name] = (func, description or func.__doc__)\n\n    iprint(f\"Tool added: {tool_name}\")\n    return self\n</code></pre> <code>add_tools_from_module(module, prefix='', exclude=None)</code> \u00b6 <p>Add all functions from a module as tools</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>def add_tools_from_module(self, module, prefix: str = \"\", exclude: list[str] = None) -&gt; 'FlowAgentBuilder':\n    \"\"\"Add all functions from a module as tools\"\"\"\n    exclude = exclude or []\n\n    for name, obj in inspect.getmembers(module, inspect.isfunction):\n        if name in exclude or name.startswith('_'):\n            continue\n\n        tool_name = f\"{prefix}{name}\" if prefix else name\n        self.add_tool(obj, name=tool_name)\n\n    iprint(f\"Added tools from module {module.__name__}\")\n    return self\n</code></pre> <code>build()</code> <code>async</code> \u00b6 <p>Build the production-ready FlowAgent</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>async def build(self) -&gt; FlowAgent:\n    \"\"\"Build the production-ready FlowAgent\"\"\"\n\n    with Spinner(message=f\"Building Agent {self.config.name}\", symbols='c'):\n        iprint(f\"Building production FlowAgent: {self.config.name}\")\n\n        # Validate configuration\n        validation_issues = self.validate_config()\n        if validation_issues[\"errors\"]:\n            error_msg = f\"Configuration validation failed: {', '.join(validation_issues['errors'])}\"\n            eprint(error_msg)\n            raise ValueError(error_msg)\n\n        # Log warnings\n        for warning in validation_issues[\"warnings\"]:\n            wprint(f\"Configuration warning: {warning}\")\n\n        try:\n            # 1. Setup API configuration\n            api_key = None\n            if self.config.api_key_env_var:\n                api_key = os.getenv(self.config.api_key_env_var)\n                if not api_key:\n                    wprint(f\"API key env var {self.config.api_key_env_var} not set\")\n\n            # 2. Create persona if configured\n            active_persona = None\n            if self.config.active_persona and self.config.active_persona in self.config.persona_profiles:\n                persona_data = self.config.persona_profiles[self.config.active_persona]\n\n                # Create FormatConfig if present\n                format_config = None\n                if \"format_config\" in persona_data:\n                    fc_data = persona_data.pop(\"format_config\")\n                    format_config = FormatConfig(\n                        response_format=ResponseFormat(fc_data.get(\"response_format\", \"frei-text\")),\n                        text_length=TextLength(fc_data.get(\"text_length\", \"chat-conversation\")),\n                        custom_instructions=fc_data.get(\"custom_instructions\", \"\"),\n                        strict_format_adherence=fc_data.get(\"strict_format_adherence\", True),\n                        quality_threshold=fc_data.get(\"quality_threshold\", 0.7)\n                    )\n\n                active_persona = PersonaConfig(**persona_data)\n                active_persona.format_config = format_config\n\n                iprint(f\"Using persona: {active_persona.name}\")\n\n            # 3. Create AgentModelData\n            amd = AgentModelData(\n                name=self.config.name,\n                fast_llm_model=self.config.fast_llm_model,\n                complex_llm_model=self.config.complex_llm_model,\n                system_message=self.config.system_message,\n                temperature=self.config.temperature,\n                max_tokens=self.config.max_tokens_output,\n                max_input_tokens=self.config.max_tokens_input,\n                api_key=api_key,\n                budget_manager=self._budget_manager,\n                persona=active_persona,\n                use_fast_response=self.config.use_fast_response\n            )\n\n            # 4. Create FlowAgent\n            agent = FlowAgent(\n                amd=amd,\n                world_model=self.config.initial_world_model.copy(),\n                verbose=self.config.verbose_logging,\n                enable_pause_resume=self.config.checkpoint.enabled,\n                checkpoint_interval=self.config.checkpoint.interval_seconds,\n                max_parallel_tasks=self.config.max_parallel_tasks\n            )\n\n            # 5. Add custom variables\n            for key, value in self.config.custom_variables.items():\n                agent.set_variable(key, value)\n\n            # 6. Add custom tools\n            tools_added = 0\n            for tool_name, (tool_func, tool_description) in self._custom_tools.items():\n                try:\n                    await agent.add_tool(tool_func, tool_name, tool_description)\n                    tools_added += 1\n                except Exception as e:\n                    eprint(f\"Failed to add tool {tool_name}: {e}\")\n\n            with Spinner(message=\"Loading MCP\", symbols='w'):\n                # 6a. Process MCP configuration if needed\n                if hasattr(self, '_mcp_needs_loading') and self._mcp_needs_loading:\n                    await self._process_mcp_config()\n\n            # 7. Add MCP tools\n            for tool_name, tool_info in self._mcp_tools.items():\n                try:\n                    await agent.add_tool(\n                        tool_info['function'],\n                        tool_name,\n                        tool_info['description']\n                    )\n                    tools_added += 1\n                except Exception as e:\n                    eprint(f\"Failed to add MCP tool {tool_name}: {e}\")\n\n            agent._mcp_session_manager = self._mcp_session_manager\n\n            # 8. Setup MCP server\n            if self.config.mcp.enabled and MCP_AVAILABLE:\n                try:\n                    agent.setup_mcp_server(\n                        host=self.config.mcp.host,\n                        port=self.config.mcp.port,\n                        name=self.config.mcp.server_name\n                    )\n                    iprint(\"MCP server configured\")\n                except Exception as e:\n                    eprint(f\"Failed to setup MCP server: {e}\")\n\n            # 9. Setup A2A server\n            if self.config.a2a.enabled and A2A_AVAILABLE:\n                try:\n                    agent.setup_a2a_server(\n                        host=self.config.a2a.host,\n                        port=self.config.a2a.port\n                    )\n                    iprint(\"A2A server configured\")\n                except Exception as e:\n                    eprint(f\"Failed to setup A2A server: {e}\")\n\n            # 10. Initialize enhanced session context\n            try:\n                await agent.initialize_session_context(max_history=200)\n                iprint(\"Enhanced session context initialized\")\n            except Exception as e:\n                wprint(f\"Session context initialization failed: {e}\")\n\n\n            # Final summary\n            iprint(\"ok FlowAgent built successfully!\")\n            iprint(f\"   Agent: {agent.amd.name}\")\n            iprint(f\"   Tools: {tools_added}\")\n            iprint(f\"   MCP: {'ok' if self.config.mcp.enabled else 'F'}\")\n            iprint(f\"   A2A: {'ok' if self.config.a2a.enabled else 'F'}\")\n            iprint(f\"   Telemetry: {'ok' if self.config.telemetry.enabled else 'F'}\")\n            iprint(f\"   Checkpoints: {'ok' if self.config.checkpoint.enabled else 'F'}\")\n            iprint(f\"   Persona: {active_persona.name if active_persona else 'Default'}\")\n\n            return agent\n\n        except Exception as e:\n            eprint(f\"Failed to build FlowAgent: {e}\")\n            raise\n</code></pre> <code>create_analyst_agent(name='AnalystAgent', with_telemetry=True)</code> <code>classmethod</code> \u00b6 <p>Create a pre-configured data analyst agent</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>@classmethod\ndef create_analyst_agent(cls, name: str = \"AnalystAgent\",\n                         with_telemetry: bool = True) -&gt; 'FlowAgentBuilder':\n    \"\"\"Create a pre-configured data analyst agent\"\"\"\n    builder = (cls()\n               .with_name(name)\n               .with_analyst_persona()\n               .with_checkpointing(enabled=True)\n               .verbose(False))\n\n    if with_telemetry:\n        builder.enable_telemetry(console_export=True)\n\n    return builder\n</code></pre> <code>create_creative_agent(name='CreativeAgent')</code> <code>classmethod</code> \u00b6 <p>Create a creative assistant agent</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>@classmethod\ndef create_creative_agent(cls, name: str = \"CreativeAgent\") -&gt; 'FlowAgentBuilder':\n    \"\"\"Create a creative assistant agent\"\"\"\n    return (cls()\n            .with_name(name)\n            .with_creative_persona()\n            .with_temperature(0.8)  # More creative\n            .with_checkpointing(enabled=True))\n</code></pre> <code>create_developer_agent(name='DeveloperAgent', with_mcp=True, with_a2a=False)</code> <code>classmethod</code> \u00b6 <p>Create a pre-configured developer agent</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>@classmethod\ndef create_developer_agent(cls, name: str = \"DeveloperAgent\",\n                           with_mcp: bool = True, with_a2a: bool = False) -&gt; 'FlowAgentBuilder':\n    \"\"\"Create a pre-configured developer agent\"\"\"\n    builder = (cls()\n               .with_name(name)\n               .with_developer_persona()\n               .with_checkpointing(enabled=True, interval_seconds=300)\n               .verbose(True))\n\n    if with_mcp:\n        builder.enable_mcp_server(port=8001)\n    if with_a2a:\n        builder.enable_a2a_server(port=5001)\n\n    return builder\n</code></pre> <code>create_executive_agent(name='ExecutiveAgent', with_integrations=True)</code> <code>classmethod</code> \u00b6 <p>Create an executive assistant agent</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>@classmethod\ndef create_executive_agent(cls, name: str = \"ExecutiveAgent\",\n                           with_integrations: bool = True) -&gt; 'FlowAgentBuilder':\n    \"\"\"Create an executive assistant agent\"\"\"\n    builder = (cls()\n               .with_name(name)\n               .with_executive_persona()\n               .with_checkpointing(enabled=True))\n\n    if with_integrations:\n        builder.enable_a2a_server()  # Executives need A2A for delegation\n        builder.enable_telemetry()  # Need metrics\n\n    return builder\n</code></pre> <code>create_general_assistant(name='AssistantAgent', full_integration=True)</code> <code>classmethod</code> \u00b6 <p>Create a general-purpose assistant with full integration</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>@classmethod\ndef create_general_assistant(cls, name: str = \"AssistantAgent\",\n                             full_integration: bool = True) -&gt; 'FlowAgentBuilder':\n    \"\"\"Create a general-purpose assistant with full integration\"\"\"\n    builder = (cls()\n               .with_name(name)\n               .with_assistant_persona()\n               .with_checkpointing(enabled=True))\n\n    if full_integration:\n        builder.enable_mcp_server()\n        builder.enable_a2a_server()\n        builder.enable_telemetry()\n\n    return builder\n</code></pre> <code>enable_a2a_server(host='0.0.0.0', port=5000, agent_name=None, agent_description=None)</code> \u00b6 <p>Enable A2A server for agent-to-agent communication</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>def enable_a2a_server(self, host: str = \"0.0.0.0\", port: int = 5000,\n                      agent_name: str = None, agent_description: str = None) -&gt; 'FlowAgentBuilder':\n    \"\"\"Enable A2A server for agent-to-agent communication\"\"\"\n    if not A2A_AVAILABLE:\n        wprint(\"A2A not available, cannot enable server\")\n        return self\n\n    self.config.a2a.enabled = True\n    self.config.a2a.host = host\n    self.config.a2a.port = port\n    self.config.a2a.agent_name = agent_name or self.config.name\n    self.config.a2a.agent_description = agent_description or self.config.description\n\n    iprint(f\"A2A server enabled: {host}:{port}\")\n    return self\n</code></pre> <code>enable_mcp_server(host='0.0.0.0', port=8000, server_name=None)</code> \u00b6 <p>Enable MCP server</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>def enable_mcp_server(self, host: str = \"0.0.0.0\", port: int = 8000,\n                      server_name: str = None) -&gt; 'FlowAgentBuilder':\n    \"\"\"Enable MCP server\"\"\"\n    if not MCP_AVAILABLE:\n        wprint(\"MCP not available, cannot enable server\")\n        return self\n\n    self.config.mcp.enabled = True\n    self.config.mcp.host = host\n    self.config.mcp.port = port\n    self.config.mcp.server_name = server_name or f\"{self.config.name}_MCP\"\n\n    iprint(f\"MCP server enabled: {host}:{port}\")\n    return self\n</code></pre> <code>enable_telemetry(service_name=None, endpoint=None, console_export=True)</code> \u00b6 <p>Enable OpenTelemetry tracing</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>def enable_telemetry(self, service_name: str = None, endpoint: str = None,\n                     console_export: bool = True) -&gt; 'FlowAgentBuilder':\n    \"\"\"Enable OpenTelemetry tracing\"\"\"\n    if not OTEL_AVAILABLE:\n        wprint(\"OpenTelemetry not available, cannot enable telemetry\")\n        return self\n\n    self.config.telemetry.enabled = True\n    self.config.telemetry.service_name = service_name or self.config.name\n    self.config.telemetry.endpoint = endpoint\n    self.config.telemetry.console_export = console_export\n\n    # Initialize tracer provider\n    self._tracer_provider = TracerProvider()\n    trace.set_tracer_provider(self._tracer_provider)\n\n    # Add exporters\n    if console_export:\n        console_exporter = ConsoleSpanExporter()\n        span_processor = BatchSpanProcessor(console_exporter)\n        self._tracer_provider.add_span_processor(span_processor)\n\n    if endpoint:\n        try:\n            otlp_exporter = OTLPSpanExporter(endpoint=endpoint)\n            otlp_processor = BatchSpanProcessor(otlp_exporter)\n            self._tracer_provider.add_span_processor(otlp_processor)\n        except Exception as e:\n            wprint(f\"Failed to setup OTLP exporter: {e}\")\n\n    iprint(f\"Telemetry enabled for service: {service_name}\")\n    return self\n</code></pre> <code>from_config_file(config_path)</code> <code>classmethod</code> \u00b6 <p>Create builder from configuration file</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>@classmethod\ndef from_config_file(cls, config_path: str) -&gt; 'FlowAgentBuilder':\n    \"\"\"Create builder from configuration file\"\"\"\n    return cls(config_path=config_path)\n</code></pre> <code>load_config(config_path)</code> \u00b6 <p>Load agent configuration from file</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>def load_config(self, config_path: str) -&gt; AgentConfig:\n    \"\"\"Load agent configuration from file\"\"\"\n    path = Path(config_path)\n    if not path.exists():\n        raise FileNotFoundError(f\"Config file not found: {config_path}\")\n\n    try:\n        with open(path, encoding='utf-8') as f:\n            if path.suffix.lower() in ['.yaml', '.yml']:\n                data = yaml.safe_load(f)\n            else:\n                data = json.load(f)\n\n        return AgentConfig(**data)\n\n    except Exception as e:\n        eprint(f\"Failed to load config from {config_path}: {e}\")\n        raise\n</code></pre> <code>load_mcp_tools_from_config(config_path)</code> \u00b6 <p>Enhanced MCP config loading with automatic session management and full capability extraction</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>def load_mcp_tools_from_config(self, config_path: str) -&gt; 'FlowAgentBuilder':\n    \"\"\"Enhanced MCP config loading with automatic session management and full capability extraction\"\"\"\n    if not MCP_AVAILABLE:\n        wprint(\"MCP not available, skipping tool loading\")\n        return self\n\n    config_path = Path(config_path)\n    if not config_path.exists():\n        raise FileNotFoundError(f\"MCP config not found: {config_path}\")\n\n    try:\n        with open(config_path, encoding='utf-8') as f:\n            if config_path.suffix.lower() in ['.yaml', '.yml']:\n                mcp_config = yaml.safe_load(f)\n            else:\n                mcp_config = json.load(f)\n\n        # Store config for async processing\n        self._mcp_config_data = mcp_config\n        self.config.mcp.config_path = str(config_path)\n\n        # Mark for processing during build\n        self._mcp_needs_loading = True\n\n        iprint(f\"MCP config loaded from {config_path}, will process during build\")\n\n    except Exception as e:\n        eprint(f\"Failed to load MCP config from {config_path}: {e}\")\n        raise\n\n    return self\n</code></pre> <code>save_config(config_path, format='yaml')</code> \u00b6 <p>Save current configuration to file</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>def save_config(self, config_path: str, format: str = 'yaml'):\n    \"\"\"Save current configuration to file\"\"\"\n    path = Path(config_path)\n    path.parent.mkdir(parents=True, exist_ok=True)\n\n    try:\n        data = self.config.model_dump()\n\n        with open(path, 'w', encoding='utf-8') as f:\n            if format.lower() == 'yaml':\n                yaml.dump(data, f, default_flow_style=False, indent=2)\n            else:\n                json.dump(data, f, indent=2)\n\n        iprint(f\"Configuration saved to {config_path}\")\n\n    except Exception as e:\n        eprint(f\"Failed to save config to {config_path}: {e}\")\n        raise\n</code></pre> <code>set_active_persona(profile_name)</code> \u00b6 <p>Set active persona profile</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>def set_active_persona(self, profile_name: str) -&gt; 'FlowAgentBuilder':\n    \"\"\"Set active persona profile\"\"\"\n    if profile_name in self.config.persona_profiles:\n        self.config.active_persona = profile_name\n        iprint(f\"Active persona set: {profile_name}\")\n    else:\n        wprint(f\"Persona profile not found: {profile_name}\")\n    return self\n</code></pre> <code>validate_config()</code> \u00b6 <p>Validate the current configuration</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>def validate_config(self) -&gt; dict[str, list[str]]:\n    \"\"\"Validate the current configuration\"\"\"\n    issues = {\"errors\": [], \"warnings\": []}\n\n    # Validate required settings\n    if not self.config.fast_llm_model:\n        issues[\"errors\"].append(\"Fast LLM model not specified\")\n    if not self.config.complex_llm_model:\n        issues[\"errors\"].append(\"Complex LLM model not specified\")\n\n    # Validate MCP configuration\n    if self.config.mcp.enabled and not MCP_AVAILABLE:\n        issues[\"errors\"].append(\"MCP enabled but MCP not available\")\n\n    # Validate A2A configuration\n    if self.config.a2a.enabled and not A2A_AVAILABLE:\n        issues[\"errors\"].append(\"A2A enabled but A2A not available\")\n\n    # Validate telemetry\n    if self.config.telemetry.enabled and not OTEL_AVAILABLE:\n        issues[\"errors\"].append(\"Telemetry enabled but OpenTelemetry not available\")\n\n    # Validate personas\n    if self.config.active_persona and self.config.active_persona not in self.config.persona_profiles:\n        issues[\"errors\"].append(f\"Active persona '{self.config.active_persona}' not found in profiles\")\n\n    # Validate checkpoint directory\n    if self.config.checkpoint.enabled:\n        try:\n            Path(self.config.checkpoint.checkpoint_dir).mkdir(parents=True, exist_ok=True)\n        except Exception as e:\n            issues[\"warnings\"].append(f\"Cannot create checkpoint directory: {e}\")\n\n    return issues\n</code></pre> <code>verbose(enable=True)</code> \u00b6 <p>Enable verbose logging</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>def verbose(self, enable: bool = True) -&gt; 'FlowAgentBuilder':\n    \"\"\"Enable verbose logging\"\"\"\n    self.config.verbose_logging = enable\n    if enable:\n        logging.getLogger().setLevel(logging.DEBUG)\n    return self\n</code></pre> <code>with_analyst_persona(name='Data Analyst')</code> \u00b6 <p>Add and set a pre-built analyst persona</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>def with_analyst_persona(self, name: str = \"Data Analyst\") -&gt; 'FlowAgentBuilder':\n    \"\"\"Add and set a pre-built analyst persona\"\"\"\n    return (self\n            .add_persona_profile(\n        \"analyst\",\n        name=name,\n        style=\"analytical\",\n        tone=\"objective\",\n        personality_traits=[\"methodical\", \"insight_driven\", \"evidence_based\"],\n        custom_instructions=\"Focus on statistical rigor and actionable recommendations.\",\n        response_format=\"with-tables\",\n        text_length=\"detailed-indepth\"\n    )\n            .set_active_persona(\"analyst\"))\n</code></pre> <code>with_assistant_persona(name='AI Assistant')</code> \u00b6 <p>Add and set a pre-built general assistant persona</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>def with_assistant_persona(self, name: str = \"AI Assistant\") -&gt; 'FlowAgentBuilder':\n    \"\"\"Add and set a pre-built general assistant persona\"\"\"\n    return (self\n            .add_persona_profile(\n        \"assistant\",\n        name=name,\n        style=\"friendly\",\n        tone=\"helpful\",\n        personality_traits=[\"helpful\", \"patient\", \"clear\", \"adaptive\"],\n        custom_instructions=\"Be helpful and adapt communication to user expertise level.\",\n        response_format=\"with-bullet-points\",\n        text_length=\"chat-conversation\"\n    )\n            .set_active_persona(\"assistant\"))\n</code></pre> <code>with_budget_manager(max_cost=10.0)</code> \u00b6 <p>Enable budget management</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>def with_budget_manager(self, max_cost: float = 10.0) -&gt; 'FlowAgentBuilder':\n    \"\"\"Enable budget management\"\"\"\n    if LITELLM_AVAILABLE:\n        self._budget_manager = BudgetManager(\"agent\")\n        iprint(f\"Budget manager enabled: ${max_cost}\")\n    else:\n        wprint(\"LiteLLM not available, budget manager disabled\")\n    return self\n</code></pre> <code>with_checkpointing(enabled=True, interval_seconds=300, checkpoint_dir='./checkpoints', max_checkpoints=10)</code> \u00b6 <p>Configure checkpointing</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>def with_checkpointing(self, enabled: bool = True, interval_seconds: int = 300,\n                       checkpoint_dir: str = \"./checkpoints\", max_checkpoints: int = 10) -&gt; 'FlowAgentBuilder':\n    \"\"\"Configure checkpointing\"\"\"\n    self.config.checkpoint.enabled = enabled\n    self.config.checkpoint.interval_seconds = interval_seconds\n    self.config.checkpoint.checkpoint_dir = checkpoint_dir\n    self.config.checkpoint.max_checkpoints = max_checkpoints\n\n    if enabled:\n        # Ensure checkpoint directory exists\n        Path(checkpoint_dir).mkdir(parents=True, exist_ok=True)\n        iprint(f\"Checkpointing enabled: {checkpoint_dir} (every {interval_seconds}s)\")\n\n    return self\n</code></pre> <code>with_creative_persona(name='Creative Assistant')</code> \u00b6 <p>Add and set a pre-built creative persona</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>def with_creative_persona(self, name: str = \"Creative Assistant\") -&gt; 'FlowAgentBuilder':\n    \"\"\"Add and set a pre-built creative persona\"\"\"\n    return (self\n            .add_persona_profile(\n        \"creative\",\n        name=name,\n        style=\"creative\",\n        tone=\"inspiring\",\n        personality_traits=[\"imaginative\", \"expressive\", \"innovative\", \"engaging\"],\n        custom_instructions=\"Think outside the box and provide creative, inspiring solutions.\",\n        response_format=\"md-text\",\n        text_length=\"detailed-indepth\"\n    )\n            .set_active_persona(\"creative\"))\n</code></pre> <code>with_custom_variables(variables)</code> \u00b6 <p>Add custom variables</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>def with_custom_variables(self, variables: dict[str, Any]) -&gt; 'FlowAgentBuilder':\n    \"\"\"Add custom variables\"\"\"\n    self.config.custom_variables.update(variables)\n    return self\n</code></pre> <code>with_developer_persona(name='Senior Developer')</code> \u00b6 <p>Add and set a pre-built developer persona</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>def with_developer_persona(self, name: str = \"Senior Developer\") -&gt; 'FlowAgentBuilder':\n    \"\"\"Add and set a pre-built developer persona\"\"\"\n    return (self\n            .add_persona_profile(\n        \"developer\",\n        name=name,\n        style=\"technical\",\n        tone=\"professional\",\n        personality_traits=[\"precise\", \"thorough\", \"security_conscious\", \"best_practices\"],\n        custom_instructions=\"Focus on code quality, maintainability, and security. Always consider edge cases.\",\n        response_format=\"code-structure\",\n        text_length=\"detailed-indepth\"\n    )\n            .set_active_persona(\"developer\"))\n</code></pre> <code>with_executive_persona(name='Executive Assistant')</code> \u00b6 <p>Add and set a pre-built executive persona</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>def with_executive_persona(self, name: str = \"Executive Assistant\") -&gt; 'FlowAgentBuilder':\n    \"\"\"Add and set a pre-built executive persona\"\"\"\n    return (self\n            .add_persona_profile(\n        \"executive\",\n        name=name,\n        style=\"professional\",\n        tone=\"authoritative\",\n        personality_traits=[\"strategic\", \"decisive\", \"results_oriented\", \"efficient\"],\n        custom_instructions=\"Provide strategic insights with executive-level clarity and focus on outcomes.\",\n        response_format=\"with-bullet-points\",\n        text_length=\"table-conversation\"\n    )\n            .set_active_persona(\"executive\"))\n</code></pre> <code>with_models(fast_model, complex_model=None)</code> \u00b6 <p>Set LLM models</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>def with_models(self, fast_model: str, complex_model: str = None) -&gt; 'FlowAgentBuilder':\n    \"\"\"Set LLM models\"\"\"\n    self.config.fast_llm_model = fast_model\n    if complex_model:\n        self.config.complex_llm_model = complex_model\n    return self\n</code></pre> <code>with_name(name)</code> \u00b6 <p>Set agent name</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>def with_name(self, name: str) -&gt; 'FlowAgentBuilder':\n    \"\"\"Set agent name\"\"\"\n    self.config.name = name\n    return self\n</code></pre> <code>with_system_message(message)</code> \u00b6 <p>Set system message</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>def with_system_message(self, message: str) -&gt; 'FlowAgentBuilder':\n    \"\"\"Set system message\"\"\"\n    self.config.system_message = message\n    return self\n</code></pre> <code>with_temperature(temp)</code> \u00b6 <p>Set temperature</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>def with_temperature(self, temp: float) -&gt; 'FlowAgentBuilder':\n    \"\"\"Set temperature\"\"\"\n    self.config.temperature = temp\n    return self\n</code></pre> <code>with_world_model(world_model)</code> \u00b6 <p>Set initial world model</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>def with_world_model(self, world_model: dict[str, Any]) -&gt; 'FlowAgentBuilder':\n    \"\"\"Set initial world model\"\"\"\n    self.config.initial_world_model.update(world_model)\n    return self\n</code></pre> <code>MCPConfig</code> \u00b6 <p>               Bases: <code>BaseModel</code></p> <p>MCP server and tools configuration</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>class MCPConfig(BaseModel):\n    \"\"\"MCP server and tools configuration\"\"\"\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    enabled: bool = False\n    config_path: str = None  # Path to MCP tools config file\n    server_name: str = None\n    host: str = \"0.0.0.0\"\n    port: int = 8000\n    auto_expose_tools: bool = True\n    tools_from_config: list[dict[str, Any]] = Field(default_factory=list)\n</code></pre> <code>TelemetryConfig</code> \u00b6 <p>               Bases: <code>BaseModel</code></p> <p>OpenTelemetry configuration</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>class TelemetryConfig(BaseModel):\n    \"\"\"OpenTelemetry configuration\"\"\"\n    enabled: bool = False\n    service_name: str = None\n    endpoint: str = None  # OTLP endpoint\n    console_export: bool = True\n    batch_export: bool = True\n    sample_rate: float = 1.0\n</code></pre> <code>detect_shell()</code> \u00b6 <p>Detects the best available shell and the argument to execute a command. Returns:     A tuple of (shell_executable, command_argument).     e.g., ('/bin/bash', '-c') or ('powershell.exe', '-Command')</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>def detect_shell() -&gt; tuple[str, str]:\n    \"\"\"\n    Detects the best available shell and the argument to execute a command.\n    Returns:\n        A tuple of (shell_executable, command_argument).\n        e.g., ('/bin/bash', '-c') or ('powershell.exe', '-Command')\n    \"\"\"\n    if platform.system() == \"Windows\":\n        if shell_path := shutil.which(\"pwsh\"):\n            return shell_path, \"-Command\"\n        if shell_path := shutil.which(\"powershell\"):\n            return shell_path, \"-Command\"\n        return \"cmd.exe\", \"/c\"\n\n    shell_env = os.environ.get(\"SHELL\")\n    if shell_env and shutil.which(shell_env):\n        return shell_env, \"-c\"\n\n    for shell in [\"bash\", \"zsh\", \"sh\"]:\n        if shell_path := shutil.which(shell):\n            return shell_path, \"-c\"\n\n    return \"/bin/sh\", \"-c\"\n</code></pre> <code>example_production_usage()</code> <code>async</code> \u00b6 <p>Production usage example with full features</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>async def example_production_usage():\n    \"\"\"Production usage example with full features\"\"\"\n\n    iprint(\"=== Production FlowAgent Builder Example ===\")\n\n    # Example 1: Developer agent with full MCP integration\n    iprint(\"Creating developer agent with MCP integration...\")\n\n    # Add a custom tool\n    def get_system_info():\n        \"\"\"Get basic system information\"\"\"\n        import platform\n        return {\n            \"platform\": platform.platform(),\n            \"python_version\": platform.python_version(),\n            \"architecture\": platform.architecture()\n        }\n\n    developer_agent = await (FlowAgentBuilder\n                             .create_developer_agent(\"ProductionDev\", with_mcp=True, with_a2a=True)\n                             .add_tool(get_system_info, \"get_system_info\", \"Get system information\")\n                             .enable_telemetry(console_export=True)\n                             .with_custom_variables({\n        \"project_name\": \"FlowAgent Production\",\n        \"environment\": \"production\"\n    })\n                             .build())\n\n    # Test the developer agent\n    dev_response = await developer_agent.a_run(\n        \"Hello! I'm working on {{ project_name }}. Can you tell me about the system and create a simple Python function?\"\n    )\n    iprint(f\"Developer agent response: {dev_response[:200]}...\")\n\n    # Example 2: Load from configuration file\n    iprint(\"\\nTesting configuration save/load...\")\n\n    # Save current config\n    config_path = \"/tmp/production_agent_config.yaml\"\n    builder = FlowAgentBuilder.create_analyst_agent(\"ConfigTestAgent\")\n    builder.save_config(config_path)\n\n    # Load from config\n    loaded_builder = FlowAgentBuilder.from_config_file(config_path)\n    config_agent = await loaded_builder.build()\n\n    config_response = await config_agent.a_run(\"Analyze this data: [1, 2, 3, 4, 5]\")\n    iprint(f\"Config-loaded agent response: {config_response[:150]}...\")\n\n    # Example 3: Agent with MCP tools from config\n    iprint(\"\\nTesting MCP tools integration...\")\n\n    # Create a sample MCP config\n    mcp_config = {\n        \"tools\": [\n            {\n                \"name\": \"weather_checker\",\n                \"description\": \"Check weather for a location\",\n                \"function_code\": '''\nasync def weather_checker(location: str) -&gt; str:\n    \"\"\"Mock weather checker\"\"\"\n    import random\n    conditions = [\"sunny\", \"cloudy\", \"rainy\", \"snowy\"]\n    temp = random.randint(-10, 35)\n    condition = random.choice(conditions)\n    return f\"Weather in {location}: {condition}, {temp}\u00b0C\"\n'''\n            }\n        ]\n    }\n\n    mcp_config_path = \"/tmp/mcp_tools_config.json\"\n    with open(mcp_config_path, 'w') as f:\n        json.dump(mcp_config, f, indent=2)\n\n    mcp_agent = await (FlowAgentBuilder()\n                       .with_name(\"MCPTestAgent\")\n                       .with_assistant_persona()\n                       .enable_mcp_server(port=8002)\n                       .load_mcp_tools_from_config(mcp_config_path)\n                       .build())\n\n    mcp_response = await mcp_agent.a_run(\"What's the weather like in Berlin?\")\n    iprint(f\"MCP agent response: {mcp_response[:150]}...\")\n\n    # Show agent status\n    iprint(\"\\n=== Agent Status ===\")\n    status = developer_agent.status(pretty_print=False)\n    iprint(f\"Developer agent tools: {len(status['capabilities']['tool_names'])}\")\n    iprint(f\"MCP agent tools: {len(mcp_agent.shared.get('available_tools', []))}\")\n\n    # Cleanup\n    await developer_agent.close()\n    await config_agent.close()\n    await mcp_agent.close()\n\n    iprint(\"Production example completed successfully!\")\n</code></pre> <code>example_quick_start()</code> <code>async</code> \u00b6 <p>Quick start examples for common scenarios</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/builder.py</code> <pre><code>async def example_quick_start():\n    \"\"\"Quick start examples for common scenarios\"\"\"\n\n    iprint(\"=== Quick Start Examples ===\")\n\n    # 1. Simple developer agent\n    dev_agent = await FlowAgentBuilder.create_developer_agent(\"QuickDev\").build()\n    response1 = await dev_agent.a_run(\"Create a Python function to validate email addresses\")\n    iprint(f\"Quick dev response: {response1[:100]}...\")\n    await dev_agent.close()\n\n    # 2. Analyst with custom data\n    analyst_agent = await (FlowAgentBuilder\n                           .create_analyst_agent(\"QuickAnalyst\")\n                           .with_custom_variables({\"dataset\": \"sales_data_2024\"})\n                           .build())\n    response2 = await analyst_agent.a_run(\"Analyze the trends in {{ dataset }}\")\n    iprint(f\"Quick analyst response: {response2[:100]}...\")\n    await analyst_agent.close()\n\n    # 3. Creative assistant\n    creative_agent = await FlowAgentBuilder.create_creative_agent(\"QuickCreative\").build()\n    response3 = await creative_agent.a_run(\"Write a creative story about AI agents collaborating\")\n    iprint(f\"Quick creative response: {response3[:100]}...\")\n    await creative_agent.close()\n\n    iprint(\"Quick start examples completed!\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.Agent.chain","title":"<code>chain</code>","text":"<code>CF</code> \u00b6 <p>Chain Format - handles formatting and data extraction between tasks.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/chain.py</code> <pre><code>class CF:\n    \"\"\"Chain Format - handles formatting and data extraction between tasks.\"\"\"\n\n    def __init__(self, format_class: type[BaseModel]):\n        self.format_class = format_class\n        self.extract_key: str | tuple | None = None\n        self.is_parallel_extraction = False\n\n    def __sub__(self, key: str | tuple):\n        \"\"\"Implements the - operator for data extraction keys.\"\"\"\n        new_cf = copy.copy(self)\n        if isinstance(key, str):\n            if '[n]' in key:\n                new_cf.extract_key = key.replace('[n]', '')\n                new_cf.is_parallel_extraction = True\n            else:\n                new_cf.extract_key = key\n        elif isinstance(key, tuple):\n            new_cf.extract_key = key\n        return new_cf\n</code></pre> <code>__sub__(key)</code> \u00b6 <p>Implements the - operator for data extraction keys.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/chain.py</code> <pre><code>def __sub__(self, key: str | tuple):\n    \"\"\"Implements the - operator for data extraction keys.\"\"\"\n    new_cf = copy.copy(self)\n    if isinstance(key, str):\n        if '[n]' in key:\n            new_cf.extract_key = key.replace('[n]', '')\n            new_cf.is_parallel_extraction = True\n        else:\n            new_cf.extract_key = key\n    elif isinstance(key, tuple):\n        new_cf.extract_key = key\n    return new_cf\n</code></pre> <code>Chain</code> \u00b6 <p>               Bases: <code>ChainBase</code></p> <p>The main class for creating and executing sequential chains of tasks.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/chain.py</code> <pre><code>class Chain(ChainBase):\n    \"\"\"The main class for creating and executing sequential chains of tasks.\"\"\"\n\n    def __init__(self, agent: 'FlowAgent' = None):\n        self.tasks: list[Any] = [agent] if agent else []\n        self.progress_tracker: ProgressTracker | None = None\n\n    @classmethod\n    def _create_chain(cls, components: list[Any]) -&gt; 'Chain':\n        chain = cls()\n        chain.tasks = components\n        return chain\n\n    def _extract_data(self, data: dict, cf: CF) -&gt; Any:\n        \"\"\"Extracts data from a dictionary based on the CF configuration.\"\"\"\n        if not isinstance(data, dict):\n            return data\n\n        key = cf.extract_key\n        if key == '*':\n            return data\n        if isinstance(key, tuple):\n            return {k: data.get(k) for k in key if k in data}\n        if isinstance(key, str) and key in data:\n            return data[key]\n        return data  # Return original data if key not found\n\n    async def a_run(self, query: Any, **kwargs):\n        \"\"\"\n        Executes the chain of tasks asynchronously with dynamic method selection,\n        data extraction, and auto-parallelization.\n        \"\"\"\n        current_data = query\n\n        # We need to iterate with an index to look ahead\n        i = 0\n        while i &lt; len(self.tasks):\n            task = self.tasks[i]\n\n            # --- Auto-Erkennung und Ausf\u00fchrung ---\n            if hasattr(task, 'a_run') and hasattr(task, 'a_format_class'):\n                next_task = self.tasks[i + 1] if (i + 1) &lt; len(self.tasks) else None\n                task.active_session = kwargs.get(\"session_id\", \"default\")\n                # Dynamische Entscheidung: a_format_class oder a_run aufrufen?\n                if isinstance(next_task, CF):\n                    # N\u00e4chste Aufgabe ist Formatierung, also a_format_class aufrufen\n                    current_data = await task.a_format_class(\n                        next_task.format_class, str(current_data), **kwargs\n                    )\n                else:\n                    # Standardausf\u00fchrung\n                    current_data = await task.a_run(str(current_data), **kwargs)\n                task.active_session = None\n\n            elif isinstance(task, CF):\n                # --- Auto-Extraktion und Parallelisierung ---\n                if task.extract_key:\n                    extracted_data = self._extract_data(current_data, task)\n\n                    if task.is_parallel_extraction and isinstance(extracted_data, list):\n                        next_task_for_parallel = self.tasks[i + 1] if (i + 1) &lt; len(self.tasks) else None\n                        if next_task_for_parallel:\n                            # Erstelle eine tempor\u00e4re Parallel-Kette und f\u00fchre sie aus\n                            parallel_runner = ParallelChain([next_task_for_parallel] * len(extracted_data))\n\n                            # F\u00fchre jeden Task mit dem entsprechenden Datenelement aus\n                            parallel_tasks = [\n                                next_task_for_parallel.a_run(item, **kwargs) for item in extracted_data\n                            ]\n                            current_data = await asyncio.gather(*parallel_tasks)\n\n                            # \u00dcberspringe die n\u00e4chste Aufgabe, da sie bereits parallel ausgef\u00fchrt wurde\n                            i += 1\n                        else:\n                            current_data = extracted_data\n                    else:\n                        current_data = extracted_data\n                else:\n                    # Keine Extraktion, Daten bleiben unver\u00e4ndert (CF dient nur als Marker)\n                    pass\n\n            elif isinstance(task, ParallelChain | ConditionalChain | ErrorHandlingChain):\n                current_data = await task.a_run(current_data, **kwargs)\n\n            elif isinstance(task, IS):\n                # IS needs to be paired with &gt;&gt; to form a ConditionalChain\n                next_task_for_cond = self.tasks[i + 1] if (i + 1) &lt; len(self.tasks) else None\n                if next_task_for_cond:\n                    # Form a conditional chain on the fly\n                    conditional_task = ConditionalChain(task, next_task_for_cond)\n                    # Check for a false branch defined with %\n                    next_next_task = self.tasks[i + 2] if (i + 2) &lt; len(self.tasks) else None\n                    if isinstance(next_next_task, ConditionalChain) and next_next_task.false_branch:\n                        conditional_task.false_branch = next_next_task.false_branch\n                        i += 1  # also skip the false branch marker\n\n                    current_data = await conditional_task.a_run(current_data, **kwargs)\n                    i += 1  # Skip the next task as it's part of the conditional\n                else:\n                    raise ValueError(\"IS condition must be followed by a task to execute.\")\n\n            i += 1  # Gehe zur n\u00e4chsten Aufgabe\n\n        return current_data\n</code></pre> <code>a_run(query, **kwargs)</code> <code>async</code> \u00b6 <p>Executes the chain of tasks asynchronously with dynamic method selection, data extraction, and auto-parallelization.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/chain.py</code> <pre><code>async def a_run(self, query: Any, **kwargs):\n    \"\"\"\n    Executes the chain of tasks asynchronously with dynamic method selection,\n    data extraction, and auto-parallelization.\n    \"\"\"\n    current_data = query\n\n    # We need to iterate with an index to look ahead\n    i = 0\n    while i &lt; len(self.tasks):\n        task = self.tasks[i]\n\n        # --- Auto-Erkennung und Ausf\u00fchrung ---\n        if hasattr(task, 'a_run') and hasattr(task, 'a_format_class'):\n            next_task = self.tasks[i + 1] if (i + 1) &lt; len(self.tasks) else None\n            task.active_session = kwargs.get(\"session_id\", \"default\")\n            # Dynamische Entscheidung: a_format_class oder a_run aufrufen?\n            if isinstance(next_task, CF):\n                # N\u00e4chste Aufgabe ist Formatierung, also a_format_class aufrufen\n                current_data = await task.a_format_class(\n                    next_task.format_class, str(current_data), **kwargs\n                )\n            else:\n                # Standardausf\u00fchrung\n                current_data = await task.a_run(str(current_data), **kwargs)\n            task.active_session = None\n\n        elif isinstance(task, CF):\n            # --- Auto-Extraktion und Parallelisierung ---\n            if task.extract_key:\n                extracted_data = self._extract_data(current_data, task)\n\n                if task.is_parallel_extraction and isinstance(extracted_data, list):\n                    next_task_for_parallel = self.tasks[i + 1] if (i + 1) &lt; len(self.tasks) else None\n                    if next_task_for_parallel:\n                        # Erstelle eine tempor\u00e4re Parallel-Kette und f\u00fchre sie aus\n                        parallel_runner = ParallelChain([next_task_for_parallel] * len(extracted_data))\n\n                        # F\u00fchre jeden Task mit dem entsprechenden Datenelement aus\n                        parallel_tasks = [\n                            next_task_for_parallel.a_run(item, **kwargs) for item in extracted_data\n                        ]\n                        current_data = await asyncio.gather(*parallel_tasks)\n\n                        # \u00dcberspringe die n\u00e4chste Aufgabe, da sie bereits parallel ausgef\u00fchrt wurde\n                        i += 1\n                    else:\n                        current_data = extracted_data\n                else:\n                    current_data = extracted_data\n            else:\n                # Keine Extraktion, Daten bleiben unver\u00e4ndert (CF dient nur als Marker)\n                pass\n\n        elif isinstance(task, ParallelChain | ConditionalChain | ErrorHandlingChain):\n            current_data = await task.a_run(current_data, **kwargs)\n\n        elif isinstance(task, IS):\n            # IS needs to be paired with &gt;&gt; to form a ConditionalChain\n            next_task_for_cond = self.tasks[i + 1] if (i + 1) &lt; len(self.tasks) else None\n            if next_task_for_cond:\n                # Form a conditional chain on the fly\n                conditional_task = ConditionalChain(task, next_task_for_cond)\n                # Check for a false branch defined with %\n                next_next_task = self.tasks[i + 2] if (i + 2) &lt; len(self.tasks) else None\n                if isinstance(next_next_task, ConditionalChain) and next_next_task.false_branch:\n                    conditional_task.false_branch = next_next_task.false_branch\n                    i += 1  # also skip the false branch marker\n\n                current_data = await conditional_task.a_run(current_data, **kwargs)\n                i += 1  # Skip the next task as it's part of the conditional\n            else:\n                raise ValueError(\"IS condition must be followed by a task to execute.\")\n\n        i += 1  # Gehe zur n\u00e4chsten Aufgabe\n\n    return current_data\n</code></pre> <code>ChainBase</code> \u00b6 <p>Abstract base class for all chain types, providing common operators.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/chain.py</code> <pre><code>class ChainBase:\n    \"\"\"Abstract base class for all chain types, providing common operators.\"\"\"\n\n    def __rshift__(self, other: Any) -&gt; 'Chain':\n        \"\"\"Implements the &gt;&gt; operator to chain tasks sequentially.\"\"\"\n        if isinstance(self, Chain):\n            new_tasks = self.tasks + [other]\n            return Chain._create_chain(new_tasks)\n        return Chain._create_chain([self, other])\n\n    def __add__(self, other: Any) -&gt; 'ParallelChain':\n        \"\"\"Implements the + operator for parallel execution.\"\"\"\n        return ParallelChain([self, other])\n\n    def __and__(self, other: Any) -&gt; 'ParallelChain':\n        \"\"\"Implements the &amp; operator, an alias for parallel execution.\"\"\"\n        return ParallelChain([self, other])\n\n    def __or__(self, other: Any) -&gt; 'ErrorHandlingChain':\n        \"\"\"Implements the | operator for defining a fallback/error handling path.\"\"\"\n        return ErrorHandlingChain(self, other)\n\n    def __mod__(self, other: Any) -&gt; 'ConditionalChain':\n        \"\"\"Implements the % operator for defining a false/else branch in a condition.\"\"\"\n        # This is typically used after a conditional chain.\n        if isinstance(self, ConditionalChain):\n            self.false_branch = other\n            return self\n        # Allows creating a conditional chain directly\n        return ConditionalChain(None, self, other)\n\n    def set_progress_callback(self, progress_tracker: 'ProgressTracker'):\n        \"\"\"Recursively sets the progress callback for all tasks in the chain.\"\"\"\n        tasks_to_process = []\n        if hasattr(self, 'tasks'): tasks_to_process.extend(self.tasks)  # Chain\n        if hasattr(self, 'agents'): tasks_to_process.extend(self.agents)  # ParallelChain\n        if hasattr(self, 'true_branch'): tasks_to_process.append(self.true_branch)  # ConditionalChain\n        if hasattr(self, 'false_branch') and self.false_branch: tasks_to_process.append(\n            self.false_branch)  # ConditionalChain\n        if hasattr(self, 'primary'): tasks_to_process.append(self.primary)  # ErrorHandlingChain\n        if hasattr(self, 'fallback'): tasks_to_process.append(self.fallback)  # ErrorHandlingChain\n\n        for task in tasks_to_process:\n            if hasattr(task, 'set_progress_callback'):\n                task.set_progress_callback(progress_tracker)\n\n    def __call__(self, *args, **kwargs):\n        \"\"\"Allows the chain to be called like a function, returning an awaitable runner.\"\"\"\n        return self._Runner(self, args, kwargs)\n\n    class _Runner:\n        def __init__(self, parent, args, kwargs):\n            self.parent = parent\n            self.args = args\n            self.kwargs = kwargs\n\n        def __call__(self):\n            \"\"\"Synchronous execution.\"\"\"\n            return asyncio.run(self.parent.a_run(*self.args, **self.kwargs))\n\n        def __await__(self):\n            \"\"\"Asynchronous execution.\"\"\"\n            return self.parent.a_run(*self.args, **self.kwargs).__await__()\n</code></pre> <code>__add__(other)</code> \u00b6 <p>Implements the + operator for parallel execution.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/chain.py</code> <pre><code>def __add__(self, other: Any) -&gt; 'ParallelChain':\n    \"\"\"Implements the + operator for parallel execution.\"\"\"\n    return ParallelChain([self, other])\n</code></pre> <code>__and__(other)</code> \u00b6 <p>Implements the &amp; operator, an alias for parallel execution.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/chain.py</code> <pre><code>def __and__(self, other: Any) -&gt; 'ParallelChain':\n    \"\"\"Implements the &amp; operator, an alias for parallel execution.\"\"\"\n    return ParallelChain([self, other])\n</code></pre> <code>__call__(*args, **kwargs)</code> \u00b6 <p>Allows the chain to be called like a function, returning an awaitable runner.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/chain.py</code> <pre><code>def __call__(self, *args, **kwargs):\n    \"\"\"Allows the chain to be called like a function, returning an awaitable runner.\"\"\"\n    return self._Runner(self, args, kwargs)\n</code></pre> <code>__mod__(other)</code> \u00b6 <p>Implements the % operator for defining a false/else branch in a condition.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/chain.py</code> <pre><code>def __mod__(self, other: Any) -&gt; 'ConditionalChain':\n    \"\"\"Implements the % operator for defining a false/else branch in a condition.\"\"\"\n    # This is typically used after a conditional chain.\n    if isinstance(self, ConditionalChain):\n        self.false_branch = other\n        return self\n    # Allows creating a conditional chain directly\n    return ConditionalChain(None, self, other)\n</code></pre> <code>__or__(other)</code> \u00b6 <p>Implements the | operator for defining a fallback/error handling path.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/chain.py</code> <pre><code>def __or__(self, other: Any) -&gt; 'ErrorHandlingChain':\n    \"\"\"Implements the | operator for defining a fallback/error handling path.\"\"\"\n    return ErrorHandlingChain(self, other)\n</code></pre> <code>__rshift__(other)</code> \u00b6 <p>Implements the &gt;&gt; operator to chain tasks sequentially.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/chain.py</code> <pre><code>def __rshift__(self, other: Any) -&gt; 'Chain':\n    \"\"\"Implements the &gt;&gt; operator to chain tasks sequentially.\"\"\"\n    if isinstance(self, Chain):\n        new_tasks = self.tasks + [other]\n        return Chain._create_chain(new_tasks)\n    return Chain._create_chain([self, other])\n</code></pre> <code>set_progress_callback(progress_tracker)</code> \u00b6 <p>Recursively sets the progress callback for all tasks in the chain.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/chain.py</code> <pre><code>def set_progress_callback(self, progress_tracker: 'ProgressTracker'):\n    \"\"\"Recursively sets the progress callback for all tasks in the chain.\"\"\"\n    tasks_to_process = []\n    if hasattr(self, 'tasks'): tasks_to_process.extend(self.tasks)  # Chain\n    if hasattr(self, 'agents'): tasks_to_process.extend(self.agents)  # ParallelChain\n    if hasattr(self, 'true_branch'): tasks_to_process.append(self.true_branch)  # ConditionalChain\n    if hasattr(self, 'false_branch') and self.false_branch: tasks_to_process.append(\n        self.false_branch)  # ConditionalChain\n    if hasattr(self, 'primary'): tasks_to_process.append(self.primary)  # ErrorHandlingChain\n    if hasattr(self, 'fallback'): tasks_to_process.append(self.fallback)  # ErrorHandlingChain\n\n    for task in tasks_to_process:\n        if hasattr(task, 'set_progress_callback'):\n            task.set_progress_callback(progress_tracker)\n</code></pre> <code>ConditionalChain</code> \u00b6 <p>               Bases: <code>ChainBase</code></p> <p>Handles conditional execution based on a condition.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/chain.py</code> <pre><code>class ConditionalChain(ChainBase):\n    \"\"\"Handles conditional execution based on a condition.\"\"\"\n\n    def __init__(self, condition: IS, true_branch: Any, false_branch: Any = None):\n        self.condition = condition\n        self.true_branch = true_branch\n        self.false_branch = false_branch\n\n    async def a_run(self, data: Any, **kwargs):\n        \"\"\"Executes the true or false branch based on the condition.\"\"\"\n        condition_met = False\n        if isinstance(self.condition, IS) and isinstance(data, dict):\n            if data.get(self.condition.key) == self.condition.expected_value:\n                condition_met = True\n\n        if condition_met:\n            return await self.true_branch.a_run(data, **kwargs)\n        elif self.false_branch:\n            return await self.false_branch.a_run(data, **kwargs)\n        return data  # Return original data if condition not met and no false branch\n</code></pre> <code>a_run(data, **kwargs)</code> <code>async</code> \u00b6 <p>Executes the true or false branch based on the condition.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/chain.py</code> <pre><code>async def a_run(self, data: Any, **kwargs):\n    \"\"\"Executes the true or false branch based on the condition.\"\"\"\n    condition_met = False\n    if isinstance(self.condition, IS) and isinstance(data, dict):\n        if data.get(self.condition.key) == self.condition.expected_value:\n            condition_met = True\n\n    if condition_met:\n        return await self.true_branch.a_run(data, **kwargs)\n    elif self.false_branch:\n        return await self.false_branch.a_run(data, **kwargs)\n    return data  # Return original data if condition not met and no false branch\n</code></pre> <code>ErrorHandlingChain</code> \u00b6 <p>               Bases: <code>ChainBase</code></p> <p>Handles exceptions in a primary chain by executing a fallback chain.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/chain.py</code> <pre><code>class ErrorHandlingChain(ChainBase):\n    \"\"\"Handles exceptions in a primary chain by executing a fallback chain.\"\"\"\n\n    def __init__(self, primary: Any, fallback: Any):\n        self.primary = primary\n        self.fallback = fallback\n\n    async def a_run(self, query: Any, **kwargs):\n        \"\"\"Tries the primary chain and executes the fallback on failure.\"\"\"\n        try:\n            return await self.primary.a_run(query, **kwargs)\n        except Exception as e:\n            print(f\"Primary chain failed with error: {e}. Running fallback.\")\n            return await self.fallback.a_run(query, **kwargs)\n</code></pre> <code>a_run(query, **kwargs)</code> <code>async</code> \u00b6 <p>Tries the primary chain and executes the fallback on failure.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/chain.py</code> <pre><code>async def a_run(self, query: Any, **kwargs):\n    \"\"\"Tries the primary chain and executes the fallback on failure.\"\"\"\n    try:\n        return await self.primary.a_run(query, **kwargs)\n    except Exception as e:\n        print(f\"Primary chain failed with error: {e}. Running fallback.\")\n        return await self.fallback.a_run(query, **kwargs)\n</code></pre> <code>IS</code> \u00b6 <p>Conditional check for branching logic.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/chain.py</code> <pre><code>class IS:\n    \"\"\"Conditional check for branching logic.\"\"\"\n\n    def __init__(self, key: str, expected_value: Any):\n        self.key = key\n        self.expected_value = expected_value\n</code></pre> <code>ParallelChain</code> \u00b6 <p>               Bases: <code>ChainBase</code></p> <p>Handles parallel execution of multiple agents or chains.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/chain.py</code> <pre><code>class ParallelChain(ChainBase):\n    \"\"\"Handles parallel execution of multiple agents or chains.\"\"\"\n\n    def __init__(self, agents: list[Union['FlowAgent', ChainBase]]):\n        self.agents = agents\n\n    async def a_run(self, query: Any, **kwargs):\n        \"\"\"Runs all agents/chains in parallel.\"\"\"\n        tasks = [agent.a_run(query, **kwargs) for agent in self.agents]\n        results = await asyncio.gather(*tasks)\n        return self._combine_results(results)\n\n    def _combine_results(self, results: list[Any]) -&gt; Any:\n        \"\"\"Intelligently combines parallel results.\"\"\"\n        if all(isinstance(r, str) for r in results):\n            return \" | \".join(results)\n        return results\n</code></pre> <code>a_run(query, **kwargs)</code> <code>async</code> \u00b6 <p>Runs all agents/chains in parallel.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/chain.py</code> <pre><code>async def a_run(self, query: Any, **kwargs):\n    \"\"\"Runs all agents/chains in parallel.\"\"\"\n    tasks = [agent.a_run(query, **kwargs) for agent in self.agents]\n    results = await asyncio.gather(*tasks)\n    return self._combine_results(results)\n</code></pre> <code>chain_to_graph(self)</code> \u00b6 <p>Convert chain to hierarchical structure with complete component detection.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/chain.py</code> <pre><code>def chain_to_graph(self) -&gt; dict[str, Any]:\n    \"\"\"Convert chain to hierarchical structure with complete component detection.\"\"\"\n\n    def process_component(comp, depth=0, visited=None):\n        if visited is None:\n            visited = set()\n\n        # Prevent infinite recursion\n        comp_id = id(comp)\n        if comp_id in visited or depth &gt; 20:\n            return {\"type\": \"Circular\", \"display\": \"[CIRCULAR_REF]\", \"depth\": depth}\n        visited.add(comp_id)\n\n        if comp is None:\n            return {\"type\": \"Error\", \"display\": \"[NULL]\", \"depth\": depth}\n\n        try:\n            # Agent detection\n            if hasattr(comp, 'amd') and comp.amd:\n                return {\n                    \"type\": \"Agent\",\n                    \"display\": f\"[Agent] {comp.amd.name}\",\n                    \"name\": comp.amd.name,\n                    \"depth\": depth\n                }\n\n            # Format detection (CF) with parallel detection\n            if hasattr(comp, 'format_class'):\n                name = comp.format_class.__name__\n                display = f\"[Format] {name}\"\n\n                result = {\n                    \"type\": \"Format\",\n                    \"display\": display,\n                    \"format_class\": name,\n                    \"extract_key\": getattr(comp, 'extract_key', None),\n                    \"depth\": depth,\n                    \"creates_parallel\": False\n                }\n\n                # Extract key visualization\n                if hasattr(comp, 'extract_key') and comp.extract_key:\n                    key = comp.extract_key\n                    if key == '*':\n                        display += \" \\033[90m(*all*)\\033[0m\"\n                    elif isinstance(key, str):\n                        display += f\" \\033[90m(\u2192{key})\\033[0m\"\n                    elif isinstance(key, tuple):\n                        display += f\" \\033[90m(\u2192{','.join(key)})\\033[0m\"\n\n                # Parallel detection\n                if hasattr(comp, 'parallel_count') and comp.parallel_count == 'n':\n                    display += \" \\033[95m[PARALLEL]\\033[0m\"\n                    result[\"creates_parallel\"] = True\n                    result[\"parallel_type\"] = \"auto_n\"\n\n                result[\"display\"] = display\n                return result\n\n            # Condition detection (IS)\n            if hasattr(comp, 'key') and hasattr(comp, 'expected_value'):\n                return {\n                    \"type\": \"Condition\",\n                    \"display\": f\"[Condition] IS {comp.key}=='{comp.expected_value}'\",\n                    \"condition_key\": comp.key,\n                    \"expected_value\": comp.expected_value,\n                    \"depth\": depth\n                }\n\n            # Parallel chain detection\n            if hasattr(comp, 'agents') and isinstance(comp.agents, list | tuple):\n                branches = []\n                for i, agent in enumerate(comp.agents):\n                    if agent:\n                        branch_data = process_component(agent, depth + 1, visited.copy())\n                        branch_data[\"branch_id\"] = i\n                        branches.append(branch_data)\n\n                return {\n                    \"type\": \"Parallel\",\n                    \"display\": f\"[Parallel] {len(branches)} branches\",\n                    \"branches\": branches,\n                    \"branch_count\": len(branches),\n                    \"execution_type\": \"concurrent\",\n                    \"depth\": depth\n                }\n\n            # Conditional chain detection\n            if hasattr(comp, 'condition') and hasattr(comp, 'true_branch'):\n                condition_data = process_component(comp.condition, depth + 1,\n                                                   visited.copy()) if comp.condition else None\n                true_data = process_component(comp.true_branch, depth + 1, visited.copy()) if comp.true_branch else None\n                false_data = None\n\n                if hasattr(comp, 'false_branch') and comp.false_branch:\n                    false_data = process_component(comp.false_branch, depth + 1, visited.copy())\n\n                return {\n                    \"type\": \"Conditional\",\n                    \"display\": \"[Conditional] Branch Logic\",\n                    \"condition\": condition_data,\n                    \"true_branch\": true_data,\n                    \"false_branch\": false_data,\n                    \"has_false_branch\": false_data is not None,\n                    \"depth\": depth\n                }\n\n            # Error handling detection\n            if hasattr(comp, 'primary') and hasattr(comp, 'fallback'):\n                primary_data = process_component(comp.primary, depth + 1, visited.copy()) if comp.primary else None\n                fallback_data = process_component(comp.fallback, depth + 1, visited.copy()) if comp.fallback else None\n\n                return {\n                    \"type\": \"ErrorHandling\",\n                    \"display\": \"[Try-Catch] Error Handler\",\n                    \"primary\": primary_data,\n                    \"fallback\": fallback_data,\n                    \"has_fallback\": fallback_data is not None,\n                    \"depth\": depth\n                }\n\n            # Regular chain detection\n            if hasattr(comp, 'tasks') and isinstance(comp.tasks, list | tuple):\n                tasks = []\n                for i, task in enumerate(comp.tasks):\n                    if task is not None:\n                        task_data = process_component(task, depth + 1, visited.copy())\n                        task_data[\"task_id\"] = i\n                        tasks.append(task_data)\n\n                # Analyze chain characteristics\n                has_conditionals = any(t.get(\"type\") == \"Conditional\" for t in tasks)\n                has_parallels = any(t.get(\"type\") == \"Parallel\" for t in tasks)\n                has_error_handling = any(t.get(\"type\") == \"ErrorHandling\" for t in tasks)\n                has_auto_parallel = any(t.get(\"creates_parallel\", False) for t in tasks)\n\n                chain_type = \"Sequential\"\n                if has_auto_parallel:\n                    chain_type = \"Auto-Parallel\"\n                elif has_conditionals and has_parallels:\n                    chain_type = \"Complex\"\n                elif has_conditionals:\n                    chain_type = \"Conditional\"\n                elif has_parallels:\n                    chain_type = \"Mixed-Parallel\"\n                elif has_error_handling:\n                    chain_type = \"Error-Handling\"\n\n                return {\n                    \"type\": \"Chain\",\n                    \"display\": f\"[Chain] {chain_type}\",\n                    \"tasks\": tasks,\n                    \"task_count\": len(tasks),\n                    \"chain_type\": chain_type,\n                    \"has_conditionals\": has_conditionals,\n                    \"has_parallels\": has_parallels,\n                    \"has_error_handling\": has_error_handling,\n                    \"has_auto_parallel\": has_auto_parallel,\n                    \"depth\": depth\n                }\n\n            # Fallback for unknown types\n            return {\n                \"type\": \"Unknown\",\n                \"display\": f\"[Unknown] {type(comp).__name__}\",\n                \"class_name\": type(comp).__name__,\n                \"depth\": depth\n            }\n\n        except Exception as e:\n            return {\n                \"type\": \"Error\",\n                \"display\": f\"[ERROR] {str(e)[:50]}\",\n                \"error\": str(e),\n                \"depth\": depth\n            }\n        finally:\n            visited.discard(comp_id)\n\n    return {\"structure\": process_component(self)}\n</code></pre> <code>print_graph(self)</code> \u00b6 <p>Enhanced chain visualization with complete functionality coverage and parallel detection.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/chain.py</code> <pre><code>def print_graph(self):\n    \"\"\"Enhanced chain visualization with complete functionality coverage and parallel detection.\"\"\"\n\n    # Enhanced color scheme with parallel indicators\n    COLORS = {\n        \"Agent\": \"\\033[94m\",  # Blue\n        \"Format\": \"\\033[92m\",  # Green\n        \"Condition\": \"\\033[93m\",  # Yellow\n        \"Parallel\": \"\\033[95m\",  # Magenta\n        \"Conditional\": \"\\033[96m\",  # Cyan\n        \"ErrorHandling\": \"\\033[91m\",  # Red\n        \"Chain\": \"\\033[97m\",  # White\n        \"Unknown\": \"\\033[31m\",  # Dark Red\n        \"Error\": \"\\033[91m\",  # Red\n        \"AutoParallel\": \"\\033[105m\",  # Bright Magenta Background\n    }\n    RESET = \"\\033[0m\"\n    BOLD = \"\\033[1m\"\n    DIM = \"\\033[2m\"\n    PARALLEL_ICON = \"\u26a1\"\n    BRANCH_ICON = \"\ud83d\udd00\"\n    ERROR_ICON = \"\ud83d\udea8\"\n\n    def style_component(comp, override_color=None):\n        \"\"\"Apply enhanced styling with parallel indicators.\"\"\"\n        if not comp:\n            return f\"{COLORS['Error']}[NULL]{RESET}\"\n\n        comp_type = comp.get(\"type\", \"Unknown\")\n        display = comp.get(\"display\", f\"[{comp_type}]\")\n\n        # Special handling for parallel-creating formats\n        if comp_type == \"Format\" and comp.get(\"creates_parallel\", False):\n            color = override_color or COLORS[\"AutoParallel\"]\n            return f\"{color}{PARALLEL_ICON} {display}{RESET}\"\n        else:\n            color = override_color or COLORS.get(comp_type, COLORS['Unknown'])\n            return f\"{color}{display}{RESET}\"\n\n    def print_section_header(title, details=None):\n        \"\"\"Print formatted section header.\"\"\"\n        print(f\"\\n{BOLD}{'=' * 60}{RESET}\")\n        print(f\"{BOLD}\ud83d\udd17 {title}{RESET}\")\n        if details:\n            print(f\"{DIM}{details}{RESET}\")\n        print(f\"{BOLD}{'=' * 60}{RESET}\")\n\n    def render_task_flow(tasks, indent=\"\", show_parallel_creation=True):\n        \"\"\"Render tasks with parallel creation detection.\"\"\"\n        if not tasks:\n            print(f\"{indent}{DIM}(No tasks){RESET}\")\n            return\n\n        for i, task in enumerate(tasks):\n            if not task:\n                continue\n\n            is_last = i == len(tasks) - 1\n            connector = \"\u2514\u2500 \" if is_last else \"\u251c\u2500 \"\n            next_indent = indent + (\"    \" if is_last else \"\u2502   \")\n\n            task_type = task.get(\"type\", \"Unknown\")\n\n            # Handle different task types\n            if task_type == \"Format\" and task.get(\"creates_parallel\", False):\n                print(f\"{indent}{connector}{style_component(task)}\")\n\n                # Show what happens next\n                if i + 1 &lt; len(tasks):\n                    next_task = tasks[i + 1]\n                    print(f\"{next_indent}\u251c\u2500 {DIM}Creates parallel execution for:{RESET}\")\n                    print(f\"{next_indent}\u2514\u2500 {PARALLEL_ICON} {style_component(next_task)}\")\n                    # Skip the next task in main loop since we showed it here\n                    continue\n\n            elif task_type == \"Parallel\":\n                print(f\"{indent}{connector}{style_component(task)}\")\n                branches = task.get(\"branches\", [])\n\n                for j, branch in enumerate(branches):\n                    if branch:\n                        branch_last = j == len(branches) - 1\n                        branch_conn = \"\u2514\u2500 \" if branch_last else \"\u251c\u2500 \"\n                        branch_indent = next_indent + (\"    \" if branch_last else \"\u2502   \")\n\n                        print(f\"{next_indent}{branch_conn}{BRANCH_ICON} Branch {j + 1}:\")\n\n                        if branch.get(\"type\") == \"Chain\":\n                            render_task_flow(branch.get(\"tasks\", []), branch_indent, False)\n                        else:\n                            print(f\"{branch_indent}\u2514\u2500 {style_component(branch)}\")\n\n            elif task_type == \"Conditional\":\n                print(f\"{indent}{connector}{style_component(task)}\")\n\n                # Condition\n                condition = task.get(\"condition\")\n                if condition:\n                    print(f\"{next_indent}\u251c\u2500 {style_component(condition)}\")\n\n                # True branch\n                true_branch = task.get(\"true_branch\")\n                false_branch = task.get(\"false_branch\")\n                has_false = false_branch is not None\n\n                if true_branch:\n                    true_conn = \"\u251c\u2500 \" if has_false else \"\u2514\u2500 \"\n                    print(f\"{next_indent}{true_conn}{COLORS['Conditional']}\u2713 TRUE:{RESET}\")\n                    true_indent = next_indent + (\"\u2502   \" if has_false else \"    \")\n\n                    if true_branch.get(\"type\") == \"Chain\":\n                        render_task_flow(true_branch.get(\"tasks\", []), true_indent, False)\n                    else:\n                        print(f\"{true_indent}\u2514\u2500 {style_component(true_branch)}\")\n\n                if false_branch:\n                    print(f\"{next_indent}\u2514\u2500 {COLORS['Conditional']}\u2717 FALSE:{RESET}\")\n                    false_indent = next_indent + \"    \"\n\n                    if false_branch.get(\"type\") == \"Chain\":\n                        render_task_flow(false_branch.get(\"tasks\", []), false_indent, False)\n                    else:\n                        print(f\"{false_indent}\u2514\u2500 {style_component(false_branch)}\")\n\n            elif task_type == \"ErrorHandling\":\n                print(f\"{indent}{connector}{style_component(task)}\")\n\n                primary = task.get(\"primary\")\n                fallback = task.get(\"fallback\")\n                has_fallback = fallback is not None\n\n                if primary:\n                    prim_conn = \"\u251c\u2500 \" if has_fallback else \"\u2514\u2500 \"\n                    print(f\"{next_indent}{prim_conn}{COLORS['Chain']}\ud83c\udfaf PRIMARY:{RESET}\")\n                    prim_indent = next_indent + (\"\u2502   \" if has_fallback else \"    \")\n\n                    if primary.get(\"type\") == \"Chain\":\n                        render_task_flow(primary.get(\"tasks\", []), prim_indent, False)\n                    else:\n                        print(f\"{prim_indent}\u2514\u2500 {style_component(primary)}\")\n\n                if fallback:\n                    print(f\"{next_indent}\u2514\u2500 {ERROR_ICON} FALLBACK:\")\n                    fallback_indent = next_indent + \"    \"\n\n                    if fallback.get(\"type\") == \"Chain\":\n                        render_task_flow(fallback.get(\"tasks\", []), fallback_indent, False)\n                    else:\n                        print(f\"{fallback_indent}\u2514\u2500 {style_component(fallback)}\")\n\n            else:\n                print(f\"{indent}{connector}{style_component(task)}\")\n\n    # Main execution\n    try:\n        # Generate graph structure\n        graph_data = self.chain_to_graph()\n        structure = graph_data.get(\"structure\")\n\n        if not structure:\n            print_section_header(\"Empty Chain\")\n            return\n\n        # Determine chain characteristics\n        chain_type = structure.get(\"chain_type\", \"Unknown\")\n        has_auto_parallel = structure.get(\"has_auto_parallel\", False)\n        has_parallels = structure.get(\"has_parallels\", False)\n        has_conditionals = structure.get(\"has_conditionals\", False)\n        has_error_handling = structure.get(\"has_error_handling\", False)\n        task_count = structure.get(\"task_count\", 0)\n\n        # Build header info\n        info_parts = [f\"Tasks: {task_count}\"]\n        if has_auto_parallel:\n            info_parts.append(f\"{PARALLEL_ICON} Auto-Parallel\")\n        if has_parallels:\n            info_parts.append(f\"{BRANCH_ICON} Parallel Branches\")\n        if has_conditionals:\n            info_parts.append(\"\ud83d\udd00 Conditionals\")\n        if has_error_handling:\n            info_parts.append(f\"{ERROR_ICON} Error Handling\")\n\n        print_section_header(f\"Chain Visualization - {chain_type}\", \" | \".join(info_parts))\n\n        # Handle different structure types\n        struct_type = structure.get(\"type\", \"Unknown\")\n\n        if struct_type == \"Chain\":\n            tasks = structure.get(\"tasks\", [])\n            render_task_flow(tasks)\n\n        elif struct_type == \"Parallel\":\n            print(f\"{style_component(structure)}\")\n            branches = structure.get(\"branches\", [])\n            for i, branch in enumerate(branches):\n                is_last = i == len(branches) - 1\n                conn = \"\u2514\u2500 \" if is_last else \"\u251c\u2500 \"\n                indent = \"    \" if is_last else \"\u2502   \"\n\n                print(f\"{conn}{BRANCH_ICON} Branch {i + 1}:\")\n                if branch.get(\"type\") == \"Chain\":\n                    render_task_flow(branch.get(\"tasks\", []), indent, False)\n                else:\n                    print(f\"{indent}\u2514\u2500 {style_component(branch)}\")\n\n        elif struct_type == \"Conditional\" or struct_type == \"ErrorHandling\":\n            render_task_flow([structure])\n\n        else:\n            print(f\"\u2514\u2500 {style_component(structure)}\")\n\n        print(f\"\\n{DIM}{'\u2500' * 60}{RESET}\")\n\n    except Exception as e:\n        print(f\"\\n{COLORS['Error']}{BOLD}[VISUALIZATION ERROR]{RESET}\")\n        print(f\"{COLORS['Error']}Error: {str(e)}{RESET}\")\n\n        # Emergency fallback\n        print(f\"\\n{DIM}--- Emergency Info ---{RESET}\")\n        try:\n            attrs = []\n            for attr in ['tasks', 'agents', 'condition', 'true_branch', 'false_branch', 'primary', 'fallback']:\n                if hasattr(self, attr):\n                    val = getattr(self, attr)\n                    if val is not None:\n                        if isinstance(val, list | tuple):\n                            attrs.append(f\"{attr}: {len(val)} items\")\n                        else:\n                            attrs.append(f\"{attr}: {type(val).__name__}\")\n\n            if attrs:\n                print(\"Chain attributes:\")\n                for attr in attrs:\n                    print(f\"  \u2022 {attr}\")\n        except:\n            print(\"Complete inspection failed\")\n\n        print(f\"{DIM}--- End Emergency Info ---{RESET}\\n\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.Agent.config","title":"<code>config</code>","text":"<code>A2AConfig</code> \u00b6 <p>               Bases: <code>BaseModel</code></p> <p>Configuration for A2A integration.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/config.py</code> <pre><code>class A2AConfig(BaseModel):\n    \"\"\"Configuration for A2A integration.\"\"\"\n    server: dict[str, Any] | None = Field(default=None, description=\"Configuration to run an A2A server (host, port, etc.).\")\n    known_agents: dict[str, str] = Field(default_factory=dict, description=\"Named A2A agent URLs to interact with (e.g., {'weather_agent': 'http://weather:5000'}).\")\n    default_task_timeout: int = Field(default=120, description=\"Default timeout in seconds for waiting on A2A task results.\")\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n</code></pre> <code>ADKConfig</code> \u00b6 <p>               Bases: <code>BaseModel</code></p> <p>Configuration for ADK integration.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/config.py</code> <pre><code>class ADKConfig(BaseModel):\n    \"\"\"Configuration for ADK integration.\"\"\"\n    enabled: bool = Field(default=True, description=\"Enable ADK features if ADK is installed.\")\n    description: str | None = Field(default=None, description=\"ADK LlmAgent description.\")\n    instruction_override: str | None = Field(default=None, description=\"Override agent's system message for ADK.\")\n    # Tools added via builder or auto-discovery\n    code_executor: str | BaseCodeExecutor | None = Field(default=None, description=\"Reference name or instance of ADK code executor.\")\n    planner: str | BasePlanner | None = Field(default=None, description=\"Reference name or instance of ADK planner.\")\n    examples: list[Example] | None = Field(default=None, description=\"Few-shot examples for ADK.\")\n    output_schema: type[BaseModel] | None = Field(default=None, description=\"Pydantic model for structured output.\")\n    # MCP Toolset config handled separately if ADK is enabled\n    use_mcp_toolset: bool = Field(default=True, description=\"Use ADK's MCPToolset for MCP client connections if ADK is enabled.\")\n    # Runner config handled separately\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n</code></pre> <code>AgentConfig</code> \u00b6 <p>               Bases: <code>BaseModel</code></p> <p>Main configuration schema for an EnhancedAgent.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/config.py</code> <pre><code>class AgentConfig(BaseModel):\n    \"\"\"Main configuration schema for an EnhancedAgent.\"\"\"\n    agent_name: str = Field(..., description=\"Unique name for this agent instance.\")\n    version: str = Field(default=\"0.1.0\")\n\n    agent_instruction: str = Field(default=\"You are a helpful AI assistant. Answer user questions to the best of your knowledge. Respond concisely. use tools when needed\")\n    agent_description: str = Field(default=\"An configurable, production-ready agent with integrated capabilities.\")\n\n    # Model Selection\n    models: list[ModelConfig] = Field(..., description=\"List of available LLM configurations.\")\n    default_llm_model: str = Field(..., description=\"Name of the ModelConfig to use for general LLM calls.\")\n    formatter_llm_model: str | None = Field(default=None, description=\"Optional: Name of a faster/cheaper ModelConfig for a_format_class calls.\")\n\n    # Core Agent Settings\n    world_model_initial_data: dict[str, Any] | None = Field(default=None)\n    enable_streaming: bool = Field(default=False)\n    verbose: bool = Field(default=False)\n    log_level: str = Field(default=\"INFO\", description=\"Logging level (DEBUG, INFO, WARNING, ERROR).\")\n    max_history_length: int = Field(default=20, description=\"Max conversation turns for LiteLLM history.\")\n    trim_strategy: Literal[\"litellm\", \"basic\"] = Field(default=\"litellm\")\n    persist_history: bool = Field(default=True, description=\"Persist conversation history (requires persistent ChatSession).\")\n    user_id_default: str | None = Field(default=None, description=\"Default user ID for interactions.\")\n\n    # Secure Code Execution\n    code_executor_type: Literal[\"restricted\", \"docker\", \"none\"] = Field(default=\"restricted\", description=\"Type of code executor to use.\")\n    code_executor_config: dict[str, Any] = Field(default_factory=dict, description=\"Configuration specific to the chosen code executor.\")\n    enable_adk_code_execution_tool: bool = Field(default=True, description=\"Expose code execution as an ADK tool if ADK is enabled.\")\n\n    # Framework Integrations\n    adk: ADKConfig | None = Field(default_factory=ADKConfig if ADK_AVAILABLE_CONF else lambda: None)\n    mcp: MCPConfig | None = Field(default_factory=MCPConfig if MCP_AVAILABLE_CONF else lambda: None)\n    a2a: A2AConfig | None = Field(default_factory=A2AConfig if A2A_AVAILABLE_CONF else lambda: None)\n\n    # Observability &amp; Cost\n    observability: ObservabilityConfig | None = Field(default_factory=ObservabilityConfig)\n    budget_manager: BudgetManager | None = Field(default=None, description=\"Global LiteLLM budget manager instance.\") # Needs to be passed in\n\n    # Human-in-the-Loop\n    enable_hitl: bool = Field(default=False, description=\"Enable basic Human-in-the-Loop hooks.\")\n\n    # Add other global settings as needed\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    @model_validator(mode='after')\n    def validate_model_references(self) -&gt; 'AgentConfig':\n        model_names = {m.name for m in self.models}\n        if self.default_llm_model not in model_names:\n            raise ValueError(f\"default_llm_model '{self.default_llm_model}' not found in defined models.\")\n        if self.formatter_llm_model and self.formatter_llm_model not in model_names:\n            raise ValueError(f\"formatter_llm_model '{self.formatter_llm_model}' not found in defined models.\")\n        return self\n\n    @model_validator(mode='after')\n    def validate_framework_availability(self) -&gt; 'AgentConfig':\n        if self.adk and self.adk.enabled and not ADK_AVAILABLE_CONF:\n            logger.warning(\"ADK configuration provided but ADK library not installed. Disabling ADK features.\")\n            self.adk.enabled = False\n        if self.mcp and (self.mcp.server or self.mcp.client_connections) and not MCP_AVAILABLE_CONF:\n             logger.warning(\"MCP configuration provided but MCP library not installed. Disabling MCP features.\")\n             self.mcp = None # Or disable specific parts\n        if self.a2a and (self.a2a.server or self.a2a.known_agents) and not A2A_AVAILABLE_CONF:\n             logger.warning(\"A2A configuration provided but A2A library not installed. Disabling A2A features.\")\n             self.a2a = None # Or disable specific parts\n        return self\n\n    @classmethod\n    def load_from_yaml(cls, path: str | Path) -&gt; 'AgentConfig':\n        \"\"\"Loads configuration from a YAML file.\"\"\"\n        file_path = Path(path)\n        if not file_path.is_file():\n            raise FileNotFoundError(f\"Configuration file not found: {path}\")\n        with open(file_path) as f:\n            config_data = yaml.safe_load(f)\n        logger.info(f\"Loaded agent configuration from {path}\")\n        return cls(**config_data)\n\n    def save_to_yaml(self, path: str | Path):\n        \"\"\"Saves the current configuration to a YAML file.\"\"\"\n        file_path = Path(path)\n        file_path.parent.mkdir(parents=True, exist_ok=True)\n        with open(file_path, 'w') as f:\n            # Use Pydantic's model_dump for clean serialization\n            yaml.dump(self.model_dump(mode='python'), f, sort_keys=False)\n        logger.info(f\"Saved agent configuration to {path}\")\n</code></pre> <code>load_from_yaml(path)</code> <code>classmethod</code> \u00b6 <p>Loads configuration from a YAML file.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/config.py</code> <pre><code>@classmethod\ndef load_from_yaml(cls, path: str | Path) -&gt; 'AgentConfig':\n    \"\"\"Loads configuration from a YAML file.\"\"\"\n    file_path = Path(path)\n    if not file_path.is_file():\n        raise FileNotFoundError(f\"Configuration file not found: {path}\")\n    with open(file_path) as f:\n        config_data = yaml.safe_load(f)\n    logger.info(f\"Loaded agent configuration from {path}\")\n    return cls(**config_data)\n</code></pre> <code>save_to_yaml(path)</code> \u00b6 <p>Saves the current configuration to a YAML file.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/config.py</code> <pre><code>def save_to_yaml(self, path: str | Path):\n    \"\"\"Saves the current configuration to a YAML file.\"\"\"\n    file_path = Path(path)\n    file_path.parent.mkdir(parents=True, exist_ok=True)\n    with open(file_path, 'w') as f:\n        # Use Pydantic's model_dump for clean serialization\n        yaml.dump(self.model_dump(mode='python'), f, sort_keys=False)\n    logger.info(f\"Saved agent configuration to {path}\")\n</code></pre> <code>MCPConfig</code> \u00b6 <p>               Bases: <code>BaseModel</code></p> <p>Configuration for MCP integration.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/config.py</code> <pre><code>class MCPConfig(BaseModel):\n    \"\"\"Configuration for MCP integration.\"\"\"\n    server: dict[str, Any] | None = Field(default=None, description=\"Configuration to run an MCP server (host, port, etc.).\")\n    client_connections: dict[str, str] = Field(default_factory=dict, description=\"Named MCP server URLs to connect to as a client (e.g., {'files': 'stdio:npx @mcp/server-filesystem /data'}).\")\n    # ADK's MCPToolset handles client connections if ADKConfig.use_mcp_toolset is True\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n</code></pre> <code>ModelConfig</code> \u00b6 <p>               Bases: <code>BaseModel</code></p> <p>Configuration specific to an LLM model via LiteLLM.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/config.py</code> <pre><code>class ModelConfig(BaseModel):\n    \"\"\"Configuration specific to an LLM model via LiteLLM.\"\"\"\n    # Used as key for model selection\n    name: str = Field(..., description=\"Unique identifier/alias for this model configuration (e.g., 'fast_formatter', 'main_reasoner').\")\n    model: str = Field(..., description=\"LiteLLM model string (e.g., 'gemini/gemini-1.5-pro-latest', 'ollama/mistral').\")\n    provider: str | None = Field(default=None, description=\"LiteLLM provider override if needed.\")\n    api_key: str | None = Field(default=None, description=\"API Key (consider using environment variables).\")\n    api_base: str | None = Field(default=None, description=\"API Base URL (for local models, proxies).\")\n    api_version: str | None = Field(default=None, description=\"API Version (e.g., for Azure).\")\n\n    # Common LLM Parameters\n    temperature: float | None = Field(default=0.7)\n    top_p: float | None = Field(default=None)\n    top_k: int | None = Field(default=None)\n    max_tokens: int | None = Field(default=2048, description=\"Max tokens for generation.\")\n    max_input_tokens: int | None = Field(default=None, description=\"Max input context window (autodetected if None).\")\n    stop_sequence: list[str] | None = Field(default=None)\n    presence_penalty: float | None = Field(default=None)\n    frequency_penalty: float | None = Field(default=None)\n    system_message: str | None = Field(default=None, description=\"Default system message for this model.\")\n\n    # LiteLLM Specific\n    caching: bool = Field(default=True, description=\"Enable LiteLLM caching for this model.\")\n    # budget_manager: Optional[BudgetManager] = Field(default=None) # Budget manager applied globally or per-agent\n\n    model_config = ConfigDict(arbitrary_types_allowed=True, extra='allow') # Allow extra LiteLLM params\n</code></pre> <code>ObservabilityConfig</code> \u00b6 <p>               Bases: <code>BaseModel</code></p> <p>Configuration for observability (OpenTelemetry).</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/config.py</code> <pre><code>class ObservabilityConfig(BaseModel):\n    \"\"\"Configuration for observability (OpenTelemetry).\"\"\"\n    enabled: bool = Field(default=True)\n    endpoint: str | None = Field(default=None, description=\"OTLP endpoint URL (e.g., http://jaeger:4317).\")\n    service_name: str | None = Field(default=None, description=\"Service name for traces/metrics (defaults to agent name).\")\n    # Add more OTel config options as needed (headers, certs, resource attributes)\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.Agent.executors","title":"<code>executors</code>","text":"<code>DockerCodeExecutor</code> \u00b6 <p>               Bases: <code>_BaseExecutorClass</code></p> <p>Executes Python code in a sandboxed Docker container.</p> <p>Requires Docker to be installed and running, and the 'docker' Python SDK.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/executors.py</code> <pre><code>class DockerCodeExecutor(_BaseExecutorClass):\n    \"\"\"\n    Executes Python code in a sandboxed Docker container.\n\n    Requires Docker to be installed and running, and the 'docker' Python SDK.\n    \"\"\"\n    DEFAULT_DOCKER_IMAGE = \"python:3.10-slim\" # Use a minimal image\n    DEFAULT_TIMEOUT = 10 # Seconds\n    DEFAULT_MEM_LIMIT = \"128m\"\n    DEFAULT_CPUS = 0.5\n\n    def __init__(self,\n                 docker_image: str = DEFAULT_DOCKER_IMAGE,\n                 timeout: int = DEFAULT_TIMEOUT,\n                 mem_limit: str = DEFAULT_MEM_LIMIT,\n                 cpus: float = DEFAULT_CPUS,\n                 network_mode: str = \"none\", # Disable networking by default for security\n                 docker_client_config: dict | None = None):\n        if not DOCKER_AVAILABLE:\n            raise ImportError(\"Docker SDK not installed ('pip install docker'). Cannot use DockerCodeExecutor.\")\n\n        self.docker_image = docker_image\n        self.timeout = timeout\n        self.mem_limit = mem_limit\n        self.cpus = cpus\n        self.network_mode = network_mode\n        try:\n            self.client = docker.from_env(**(docker_client_config or {}))\n            self.client.ping() # Check connection\n            # Ensure image exists locally or pull it\n            try:\n                self.client.images.get(self.docker_image)\n                logger.info(f\"Docker image '{self.docker_image}' found locally.\")\n            except ImageNotFound:\n                logger.warning(f\"Docker image '{self.docker_image}' not found locally. Attempting to pull...\")\n                try:\n                    self.client.images.pull(self.docker_image)\n                    logger.info(f\"Successfully pulled Docker image '{self.docker_image}'.\")\n                except APIError as pull_err:\n                    raise RuntimeError(f\"Failed to pull Docker image '{self.docker_image}': {pull_err}\") from pull_err\n        except Exception as e:\n            raise RuntimeError(f\"Failed to connect to Docker daemon: {e}. Is Docker running?\") from e\n        logger.info(f\"DockerCodeExecutor initialized (Image: {docker_image}, Timeout: {timeout}s, Network: {network_mode})\")\n\n    def _execute(self, code: str) -&gt; dict[str, Any]:\n        \"\"\"Internal execution logic.\"\"\"\n        result = {\"stdout\": \"\", \"stderr\": \"\", \"error\": None, \"exit_code\": None}\n        container = None\n\n        try:\n            logger.debug(f\"Creating Docker container from image '{self.docker_image}'...\")\n            container = self.client.containers.run(\n                image=self.docker_image,\n                command=[\"python\", \"-c\", code],\n                detach=True,\n                mem_limit=self.mem_limit,\n                nano_cpus=int(self.cpus * 1e9),\n                network_mode=self.network_mode,\n                # Security considerations: Consider read-only filesystem, dropping capabilities\n                read_only=True,\n                # working_dir=\"/app\", # Define a working dir if needed\n                # volumes={...} # Mount volumes carefully if required\n            )\n            logger.debug(f\"Container '{container.short_id}' started.\")\n\n            # Wait for container completion with timeout\n            container_result = container.wait(timeout=self.timeout)\n            result[\"exit_code\"] = container_result.get(\"StatusCode\", None)\n\n            # Retrieve logs\n            result[\"stdout\"] = container.logs(stdout=True, stderr=False).decode('utf-8', errors='replace').strip()\n            result[\"stderr\"] = container.logs(stdout=False, stderr=True).decode('utf-8', errors='replace').strip()\n\n            logger.debug(f\"Container '{container.short_id}' finished with exit code {result['exit_code']}.\")\n            if result[\"exit_code\"] != 0:\n                 logger.warning(f\"Container stderr: {result['stderr'][:500]}...\") # Log stderr on failure\n\n        except ContainerError as e:\n            result[\"error\"] = f\"ContainerError: {e}\"\n            result[\"stderr\"] = e.stderr.decode('utf-8', errors='replace').strip() if e.stderr else str(e)\n            result[\"exit_code\"] = e.exit_status\n            logger.error(f\"Container '{container.short_id if container else 'N/A'}' failed: {result['error']}\\nStderr: {result['stderr']}\")\n        except APIError as e:\n            result[\"error\"] = f\"Docker APIError: {e}\"\n            result[\"exit_code\"] = -1\n            logger.error(f\"Docker API error during execution: {e}\")\n        except Exception as e:\n            # Catch potential timeout errors from container.wait or other unexpected issues\n            result[\"error\"] = f\"Unexpected execution error: {type(e).__name__}: {e}\"\n            result[\"exit_code\"] = -1\n            # Check if it looks like a timeout\n            if isinstance(e, TimeoutError) or \"Timeout\" in str(e): # docker SDK might raise requests.exceptions.ReadTimeout\n                result[\"stderr\"] = f\"Execution timed out after {self.timeout} seconds.\"\n                logger.warning(f\"Container execution timed out ({self.timeout}s).\")\n            else:\n                logger.error(f\"Unexpected error during Docker execution: {e}\", exc_info=True)\n        finally:\n            if container:\n                try:\n                    logger.debug(f\"Removing container '{container.short_id}'...\")\n                    container.remove(force=True)\n                except APIError as rm_err:\n                    logger.warning(f\"Failed to remove container {container.short_id}: {rm_err}\")\n\n        return result\n\n     # --- ADK Compatibility Method ---\n    if ADK_EXEC_AVAILABLE:\n        def execute_code(self, invocation_context: InvocationContext, code_input: CodeExecutionInput) -&gt; CodeExecutionResult:\n            logger.debug(f\"DockerCodeExecutor executing ADK request (lang: {code_input.language}). Code: {code_input.code[:100]}...\")\n            if code_input.language.lower() != 'python':\n                 return CodeExecutionResult(output=f\"Error: Unsupported language '{code_input.language}'. Only Python is supported.\", outcome=\"OUTCOME_FAILURE\")\n\n            exec_result = self._execute(code_input.code)\n\n            output_str = \"\"\n            if exec_result[\"stdout\"]:\n                output_str += f\"Stdout:\\n{exec_result['stdout']}\\n\"\n            if exec_result[\"stderr\"]:\n                 output_str += f\"Stderr:\\n{exec_result['stderr']}\\n\"\n            if not output_str and exec_result[\"exit_code\"] == 0:\n                 output_str = \"Execution successful with no output.\"\n            elif not output_str and exec_result[\"exit_code\"] != 0:\n                 output_str = f\"Execution failed with no output (Exit code: {exec_result['exit_code']}). Error: {exec_result['error']}\"\n\n            outcome = \"OUTCOME_SUCCESS\" if exec_result[\"exit_code\"] == 0 else \"OUTCOME_FAILURE\"\n\n            return CodeExecutionResult(output=output_str.strip(), outcome=outcome)\n    # --- End ADK Compatibility ---\n\n    # --- Direct Call Method ---\n    def execute(self, code: str) -&gt; dict[str, Any]:\n        \"\"\"Directly execute code, returning detailed dictionary.\"\"\"\n        logger.debug(f\"DockerCodeExecutor executing direct call. Code: {code[:100]}...\")\n        return self._execute(code)\n</code></pre> <code>execute(code)</code> \u00b6 <p>Directly execute code, returning detailed dictionary.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/executors.py</code> <pre><code>def execute(self, code: str) -&gt; dict[str, Any]:\n    \"\"\"Directly execute code, returning detailed dictionary.\"\"\"\n    logger.debug(f\"DockerCodeExecutor executing direct call. Code: {code[:100]}...\")\n    return self._execute(code)\n</code></pre> <code>RestrictedPythonExecutor</code> \u00b6 <p>               Bases: <code>_BaseExecutorClass</code></p> <p>Executes Python code using restrictedpython.</p> <p>Safer than exec() but NOT a full sandbox. Known vulnerabilities exist. Use with extreme caution and only with trusted code sources or for low-risk operations. Docker is strongly recommended for untrusted code.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/executors.py</code> <pre><code>class RestrictedPythonExecutor(_BaseExecutorClass):\n    \"\"\"\n    Executes Python code using restrictedpython.\n\n    Safer than exec() but NOT a full sandbox. Known vulnerabilities exist.\n    Use with extreme caution and only with trusted code sources or for\n    low-risk operations. Docker is strongly recommended for untrusted code.\n    \"\"\"\n    DEFAULT_ALLOWED_GLOBALS = {\n        **safe_globals,\n        '_print_': restrictedpython.PrintCollector,\n        '_getattr_': restrictedpython.safe_getattr,\n        '_getitem_': restrictedpython.safe_getitem,\n        '_write_': restrictedpython.guarded_setattr, # Allows modifying specific safe objects if needed\n        # Add other safe builtins or modules carefully\n        'math': __import__('math'),\n        'random': __import__('random'),\n        'datetime': __import__('datetime'),\n        'time': __import__('time'),\n        # 'requests': None, # Example: Explicitly disallow\n    }\n\n    def __init__(self, allowed_globals: dict | None = None, max_execution_time: int = 5):\n        if not RESTRICTEDPYTHON_AVAILABLE:\n            raise ImportError(\"restrictedpython is not installed. Cannot use RestrictedPythonExecutor.\")\n        self.allowed_globals = allowed_globals or self.DEFAULT_ALLOWED_GLOBALS\n        self.max_execution_time = max_execution_time # Basic timeout (not perfectly enforced by restrictedpython)\n        logger.warning(\"Initialized RestrictedPythonExecutor. This provides LIMITED sandboxing. Use Docker for untrusted code.\")\n\n    def _execute(self, code: str) -&gt; dict[str, Any]:\n        \"\"\"Internal execution logic.\"\"\"\n        start_time = time.monotonic()\n        result = {\"stdout\": \"\", \"stderr\": \"\", \"error\": None, \"exit_code\": None}\n        local_vars = {}\n        stdout_capture = io.StringIO()\n        stderr_capture = io.StringIO()\n\n        try:\n            # Basic timeout check (not preemptive)\n            if time.monotonic() - start_time &gt; self.max_execution_time:\n                 raise TimeoutError(f\"Execution exceeded max time of {self.max_execution_time}s (pre-check).\")\n\n            # Compile the code in restricted mode\n            byte_code = compile_restricted(code, filename='&lt;inline code&gt;', mode='exec')\n\n            # Add a print collector to capture output\n            self.allowed_globals['_print_'] = restrictedpython.PrintCollector\n            print_collector = self.allowed_globals['_print_']()\n            exec_globals = {**self.allowed_globals, '_print': print_collector}\n\n            # Execute the compiled code\n            # Note: restrictedpython does not inherently support robust timeouts during exec\n            exec(byte_code, exec_globals, local_vars)\n\n            # Check execution time again\n            duration = time.monotonic() - start_time\n            if duration &gt; self.max_execution_time:\n                logger.warning(f\"Execution finished but exceeded max time ({duration:.2f}s &gt; {self.max_execution_time}s).\")\n                # Potentially treat as an error or partial success\n\n            result[\"stdout\"] = print_collector.printed_text # Access collected prints\n            result[\"exit_code\"] = 0 # Assume success if no exception\n\n        except TimeoutError as e:\n            result[\"stderr\"] = f\"TimeoutError: {e}\"\n            result[\"error\"] = str(e)\n            result[\"exit_code\"] = -1 # Indicate timeout\n        except SyntaxError as e:\n            result[\"stderr\"] = f\"SyntaxError: {e}\"\n            result[\"error\"] = str(e)\n            result[\"exit_code\"] = 1\n        except Exception as e:\n            # Capture other potential execution errors allowed by restrictedpython\n            error_type = type(e).__name__\n            error_msg = f\"{error_type}: {e}\"\n            result[\"stderr\"] = error_msg\n            result[\"error\"] = str(e)\n            result[\"exit_code\"] = 1\n            logger.warning(f\"RestrictedPython execution caught exception: {error_msg}\", exc_info=False) # Avoid logging potentially sensitive details from code\n        finally:\n            stdout_capture.close() # Not used directly with PrintCollector\n            stderr_capture.close()\n\n        return result\n\n    # --- ADK Compatibility Method ---\n    if ADK_EXEC_AVAILABLE:\n        def execute_code(self, invocation_context: InvocationContext, code_input: CodeExecutionInput) -&gt; CodeExecutionResult:\n            logger.debug(f\"RestrictedPythonExecutor executing ADK request (lang: {code_input.language}). Code: {code_input.code[:100]}...\")\n            if code_input.language.lower() != 'python':\n                 return CodeExecutionResult(output=f\"Error: Unsupported language '{code_input.language}'. Only Python is supported.\", outcome=\"OUTCOME_FAILURE\")\n\n            exec_result = self._execute(code_input.code)\n\n            output_str = \"\"\n            if exec_result[\"stdout\"]:\n                output_str += f\"Stdout:\\n{exec_result['stdout']}\\n\"\n            if exec_result[\"stderr\"]:\n                 output_str += f\"Stderr:\\n{exec_result['stderr']}\\n\"\n            if not output_str and exec_result[\"exit_code\"] == 0:\n                 output_str = \"Execution successful with no output.\"\n            elif not output_str and exec_result[\"exit_code\"] != 0:\n                 output_str = f\"Execution failed with no output (Exit code: {exec_result['exit_code']}). Error: {exec_result['error']}\"\n\n\n            outcome = \"OUTCOME_SUCCESS\" if exec_result[\"exit_code\"] == 0 else \"OUTCOME_FAILURE\"\n\n            return CodeExecutionResult(output=output_str.strip(), outcome=outcome)\n    # --- End ADK Compatibility ---\n\n    # --- Direct Call Method ---\n    def execute(self, code: str) -&gt; dict[str, Any]:\n        \"\"\"Directly execute code, returning detailed dictionary.\"\"\"\n        logger.debug(f\"RestrictedPythonExecutor executing direct call. Code: {code[:100]}...\")\n        return self._execute(code)\n</code></pre> <code>execute(code)</code> \u00b6 <p>Directly execute code, returning detailed dictionary.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/executors.py</code> <pre><code>def execute(self, code: str) -&gt; dict[str, Any]:\n    \"\"\"Directly execute code, returning detailed dictionary.\"\"\"\n    logger.debug(f\"RestrictedPythonExecutor executing direct call. Code: {code[:100]}...\")\n    return self._execute(code)\n</code></pre> <code>get_code_executor(config)</code> \u00b6 <p>Creates a code executor instance based on configuration.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/executors.py</code> <pre><code>def get_code_executor(config: 'AgentConfig') -&gt; RestrictedPythonExecutor | DockerCodeExecutor | BaseCodeExecutor | None:\n    \"\"\"Creates a code executor instance based on configuration.\"\"\"\n    executor_type = config.code_executor_type\n    executor_config = config.code_executor_config or {}\n\n    if executor_type == \"restricted\":\n        if not RESTRICTEDPYTHON_AVAILABLE:\n            logger.error(\"RestrictedPython executor configured but library not installed. Code execution disabled.\")\n            return None\n        return RestrictedPythonExecutor(**executor_config)\n    elif executor_type == \"docker\":\n        if not DOCKER_AVAILABLE:\n            logger.error(\"Docker executor configured but library not installed or Docker not running. Code execution disabled.\")\n            return None\n        try:\n            return DockerCodeExecutor(**executor_config)\n        except Exception as e:\n            logger.error(f\"Failed to initialize DockerCodeExecutor: {e}. Code execution disabled.\")\n            return None\n    elif executor_type == \"none\":\n        logger.info(\"Code execution explicitly disabled in configuration.\")\n        return None\n    elif executor_type and ADK_EXEC_AVAILABLE and isinstance(executor_type, BaseCodeExecutor):\n        # Allow passing a pre-configured ADK executor instance\n        logger.info(f\"Using pre-configured ADK code executor: {type(executor_type).__name__}\")\n        return executor_type\n    else:\n        logger.warning(f\"Unknown or unsupported code_executor_type: '{executor_type}'. Code execution disabled.\")\n        return None\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.Agent.types","title":"<code>types</code>","text":"<code>AgentCheckpoint</code> <code>dataclass</code> \u00b6 <p>Enhanced AgentCheckpoint with UnifiedContextManager and ChatSession integration</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>@dataclass\nclass AgentCheckpoint:\n    \"\"\"Enhanced AgentCheckpoint with UnifiedContextManager and ChatSession integration\"\"\"\n    timestamp: datetime\n    agent_state: dict[str, Any]\n    task_state: dict[str, Any]\n    world_model: dict[str, Any]\n    active_flows: list[str]\n    metadata: dict[str, Any] = field(default_factory=dict)\n\n    # NEUE: Enhanced checkpoint data for UnifiedContextManager integration\n    session_data: dict[str, Any] = field(default_factory=dict)\n    context_manager_state: dict[str, Any] = field(default_factory=dict)\n    conversation_history: list[dict[str, Any]] = field(default_factory=list)\n    variable_system_state: dict[str, Any] = field(default_factory=dict)\n    results_store: dict[str, Any] = field(default_factory=dict)\n    tool_capabilities: dict[str, Any] = field(default_factory=dict)\n    variable_scopes: dict[str, Any] = field(default_factory=dict)\n\n    # Optional: Additional system state\n    performance_metrics: dict[str, Any] = field(default_factory=dict)\n    execution_history: list[dict[str, Any]] = field(default_factory=list)\n\n    def get_checkpoint_summary(self) -&gt; str:\n        \"\"\"Get human-readable checkpoint summary\"\"\"\n        try:\n            summary_parts = []\n\n            # Basic info\n            if self.session_data:\n                session_count = len([s for s in self.session_data.values() if s.get(\"status\") != \"failed\"])\n                summary_parts.append(f\"{session_count} sessions\")\n\n            # Task info\n            if self.task_state:\n                completed_tasks = len([t for t in self.task_state.values() if t.get(\"status\") == \"completed\"])\n                total_tasks = len(self.task_state)\n                summary_parts.append(f\"{completed_tasks}/{total_tasks} tasks\")\n\n            # Conversation info\n            if self.conversation_history:\n                summary_parts.append(f\"{len(self.conversation_history)} messages\")\n\n            # Context info\n            if self.context_manager_state:\n                cache_count = self.context_manager_state.get(\"cache_entries\", 0)\n                if cache_count &gt; 0:\n                    summary_parts.append(f\"{cache_count} cached contexts\")\n\n            # Variable system info\n            if self.variable_system_state:\n                scopes = len(self.variable_system_state.get(\"scopes\", {}))\n                summary_parts.append(f\"{scopes} variable scopes\")\n\n            # Tool capabilities\n            if self.tool_capabilities:\n                summary_parts.append(f\"{len(self.tool_capabilities)} analyzed tools\")\n\n            return \"; \".join(summary_parts) if summary_parts else \"Basic checkpoint\"\n\n        except Exception as e:\n            return f\"Summary generation failed: {str(e)}\"\n\n    def get_storage_size_estimate(self) -&gt; dict[str, int]:\n        \"\"\"Estimate storage size of different checkpoint components\"\"\"\n        try:\n            sizes = {}\n\n            # Calculate sizes in bytes (approximate)\n            sizes[\"agent_state\"] = len(str(self.agent_state))\n            sizes[\"task_state\"] = len(str(self.task_state))\n            sizes[\"world_model\"] = len(str(self.world_model))\n            sizes[\"conversation_history\"] = len(str(self.conversation_history))\n            sizes[\"session_data\"] = len(str(self.session_data))\n            sizes[\"context_manager_state\"] = len(str(self.context_manager_state))\n            sizes[\"variable_system_state\"] = len(str(self.variable_system_state))\n            sizes[\"results_store\"] = len(str(self.results_store))\n            sizes[\"tool_capabilities\"] = len(str(self.tool_capabilities))\n\n            sizes[\"total_bytes\"] = sum(sizes.values())\n            sizes[\"total_kb\"] = sizes[\"total_bytes\"] / 1024\n            sizes[\"total_mb\"] = sizes[\"total_kb\"] / 1024\n\n            return sizes\n\n        except Exception as e:\n            return {\"error\": str(e)}\n\n    def validate_checkpoint_integrity(self) -&gt; dict[str, Any]:\n        \"\"\"Validate checkpoint integrity and completeness\"\"\"\n        validation = {\n            \"is_valid\": True,\n            \"errors\": [],\n            \"warnings\": [],\n            \"completeness_score\": 0.0,\n            \"components_present\": []\n        }\n\n        try:\n            # Check required components\n            required_components = [\"timestamp\", \"agent_state\", \"task_state\", \"world_model\", \"active_flows\"]\n            for component in required_components:\n                if hasattr(self, component) and getattr(self, component) is not None:\n                    validation[\"components_present\"].append(component)\n                else:\n                    validation[\"errors\"].append(f\"Missing required component: {component}\")\n                    validation[\"is_valid\"] = False\n\n            # Check optional enhanced components\n            enhanced_components = [\"session_data\", \"context_manager_state\", \"conversation_history\",\n                                   \"variable_system_state\", \"results_store\", \"tool_capabilities\"]\n\n            for component in enhanced_components:\n                if hasattr(self, component) and getattr(self, component):\n                    validation[\"components_present\"].append(component)\n\n            # Calculate completeness score\n            total_possible = len(required_components) + len(enhanced_components)\n            validation[\"completeness_score\"] = len(validation[\"components_present\"]) / total_possible\n\n            # Check timestamp validity\n            if isinstance(self.timestamp, datetime):\n                age_hours = (datetime.now() - self.timestamp).total_seconds() / 3600\n                if age_hours &gt; 24:\n                    validation[\"warnings\"].append(f\"Checkpoint is {age_hours:.1f} hours old\")\n            else:\n                validation[\"errors\"].append(\"Invalid timestamp format\")\n                validation[\"is_valid\"] = False\n\n            # Check session data consistency\n            if self.session_data and self.conversation_history:\n                session_ids_in_data = set(self.session_data.keys())\n                session_ids_in_conversation = set(\n                    msg.get(\"session_id\") for msg in self.conversation_history\n                    if msg.get(\"session_id\")\n                )\n\n                if session_ids_in_data != session_ids_in_conversation:\n                    validation[\"warnings\"].append(\"Session data and conversation history session IDs don't match\")\n\n            return validation\n\n        except Exception as e:\n            validation[\"errors\"].append(f\"Validation error: {str(e)}\")\n            validation[\"is_valid\"] = False\n            return validation\n\n    def get_version_info(self) -&gt; dict[str, str]:\n        \"\"\"Get checkpoint version information\"\"\"\n        return {\n            \"checkpoint_version\": self.metadata.get(\"checkpoint_version\", \"1.0\"),\n            \"data_format\": \"enhanced\" if self.session_data or self.context_manager_state else \"basic\",\n            \"context_system\": \"unified\" if self.context_manager_state else \"legacy\",\n            \"variable_system\": \"integrated\" if self.variable_system_state else \"basic\",\n            \"session_management\": \"chatsession\" if self.session_data else \"memory_only\",\n            \"created_with\": \"FlowAgent v2.0 Enhanced Context System\"\n        }\n</code></pre> <code>get_checkpoint_summary()</code> \u00b6 <p>Get human-readable checkpoint summary</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def get_checkpoint_summary(self) -&gt; str:\n    \"\"\"Get human-readable checkpoint summary\"\"\"\n    try:\n        summary_parts = []\n\n        # Basic info\n        if self.session_data:\n            session_count = len([s for s in self.session_data.values() if s.get(\"status\") != \"failed\"])\n            summary_parts.append(f\"{session_count} sessions\")\n\n        # Task info\n        if self.task_state:\n            completed_tasks = len([t for t in self.task_state.values() if t.get(\"status\") == \"completed\"])\n            total_tasks = len(self.task_state)\n            summary_parts.append(f\"{completed_tasks}/{total_tasks} tasks\")\n\n        # Conversation info\n        if self.conversation_history:\n            summary_parts.append(f\"{len(self.conversation_history)} messages\")\n\n        # Context info\n        if self.context_manager_state:\n            cache_count = self.context_manager_state.get(\"cache_entries\", 0)\n            if cache_count &gt; 0:\n                summary_parts.append(f\"{cache_count} cached contexts\")\n\n        # Variable system info\n        if self.variable_system_state:\n            scopes = len(self.variable_system_state.get(\"scopes\", {}))\n            summary_parts.append(f\"{scopes} variable scopes\")\n\n        # Tool capabilities\n        if self.tool_capabilities:\n            summary_parts.append(f\"{len(self.tool_capabilities)} analyzed tools\")\n\n        return \"; \".join(summary_parts) if summary_parts else \"Basic checkpoint\"\n\n    except Exception as e:\n        return f\"Summary generation failed: {str(e)}\"\n</code></pre> <code>get_storage_size_estimate()</code> \u00b6 <p>Estimate storage size of different checkpoint components</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def get_storage_size_estimate(self) -&gt; dict[str, int]:\n    \"\"\"Estimate storage size of different checkpoint components\"\"\"\n    try:\n        sizes = {}\n\n        # Calculate sizes in bytes (approximate)\n        sizes[\"agent_state\"] = len(str(self.agent_state))\n        sizes[\"task_state\"] = len(str(self.task_state))\n        sizes[\"world_model\"] = len(str(self.world_model))\n        sizes[\"conversation_history\"] = len(str(self.conversation_history))\n        sizes[\"session_data\"] = len(str(self.session_data))\n        sizes[\"context_manager_state\"] = len(str(self.context_manager_state))\n        sizes[\"variable_system_state\"] = len(str(self.variable_system_state))\n        sizes[\"results_store\"] = len(str(self.results_store))\n        sizes[\"tool_capabilities\"] = len(str(self.tool_capabilities))\n\n        sizes[\"total_bytes\"] = sum(sizes.values())\n        sizes[\"total_kb\"] = sizes[\"total_bytes\"] / 1024\n        sizes[\"total_mb\"] = sizes[\"total_kb\"] / 1024\n\n        return sizes\n\n    except Exception as e:\n        return {\"error\": str(e)}\n</code></pre> <code>get_version_info()</code> \u00b6 <p>Get checkpoint version information</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def get_version_info(self) -&gt; dict[str, str]:\n    \"\"\"Get checkpoint version information\"\"\"\n    return {\n        \"checkpoint_version\": self.metadata.get(\"checkpoint_version\", \"1.0\"),\n        \"data_format\": \"enhanced\" if self.session_data or self.context_manager_state else \"basic\",\n        \"context_system\": \"unified\" if self.context_manager_state else \"legacy\",\n        \"variable_system\": \"integrated\" if self.variable_system_state else \"basic\",\n        \"session_management\": \"chatsession\" if self.session_data else \"memory_only\",\n        \"created_with\": \"FlowAgent v2.0 Enhanced Context System\"\n    }\n</code></pre> <code>validate_checkpoint_integrity()</code> \u00b6 <p>Validate checkpoint integrity and completeness</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def validate_checkpoint_integrity(self) -&gt; dict[str, Any]:\n    \"\"\"Validate checkpoint integrity and completeness\"\"\"\n    validation = {\n        \"is_valid\": True,\n        \"errors\": [],\n        \"warnings\": [],\n        \"completeness_score\": 0.0,\n        \"components_present\": []\n    }\n\n    try:\n        # Check required components\n        required_components = [\"timestamp\", \"agent_state\", \"task_state\", \"world_model\", \"active_flows\"]\n        for component in required_components:\n            if hasattr(self, component) and getattr(self, component) is not None:\n                validation[\"components_present\"].append(component)\n            else:\n                validation[\"errors\"].append(f\"Missing required component: {component}\")\n                validation[\"is_valid\"] = False\n\n        # Check optional enhanced components\n        enhanced_components = [\"session_data\", \"context_manager_state\", \"conversation_history\",\n                               \"variable_system_state\", \"results_store\", \"tool_capabilities\"]\n\n        for component in enhanced_components:\n            if hasattr(self, component) and getattr(self, component):\n                validation[\"components_present\"].append(component)\n\n        # Calculate completeness score\n        total_possible = len(required_components) + len(enhanced_components)\n        validation[\"completeness_score\"] = len(validation[\"components_present\"]) / total_possible\n\n        # Check timestamp validity\n        if isinstance(self.timestamp, datetime):\n            age_hours = (datetime.now() - self.timestamp).total_seconds() / 3600\n            if age_hours &gt; 24:\n                validation[\"warnings\"].append(f\"Checkpoint is {age_hours:.1f} hours old\")\n        else:\n            validation[\"errors\"].append(\"Invalid timestamp format\")\n            validation[\"is_valid\"] = False\n\n        # Check session data consistency\n        if self.session_data and self.conversation_history:\n            session_ids_in_data = set(self.session_data.keys())\n            session_ids_in_conversation = set(\n                msg.get(\"session_id\") for msg in self.conversation_history\n                if msg.get(\"session_id\")\n            )\n\n            if session_ids_in_data != session_ids_in_conversation:\n                validation[\"warnings\"].append(\"Session data and conversation history session IDs don't match\")\n\n        return validation\n\n    except Exception as e:\n        validation[\"errors\"].append(f\"Validation error: {str(e)}\")\n        validation[\"is_valid\"] = False\n        return validation\n</code></pre> <code>AgentModelData</code> \u00b6 <p>               Bases: <code>BaseModel</code></p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>class AgentModelData(BaseModel):\n    name: str = \"FlowAgent\"\n    fast_llm_model: str = \"openrouter/anthropic/claude-3-haiku\"\n    complex_llm_model: str = \"openrouter/openai/gpt-4o\"\n    system_message: str = \"You are a production-ready autonomous agent.\"\n    temperature: float = 0.7\n    max_tokens: int = 2048\n    max_input_tokens: int = 32768\n    api_key: str | None  = None\n    api_base: str | None  = None\n    budget_manager: Any  = None\n    caching: bool = True\n    persona: PersonaConfig | None = True\n    use_fast_response: bool = True\n\n    def get_system_message_with_persona(self) -&gt; str:\n        \"\"\"Get system message with persona integration\"\"\"\n        base_message = self.system_message\n\n        if self.persona and self.persona.apply_method in [\"system_prompt\", \"both\"]:\n            persona_addition = self.persona.to_system_prompt_addition()\n            if persona_addition:\n                base_message += f\"\\n## Persona Instructions\\n{persona_addition}\"\n\n        return base_message\n</code></pre> <code>get_system_message_with_persona()</code> \u00b6 <p>Get system message with persona integration</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def get_system_message_with_persona(self) -&gt; str:\n    \"\"\"Get system message with persona integration\"\"\"\n    base_message = self.system_message\n\n    if self.persona and self.persona.apply_method in [\"system_prompt\", \"both\"]:\n        persona_addition = self.persona.to_system_prompt_addition()\n        if persona_addition:\n            base_message += f\"\\n## Persona Instructions\\n{persona_addition}\"\n\n    return base_message\n</code></pre> <code>ChainMetadata</code> <code>dataclass</code> \u00b6 <p>Metadata for stored chains</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>@dataclass\nclass ChainMetadata:\n    \"\"\"Metadata for stored chains\"\"\"\n    name: str\n    description: str = \"\"\n    created_at: datetime = field(default_factory=datetime.now)\n    modified_at: datetime = field(default_factory=datetime.now)\n    version: str = \"1.0.0\"\n    tags: list[str] = field(default_factory=list)\n    author: str = \"\"\n    complexity: str = \"simple\"  # simple, medium, complex\n    agent_count: int = 0\n    has_conditionals: bool = False\n    has_parallels: bool = False\n    has_error_handling: bool = False\n</code></pre> <code>DecisionTask</code> <code>dataclass</code> \u00b6 <p>               Bases: <code>Task</code></p> <p>Task f\u00fcr dynamisches Routing</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>@dataclass\nclass DecisionTask(Task):\n    \"\"\"Task f\u00fcr dynamisches Routing\"\"\"\n    decision_prompt: str = \"\"  # Kurze Frage an LLM\n    routing_map: dict[str, str] = field(default_factory=dict)  # Ergebnis -&gt; n\u00e4chster Task\n    decision_model: str = \"fast\"  # Welches LLM f\u00fcr Entscheidung\n</code></pre> <code>FormatConfig</code> <code>dataclass</code> \u00b6 <p>Konfiguration f\u00fcr Response-Format und -L\u00e4nge</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>@dataclass\nclass FormatConfig:\n    \"\"\"Konfiguration f\u00fcr Response-Format und -L\u00e4nge\"\"\"\n    response_format: ResponseFormat = ResponseFormat.FREE_TEXT\n    text_length: TextLength = TextLength.CHAT_CONVERSATION\n    custom_instructions: str = \"\"\n    strict_format_adherence: bool = True\n    quality_threshold: float = 0.7\n\n    def get_format_instructions(self) -&gt; str:\n        \"\"\"Generiere Format-spezifische Anweisungen\"\"\"\n        format_instructions = {\n            ResponseFormat.FREE_TEXT: \"Use natural continuous text without special formatting.\",\n            ResponseFormat.WITH_TABLES: \"Integrate tables for structured data representation. Use Markdown tables.\",\n            ResponseFormat.WITH_BULLET_POINTS: \"Structure information with bullet points (\u2022, -, *) for better readability.\",\n            ResponseFormat.WITH_LISTS: \"Use numbered and unnumbered lists to organize content.\",\n            ResponseFormat.TEXT_ONLY: \"Plain text only without formatting, symbols, or structural elements.\",\n            ResponseFormat.MD_TEXT: \"Full Markdown formatting with headings, code blocks, links, etc.\",\n            ResponseFormat.YAML_TEXT: \"Structure responses in YAML format for machine-readable output.\",\n            ResponseFormat.JSON_TEXT: \"Format responses as a JSON structure for API integration.\",\n            ResponseFormat.PSEUDO_CODE: \"Use pseudocode structure for algorithmic or logical explanations.\",\n            ResponseFormat.CODE_STRUCTURE: \"Structure like code with indentation, comments, and logical blocks.\"\n        }\n        return format_instructions.get(self.response_format, \"Standard-Formatierung.\")\n\n    def get_length_instructions(self) -&gt; str:\n        \"\"\"Generiere L\u00e4ngen-spezifische Anweisungen\"\"\"\n        length_instructions = {\n            TextLength.MINI_CHAT: \"Very short, concise answers (1\u20132 sentences, max 50 words). Chat style.\",\n            TextLength.CHAT_CONVERSATION: \"Moderate conversation length (2\u20134 sentences, 50\u2013150 words). Natural conversational style.\",\n            TextLength.TABLE_CONVERSATION: \"Structured, tabular presentation with compact explanations (100\u2013250 words).\",\n            TextLength.DETAILED_INDEPTH: \"Comprehensive, detailed explanations (300\u2013800 words) with depth and context.\",\n            TextLength.PHD_LEVEL: \"Academic depth with extensive explanations (800+ words), references, and technical terminology.\"\n        }\n        return length_instructions.get(self.text_length, \"Standard-L\u00e4nge.\")\n\n    def get_combined_instructions(self) -&gt; str:\n        \"\"\"Kombiniere Format- und L\u00e4ngen-Anweisungen\"\"\"\n        instructions = []\n        instructions.append(\"## Format-Anforderungen:\")\n        instructions.append(self.get_format_instructions())\n        instructions.append(\"\\n## L\u00e4ngen-Anforderungen:\")\n        instructions.append(self.get_length_instructions())\n\n        if self.custom_instructions:\n            instructions.append(\"\\n## Zus\u00e4tzliche Anweisungen:\")\n            instructions.append(self.custom_instructions)\n\n        if self.strict_format_adherence:\n            instructions.append(\"\\n## ATTENTION: STRICT FORMAT ADHERENCE REQUIRED!\")\n\n        return \"\\n\".join(instructions)\n\n    def get_expected_word_range(self) -&gt; tuple[int, int]:\n        \"\"\"Erwartete Wortanzahl f\u00fcr Qualit\u00e4tsbewertung\"\"\"\n        ranges = {\n            TextLength.MINI_CHAT: (10, 50),\n            TextLength.CHAT_CONVERSATION: (50, 150),\n            TextLength.TABLE_CONVERSATION: (100, 250),\n            TextLength.DETAILED_INDEPTH: (300, 800),\n            TextLength.PHD_LEVEL: (800, 2000)\n        }\n        return ranges.get(self.text_length, (50, 200))\n</code></pre> <code>get_combined_instructions()</code> \u00b6 <p>Kombiniere Format- und L\u00e4ngen-Anweisungen</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def get_combined_instructions(self) -&gt; str:\n    \"\"\"Kombiniere Format- und L\u00e4ngen-Anweisungen\"\"\"\n    instructions = []\n    instructions.append(\"## Format-Anforderungen:\")\n    instructions.append(self.get_format_instructions())\n    instructions.append(\"\\n## L\u00e4ngen-Anforderungen:\")\n    instructions.append(self.get_length_instructions())\n\n    if self.custom_instructions:\n        instructions.append(\"\\n## Zus\u00e4tzliche Anweisungen:\")\n        instructions.append(self.custom_instructions)\n\n    if self.strict_format_adherence:\n        instructions.append(\"\\n## ATTENTION: STRICT FORMAT ADHERENCE REQUIRED!\")\n\n    return \"\\n\".join(instructions)\n</code></pre> <code>get_expected_word_range()</code> \u00b6 <p>Erwartete Wortanzahl f\u00fcr Qualit\u00e4tsbewertung</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def get_expected_word_range(self) -&gt; tuple[int, int]:\n    \"\"\"Erwartete Wortanzahl f\u00fcr Qualit\u00e4tsbewertung\"\"\"\n    ranges = {\n        TextLength.MINI_CHAT: (10, 50),\n        TextLength.CHAT_CONVERSATION: (50, 150),\n        TextLength.TABLE_CONVERSATION: (100, 250),\n        TextLength.DETAILED_INDEPTH: (300, 800),\n        TextLength.PHD_LEVEL: (800, 2000)\n    }\n    return ranges.get(self.text_length, (50, 200))\n</code></pre> <code>get_format_instructions()</code> \u00b6 <p>Generiere Format-spezifische Anweisungen</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def get_format_instructions(self) -&gt; str:\n    \"\"\"Generiere Format-spezifische Anweisungen\"\"\"\n    format_instructions = {\n        ResponseFormat.FREE_TEXT: \"Use natural continuous text without special formatting.\",\n        ResponseFormat.WITH_TABLES: \"Integrate tables for structured data representation. Use Markdown tables.\",\n        ResponseFormat.WITH_BULLET_POINTS: \"Structure information with bullet points (\u2022, -, *) for better readability.\",\n        ResponseFormat.WITH_LISTS: \"Use numbered and unnumbered lists to organize content.\",\n        ResponseFormat.TEXT_ONLY: \"Plain text only without formatting, symbols, or structural elements.\",\n        ResponseFormat.MD_TEXT: \"Full Markdown formatting with headings, code blocks, links, etc.\",\n        ResponseFormat.YAML_TEXT: \"Structure responses in YAML format for machine-readable output.\",\n        ResponseFormat.JSON_TEXT: \"Format responses as a JSON structure for API integration.\",\n        ResponseFormat.PSEUDO_CODE: \"Use pseudocode structure for algorithmic or logical explanations.\",\n        ResponseFormat.CODE_STRUCTURE: \"Structure like code with indentation, comments, and logical blocks.\"\n    }\n    return format_instructions.get(self.response_format, \"Standard-Formatierung.\")\n</code></pre> <code>get_length_instructions()</code> \u00b6 <p>Generiere L\u00e4ngen-spezifische Anweisungen</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def get_length_instructions(self) -&gt; str:\n    \"\"\"Generiere L\u00e4ngen-spezifische Anweisungen\"\"\"\n    length_instructions = {\n        TextLength.MINI_CHAT: \"Very short, concise answers (1\u20132 sentences, max 50 words). Chat style.\",\n        TextLength.CHAT_CONVERSATION: \"Moderate conversation length (2\u20134 sentences, 50\u2013150 words). Natural conversational style.\",\n        TextLength.TABLE_CONVERSATION: \"Structured, tabular presentation with compact explanations (100\u2013250 words).\",\n        TextLength.DETAILED_INDEPTH: \"Comprehensive, detailed explanations (300\u2013800 words) with depth and context.\",\n        TextLength.PHD_LEVEL: \"Academic depth with extensive explanations (800+ words), references, and technical terminology.\"\n    }\n    return length_instructions.get(self.text_length, \"Standard-L\u00e4nge.\")\n</code></pre> <code>LLMTask</code> <code>dataclass</code> \u00b6 <p>               Bases: <code>Task</code></p> <p>Spezialisierter Task f\u00fcr LLM-Aufrufe</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>@dataclass\nclass LLMTask(Task):\n    \"\"\"Spezialisierter Task f\u00fcr LLM-Aufrufe\"\"\"\n    llm_config: dict[str, Any] = field(default_factory=lambda: {\n        \"model_preference\": \"fast\",  # \"fast\" | \"complex\"\n        \"temperature\": 0.7,\n        \"max_tokens\": 1024\n    })\n    prompt_template: str = \"\"\n    context_keys: list[str] = field(default_factory=list)  # Keys aus shared state\n    output_schema: dict  = None  # JSON Schema f\u00fcr Validierung\n</code></pre> <code>PersonaConfig</code> <code>dataclass</code> \u00b6 Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>@dataclass\nclass PersonaConfig:\n    name: str\n    style: str = \"professional\"\n    personality_traits: list[str] = field(default_factory=lambda: [\"helpful\", \"concise\"])\n    tone: str = \"friendly\"\n    response_format: str = \"direct\"\n    custom_instructions: str = \"\"\n\n    format_config: FormatConfig  = None\n\n    apply_method: str = \"system_prompt\"  # \"system_prompt\" | \"post_process\" | \"both\"\n    integration_level: str = \"light\"  # \"light\" | \"medium\" | \"heavy\"\n\n    def to_system_prompt_addition(self) -&gt; str:\n        \"\"\"Convert persona to system prompt addition with format integration\"\"\"\n        if self.apply_method in [\"system_prompt\", \"both\"]:\n            additions = []\n            additions.append(f\"You are {self.name}.\")\n            additions.append(f\"Your communication style is {self.style} with a {self.tone} tone.\")\n\n            if self.personality_traits:\n                traits_str = \", \".join(self.personality_traits)\n                additions.append(f\"Your key traits are: {traits_str}.\")\n\n            if self.custom_instructions:\n                additions.append(self.custom_instructions)\n\n            # Format-spezifische Anweisungen hinzuf\u00fcgen\n            if self.format_config:\n                additions.append(\"\\n\" + self.format_config.get_combined_instructions())\n\n            return \" \".join(additions)\n        return \"\"\n\n    def update_format(self, response_format: ResponseFormat|str, text_length: TextLength|str, custom_instructions: str = \"\"):\n        \"\"\"Dynamische Format-Aktualisierung\"\"\"\n        try:\n            format_enum = ResponseFormat(response_format) if isinstance(response_format, str) else response_format\n            length_enum = TextLength(text_length) if isinstance(text_length, str) else text_length\n\n            if not self.format_config:\n                self.format_config = FormatConfig()\n\n            self.format_config.response_format = format_enum\n            self.format_config.text_length = length_enum\n\n            if custom_instructions:\n                self.format_config.custom_instructions = custom_instructions\n\n\n        except ValueError:\n            raise ValueError(f\"Invalid format '{response_format}' or length '{text_length}'\")\n\n    def should_post_process(self) -&gt; bool:\n        \"\"\"Check if post-processing should be applied\"\"\"\n        return self.apply_method in [\"post_process\", \"both\"]\n</code></pre> <code>should_post_process()</code> \u00b6 <p>Check if post-processing should be applied</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def should_post_process(self) -&gt; bool:\n    \"\"\"Check if post-processing should be applied\"\"\"\n    return self.apply_method in [\"post_process\", \"both\"]\n</code></pre> <code>to_system_prompt_addition()</code> \u00b6 <p>Convert persona to system prompt addition with format integration</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def to_system_prompt_addition(self) -&gt; str:\n    \"\"\"Convert persona to system prompt addition with format integration\"\"\"\n    if self.apply_method in [\"system_prompt\", \"both\"]:\n        additions = []\n        additions.append(f\"You are {self.name}.\")\n        additions.append(f\"Your communication style is {self.style} with a {self.tone} tone.\")\n\n        if self.personality_traits:\n            traits_str = \", \".join(self.personality_traits)\n            additions.append(f\"Your key traits are: {traits_str}.\")\n\n        if self.custom_instructions:\n            additions.append(self.custom_instructions)\n\n        # Format-spezifische Anweisungen hinzuf\u00fcgen\n        if self.format_config:\n            additions.append(\"\\n\" + self.format_config.get_combined_instructions())\n\n        return \" \".join(additions)\n    return \"\"\n</code></pre> <code>update_format(response_format, text_length, custom_instructions='')</code> \u00b6 <p>Dynamische Format-Aktualisierung</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def update_format(self, response_format: ResponseFormat|str, text_length: TextLength|str, custom_instructions: str = \"\"):\n    \"\"\"Dynamische Format-Aktualisierung\"\"\"\n    try:\n        format_enum = ResponseFormat(response_format) if isinstance(response_format, str) else response_format\n        length_enum = TextLength(text_length) if isinstance(text_length, str) else text_length\n\n        if not self.format_config:\n            self.format_config = FormatConfig()\n\n        self.format_config.response_format = format_enum\n        self.format_config.text_length = length_enum\n\n        if custom_instructions:\n            self.format_config.custom_instructions = custom_instructions\n\n\n    except ValueError:\n        raise ValueError(f\"Invalid format '{response_format}' or length '{text_length}'\")\n</code></pre> <code>ProgressEvent</code> <code>dataclass</code> \u00b6 <p>Enhanced progress event with better error handling</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>@dataclass\nclass ProgressEvent:\n\n    \"\"\"Enhanced progress event with better error handling\"\"\"\n\n    # === 1. Kern-Attribute (F\u00fcr jedes Event) ===\n    event_type: str\n    node_name: str\n    timestamp: float = field(default_factory=time.time)\n    event_id: str = field(default_factory=lambda: str(uuid.uuid4()))\n    session_id: Optional[str] = None\n\n    # === 2. Status und Ergebnis-Attribute ===\n    status: Optional[NodeStatus] = None\n    success: Optional[bool] = None\n    duration: Optional[float] = None\n    error_details: dict[str, Any] = field(default_factory=dict)  # Strukturiert: message, type, traceback\n\n    # === 3. LLM-spezifische Attribute ===\n    llm_model: Optional[str] = None\n    llm_prompt_tokens: Optional[int] = None\n    llm_completion_tokens: Optional[int] = None\n    llm_total_tokens: Optional[int] = None\n    llm_cost: Optional[float] = None\n    llm_input: Optional[Any] = None  # Optional f\u00fcr Debugging, kann gro\u00df sein\n    llm_output: Optional[str] = None # Optional f\u00fcr Debugging, kann gro\u00df sein\n\n    # === 4. Tool-spezifische Attribute ===\n    tool_name: Optional[str] = None\n    is_meta_tool: Optional[bool] = None\n    tool_args: Optional[dict[str, Any]] = None\n    tool_result: Optional[Any] = None\n    tool_error: Optional[str] = None\n    llm_temperature: Optional[float]  = None\n\n    # === 5. Strategie- und Kontext-Attribute ===\n    agent_name: Optional[str] = None\n    task_id: Optional[str] = None\n    plan_id: Optional[str] = None\n\n\n    # Node/Routing data\n    routing_decision: Optional[str] = None\n    node_phase: Optional[str] = None\n    node_duration: Optional[float] = None\n\n    # === 6. Metadaten (F\u00fcr alles andere) ===\n    metadata: dict[str, Any] = field(default_factory=dict)\n\n\n    def __post_init__(self):\n\n        if self.timestamp is None:\n            self.timestamp = time.time()\n\n        if self.metadata is None:\n            self.metadata = {}\n        if not self.event_id:\n            self.event_id = f\"{self.node_name}_{self.event_type}_{int(self.timestamp * 1000000)}\"\n        if 'error' in self.metadata or 'error_type' in self.metadata:\n            if self.error_details is None:\n                self.error_details = {}\n            self.error_details['error'] = self.metadata.get('error')\n            self.error_details['error_type'] = self.metadata.get('error_type')\n            self.status = NodeStatus.FAILED\n        if self.status == NodeStatus.FAILED:\n            self.success = False\n        if self.status == NodeStatus.COMPLETED:\n            self.success = True\n\n    def _to_dict(self) -&gt; dict[str, Any]:\n        \"\"\"Convert ProgressEvent to dictionary with proper handling of all field types\"\"\"\n        result = {}\n\n        # Get all fields from the dataclass\n        for field in fields(self):\n            value = getattr(self, field.name)\n\n            # Handle None values\n            if value is None:\n                result[field.name] = None\n                continue\n\n            # Handle NodeStatus enum\n            if isinstance(value, NodeStatus | Enum):\n                result[field.name] = value.value\n            # Handle dataclass objects\n            elif is_dataclass(value):\n                result[field.name] = asdict(value)\n            # Handle dictionaries (recursively process nested enums/dataclasses)\n            elif isinstance(value, dict):\n                result[field.name] = self._process_dict(value)\n            # Handle lists (recursively process nested items)\n            elif isinstance(value, list):\n                result[field.name] = self._process_list(value)\n            # Handle primitive types\n            else:\n                result[field.name] = value\n\n        return result\n\n    def _process_dict(self, d: dict[str, Any]) -&gt; dict[str, Any]:\n        \"\"\"Recursively process dictionary values\"\"\"\n        result = {}\n        for k, v in d.items():\n            if isinstance(v, Enum):\n                result[k] = v.value\n            elif is_dataclass(v):\n                result[k] = asdict(v)\n            elif isinstance(v, dict):\n                result[k] = self._process_dict(v)\n            elif isinstance(v, list):\n                result[k] = self._process_list(v)\n            else:\n                result[k] = v\n        return result\n\n    def _process_list(self, lst: list[Any]) -&gt; list[Any]:\n        \"\"\"Recursively process list items\"\"\"\n        result = []\n        for item in lst:\n            if isinstance(item, Enum):\n                result.append(item.value)\n            elif is_dataclass(item):\n                result.append(asdict(item))\n            elif isinstance(item, dict):\n                result.append(self._process_dict(item))\n            elif isinstance(item, list):\n                result.append(self._process_list(item))\n            else:\n                result.append(item)\n        return result\n\n    @classmethod\n    def from_dict(cls, data: dict[str, Any]) -&gt; 'ProgressEvent':\n        \"\"\"Create ProgressEvent from dictionary\"\"\"\n        # Create a copy to avoid modifying the original\n        data_copy = dict(data)\n\n        # Handle NodeStatus enum conversion from string back to enum\n        if 'status' in data_copy and data_copy['status'] is not None:\n            if isinstance(data_copy['status'], str):\n                try:\n                    data_copy['status'] = NodeStatus(data_copy['status'])\n                except (ValueError, TypeError):\n                    # If invalid status value, set to None\n                    data_copy['status'] = None\n\n        # Filter out any keys that aren't valid dataclass fields\n        field_names = {field.name for field in fields(cls)}\n        filtered_data = {k: v for k, v in data_copy.items() if k in field_names}\n\n        # Ensure metadata is properly initialized\n        if 'metadata' not in filtered_data or filtered_data['metadata'] is None:\n            filtered_data['metadata'] = {}\n\n        return cls(**filtered_data)\n\n    def to_dict(self) -&gt; dict[str, Any]:\n        \"\"\"Return event data with None values removed for compact display\"\"\"\n        data = self._to_dict()\n\n        def clean_dict(d):\n            if isinstance(d, dict):\n                return {k: clean_dict(v) for k, v in d.items()\n                        if v is not None and v != {} and v != [] and v != ''}\n            elif isinstance(d, list):\n                cleaned_list = [clean_dict(item) for item in d if item is not None]\n                return [item for item in cleaned_list if item != {} and item != []]\n            return d\n\n        return clean_dict(data)\n\n    def get_chat_display_data(self) -&gt; dict[str, Any]:\n        \"\"\"Get data optimized for chat view display\"\"\"\n        filtered = self.filter_none_values()\n\n        # Core fields always shown\n        core_data = {\n            'event_type': filtered.get('event_type'),\n            'node_name': filtered.get('node_name'),\n            'timestamp': filtered.get('timestamp'),\n            'event_id': filtered.get('event_id'),\n            'status': filtered.get('status')\n        }\n\n        # Add specific fields based on event type\n        if self.event_type == 'outline_created':\n            if 'metadata' in filtered:\n                core_data['outline_steps'] = len(filtered['metadata'].get('outline', []))\n        elif self.event_type == 'reasoning_loop':\n            if 'metadata' in filtered:\n                core_data.update({\n                    'loop_number': filtered['metadata'].get('loop_number'),\n                    'outline_step': filtered['metadata'].get('outline_step'),\n                    'context_size': filtered['metadata'].get('context_size')\n                })\n        elif self.event_type == 'tool_call':\n            core_data.update({\n                'tool_name': filtered.get('tool_name'),\n                'is_meta_tool': filtered.get('is_meta_tool')\n            })\n        elif self.event_type == 'llm_call':\n            core_data.update({\n                'llm_model': filtered.get('llm_model'),\n                'llm_total_tokens': filtered.get('llm_total_tokens'),\n                'llm_cost': filtered.get('llm_cost')\n            })\n\n        # Remove None values from core_data\n        return {k: v for k, v in core_data.items() if v is not None}\n\n    def get_detailed_display_data(self) -&gt; dict[str, Any]:\n        \"\"\"Get complete filtered data for detailed popup view\"\"\"\n        return self.filter_none_values()\n\n    def get_progress_summary(self) -&gt; str:\n        \"\"\"Get a brief summary for progress sidebar\"\"\"\n        if self.event_type == 'reasoning_loop' and 'metadata' in self.filter_none_values():\n            metadata = self.filter_none_values()['metadata']\n            loop_num = metadata.get('loop_number', '?')\n            step = metadata.get('outline_step', '?')\n            return f\"Loop {loop_num}, Step {step}\"\n        elif self.event_type == 'tool_call':\n            tool_name = self.tool_name or 'Unknown Tool'\n            return f\"{'Meta ' if self.is_meta_tool else ''}{tool_name}\"\n        elif self.event_type == 'llm_call':\n            model = self.llm_model or 'Unknown Model'\n            tokens = self.llm_total_tokens\n            return f\"{model} ({tokens} tokens)\" if tokens else model\n        else:\n            return self.event_type.replace('_', ' ').title()\n</code></pre> <code>from_dict(data)</code> <code>classmethod</code> \u00b6 <p>Create ProgressEvent from dictionary</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: dict[str, Any]) -&gt; 'ProgressEvent':\n    \"\"\"Create ProgressEvent from dictionary\"\"\"\n    # Create a copy to avoid modifying the original\n    data_copy = dict(data)\n\n    # Handle NodeStatus enum conversion from string back to enum\n    if 'status' in data_copy and data_copy['status'] is not None:\n        if isinstance(data_copy['status'], str):\n            try:\n                data_copy['status'] = NodeStatus(data_copy['status'])\n            except (ValueError, TypeError):\n                # If invalid status value, set to None\n                data_copy['status'] = None\n\n    # Filter out any keys that aren't valid dataclass fields\n    field_names = {field.name for field in fields(cls)}\n    filtered_data = {k: v for k, v in data_copy.items() if k in field_names}\n\n    # Ensure metadata is properly initialized\n    if 'metadata' not in filtered_data or filtered_data['metadata'] is None:\n        filtered_data['metadata'] = {}\n\n    return cls(**filtered_data)\n</code></pre> <code>get_chat_display_data()</code> \u00b6 <p>Get data optimized for chat view display</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def get_chat_display_data(self) -&gt; dict[str, Any]:\n    \"\"\"Get data optimized for chat view display\"\"\"\n    filtered = self.filter_none_values()\n\n    # Core fields always shown\n    core_data = {\n        'event_type': filtered.get('event_type'),\n        'node_name': filtered.get('node_name'),\n        'timestamp': filtered.get('timestamp'),\n        'event_id': filtered.get('event_id'),\n        'status': filtered.get('status')\n    }\n\n    # Add specific fields based on event type\n    if self.event_type == 'outline_created':\n        if 'metadata' in filtered:\n            core_data['outline_steps'] = len(filtered['metadata'].get('outline', []))\n    elif self.event_type == 'reasoning_loop':\n        if 'metadata' in filtered:\n            core_data.update({\n                'loop_number': filtered['metadata'].get('loop_number'),\n                'outline_step': filtered['metadata'].get('outline_step'),\n                'context_size': filtered['metadata'].get('context_size')\n            })\n    elif self.event_type == 'tool_call':\n        core_data.update({\n            'tool_name': filtered.get('tool_name'),\n            'is_meta_tool': filtered.get('is_meta_tool')\n        })\n    elif self.event_type == 'llm_call':\n        core_data.update({\n            'llm_model': filtered.get('llm_model'),\n            'llm_total_tokens': filtered.get('llm_total_tokens'),\n            'llm_cost': filtered.get('llm_cost')\n        })\n\n    # Remove None values from core_data\n    return {k: v for k, v in core_data.items() if v is not None}\n</code></pre> <code>get_detailed_display_data()</code> \u00b6 <p>Get complete filtered data for detailed popup view</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def get_detailed_display_data(self) -&gt; dict[str, Any]:\n    \"\"\"Get complete filtered data for detailed popup view\"\"\"\n    return self.filter_none_values()\n</code></pre> <code>get_progress_summary()</code> \u00b6 <p>Get a brief summary for progress sidebar</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def get_progress_summary(self) -&gt; str:\n    \"\"\"Get a brief summary for progress sidebar\"\"\"\n    if self.event_type == 'reasoning_loop' and 'metadata' in self.filter_none_values():\n        metadata = self.filter_none_values()['metadata']\n        loop_num = metadata.get('loop_number', '?')\n        step = metadata.get('outline_step', '?')\n        return f\"Loop {loop_num}, Step {step}\"\n    elif self.event_type == 'tool_call':\n        tool_name = self.tool_name or 'Unknown Tool'\n        return f\"{'Meta ' if self.is_meta_tool else ''}{tool_name}\"\n    elif self.event_type == 'llm_call':\n        model = self.llm_model or 'Unknown Model'\n        tokens = self.llm_total_tokens\n        return f\"{model} ({tokens} tokens)\" if tokens else model\n    else:\n        return self.event_type.replace('_', ' ').title()\n</code></pre> <code>to_dict()</code> \u00b6 <p>Return event data with None values removed for compact display</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Return event data with None values removed for compact display\"\"\"\n    data = self._to_dict()\n\n    def clean_dict(d):\n        if isinstance(d, dict):\n            return {k: clean_dict(v) for k, v in d.items()\n                    if v is not None and v != {} and v != [] and v != ''}\n        elif isinstance(d, list):\n            cleaned_list = [clean_dict(item) for item in d if item is not None]\n            return [item for item in cleaned_list if item != {} and item != []]\n        return d\n\n    return clean_dict(data)\n</code></pre> <code>ProgressTracker</code> \u00b6 <p>Advanced progress tracking with cost calculation</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>class ProgressTracker:\n    \"\"\"Advanced progress tracking with cost calculation\"\"\"\n\n    def __init__(self, progress_callback: callable  = None, agent_name=\"unknown\"):\n        self.progress_callback = progress_callback\n        self.events: list[ProgressEvent] = []\n        self.active_timers: dict[str, float] = {}\n\n        # Cost tracking (simplified - would need actual provider pricing)\n        self.token_costs = {\n            \"input\": 0.00001,  # $0.01/1K tokens input\n            \"output\": 0.00003,  # $0.03/1K tokens output\n        }\n        self.agent_name = agent_name\n\n    async def emit_event(self, event: ProgressEvent):\n        \"\"\"Emit progress event with callback and storage\"\"\"\n        self.events.append(event)\n        event.agent_name = self.agent_name\n\n        if self.progress_callback:\n            try:\n                if asyncio.iscoroutinefunction(self.progress_callback):\n                    await self.progress_callback(event)\n                else:\n                    self.progress_callback(event)\n            except Exception:\n                import traceback\n                print(traceback.format_exc())\n\n\n    def start_timer(self, key: str) -&gt; float:\n        \"\"\"Start timing operation\"\"\"\n        start_time = time.perf_counter()\n        self.active_timers[key] = start_time\n        return start_time\n\n    def end_timer(self, key: str) -&gt; float:\n        \"\"\"End timing operation and return duration\"\"\"\n        if key not in self.active_timers:\n            return 0.0\n        duration = time.perf_counter() - self.active_timers[key]\n        del self.active_timers[key]\n        return duration\n\n    def calculate_llm_cost(self, model: str, input_tokens: int, output_tokens: int,completion_response:Any=None) -&gt; float:\n        \"\"\"Calculate approximate LLM cost\"\"\"\n        try:\n            import litellm\n            cost = litellm.completion_cost(model=model, completion_response=completion_response)\n            return cost\n        except ImportError:\n            cost = 0.0\n        # Simplified cost calculation - would need actual provider pricing\n        input_cost = (input_tokens / 1000) * self.token_costs[\"input\"]\n        output_cost = (output_tokens / 1000) * self.token_costs[\"output\"]\n        return input_cost + output_cost\n\n    def get_summary(self) -&gt; dict[str, Any]:\n        \"\"\"Get comprehensive progress summary\"\"\"\n        summary = {\n            \"total_events\": len(self.events),\n            \"llm_calls\": len([e for e in self.events if e.event_type == \"llm_call\"]),\n            \"tool_calls\": len([e for e in self.events if e.event_type == \"tool_call\"]),\n            \"total_cost\": sum(e.llm_cost for e in self.events if e.llm_cost),\n            \"total_tokens\": sum(e.llm_total_tokens for e in self.events if e.llm_total_tokens),\n            \"total_duration\": sum(e.node_duration for e in self.events if e.node_duration),\n            \"nodes_visited\": list(set(e.node_name for e in self.events)),\n            \"tools_used\": list(set(e.tool_name for e in self.events if e.tool_name)),\n            \"models_used\": list(set(e.llm_model for e in self.events if e.llm_model))\n        }\n        return summary\n</code></pre> <code>calculate_llm_cost(model, input_tokens, output_tokens, completion_response=None)</code> \u00b6 <p>Calculate approximate LLM cost</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def calculate_llm_cost(self, model: str, input_tokens: int, output_tokens: int,completion_response:Any=None) -&gt; float:\n    \"\"\"Calculate approximate LLM cost\"\"\"\n    try:\n        import litellm\n        cost = litellm.completion_cost(model=model, completion_response=completion_response)\n        return cost\n    except ImportError:\n        cost = 0.0\n    # Simplified cost calculation - would need actual provider pricing\n    input_cost = (input_tokens / 1000) * self.token_costs[\"input\"]\n    output_cost = (output_tokens / 1000) * self.token_costs[\"output\"]\n    return input_cost + output_cost\n</code></pre> <code>emit_event(event)</code> <code>async</code> \u00b6 <p>Emit progress event with callback and storage</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>async def emit_event(self, event: ProgressEvent):\n    \"\"\"Emit progress event with callback and storage\"\"\"\n    self.events.append(event)\n    event.agent_name = self.agent_name\n\n    if self.progress_callback:\n        try:\n            if asyncio.iscoroutinefunction(self.progress_callback):\n                await self.progress_callback(event)\n            else:\n                self.progress_callback(event)\n        except Exception:\n            import traceback\n            print(traceback.format_exc())\n</code></pre> <code>end_timer(key)</code> \u00b6 <p>End timing operation and return duration</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def end_timer(self, key: str) -&gt; float:\n    \"\"\"End timing operation and return duration\"\"\"\n    if key not in self.active_timers:\n        return 0.0\n    duration = time.perf_counter() - self.active_timers[key]\n    del self.active_timers[key]\n    return duration\n</code></pre> <code>get_summary()</code> \u00b6 <p>Get comprehensive progress summary</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def get_summary(self) -&gt; dict[str, Any]:\n    \"\"\"Get comprehensive progress summary\"\"\"\n    summary = {\n        \"total_events\": len(self.events),\n        \"llm_calls\": len([e for e in self.events if e.event_type == \"llm_call\"]),\n        \"tool_calls\": len([e for e in self.events if e.event_type == \"tool_call\"]),\n        \"total_cost\": sum(e.llm_cost for e in self.events if e.llm_cost),\n        \"total_tokens\": sum(e.llm_total_tokens for e in self.events if e.llm_total_tokens),\n        \"total_duration\": sum(e.node_duration for e in self.events if e.node_duration),\n        \"nodes_visited\": list(set(e.node_name for e in self.events)),\n        \"tools_used\": list(set(e.tool_name for e in self.events if e.tool_name)),\n        \"models_used\": list(set(e.llm_model for e in self.events if e.llm_model))\n    }\n    return summary\n</code></pre> <code>start_timer(key)</code> \u00b6 <p>Start timing operation</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def start_timer(self, key: str) -&gt; float:\n    \"\"\"Start timing operation\"\"\"\n    start_time = time.perf_counter()\n    self.active_timers[key] = start_time\n    return start_time\n</code></pre> <code>Task</code> <code>dataclass</code> \u00b6 Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>@dataclass\nclass Task:\n    id: str\n    type: str\n    description: str\n    status: str = \"pending\"  # pending, running, completed, failed, paused\n    priority: int = 1\n    dependencies: list[str] = field(default_factory=list)\n    subtasks: list[str] = field(default_factory=list)\n    result: Any = None\n    error: str = None\n    created_at: datetime = field(default_factory=datetime.now)\n    started_at: datetime  = None\n    completed_at: datetime  = None\n    metadata: dict[str, Any] = field(default_factory=dict)\n    retry_count: int = 0\n    max_retries: int = 3\n    critical: bool = False\n\n    task_identification_attr: bool = True\n\n\n    def __post_init__(self):\n        \"\"\"Ensure all mutable defaults are properly initialized\"\"\"\n        if self.metadata is None:\n            self.metadata = {}\n        if self.dependencies is None:\n            self.dependencies = []\n        if self.subtasks is None:\n            self.subtasks = []\n\n    def __getitem__(self, key):\n        return getattr(self, key)\n\n    def __setitem__(self, key, value):\n        setattr(self, key, value)\n</code></pre> <code>__post_init__()</code> \u00b6 <p>Ensure all mutable defaults are properly initialized</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def __post_init__(self):\n    \"\"\"Ensure all mutable defaults are properly initialized\"\"\"\n    if self.metadata is None:\n        self.metadata = {}\n    if self.dependencies is None:\n        self.dependencies = []\n    if self.subtasks is None:\n        self.subtasks = []\n</code></pre> <code>ToolAnalysis</code> \u00b6 <p>               Bases: <code>BaseModel</code></p> <p>Defines the structure for a valid tool analysis.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>class ToolAnalysis(BaseModel):\n    \"\"\"Defines the structure for a valid tool analysis.\"\"\"\n    primary_function: str = Field(..., description=\"The main purpose of the tool.\")\n    use_cases: list[str] = Field(..., description=\"Specific use cases for the tool.\")\n    trigger_phrases: list[str] = Field(..., description=\"Phrases that should trigger the tool.\")\n    indirect_connections: list[str] = Field(..., description=\"Non-obvious connections or applications.\")\n    complexity_scenarios: list[str] = Field(..., description=\"Complex scenarios where the tool can be applied.\")\n    user_intent_categories: list[str] = Field(..., description=\"Categories of user intent the tool addresses.\")\n    confidence_triggers: dict[str, float] = Field(..., description=\"Phrases mapped to confidence scores.\")\n    tool_complexity: str = Field(..., description=\"The complexity of the tool, rated as low, medium, or high.\")\n    args_schema: dict[str, Any] | None = Field(..., description=\"The schema for the tool's arguments.\")\n</code></pre> <code>ToolTask</code> <code>dataclass</code> \u00b6 <p>               Bases: <code>Task</code></p> <p>Spezialisierter Task f\u00fcr Tool-Aufrufe</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>@dataclass\nclass ToolTask(Task):\n    \"\"\"Spezialisierter Task f\u00fcr Tool-Aufrufe\"\"\"\n    tool_name: str = \"\"\n    arguments: dict[str, Any] = field(default_factory=dict)  # Kann {{ }} Referenzen enthalten\n    hypothesis: str = \"\"  # Was erwarten wir von diesem Tool?\n    validation_criteria: str = \"\"  # Wie validieren wir das Ergebnis?\n    expectation: str = \"\"  # Wie sollte das Ergebnis aussehen?\n</code></pre> <code>create_task(task_type, **kwargs)</code> \u00b6 <p>Factory f\u00fcr Task-Erstellung mit korrektem Typ</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/types.py</code> <pre><code>def create_task(task_type: str, **kwargs) -&gt; Task:\n    \"\"\"Factory f\u00fcr Task-Erstellung mit korrektem Typ\"\"\"\n    task_classes = {\n        \"llm_call\": LLMTask,\n        \"tool_call\": ToolTask,\n        \"decision\": DecisionTask,\n        \"generic\": Task,\n        \"LLMTask\": LLMTask,\n        \"ToolTask\": ToolTask,\n        \"DecisionTask\": DecisionTask,\n        \"Task\": Task,\n    }\n\n    task_class = task_classes.get(task_type, Task)\n\n    # Standard-Felder setzen\n    if \"id\" not in kwargs:\n        kwargs[\"id\"] = str(uuid.uuid4())\n    if \"type\" not in kwargs:\n        kwargs[\"type\"] = task_type\n    if \"critical\" not in kwargs:\n        kwargs[\"critical\"] = task_type in [\"llm_call\", \"decision\"]\n\n    # Ensure metadata is initialized\n    if \"metadata\" not in kwargs:\n        kwargs[\"metadata\"] = {}\n\n    # Create task and ensure post_init is called\n    task = task_class(**kwargs)\n\n    # Double-check metadata initialization\n    if not hasattr(task, 'metadata') or task.metadata is None:\n        task.metadata = {}\n\n    return task\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.Agent.utils","title":"<code>utils</code>","text":"<code>LLMMessage</code> <code>dataclass</code> \u00b6 <p>Represents a message in a conversation with the LLM.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/utils.py</code> <pre><code>@dataclass\nclass LLMMessage:\n    \"\"\"Represents a message in a conversation with the LLM.\"\"\"\n    role: str  # \"user\", \"assistant\", \"system\", \"tool\"\n    # Content can be string or list (e.g., multimodal with text/image dicts)\n    # Conforms to LiteLLM/OpenAI structure\n    content: str | list[dict[str, Any]]\n    tool_call_id: str | None = None  # For tool responses\n    name: str | None = None  # For tool calls/responses (function name)\n\n    def to_dict(self) -&gt; dict:\n        \"\"\"Convert to dictionary, handling potential dataclass nuances.\"\"\"\n        d = {\"role\": self.role, \"content\": self.content}\n        if self.tool_call_id:\n            d[\"tool_call_id\"] = self.tool_call_id\n        if self.name:\n            d[\"name\"] = self.name\n        return d\n</code></pre> <code>to_dict()</code> \u00b6 <p>Convert to dictionary, handling potential dataclass nuances.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/utils.py</code> <pre><code>def to_dict(self) -&gt; dict:\n    \"\"\"Convert to dictionary, handling potential dataclass nuances.\"\"\"\n    d = {\"role\": self.role, \"content\": self.content}\n    if self.tool_call_id:\n        d[\"tool_call_id\"] = self.tool_call_id\n    if self.name:\n        d[\"name\"] = self.name\n    return d\n</code></pre> <code>WorldModel</code> <code>dataclass</code> \u00b6 <p>Thread-safe representation of the agent's persistent understanding of the world.</p> Source code in <code>toolboxv2/mods/isaa/base/Agent/utils.py</code> <pre><code>@dataclass\nclass WorldModel:\n    \"\"\"Thread-safe representation of the agent's persistent understanding of the world.\"\"\"\n    data: dict[str, Any] = dataclass_field(default_factory=dict)\n    _lock: threading.Lock = dataclass_field(default_factory=threading.Lock)\n\n    def get(self, key: str, default: Any = None) -&gt; Any:\n        with self._lock:\n            return self.data.get(key, default)\n\n    def set(self, key: str, value: Any):\n        with self._lock:\n            logger_wm.debug(f\"WorldModel SET: {key} = {value}\")\n            self.data[key] = value\n\n    def remove(self, key: str):\n        with self._lock:\n            if key in self.data:\n                logger_wm.debug(f\"WorldModel REMOVE: {key}\")\n                del self.data[key]\n\n    def show(self) -&gt; str:\n        with self._lock:\n            if not self.data:\n                return \"[empty]\"\n            try:\n                items = [f\"- {k}: {json.dumps(v, indent=None, ensure_ascii=False, default=str)}\"\n                         for k, v in self.data.items()]\n                return \"\\n\".join(items)\n            except Exception:\n                items = [f\"- {k}: {str(v)}\" for k, v in self.data.items()]\n                return \"\\n\".join(items)\n\n    def to_dict(self) -&gt; dict[str, Any]:\n        with self._lock:\n            # Deep copy might be needed if values are mutable and modified externally\n            # For simplicity, shallow copy is used here.\n            return self.data.copy()\n\n    def update_from_dict(self, data_dict: dict[str, Any]):\n        with self._lock:\n            self.data.update(data_dict)\n            logger_wm.debug(f\"WorldModel updated from dict: {list(data_dict.keys())}\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.AgentUtils","title":"<code>AgentUtils</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.AgentUtils.AISemanticMemory","title":"<code>AISemanticMemory</code>","text":"Source code in <code>toolboxv2/mods/isaa/base/AgentUtils.py</code> <pre><code>class AISemanticMemory(metaclass=Singleton):\n    def __init__(self,\n                 base_path: str = \"/semantic_memory\",\n                 default_model: str = os.getenv(\"BLITZMODEL\"),\n                 default_embedding_model: str = os.getenv(\"DEFAULTMODELEMBEDDING\"),\n                 default_similarity_threshold: float = 0.61,\n                 default_batch_size: int = 64,\n                 default_n_clusters: int = 2,\n                 default_deduplication_threshold: float = 0.85):\n        \"\"\"\n        Initialize AISemanticMemory with KnowledgeBase integration\n\n        Args:\n            base_path: Root directory for memory storage\n            default_model: Default model for text generation\n            default_embedding_model: Default embedding model\n            default_similarity_threshold: Default similarity threshold for retrieval\n            default_batch_size: Default batch size for processing\n            default_n_clusters: Default number of clusters for FAISS\n            default_deduplication_threshold: Default threshold for deduplication\n        \"\"\"\n        self.base_path = os.path.join(os.getcwd(), \".data\", base_path)\n        self.memories: dict[str, KnowledgeBase] = {}\n\n        # Map of embedding models to their dimensions\n        self.embedding_dims = {\n            \"text-embedding-3-small\": 1536,\n            \"text-embedding-3-large\": 3072,\n            \"nomic-embed-text\": 768,\n            \"default\": 768\n        }\n\n        self.default_config = {\n            \"embedding_model\": default_embedding_model,\n            \"embedding_dim\": self._get_embedding_dim(default_embedding_model),\n            \"similarity_threshold\": default_similarity_threshold,\n            \"batch_size\": default_batch_size,\n            \"n_clusters\": default_n_clusters,\n            \"deduplication_threshold\": default_deduplication_threshold,\n            \"model_name\": default_model\n        }\n\n    def _get_embedding_dim(self, model_name: str) -&gt; int:\n        \"\"\"Get embedding dimension for a model\"\"\"\n        return self.embedding_dims.get(model_name, 768)\n\n    @staticmethod\n    def _sanitize_name(name: str) -&gt; str:\n        \"\"\"Sanitize memory name for filesystem safety\"\"\"\n        name = re.sub(r'[^a-zA-Z0-9_-]', '-', name)[:63].strip('-')\n        if not name:\n            raise ValueError(\"Invalid memory name\")\n        if len(name) &lt; 3:\n            name += \"Z\" * (3 - len(name))\n        return name\n\n    def create_memory(self,\n                      name: str,\n                      model_config: dict | None = None,\n                      storage_config: dict | None = None) -&gt; KnowledgeBase:\n        \"\"\"\n        Create new memory store with KnowledgeBase\n\n        Args:\n            name: Unique name for the memory store\n            model_config: Configuration for embedding model\n            storage_config: Configuration for KnowledgeBase parameters\n        \"\"\"\n        sanitized = self._sanitize_name(name)\n        if sanitized in self.memories:\n            raise ValueError(f\"Memory '{name}' already exists\")\n\n        # Determine embedding model and dimension\n        embedding_model = self.default_config[\"embedding_model\"]\n        model_name = self.default_config[\"model_name\"]\n        if model_config:\n            embedding_model = model_config.get(\"embedding_model\", embedding_model)\n            model_name = model_config.get(\"model_name\", model_name)\n        embedding_dim = self._get_embedding_dim(embedding_model)\n\n        # Get KnowledgeBase parameters\n        kb_params = {\n            \"embedding_dim\": embedding_dim,\n            \"embedding_model\": embedding_model,\n            \"similarity_threshold\": self.default_config[\"similarity_threshold\"],\n            \"batch_size\": self.default_config[\"batch_size\"],\n            \"n_clusters\": self.default_config[\"n_clusters\"],\n            \"deduplication_threshold\": self.default_config[\"deduplication_threshold\"],\n            \"model_name\": model_name,\n        }\n\n        if storage_config:\n            kb_params.update({\n                \"similarity_threshold\": storage_config.get(\"similarity_threshold\", kb_params[\"similarity_threshold\"]),\n                \"batch_size\": storage_config.get(\"batch_size\", kb_params[\"batch_size\"]),\n                \"n_clusters\": storage_config.get(\"n_clusters\", kb_params[\"n_clusters\"]),\n                \"model_name\": storage_config.get(\"model_name\", kb_params[\"model_name\"]),\n                \"embedding_model\": storage_config.get(\"embedding_model\", kb_params[\"embedding_model\"]),\n                \"deduplication_threshold\": storage_config.get(\"deduplication_threshold\",\n                                                              kb_params[\"deduplication_threshold\"]),\n            })\n\n        # Create KnowledgeBase instance\n        self.memories[sanitized] = KnowledgeBase(**kb_params)\n        return self.memories[sanitized]\n\n    async def add_data(self,\n                       memory_name: str,\n                       data: str | list[str] | bytes | dict,\n                       metadata: dict | None = None, direct=False) -&gt; bool:\n        \"\"\"\n        Add data to memory store\n\n        Args:\n            memory_name: Target memory store\n            data: Text, list of texts, binary file, or structured data\n            metadata: Optional metadata\n        \"\"\"\n        name = self._sanitize_name(memory_name)\n        kb = self.memories.get(name)\n        if not kb:\n            kb = self.create_memory(name)\n\n        # Process input data\n        texts = []\n        if isinstance(data, bytes):\n            try:\n                text = extract_text_natively(data, filename=\"\" if metadata is None else metadata.get(\"filename\", \"\"))\n                texts = [text.replace('\\\\t', '').replace('\\t', '')]\n            except Exception as e:\n                raise ValueError(f\"File processing failed: {str(e)}\")\n        elif isinstance(data, str):\n            texts = [data.replace('\\\\t', '').replace('\\t', '')]\n        elif isinstance(data, list):\n            texts = [d.replace('\\\\t', '').replace('\\t', '') for d in data]\n        elif isinstance(data, dict):\n            # Custom KG not supported in current KnowledgeBase\n            raise NotImplementedError(\"Custom knowledge graph insertion not supported\")\n        else:\n            raise ValueError(\"Unsupported data type\")\n\n        # Add data to KnowledgeBase\n        try:\n            added, duplicates = await kb.add_data(texts, metadata, direct=direct)\n            return added &gt; 0\n        except Exception as e:\n            import traceback\n            print(traceback.format_exc())\n            raise RuntimeError(f\"Data addition failed: {str(e)}\")\n\n    def get(self, names):\n        return [m for n,m in self._get_target_memories(names)]\n\n    async def query(self,\n                    query: str,\n                    memory_names: str | list[str] | None = None,\n                    query_params: dict | None = None,\n                    to_str: bool = False,\n                    unified_retrieve: bool =False) -&gt; str | list[dict]:\n        \"\"\"\n        Query memories using KnowledgeBase retrieval\n\n        Args:\n            query: Search query\n            memory_names: Target memory names\n            query_params: Query parameters\n            to_str: Return string format\n            unified_retrieve: Unified retrieve\n        \"\"\"\n        targets = self._get_target_memories(memory_names)\n        if not targets:\n            return []\n\n        results = []\n        for name, kb in targets:\n            #try:\n                # Use KnowledgeBase's retrieve_with_overview for comprehensive results\n                result = await kb.retrieve_with_overview(\n                    query=query,\n                    k=query_params.get(\"k\", 3) if query_params else 3,\n                    min_similarity=query_params.get(\"min_similarity\", 0.2) if query_params else 0.2,\n                    cross_ref_depth=query_params.get(\"cross_ref_depth\", 2) if query_params else 2,\n                    max_cross_refs=query_params.get(\"max_cross_refs\", 2) if query_params else 2,\n                    max_sentences=query_params.get(\"max_sentences\", 5) if query_params else 5\n                ) if not unified_retrieve else await kb.unified_retrieve(\n                    query=query,\n                    k=query_params.get(\"k\", 2) if query_params else 2,\n                    min_similarity=query_params.get(\"min_similarity\", 0.2) if query_params else 0.2,\n                    cross_ref_depth=query_params.get(\"cross_ref_depth\", 2) if query_params else 2,\n                    max_cross_refs=query_params.get(\"max_cross_refs\", 6) if query_params else 6,\n                    max_sentences=query_params.get(\"max_sentences\", 12) if query_params else 12\n                )\n                results.append({\n                    \"memory\": name,\n                    \"result\": result\n                })\n            #except Exception as e:\n            #    print(f\"Query failed on {name}: {str(e)}\")\n        if to_str:\n            if not unified_retrieve:\n                str_res = [\n                    f\"{x['memory']} - {json.dumps(x['result'].overview)}\\n - {[c.text for c in x['result'].details]}\\n - {[(k, [c.text for c in v]) for k, v in x['result'].cross_references.items()]}\"\n                    for x in results]\n                # str_res =\n            else:\n                str_res = json.dumps(results)\n            return str_res\n        return results\n\n    def _get_target_memories(self, memory_names: str | list[str] | None) -&gt; list[tuple[str, KnowledgeBase]]:\n        \"\"\"Get target memories for query\"\"\"\n        if not memory_names:\n            return list(self.memories.items())\n\n        names = [memory_names] if isinstance(memory_names, str) else memory_names\n\n        targets = []\n        for name in names:\n            sanitized = self._sanitize_name(name)\n            if kb := self.memories.get(sanitized):\n                targets.append((sanitized, kb))\n        return targets\n\n    def list_memories(self) -&gt; list[str]:\n        \"\"\"List all available memories\"\"\"\n        return list(self.memories.keys())\n\n    async def delete_memory(self, name: str) -&gt; bool:\n        \"\"\"Delete a memory store\"\"\"\n        sanitized = self._sanitize_name(name)\n        if sanitized in self.memories:\n            del self.memories[sanitized]\n            return True\n        return False\n\n    def save_memory(self, name: str, path: str) -&gt; bool | bytes:\n        \"\"\"Save a memory store to disk\"\"\"\n        sanitized = self._sanitize_name(name)\n        if kb := self.memories.get(sanitized):\n            try:\n                return kb.save(path)\n            except Exception as e:\n                print(f\"Error saving memory: {str(e)}\")\n                return False\n        return False\n\n    def save_all_memories(self, path: str) -&gt; bool:\n        \"\"\"Save all memory stores to disk\"\"\"\n        for name, kb in self.memories.items():\n            try:\n                kb.save(os.path.join(path, f\"{name}.pkl\"))\n            except Exception as e:\n                print(f\"Error saving memory: {str(e)}\")\n                return False\n        return True\n\n    def load_all_memories(self, path: str) -&gt; bool:\n        \"\"\"Load all memory stores from disk\"\"\"\n        for file in os.listdir(path):\n            if file.endswith(\".pkl\"):\n                try:\n                    self.memories[file[:-4]] = KnowledgeBase.load(os.path.join(path, file))\n                except EOFError:\n                    return False\n                except FileNotFoundError:\n                    return False\n                except Exception as e:\n                    print(f\"Error loading memory: {str(e)}\")\n                    return False\n        return True\n\n    def load_memory(self, name: str, path: str | bytes) -&gt; bool:\n        \"\"\"Load a memory store from disk\"\"\"\n        sanitized = self._sanitize_name(name)\n        if sanitized in self.memories:\n            return False\n        try:\n            self.memories[sanitized] = KnowledgeBase.load(path)\n            return True\n        except Exception:\n            # print(f\"Error loading memory: {str(e)}\")\n            return False\n</code></pre> <code>__init__(base_path='/semantic_memory', default_model=os.getenv('BLITZMODEL'), default_embedding_model=os.getenv('DEFAULTMODELEMBEDDING'), default_similarity_threshold=0.61, default_batch_size=64, default_n_clusters=2, default_deduplication_threshold=0.85)</code> \u00b6 <p>Initialize AISemanticMemory with KnowledgeBase integration</p> <p>Parameters:</p> Name Type Description Default <code>base_path</code> <code>str</code> <p>Root directory for memory storage</p> <code>'/semantic_memory'</code> <code>default_model</code> <code>str</code> <p>Default model for text generation</p> <code>getenv('BLITZMODEL')</code> <code>default_embedding_model</code> <code>str</code> <p>Default embedding model</p> <code>getenv('DEFAULTMODELEMBEDDING')</code> <code>default_similarity_threshold</code> <code>float</code> <p>Default similarity threshold for retrieval</p> <code>0.61</code> <code>default_batch_size</code> <code>int</code> <p>Default batch size for processing</p> <code>64</code> <code>default_n_clusters</code> <code>int</code> <p>Default number of clusters for FAISS</p> <code>2</code> <code>default_deduplication_threshold</code> <code>float</code> <p>Default threshold for deduplication</p> <code>0.85</code> Source code in <code>toolboxv2/mods/isaa/base/AgentUtils.py</code> <pre><code>def __init__(self,\n             base_path: str = \"/semantic_memory\",\n             default_model: str = os.getenv(\"BLITZMODEL\"),\n             default_embedding_model: str = os.getenv(\"DEFAULTMODELEMBEDDING\"),\n             default_similarity_threshold: float = 0.61,\n             default_batch_size: int = 64,\n             default_n_clusters: int = 2,\n             default_deduplication_threshold: float = 0.85):\n    \"\"\"\n    Initialize AISemanticMemory with KnowledgeBase integration\n\n    Args:\n        base_path: Root directory for memory storage\n        default_model: Default model for text generation\n        default_embedding_model: Default embedding model\n        default_similarity_threshold: Default similarity threshold for retrieval\n        default_batch_size: Default batch size for processing\n        default_n_clusters: Default number of clusters for FAISS\n        default_deduplication_threshold: Default threshold for deduplication\n    \"\"\"\n    self.base_path = os.path.join(os.getcwd(), \".data\", base_path)\n    self.memories: dict[str, KnowledgeBase] = {}\n\n    # Map of embedding models to their dimensions\n    self.embedding_dims = {\n        \"text-embedding-3-small\": 1536,\n        \"text-embedding-3-large\": 3072,\n        \"nomic-embed-text\": 768,\n        \"default\": 768\n    }\n\n    self.default_config = {\n        \"embedding_model\": default_embedding_model,\n        \"embedding_dim\": self._get_embedding_dim(default_embedding_model),\n        \"similarity_threshold\": default_similarity_threshold,\n        \"batch_size\": default_batch_size,\n        \"n_clusters\": default_n_clusters,\n        \"deduplication_threshold\": default_deduplication_threshold,\n        \"model_name\": default_model\n    }\n</code></pre> <code>add_data(memory_name, data, metadata=None, direct=False)</code> <code>async</code> \u00b6 <p>Add data to memory store</p> <p>Parameters:</p> Name Type Description Default <code>memory_name</code> <code>str</code> <p>Target memory store</p> required <code>data</code> <code>str | list[str] | bytes | dict</code> <p>Text, list of texts, binary file, or structured data</p> required <code>metadata</code> <code>dict | None</code> <p>Optional metadata</p> <code>None</code> Source code in <code>toolboxv2/mods/isaa/base/AgentUtils.py</code> <pre><code>async def add_data(self,\n                   memory_name: str,\n                   data: str | list[str] | bytes | dict,\n                   metadata: dict | None = None, direct=False) -&gt; bool:\n    \"\"\"\n    Add data to memory store\n\n    Args:\n        memory_name: Target memory store\n        data: Text, list of texts, binary file, or structured data\n        metadata: Optional metadata\n    \"\"\"\n    name = self._sanitize_name(memory_name)\n    kb = self.memories.get(name)\n    if not kb:\n        kb = self.create_memory(name)\n\n    # Process input data\n    texts = []\n    if isinstance(data, bytes):\n        try:\n            text = extract_text_natively(data, filename=\"\" if metadata is None else metadata.get(\"filename\", \"\"))\n            texts = [text.replace('\\\\t', '').replace('\\t', '')]\n        except Exception as e:\n            raise ValueError(f\"File processing failed: {str(e)}\")\n    elif isinstance(data, str):\n        texts = [data.replace('\\\\t', '').replace('\\t', '')]\n    elif isinstance(data, list):\n        texts = [d.replace('\\\\t', '').replace('\\t', '') for d in data]\n    elif isinstance(data, dict):\n        # Custom KG not supported in current KnowledgeBase\n        raise NotImplementedError(\"Custom knowledge graph insertion not supported\")\n    else:\n        raise ValueError(\"Unsupported data type\")\n\n    # Add data to KnowledgeBase\n    try:\n        added, duplicates = await kb.add_data(texts, metadata, direct=direct)\n        return added &gt; 0\n    except Exception as e:\n        import traceback\n        print(traceback.format_exc())\n        raise RuntimeError(f\"Data addition failed: {str(e)}\")\n</code></pre> <code>create_memory(name, model_config=None, storage_config=None)</code> \u00b6 <p>Create new memory store with KnowledgeBase</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Unique name for the memory store</p> required <code>model_config</code> <code>dict | None</code> <p>Configuration for embedding model</p> <code>None</code> <code>storage_config</code> <code>dict | None</code> <p>Configuration for KnowledgeBase parameters</p> <code>None</code> Source code in <code>toolboxv2/mods/isaa/base/AgentUtils.py</code> <pre><code>def create_memory(self,\n                  name: str,\n                  model_config: dict | None = None,\n                  storage_config: dict | None = None) -&gt; KnowledgeBase:\n    \"\"\"\n    Create new memory store with KnowledgeBase\n\n    Args:\n        name: Unique name for the memory store\n        model_config: Configuration for embedding model\n        storage_config: Configuration for KnowledgeBase parameters\n    \"\"\"\n    sanitized = self._sanitize_name(name)\n    if sanitized in self.memories:\n        raise ValueError(f\"Memory '{name}' already exists\")\n\n    # Determine embedding model and dimension\n    embedding_model = self.default_config[\"embedding_model\"]\n    model_name = self.default_config[\"model_name\"]\n    if model_config:\n        embedding_model = model_config.get(\"embedding_model\", embedding_model)\n        model_name = model_config.get(\"model_name\", model_name)\n    embedding_dim = self._get_embedding_dim(embedding_model)\n\n    # Get KnowledgeBase parameters\n    kb_params = {\n        \"embedding_dim\": embedding_dim,\n        \"embedding_model\": embedding_model,\n        \"similarity_threshold\": self.default_config[\"similarity_threshold\"],\n        \"batch_size\": self.default_config[\"batch_size\"],\n        \"n_clusters\": self.default_config[\"n_clusters\"],\n        \"deduplication_threshold\": self.default_config[\"deduplication_threshold\"],\n        \"model_name\": model_name,\n    }\n\n    if storage_config:\n        kb_params.update({\n            \"similarity_threshold\": storage_config.get(\"similarity_threshold\", kb_params[\"similarity_threshold\"]),\n            \"batch_size\": storage_config.get(\"batch_size\", kb_params[\"batch_size\"]),\n            \"n_clusters\": storage_config.get(\"n_clusters\", kb_params[\"n_clusters\"]),\n            \"model_name\": storage_config.get(\"model_name\", kb_params[\"model_name\"]),\n            \"embedding_model\": storage_config.get(\"embedding_model\", kb_params[\"embedding_model\"]),\n            \"deduplication_threshold\": storage_config.get(\"deduplication_threshold\",\n                                                          kb_params[\"deduplication_threshold\"]),\n        })\n\n    # Create KnowledgeBase instance\n    self.memories[sanitized] = KnowledgeBase(**kb_params)\n    return self.memories[sanitized]\n</code></pre> <code>delete_memory(name)</code> <code>async</code> \u00b6 <p>Delete a memory store</p> Source code in <code>toolboxv2/mods/isaa/base/AgentUtils.py</code> <pre><code>async def delete_memory(self, name: str) -&gt; bool:\n    \"\"\"Delete a memory store\"\"\"\n    sanitized = self._sanitize_name(name)\n    if sanitized in self.memories:\n        del self.memories[sanitized]\n        return True\n    return False\n</code></pre> <code>list_memories()</code> \u00b6 <p>List all available memories</p> Source code in <code>toolboxv2/mods/isaa/base/AgentUtils.py</code> <pre><code>def list_memories(self) -&gt; list[str]:\n    \"\"\"List all available memories\"\"\"\n    return list(self.memories.keys())\n</code></pre> <code>load_all_memories(path)</code> \u00b6 <p>Load all memory stores from disk</p> Source code in <code>toolboxv2/mods/isaa/base/AgentUtils.py</code> <pre><code>def load_all_memories(self, path: str) -&gt; bool:\n    \"\"\"Load all memory stores from disk\"\"\"\n    for file in os.listdir(path):\n        if file.endswith(\".pkl\"):\n            try:\n                self.memories[file[:-4]] = KnowledgeBase.load(os.path.join(path, file))\n            except EOFError:\n                return False\n            except FileNotFoundError:\n                return False\n            except Exception as e:\n                print(f\"Error loading memory: {str(e)}\")\n                return False\n    return True\n</code></pre> <code>load_memory(name, path)</code> \u00b6 <p>Load a memory store from disk</p> Source code in <code>toolboxv2/mods/isaa/base/AgentUtils.py</code> <pre><code>def load_memory(self, name: str, path: str | bytes) -&gt; bool:\n    \"\"\"Load a memory store from disk\"\"\"\n    sanitized = self._sanitize_name(name)\n    if sanitized in self.memories:\n        return False\n    try:\n        self.memories[sanitized] = KnowledgeBase.load(path)\n        return True\n    except Exception:\n        # print(f\"Error loading memory: {str(e)}\")\n        return False\n</code></pre> <code>query(query, memory_names=None, query_params=None, to_str=False, unified_retrieve=False)</code> <code>async</code> \u00b6 <p>Query memories using KnowledgeBase retrieval</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Search query</p> required <code>memory_names</code> <code>str | list[str] | None</code> <p>Target memory names</p> <code>None</code> <code>query_params</code> <code>dict | None</code> <p>Query parameters</p> <code>None</code> <code>to_str</code> <code>bool</code> <p>Return string format</p> <code>False</code> <code>unified_retrieve</code> <code>bool</code> <p>Unified retrieve</p> <code>False</code> Source code in <code>toolboxv2/mods/isaa/base/AgentUtils.py</code> <pre><code>async def query(self,\n                query: str,\n                memory_names: str | list[str] | None = None,\n                query_params: dict | None = None,\n                to_str: bool = False,\n                unified_retrieve: bool =False) -&gt; str | list[dict]:\n    \"\"\"\n    Query memories using KnowledgeBase retrieval\n\n    Args:\n        query: Search query\n        memory_names: Target memory names\n        query_params: Query parameters\n        to_str: Return string format\n        unified_retrieve: Unified retrieve\n    \"\"\"\n    targets = self._get_target_memories(memory_names)\n    if not targets:\n        return []\n\n    results = []\n    for name, kb in targets:\n        #try:\n            # Use KnowledgeBase's retrieve_with_overview for comprehensive results\n            result = await kb.retrieve_with_overview(\n                query=query,\n                k=query_params.get(\"k\", 3) if query_params else 3,\n                min_similarity=query_params.get(\"min_similarity\", 0.2) if query_params else 0.2,\n                cross_ref_depth=query_params.get(\"cross_ref_depth\", 2) if query_params else 2,\n                max_cross_refs=query_params.get(\"max_cross_refs\", 2) if query_params else 2,\n                max_sentences=query_params.get(\"max_sentences\", 5) if query_params else 5\n            ) if not unified_retrieve else await kb.unified_retrieve(\n                query=query,\n                k=query_params.get(\"k\", 2) if query_params else 2,\n                min_similarity=query_params.get(\"min_similarity\", 0.2) if query_params else 0.2,\n                cross_ref_depth=query_params.get(\"cross_ref_depth\", 2) if query_params else 2,\n                max_cross_refs=query_params.get(\"max_cross_refs\", 6) if query_params else 6,\n                max_sentences=query_params.get(\"max_sentences\", 12) if query_params else 12\n            )\n            results.append({\n                \"memory\": name,\n                \"result\": result\n            })\n        #except Exception as e:\n        #    print(f\"Query failed on {name}: {str(e)}\")\n    if to_str:\n        if not unified_retrieve:\n            str_res = [\n                f\"{x['memory']} - {json.dumps(x['result'].overview)}\\n - {[c.text for c in x['result'].details]}\\n - {[(k, [c.text for c in v]) for k, v in x['result'].cross_references.items()]}\"\n                for x in results]\n            # str_res =\n        else:\n            str_res = json.dumps(results)\n        return str_res\n    return results\n</code></pre> <code>save_all_memories(path)</code> \u00b6 <p>Save all memory stores to disk</p> Source code in <code>toolboxv2/mods/isaa/base/AgentUtils.py</code> <pre><code>def save_all_memories(self, path: str) -&gt; bool:\n    \"\"\"Save all memory stores to disk\"\"\"\n    for name, kb in self.memories.items():\n        try:\n            kb.save(os.path.join(path, f\"{name}.pkl\"))\n        except Exception as e:\n            print(f\"Error saving memory: {str(e)}\")\n            return False\n    return True\n</code></pre> <code>save_memory(name, path)</code> \u00b6 <p>Save a memory store to disk</p> Source code in <code>toolboxv2/mods/isaa/base/AgentUtils.py</code> <pre><code>def save_memory(self, name: str, path: str) -&gt; bool | bytes:\n    \"\"\"Save a memory store to disk\"\"\"\n    sanitized = self._sanitize_name(name)\n    if kb := self.memories.get(sanitized):\n        try:\n            return kb.save(path)\n        except Exception as e:\n            print(f\"Error saving memory: {str(e)}\")\n            return False\n    return False\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.AgentUtils.PyEnvEval","title":"<code>PyEnvEval</code>","text":"Source code in <code>toolboxv2/mods/isaa/base/AgentUtils.py</code> <pre><code>class PyEnvEval:\n    def __init__(self):\n        self.local_env = locals().copy()\n        self.global_env = {'local_env': self.local_env}  # globals().copy()\n\n    def eval_code(self, code):\n        try:\n            exec(code, self.global_env, self.local_env)\n            result = eval(code, self.global_env, self.local_env)\n            return self.format_output(result)\n        except Exception as e:\n            return self.format_output(str(e))\n\n    def get_env(self):\n        local_env_str = self.format_env(self.local_env)\n        return f'Locals:\\n{local_env_str}'\n\n    @staticmethod\n    def format_output(output):\n        return f'Ergebnis: {output}'\n\n    @staticmethod\n    def format_env(env):\n        return '\\n'.join(f'{key}: {value}' for key, value in env.items())\n\n    def run_and_display(self, python_code):\n        \"\"\"function to eval python code\"\"\"\n        start = f'Start-state:\\n{self.get_env()}'\n        result = self.eval_code(python_code)\n        end = f'End-state:\\n{self.get_env()}'\n        return f'{start}\\nResult:\\n{result}\\n{end}'\n\n    def tool(self):\n        return {\"PythonEval\": {\"func\": self.run_and_display, \"description\": \"Use Python Code to Get to an Persis Answer! input must be valid python code all non code parts must be comments!\"}}\n</code></pre> <code>run_and_display(python_code)</code> \u00b6 <p>function to eval python code</p> Source code in <code>toolboxv2/mods/isaa/base/AgentUtils.py</code> <pre><code>def run_and_display(self, python_code):\n    \"\"\"function to eval python code\"\"\"\n    start = f'Start-state:\\n{self.get_env()}'\n    result = self.eval_code(python_code)\n    end = f'End-state:\\n{self.get_env()}'\n    return f'{start}\\nResult:\\n{result}\\n{end}'\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.AgentUtils.Scripts","title":"<code>Scripts</code>","text":"Source code in <code>toolboxv2/mods/isaa/base/AgentUtils.py</code> <pre><code>class Scripts:\n    def __init__(self, filename):\n        self.scripts = {}\n        self.filename = filename\n        self.temp_dir = Path(tempfile.gettempdir()) / \"agent_scripts\"\n        self.temp_dir.mkdir(exist_ok=True)\n\n    def create_script(self, name: str, description: str, content: str, script_type: str = \"py\", dependencies: str = \"\"):\n        \"\"\"Create a script with optional dependencies\"\"\"\n        if not name.replace('_', '').replace('-', '').isalnum():\n            return \"Error: Script name must be alphanumeric (with _ or - allowed)\"\n\n        self.scripts[name] = {\n            \"description\": description,\n            \"content\": content,\n            \"type\": script_type.lower(),\n            \"dependencies\": dependencies.strip()\n        }\n        return f\"\u2705 Script '{name}' created! Your capabilities have been extended.\"\n\n    def remove_script(self, name: str):\n        \"\"\"Remove a script\"\"\"\n        if name in self.scripts:\n            del self.scripts[name]\n            return f\"\u2705 Script '{name}' removed!\"\n        return f\"\u274c Script '{name}' not found!\"\n\n    def run_script(self, name: str, args: str = \"\"):\n        \"\"\"Run a script with optional arguments - async-safe wrapper\"\"\"\n        try:\n            # Get the current event loop\n            loop = asyncio.get_event_loop()\n            # Run the async version\n            return loop.run_until_complete(self._run_script_async(name, args))\n        except RuntimeError:\n            # If no event loop, run synchronously (fallback)\n            return self._run_script_sync(name, args)\n\n    async def _run_script_async(self, name: str, args: str = \"\"):\n        \"\"\"Async version of run_script\"\"\"\n        if name not in self.scripts:\n            return f\"\u274c Script '{name}' not found! Use listScripts to see available scripts.\"\n\n        script = self.scripts[name]\n        script_type = script[\"type\"]\n\n        # Create temporary script file\n        temp_script = self.temp_dir / f\"{name}_{os.getpid()}.{script_type}\"\n\n        try:\n            with open(temp_script, \"w\", encoding=\"utf-8\") as f:\n                f.write(script[\"content\"])\n\n            # Parse arguments safely\n            script_args = args.split() if args.strip() else []\n\n            if script_type == \"py\":\n                return await self._run_python_script_async(temp_script, script_args, script.get(\"dependencies\", \"\"))\n            elif script_type in [\"sh\", \"bash\"]:\n                return await self._run_shell_script_async(temp_script, script_args)\n            else:\n                return f\"\u274c Unsupported script type: {script_type}. Use 'py' or 'sh'\"\n\n        except Exception as e:\n            return f\"\u274c Error running script: {str(e)}\"\n        finally:\n            if temp_script.exists():\n                temp_script.unlink()\n\n    def _run_script_sync(self, name: str, args: str = \"\"):\n        \"\"\"Synchronous fallback version\"\"\"\n        if name not in self.scripts:\n            return f\"\u274c Script '{name}' not found! Use listScripts to see available scripts.\"\n\n        script = self.scripts[name]\n        script_type = script[\"type\"]\n\n        # Create temporary script file\n        temp_script = self.temp_dir / f\"{name}_{os.getpid()}.{script_type}\"\n\n        try:\n            with open(temp_script, \"w\", encoding=\"utf-8\") as f:\n                f.write(script[\"content\"])\n\n            # Parse arguments safely\n            script_args = args.split() if args.strip() else []\n\n            if script_type == \"py\":\n                return self._run_python_script_sync(temp_script, script_args, script.get(\"dependencies\", \"\"))\n            elif script_type in [\"sh\", \"bash\"]:\n                return self._run_shell_script_sync(temp_script, script_args)\n            else:\n                return f\"\u274c Unsupported script type: {script_type}. Use 'py' or 'sh'\"\n\n        except Exception as e:\n            return f\"\u274c Error running script: {str(e)}\"\n        finally:\n            if temp_script.exists():\n                temp_script.unlink()\n\n    async def _run_python_script_async(self, script_path: Path, args: list, dependencies: str):\n        \"\"\"Run Python script async with uv dependency management\"\"\"\n        cmd = []\n\n        if dependencies.strip():\n            if shutil.which(\"uv\"):\n                dep_list = [dep.strip() for dep in dependencies.replace('\\n', ' ').split() if dep.strip()]\n                cmd = [\"uv\", \"run\"]\n                for dep in dep_list:\n                    cmd.extend([\"--with\", dep])\n                cmd.extend([sys.executable, str(script_path)] + args)\n            else:\n                return \"\u274c uv not found. Install uv for dependency management: `pip install uv`\"\n        else:\n            cmd = [sys.executable, str(script_path)] + args\n\n        return await self._execute_command_async(cmd)\n\n    async def _run_shell_script_async(self, script_path: Path, args: list):\n        \"\"\"Run shell script async cross-platform\"\"\"\n        if platform.system() == \"Windows\":\n            cmd = [\"cmd\", \"/c\", str(script_path)] + args\n        else:\n            cmd = [\"sh\", str(script_path)] + args\n\n        return await self._execute_command_async(cmd)\n\n    def _run_python_script_sync(self, script_path: Path, args: list, dependencies: str):\n        \"\"\"Run Python script sync with uv dependency management\"\"\"\n\n        cmd = []\n\n        if dependencies.strip():\n            if shutil.which(\"uv\"):\n                dep_list = [dep.strip() for dep in dependencies.replace('\\n', ' ').split() if dep.strip()]\n                cmd = [\"uv\", \"run\"]\n                for dep in dep_list:\n                    cmd.extend([\"--with\", dep])\n                cmd.extend([sys.executable, str(script_path)] + args)\n            else:\n                return \"\u274c uv not found. Install uv for dependency management: `pip install uv`\"\n        else:\n            cmd = [sys.executable, str(script_path)] + args\n\n        return self._execute_command_sync(cmd)\n\n    def _run_shell_script_sync(self, script_path: Path, args: list):\n        \"\"\"Run shell script sync cross-platform\"\"\"\n        if platform.system() == \"Windows\":\n            cmd = [\"cmd\", \"/c\", str(script_path)] + args\n        else:\n            cmd = [\"sh\", str(script_path)] + args\n\n        return self._execute_command_sync(cmd)\n\n    async def _execute_command_async(self, cmd: list, timeout: int = 60):\n        \"\"\"Execute command async safely with timeout\"\"\"\n        try:\n            process = await asyncio.create_subprocess_exec(\n                *cmd,\n                stdout=asyncio.subprocess.PIPE,\n                stderr=asyncio.subprocess.PIPE,\n                cwd=str(self.temp_dir),\n                text=False,\n            )\n\n            try:\n                stdout, stderr = await asyncio.wait_for(\n                    process.communicate(),\n                    timeout=timeout\n                )\n            except TimeoutError:\n                process.kill()\n                await process.wait()\n                return f\"\u23f1\ufe0f Script timed out after {timeout} seconds\"\n            output = remove_styles(safe_decode(stdout))\n            if stderr:\n                error_msg = remove_styles(safe_decode(stderr))\n                output += f\"\\n\ud83d\udd34 STDERR: {error_msg}\"\n\n            if process.returncode != 0:\n                output += f\"\\n\u26a0\ufe0f  Exit code: {process.returncode}\"\n\n            return output.strip() if output.strip() else \"\u2705 Script completed (no output)\"\n\n        except Exception as e:\n            return f\"\u274c Execution error: {str(e)}\"\n\n    def _execute_command_sync(self, cmd: list, timeout: int = 60):\n        \"\"\"Execute command sync safely with timeout\"\"\"\n\n        try:\n            result = subprocess.run(\n                cmd,\n                capture_output=True,\n                text=False,\n                timeout=timeout,\n                cwd=str(self.temp_dir)\n            )\n\n            output = remove_styles(safe_decode(result.stdout))\n            if result.stderr:\n                output += f\"\\n\ud83d\udd34 STDERR: {remove_styles(safe_decode(result.stderr))}\"\n\n            if result.returncode != 0:\n                output += f\"\\n\u26a0\ufe0f  Exit code: {result.returncode}\"\n\n            return output.strip() if output.strip() else \"\u2705 Script completed (no output)\"\n\n        except subprocess.TimeoutExpired:\n            return f\"\u23f1\ufe0f Script timed out after {timeout} seconds\"\n        except Exception as e:\n            return f\"\u274c Execution error: {str(e)}\"\n\n    def get_scripts_list(self):\n        \"\"\"Get formatted list of all scripts\"\"\"\n        if not self.scripts:\n            return \"\ud83d\udcdd No scripts available. Create scripts to extend your capabilities!\"\n\n        result = [\"\ud83d\udd27 Available Enhanced Capabilities:\"]\n        for name, script in self.scripts.items():\n            deps = f\" [deps: {script['dependencies']}]\" if script.get('dependencies') else \"\"\n            result.append(f\"  \u2022 {name} ({script['type']}){deps}: {script['description']}\")\n\n        return \"\\n\".join(result)\n\n    def save_scripts(self):\n        \"\"\"Save scripts to persistent storage\"\"\"\n        try:\n            os.makedirs(os.path.dirname(self.filename) if os.path.dirname(self.filename) else \".\", exist_ok=True)\n            with open(f\"{self.filename}.pkl\", \"wb\") as f:\n                pickle.dump(self.scripts, f)\n            return \"\ud83d\udcbe Scripts saved successfully!\"\n        except Exception as e:\n            return f\"\u274c Save error: {str(e)}\"\n\n    def load_scripts(self):\n        \"\"\"Load scripts from persistent storage\"\"\"\n        try:\n            if os.path.exists(f\"{self.filename}.pkl\"):\n                with open(f\"{self.filename}.pkl\", \"rb\") as f:\n                    data = f.read()\n                if data:\n                    self.scripts = pickle.loads(data)\n            else:\n                os.makedirs(os.path.dirname(self.filename) if os.path.dirname(self.filename) else \".\", exist_ok=True)\n                open(f\"{self.filename}.pkl\", \"a\").close()\n        except Exception as e:\n            print(f\"Load error: {str(e)}\")\n</code></pre> <code>create_script(name, description, content, script_type='py', dependencies='')</code> \u00b6 <p>Create a script with optional dependencies</p> Source code in <code>toolboxv2/mods/isaa/base/AgentUtils.py</code> <pre><code>def create_script(self, name: str, description: str, content: str, script_type: str = \"py\", dependencies: str = \"\"):\n    \"\"\"Create a script with optional dependencies\"\"\"\n    if not name.replace('_', '').replace('-', '').isalnum():\n        return \"Error: Script name must be alphanumeric (with _ or - allowed)\"\n\n    self.scripts[name] = {\n        \"description\": description,\n        \"content\": content,\n        \"type\": script_type.lower(),\n        \"dependencies\": dependencies.strip()\n    }\n    return f\"\u2705 Script '{name}' created! Your capabilities have been extended.\"\n</code></pre> <code>get_scripts_list()</code> \u00b6 <p>Get formatted list of all scripts</p> Source code in <code>toolboxv2/mods/isaa/base/AgentUtils.py</code> <pre><code>def get_scripts_list(self):\n    \"\"\"Get formatted list of all scripts\"\"\"\n    if not self.scripts:\n        return \"\ud83d\udcdd No scripts available. Create scripts to extend your capabilities!\"\n\n    result = [\"\ud83d\udd27 Available Enhanced Capabilities:\"]\n    for name, script in self.scripts.items():\n        deps = f\" [deps: {script['dependencies']}]\" if script.get('dependencies') else \"\"\n        result.append(f\"  \u2022 {name} ({script['type']}){deps}: {script['description']}\")\n\n    return \"\\n\".join(result)\n</code></pre> <code>load_scripts()</code> \u00b6 <p>Load scripts from persistent storage</p> Source code in <code>toolboxv2/mods/isaa/base/AgentUtils.py</code> <pre><code>def load_scripts(self):\n    \"\"\"Load scripts from persistent storage\"\"\"\n    try:\n        if os.path.exists(f\"{self.filename}.pkl\"):\n            with open(f\"{self.filename}.pkl\", \"rb\") as f:\n                data = f.read()\n            if data:\n                self.scripts = pickle.loads(data)\n        else:\n            os.makedirs(os.path.dirname(self.filename) if os.path.dirname(self.filename) else \".\", exist_ok=True)\n            open(f\"{self.filename}.pkl\", \"a\").close()\n    except Exception as e:\n        print(f\"Load error: {str(e)}\")\n</code></pre> <code>remove_script(name)</code> \u00b6 <p>Remove a script</p> Source code in <code>toolboxv2/mods/isaa/base/AgentUtils.py</code> <pre><code>def remove_script(self, name: str):\n    \"\"\"Remove a script\"\"\"\n    if name in self.scripts:\n        del self.scripts[name]\n        return f\"\u2705 Script '{name}' removed!\"\n    return f\"\u274c Script '{name}' not found!\"\n</code></pre> <code>run_script(name, args='')</code> \u00b6 <p>Run a script with optional arguments - async-safe wrapper</p> Source code in <code>toolboxv2/mods/isaa/base/AgentUtils.py</code> <pre><code>def run_script(self, name: str, args: str = \"\"):\n    \"\"\"Run a script with optional arguments - async-safe wrapper\"\"\"\n    try:\n        # Get the current event loop\n        loop = asyncio.get_event_loop()\n        # Run the async version\n        return loop.run_until_complete(self._run_script_async(name, args))\n    except RuntimeError:\n        # If no event loop, run synchronously (fallback)\n        return self._run_script_sync(name, args)\n</code></pre> <code>save_scripts()</code> \u00b6 <p>Save scripts to persistent storage</p> Source code in <code>toolboxv2/mods/isaa/base/AgentUtils.py</code> <pre><code>def save_scripts(self):\n    \"\"\"Save scripts to persistent storage\"\"\"\n    try:\n        os.makedirs(os.path.dirname(self.filename) if os.path.dirname(self.filename) else \".\", exist_ok=True)\n        with open(f\"{self.filename}.pkl\", \"wb\") as f:\n            pickle.dump(self.scripts, f)\n        return \"\ud83d\udcbe Scripts saved successfully!\"\n    except Exception as e:\n        return f\"\u274c Save error: {str(e)}\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.AgentUtils.anything_from_str_to_dict","title":"<code>anything_from_str_to_dict(data, expected_keys=None, mini_task=lambda x: '')</code>","text":"<p>Versucht, einen String in ein oder mehrere Dictionaries umzuwandeln. Ber\u00fccksichtigt dabei die erwarteten Schl\u00fcssel und ihre Standardwerte.</p> Source code in <code>toolboxv2/mods/isaa/base/AgentUtils.py</code> <pre><code>def anything_from_str_to_dict(data: str, expected_keys: dict = None, mini_task=lambda x: ''):\n    \"\"\"\n    Versucht, einen String in ein oder mehrere Dictionaries umzuwandeln.\n    Ber\u00fccksichtigt dabei die erwarteten Schl\u00fcssel und ihre Standardwerte.\n    \"\"\"\n    if len(data) &lt; 4:\n        return []\n\n    if expected_keys is None:\n        expected_keys = {}\n\n    result = []\n    json_objects = find_json_objects_in_str(data)\n    if not json_objects and data.startswith('[') and data.endswith(']'):\n        json_objects = eval(data)\n    if json_objects and len(json_objects) &gt; 0 and isinstance(json_objects[0], dict):\n        result.extend([{**expected_keys, **ob} for ob in json_objects])\n    if not result:\n        completed_object = complete_json_object(data, mini_task)\n        if completed_object is not None:\n            result.append(completed_object)\n    if len(result) == 0 and expected_keys:\n        result = [{list(expected_keys.keys())[0]: data}]\n    for res in result:\n        if isinstance(res, list) and len(res) &gt; 0:\n            res = res[0]\n        for key, value in expected_keys.items():\n            if key not in res:\n                res[key] = value\n\n    if len(result) == 0:\n        fixed = fix_json(data)\n        if fixed:\n            result.append(fixed)\n\n    return result\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.AgentUtils.complete_json_object","title":"<code>complete_json_object(data, mini_task)</code>","text":"<p>Ruft eine Funktion auf, um einen String in das richtige Format zu bringen. Gibt das resultierende JSON-Objekt zur\u00fcck, wenn die Funktion erfolgreich ist, sonst None.</p> Source code in <code>toolboxv2/mods/isaa/base/AgentUtils.py</code> <pre><code>def complete_json_object(data: str, mini_task):\n    \"\"\"\n    Ruft eine Funktion auf, um einen String in das richtige Format zu bringen.\n    Gibt das resultierende JSON-Objekt zur\u00fcck, wenn die Funktion erfolgreich ist, sonst None.\n    \"\"\"\n    ret = mini_task(\n        f\"Vervollst\u00e4ndige das Json Object. Und bringe den string in das Richtige format. data={data}\\nJson=\")\n    if ret:\n        return anything_from_str_to_dict(ret)\n    return None\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.AgentUtils.detect_shell","title":"<code>detect_shell()</code>","text":"<p>Detects the best available shell and the argument to execute a command. Returns:     A tuple of (shell_executable, command_argument).     e.g., ('/bin/bash', '-c') or ('powershell.exe', '-Command')</p> Source code in <code>toolboxv2/mods/isaa/base/AgentUtils.py</code> <pre><code>def detect_shell() -&gt; tuple[str, str]:\n    \"\"\"\n    Detects the best available shell and the argument to execute a command.\n    Returns:\n        A tuple of (shell_executable, command_argument).\n        e.g., ('/bin/bash', '-c') or ('powershell.exe', '-Command')\n    \"\"\"\n    if platform.system() == \"Windows\":\n        if shell_path := shutil.which(\"pwsh\"):\n            return shell_path, \"-Command\"\n        if shell_path := shutil.which(\"powershell\"):\n            return shell_path, \"-Command\"\n        return \"cmd.exe\", \"/c\"\n\n    shell_env = os.environ.get(\"SHELL\")\n    if shell_env and shutil.which(shell_env):\n        return shell_env, \"-c\"\n\n    for shell in [\"bash\", \"zsh\", \"sh\"]:\n        if shell_path := shutil.which(shell):\n            return shell_path, \"-c\"\n\n    return \"/bin/sh\", \"-c\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.AgentUtils.extract_text_natively","title":"<code>extract_text_natively(data, filename='')</code>","text":"<p>Extrahiert Text aus verschiedenen Dateitypen mit nativen Python-Methoden oder reinen Python-Bibliotheken (speziell PyPDF2 f\u00fcr PDFs).</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>bytes</code> <p>Der Inhalt der Datei als Bytes.</p> required <code>filename</code> <code>str</code> <p>Der Originaldateiname, um den Typ zu bestimmen.</p> <code>''</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Der extrahierte Text.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>Wenn der Dateityp nicht unterst\u00fctzt wird oder die Verarbeitung fehlschl\u00e4gt.</p> <code>ImportError</code> <p>Wenn PyPDF2 f\u00fcr die Verarbeitung von PDF-Dateien ben\u00f6tigt, aber nicht installiert ist.</p> Source code in <code>toolboxv2/mods/isaa/base/AgentUtils.py</code> <pre><code>def extract_text_natively(data: bytes, filename: str = \"\") -&gt; str:\n    \"\"\"\n    Extrahiert Text aus verschiedenen Dateitypen mit nativen Python-Methoden\n    oder reinen Python-Bibliotheken (speziell PyPDF2 f\u00fcr PDFs).\n\n    Args:\n        data (bytes): Der Inhalt der Datei als Bytes.\n        filename (str, optional): Der Originaldateiname, um den Typ zu bestimmen.\n\n    Returns:\n        str: Der extrahierte Text.\n\n    Raises:\n        ValueError: Wenn der Dateityp nicht unterst\u00fctzt wird oder die Verarbeitung fehlschl\u00e4gt.\n        ImportError: Wenn PyPDF2 f\u00fcr die Verarbeitung von PDF-Dateien ben\u00f6tigt, aber nicht installiert ist.\n    \"\"\"\n    file_ext = filename.lower().split('.')[-1] if '.' in filename else ''\n\n    # 1. DOCX-Verarbeitung (nativ mit zipfile und xml)\n    if data.startswith(b'PK\\x03\\x04'):\n        try:\n            docx_file = io.BytesIO(data)\n            text_parts = []\n            with zipfile.ZipFile(docx_file) as zf:\n                namespace = \"{http://schemas.openxmlformats.org/wordprocessingml/2006/main}\"\n                body_path = \"word/document.xml\"\n                if body_path in zf.namelist():\n                    xml_content = zf.read(body_path)\n                    tree = ET.fromstring(xml_content)\n                    for para in tree.iter(f\"{namespace}p\"):\n                        texts_in_para = [node.text for node in para.iter(f\"{namespace}t\") if node.text]\n                        if texts_in_para:\n                            text_parts.append(\"\".join(texts_in_para))\n                return \"\\n\".join(text_parts)\n        except (zipfile.BadZipFile, ET.ParseError):\n            pass  # F\u00e4hrt fort, falls es eine ZIP-Datei, aber kein g\u00fcltiges DOCX ist\n\n    # 2. PDF-Verarbeitung (mit PyPDF2)\n    if data.startswith(b'%PDF-'):\n        if PyPDF2 is None:\n            raise ImportError(\n                \"Die Bibliothek 'PyPDF2' wird ben\u00f6tigt, um PDF-Dateien zu verarbeiten. Bitte installieren Sie sie mit 'pip install PyPDF2'.\")\n\n        try:\n            # Erstelle ein In-Memory-Dateiobjekt f\u00fcr PyPDF2\n            pdf_file = io.BytesIO(data)\n            # Verwende PdfFileReader aus PyPDF2\n            pdf_reader = PyPDF2.PdfFileReader(pdf_file)\n\n            text_parts = []\n            # Iteriere durch die Seiten\n            for page_num in range(pdf_reader.numPages):\n                page = pdf_reader.getPage(page_num)\n                # Extrahiere Text mit extractText()\n                page_text = page.extractText()\n                if page_text:\n                    text_parts.append(page_text)\n\n            return \"\\n\".join(text_parts)\n        except Exception as e:\n            raise ValueError(f\"PDF-Verarbeitung mit PyPDF2 fehlgeschlagen: {e}\")\n\n    # 3. Fallback auf reinen Text (TXT)\n\n    try:\n        return data.decode('utf-8')\n    except UnicodeDecodeError:\n        try:\n            return data.decode('latin-1')\n        except Exception as e:\n            raise ValueError(f\"Text-Dekodierung fehlgeschlagen: {e}\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.AgentUtils.find_json_objects_in_str","title":"<code>find_json_objects_in_str(data)</code>","text":"<p>Sucht nach JSON-Objekten innerhalb eines Strings. Gibt eine Liste von JSON-Objekten zur\u00fcck, die im String gefunden wurden.</p> Source code in <code>toolboxv2/mods/isaa/base/AgentUtils.py</code> <pre><code>def find_json_objects_in_str(data: str):\n    \"\"\"\n    Sucht nach JSON-Objekten innerhalb eines Strings.\n    Gibt eine Liste von JSON-Objekten zur\u00fcck, die im String gefunden wurden.\n    \"\"\"\n    json_objects = extract_json_objects(data)\n    if not isinstance(json_objects, list):\n        json_objects = [json_objects]\n    return [get_json_from_json_str(ob, 10) for ob in json_objects if get_json_from_json_str(ob, 10) is not None]\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.AgentUtils.get_json_from_json_str","title":"<code>get_json_from_json_str(json_str, repeat=1)</code>","text":"<p>Versucht, einen JSON-String in ein Python-Objekt umzuwandeln.</p> <p>Wenn beim Parsen ein Fehler auftritt, versucht die Funktion, das Problem zu beheben, indem sie das Zeichen an der Position des Fehlers durch ein Escape-Zeichen ersetzt. Dieser Vorgang wird bis zu <code>repeat</code>-mal wiederholt.</p> <p>Parameters:</p> Name Type Description Default <code>json_str</code> <code>str or list or dict</code> <p>Der JSON-String, der geparst werden soll.</p> required <code>repeat</code> <code>int</code> <p>Die Anzahl der Versuche, das Parsen durchzuf\u00fchren.</p> <code>1</code> <p>Returns:</p> Type Description <code>dict or None</code> <p>Das resultierende Python-Objekt.</p> Source code in <code>toolboxv2/mods/isaa/base/AgentUtils.py</code> <pre><code>def get_json_from_json_str(json_str: str or list or dict, repeat: int = 1) -&gt; dict or None:\n    \"\"\"Versucht, einen JSON-String in ein Python-Objekt umzuwandeln.\n\n    Wenn beim Parsen ein Fehler auftritt, versucht die Funktion, das Problem zu beheben,\n    indem sie das Zeichen an der Position des Fehlers durch ein Escape-Zeichen ersetzt.\n    Dieser Vorgang wird bis zu `repeat`-mal wiederholt.\n\n    Args:\n        json_str: Der JSON-String, der geparst werden soll.\n        repeat: Die Anzahl der Versuche, das Parsen durchzuf\u00fchren.\n\n    Returns:\n        Das resultierende Python-Objekt.\n    \"\"\"\n    for _ in range(repeat):\n        try:\n            return parse_json_with_auto_detection(json_str)\n        except json.JSONDecodeError as e:\n            unexp = int(re.findall(r'\\(char (\\d+)\\)', str(e))[0])\n            unesc = json_str.rfind(r'\"', 0, unexp)\n            json_str = json_str[:unesc] + r'\\\"' + json_str[unesc + 1:]\n            closg = json_str.find(r'\"', unesc + 2)\n            json_str = json_str[:closg] + r'\\\"' + json_str[closg + 1:]\n        new = fix_json_object(json_str)\n        if new is not None:\n            json_str = new\n    get_logger().info(f\"Unable to parse JSON string after {json_str}\")\n    return None\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.AgentUtils.parse_json_with_auto_detection","title":"<code>parse_json_with_auto_detection(json_data)</code>","text":"<p>Parses JSON data, automatically detecting if a value is a JSON string and parsing it accordingly. If a value cannot be parsed as JSON, it is returned as is.</p> Source code in <code>toolboxv2/mods/isaa/base/AgentUtils.py</code> <pre><code>def parse_json_with_auto_detection(json_data):\n    \"\"\"\n    Parses JSON data, automatically detecting if a value is a JSON string and parsing it accordingly.\n    If a value cannot be parsed as JSON, it is returned as is.\n    \"\"\"\n\n    def try_parse_json(value):\n        \"\"\"\n        Tries to parse a value as JSON. If the parsing fails, the original value is returned.\n        \"\"\"\n        try:\n            # print(\"parse_json_with_auto_detection:\", type(value), value)\n            parsed_value = json.loads(value)\n            # print(\"parsed_value:\", type(parsed_value), parsed_value)\n            # If the parsed value is a string, it might be a JSON string, so we try to parse it again\n            if isinstance(parsed_value, str):\n                return eval(parsed_value)\n            else:\n                return parsed_value\n        except Exception:\n            # logging.warning(f\"Failed to parse value as JSON: {value}. Exception: {e}\")\n            return value\n\n    get_logger()\n\n    if isinstance(json_data, dict):\n        return {key: parse_json_with_auto_detection(value) for key, value in json_data.items()}\n    elif isinstance(json_data, list):\n        return [parse_json_with_auto_detection(item) for item in json_data]\n    else:\n        return try_parse_json(json_data)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.KnowledgeBase","title":"<code>KnowledgeBase</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.KnowledgeBase.Chunk","title":"<code>Chunk</code>  <code>dataclass</code>","text":"<p>Represents a chunk of text with its embedding and metadata</p> Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>@dataclass(slots=True)\nclass Chunk:\n    \"\"\"Represents a chunk of text with its embedding and metadata\"\"\"\n    text: str\n    embedding: np.ndarray\n    metadata: dict[str, Any]\n    content_hash: str\n    cluster_id: int | None = None\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.KnowledgeBase.ConceptAnalysis","title":"<code>ConceptAnalysis</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents the analysis of key concepts.</p> <p>Attributes:</p> Name Type Description <code>key_concepts</code> <code>list[str]</code> <p>A list of primary key concepts identified.</p> <code>relationships</code> <code>list[str]</code> <p>A list of relationships between the identified key concepts.</p> <code>importance_hierarchy</code> <code>list[str]</code> <p>A list that represents the hierarchical importance of the key concepts.</p> Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>class ConceptAnalysis(BaseModel):\n    \"\"\"\n    Represents the analysis of key concepts.\n\n    Attributes:\n        key_concepts (list[str]): A list of primary key concepts identified.\n        relationships (list[str]): A list of relationships between the identified key concepts.\n        importance_hierarchy (list[str]): A list that represents the hierarchical importance of the key concepts.\n    \"\"\"\n    key_concepts: list[str]\n    relationships: list[str]\n    importance_hierarchy: list[str]\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.KnowledgeBase.ConceptExtractor","title":"<code>ConceptExtractor</code>","text":"<p>Handles extraction of concepts and relationships from text</p> Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>class ConceptExtractor:\n    \"\"\"Handles extraction of concepts and relationships from text\"\"\"\n\n    def __init__(self, knowledge_base, requests_per_second = 85.):\n        self.kb = knowledge_base\n        self.concept_graph = ConceptGraph()\n        self.requests_per_second = requests_per_second\n\n    async def extract_concepts(self, texts: list[str], metadatas: list[dict[str, Any]]) -&gt; list[list[Concept]]:\n        \"\"\"\n        Extract concepts from texts using concurrent processing with rate limiting.\n        Requests are made at the specified rate while responses are processed asynchronously.\n        \"\"\"\n        # Ensure metadatas list matches texts length\n        metadatas = metadatas + [{}] * (len(texts) - len(metadatas))\n\n        # Initialize rate limiter\n        rate_limiter = DynamicRateLimiter()\n\n        system_prompt = (\n            \"Analyze the given text and extract key concepts and their relationships. For each concept:\\n\"\n            \"1. Identify the concept name and category (technical, domain, method, property, ...)\\n\"\n            \"2. Determine relationships with other concepts (uses, part_of, similar_to, depends_on, ...)\\n\"\n            \"3. Assess importance (0-1 score) based on centrality to the text\\n\"\n            \"4. Extract relevant context snippets\\n\"\n            \"5. Max 5 Concepts!\\n\"\n            \"only return in json format!\\n\"\n            \"\"\"{\"concepts\": [{\n                \"name\": \"concept_name\",\n                \"category\": \"category_name\",\n                \"relationships\": {\n                    \"relationship_type\": [\"related_concept1\", \"related_concept2\"]\n                },\n                \"importance_score\": 0.0,\n                \"context_snippets\": [\"relevant text snippet\"]\n            }]}\\n\"\"\"\n        )\n\n        # Prepare all requests\n        requests = [\n            (idx, f\"Text to Convert in to JSON structure:\\n{text}\", system_prompt, metadata)\n            for idx, (text, metadata) in enumerate(zip(texts, metadatas, strict=False))\n        ]\n\n        async def process_single_request(idx: int, prompt: str, system_prompt: str, metadata: dict[str, Any]):\n            \"\"\"Process a single request with rate limiting\"\"\"\n            try:\n                # Wait for rate limit\n                await rate_limiter.acquire()\n                i__[1] += 1\n                # Make API call without awaiting the response\n                response_future = litellm_complete(\n                    prompt=prompt,\n                    system_prompt=system_prompt,\n                    response_format=Concepts,\n                    model_name=self.kb.model_name,\n                    fallbacks=[\"groq/gemma2-9b-it\"] +\n                              [m for m in os.getenv(\"FALLBACKS_MODELS_PREM\", '').split(',') if m]\n                )\n\n                return idx, response_future\n\n            except Exception as e:\n                print(f\"Error initiating request {idx}: {str(e)}\")\n                return idx, None\n\n        async def process_response(idx: int, response_future) -&gt; list[Concept]:\n            \"\"\"Process the response once it's ready\"\"\"\n            try:\n                if response_future is None:\n                    return []\n\n                response = await response_future\n                return await self._process_response(response, metadatas[idx])\n\n            except Exception as e:\n                print(f\"Error processing response {idx}: {str(e)}\")\n                return []\n\n        # Create tasks for all requests\n        request_tasks = []\n        batch_size = self.kb.batch_size\n\n        rate_limiter.update_rate(self.requests_per_second)\n\n        for batch_start in range(0, len(requests), batch_size):\n            batch = requests[batch_start:batch_start + batch_size]\n\n            # Create tasks for the batch\n            batch_tasks = [\n                process_single_request(idx, prompt, sys_prompt, meta)\n                for idx, prompt, sys_prompt, meta in batch\n            ]\n            request_tasks.extend(batch_tasks)\n\n        # Execute all requests with rate limiting\n        request_results = await asyncio.gather(*request_tasks)\n\n        # Process responses as they complete\n        response_tasks = [\n            process_response(idx, response_future)\n            for idx, response_future in request_results\n        ]\n\n        # Gather all results\n        all_results = await asyncio.gather(*response_tasks)\n\n        # Sort results by original index\n        sorted_results = [[] for _ in texts]\n        for idx, concepts in enumerate(all_results):\n            sorted_results[idx] = concepts\n\n        return sorted_results\n\n    async def _process_response(self, response: Any, metadata: dict[str, Any]) -&gt; list[Concept]:\n        \"\"\"Helper method to process a single response and convert it to Concepts\"\"\"\n        try:\n            # Extract content from response\n            if hasattr(response, 'choices'):\n                content = response.choices[0].message.content\n                if content is None:\n                    content = response.choices[0].message.tool_calls[0].function.arguments\n                if content is None:\n                    return []\n            elif isinstance(response, str):\n                content = response\n            else:\n                print(f\"Unexpected response type: {type(response)}\")\n                return []\n\n            # Parse JSON and create concepts\n            concept_data = after_format(content)\n            concepts = []\n\n            for concept_info in concept_data.get(\"concepts\", []):\n                concept = Concept(\n                    name=concept_info[\"name\"],\n                    category=concept_info.get(\"category\", \"N/A\"),\n                    relationships={k: set(v) for k, v in concept_info.get(\"relationships\", {}).items()},\n                    importance_score=concept_info.get(\"importance_score\", 0.1),\n                    context_snippets=concept_info.get(\"context_snippets\", \"N/A\"),\n                    metadata=metadata\n                )\n                concepts.append(concept)\n                self.concept_graph.add_concept(concept)\n\n            return concepts\n\n        except Exception:\n            i__[2] +=1\n            return []\n\n    async def process_chunks(self, chunks: list[Chunk]) -&gt; None:\n        \"\"\"\n        Process all chunks in batch to extract and store concepts.\n        Each chunk's metadata will be updated with the concept names and relationships.\n        \"\"\"\n        # Gather all texts from the chunks.\n        texts = [chunk.text for chunk in chunks]\n        # Call extract_concepts once with all texts.\n        all_concepts = await self.extract_concepts(texts, [chunk.metadata for chunk in chunks])\n\n        # Update each chunk's metadata with its corresponding concepts.\n        for chunk, concepts in zip(chunks, all_concepts, strict=False):\n            chunk.metadata[\"concepts\"] = [c.name for c in concepts]\n            chunk.metadata[\"concept_relationships\"] = {\n                c.name: {k: list(v) for k, v in c.relationships.items()}\n                for c in concepts\n            }\n\n    async def query_concepts(self, query: str) -&gt; dict[str, any]:\n        \"\"\"Query the concept graph based on natural language query\"\"\"\n\n        system_prompt = \"\"\"\n        Convert the natural language query about concepts into a structured format that specifies:\n        1. Main concepts of interest\n        2. Desired relationship types\n        3. Any category filters\n        4. Importance threshold\n\n        Format as JSON.\n        \"\"\"\n\n        prompt = f\"\"\"\n        Query: {query}\n\n        Convert to this JSON structure:\n        {{\n            \"target_concepts\": [\"concept1\", \"concept2\"],\n            \"relationship_types\": [\"type1\", \"type2\"],\n            \"categories\": [\"category1\", \"category2\"],\n            \"min_importance\": 0.0\n        }}\n        \"\"\"\n\n        try:\n            response = await litellm_complete(\n                model_name=self.kb.model_name,\n                prompt=prompt,\n                system_prompt=system_prompt,\n                response_format=TConcept\n            )\n\n            query_params = json.loads(response)\n\n            results = {\n                \"concepts\": {},\n                \"relationships\": [],\n                \"groups\": []\n            }\n\n            # Find matching concepts\n            for concept_name in query_params[\"target_concepts\"]:\n                if concept_name in self.concept_graph.concepts:\n                    concept = self.concept_graph.concepts[concept_name]\n                    if concept.importance_score &gt;= query_params[\"min_importance\"]:\n                        results[\"concepts\"][concept_name] = {\n                            \"category\": concept.category,\n                            \"importance\": concept.importance_score,\n                            \"context\": concept.context_snippets\n                        }\n\n                        # Get relationships\n                        for rel_type in query_params[\"relationship_types\"]:\n                            related = self.concept_graph.get_related_concepts(\n                                concept_name, rel_type\n                            )\n                            for related_concept in related:\n                                results[\"relationships\"].append({\n                                    \"from\": concept_name,\n                                    \"to\": related_concept,\n                                    \"type\": rel_type\n                                })\n\n            # Group concepts by category\n            category_groups = defaultdict(list)\n            for concept_name, concept_info in results[\"concepts\"].items():\n                category_groups[concept_info[\"category\"]].append(concept_name)\n            results[\"groups\"] = [\n                {\"category\": cat, \"concepts\": concepts}\n                for cat, concepts in category_groups.items()\n            ]\n\n            return results\n\n        except Exception as e:\n            print(f\"Error querying concepts: {str(e)}\")\n            return {\"concepts\": {}, \"relationships\": [], \"groups\": []}\n</code></pre> <code>extract_concepts(texts, metadatas)</code> <code>async</code> \u00b6 <p>Extract concepts from texts using concurrent processing with rate limiting. Requests are made at the specified rate while responses are processed asynchronously.</p> Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>async def extract_concepts(self, texts: list[str], metadatas: list[dict[str, Any]]) -&gt; list[list[Concept]]:\n    \"\"\"\n    Extract concepts from texts using concurrent processing with rate limiting.\n    Requests are made at the specified rate while responses are processed asynchronously.\n    \"\"\"\n    # Ensure metadatas list matches texts length\n    metadatas = metadatas + [{}] * (len(texts) - len(metadatas))\n\n    # Initialize rate limiter\n    rate_limiter = DynamicRateLimiter()\n\n    system_prompt = (\n        \"Analyze the given text and extract key concepts and their relationships. For each concept:\\n\"\n        \"1. Identify the concept name and category (technical, domain, method, property, ...)\\n\"\n        \"2. Determine relationships with other concepts (uses, part_of, similar_to, depends_on, ...)\\n\"\n        \"3. Assess importance (0-1 score) based on centrality to the text\\n\"\n        \"4. Extract relevant context snippets\\n\"\n        \"5. Max 5 Concepts!\\n\"\n        \"only return in json format!\\n\"\n        \"\"\"{\"concepts\": [{\n            \"name\": \"concept_name\",\n            \"category\": \"category_name\",\n            \"relationships\": {\n                \"relationship_type\": [\"related_concept1\", \"related_concept2\"]\n            },\n            \"importance_score\": 0.0,\n            \"context_snippets\": [\"relevant text snippet\"]\n        }]}\\n\"\"\"\n    )\n\n    # Prepare all requests\n    requests = [\n        (idx, f\"Text to Convert in to JSON structure:\\n{text}\", system_prompt, metadata)\n        for idx, (text, metadata) in enumerate(zip(texts, metadatas, strict=False))\n    ]\n\n    async def process_single_request(idx: int, prompt: str, system_prompt: str, metadata: dict[str, Any]):\n        \"\"\"Process a single request with rate limiting\"\"\"\n        try:\n            # Wait for rate limit\n            await rate_limiter.acquire()\n            i__[1] += 1\n            # Make API call without awaiting the response\n            response_future = litellm_complete(\n                prompt=prompt,\n                system_prompt=system_prompt,\n                response_format=Concepts,\n                model_name=self.kb.model_name,\n                fallbacks=[\"groq/gemma2-9b-it\"] +\n                          [m for m in os.getenv(\"FALLBACKS_MODELS_PREM\", '').split(',') if m]\n            )\n\n            return idx, response_future\n\n        except Exception as e:\n            print(f\"Error initiating request {idx}: {str(e)}\")\n            return idx, None\n\n    async def process_response(idx: int, response_future) -&gt; list[Concept]:\n        \"\"\"Process the response once it's ready\"\"\"\n        try:\n            if response_future is None:\n                return []\n\n            response = await response_future\n            return await self._process_response(response, metadatas[idx])\n\n        except Exception as e:\n            print(f\"Error processing response {idx}: {str(e)}\")\n            return []\n\n    # Create tasks for all requests\n    request_tasks = []\n    batch_size = self.kb.batch_size\n\n    rate_limiter.update_rate(self.requests_per_second)\n\n    for batch_start in range(0, len(requests), batch_size):\n        batch = requests[batch_start:batch_start + batch_size]\n\n        # Create tasks for the batch\n        batch_tasks = [\n            process_single_request(idx, prompt, sys_prompt, meta)\n            for idx, prompt, sys_prompt, meta in batch\n        ]\n        request_tasks.extend(batch_tasks)\n\n    # Execute all requests with rate limiting\n    request_results = await asyncio.gather(*request_tasks)\n\n    # Process responses as they complete\n    response_tasks = [\n        process_response(idx, response_future)\n        for idx, response_future in request_results\n    ]\n\n    # Gather all results\n    all_results = await asyncio.gather(*response_tasks)\n\n    # Sort results by original index\n    sorted_results = [[] for _ in texts]\n    for idx, concepts in enumerate(all_results):\n        sorted_results[idx] = concepts\n\n    return sorted_results\n</code></pre> <code>process_chunks(chunks)</code> <code>async</code> \u00b6 <p>Process all chunks in batch to extract and store concepts. Each chunk's metadata will be updated with the concept names and relationships.</p> Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>async def process_chunks(self, chunks: list[Chunk]) -&gt; None:\n    \"\"\"\n    Process all chunks in batch to extract and store concepts.\n    Each chunk's metadata will be updated with the concept names and relationships.\n    \"\"\"\n    # Gather all texts from the chunks.\n    texts = [chunk.text for chunk in chunks]\n    # Call extract_concepts once with all texts.\n    all_concepts = await self.extract_concepts(texts, [chunk.metadata for chunk in chunks])\n\n    # Update each chunk's metadata with its corresponding concepts.\n    for chunk, concepts in zip(chunks, all_concepts, strict=False):\n        chunk.metadata[\"concepts\"] = [c.name for c in concepts]\n        chunk.metadata[\"concept_relationships\"] = {\n            c.name: {k: list(v) for k, v in c.relationships.items()}\n            for c in concepts\n        }\n</code></pre> <code>query_concepts(query)</code> <code>async</code> \u00b6 <p>Query the concept graph based on natural language query</p> Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>async def query_concepts(self, query: str) -&gt; dict[str, any]:\n    \"\"\"Query the concept graph based on natural language query\"\"\"\n\n    system_prompt = \"\"\"\n    Convert the natural language query about concepts into a structured format that specifies:\n    1. Main concepts of interest\n    2. Desired relationship types\n    3. Any category filters\n    4. Importance threshold\n\n    Format as JSON.\n    \"\"\"\n\n    prompt = f\"\"\"\n    Query: {query}\n\n    Convert to this JSON structure:\n    {{\n        \"target_concepts\": [\"concept1\", \"concept2\"],\n        \"relationship_types\": [\"type1\", \"type2\"],\n        \"categories\": [\"category1\", \"category2\"],\n        \"min_importance\": 0.0\n    }}\n    \"\"\"\n\n    try:\n        response = await litellm_complete(\n            model_name=self.kb.model_name,\n            prompt=prompt,\n            system_prompt=system_prompt,\n            response_format=TConcept\n        )\n\n        query_params = json.loads(response)\n\n        results = {\n            \"concepts\": {},\n            \"relationships\": [],\n            \"groups\": []\n        }\n\n        # Find matching concepts\n        for concept_name in query_params[\"target_concepts\"]:\n            if concept_name in self.concept_graph.concepts:\n                concept = self.concept_graph.concepts[concept_name]\n                if concept.importance_score &gt;= query_params[\"min_importance\"]:\n                    results[\"concepts\"][concept_name] = {\n                        \"category\": concept.category,\n                        \"importance\": concept.importance_score,\n                        \"context\": concept.context_snippets\n                    }\n\n                    # Get relationships\n                    for rel_type in query_params[\"relationship_types\"]:\n                        related = self.concept_graph.get_related_concepts(\n                            concept_name, rel_type\n                        )\n                        for related_concept in related:\n                            results[\"relationships\"].append({\n                                \"from\": concept_name,\n                                \"to\": related_concept,\n                                \"type\": rel_type\n                            })\n\n        # Group concepts by category\n        category_groups = defaultdict(list)\n        for concept_name, concept_info in results[\"concepts\"].items():\n            category_groups[concept_info[\"category\"]].append(concept_name)\n        results[\"groups\"] = [\n            {\"category\": cat, \"concepts\": concepts}\n            for cat, concepts in category_groups.items()\n        ]\n\n        return results\n\n    except Exception as e:\n        print(f\"Error querying concepts: {str(e)}\")\n        return {\"concepts\": {}, \"relationships\": [], \"groups\": []}\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.KnowledgeBase.ConceptGraph","title":"<code>ConceptGraph</code>","text":"<p>Manages concept relationships and hierarchies</p> Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>class ConceptGraph:\n    \"\"\"Manages concept relationships and hierarchies\"\"\"\n\n    def __init__(self):\n        self.concepts: dict[str, Concept] = {}\n\n    def add_concept(self, concept: Concept):\n        \"\"\"Add or update a concept in the graph\"\"\"\n        if concept.name.lower() in self.concepts:\n            # Merge relationships and context\n            existing = self.concepts[concept.name.lower()]\n            for rel_type, related in concept.relationships.items():\n                if rel_type not in existing.relationships:\n                    existing.relationships[rel_type] = set()\n                existing.relationships[rel_type].update(related)\n            existing.context_snippets.extend(concept.context_snippets)\n            # Update importance score with rolling average\n            existing.importance_score = (existing.importance_score + concept.importance_score) / 2\n        else:\n            self.concepts[concept.name.lower()] = concept\n\n    def get_related_concepts(self, concept_name: str, relationship_type: str | None = None) -&gt; set[str]:\n        \"\"\"Get related concepts, optionally filtered by relationship type\"\"\"\n        if concept_name not in self.concepts:\n            return set()\n\n        concept = self.concepts[concept_name.lower()]\n        if relationship_type:\n            return concept.relationships.get(relationship_type, set())\n\n        related = set()\n        for relations in concept.relationships.values():\n            related.update(relations)\n        return related\n\n\n    def convert_to_networkx(self) -&gt; nx.DiGraph:\n        \"\"\"Convert ConceptGraph to NetworkX graph with layout\"\"\"\n        print(f\"Converting to NetworkX graph with {len(self.concepts.values())} concepts\")\n\n        G = nx.DiGraph()\n\n        if len(self.concepts.values()) == 0:\n            return G\n\n        for concept in self.concepts.values():\n            cks = '\\n - '.join(concept.context_snippets[:4])\n            G.add_node(\n                concept.name,\n                size=concept.importance_score * 10,\n                group=concept.category,\n                title=f\"\"\"\n                    {concept.name}\n                    Category: {concept.category}\n                    Importance: {concept.importance_score:.2f}\n                    Context: \\n - {cks}\n                    \"\"\"\n            )\n\n            for rel_type, targets in concept.relationships.items():\n                for target in targets:\n                    G.add_edge(concept.name, target, label=rel_type, title=rel_type)\n\n        return G\n</code></pre> <code>add_concept(concept)</code> \u00b6 <p>Add or update a concept in the graph</p> Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>def add_concept(self, concept: Concept):\n    \"\"\"Add or update a concept in the graph\"\"\"\n    if concept.name.lower() in self.concepts:\n        # Merge relationships and context\n        existing = self.concepts[concept.name.lower()]\n        for rel_type, related in concept.relationships.items():\n            if rel_type not in existing.relationships:\n                existing.relationships[rel_type] = set()\n            existing.relationships[rel_type].update(related)\n        existing.context_snippets.extend(concept.context_snippets)\n        # Update importance score with rolling average\n        existing.importance_score = (existing.importance_score + concept.importance_score) / 2\n    else:\n        self.concepts[concept.name.lower()] = concept\n</code></pre> <code>convert_to_networkx()</code> \u00b6 <p>Convert ConceptGraph to NetworkX graph with layout</p> Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>def convert_to_networkx(self) -&gt; nx.DiGraph:\n    \"\"\"Convert ConceptGraph to NetworkX graph with layout\"\"\"\n    print(f\"Converting to NetworkX graph with {len(self.concepts.values())} concepts\")\n\n    G = nx.DiGraph()\n\n    if len(self.concepts.values()) == 0:\n        return G\n\n    for concept in self.concepts.values():\n        cks = '\\n - '.join(concept.context_snippets[:4])\n        G.add_node(\n            concept.name,\n            size=concept.importance_score * 10,\n            group=concept.category,\n            title=f\"\"\"\n                {concept.name}\n                Category: {concept.category}\n                Importance: {concept.importance_score:.2f}\n                Context: \\n - {cks}\n                \"\"\"\n        )\n\n        for rel_type, targets in concept.relationships.items():\n            for target in targets:\n                G.add_edge(concept.name, target, label=rel_type, title=rel_type)\n\n    return G\n</code></pre> <code>get_related_concepts(concept_name, relationship_type=None)</code> \u00b6 <p>Get related concepts, optionally filtered by relationship type</p> Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>def get_related_concepts(self, concept_name: str, relationship_type: str | None = None) -&gt; set[str]:\n    \"\"\"Get related concepts, optionally filtered by relationship type\"\"\"\n    if concept_name not in self.concepts:\n        return set()\n\n    concept = self.concepts[concept_name.lower()]\n    if relationship_type:\n        return concept.relationships.get(relationship_type, set())\n\n    related = set()\n    for relations in concept.relationships.values():\n        related.update(relations)\n    return related\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.KnowledgeBase.Concepts","title":"<code>Concepts</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a collection of key concepts.</p> <p>Attributes:</p> Name Type Description <code>concepts</code> <code>List[rConcept]</code> <p>A list of Concept instances, each representing an individual key concept.</p> Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>class Concepts(BaseModel):\n    \"\"\"\n    Represents a collection of key concepts.\n\n    Attributes:\n        concepts (List[rConcept]): A list of Concept instances, each representing an individual key concept.\n    \"\"\"\n    concepts: list[rConcept]\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.KnowledgeBase.DataModel","title":"<code>DataModel</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>The main data model that encapsulates the overall analysis.</p> <p>Attributes:</p> Name Type Description <code>main_summary</code> <code>str</code> <p>A Detailed overview summarizing the key findings and relations format MD string.</p> <code>concept_analysis</code> <code>ConceptAnalysis</code> <p>An instance containing the analysis of key concepts.</p> <code>topic_insights</code> <code>TopicInsights</code> <p>An instance containing insights regarding the topics.</p> <code>relevance_assessment</code> <code>RelevanceAssessment</code> <p>An instance assessing the relevance and alignment of the query.</p> Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>class DataModel(BaseModel):\n    \"\"\"\n    The main data model that encapsulates the overall analysis.\n\n    Attributes:\n        main_summary (str): A Detailed overview summarizing the key findings and relations format MD string.\n        concept_analysis (ConceptAnalysis): An instance containing the analysis of key concepts.\n        topic_insights (TopicInsights): An instance containing insights regarding the topics.\n        relevance_assessment (RelevanceAssessment): An instance assessing the relevance and alignment of the query.\n    \"\"\"\n    main_summary: str\n    concept_analysis: ConceptAnalysis\n    topic_insights: TopicInsights\n    relevance_assessment: RelevanceAssessment\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.KnowledgeBase.DynamicRateLimiter","title":"<code>DynamicRateLimiter</code>","text":"Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>class DynamicRateLimiter:\n    def __init__(self):\n        self.last_request_time = 0.0\n        self._lock = asyncio.Lock()\n\n    def update_rate(self, requests_per_second: float):\n        \"\"\"Update rate limit dynamically\"\"\"\n        self.min_interval = 1.0 / requests_per_second if requests_per_second &gt; 0 else float('inf')\n\n    async def acquire(self):\n        \"\"\"Acquire permission to make a request\"\"\"\n        async with self._lock:\n            current_time = time.time()\n            time_since_last = current_time - self.last_request_time\n            if time_since_last &lt; self.min_interval:\n                wait_time = self.min_interval - time_since_last\n                await asyncio.sleep(wait_time)\n            self.last_request_time = time.time()\n</code></pre> <code>acquire()</code> <code>async</code> \u00b6 <p>Acquire permission to make a request</p> Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>async def acquire(self):\n    \"\"\"Acquire permission to make a request\"\"\"\n    async with self._lock:\n        current_time = time.time()\n        time_since_last = current_time - self.last_request_time\n        if time_since_last &lt; self.min_interval:\n            wait_time = self.min_interval - time_since_last\n            await asyncio.sleep(wait_time)\n        self.last_request_time = time.time()\n</code></pre> <code>update_rate(requests_per_second)</code> \u00b6 <p>Update rate limit dynamically</p> Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>def update_rate(self, requests_per_second: float):\n    \"\"\"Update rate limit dynamically\"\"\"\n    self.min_interval = 1.0 / requests_per_second if requests_per_second &gt; 0 else float('inf')\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.KnowledgeBase.GraphVisualizer","title":"<code>GraphVisualizer</code>","text":"Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>class GraphVisualizer:\n    @staticmethod\n    def visualize(nx_graph: nx.DiGraph, output_file: str = \"concept_graph.html\", get_output=False):\n        \"\"\"Create interactive visualization using PyVis\"\"\"\n        from pyvis.network import Network\n        net = Network(\n            height=\"800px\",\n            width=\"100%\",\n            notebook=False,\n            directed=True,\n            bgcolor=\"#1a1a1a\",\n            font_color=\"white\"\n        )\n\n        net.from_nx(nx_graph)\n\n        net.save_graph(output_file)\n        print(f\"Graph saved to {output_file} Open in browser to view.\", len(nx_graph))\n        if get_output:\n            c = open(output_file, encoding=\"utf-8\").read()\n            os.remove(output_file)\n            return c\n</code></pre> <code>visualize(nx_graph, output_file='concept_graph.html', get_output=False)</code> <code>staticmethod</code> \u00b6 <p>Create interactive visualization using PyVis</p> Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>@staticmethod\ndef visualize(nx_graph: nx.DiGraph, output_file: str = \"concept_graph.html\", get_output=False):\n    \"\"\"Create interactive visualization using PyVis\"\"\"\n    from pyvis.network import Network\n    net = Network(\n        height=\"800px\",\n        width=\"100%\",\n        notebook=False,\n        directed=True,\n        bgcolor=\"#1a1a1a\",\n        font_color=\"white\"\n    )\n\n    net.from_nx(nx_graph)\n\n    net.save_graph(output_file)\n    print(f\"Graph saved to {output_file} Open in browser to view.\", len(nx_graph))\n    if get_output:\n        c = open(output_file, encoding=\"utf-8\").read()\n        os.remove(output_file)\n        return c\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.KnowledgeBase.KnowledgeBase","title":"<code>KnowledgeBase</code>","text":"Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>class KnowledgeBase:\n    def __init__(self, embedding_dim: int = 256, similarity_threshold: float = 0.61, batch_size: int = 64,\n                 n_clusters: int = 4, deduplication_threshold: float = 0.85, model_name=os.getenv(\"SUMMARYMODEL\"),\n                 embedding_model=os.getenv(\"DEFAULTMODELEMBEDDING\"),\n                 vis_class:str | None = \"FaissVectorStore\",\n                 vis_kwargs:dict[str, Any] | None=None,\n                 requests_per_second=85.,\n                 chunk_size: int = 3600,\n                 chunk_overlap: int = 130,\n                 separator: str = \"\\n\"\n                 ):\n        \"\"\"Initialize the knowledge base with given parameters\"\"\"\n\n        self.existing_hashes: set[str] = set()\n        self.embedding_model = embedding_model\n        self.embedding_dim = embedding_dim\n        self.similarity_threshold = similarity_threshold\n        self.deduplication_threshold = deduplication_threshold\n        if model_name == \"openrouter/mistralai/mistral-nemo\":\n            batch_size = 9\n            requests_per_second = 1.5\n        self.batch_size = batch_size\n        self.n_clusters = n_clusters\n        self.model_name = model_name\n        self.sto: list = []\n\n        self.text_splitter = TextSplitter(chunk_size=chunk_size,chunk_overlap=chunk_overlap, separator=separator)\n        self.similarity_graph = {}\n        self.concept_extractor = ConceptExtractor(self, requests_per_second)\n\n        self.vis_class = None\n        self.vis_kwargs = None\n        self.vdb = None\n        self.init_vis(vis_class, vis_kwargs)\n\n    def init_vis(self, vis_class, vis_kwargs):\n        if vis_class is None:\n            vis_class = \"FaissVectorStore\"\n        if vis_class == \"FaissVectorStore\":\n            if vis_kwargs is None:\n                vis_kwargs = {\n                    \"dimension\": self.embedding_dim\n                }\n            self.vdb = FaissVectorStore(**vis_kwargs)\n        else:\n            from toolboxv2.mods.isaa.base.VectorStores.taichiNumpyNumbaVectorStores import (\n                EnhancedVectorStore,\n                FastVectorStore1,\n                FastVectorStoreO,\n                NumpyVectorStore,\n                VectorStoreConfig,\n            )\n        if vis_class == \"FastVectorStoreO\":\n            if vis_kwargs is None:\n                vis_kwargs = {\n                    \"embedding_size\": self.embedding_dim\n                }\n            self.vdb = FastVectorStoreO(**vis_kwargs)\n        if vis_class == \"EnhancedVectorStore\":\n            if vis_kwargs is None:\n                vis_kwargs = {\n                    \"dimension\": self.embedding_dim\n                }\n            vis_kwargs = VectorStoreConfig(**vis_kwargs)\n            self.vdb = EnhancedVectorStore(vis_kwargs)\n        if vis_class == \"FastVectorStore1\":\n            self.vdb = FastVectorStore1()\n        if vis_class == \"NumpyVectorStore\":\n            self.vdb = NumpyVectorStore()\n\n        self.vis_class = vis_class\n        self.vis_kwargs = vis_kwargs\n\n\n    @staticmethod\n    def compute_hash(text: str) -&gt; str:\n        \"\"\"Compute SHA-256 hash of text\"\"\"\n        return hashlib.sha256(text.encode('utf-8', errors='ignore')).hexdigest()\n\n    async def _get_embeddings(self, texts: list[str]) -&gt; np.ndarray:\n        \"\"\"Get normalized embeddings in batches\"\"\"\n        try:\n            async def process_batch(batch: list[str]) -&gt; np.ndarray:\n                from toolboxv2.mods.isaa.extras.adapter import litellm_embed\n                # print(\"Processing\", batch)\n                embeddings = await litellm_embed(texts=batch, model=self.embedding_model)\n                return normalize_vectors(embeddings)\n\n            tasks = []\n            for i in range(0, len(texts), self.batch_size):\n                batch = texts[i:i + self.batch_size]\n                tasks.append(process_batch(batch))\n\n            embeddings = await asyncio.gather(*tasks)\n            i__[0] += len(texts)\n            return np.vstack(embeddings)\n        except Exception as e:\n            get_logger().error(f\"Error generating embeddings: {str(e)}\")\n            raise\n\n\n\n    def _remove_similar_chunks(self, threshold: float = None) -&gt; int:\n        \"\"\"Remove chunks that are too similar to each other\"\"\"\n        if len(self.vdb.chunks) &lt; 2:\n            return 0\n\n        if threshold is None:\n            threshold = self.deduplication_threshold\n\n        try:\n            # Get all embeddings\n            embeddings = np.vstack([c.embedding for c in self.vdb.chunks])\n            n = len(embeddings)\n\n            # Compute similarity matrix\n            similarities = np.dot(embeddings, embeddings.T)\n\n            # Create mask for chunks to keep\n            keep_mask = np.ones(n, dtype=bool)\n\n            # Iterate through chunks\n            for i in range(n):\n                if not keep_mask[i]:\n                    continue\n\n                # Find chunks that are too similar to current chunk\n                similar_indices = similarities[i] &gt;= threshold\n                similar_indices[i] = False  # Don't count self-similarity\n\n                # Mark similar chunks for removal\n                keep_mask[similar_indices] = False\n\n            # Keep only unique chunks\n            unique_chunks = [chunk for chunk, keep in zip(self.vdb.chunks, keep_mask, strict=False) if keep]\n            removed_count = len(self.vdb.chunks) - len(unique_chunks)\n\n            # Update chunks and hashes\n            self.vdb.chunks = unique_chunks\n            self.existing_hashes = {chunk.content_hash for chunk in self.vdb.chunks}\n\n            # Rebuild index if chunks were removed\n            if removed_count &gt; 0:\n                self.vdb.rebuild_index()\n\n\n            return removed_count\n\n        except Exception as e:\n            get_logger().error(f\"Error removing similar chunks: {str(e)}\")\n            raise\n\n    async def _add_data(\n        self,\n        texts: list[str],\n        metadata: list[dict[str, Any]] | None= None,\n    ) -&gt; tuple[int, int]:\n        \"\"\"\n        Process and add new data to the knowledge base\n        Returns: Tuple of (added_count, duplicate_count)\n        \"\"\"\n        if len(texts) == 0:\n            return -1, -1\n        try:\n            # Compute hashes and filter exact duplicates\n            hashes = [self.compute_hash(text) for text in texts]\n            unique_data = []\n            for t, m, h in zip(texts, metadata, hashes, strict=False):\n                if h in self.existing_hashes:\n                    continue\n                # Update existing hashes\n                self.existing_hashes.add(h)\n                unique_data.append((t, m, h))\n\n            if not unique_data:\n                return 0, len(texts)\n\n            # Get embeddings\n            embeddings = await self._get_embeddings(texts)\n\n            texts = []\n            metadata = []\n            hashes = []\n            embeddings_final = []\n            if len(self.vdb.chunks):\n                for i, d in enumerate(unique_data):\n                    c = self.vdb.search(embeddings[i], 5, self.deduplication_threshold)\n                    if len(c) &gt; 2:\n                        continue\n                    t, m, h = d\n                    texts.append(t)\n                    metadata.append(m)\n                    hashes.append(h)\n                    embeddings_final.append(embeddings[i])\n\n            else:\n                texts , metadata, hashes = zip(*unique_data, strict=False)\n                embeddings_final = embeddings\n\n            if not texts:  # All were similar to existing chunks\n                return 0, len(unique_data)\n\n            # Create and add new chunks\n            new_chunks = [\n                Chunk(text=t, embedding=e, metadata=m, content_hash=h)\n                for t, e, m, h in zip(texts, embeddings_final, metadata, hashes, strict=False)\n            ]\n\n            # Add new chunks\n            # Update index\n            if new_chunks:\n                all_embeddings = np.vstack([c.embedding for c in new_chunks])\n                self.vdb.add_embeddings(all_embeddings, new_chunks)\n\n            # Remove similar chunks from the entire collection\n            removed = self._remove_similar_chunks()\n            get_logger().info(f\"Removed {removed} similar chunks during deduplication\")\n            # Invalidate visualization cache\n\n            if len(new_chunks) - removed &gt; 0:\n                # Process new chunks for concepts\n                await self.concept_extractor.process_chunks(new_chunks)\n            print(\"[total, calls, errors]\", i__)\n\n            return len(new_chunks) - removed, len(texts) - len(new_chunks) + removed\n\n        except Exception as e:\n            get_logger().error(f\"Error adding data: {str(e)}\")\n            raise\n\n\n    async def add_data(\n        self,\n        texts: list[str],\n        metadata: list[dict[str, Any]] | None = None, direct:bool = False\n    ) -&gt; tuple[int, int]:\n        \"\"\"Enhanced version with smart splitting and clustering\"\"\"\n        if isinstance(texts, str):\n            texts = [texts]\n        if metadata is None:\n            metadata = [{}] * len(texts)\n        if isinstance(metadata, dict):\n            metadata = [metadata]\n        if len(texts) != len(metadata):\n            raise ValueError(\"Length of texts and metadata must match\")\n\n        if not direct and len(texts) == 1 and len(texts[0]) &lt; 10_000:\n            if len(self.sto) &lt; self.batch_size and len(texts) == 1:\n                self.sto.append((texts[0], metadata[0]))\n                return -1, -1\n            if len(self.sto) &gt;= self.batch_size:\n                _ = [texts.append(t) or metadata.append([m]) for (t, m) in self.sto]\n                self.sto = []\n\n        # Split large texts\n        split_texts = []\n        split_metadata = []\n\n        while Spinner(\"Saving Data to Memory\", symbols='t'):\n\n            for idx, text in enumerate(texts):\n                chunks = self.text_splitter.split_text(text)\n                split_texts.extend(chunks)\n\n                # Adjust metadata for splits\n                meta = metadata[idx] if metadata else {}\n                if isinstance(meta, list):\n                    meta = meta[0]\n                for i, _chunk in enumerate(chunks):\n                    chunk_meta = meta.copy()\n                    chunk_meta.update({\n                        'chunk_index': i,\n                        'total_chunks': len(chunks),\n                        'original_text_id': idx\n                    })\n                    split_metadata.append(chunk_meta)\n\n            return await self._add_data(split_texts, split_metadata)\n\n    def _update_similarity_graph(self, embeddings: np.ndarray, chunk_ids: list[int]):\n        \"\"\"Update similarity graph for connected information detection\"\"\"\n        similarities = np.dot(embeddings, embeddings.T)\n\n        for i in range(len(chunk_ids)):\n            for j in range(i + 1, len(chunk_ids)):\n                if similarities[i, j] &gt;= self.similarity_threshold:\n                    id1, id2 = chunk_ids[i], chunk_ids[j]\n                    if id1 not in self.similarity_graph:\n                        self.similarity_graph[id1] = set()\n                    if id2 not in self.similarity_graph:\n                        self.similarity_graph[id2] = set()\n                    self.similarity_graph[id1].add(id2)\n                    self.similarity_graph[id2].add(id1)\n\n    async def retrieve(\n        self,\n        query: str=\"\",\n        query_embedding: np.ndarray | None = None,\n        k: int = 5,\n        min_similarity: float = 0.2,\n        include_connected: bool = True\n    ) -&gt; list[Chunk]:\n        \"\"\"Enhanced retrieval with connected information\"\"\"\n        if query_embedding is None:\n            query_embedding = (await self._get_embeddings([query]))[0]\n        k = min(k, len(self.vdb.chunks))\n        if k &lt;= 0:\n            return []\n        initial_results = self.vdb.search(query_embedding, k, min_similarity)\n\n        if not include_connected or not initial_results:\n            return initial_results\n\n        # Find connected chunks\n        connected_chunks = set()\n        for chunk in initial_results:\n            chunk_id = self.vdb.chunks.index(chunk)\n            if chunk_id in self.similarity_graph:\n                connected_chunks.update(self.similarity_graph[chunk_id])\n\n        # Add connected chunks to results\n        all_chunks = self.vdb.chunks\n        additional_results = [all_chunks[i] for i in connected_chunks\n                              if all_chunks[i] not in initial_results]\n\n        # Sort by similarity to query\n        all_results = initial_results + additional_results\n\n        return sorted(\n            all_results,\n            key=lambda x: np.dot(x.embedding, query_embedding),\n            reverse=True\n        )[:k * 2]  # Return more results when including connected information\n\n    async def forget_irrelevant(self, irrelevant_concepts: list[str], similarity_threshold: float | None=None) -&gt; int:\n        \"\"\"\n        Remove chunks similar to irrelevant concepts\n        Returns: Number of chunks removed\n        \"\"\"\n        if not irrelevant_concepts:\n            return 0\n\n        if similarity_threshold is None:\n            similarity_threshold = self.similarity_threshold\n\n        try:\n            irrelevant_embeddings = await self._get_embeddings(irrelevant_concepts)\n            initial_count = len(self.vdb.chunks)\n\n            def is_relevant(chunk: Chunk) -&gt; bool:\n                similarities = np.dot(chunk.embedding, irrelevant_embeddings.T)\n                do_keep = np.max(similarities) &lt; similarity_threshold\n                if do_keep:\n                    return True\n                for c in chunk.metadata.get(\"concepts\", []):\n                    if c in self.concept_extractor.concept_graph.concepts:\n                        del self.concept_extractor.concept_graph.concepts[c]\n                return False\n\n            relevant_chunks = [chunk for chunk in self.vdb.chunks if is_relevant(chunk)]\n            self.vdb.chunks = relevant_chunks\n            self.existing_hashes = {chunk.content_hash for chunk in self.vdb.chunks}\n            self.vdb.rebuild_index()\n\n            return initial_count - len(self.vdb.chunks)\n\n        except Exception as e:\n            get_logger().error(f\"Error forgetting irrelevant concepts: {str(e)}\")\n            raise\n\n    ## ----------------------------------------------------------------\n\n    def _cluster_chunks(\n        self,\n        chunks: list[Chunk],\n        query_embedding: np.ndarray | None = None,\n        min_cluster_size: int = 2,\n        min_samples: int = 1,\n        max_clusters: int = 10\n    ) -&gt; dict[int, list[Chunk]]:\n        \"\"\"\n        Enhanced clustering of chunks into topics with query awareness\n        and dynamic parameter adjustment\n        \"\"\"\n        if len(chunks) &lt; 2:\n            return {0: chunks}\n\n        embeddings = np.vstack([chunk.embedding for chunk in chunks])\n\n        # Normalize embeddings for cosine similarity\n        embeddings = normalize_vectors(embeddings)\n\n        # If query is provided, weight embeddings by query relevance\n        if query_embedding is not None:\n            query_similarities = np.dot(embeddings, query_embedding)\n            # Apply soft weighting to maintain structure while considering query relevance\n            embeddings = embeddings * query_similarities[:, np.newaxis]\n            embeddings = normalize_vectors(embeddings)\n\n        # Dynamic parameter adjustment based on dataset size\n        adjusted_min_cluster_size = max(\n            min_cluster_size,\n            min(len(chunks) // 10, 5)  # Scale with data size, max 5\n        )\n\n        adjusted_min_samples = max(\n            min_samples,\n            adjusted_min_cluster_size // 2\n        )\n\n        # Try different parameter combinations for optimal clustering\n        best_clusters = None\n        best_score = float('-inf')\n\n        epsilon_range = [0.2, 0.3, 0.4]\n\n        for epsilon in epsilon_range:\n            clusterer = HDBSCAN(\n                min_cluster_size=adjusted_min_cluster_size,\n                min_samples=adjusted_min_samples,\n                metric='cosine',\n                cluster_selection_epsilon=epsilon\n            )\n\n            cluster_labels = clusterer.fit_predict(embeddings)\n\n            # Skip if all points are noise\n            if len(set(cluster_labels)) &lt;= 1:\n                continue\n\n            # Calculate clustering quality metrics\n            score = self._evaluate_clustering(\n                embeddings,\n                cluster_labels,\n                query_embedding\n            )\n\n            if score &gt; best_score:\n                best_score = score\n                best_clusters = cluster_labels\n\n        # If no good clustering found, fall back to simpler approach\n        if best_clusters is None:\n            return self._fallback_clustering(chunks, query_embedding)\n\n        # Organize chunks by cluster\n        clusters: dict[int, list[Chunk]] = {}\n\n        # Sort clusters by size and relevance\n        cluster_scores = []\n\n        for label in set(best_clusters):\n            if label == -1:  # Handle noise points separately\n                continue\n\n            # Fixed: Use boolean mask to select chunks for current cluster\n            cluster_mask = best_clusters == label\n            cluster_chunks = [chunk for chunk, is_in_cluster in zip(chunks, cluster_mask, strict=False) if is_in_cluster]\n\n            # Skip empty clusters\n            if not cluster_chunks:\n                continue\n\n            # Calculate cluster score based on size and query relevance\n            score = len(cluster_chunks)\n            if query_embedding is not None:\n                cluster_embeddings = np.vstack([c.embedding for c in cluster_chunks])\n                query_relevance = np.mean(np.dot(cluster_embeddings, query_embedding))\n                score = score * (1 + query_relevance)  # Boost by relevance\n\n            cluster_scores.append((label, score, cluster_chunks))\n\n        # Sort clusters by score and limit to max_clusters\n        cluster_scores.sort(key=lambda x: x[1], reverse=True)\n\n        # Assign cleaned clusters\n        for i, (_, _, cluster_chunks) in enumerate(cluster_scores[:max_clusters]):\n            clusters[i] = cluster_chunks\n\n        # Handle noise points by assigning to nearest cluster\n        noise_chunks = [chunk for chunk, label in zip(chunks, best_clusters, strict=False) if label == -1]\n        if noise_chunks:\n            self._assign_noise_points(noise_chunks, clusters, query_embedding)\n\n        return clusters\n\n    @staticmethod\n    def _evaluate_clustering(\n        embeddings: np.ndarray,\n        labels: np.ndarray,\n        query_embedding: np.ndarray | None = None\n    ) -&gt; float:\n        \"\"\"\n        Evaluate clustering quality using multiple metrics\n        \"\"\"\n        if len(set(labels)) &lt;= 1:\n            return float('-inf')\n\n        # Calculate silhouette score for cluster cohesion\n        from sklearn.metrics import silhouette_score\n        try:\n            sil_score = silhouette_score(embeddings, labels, metric='cosine')\n        except:\n            sil_score = -1\n\n        # Calculate Davies-Bouldin score for cluster separation\n        from sklearn.metrics import davies_bouldin_score\n        try:\n            db_score = -davies_bouldin_score(embeddings, labels)  # Negated as lower is better\n        except:\n            db_score = -1\n\n        # Calculate query relevance if provided\n        query_score = 0\n        if query_embedding is not None:\n            unique_labels = set(labels) - {-1}\n            if unique_labels:\n                query_sims = []\n                for label in unique_labels:\n                    cluster_mask = labels == label\n                    cluster_embeddings = embeddings[cluster_mask]\n                    cluster_centroid = np.mean(cluster_embeddings, axis=0)\n                    query_sims.append(np.dot(cluster_centroid, query_embedding))\n                query_score = np.mean(query_sims)\n\n        # Combine scores with weights\n        combined_score = (\n            0.4 * sil_score +\n            0.3 * db_score +\n            0.3 * query_score\n        )\n\n        return combined_score\n\n    @staticmethod\n    def _fallback_clustering(\n        chunks: list[Chunk],\n        query_embedding: np.ndarray | None = None\n    ) -&gt; dict[int, list[Chunk]]:\n        \"\"\"\n        Simple fallback clustering when HDBSCAN fails\n        \"\"\"\n        if query_embedding is not None:\n            # Sort by query relevance\n            chunks_with_scores = [\n                (chunk, np.dot(chunk.embedding, query_embedding))\n                for chunk in chunks\n            ]\n            chunks_with_scores.sort(key=lambda x: x[1], reverse=True)\n            chunks = [c for c, _ in chunks_with_scores]\n\n        # Create fixed-size clusters\n        clusters = {}\n        cluster_size = max(2, len(chunks) // 5)\n\n        for i in range(0, len(chunks), cluster_size):\n            clusters[len(clusters)] = chunks[i:i + cluster_size]\n\n        return clusters\n\n    @staticmethod\n    def _assign_noise_points(\n        noise_chunks: list[Chunk],\n        clusters: dict[int, list[Chunk]],\n        query_embedding: np.ndarray | None = None\n    ) -&gt; None:\n        \"\"\"\n        Assign noise points to nearest clusters\n        \"\"\"\n        if not clusters:\n            clusters[0] = noise_chunks\n            return\n\n        for chunk in noise_chunks:\n            best_cluster = None\n            best_similarity = float('-inf')\n\n            for cluster_id, cluster_chunks in clusters.items():\n                cluster_embeddings = np.vstack([c.embedding for c in cluster_chunks])\n                cluster_centroid = np.mean(cluster_embeddings, axis=0)\n\n                similarity = np.dot(chunk.embedding, cluster_centroid)\n\n                # Consider query relevance in assignment if available\n                if query_embedding is not None:\n                    query_sim = np.dot(chunk.embedding, query_embedding)\n                    similarity = 0.7 * similarity + 0.3 * query_sim\n\n                if similarity &gt; best_similarity:\n                    best_similarity = similarity\n                    best_cluster = cluster_id\n\n            if best_cluster is not None:\n                clusters[best_cluster].append(chunk)\n\n    @staticmethod\n    def _generate_topic_summary(\n        chunks: list[Chunk],\n        query_embedding: np.ndarray,\n        max_sentences=3\n    ) -&gt; str:\n        \"\"\"Generate a summary for a topic using most representative chunks\"\"\"\n        if not chunks:\n            return \"\"\n\n        # Find chunks most similar to cluster centroid\n        embeddings = np.vstack([chunk.embedding for chunk in chunks])\n        centroid = embeddings.mean(axis=0)\n\n        # Calculate similarities to both centroid and query\n        centroid_sims = np.dot(embeddings, centroid)\n        query_sims = np.dot(embeddings, query_embedding)\n\n        # Combine both similarities\n        combined_sims = 0.7 * centroid_sims + 0.3 * query_sims\n\n        # Select top sentences from most representative chunks\n        top_indices = np.argsort(combined_sims)[-max_sentences:]\n        summary_chunks = [chunks[i] for i in top_indices]\n\n        # Extract key sentences\n        sentences = []\n        for chunk in summary_chunks:\n            sentences.extend(sent.strip() for sent in chunk.text.split('.') if sent.strip())\n\n        return '. '.join(sentences[:max_sentences]) + '.'\n\n    async def retrieve_with_overview(\n        self,\n        query: str,\n        query_embedding=None,\n        k: int = 5,\n        min_similarity: float = 0.2,\n        max_sentences: int = 5,\n        cross_ref_depth: int = 2,\n        max_cross_refs: int = 10  # New parameter to control cross-reference count\n    ) -&gt; RetrievalResult:\n        \"\"\"Enhanced retrieval with better cross-reference handling\"\"\"\n        # Get initial results with query embedding\n        if query_embedding is None:\n            query_embedding = (await self._get_embeddings([query]))[0]\n        initial_results = await self.retrieve(query_embedding=query_embedding, k=k, min_similarity=min_similarity)\n\n        if not initial_results:\n            return RetrievalResult([], [], {})\n\n        # Find cross-references with similarity scoring\n        initial_ids = {self.vdb.chunks.index(chunk) for chunk in initial_results}\n        related_ids = self._find_cross_references(\n            initial_ids,\n            depth=cross_ref_depth,\n            query_embedding=query_embedding  # Pass query embedding for relevance scoring\n        )\n\n        # Get all relevant chunks with smarter filtering\n        all_chunks = self.vdb.chunks\n        all_relevant_chunks = initial_results + [\n            chunk for i, chunk in enumerate(all_chunks)\n            if i in related_ids and self._is_relevant_cross_ref(\n                chunk,\n                query_embedding,\n                initial_results\n            )\n        ]\n\n        # Enhanced clustering with dynamic cluster size\n        clusters = self._cluster_chunks(\n            all_relevant_chunks,\n            query_embedding=query_embedding\n        )\n\n        # Fallback: If no clusters are found, treat all relevant chunks as a single cluster.\n        if not clusters:\n            print(\"No clusters found. Falling back to using all relevant chunks as a single cluster.\")\n            clusters = {0: all_relevant_chunks}\n\n        # Generate summaries and organize results\n        overview = []\n        cross_references = {}\n\n        for cluster_id, cluster_chunks in clusters.items():\n            summary = self._generate_topic_summary(\n                cluster_chunks,\n                query_embedding,\n                max_sentences=max_sentences  # Increased for more context\n            )\n\n            # Enhanced chunk sorting with combined scoring\n            sorted_chunks = self._sort_chunks_by_relevance(\n                cluster_chunks,\n                query_embedding,\n                initial_results\n            )\n\n            # Separate direct matches and cross-references\n            direct_matches_ = [{'text':c.text, 'metadata':c.metadata} for c in sorted_chunks if c in initial_results]\n            direct_matches = []\n            for match in direct_matches_:\n                if match in direct_matches:\n                    continue\n                direct_matches.append(match)\n            cross_refs_ = [c for c in sorted_chunks if c not in initial_results]\n            cross_refs = []\n            for match in cross_refs_:\n                if match in cross_refs:\n                    continue\n                cross_refs.append(match)\n            # Limit cross-references while maintaining diversity\n            selected_cross_refs = self._select_diverse_cross_refs(\n                cross_refs,\n                max_cross_refs,\n                query_embedding\n            )\n\n            topic_info = {\n                'topic_id': cluster_id,\n                'summary': summary,\n                'main_chunks': [x for x in direct_matches[:3]],\n                'chunk_count': len(cluster_chunks),\n                'relevance_score': self._calculate_topic_relevance(\n                    cluster_chunks,\n                    query_embedding\n                )\n            }\n            overview.append(topic_info)\n\n            if selected_cross_refs:\n                cross_references[f\"topic_{cluster_id}\"] = selected_cross_refs\n\n        # Sort overview by relevance score\n        overview.sort(key=lambda x: x['relevance_score'], reverse=True)\n\n        return RetrievalResult(\n            overview=overview,\n            details=initial_results,\n            cross_references=cross_references\n        )\n\n    def _find_cross_references(\n        self,\n        chunk_ids: set[int],\n        depth: int,\n        query_embedding: np.ndarray\n    ) -&gt; set[int]:\n        \"\"\"Enhanced cross-reference finding with relevance scoring\"\"\"\n        related_ids = set(chunk_ids)\n        current_depth = 0\n        frontier = set(chunk_ids)\n\n        while current_depth &lt; depth and frontier:\n            new_frontier = set()\n            for chunk_id in frontier:\n                if chunk_id in self.similarity_graph:\n                    # Score potential cross-references by relevance\n                    candidates = self.similarity_graph[chunk_id] - related_ids\n                    scored_candidates = [\n                        (cid, self._calculate_topic_relevance(\n                            [self.vdb.chunks[cid]],\n                            query_embedding\n                        ))\n                        for cid in candidates\n                    ]\n\n                    # Filter by relevance threshold\n                    relevant_candidates = {\n                        cid for cid, score in scored_candidates\n                        if score &gt; 0.5  # Adjustable threshold\n                    }\n                    new_frontier.update(relevant_candidates)\n\n            related_ids.update(new_frontier)\n            frontier = new_frontier\n            current_depth += 1\n\n        return related_ids\n\n    @staticmethod\n    def _is_relevant_cross_ref(\n        chunk: Chunk,\n        query_embedding: np.ndarray,\n        initial_results: list[Chunk]\n    ) -&gt; bool:\n        \"\"\"Determine if a cross-reference is relevant enough to include\"\"\"\n        # Calculate similarity to query\n        query_similarity = np.dot(chunk.embedding, query_embedding)\n\n        # Calculate similarity to initial results\n        initial_similarities = [\n            np.dot(chunk.embedding, r.embedding) for r in initial_results\n        ]\n        max_initial_similarity = max(initial_similarities)\n\n        # Combined relevance score\n        relevance_score = 0.7 * query_similarity + 0.3 * max_initial_similarity\n\n        return relevance_score &gt; 0.6  # Adjustable threshold\n\n    @staticmethod\n    def _select_diverse_cross_refs(\n        cross_refs: list[Chunk],\n        max_count: int,\n        query_embedding: np.ndarray\n    ) -&gt; list[Chunk]:\n        \"\"\"Select diverse and relevant cross-references\"\"\"\n        if not cross_refs or len(cross_refs) &lt;= max_count:\n            return cross_refs\n\n        # Calculate diversity scores\n        embeddings = np.vstack([c.embedding for c in cross_refs])\n        similarities = np.dot(embeddings, embeddings.T)\n\n        selected = []\n        remaining = list(enumerate(cross_refs))\n\n        while len(selected) &lt; max_count and remaining:\n            # Score remaining chunks by relevance and diversity\n            scores = []\n            for idx, chunk in remaining:\n                relevance = np.dot(chunk.embedding, query_embedding)\n                diversity = 1.0\n                if selected:\n                    # Calculate diversity penalty based on similarity to selected chunks\n                    selected_similarities = [\n                        similarities[idx][list(cross_refs).index(s)]\n                        for s in selected\n                    ]\n                    diversity = 1.0 - max(selected_similarities)\n\n                combined_score = 0.7 * relevance + 0.3 * diversity\n                scores.append((combined_score, idx, chunk))\n\n            # Select the highest scoring chunk\n            scores.sort(reverse=True)\n            _, idx, chunk = scores[0]\n            selected.append(chunk)\n            remaining = [(i, c) for i, c in remaining if i != idx]\n\n        return selected\n\n    @staticmethod\n    def _calculate_topic_relevance(\n        chunks: list[Chunk],\n        query_embedding: np.ndarray,\n    ) -&gt; float:\n        \"\"\"Calculate overall topic relevance score\"\"\"\n        if not chunks:\n            return 0.0\n\n        similarities = [\n            np.dot(chunk.embedding, query_embedding) for chunk in chunks\n        ]\n        return np.mean(similarities)\n\n    @staticmethod\n    def _sort_chunks_by_relevance(\n        chunks: list[Chunk],\n        query_embedding: np.ndarray,\n        initial_results: list[Chunk]\n    ) -&gt; list[Chunk]:\n        \"\"\"Sort chunks by combined relevance score\"\"\"\n        scored_chunks = []\n        for chunk in chunks:\n            query_similarity = np.dot(chunk.embedding, query_embedding)\n            initial_similarities = [\n                np.dot(chunk.embedding, r.embedding)\n                for r in initial_results\n            ]\n            max_initial_similarity = max(initial_similarities) if initial_similarities else 0\n\n            # Combined score favoring query relevance\n            combined_score = 0.7 * query_similarity + 0.3 * max_initial_similarity\n            scored_chunks.append((combined_score, chunk))\n\n        scored_chunks.sort(reverse=True)\n        return [chunk for _, chunk in scored_chunks]\n\n    async def query_concepts(self, query: str) -&gt; dict[str, any]:\n        \"\"\"Query concepts extracted from the knowledge base\"\"\"\n        return await self.concept_extractor.query_concepts(query)\n\n    async def unified_retrieve(\n        self,\n        query: str,\n        k: int = 5,\n        min_similarity: float = 0.2,\n        cross_ref_depth: int = 2,\n        max_cross_refs: int = 10,\n        max_sentences: int = 10\n    ) -&gt; dict[str, Any]:\n        \"\"\"\n        Unified retrieval function that combines concept querying, retrieval with overview,\n        and basic retrieval, then generates a comprehensive summary using LLM.\n\n        Args:\n            query: Search query string\n            k: Number of primary results to retrieve\n            min_similarity: Minimum similarity threshold for retrieval\n            cross_ref_depth: Depth for cross-reference search\n            max_cross_refs: Maximum number of cross-references per topic\n            max_sentences: Maximum number Sentences in the main summary text\n\n        Returns:\n            Dictionary containing comprehensive results including summary and details\n        \"\"\"\n        # Get concept information\n        concept_results = await self.concept_extractor.query_concepts(query)\n\n        # Get retrieval overview\n\n        query_embedding = (await self._get_embeddings([query]))[0]\n        overview_results = await self.retrieve_with_overview(\n            query=query,\n            query_embedding=query_embedding,\n            k=k,\n            min_similarity=min_similarity,\n            cross_ref_depth=cross_ref_depth,\n            max_cross_refs=max_cross_refs,\n            max_sentences=max_sentences\n        )\n\n        # Get basic retrieval results\n        basic_results = await self.retrieve(\n            query_embedding=query_embedding,\n            k=k,\n            min_similarity=min_similarity\n        )\n        if len(basic_results) == 0:\n            return {}\n        if len(basic_results) == 1 and isinstance(basic_results[0], str) and basic_results[0].endswith('[]\\n - []\\n - []'):\n            return {}\n\n        # Prepare context for LLM summary\n        context = {\n            \"concepts\": {\n                \"main_concepts\": concept_results.get(\"concepts\", {}),\n                \"relationships\": concept_results.get(\"relationships\", []),\n                \"concept_groups\": concept_results.get(\"groups\", [])\n            },\n            \"topics\": [\n                {\n                    \"id\": topic[\"topic_id\"],\n                    \"summary\": topic[\"summary\"],\n                    \"relevance\": topic[\"relevance_score\"],\n                    \"chunk_count\": topic[\"chunk_count\"]\n                }\n                for topic in overview_results.overview\n            ],\n            \"key_chunks\": [\n                {\n                    \"text\": chunk.text,\n                    \"metadata\": chunk.metadata\n                }\n                for chunk in basic_results\n            ]\n        }\n\n        # Generate comprehensive summary using LLM\n        system_prompt = \"\"\"\n        Analyze the provided search results and generate a comprehensive summary\n        that includes:\n        1. Main concepts and their relationships\n        2. Key topics and their relevance\n        3. Most important findings and insights\n        4. Cross-references and connections between topics\n        5. Potential gaps or areas for further investigation\n\n        Format the response as a JSON object with these sections.\n        \"\"\"\n\n        prompt = f\"\"\"\n        Query: {query}\n\n        Context:\n        {json.dumps(context, indent=2)}\n\n        Generate a comprehensive analysis and summary following the structure:\n        \"\"\"\n\n        try:\n            await asyncio.sleep(0.25)\n            llm_response = await litellm_complete(\n                model_name=self.model_name,\n                prompt=prompt,\n                system_prompt=system_prompt,\n                response_format=DataModel,\n            )\n            summary_analysis = json.loads(llm_response)\n        except Exception as e:\n            get_logger().error(f\"Error generating summary: {str(e)}\")\n            summary_analysis = {\n                \"main_summary\": \"Error generating summary\",\n                \"error\": str(e)\n            }\n\n        # Compile final results\n        return {\n            \"summary\": summary_analysis,\n            \"raw_results\": {\n                \"concepts\": concept_results,\n                \"overview\": {\n                    \"topics\": overview_results.overview,\n                    \"cross_references\": overview_results.cross_references\n                },\n                \"relevant_chunks\": [\n                    {\n                        \"text\": chunk.text,\n                        \"metadata\": chunk.metadata,\n                        \"cluster_id\": chunk.cluster_id\n                    }\n                    for chunk in basic_results\n                ]\n            },\n            \"metadata\": {\n                \"query\": query,\n                \"timestamp\": time.time(),\n                \"retrieval_params\": {\n                    \"k\": k,\n                    \"min_similarity\": min_similarity,\n                    \"cross_ref_depth\": cross_ref_depth,\n                    \"max_cross_refs\": max_cross_refs\n                }\n            }\n        }\n\n    def save(self, path: str) -&gt; bytes | None:\n        \"\"\"\n        Save the complete knowledge base to disk, including all sub-components\n\n        Args:\n            path (str): Path where the knowledge base will be saved\n        \"\"\"\n        try:\n            data = {\n                # Core components\n                'vdb': self.vdb.save(),\n                'vis_kwargs': self.vis_kwargs,\n                'vis_class': self.vis_class,\n                'existing_hashes': self.existing_hashes,\n\n                # Configuration parameters\n                'embedding_dim': self.embedding_dim,\n                'similarity_threshold': self.similarity_threshold,\n                'batch_size': self.batch_size,\n                'n_clusters': self.n_clusters,\n                'deduplication_threshold': self.deduplication_threshold,\n                'model_name': self.model_name,\n                'embedding_model': self.embedding_model,\n\n                # Cache and graph data\n                'similarity_graph': self.similarity_graph,\n                'sto': self.sto,\n\n                # Text splitter configuration\n                'text_splitter_config': {\n                    'chunk_size': self.text_splitter.chunk_size,\n                    'chunk_overlap': self.text_splitter.chunk_overlap,\n                    'separator': self.text_splitter.separator\n                },\n\n                # Concept extractor data\n                'concept_graph': {\n                    'concepts': {\n                        name: {\n                            'name': concept.name,\n                            'category': concept.category,\n                            'relationships': {k: list(v) for k, v in concept.relationships.items()},\n                            'importance_score': concept.importance_score,\n                            'context_snippets': concept.context_snippets,\n                            'metadata': concept.metadata\n                        }\n                        for name, concept in self.concept_extractor.concept_graph.concepts.items()\n                    }\n                }\n            }\n            b = pickle.dumps(data, protocol=pickle.HIGHEST_PROTOCOL)\n\n            if path is None:\n                return b\n\n            path = Path(path)\n            tmp = path.with_suffix(path.suffix + \".tmp\") if path.suffix else path.with_name(path.name + \".tmp\")\n\n            try:\n                # Schreibe zuerst in eine tempor\u00e4re Datei\n                with open(tmp, \"wb\") as f:\n                    f.write(b)\n                    f.flush()\n                    os.fsync(f.fileno())  # sicherstellen, dass die Daten auf Platte sind\n                # Atomischer Austausch\n                os.replace(tmp, path)\n            finally:\n                # Aufr\u00e4umen falls tmp noch existiert (bei Fehlern)\n                if tmp.exists():\n                    with contextlib.suppress(Exception):\n                        tmp.unlink()\n            return None\n            # print(f\"Knowledge base successfully saved to {path} with {len(self.concept_extractor.concept_graph.concepts.items())} concepts\")\n\n        except Exception as e:\n            print(f\"Error saving knowledge base: {str(e)}\")\n            raise\n    def init_vdb(self, db:AbstractVectorStore=AbstractVectorStore):\n        pass\n    @classmethod\n    def load(cls, path: str | bytes) -&gt; 'KnowledgeBase':\n        \"\"\"\n        Load a complete knowledge base from disk, including all sub-components\n\n        Args:\n            path (str): Path from where to load the knowledge base\n\n        Returns:\n            KnowledgeBase: A fully restored knowledge base instance\n        \"\"\"\n        try:\n            if isinstance(path, bytes | bytearray | memoryview):\n                data_bytes = bytes(path)\n                try:\n                    data = pickle.loads(data_bytes)\n                except Exception as e:\n                    raise EOFError(f\"Fehler beim pickle.loads von bytes: {e}\") from e\n            else:\n                p = Path(path)\n                if not p.exists():\n                    raise FileNotFoundError(f\"{p} existiert nicht\")\n                size = p.stat().st_size\n                if size == 0:\n                    raise EOFError(f\"{p} ist leer (0 bytes)\")\n                try:\n                    with open(p, \"rb\") as f:\n                        try:\n                            data = pickle.load(f)\n                        except EOFError as e:\n                            # Debug info: erste bytes ausgeben\n                            f.seek(0)\n                            snippet = f.read(128)\n                            raise EOFError(\n                                f\"EOFError beim Laden {p} (Gr\u00f6\u00dfe {size} bytes). Erste 128 bytes: {snippet!r}\") from e\n\n                except Exception as e:\n                    raise ValueError(f\"Invalid path type {e}\") from e\n\n            # Create new knowledge base instance with saved configuration\n            kb = cls(\n                embedding_dim=data['embedding_dim'],\n                similarity_threshold=data['similarity_threshold'],\n                batch_size=data['batch_size'],\n                n_clusters=data['n_clusters'],\n                deduplication_threshold=data['deduplication_threshold'],\n                model_name=data['model_name'],\n                embedding_model=data['embedding_model']\n            )\n\n            # Restore core components\n            kb.init_vis(data.get('vis_class'), data.get('vis_kwargs'))\n            kb.existing_hashes = data['existing_hashes']\n\n            # Restore cache and graph data\n            kb.similarity_graph = data.get('similarity_graph', {})\n            kb.sto = data.get('sto', [])\n\n            # Restore text splitter configuration\n            splitter_config = data.get('text_splitter_config', {})\n            kb.text_splitter = TextSplitter(\n                chunk_size=splitter_config.get('chunk_size', 12_000),\n                chunk_overlap=splitter_config.get('chunk_overlap', 200),\n                separator=splitter_config.get('separator', '\\n')\n            )\n\n            # Restore concept graph\n            concept_data = data.get('concept_graph', {}).get('concepts', {})\n            for concept_info in concept_data.values():\n                concept = Concept(\n                    name=concept_info['name'],\n                    category=concept_info['category'],\n                    relationships={k: set(v) for k, v in concept_info['relationships'].items()},\n                    importance_score=concept_info['importance_score'],\n                    context_snippets=concept_info['context_snippets'],\n                    metadata=concept_info['metadata']\n                )\n                kb.concept_extractor.concept_graph.add_concept(concept)\n\n            # print(f\"Knowledge base successfully loaded from {path} with {len(concept_data)} concepts\")\n            return kb\n\n        except Exception:\n            #print(f\"Error loading knowledge base: {str(e)}\")\n            #import traceback\n            #traceback.print_exception(e)\n            raise\n\n    def vis(self,output_file: str = \"concept_graph.html\", get_output_html=False, get_output_net=False):\n        if not self.concept_extractor.concept_graph.concepts:\n            print(\"NO Concepts defined\")\n            return None\n        net = self.concept_extractor.concept_graph.convert_to_networkx()\n        if get_output_net:\n            return net\n        return GraphVisualizer.visualize(net, output_file=output_file, get_output=get_output_html)\n</code></pre> <code>__init__(embedding_dim=256, similarity_threshold=0.61, batch_size=64, n_clusters=4, deduplication_threshold=0.85, model_name=os.getenv('SUMMARYMODEL'), embedding_model=os.getenv('DEFAULTMODELEMBEDDING'), vis_class='FaissVectorStore', vis_kwargs=None, requests_per_second=85.0, chunk_size=3600, chunk_overlap=130, separator='\\n')</code> \u00b6 <p>Initialize the knowledge base with given parameters</p> Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>def __init__(self, embedding_dim: int = 256, similarity_threshold: float = 0.61, batch_size: int = 64,\n             n_clusters: int = 4, deduplication_threshold: float = 0.85, model_name=os.getenv(\"SUMMARYMODEL\"),\n             embedding_model=os.getenv(\"DEFAULTMODELEMBEDDING\"),\n             vis_class:str | None = \"FaissVectorStore\",\n             vis_kwargs:dict[str, Any] | None=None,\n             requests_per_second=85.,\n             chunk_size: int = 3600,\n             chunk_overlap: int = 130,\n             separator: str = \"\\n\"\n             ):\n    \"\"\"Initialize the knowledge base with given parameters\"\"\"\n\n    self.existing_hashes: set[str] = set()\n    self.embedding_model = embedding_model\n    self.embedding_dim = embedding_dim\n    self.similarity_threshold = similarity_threshold\n    self.deduplication_threshold = deduplication_threshold\n    if model_name == \"openrouter/mistralai/mistral-nemo\":\n        batch_size = 9\n        requests_per_second = 1.5\n    self.batch_size = batch_size\n    self.n_clusters = n_clusters\n    self.model_name = model_name\n    self.sto: list = []\n\n    self.text_splitter = TextSplitter(chunk_size=chunk_size,chunk_overlap=chunk_overlap, separator=separator)\n    self.similarity_graph = {}\n    self.concept_extractor = ConceptExtractor(self, requests_per_second)\n\n    self.vis_class = None\n    self.vis_kwargs = None\n    self.vdb = None\n    self.init_vis(vis_class, vis_kwargs)\n</code></pre> <code>add_data(texts, metadata=None, direct=False)</code> <code>async</code> \u00b6 <p>Enhanced version with smart splitting and clustering</p> Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>async def add_data(\n    self,\n    texts: list[str],\n    metadata: list[dict[str, Any]] | None = None, direct:bool = False\n) -&gt; tuple[int, int]:\n    \"\"\"Enhanced version with smart splitting and clustering\"\"\"\n    if isinstance(texts, str):\n        texts = [texts]\n    if metadata is None:\n        metadata = [{}] * len(texts)\n    if isinstance(metadata, dict):\n        metadata = [metadata]\n    if len(texts) != len(metadata):\n        raise ValueError(\"Length of texts and metadata must match\")\n\n    if not direct and len(texts) == 1 and len(texts[0]) &lt; 10_000:\n        if len(self.sto) &lt; self.batch_size and len(texts) == 1:\n            self.sto.append((texts[0], metadata[0]))\n            return -1, -1\n        if len(self.sto) &gt;= self.batch_size:\n            _ = [texts.append(t) or metadata.append([m]) for (t, m) in self.sto]\n            self.sto = []\n\n    # Split large texts\n    split_texts = []\n    split_metadata = []\n\n    while Spinner(\"Saving Data to Memory\", symbols='t'):\n\n        for idx, text in enumerate(texts):\n            chunks = self.text_splitter.split_text(text)\n            split_texts.extend(chunks)\n\n            # Adjust metadata for splits\n            meta = metadata[idx] if metadata else {}\n            if isinstance(meta, list):\n                meta = meta[0]\n            for i, _chunk in enumerate(chunks):\n                chunk_meta = meta.copy()\n                chunk_meta.update({\n                    'chunk_index': i,\n                    'total_chunks': len(chunks),\n                    'original_text_id': idx\n                })\n                split_metadata.append(chunk_meta)\n\n        return await self._add_data(split_texts, split_metadata)\n</code></pre> <code>compute_hash(text)</code> <code>staticmethod</code> \u00b6 <p>Compute SHA-256 hash of text</p> Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>@staticmethod\ndef compute_hash(text: str) -&gt; str:\n    \"\"\"Compute SHA-256 hash of text\"\"\"\n    return hashlib.sha256(text.encode('utf-8', errors='ignore')).hexdigest()\n</code></pre> <code>forget_irrelevant(irrelevant_concepts, similarity_threshold=None)</code> <code>async</code> \u00b6 <p>Remove chunks similar to irrelevant concepts Returns: Number of chunks removed</p> Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>async def forget_irrelevant(self, irrelevant_concepts: list[str], similarity_threshold: float | None=None) -&gt; int:\n    \"\"\"\n    Remove chunks similar to irrelevant concepts\n    Returns: Number of chunks removed\n    \"\"\"\n    if not irrelevant_concepts:\n        return 0\n\n    if similarity_threshold is None:\n        similarity_threshold = self.similarity_threshold\n\n    try:\n        irrelevant_embeddings = await self._get_embeddings(irrelevant_concepts)\n        initial_count = len(self.vdb.chunks)\n\n        def is_relevant(chunk: Chunk) -&gt; bool:\n            similarities = np.dot(chunk.embedding, irrelevant_embeddings.T)\n            do_keep = np.max(similarities) &lt; similarity_threshold\n            if do_keep:\n                return True\n            for c in chunk.metadata.get(\"concepts\", []):\n                if c in self.concept_extractor.concept_graph.concepts:\n                    del self.concept_extractor.concept_graph.concepts[c]\n            return False\n\n        relevant_chunks = [chunk for chunk in self.vdb.chunks if is_relevant(chunk)]\n        self.vdb.chunks = relevant_chunks\n        self.existing_hashes = {chunk.content_hash for chunk in self.vdb.chunks}\n        self.vdb.rebuild_index()\n\n        return initial_count - len(self.vdb.chunks)\n\n    except Exception as e:\n        get_logger().error(f\"Error forgetting irrelevant concepts: {str(e)}\")\n        raise\n</code></pre> <code>load(path)</code> <code>classmethod</code> \u00b6 <p>Load a complete knowledge base from disk, including all sub-components</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path from where to load the knowledge base</p> required <p>Returns:</p> Name Type Description <code>KnowledgeBase</code> <code>KnowledgeBase</code> <p>A fully restored knowledge base instance</p> Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>@classmethod\ndef load(cls, path: str | bytes) -&gt; 'KnowledgeBase':\n    \"\"\"\n    Load a complete knowledge base from disk, including all sub-components\n\n    Args:\n        path (str): Path from where to load the knowledge base\n\n    Returns:\n        KnowledgeBase: A fully restored knowledge base instance\n    \"\"\"\n    try:\n        if isinstance(path, bytes | bytearray | memoryview):\n            data_bytes = bytes(path)\n            try:\n                data = pickle.loads(data_bytes)\n            except Exception as e:\n                raise EOFError(f\"Fehler beim pickle.loads von bytes: {e}\") from e\n        else:\n            p = Path(path)\n            if not p.exists():\n                raise FileNotFoundError(f\"{p} existiert nicht\")\n            size = p.stat().st_size\n            if size == 0:\n                raise EOFError(f\"{p} ist leer (0 bytes)\")\n            try:\n                with open(p, \"rb\") as f:\n                    try:\n                        data = pickle.load(f)\n                    except EOFError as e:\n                        # Debug info: erste bytes ausgeben\n                        f.seek(0)\n                        snippet = f.read(128)\n                        raise EOFError(\n                            f\"EOFError beim Laden {p} (Gr\u00f6\u00dfe {size} bytes). Erste 128 bytes: {snippet!r}\") from e\n\n            except Exception as e:\n                raise ValueError(f\"Invalid path type {e}\") from e\n\n        # Create new knowledge base instance with saved configuration\n        kb = cls(\n            embedding_dim=data['embedding_dim'],\n            similarity_threshold=data['similarity_threshold'],\n            batch_size=data['batch_size'],\n            n_clusters=data['n_clusters'],\n            deduplication_threshold=data['deduplication_threshold'],\n            model_name=data['model_name'],\n            embedding_model=data['embedding_model']\n        )\n\n        # Restore core components\n        kb.init_vis(data.get('vis_class'), data.get('vis_kwargs'))\n        kb.existing_hashes = data['existing_hashes']\n\n        # Restore cache and graph data\n        kb.similarity_graph = data.get('similarity_graph', {})\n        kb.sto = data.get('sto', [])\n\n        # Restore text splitter configuration\n        splitter_config = data.get('text_splitter_config', {})\n        kb.text_splitter = TextSplitter(\n            chunk_size=splitter_config.get('chunk_size', 12_000),\n            chunk_overlap=splitter_config.get('chunk_overlap', 200),\n            separator=splitter_config.get('separator', '\\n')\n        )\n\n        # Restore concept graph\n        concept_data = data.get('concept_graph', {}).get('concepts', {})\n        for concept_info in concept_data.values():\n            concept = Concept(\n                name=concept_info['name'],\n                category=concept_info['category'],\n                relationships={k: set(v) for k, v in concept_info['relationships'].items()},\n                importance_score=concept_info['importance_score'],\n                context_snippets=concept_info['context_snippets'],\n                metadata=concept_info['metadata']\n            )\n            kb.concept_extractor.concept_graph.add_concept(concept)\n\n        # print(f\"Knowledge base successfully loaded from {path} with {len(concept_data)} concepts\")\n        return kb\n\n    except Exception:\n        #print(f\"Error loading knowledge base: {str(e)}\")\n        #import traceback\n        #traceback.print_exception(e)\n        raise\n</code></pre> <code>query_concepts(query)</code> <code>async</code> \u00b6 <p>Query concepts extracted from the knowledge base</p> Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>async def query_concepts(self, query: str) -&gt; dict[str, any]:\n    \"\"\"Query concepts extracted from the knowledge base\"\"\"\n    return await self.concept_extractor.query_concepts(query)\n</code></pre> <code>retrieve(query='', query_embedding=None, k=5, min_similarity=0.2, include_connected=True)</code> <code>async</code> \u00b6 <p>Enhanced retrieval with connected information</p> Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>async def retrieve(\n    self,\n    query: str=\"\",\n    query_embedding: np.ndarray | None = None,\n    k: int = 5,\n    min_similarity: float = 0.2,\n    include_connected: bool = True\n) -&gt; list[Chunk]:\n    \"\"\"Enhanced retrieval with connected information\"\"\"\n    if query_embedding is None:\n        query_embedding = (await self._get_embeddings([query]))[0]\n    k = min(k, len(self.vdb.chunks))\n    if k &lt;= 0:\n        return []\n    initial_results = self.vdb.search(query_embedding, k, min_similarity)\n\n    if not include_connected or not initial_results:\n        return initial_results\n\n    # Find connected chunks\n    connected_chunks = set()\n    for chunk in initial_results:\n        chunk_id = self.vdb.chunks.index(chunk)\n        if chunk_id in self.similarity_graph:\n            connected_chunks.update(self.similarity_graph[chunk_id])\n\n    # Add connected chunks to results\n    all_chunks = self.vdb.chunks\n    additional_results = [all_chunks[i] for i in connected_chunks\n                          if all_chunks[i] not in initial_results]\n\n    # Sort by similarity to query\n    all_results = initial_results + additional_results\n\n    return sorted(\n        all_results,\n        key=lambda x: np.dot(x.embedding, query_embedding),\n        reverse=True\n    )[:k * 2]  # Return more results when including connected information\n</code></pre> <code>retrieve_with_overview(query, query_embedding=None, k=5, min_similarity=0.2, max_sentences=5, cross_ref_depth=2, max_cross_refs=10)</code> <code>async</code> \u00b6 <p>Enhanced retrieval with better cross-reference handling</p> Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>async def retrieve_with_overview(\n    self,\n    query: str,\n    query_embedding=None,\n    k: int = 5,\n    min_similarity: float = 0.2,\n    max_sentences: int = 5,\n    cross_ref_depth: int = 2,\n    max_cross_refs: int = 10  # New parameter to control cross-reference count\n) -&gt; RetrievalResult:\n    \"\"\"Enhanced retrieval with better cross-reference handling\"\"\"\n    # Get initial results with query embedding\n    if query_embedding is None:\n        query_embedding = (await self._get_embeddings([query]))[0]\n    initial_results = await self.retrieve(query_embedding=query_embedding, k=k, min_similarity=min_similarity)\n\n    if not initial_results:\n        return RetrievalResult([], [], {})\n\n    # Find cross-references with similarity scoring\n    initial_ids = {self.vdb.chunks.index(chunk) for chunk in initial_results}\n    related_ids = self._find_cross_references(\n        initial_ids,\n        depth=cross_ref_depth,\n        query_embedding=query_embedding  # Pass query embedding for relevance scoring\n    )\n\n    # Get all relevant chunks with smarter filtering\n    all_chunks = self.vdb.chunks\n    all_relevant_chunks = initial_results + [\n        chunk for i, chunk in enumerate(all_chunks)\n        if i in related_ids and self._is_relevant_cross_ref(\n            chunk,\n            query_embedding,\n            initial_results\n        )\n    ]\n\n    # Enhanced clustering with dynamic cluster size\n    clusters = self._cluster_chunks(\n        all_relevant_chunks,\n        query_embedding=query_embedding\n    )\n\n    # Fallback: If no clusters are found, treat all relevant chunks as a single cluster.\n    if not clusters:\n        print(\"No clusters found. Falling back to using all relevant chunks as a single cluster.\")\n        clusters = {0: all_relevant_chunks}\n\n    # Generate summaries and organize results\n    overview = []\n    cross_references = {}\n\n    for cluster_id, cluster_chunks in clusters.items():\n        summary = self._generate_topic_summary(\n            cluster_chunks,\n            query_embedding,\n            max_sentences=max_sentences  # Increased for more context\n        )\n\n        # Enhanced chunk sorting with combined scoring\n        sorted_chunks = self._sort_chunks_by_relevance(\n            cluster_chunks,\n            query_embedding,\n            initial_results\n        )\n\n        # Separate direct matches and cross-references\n        direct_matches_ = [{'text':c.text, 'metadata':c.metadata} for c in sorted_chunks if c in initial_results]\n        direct_matches = []\n        for match in direct_matches_:\n            if match in direct_matches:\n                continue\n            direct_matches.append(match)\n        cross_refs_ = [c for c in sorted_chunks if c not in initial_results]\n        cross_refs = []\n        for match in cross_refs_:\n            if match in cross_refs:\n                continue\n            cross_refs.append(match)\n        # Limit cross-references while maintaining diversity\n        selected_cross_refs = self._select_diverse_cross_refs(\n            cross_refs,\n            max_cross_refs,\n            query_embedding\n        )\n\n        topic_info = {\n            'topic_id': cluster_id,\n            'summary': summary,\n            'main_chunks': [x for x in direct_matches[:3]],\n            'chunk_count': len(cluster_chunks),\n            'relevance_score': self._calculate_topic_relevance(\n                cluster_chunks,\n                query_embedding\n            )\n        }\n        overview.append(topic_info)\n\n        if selected_cross_refs:\n            cross_references[f\"topic_{cluster_id}\"] = selected_cross_refs\n\n    # Sort overview by relevance score\n    overview.sort(key=lambda x: x['relevance_score'], reverse=True)\n\n    return RetrievalResult(\n        overview=overview,\n        details=initial_results,\n        cross_references=cross_references\n    )\n</code></pre> <code>save(path)</code> \u00b6 <p>Save the complete knowledge base to disk, including all sub-components</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path where the knowledge base will be saved</p> required Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>def save(self, path: str) -&gt; bytes | None:\n    \"\"\"\n    Save the complete knowledge base to disk, including all sub-components\n\n    Args:\n        path (str): Path where the knowledge base will be saved\n    \"\"\"\n    try:\n        data = {\n            # Core components\n            'vdb': self.vdb.save(),\n            'vis_kwargs': self.vis_kwargs,\n            'vis_class': self.vis_class,\n            'existing_hashes': self.existing_hashes,\n\n            # Configuration parameters\n            'embedding_dim': self.embedding_dim,\n            'similarity_threshold': self.similarity_threshold,\n            'batch_size': self.batch_size,\n            'n_clusters': self.n_clusters,\n            'deduplication_threshold': self.deduplication_threshold,\n            'model_name': self.model_name,\n            'embedding_model': self.embedding_model,\n\n            # Cache and graph data\n            'similarity_graph': self.similarity_graph,\n            'sto': self.sto,\n\n            # Text splitter configuration\n            'text_splitter_config': {\n                'chunk_size': self.text_splitter.chunk_size,\n                'chunk_overlap': self.text_splitter.chunk_overlap,\n                'separator': self.text_splitter.separator\n            },\n\n            # Concept extractor data\n            'concept_graph': {\n                'concepts': {\n                    name: {\n                        'name': concept.name,\n                        'category': concept.category,\n                        'relationships': {k: list(v) for k, v in concept.relationships.items()},\n                        'importance_score': concept.importance_score,\n                        'context_snippets': concept.context_snippets,\n                        'metadata': concept.metadata\n                    }\n                    for name, concept in self.concept_extractor.concept_graph.concepts.items()\n                }\n            }\n        }\n        b = pickle.dumps(data, protocol=pickle.HIGHEST_PROTOCOL)\n\n        if path is None:\n            return b\n\n        path = Path(path)\n        tmp = path.with_suffix(path.suffix + \".tmp\") if path.suffix else path.with_name(path.name + \".tmp\")\n\n        try:\n            # Schreibe zuerst in eine tempor\u00e4re Datei\n            with open(tmp, \"wb\") as f:\n                f.write(b)\n                f.flush()\n                os.fsync(f.fileno())  # sicherstellen, dass die Daten auf Platte sind\n            # Atomischer Austausch\n            os.replace(tmp, path)\n        finally:\n            # Aufr\u00e4umen falls tmp noch existiert (bei Fehlern)\n            if tmp.exists():\n                with contextlib.suppress(Exception):\n                    tmp.unlink()\n        return None\n        # print(f\"Knowledge base successfully saved to {path} with {len(self.concept_extractor.concept_graph.concepts.items())} concepts\")\n\n    except Exception as e:\n        print(f\"Error saving knowledge base: {str(e)}\")\n        raise\n</code></pre> <code>unified_retrieve(query, k=5, min_similarity=0.2, cross_ref_depth=2, max_cross_refs=10, max_sentences=10)</code> <code>async</code> \u00b6 <p>Unified retrieval function that combines concept querying, retrieval with overview, and basic retrieval, then generates a comprehensive summary using LLM.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Search query string</p> required <code>k</code> <code>int</code> <p>Number of primary results to retrieve</p> <code>5</code> <code>min_similarity</code> <code>float</code> <p>Minimum similarity threshold for retrieval</p> <code>0.2</code> <code>cross_ref_depth</code> <code>int</code> <p>Depth for cross-reference search</p> <code>2</code> <code>max_cross_refs</code> <code>int</code> <p>Maximum number of cross-references per topic</p> <code>10</code> <code>max_sentences</code> <code>int</code> <p>Maximum number Sentences in the main summary text</p> <code>10</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary containing comprehensive results including summary and details</p> Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>async def unified_retrieve(\n    self,\n    query: str,\n    k: int = 5,\n    min_similarity: float = 0.2,\n    cross_ref_depth: int = 2,\n    max_cross_refs: int = 10,\n    max_sentences: int = 10\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Unified retrieval function that combines concept querying, retrieval with overview,\n    and basic retrieval, then generates a comprehensive summary using LLM.\n\n    Args:\n        query: Search query string\n        k: Number of primary results to retrieve\n        min_similarity: Minimum similarity threshold for retrieval\n        cross_ref_depth: Depth for cross-reference search\n        max_cross_refs: Maximum number of cross-references per topic\n        max_sentences: Maximum number Sentences in the main summary text\n\n    Returns:\n        Dictionary containing comprehensive results including summary and details\n    \"\"\"\n    # Get concept information\n    concept_results = await self.concept_extractor.query_concepts(query)\n\n    # Get retrieval overview\n\n    query_embedding = (await self._get_embeddings([query]))[0]\n    overview_results = await self.retrieve_with_overview(\n        query=query,\n        query_embedding=query_embedding,\n        k=k,\n        min_similarity=min_similarity,\n        cross_ref_depth=cross_ref_depth,\n        max_cross_refs=max_cross_refs,\n        max_sentences=max_sentences\n    )\n\n    # Get basic retrieval results\n    basic_results = await self.retrieve(\n        query_embedding=query_embedding,\n        k=k,\n        min_similarity=min_similarity\n    )\n    if len(basic_results) == 0:\n        return {}\n    if len(basic_results) == 1 and isinstance(basic_results[0], str) and basic_results[0].endswith('[]\\n - []\\n - []'):\n        return {}\n\n    # Prepare context for LLM summary\n    context = {\n        \"concepts\": {\n            \"main_concepts\": concept_results.get(\"concepts\", {}),\n            \"relationships\": concept_results.get(\"relationships\", []),\n            \"concept_groups\": concept_results.get(\"groups\", [])\n        },\n        \"topics\": [\n            {\n                \"id\": topic[\"topic_id\"],\n                \"summary\": topic[\"summary\"],\n                \"relevance\": topic[\"relevance_score\"],\n                \"chunk_count\": topic[\"chunk_count\"]\n            }\n            for topic in overview_results.overview\n        ],\n        \"key_chunks\": [\n            {\n                \"text\": chunk.text,\n                \"metadata\": chunk.metadata\n            }\n            for chunk in basic_results\n        ]\n    }\n\n    # Generate comprehensive summary using LLM\n    system_prompt = \"\"\"\n    Analyze the provided search results and generate a comprehensive summary\n    that includes:\n    1. Main concepts and their relationships\n    2. Key topics and their relevance\n    3. Most important findings and insights\n    4. Cross-references and connections between topics\n    5. Potential gaps or areas for further investigation\n\n    Format the response as a JSON object with these sections.\n    \"\"\"\n\n    prompt = f\"\"\"\n    Query: {query}\n\n    Context:\n    {json.dumps(context, indent=2)}\n\n    Generate a comprehensive analysis and summary following the structure:\n    \"\"\"\n\n    try:\n        await asyncio.sleep(0.25)\n        llm_response = await litellm_complete(\n            model_name=self.model_name,\n            prompt=prompt,\n            system_prompt=system_prompt,\n            response_format=DataModel,\n        )\n        summary_analysis = json.loads(llm_response)\n    except Exception as e:\n        get_logger().error(f\"Error generating summary: {str(e)}\")\n        summary_analysis = {\n            \"main_summary\": \"Error generating summary\",\n            \"error\": str(e)\n        }\n\n    # Compile final results\n    return {\n        \"summary\": summary_analysis,\n        \"raw_results\": {\n            \"concepts\": concept_results,\n            \"overview\": {\n                \"topics\": overview_results.overview,\n                \"cross_references\": overview_results.cross_references\n            },\n            \"relevant_chunks\": [\n                {\n                    \"text\": chunk.text,\n                    \"metadata\": chunk.metadata,\n                    \"cluster_id\": chunk.cluster_id\n                }\n                for chunk in basic_results\n            ]\n        },\n        \"metadata\": {\n            \"query\": query,\n            \"timestamp\": time.time(),\n            \"retrieval_params\": {\n                \"k\": k,\n                \"min_similarity\": min_similarity,\n                \"cross_ref_depth\": cross_ref_depth,\n                \"max_cross_refs\": max_cross_refs\n            }\n        }\n    }\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.KnowledgeBase.RelevanceAssessment","title":"<code>RelevanceAssessment</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents an assessment of the relevance of the data in relation to a specific query.</p> <p>Attributes:</p> Name Type Description <code>query_alignment</code> <code>float</code> <p>A float representing the alignment between the query and the data.</p> <code>confidence_score</code> <code>float</code> <p>A float indicating the confidence level in the alignment.</p> <code>coverage_analysis</code> <code>str</code> <p>A textual description analyzing the data coverage.</p> Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>class RelevanceAssessment(BaseModel):\n    \"\"\"\n    Represents an assessment of the relevance of the data in relation to a specific query.\n\n    Attributes:\n        query_alignment (float): A float representing the alignment between the query and the data.\n        confidence_score (float): A float indicating the confidence level in the alignment.\n        coverage_analysis (str): A textual description analyzing the data coverage.\n    \"\"\"\n    query_alignment: float\n    confidence_score: float\n    coverage_analysis: str\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.KnowledgeBase.RetrievalResult","title":"<code>RetrievalResult</code>  <code>dataclass</code>","text":"<p>Structure for organizing retrieval results</p> Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>@dataclass\nclass RetrievalResult:\n    \"\"\"Structure for organizing retrieval results\"\"\"\n    overview: list[dict[str, any]]  # List of topic summaries\n    details: list[Chunk]  # Detailed chunks\n    cross_references: dict[str, list[Chunk]]  # Related chunks by topic\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.KnowledgeBase.TConcept","title":"<code>TConcept</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents the criteria or target parameters for concept selection and filtering.</p> <p>Attributes:</p> Name Type Description <code>min_importance</code> <code>float</code> <p>The minimum importance score a concept must have to be considered.</p> <code>target_concepts</code> <code>List[str]</code> <p>A list of names of target concepts to focus on.</p> <code>relationship_types</code> <code>List[str]</code> <p>A list of relationship types to be considered in the analysis.</p> <code>categories</code> <code>List[str]</code> <p>A list of concept categories to filter or group the concepts.</p> Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>class TConcept(BaseModel):\n    \"\"\"\n    Represents the criteria or target parameters for concept selection and filtering.\n\n    Attributes:\n        min_importance (float): The minimum importance score a concept must have to be considered.\n        target_concepts (List[str]): A list of names of target concepts to focus on.\n        relationship_types (List[str]): A list of relationship types to be considered in the analysis.\n        categories (List[str]): A list of concept categories to filter or group the concepts.\n    \"\"\"\n    min_importance: float\n    target_concepts: list[str]\n    relationship_types: list[str]\n    categories: list[str]\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.KnowledgeBase.TextSplitter","title":"<code>TextSplitter</code>","text":"Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>class TextSplitter:\n    def __init__(\n        self,\n        chunk_size: int = 3600,\n        chunk_overlap: int = 130,\n        separator: str = \"\\n\"\n    ):\n        self.chunk_size = chunk_size\n        self.chunk_overlap = chunk_overlap\n        self.separator = separator\n\n    def approximate(self, text_len: int) -&gt; float:\n        \"\"\"\n        Approximate the number of chunks and average chunk size for a given text length\n\n        Args:\n            text_len (int): Length of the text to be split\n\n        Returns:\n            Tuple[int, int]: (number_of_chunks, approximate_chunk_size)\n        \"\"\"\n        if text_len &lt;= self.chunk_size:\n            return 1, text_len\n\n        # Handle extreme overlap cases\n        if self.chunk_overlap &gt;= self.chunk_size:\n            estimated_chunks = text_len\n            return estimated_chunks, 1\n\n        # Calculate based on overlap ratio\n        overlap_ratio = self.chunk_overlap / self.chunk_size\n        base_chunks = text_len / self.chunk_size\n        estimated_chunks = base_chunks * 2 / (overlap_ratio if overlap_ratio &gt; 0 else 1)\n\n        # print('#',estimated_chunks, base_chunks, overlap_ratio)\n        # Calculate average chunk size\n        avg_chunk_size = max(1, text_len / estimated_chunks)\n\n        return estimated_chunks * avg_chunk_size\n\n    def split_text(self, text: str) -&gt; list[str]:\n        \"\"\"Split text into chunks with overlap\"\"\"\n        # Clean and normalize text\n        text = re.sub(r'\\s+', ' ', text).strip()\n\n        # If text is shorter than chunk_size, return as is\n        if len(text) &lt;= self.chunk_size:\n            return [text]\n\n        chunks = []\n        start = 0\n\n        while start &lt; len(text):\n            # Find end of chunk\n            end = start + self.chunk_size\n\n            if end &gt;= len(text):\n                chunks.append(text[start:])\n                break\n\n            # Try to find a natural break point\n            last_separator = text.rfind(self.separator, start, end)\n            if last_separator != -1:\n                end = last_separator\n\n            # Add chunk\n            chunks.append(text[start:end])\n\n            # Calculate allowed overlap for this chunk\n            chunk_length = end - start\n            allowed_overlap = min(self.chunk_overlap, chunk_length - 1)\n\n            # Move start position considering adjusted overlap\n            start = end - allowed_overlap\n\n        return chunks\n</code></pre> <code>approximate(text_len)</code> \u00b6 <p>Approximate the number of chunks and average chunk size for a given text length</p> <p>Parameters:</p> Name Type Description Default <code>text_len</code> <code>int</code> <p>Length of the text to be split</p> required <p>Returns:</p> Type Description <code>float</code> <p>Tuple[int, int]: (number_of_chunks, approximate_chunk_size)</p> Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>def approximate(self, text_len: int) -&gt; float:\n    \"\"\"\n    Approximate the number of chunks and average chunk size for a given text length\n\n    Args:\n        text_len (int): Length of the text to be split\n\n    Returns:\n        Tuple[int, int]: (number_of_chunks, approximate_chunk_size)\n    \"\"\"\n    if text_len &lt;= self.chunk_size:\n        return 1, text_len\n\n    # Handle extreme overlap cases\n    if self.chunk_overlap &gt;= self.chunk_size:\n        estimated_chunks = text_len\n        return estimated_chunks, 1\n\n    # Calculate based on overlap ratio\n    overlap_ratio = self.chunk_overlap / self.chunk_size\n    base_chunks = text_len / self.chunk_size\n    estimated_chunks = base_chunks * 2 / (overlap_ratio if overlap_ratio &gt; 0 else 1)\n\n    # print('#',estimated_chunks, base_chunks, overlap_ratio)\n    # Calculate average chunk size\n    avg_chunk_size = max(1, text_len / estimated_chunks)\n\n    return estimated_chunks * avg_chunk_size\n</code></pre> <code>split_text(text)</code> \u00b6 <p>Split text into chunks with overlap</p> Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>def split_text(self, text: str) -&gt; list[str]:\n    \"\"\"Split text into chunks with overlap\"\"\"\n    # Clean and normalize text\n    text = re.sub(r'\\s+', ' ', text).strip()\n\n    # If text is shorter than chunk_size, return as is\n    if len(text) &lt;= self.chunk_size:\n        return [text]\n\n    chunks = []\n    start = 0\n\n    while start &lt; len(text):\n        # Find end of chunk\n        end = start + self.chunk_size\n\n        if end &gt;= len(text):\n            chunks.append(text[start:])\n            break\n\n        # Try to find a natural break point\n        last_separator = text.rfind(self.separator, start, end)\n        if last_separator != -1:\n            end = last_separator\n\n        # Add chunk\n        chunks.append(text[start:end])\n\n        # Calculate allowed overlap for this chunk\n        chunk_length = end - start\n        allowed_overlap = min(self.chunk_overlap, chunk_length - 1)\n\n        # Move start position considering adjusted overlap\n        start = end - allowed_overlap\n\n    return chunks\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.KnowledgeBase.TopicInsights","title":"<code>TopicInsights</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents insights related to various topics.</p> <p>Attributes:</p> Name Type Description <code>primary_topics</code> <code>list[str]</code> <p>A list of main topics addressed.</p> <code>cross_references</code> <code>list[str]</code> <p>A list of cross-references that connect different topics.</p> <code>knowledge_gaps</code> <code>list[str]</code> <p>A list of identified gaps in the current knowledge.</p> Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>class TopicInsights(BaseModel):\n    \"\"\"\n    Represents insights related to various topics.\n\n    Attributes:\n        primary_topics (list[str]): A list of main topics addressed.\n        cross_references (list[str]): A list of cross-references that connect different topics.\n        knowledge_gaps (list[str]): A list of identified gaps in the current knowledge.\n    \"\"\"\n    primary_topics: list[str]\n    cross_references: list[str]\n    knowledge_gaps: list[str]\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.KnowledgeBase.rConcept","title":"<code>rConcept</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a key concept with its relationships and associated metadata.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The name of the concept.</p> <code>category</code> <code>str</code> <p>The category of the concept (e.g., 'technical', 'domain', 'method', etc.).</p> <code>relationships</code> <code>Dict[str, List[str]]</code> <p>A mapping where each key is a type of relationship and the value is a list of related concept names.</p> <code>importance_score</code> <code>float</code> <p>A numerical score representing the importance or relevance of the concept.</p> <code>context_snippets</code> <code>List[str]</code> <p>A list of text snippets providing context where the concept appears.</p> Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>class rConcept(BaseModel):\n    \"\"\"\n    Represents a key concept with its relationships and associated metadata.\n\n    Attributes:\n        name (str): The name of the concept.\n        category (str): The category of the concept (e.g., 'technical', 'domain', 'method', etc.).\n        relationships (Dict[str, List[str]]): A mapping where each key is a type of relationship and the\n            value is a list of related concept names.\n        importance_score (float): A numerical score representing the importance or relevance of the concept.\n        context_snippets (List[str]): A list of text snippets providing context where the concept appears.\n    \"\"\"\n    name: str\n    category: str\n    relationships: dict[str, list[str]]\n    importance_score: float\n    context_snippets: list[str]\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.KnowledgeBase.normalize_vectors","title":"<code>normalize_vectors(vectors)</code>","text":"<p>Normalize vectors to unit length</p> Source code in <code>toolboxv2/mods/isaa/base/KnowledgeBase.py</code> <pre><code>def normalize_vectors(vectors: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Normalize vectors to unit length\"\"\"\n    norms = np.linalg.norm(vectors, axis=1, keepdims=True)\n    return np.divide(vectors, norms, where=norms != 0)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.VectorStores","title":"<code>VectorStores</code>","text":"<p>Vector store implementations for the toolboxv2 system.</p>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.VectorStores.taichiNumpyNumbaVectorStores","title":"<code>taichiNumpyNumbaVectorStores</code>","text":"<code>NumpyVectorStore</code> \u00b6 <p>               Bases: <code>AbstractVectorStore</code></p> Source code in <code>toolboxv2/mods/isaa/base/VectorStores/taichiNumpyNumbaVectorStores.py</code> <pre><code>class NumpyVectorStore(AbstractVectorStore):\n    def __init__(self, use_gpu=False):\n        self.embeddings = np.empty((0, 0))\n        self.chunks = []\n        # Initialize Taich\n\n\n        self.normalized_embeddings = None\n\n    def add_embeddings(self, embeddings: np.ndarray, chunks: list[Chunk]) -&gt; None:\n        if len(embeddings.shape) != 2:\n            raise ValueError(\"Embeddings must be 2D array\")\n        if len(chunks) != embeddings.shape[0]:\n            raise ValueError(\"Mismatch between embeddings and chunks count\")\n\n        if self.embeddings.size == 0:\n            self.embeddings = embeddings\n        else:\n            if embeddings.shape[1] != self.embeddings.shape[1]:\n                raise ValueError(\"Embedding dimensions must match\")\n            self.embeddings = np.vstack([self.embeddings, embeddings])\n        self.chunks.extend(chunks)\n        # Reset normalized embeddings cache\n        self.normalized_embeddings = None\n\n    def search(self, query_embedding: np.ndarray, k: int = 5, min_similarity: float = 0.7) -&gt; list[Chunk]:\n        if self.embeddings.size == 0:\n            return []\n\n        # Pre-compute normalized embeddings if not cached\n        if self.normalized_embeddings is None:\n            self._precompute_normalized_embeddings()\n\n        # Normalize query\n        query_norm = self._normalize_vector(query_embedding)\n\n        # Enhanced Taichi kernel for similarity computation\n        n = len(self.chunks)\n        similarities = np.zeros(n, dtype=np.float32)\n\n        @ti.kernel\n        def compute_similarities_optimized(\n            query: ti.types.ndarray(dtype=ti.f32),\n            embeddings: ti.types.ndarray(dtype=ti.f32),\n            similarities: ti.types.ndarray(dtype=ti.f32),\n            n: ti.i32,\n            dim: ti.i32\n        ):\n            ti.loop_config(block_dim=256)\n            for i in range(n):\n                dot_product = 0.0\n                # Vectorized dot product computation\n                for j in range(dim):\n                    dot_product += embeddings[i, j] * query[j]\n                similarities[i] = dot_product\n\n        # Alternative optimized kernel using tile-based computation\n        @ti.kernel\n        def compute_similarities_tiled(\n            query: ti.types.ndarray(dtype=ti.f32),\n            embeddings: ti.types.ndarray(dtype=ti.f32),\n            similarities: ti.types.ndarray(dtype=ti.f32),\n            n: ti.i32,\n            dim: ti.i32\n        ):\n            tile_size = 16  # Adjust based on hardware\n            for i in range(n):\n                dot_product = 0.0\n                # Process in tiles for better cache utilization\n                for jt in range(0, dim):\n                    if jt % tile_size != 0:\n                        continue\n                    tile_sum = 0.0\n                    for j in range(jt, ti.min(jt + tile_size, dim)):\n                        tile_sum += embeddings[i, j] * query[j]\n                    dot_product += tile_sum\n                similarities[i] = dot_product\n\n        # Choose the appropriate kernel based on dimension size\n        if query_embedding.shape[0] &gt;= 256:\n            compute_similarities_tiled(\n                query_norm.astype(np.float32),\n                self.normalized_embeddings,\n                similarities,\n                n,\n                query_embedding.shape[0]\n            )\n        else:\n            compute_similarities_optimized(\n                query_norm.astype(np.float32),\n                self.normalized_embeddings,\n                similarities,\n                n,\n                query_embedding.shape[0]\n            )\n\n        # Optimize top-k selection\n        if k &gt;= n:\n            indices = np.argsort(-similarities)\n        else:\n            # Use partial sort for better performance when k &lt; n\n            indices = np.argpartition(-similarities, k)[:k]\n            indices = indices[np.argsort(-similarities[indices])]\n\n        # Filter results efficiently using vectorized operations\n        mask = similarities[indices] &gt;= min_similarity\n        filtered_indices = indices[mask]\n        return [self.chunks[idx] for idx in filtered_indices[:k]]\n\n    def save(self) -&gt; bytes:\n        return pickle.dumps({\n            'embeddings': self.embeddings,\n            'chunks': self.chunks\n        })\n\n    def load(self, data: bytes) -&gt; 'NumpyVectorStore':\n        loaded = pickle.loads(data)\n        self.embeddings = loaded['embeddings']\n        self.chunks = loaded['chunks']\n        return self\n\n    def clear(self) -&gt; None:\n        self.embeddings = np.empty((0, 0))\n        self.chunks = []\n        self.normalized_embeddings = None\n\n    def rebuild_index(self) -&gt; None:\n        pass  # No index to rebuild for numpy implementation\n\n    def _normalize_vector(self, vector: np.ndarray) -&gt; np.ndarray:\n        \"\"\"Normalize a single vector efficiently.\"\"\"\n        return vector / (np.linalg.norm(vector) + 1e-8)\n\n    def _precompute_normalized_embeddings(self) -&gt; None:\n        \"\"\"Pre-compute and cache normalized embeddings.\"\"\"\n        # Allocate output array\n        self.normalized_embeddings = np.empty_like(self.embeddings, dtype=np.float32)\n\n        # Normalize embeddings using Taichi\n        batch_normalize(\n            self.embeddings.astype(np.float32),\n            self.normalized_embeddings,\n            self.embeddings.shape[0],\n            self.embeddings.shape[1]\n        )\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.base.VectorStores.types","title":"<code>types</code>","text":"<code>AbstractVectorStore</code> \u00b6 <p>               Bases: <code>ABC</code></p> <p>Abstract base class for vector stores</p> Source code in <code>toolboxv2/mods/isaa/base/VectorStores/types.py</code> <pre><code>class AbstractVectorStore(ABC):\n    \"\"\"Abstract base class for vector stores\"\"\"\n\n    @abstractmethod\n    def add_embeddings(self, embeddings: np.ndarray, chunks: list[Chunk]) -&gt; None:\n        \"\"\"Add embeddings and their corresponding chunks to the store\"\"\"\n        pass\n\n    @abstractmethod\n    def search(self, query_embedding: np.ndarray, k: int = 5, min_similarity: float = 0.7) -&gt; list[Chunk]:\n        \"\"\"Search for similar vectors\"\"\"\n        pass\n\n    @abstractmethod\n    def save(self) -&gt; bytes:\n        \"\"\"Save the vector store to disk\"\"\"\n        pass\n\n    @abstractmethod\n    def load(self, data: bytes) -&gt; 'AbstractVectorStore':\n        \"\"\"Load the vector store from disk\"\"\"\n        pass\n\n    @abstractmethod\n    def clear(self) -&gt; None:\n        \"\"\"Clear all data from the store\"\"\"\n        pass\n\n    @abstractmethod\n    def rebuild_index(self) -&gt; None:\n        \"\"\"Optional for faster searches\"\"\"\n        pass\n</code></pre> <code>add_embeddings(embeddings, chunks)</code> <code>abstractmethod</code> \u00b6 <p>Add embeddings and their corresponding chunks to the store</p> Source code in <code>toolboxv2/mods/isaa/base/VectorStores/types.py</code> <pre><code>@abstractmethod\ndef add_embeddings(self, embeddings: np.ndarray, chunks: list[Chunk]) -&gt; None:\n    \"\"\"Add embeddings and their corresponding chunks to the store\"\"\"\n    pass\n</code></pre> <code>clear()</code> <code>abstractmethod</code> \u00b6 <p>Clear all data from the store</p> Source code in <code>toolboxv2/mods/isaa/base/VectorStores/types.py</code> <pre><code>@abstractmethod\ndef clear(self) -&gt; None:\n    \"\"\"Clear all data from the store\"\"\"\n    pass\n</code></pre> <code>load(data)</code> <code>abstractmethod</code> \u00b6 <p>Load the vector store from disk</p> Source code in <code>toolboxv2/mods/isaa/base/VectorStores/types.py</code> <pre><code>@abstractmethod\ndef load(self, data: bytes) -&gt; 'AbstractVectorStore':\n    \"\"\"Load the vector store from disk\"\"\"\n    pass\n</code></pre> <code>rebuild_index()</code> <code>abstractmethod</code> \u00b6 <p>Optional for faster searches</p> Source code in <code>toolboxv2/mods/isaa/base/VectorStores/types.py</code> <pre><code>@abstractmethod\ndef rebuild_index(self) -&gt; None:\n    \"\"\"Optional for faster searches\"\"\"\n    pass\n</code></pre> <code>save()</code> <code>abstractmethod</code> \u00b6 <p>Save the vector store to disk</p> Source code in <code>toolboxv2/mods/isaa/base/VectorStores/types.py</code> <pre><code>@abstractmethod\ndef save(self) -&gt; bytes:\n    \"\"\"Save the vector store to disk\"\"\"\n    pass\n</code></pre> <code>search(query_embedding, k=5, min_similarity=0.7)</code> <code>abstractmethod</code> \u00b6 <p>Search for similar vectors</p> Source code in <code>toolboxv2/mods/isaa/base/VectorStores/types.py</code> <pre><code>@abstractmethod\ndef search(self, query_embedding: np.ndarray, k: int = 5, min_similarity: float = 0.7) -&gt; list[Chunk]:\n    \"\"\"Search for similar vectors\"\"\"\n    pass\n</code></pre> <code>Chunk</code> <code>dataclass</code> \u00b6 <p>Represents a chunk of text with its embedding and metadata</p> Source code in <code>toolboxv2/mods/isaa/base/VectorStores/types.py</code> <pre><code>@dataclass(slots=True)\nclass Chunk:\n    \"\"\"Represents a chunk of text with its embedding and metadata\"\"\"\n    text: str\n    embedding: np.ndarray\n    metadata: dict[str, Any]\n    content_hash: str\n    cluster_id: int | None = None\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras","title":"<code>extras</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.adapter","title":"<code>adapter</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.adapter--litellm-llm-interface-module","title":"LiteLLM LLM Interface Module","text":"<p>This module provides interfaces for interacting with LiteLLM's language models, including text generation and embedding capabilities.</p> <p>Author: Lightrag Team Created: 2025-02-04 License: MIT License Version: 1.0.0</p> <p>Change Log: - 1.0.0 (2025-02-04): Initial LiteLLM release     * Ported OpenAI logic to use litellm async client     * Updated error types and environment variable names     * Preserved streaming and embedding support</p> Dependencies <ul> <li>litellm</li> <li>numpy</li> <li>pipmaster</li> <li>Python &gt;= 3.10</li> </ul> Usage <p>from llm_interfaces.litellm import logging</p> <p>if not hasattr(logging, 'NONE'):     logging.NONE = 100</p> <p>import litellm_complete, litellm_embed</p>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.adapter.litellm_complete","title":"<code>litellm_complete(prompt, system_prompt=None, history_messages=None, keyword_extraction=False, model_name='groq/gemma2-9b-it', **kwargs)</code>  <code>async</code>","text":"<p>Public completion interface using the model name specified in the global configuration. Optionally extracts keywords if requested.</p> Source code in <code>toolboxv2/mods/isaa/extras/adapter.py</code> <pre><code>async def litellm_complete(\n    prompt, system_prompt=None, history_messages=None, keyword_extraction=False, model_name = \"groq/gemma2-9b-it\", **kwargs\n) -&gt; str | AsyncIterator[str]:\n    \"\"\"\n    Public completion interface using the model name specified in the global configuration.\n    Optionally extracts keywords if requested.\n    \"\"\"\n    if history_messages is None:\n        history_messages = []\n    # Check and set response format for keyword extraction if needed\n    keyword_extraction_flag = kwargs.pop(\"keyword_extraction\", None)\n    if keyword_extraction_flag:\n        kwargs[\"response_format\"] = \"json\"\n\n    if \"response_format\" in kwargs:\n        if isinstance(kwargs[\"response_format\"], dict):\n            kwargs[\"response_format\"] = enforce_no_additional_properties(kwargs[\"response_format\"])\n        elif isinstance(kwargs[\"response_format\"], str):\n            pass\n        else:\n            kwargs[\"response_format\"] = enforce_no_additional_properties(kwargs[\"response_format\"].model_json_schema())  # oder .schema() in v1\n     # kwargs[\"hashing_kv\"].global_config[\"llm_model_name\"]\n\n    if any(x in model_name for x in [\"mistral\", \"mixtral\"]):\n        kwargs.pop(\"response_format\", None)\n\n    return await litellm_complete_if_cache(\n        model_name,\n        prompt,\n        system_prompt=system_prompt,\n        history_messages=history_messages,\n        **kwargs,\n    )\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.adapter.litellm_complete_if_cache","title":"<code>litellm_complete_if_cache(model, prompt, system_prompt=None, history_messages=None, base_url=None, api_key=None, **kwargs)</code>  <code>async</code>","text":"<p>Core function to query the LiteLLM model. It builds the message context, invokes the completion API, and returns either a complete result string or an async iterator for streaming responses.</p> Source code in <code>toolboxv2/mods/isaa/extras/adapter.py</code> <pre><code>@retry(\n    stop=stop_after_attempt(3),\n    wait=wait_exponential(multiplier=1, min=4, max=10),\n    retry=retry_if_exception_type((RateLimitError, Timeout, APIConnectionError)),\n)\nasync def litellm_complete_if_cache(\n    model,\n    prompt,\n    system_prompt=None,\n    history_messages=None,\n    base_url=None,\n    api_key=None,\n    **kwargs,\n) -&gt; str | AsyncIterator[str]:\n    \"\"\"\n    Core function to query the LiteLLM model. It builds the message context,\n    invokes the completion API, and returns either a complete result string or\n    an async iterator for streaming responses.\n    \"\"\"\n    # Set the API key if provided\n    if api_key:\n        os.environ[\"LITELLM_API_KEY\"] = api_key\n\n    # Remove internal keys not needed for the client call\n    kwargs.pop(\"hashing_kv\", None)\n    kwargs.pop(\"keyword_extraction\", None)\n\n    fallbacks_ = kwargs.pop(\"fallbacks\", [])\n    # Build the messages list from system prompt, conversation history, and the new prompt\n    messages = []\n    if system_prompt:\n        messages.append({\"role\": \"system\", \"content\": system_prompt})\n    if history_messages is not None:\n        messages.extend(history_messages)\n    messages.append({\"role\": \"user\", \"content\": prompt})\n\n    # Log query details for debugging purposes\n    try:\n        # Depending on the response format, choose the appropriate API call\n        if \"response_format\" in kwargs:\n            response = await acompletion(\n                model=model, messages=messages,\n                fallbacks=fallbacks_+os.getenv(\"FALLBACKS_MODELS\", '').split(','),\n                **kwargs\n            )\n        else:\n            response = await acompletion(\n                model=model, messages=messages,\n                fallbacks=os.getenv(\"FALLBACKS_MODELS\", '').split(','),\n                **kwargs\n            )\n    except Exception as e:\n        print(f\"\\n{model=}\\n{prompt=}\\n{system_prompt=}\\n{history_messages=}\\n{base_url=}\\n{api_key=}\\n{kwargs=}\")\n        get_logger().error(f\"Failed to litellm memory work {e}\")\n        return \"\"\n\n    # Check if the response is a streaming response (i.e. an async iterator)\n    if hasattr(response, \"__aiter__\"):\n\n        async def inner():\n            async for chunk in response:\n                # Assume LiteLLM response structure is similar to OpenAI's\n                content = chunk.choices[0].delta.content\n                if content is None:\n                    continue\n                yield content\n\n        return inner()\n    else:\n        # Non-streaming: extract and return the full content string\n\n        content = response.choices[0].message.content\n        if content is None:\n            content = response.choices[0].message.tool_calls[0].function.arguments\n        return content\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.adapter.litellm_embed","title":"<code>litellm_embed(texts, model='gemini/text-embedding-004', base_url=None, api_key=None)</code>  <code>async</code>","text":"<p>Generates embeddings for the given list of texts using LiteLLM.</p> Source code in <code>toolboxv2/mods/isaa/extras/adapter.py</code> <pre><code>@retry(\n    stop=stop_after_attempt(3),\n    wait=wait_exponential(multiplier=1, min=4, max=60),\n    retry=retry_if_exception_type((RateLimitError, Timeout, APIConnectionError)),\n)\nasync def litellm_embed(\n    texts: list[str],\n    model: str = \"gemini/text-embedding-004\",\n    base_url: str = None,\n    api_key: str = None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Generates embeddings for the given list of texts using LiteLLM.\n    \"\"\"\n    response = await litellm.aembedding(\n        model=model, input=texts,\n        # encoding_format=\"float\"\n    )\n    return np.array([dp.embedding for dp in response.data])\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.filter","title":"<code>filter</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.filter.filter_relevant_texts","title":"<code>filter_relevant_texts(query, texts, fuzzy_threshold=70, semantic_threshold=0.75, model=None)</code>","text":"<p>Filters a list of texts based on their relevance to the query. It first uses a fuzzy matching score and, if that score is below the threshold, it then checks the semantic similarity.</p> <p>:param query: The query string. :param texts: List of page texts. :param fuzzy_threshold: Fuzzy matching score threshold (0-100). :param semantic_threshold: Semantic similarity threshold (0.0-1.0). :param model: A preloaded SentenceTransformer model (if None, one will be loaded). :return: Filtered list of texts deemed relevant.</p> Source code in <code>toolboxv2/mods/isaa/extras/filter.py</code> <pre><code>def filter_relevant_texts(query: str,\n                          texts: list[str],\n                          fuzzy_threshold: int = 70,\n                          semantic_threshold: float = 0.75,\n                          model = None) -&gt; list[str]:\n    \"\"\"\n    Filters a list of texts based on their relevance to the query.\n    It first uses a fuzzy matching score and, if that score is below the threshold,\n    it then checks the semantic similarity.\n\n    :param query: The query string.\n    :param texts: List of page texts.\n    :param fuzzy_threshold: Fuzzy matching score threshold (0-100).\n    :param semantic_threshold: Semantic similarity threshold (0.0-1.0).\n    :param model: A preloaded SentenceTransformer model (if None, one will be loaded).\n    :return: Filtered list of texts deemed relevant.\n    \"\"\"\n    try:\n        from rapidfuzz import fuzz\n    except Exception:\n        os.system([sys.executable, '-m', 'pip', 'install', 'RapidFuzz'])\n        from rapidfuzz import fuzz\n    try:\n        from sentence_transformers import SentenceTransformer, util\n    except Exception:\n        os.system([sys.executable, '-m', 'pip', 'install', 'sentence-transformers'])\n        from sentence_transformers import SentenceTransformer, util\n\n    if model is None:\n        # For efficiency, consider pre-loading this model outside the function.\n        model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n\n    # Pre-compute query embedding for the semantic check:\n    query_embedding = model.encode(query, convert_to_tensor=True)\n\n    relevant_texts = []\n    for text in texts:\n        # --- Fuzzy Keyword Filtering ---\n        fuzzy_score = fuzz.partial_ratio(query.lower(), text.lower())\n        if fuzzy_score &gt;= fuzzy_threshold:\n            relevant_texts.append(text)\n        else:\n            # --- Semantic Similarity Filtering ---\n            text_embedding = model.encode(text, convert_to_tensor=True)\n            similarity = util.pytorch_cos_sim(query_embedding, text_embedding).item()\n            if similarity &gt;= semantic_threshold:\n                relevant_texts.append(text)\n    return relevant_texts\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.mcp_session_manager","title":"<code>mcp_session_manager</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.mcp_session_manager.MCPSessionManager","title":"<code>MCPSessionManager</code>","text":"<p>Manages persistent MCP sessions with automatic reconnection and parallel processing</p> Source code in <code>toolboxv2/mods/isaa/extras/mcp_session_manager.py</code> <pre><code>class MCPSessionManager:\n    \"\"\"Manages persistent MCP sessions with automatic reconnection and parallel processing\"\"\"\n\n    def __init__(self):\n        self.sessions: dict[str, ClientSession] = {}\n        self.connections: dict[str, Any] = {}\n        self.capabilities_cache: dict[str, dict] = {}\n        self.retry_count: dict[str, int] = {}\n        self.max_retries = 3\n        self.connection_timeout = 15.0  # 10 seconds timeout\n        self.operation_timeout = 10.0  # 5 seconds for operations\n\n    async def get_session_with_timeout(self, server_name: str, server_config: dict[str, Any]) -&gt; ClientSession | None:\n        \"\"\"Get session with timeout protection\"\"\"\n        try:\n            return await asyncio.wait_for(\n                self.get_session(server_name, server_config),\n                timeout=self.connection_timeout\n            )\n        except TimeoutError:\n            eprint(f\"MCP session creation timeout for {server_name}\")\n            return None\n\n    async def get_session(self, server_name: str, server_config: dict[str, Any]) -&gt; ClientSession | None:\n        \"\"\"Get or create persistent MCP session with proper context management\"\"\"\n        if server_name in self.sessions:\n            try:\n                # Test if session is still alive with timeout\n                session = self.sessions[server_name]\n                # Quick connectivity test\n                await asyncio.wait_for(session.list_tools(), timeout=2.0)\n                return session\n            except Exception as e:\n                wprint(f\"MCP session {server_name} failed, recreating: {e}\")\n                # Clean up the old session\n                if server_name in self.sessions:\n                    del self.sessions[server_name]\n                if server_name in self.connections:\n                    del self.connections[server_name]\n\n        return await self._create_session(server_name, server_config)\n\n    async def _create_session(self, server_name: str, server_config: dict[str, Any]) -&gt; ClientSession | None:\n        \"\"\"Create new MCP session with improved error handling\"\"\"\n        try:\n            command = server_config.get('command')\n            args = server_config.get('args', [])\n            env = server_config.get('env', {})\n            transport_type = server_config.get('transport', 'stdio')\n\n            if not command:\n                eprint(f\"No command specified for MCP server {server_name}\")\n                return None\n\n            iprint(f\"Creating MCP session for {server_name} (transport: {transport_type})\")\n\n            session = None\n\n            # Create connection based on transport type\n            if transport_type == 'stdio':\n                session = await self._create_stdio_session(server_name, command, args, env)\n            elif transport_type in ['http', 'streamable-http']:\n                session = await self._create_http_session(server_name, server_config)\n            else:\n                eprint(f\"Unsupported transport type: {transport_type}\")\n                return None\n\n            if session:\n                self.sessions[server_name] = session\n                self.retry_count[server_name] = 0\n                iprint(f\"\u2713 MCP session created successfully: {server_name}\")\n                return session\n\n            return None\n\n        except Exception as e:\n            self.retry_count[server_name] = self.retry_count.get(server_name, 0) + 1\n            if self.retry_count[server_name] &lt;= self.max_retries:\n                wprint(f\"MCP session creation failed (attempt {self.retry_count[server_name]}/{self.max_retries}): {e}\")\n                await asyncio.sleep(1.0)  # Longer delay before retry\n                return await self._create_session(server_name, server_config)\n            else:\n                eprint(f\"\u2717 MCP session creation failed after {self.max_retries} attempts: {e}\")\n                return None\n\n    async def _create_stdio_session(self, server_name: str, command: str, args: list[str], env: dict[str, str]) -&gt; \\\n    ClientSession | None:\n        \"\"\"Create stdio MCP session with fixed async context handling\"\"\"\n        try:\n            from mcp import StdioServerParameters\n            from mcp.client.stdio import stdio_client\n\n            # Prepare environment\n            process_env = os.environ.copy()\n            process_env.update(env)\n\n            server_params = StdioServerParameters(\n                command=command,\n                args=args,\n                env=process_env\n            )\n\n            # Create the stdio client and session in a single task context\n            stdio_connection = stdio_client(server_params)\n\n            # Enter the context manager\n            read_stream, write_stream = await stdio_connection.__aenter__()\n\n            # Store the connection for cleanup later\n            self.connections[server_name] = stdio_connection\n\n            # Create session\n            session = ClientSession(read_stream, write_stream)\n\n            # Initialize session in the same context\n            await session.__aenter__()\n            await asyncio.wait_for(session.initialize(), timeout=self.connection_timeout)\n\n            return session\n\n        except Exception as e:\n            eprint(f\"Failed to create stdio session for {server_name}: {e}\")\n            # Cleanup on failure\n            if server_name in self.connections:\n                with contextlib.suppress(Exception):\n                    await self.connections[server_name].__aexit__(None, None, None)\n                del self.connections[server_name]\n            return None\n\n    async def _create_http_session(self, server_name: str, server_config: dict[str, Any]) -&gt; ClientSession | None:\n        \"\"\"Create HTTP MCP session with timeout\"\"\"\n        try:\n            from mcp.client.streamable_http import streamablehttp_client\n\n            url = server_config.get('url', f\"http://localhost:{server_config.get('port', 8000)}/mcp\")\n\n            connection = streamablehttp_client(url)\n            read_stream, write_stream, cleanup = await asyncio.wait_for(\n                connection.__aenter__(),\n                timeout=self.connection_timeout\n            )\n\n            session = ClientSession(read_stream, write_stream)\n            await session.__aenter__()\n            await asyncio.wait_for(\n                session.initialize(),\n                timeout=self.connection_timeout\n            )\n\n            self.connections[server_name] = connection\n            return session\n\n        except Exception as e:\n            eprint(f\"Failed to create HTTP session for {server_name}: {e}\")\n            return None\n\n    async def extract_capabilities_with_timeout(self, session: ClientSession, server_name: str) -&gt; dict[str, dict]:\n        \"\"\"Extract capabilities with timeout protection\"\"\"\n        try:\n            return await asyncio.wait_for(\n                self.extract_capabilities(session, server_name),\n                timeout=self.operation_timeout\n            )\n        except TimeoutError:\n            eprint(f\"Capability extraction timeout for {server_name}\")\n            return {'tools': {}, 'resources': {}, 'resource_templates': {}, 'prompts': {}, 'images': {}}\n\n    async def extract_capabilities(self, session: ClientSession, server_name: str) -&gt; dict[str, dict]:\n        \"\"\"Extract all capabilities from MCP session\"\"\"\n        if server_name in self.capabilities_cache:\n            return self.capabilities_cache[server_name]\n\n        capabilities = {\n            'tools': {},\n            'resources': {},\n            'resource_templates': {},\n            'prompts': {},\n            'images': {}\n        }\n\n        try:\n            # Extract tools with individual timeouts\n            try:\n                tools_response = await asyncio.wait_for(session.list_tools(), timeout=3.0)\n                for tool in tools_response.tools:\n                    capabilities['tools'][tool.name] = {\n                        'name': tool.name,\n                        'description': tool.description or '',\n                        'input_schema': tool.inputSchema,\n                        'output_schema': getattr(tool, 'outputSchema', None),\n                        'display_name': getattr(tool, 'title', tool.name)\n                    }\n            except TimeoutError:\n                wprint(f\"Tools extraction timeout for {server_name}\")\n            except Exception as e:\n                wprint(f\"Failed to extract tools from {server_name}: {e}\")\n\n            # Extract resources with timeout\n            try:\n                resources_response = await asyncio.wait_for(session.list_resources(), timeout=3.0)\n                for resource in resources_response.resources:\n                    capabilities['resources'][str(resource.uri)] = {\n                        'uri': str(resource.uri),\n                        'name': resource.name or str(resource.uri),\n                        'description': resource.description or '',\n                        'mime_type': getattr(resource, 'mimeType', None)\n                    }\n            except TimeoutError:\n                wprint(f\"Resources extraction timeout for {server_name}\")\n            except Exception as e:\n                wprint(f\"Failed to extract resources from {server_name}: {e}\")\n\n            # Extract resource templates with timeout\n            try:\n                templates_response = await asyncio.wait_for(session.list_resource_templates(), timeout=3.0)\n                for template in templates_response.resourceTemplates:\n                    capabilities['resource_templates'][template.uriTemplate] = {\n                        'uri_template': template.uriTemplate,\n                        'name': template.name or template.uriTemplate,\n                        'description': template.description or ''\n                    }\n            except TimeoutError:\n                wprint(f\"Resource templates extraction timeout for {server_name}\")\n            except Exception as e:\n                wprint(f\"Failed to extract resource templates from {server_name}: {e}\")\n\n            # Extract prompts with timeout\n            try:\n                prompts_response = await asyncio.wait_for(session.list_prompts(), timeout=3.0)\n                for prompt in prompts_response.prompts:\n                    capabilities['prompts'][prompt.name] = {\n                        'name': prompt.name,\n                        'description': prompt.description or '',\n                        'arguments': [\n                            {\n                                'name': arg.name,\n                                'description': arg.description or '',\n                                'required': arg.required\n                            } for arg in (prompt.arguments or [])\n                        ]\n                    }\n            except TimeoutError:\n                wprint(f\"Prompts extraction timeout for {server_name}\")\n            except Exception as e:\n                wprint(f\"Failed to extract prompts from {server_name}: {e}\")\n\n            self.capabilities_cache[server_name] = capabilities\n\n            total_caps = (len(capabilities['tools']) + len(capabilities['resources']) +\n                          len(capabilities['resource_templates']) + len(capabilities['prompts']))\n            iprint(f\"\u2713 Extracted {total_caps} capabilities from {server_name}\")\n\n        except Exception as e:\n            eprint(f\"Failed to extract capabilities from {server_name}: {e}\")\n\n        return capabilities\n\n    async def _cleanup_session(self, server_name: str):\n        \"\"\"Clean up a specific session with proper context management\"\"\"\n        try:\n            # Clean up session first\n            if server_name in self.sessions:\n                try:\n                    session = self.sessions[server_name]\n                    await asyncio.wait_for(session.__aexit__(None, None, None), timeout=2.0)\n                except (TimeoutError, Exception) as e:\n                    wprint(f\"Session cleanup warning for {server_name}: {e}\")\n                finally:\n                    del self.sessions[server_name]\n\n            # Clean up connection\n            if server_name in self.connections:\n                try:\n                    connection = self.connections[server_name]\n                    await asyncio.wait_for(connection.__aexit__(None, None, None), timeout=2.0)\n                except (TimeoutError, Exception) as e:\n                    wprint(f\"Connection cleanup warning for {server_name}: {e}\")\n                finally:\n                    del self.connections[server_name]\n\n            # Clear cache\n            if server_name in self.capabilities_cache:\n                del self.capabilities_cache[server_name]\n\n            # Reset retry count\n            if server_name in self.retry_count:\n                del self.retry_count[server_name]\n\n        except Exception as e:\n            wprint(f\"Cleanup error for {server_name}: {e}\")\n\n    async def cleanup_all(self):\n        \"\"\"Clean up all sessions with timeout\"\"\"\n        cleanup_tasks = []\n        for server_name in list(self.sessions.keys()):\n            task = asyncio.create_task(self._cleanup_session(server_name))\n            cleanup_tasks.append(task)\n\n        if cleanup_tasks:\n            try:\n                await asyncio.wait_for(\n                    asyncio.gather(*cleanup_tasks, return_exceptions=True),\n                    timeout=5.0\n                )\n            except TimeoutError:\n                wprint(\"MCP session cleanup timeout\")\n</code></pre> <code>cleanup_all()</code> <code>async</code> \u00b6 <p>Clean up all sessions with timeout</p> Source code in <code>toolboxv2/mods/isaa/extras/mcp_session_manager.py</code> <pre><code>async def cleanup_all(self):\n    \"\"\"Clean up all sessions with timeout\"\"\"\n    cleanup_tasks = []\n    for server_name in list(self.sessions.keys()):\n        task = asyncio.create_task(self._cleanup_session(server_name))\n        cleanup_tasks.append(task)\n\n    if cleanup_tasks:\n        try:\n            await asyncio.wait_for(\n                asyncio.gather(*cleanup_tasks, return_exceptions=True),\n                timeout=5.0\n            )\n        except TimeoutError:\n            wprint(\"MCP session cleanup timeout\")\n</code></pre> <code>extract_capabilities(session, server_name)</code> <code>async</code> \u00b6 <p>Extract all capabilities from MCP session</p> Source code in <code>toolboxv2/mods/isaa/extras/mcp_session_manager.py</code> <pre><code>async def extract_capabilities(self, session: ClientSession, server_name: str) -&gt; dict[str, dict]:\n    \"\"\"Extract all capabilities from MCP session\"\"\"\n    if server_name in self.capabilities_cache:\n        return self.capabilities_cache[server_name]\n\n    capabilities = {\n        'tools': {},\n        'resources': {},\n        'resource_templates': {},\n        'prompts': {},\n        'images': {}\n    }\n\n    try:\n        # Extract tools with individual timeouts\n        try:\n            tools_response = await asyncio.wait_for(session.list_tools(), timeout=3.0)\n            for tool in tools_response.tools:\n                capabilities['tools'][tool.name] = {\n                    'name': tool.name,\n                    'description': tool.description or '',\n                    'input_schema': tool.inputSchema,\n                    'output_schema': getattr(tool, 'outputSchema', None),\n                    'display_name': getattr(tool, 'title', tool.name)\n                }\n        except TimeoutError:\n            wprint(f\"Tools extraction timeout for {server_name}\")\n        except Exception as e:\n            wprint(f\"Failed to extract tools from {server_name}: {e}\")\n\n        # Extract resources with timeout\n        try:\n            resources_response = await asyncio.wait_for(session.list_resources(), timeout=3.0)\n            for resource in resources_response.resources:\n                capabilities['resources'][str(resource.uri)] = {\n                    'uri': str(resource.uri),\n                    'name': resource.name or str(resource.uri),\n                    'description': resource.description or '',\n                    'mime_type': getattr(resource, 'mimeType', None)\n                }\n        except TimeoutError:\n            wprint(f\"Resources extraction timeout for {server_name}\")\n        except Exception as e:\n            wprint(f\"Failed to extract resources from {server_name}: {e}\")\n\n        # Extract resource templates with timeout\n        try:\n            templates_response = await asyncio.wait_for(session.list_resource_templates(), timeout=3.0)\n            for template in templates_response.resourceTemplates:\n                capabilities['resource_templates'][template.uriTemplate] = {\n                    'uri_template': template.uriTemplate,\n                    'name': template.name or template.uriTemplate,\n                    'description': template.description or ''\n                }\n        except TimeoutError:\n            wprint(f\"Resource templates extraction timeout for {server_name}\")\n        except Exception as e:\n            wprint(f\"Failed to extract resource templates from {server_name}: {e}\")\n\n        # Extract prompts with timeout\n        try:\n            prompts_response = await asyncio.wait_for(session.list_prompts(), timeout=3.0)\n            for prompt in prompts_response.prompts:\n                capabilities['prompts'][prompt.name] = {\n                    'name': prompt.name,\n                    'description': prompt.description or '',\n                    'arguments': [\n                        {\n                            'name': arg.name,\n                            'description': arg.description or '',\n                            'required': arg.required\n                        } for arg in (prompt.arguments or [])\n                    ]\n                }\n        except TimeoutError:\n            wprint(f\"Prompts extraction timeout for {server_name}\")\n        except Exception as e:\n            wprint(f\"Failed to extract prompts from {server_name}: {e}\")\n\n        self.capabilities_cache[server_name] = capabilities\n\n        total_caps = (len(capabilities['tools']) + len(capabilities['resources']) +\n                      len(capabilities['resource_templates']) + len(capabilities['prompts']))\n        iprint(f\"\u2713 Extracted {total_caps} capabilities from {server_name}\")\n\n    except Exception as e:\n        eprint(f\"Failed to extract capabilities from {server_name}: {e}\")\n\n    return capabilities\n</code></pre> <code>extract_capabilities_with_timeout(session, server_name)</code> <code>async</code> \u00b6 <p>Extract capabilities with timeout protection</p> Source code in <code>toolboxv2/mods/isaa/extras/mcp_session_manager.py</code> <pre><code>async def extract_capabilities_with_timeout(self, session: ClientSession, server_name: str) -&gt; dict[str, dict]:\n    \"\"\"Extract capabilities with timeout protection\"\"\"\n    try:\n        return await asyncio.wait_for(\n            self.extract_capabilities(session, server_name),\n            timeout=self.operation_timeout\n        )\n    except TimeoutError:\n        eprint(f\"Capability extraction timeout for {server_name}\")\n        return {'tools': {}, 'resources': {}, 'resource_templates': {}, 'prompts': {}, 'images': {}}\n</code></pre> <code>get_session(server_name, server_config)</code> <code>async</code> \u00b6 <p>Get or create persistent MCP session with proper context management</p> Source code in <code>toolboxv2/mods/isaa/extras/mcp_session_manager.py</code> <pre><code>async def get_session(self, server_name: str, server_config: dict[str, Any]) -&gt; ClientSession | None:\n    \"\"\"Get or create persistent MCP session with proper context management\"\"\"\n    if server_name in self.sessions:\n        try:\n            # Test if session is still alive with timeout\n            session = self.sessions[server_name]\n            # Quick connectivity test\n            await asyncio.wait_for(session.list_tools(), timeout=2.0)\n            return session\n        except Exception as e:\n            wprint(f\"MCP session {server_name} failed, recreating: {e}\")\n            # Clean up the old session\n            if server_name in self.sessions:\n                del self.sessions[server_name]\n            if server_name in self.connections:\n                del self.connections[server_name]\n\n    return await self._create_session(server_name, server_config)\n</code></pre> <code>get_session_with_timeout(server_name, server_config)</code> <code>async</code> \u00b6 <p>Get session with timeout protection</p> Source code in <code>toolboxv2/mods/isaa/extras/mcp_session_manager.py</code> <pre><code>async def get_session_with_timeout(self, server_name: str, server_config: dict[str, Any]) -&gt; ClientSession | None:\n    \"\"\"Get session with timeout protection\"\"\"\n    try:\n        return await asyncio.wait_for(\n            self.get_session(server_name, server_config),\n            timeout=self.connection_timeout\n        )\n    except TimeoutError:\n        eprint(f\"MCP session creation timeout for {server_name}\")\n        return None\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.modes","title":"<code>modes</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.modes.generate_prompt","title":"<code>generate_prompt(subject, context='', additional_requirements=None)</code>","text":"<p>Generates a prompt based on the given subject, with optional context and additional requirements.</p> <p>Parameters: - subject (str): The main subject for the prompt. - context (str): Optional additional context to tailor the prompt. - additional_requirements (Dict[str, Any]): Optional additional parameters or requirements for the prompt.</p> <p>Returns: - str: A crafted prompt.</p> Source code in <code>toolboxv2/mods/isaa/extras/modes.py</code> <pre><code>def generate_prompt(subject: str, context: str = \"\", additional_requirements: dict[str, Any] = None) -&gt; str:\n    \"\"\"\n    Generates a prompt based on the given subject, with optional context and additional requirements.\n\n    Parameters:\n    - subject (str): The main subject for the prompt.\n    - context (str): Optional additional context to tailor the prompt.\n    - additional_requirements (Dict[str, Any]): Optional additional parameters or requirements for the prompt.\n\n    Returns:\n    - str: A crafted prompt.\n    \"\"\"\n    prompt = f\"Based on the subject '{subject}', with the context '{context}', generate a clear and precise instruction.\"\n    if additional_requirements:\n        prompt += f\" Consider the following requirements: {additional_requirements}.\"\n    return prompt\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.terminal_progress","title":"<code>terminal_progress</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.terminal_progress.ChainPrinter","title":"<code>ChainPrinter</code>","text":"<p>Custom printer for enhanced chain visualization and progress display</p> Source code in <code>toolboxv2/mods/isaa/extras/terminal_progress.py</code> <pre><code>class ChainPrinter:\n    \"\"\"Custom printer for enhanced chain visualization and progress display\"\"\"\n\n    def __init__(self, verbose: bool = True):\n        self.verbose = verbose\n        self.colors = {\n            'success': '\\033[92m',\n            'error': '\\033[91m',\n            'warning': '\\033[93m',\n            'info': '\\033[94m',\n            'highlight': '\\033[95m',\n            'dim': '\\033[2m',\n            'bold': '\\033[1m',\n            'reset': '\\033[0m'\n        }\n\n    def _colorize(self, text: str, color: str) -&gt; str:\n        return f\"{self.colors.get(color, '')}{text}{self.colors['reset']}\"\n\n    def print_header(self, title: str, subtitle: str = None):\n        \"\"\"Print formatted header\"\"\"\n        print(f\"\\n{self._colorize('\u2550' * 60, 'highlight')}\")\n        print(f\"{self._colorize(f'\ud83d\udd17 {title}', 'bold')}\")\n        if subtitle:\n            print(f\"{self._colorize(subtitle, 'dim')}\")\n        print(f\"{self._colorize('\u2550' * 60, 'highlight')}\\n\")\n\n    def print_success(self, message: str):\n        print(f\"{self._colorize('\u2705 ', 'success')}{message}\")\n\n    def print_error(self, message: str):\n        print(f\"{self._colorize('\u274c ', 'error')}{message}\")\n\n    def print_warning(self, message: str):\n        print(f\"{self._colorize('\u26a0\ufe0f ', 'warning')}{message}\")\n\n    def print_info(self, message: str):\n        print(f\"{self._colorize('\u2139\ufe0f ', 'info')}{message}\")\n\n    def print_progress_start(self, chain_name: str):\n        print(f\"\\n{self._colorize('\ud83d\ude80 Starting chain execution:', 'info')} {self._colorize(chain_name, 'bold')}\")\n\n    def print_task_start(self, task_name: str, current: int, total: int):\n        progress = f\"[{current + 1}/{total}]\" if total &gt; 0 else \"\"\n        print(f\"  {self._colorize('\u25b6\ufe0f ', 'info')}{progress} {task_name}\")\n\n    def print_task_complete(self, task_name: str, completed: int, total: int):\n        progress = f\"[{completed}/{total}]\" if total &gt; 0 else \"\"\n        print(f\"  {self._colorize('\u2705', 'success')} {progress} {task_name} completed\")\n\n    def print_task_error(self, task_name: str, error: str):\n        print(f\"  {self._colorize('\u274c', 'error')} {task_name} failed: {error}\")\n\n    def print_progress_end(self, chain_name: str, duration: float, success: bool):\n        status = self._colorize('\u2705 COMPLETED', 'success') if success else self._colorize('\u274c FAILED', 'error')\n        print(f\"\\n{status} {chain_name} ({duration:.2f}s)\\n\")\n\n    def print_tool_usage_success(self, tool_name: str, duration: float, is_meta_tool: bool = False):\n        if is_meta_tool:\n            print(f\"  {self._colorize('\ud83d\udd27 ', 'info')}{tool_name} completed ({duration:.2f}s)\")\n        else:\n            print(f\"  {self._colorize('\ud83d\udd29 ', 'info')}{tool_name} completed ({duration:.2f}s)\")\n\n    def print_tool_usage_error(self, tool_name: str, error: str, is_meta_tool: bool = False):\n        if is_meta_tool:\n            print(f\"  {self._colorize('\ud83d\udd27 ', 'error')}{tool_name} failed: {error}\")\n        else:\n            print(f\"  {self._colorize('\ud83d\udd29 ', 'error')}{tool_name} failed: {error}\")\n\n    def print_outline_created(self, outline: dict):\n        for step in outline.get(\"steps\", []):\n            print(f\"  {self._colorize('\ud83d\udcd6 ', 'info')}Step: {self._colorize(step.get('description', 'Unknown'), 'dim')}\")\n\n    def print_reasoning_loop(self, loop_data: dict):\n        print(f\"  {self._colorize('\ud83e\udde0 ', 'info')}Reasoning Loop #{loop_data.get('loop_number', '?')}\")\n        print(\n            f\"    {self._colorize('\ud83d\udcd6 ', 'info')}Outline Step: {loop_data.get('outline_step', 0)} of {loop_data.get('outline_total', 0)}\")\n        print(f\"    {self._colorize('\ud83d\udcda ', 'info')}Context Size: {loop_data.get('context_size', 0)} entries\")\n        print(f\"    {self._colorize('\ud83d\udccb ', 'info')}Task Stack: {loop_data.get('task_stack_size', 0)} items\")\n        print(f\"    {self._colorize('\ud83d\udd04 ', 'info')}Recovery Attempts: {loop_data.get('auto_recovery_attempts', 0)}\")\n        print(f\"    {self._colorize('\ud83d\udcca ', 'info')}Performance Metrics: {loop_data.get('performance_metrics', {})}\")\n\n    def print_chain_list(self, chains: list[tuple[str, ChainMetadata]]):\n        \"\"\"Print formatted list of available chains\"\"\"\n        if not chains:\n            self.print_info(\"No chains found. Use 'create' to build your first chain.\")\n            return\n\n        self.print_header(\"Available Chains\", f\"Total: {len(chains)}\")\n\n        for name, meta in chains:\n            # Status indicators\n            indicators = []\n            if meta.has_parallels:\n                indicators.append(self._colorize(\"\u26a1\", \"highlight\"))\n            if meta.has_conditionals:\n                indicators.append(self._colorize(\"\ud83d\udd00\", \"warning\"))\n            if meta.has_error_handling:\n                indicators.append(self._colorize(\"\ud83d\udee1\ufe0f\", \"info\"))\n\n            status_str = \" \".join(indicators) if indicators else \"\"\n\n            # Complexity color\n            complexity_colors = {\"simple\": \"success\", \"medium\": \"warning\", \"complex\": \"error\"}\n            complexity = self._colorize(meta.complexity, complexity_colors.get(meta.complexity, \"info\"))\n\n            print(f\"  {self._colorize(name, 'bold')} {status_str}\")\n            print(f\"    {meta.description or 'No description'}\")\n            print(f\"    {complexity} \u2022 {meta.agent_count} agents \u2022 {meta.version}\")\n            if meta.tags:\n                tags_str = \" \".join([f\"#{tag}\" for tag in meta.tags])\n                print(f\"    {self._colorize(tags_str, 'dim')}\")\n            print()\n</code></pre> <code>print_chain_list(chains)</code> \u00b6 <p>Print formatted list of available chains</p> Source code in <code>toolboxv2/mods/isaa/extras/terminal_progress.py</code> <pre><code>def print_chain_list(self, chains: list[tuple[str, ChainMetadata]]):\n    \"\"\"Print formatted list of available chains\"\"\"\n    if not chains:\n        self.print_info(\"No chains found. Use 'create' to build your first chain.\")\n        return\n\n    self.print_header(\"Available Chains\", f\"Total: {len(chains)}\")\n\n    for name, meta in chains:\n        # Status indicators\n        indicators = []\n        if meta.has_parallels:\n            indicators.append(self._colorize(\"\u26a1\", \"highlight\"))\n        if meta.has_conditionals:\n            indicators.append(self._colorize(\"\ud83d\udd00\", \"warning\"))\n        if meta.has_error_handling:\n            indicators.append(self._colorize(\"\ud83d\udee1\ufe0f\", \"info\"))\n\n        status_str = \" \".join(indicators) if indicators else \"\"\n\n        # Complexity color\n        complexity_colors = {\"simple\": \"success\", \"medium\": \"warning\", \"complex\": \"error\"}\n        complexity = self._colorize(meta.complexity, complexity_colors.get(meta.complexity, \"info\"))\n\n        print(f\"  {self._colorize(name, 'bold')} {status_str}\")\n        print(f\"    {meta.description or 'No description'}\")\n        print(f\"    {complexity} \u2022 {meta.agent_count} agents \u2022 {meta.version}\")\n        if meta.tags:\n            tags_str = \" \".join([f\"#{tag}\" for tag in meta.tags])\n            print(f\"    {self._colorize(tags_str, 'dim')}\")\n        print()\n</code></pre> <code>print_header(title, subtitle=None)</code> \u00b6 <p>Print formatted header</p> Source code in <code>toolboxv2/mods/isaa/extras/terminal_progress.py</code> <pre><code>def print_header(self, title: str, subtitle: str = None):\n    \"\"\"Print formatted header\"\"\"\n    print(f\"\\n{self._colorize('\u2550' * 60, 'highlight')}\")\n    print(f\"{self._colorize(f'\ud83d\udd17 {title}', 'bold')}\")\n    if subtitle:\n        print(f\"{self._colorize(subtitle, 'dim')}\")\n    print(f\"{self._colorize('\u2550' * 60, 'highlight')}\\n\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.terminal_progress.ChainProgressTracker","title":"<code>ChainProgressTracker</code>","text":"<p>Enhanced progress tracker for chain execution with live display</p> Source code in <code>toolboxv2/mods/isaa/extras/terminal_progress.py</code> <pre><code>class ChainProgressTracker:\n    \"\"\"Enhanced progress tracker for chain execution with live display\"\"\"\n\n    def __init__(self, chain_printer: 'ChainPrinter'):\n        self.events: list[ProgressEvent] = []\n        self.start_time = time.time()\n        self.chain_printer = chain_printer\n        self.current_task = None\n        self.task_count = 0\n        self.completed_tasks = 0\n\n    async def emit_event(self, event: ProgressEvent):\n        \"\"\"Emit progress event with live display updates\"\"\"\n        self.events.append(event)\n\n        if event.event_type == \"chain_start\":\n            self.task_count = event.metadata.get(\"task_count\", 0)\n            self.chain_printer.print_progress_start(event.node_name)\n\n        elif event.event_type == \"task_start\":\n            self.current_task = event.node_name\n            self.chain_printer.print_task_start(event.node_name, self.completed_tasks, self.task_count)\n\n        elif event.event_type == \"task_complete\":\n            if event.status == NodeStatus.COMPLETED:\n                self.completed_tasks += 1\n                self.chain_printer.print_task_complete(event.node_name, self.completed_tasks, self.task_count)\n            elif event.status == NodeStatus.FAILED:\n                self.chain_printer.print_task_error(event.node_name, event.metadata.get(\"error\", \"Unknown error\"))\n\n        elif event.event_type == \"chain_end\":\n            duration = time.time() - self.start_time\n            self.chain_printer.print_progress_end(event.node_name, duration, event.status == NodeStatus.COMPLETED)\n\n        elif event.event_type == \"tool_call\" and event.success == False:\n            self.chain_printer.print_tool_usage_error(event.tool_name, event.metadata.get(\"error\",\n                                                                                          event.metadata.get(\"message\",\n                                                                                                             event.error_details.get(\n                                                                                                                 \"error\",\n                                                                                                                 \"Unknown error\"))))\n\n        elif event.event_type == \"tool_call\" and event.success == True:\n            self.chain_printer.print_tool_usage_success(event.tool_name, event.duration, event.is_meta_tool)\n\n        elif event.event_type == \"outline_created\":\n            self.chain_printer.print_outline_created(event.metadata.get(\"outline\", {}))\n\n        elif event.event_type == \"reasoning_loop\":\n            self.chain_printer.print_reasoning_loop(event.metadata)\n\n        elif event.event_type == \"task_error\":\n            self.chain_printer.print_task_error(event.node_name, event.metadata.get(\"error\", \"Unknown error\"))\n</code></pre> <code>emit_event(event)</code> <code>async</code> \u00b6 <p>Emit progress event with live display updates</p> Source code in <code>toolboxv2/mods/isaa/extras/terminal_progress.py</code> <pre><code>async def emit_event(self, event: ProgressEvent):\n    \"\"\"Emit progress event with live display updates\"\"\"\n    self.events.append(event)\n\n    if event.event_type == \"chain_start\":\n        self.task_count = event.metadata.get(\"task_count\", 0)\n        self.chain_printer.print_progress_start(event.node_name)\n\n    elif event.event_type == \"task_start\":\n        self.current_task = event.node_name\n        self.chain_printer.print_task_start(event.node_name, self.completed_tasks, self.task_count)\n\n    elif event.event_type == \"task_complete\":\n        if event.status == NodeStatus.COMPLETED:\n            self.completed_tasks += 1\n            self.chain_printer.print_task_complete(event.node_name, self.completed_tasks, self.task_count)\n        elif event.status == NodeStatus.FAILED:\n            self.chain_printer.print_task_error(event.node_name, event.metadata.get(\"error\", \"Unknown error\"))\n\n    elif event.event_type == \"chain_end\":\n        duration = time.time() - self.start_time\n        self.chain_printer.print_progress_end(event.node_name, duration, event.status == NodeStatus.COMPLETED)\n\n    elif event.event_type == \"tool_call\" and event.success == False:\n        self.chain_printer.print_tool_usage_error(event.tool_name, event.metadata.get(\"error\",\n                                                                                      event.metadata.get(\"message\",\n                                                                                                         event.error_details.get(\n                                                                                                             \"error\",\n                                                                                                             \"Unknown error\"))))\n\n    elif event.event_type == \"tool_call\" and event.success == True:\n        self.chain_printer.print_tool_usage_success(event.tool_name, event.duration, event.is_meta_tool)\n\n    elif event.event_type == \"outline_created\":\n        self.chain_printer.print_outline_created(event.metadata.get(\"outline\", {}))\n\n    elif event.event_type == \"reasoning_loop\":\n        self.chain_printer.print_reasoning_loop(event.metadata)\n\n    elif event.event_type == \"task_error\":\n        self.chain_printer.print_task_error(event.node_name, event.metadata.get(\"error\", \"Unknown error\"))\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.terminal_progress.DualTrackEventProcessor","title":"<code>DualTrackEventProcessor</code>","text":"<p>Processes events for both tracking perspectives</p> Source code in <code>toolboxv2/mods/isaa/extras/terminal_progress.py</code> <pre><code>class DualTrackEventProcessor:\n    \"\"\"Processes events for both tracking perspectives\"\"\"\n\n    def __init__(self):\n        self.state = DualTrackState()\n        self.event_history = []\n        self.start_time = None\n\n    def process_event(self, event: ProgressEvent):\n        \"\"\"Route event to appropriate track processors\"\"\"\n        if not self.start_time:\n            self.start_time = event.timestamp\n\n        self.event_history.append(event)\n\n        # Route to progress track processor\n        if self._is_progress_track_event(event):\n            self._process_progress_event(event)\n\n        # Route to system track processor\n        if self._is_system_track_event(event):\n            self._process_system_event(event)\n\n        # Update cross-track correlations\n        self._update_correlations(event)\n\n    def _is_progress_track_event(self, event: ProgressEvent) -&gt; bool:\n        \"\"\"Determine if event belongs to progress track\"\"\"\n        progress_events = {\n            'execution_start', 'execution_complete',\n            'outline_created', 'plan_created',\n            'reasoning_loop', 'meta_tool_analysis',\n            'tool_call', 'task_start', 'task_complete', 'task_error',\n            'llm_call'\n        }\n        return event.event_type in progress_events\n\n    def _is_system_track_event(self, event: ProgressEvent) -&gt; bool:\n        \"\"\"Determine if event belongs to system track\"\"\"\n        system_events = {\n            'node_enter', 'node_exit', 'node_phase', 'error'\n        }\n        return event.event_type in system_events\n\n    def _process_progress_event(self, event: ProgressEvent):\n        \"\"\"Process events in the semantic progress track\"\"\"\n        if event.event_type == 'execution_start':\n            self.state.semantic_progress['execution_phase'] = 'initializing'\n\n        elif event.event_type == 'outline_created':\n            # NEW &amp; IMPORTANT - extract outline structure\n            outline_data = event.metadata.get('outline') if event.metadata else None\n            if outline_data:\n                self.state.semantic_progress['current_outline'] = outline_data\n                steps = outline_data.get('steps', []) if isinstance(outline_data, dict) else []\n                self.state.semantic_progress['outline_progress'] = {\n                    'current_step': 1,\n                    'total_steps': len(steps),\n                    'completed_steps': [],\n                    'step_details': steps\n                }\n            self.state.semantic_progress['execution_phase'] = 'planning'\n\n        elif event.event_type == 'plan_created':\n            self.state.semantic_progress['execution_phase'] = 'executing'\n\n        elif event.event_type == 'reasoning_loop':\n            loop_num = event.metadata.get('loop_number', 0) if event.metadata else 0\n            self.state.semantic_progress['current_reasoning_loop'] = loop_num\n\n        elif event.event_type == 'tool_call':\n            is_meta = event.metadata.get('is_meta_tool', False) if event.metadata else False\n            tool_name = event.tool_name or 'unknown'\n\n            if is_meta:\n                if event.status == 'RUNNING':\n                    self.state.semantic_progress['active_meta_tools'].append(tool_name)\n                elif event.status in ['COMPLETED', 'FAILED']:\n                    if tool_name in self.state.semantic_progress['active_meta_tools']:\n                        self.state.semantic_progress['active_meta_tools'].remove(tool_name)\n\n        elif event.event_type in ['task_start', 'task_complete', 'task_error']:\n            task_state = self.state.semantic_progress['task_execution_state']\n            if event.event_type == 'task_start':\n                task_state['running'].append(event.task_id)\n                task_state['total'] += 1\n            elif event.event_type == 'task_complete':\n                if event.task_id in task_state['running']:\n                    task_state['running'].remove(event.task_id)\n                task_state['completed'] += 1\n            elif event.event_type == 'task_error':\n                if event.task_id in task_state['running']:\n                    task_state['running'].remove(event.task_id)\n                task_state['failed'] += 1\n\n        elif event.event_type == 'llm_call':\n            llm_state = self.state.semantic_progress['llm_interactions']\n            llm_state['total_calls'] += 1\n            if event.llm_cost:\n                llm_state['total_cost'] += event.llm_cost\n            if event.llm_total_tokens:\n                llm_state['total_tokens'] += event.llm_total_tokens\n\n        elif event.event_type == 'execution_complete':\n            self.state.semantic_progress['execution_phase'] = 'completed'\n\n    def _process_system_event(self, event: ProgressEvent):\n        \"\"\"Process events in the system track\"\"\"\n        node_name = event.node_name or 'unknown'\n\n        if event.event_type == 'node_enter':\n            self.state.system_state['active_nodes'][node_name] = {\n                'status': 'active',\n                'start_time': event.timestamp,\n                'current_phase': 'initializing'\n            }\n            if node_name not in self.state.system_state['node_flow']:\n                self.state.system_state['node_flow'].append(node_name)\n            self.state.system_state['current_node'] = node_name\n\n        elif event.event_type == 'node_exit':\n            if node_name in self.state.system_state['active_nodes']:\n                node_info = self.state.system_state['active_nodes'][node_name]\n                node_info['status'] = 'completed' if event.success else 'failed'\n                node_info['end_time'] = event.timestamp\n                node_info['duration'] = event.node_duration\n                # Remove from active\n                del self.state.system_state['active_nodes'][node_name]\n\n        elif event.event_type == 'node_phase':\n            if node_name in self.state.system_state['active_nodes']:\n                self.state.system_state['active_nodes'][node_name]['current_phase'] = event.node_phase\n            self.state.system_state['node_phases'][node_name] = event.node_phase\n\n        elif event.event_type == 'error':\n            self.state.system_state['system_health']['error_count'] += 1\n            error_detail = {\n                'timestamp': event.timestamp,\n                'node': node_name,\n                'error': event.error_details or 'Unknown error'\n            }\n            self.state.system_state['system_health']['warnings'].append(error_detail)\n            if self.state.system_state['system_health']['error_count'] &gt; 5:\n                self.state.system_state['system_health']['status'] = 'degraded'\n\n    def _update_correlations(self, event: ProgressEvent):\n        \"\"\"Update cross-track correlations\"\"\"\n        # Correlate semantic events with system nodes\n        if event.node_name and self._is_progress_track_event(event):\n            semantic_key = f\"{event.event_type}:{event.timestamp}\"\n            self.state.correlations['semantic_to_system'][semantic_key] = event.node_name\n\n        # Track timing correlations for performance analysis\n        if event.node_duration:\n            self.state.correlations['timing_correlations'].append({\n                'event_type': event.event_type,\n                'node_name': event.node_name,\n                'duration': event.node_duration,\n                'timestamp': event.timestamp\n            })\n\n    def get_progress_summary(self) -&gt; dict[str, Any]:\n        \"\"\"Get comprehensive progress summary across both tracks\"\"\"\n        current_time = time.time()\n        elapsed = current_time - self.start_time if self.start_time else 0\n\n        return {\n            'dual_track_state': {\n                'semantic_progress': self.state.semantic_progress.copy(),\n                'system_state': self.state.system_state.copy(),\n                'correlations_count': {\n                    'semantic_to_system': len(self.state.correlations['semantic_to_system']),\n                    'timing_data_points': len(self.state.correlations['timing_correlations'])\n                }\n            },\n            'execution_metrics': {\n                'total_events': len(self.event_history),\n                'elapsed_time': elapsed,\n                'events_per_second': len(self.event_history) / max(elapsed, 1),\n                'system_health': self.state.system_state['system_health']['status'],\n                'error_rate': self.state.system_state['system_health']['error_count'] / max(len(self.event_history), 1)\n            },\n            'current_activity': self._get_current_activity_summary()\n        }\n\n    def _get_current_activity_summary(self) -&gt; dict[str, Any]:\n        \"\"\"Synthesize current activity from both tracks\"\"\"\n        semantic = self.state.semantic_progress\n        system = self.state.system_state\n\n        return {\n            'execution_phase': semantic['execution_phase'],\n            'current_outline_step': semantic['outline_progress']['current_step'],\n            'total_outline_steps': semantic['outline_progress']['total_steps'],\n            'outline_completion_percent': (\n                len(semantic['outline_progress']['completed_steps']) /\n                max(semantic['outline_progress']['total_steps'], 1) * 100\n            ),\n            'active_reasoning_loop': semantic['current_reasoning_loop'],\n            'active_meta_tools': semantic['active_meta_tools'].copy(),\n            'running_tasks': len(semantic['task_execution_state']['running']),\n            'current_system_node': system['current_node'],\n            'active_system_nodes': len(system['active_nodes']),\n            'system_health_status': system['system_health']['status']\n        }\n</code></pre> <code>get_progress_summary()</code> \u00b6 <p>Get comprehensive progress summary across both tracks</p> Source code in <code>toolboxv2/mods/isaa/extras/terminal_progress.py</code> <pre><code>def get_progress_summary(self) -&gt; dict[str, Any]:\n    \"\"\"Get comprehensive progress summary across both tracks\"\"\"\n    current_time = time.time()\n    elapsed = current_time - self.start_time if self.start_time else 0\n\n    return {\n        'dual_track_state': {\n            'semantic_progress': self.state.semantic_progress.copy(),\n            'system_state': self.state.system_state.copy(),\n            'correlations_count': {\n                'semantic_to_system': len(self.state.correlations['semantic_to_system']),\n                'timing_data_points': len(self.state.correlations['timing_correlations'])\n            }\n        },\n        'execution_metrics': {\n            'total_events': len(self.event_history),\n            'elapsed_time': elapsed,\n            'events_per_second': len(self.event_history) / max(elapsed, 1),\n            'system_health': self.state.system_state['system_health']['status'],\n            'error_rate': self.state.system_state['system_health']['error_count'] / max(len(self.event_history), 1)\n        },\n        'current_activity': self._get_current_activity_summary()\n    }\n</code></pre> <code>process_event(event)</code> \u00b6 <p>Route event to appropriate track processors</p> Source code in <code>toolboxv2/mods/isaa/extras/terminal_progress.py</code> <pre><code>def process_event(self, event: ProgressEvent):\n    \"\"\"Route event to appropriate track processors\"\"\"\n    if not self.start_time:\n        self.start_time = event.timestamp\n\n    self.event_history.append(event)\n\n    # Route to progress track processor\n    if self._is_progress_track_event(event):\n        self._process_progress_event(event)\n\n    # Route to system track processor\n    if self._is_system_track_event(event):\n        self._process_system_event(event)\n\n    # Update cross-track correlations\n    self._update_correlations(event)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.terminal_progress.DualTrackState","title":"<code>DualTrackState</code>","text":"<p>Manages the dual-track system: Progress Track + System Track</p> Source code in <code>toolboxv2/mods/isaa/extras/terminal_progress.py</code> <pre><code>class DualTrackState:\n    \"\"\"Manages the dual-track system: Progress Track + System Track\"\"\"\n\n    def __init__(self):\n        # Progress Track (What the Agent Does)\n        self.semantic_progress = {\n            'execution_phase': 'starting',  # starting, planning, executing, completing\n            'current_outline': None,\n            'outline_progress': {'current_step': 0, 'total_steps': 0, 'completed_steps': []},\n            'current_reasoning_loop': 0,\n            'active_meta_tools': [],\n            'task_execution_state': {'total': 0, 'completed': 0, 'failed': 0, 'running': []},\n            'llm_interactions': {'total_calls': 0, 'total_cost': 0.0, 'total_tokens': 0}\n        }\n\n        # System Track (Where the Agent Is)\n        self.system_state = {\n            'active_nodes': {},\n            'node_flow': [],\n            'current_node': None,\n            'node_phases': {},  # node_name -&gt; current phase\n            'system_health': {'status': 'healthy', 'error_count': 0, 'warnings': []}\n        }\n\n        # Cross-track correlations\n        self.correlations = {\n            'semantic_to_system': {},  # semantic events -&gt; system nodes\n            'system_to_semantic': {},  # system nodes -&gt; semantic events\n            'timing_correlations': []\n        }\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.terminal_progress.EnhancedDisplayRenderer","title":"<code>EnhancedDisplayRenderer</code>","text":"<p>Renders dual-track information with intelligent display management</p> Source code in <code>toolboxv2/mods/isaa/extras/terminal_progress.py</code> <pre><code>class EnhancedDisplayRenderer:\n    \"\"\"Renders dual-track information with intelligent display management\"\"\"\n\n    def __init__(self, mode: VerbosityMode, use_rich: bool = True):\n        self.mode = mode\n        self.use_rich = use_rich and RICH_AVAILABLE\n        self.console = Console() if self.use_rich else None\n        self.last_display_hash = None\n\n    def render_dual_track_display(self, processor: DualTrackEventProcessor) -&gt; str:\n        \"\"\"Main rendering method for dual-track display\"\"\"\n        summary = processor.get_progress_summary()\n\n        if not self.use_rich:\n            return self._render_fallback_display(summary)\n\n        if self.mode == VerbosityMode.MINIMAL:\n            return self._render_minimal_display(summary)\n        elif self.mode == VerbosityMode.STANDARD:\n            return self._render_standard_display(summary)\n        elif self.mode == VerbosityMode.VERBOSE:\n            return self._render_verbose_display(summary)\n        elif self.mode == VerbosityMode.DEBUG:\n            return self._render_debug_display(summary)\n        elif self.mode == VerbosityMode.REALTIME:\n            return self._render_realtime_display(summary)\n\n        return \"\"\n\n    def _render_minimal_display(self, summary: dict[str, Any]) -&gt; str:\n        \"\"\"Minimal display - just essential progress\"\"\"\n        activity = summary['current_activity']\n        metrics = summary['execution_metrics']\n\n        # Simple status line\n        phase = activity['execution_phase'].title()\n        if activity['total_outline_steps'] &gt; 0:\n            progress = f\"{activity['outline_completion_percent']:.0f}%\"\n            status = f\"\ud83e\udd16 {phase} | Step {activity['current_outline_step']}/{activity['total_outline_steps']} | {progress}\"\n        else:\n            status = f\"\ud83e\udd16 {phase}\"\n\n        if metrics['error_rate'] &gt; 0.1:\n            status += f\" | \u26a0\ufe0f {metrics['error_rate']:.1%} errors\"\n\n        self.console.print(status, style=\"cyan\")\n        return status\n\n    def _render_standard_display(self, summary: dict[str, Any]) -&gt; str:\n        \"\"\"Standard display - balanced detail\"\"\"\n        activity = summary['current_activity']\n        semantic = summary['dual_track_state']['semantic_progress']\n        system = summary['dual_track_state']['system_state']\n\n        # Main header\n        self.console.print()\n        header_content = self._build_standard_header(activity, summary['execution_metrics'])\n        header_panel = Panel(header_content, title=\"\ud83e\udd16 Agent Execution Status\", style=\"cyan\", box=box.ROUNDED)\n        self.console.print(header_panel)\n\n        # Progress overview\n        if semantic['current_outline']:\n            progress_content = self._build_outline_progress_display(semantic['outline_progress'])\n            progress_panel = Panel(progress_content, title=\"\ud83d\udccb Execution Outline\", style=\"blue\", box=box.ROUNDED)\n            self.console.print(progress_panel)\n\n        # Current activity\n        current_activity = self._build_current_activity_display(activity, semantic, system)\n        activity_panel = Panel(current_activity, title=\"\ud83d\udd04 Current Activity\", style=\"green\", box=box.ROUNDED)\n        self.console.print(activity_panel)\n\n        return \"standard_display_rendered\"\n\n    def _render_verbose_display(self, summary: dict[str, Any]) -&gt; str:\n        \"\"\"Verbose display - detailed dual-track view\"\"\"\n        # Render standard display first\n        self._render_standard_display(summary)\n\n        # Add detailed system state\n        system = summary['dual_track_state']['system_state']\n        system_content = self._build_system_state_display(system)\n        system_panel = Panel(system_content, title=\"\ud83d\udd27 System State\", style=\"yellow\", box=box.ROUNDED)\n        self.console.print(system_panel)\n\n        # Add performance metrics\n        metrics_content = self._build_metrics_display(summary['execution_metrics'])\n        metrics_panel = Panel(metrics_content, title=\"\ud83d\udcca Performance Metrics\", style=\"magenta\", box=box.ROUNDED)\n        self.console.print(metrics_panel)\n\n        return \"verbose_display_rendered\"\n\n    def _render_debug_display(self, summary: dict[str, Any]) -&gt; str:\n        \"\"\"Debug display - full dual-track details\"\"\"\n        # Render verbose display first\n        self._render_verbose_display(summary)\n\n        # Add correlation data\n        correlations = summary['dual_track_state']['correlations_count']\n        correlation_content = f\"Semantic\u2194System: {correlations['semantic_to_system']} mappings\\n\"\n        correlation_content += f\"Timing Data Points: {correlations['timing_data_points']}\"\n\n        correlation_panel = Panel(correlation_content, title=\"\ud83d\udd17 Track Correlations\", style=\"red\", box=box.ROUNDED)\n        self.console.print(correlation_panel)\n\n        return \"debug_display_rendered\"\n\n    def _render_realtime_display(self, summary: dict[str, Any]) -&gt; str:\n        \"\"\"Realtime display - live updates\"\"\"\n        activity = summary['current_activity']\n\n        # Single line live status\n        phase = activity['execution_phase']\n        step_info = f\"step {activity['current_outline_step']}/{activity['total_outline_steps']}\" if activity[\n                                                                                                        'total_outline_steps'] &gt; 0 else \"no outline\"\n\n        # Animated spinner\n        spinner_chars = [\"\u280b\", \"\u2819\", \"\u2839\", \"\u2838\", \"\u283c\", \"\u2834\", \"\u2826\", \"\u2827\", \"\u2807\", \"\u280f\"]\n        spinner_idx = int(time.time() * 2) % len(spinner_chars)\n        spinner = spinner_chars[spinner_idx]\n\n        status_line = f\"\\r{spinner} \ud83e\udd16 {phase.title()} | {step_info} | {activity['outline_completion_percent']:.0f}%\"\n\n        if activity['active_meta_tools']:\n            tools_str = \",\".join(activity['active_meta_tools'][:2])\n            status_line += f\" | tools:{tools_str}\"\n\n        print(status_line, end=\"\", flush=True)\n        return status_line\n\n    def _build_standard_header(self, activity: dict[str, Any], metrics: dict[str, Any]) -&gt; str:\n        \"\"\"Build standard header content\"\"\"\n        lines = []\n\n        # Execution phase with progress\n        phase_line = f\"Phase: {activity['execution_phase'].title()}\"\n        if activity['total_outline_steps'] &gt; 0:\n            phase_line += f\" | Progress: {activity['outline_completion_percent']:.1f}%\"\n        lines.append(phase_line)\n\n        # Current activity\n        activity_parts = []\n        if activity['current_outline_step'] &gt; 0:\n            activity_parts.append(f\"Step {activity['current_outline_step']}/{activity['total_outline_steps']}\")\n        if activity['active_reasoning_loop'] &gt; 0:\n            activity_parts.append(f\"Reasoning Loop {activity['active_reasoning_loop']}\")\n        if activity['active_meta_tools']:\n            activity_parts.append(f\"Using: {', '.join(activity['active_meta_tools'][:3])}\")\n\n        if activity_parts:\n            lines.append(\"Activity: \" + \" | \".join(activity_parts))\n\n        # System health\n        health_line = f\"Health: {activity['system_health_status'].title()}\"\n        if metrics['error_rate'] &gt; 0:\n            health_line += f\" | Error Rate: {metrics['error_rate']:.1%}\"\n        health_line += f\" | Runtime: {metrics['elapsed_time']:.1f}s\"\n        lines.append(health_line)\n\n        return \"\\n\".join(lines)\n\n    def _build_outline_progress_display(self, outline_progress: dict[str, Any]) -&gt; str:\n        \"\"\"Build outline progress visualization\"\"\"\n        if not outline_progress.get('step_details'):\n            return \"No outline available\"\n\n        lines = []\n        current_step = outline_progress['current_step']\n        completed_steps = set(outline_progress['completed_steps'])\n\n        for i, step_detail in enumerate(outline_progress['step_details'], 1):\n            if isinstance(step_detail, dict):\n                description = step_detail.get('description', f'Step {i}')\n            else:\n                description = str(step_detail)\n\n            # Status icon\n            if i in completed_steps:\n                icon = \"\u2705\"\n                style = \"completed\"\n            elif i == current_step:\n                icon = \"\ud83d\udd04\"\n                style = \"current\"\n            else:\n                icon = \"\u23f8\ufe0f\"\n                style = \"pending\"\n\n            # Truncate long descriptions\n            if len(description) &gt; 60:\n                description = description[:57] + \"...\"\n\n            lines.append(f\"{icon} Step {i}: {description}\")\n\n        return \"\\n\".join(lines)\n\n    def _build_current_activity_display(self, activity: dict[str, Any], semantic: dict[str, Any],\n                                        system: dict[str, Any]) -&gt; str:\n        \"\"\"Build current activity summary\"\"\"\n        lines = []\n\n        # Current focus\n        if system['current_node']:\n            lines.append(f\"\ud83c\udfaf Current Node: {system['current_node']}\")\n\n        # Active operations\n        active_ops = []\n        if activity['active_meta_tools']:\n            active_ops.extend(activity['active_meta_tools'])\n        if activity['running_tasks'] &gt; 0:\n            active_ops.append(f\"{activity['running_tasks']} running tasks\")\n\n        if active_ops:\n            lines.append(f\"\u2699\ufe0f Active Operations: {', '.join(active_ops)}\")\n\n        # Resource usage\n        llm_info = semantic['llm_interactions']\n        if llm_info['total_calls'] &gt; 0:\n            resource_line = f\"\ud83d\udcb0 LLM: {llm_info['total_calls']} calls\"\n            if llm_info['total_cost'] &gt; 0:\n                resource_line += f\", ${llm_info['total_cost']:.4f}\"\n            if llm_info['total_tokens'] &gt; 0:\n                resource_line += f\", {llm_info['total_tokens']:,} tokens\"\n            lines.append(resource_line)\n\n        return \"\\n\".join(lines) if lines else \"System initializing...\"\n\n    def _build_system_state_display(self, system: dict[str, Any]) -&gt; str:\n        \"\"\"Build detailed system state display\"\"\"\n        lines = []\n\n        # Active nodes\n        if system['active_nodes']:\n            lines.append(f\"\ud83d\udd04 Active Nodes ({len(system['active_nodes'])}):\")\n            for node_name, node_info in list(system['active_nodes'].items())[:5]:\n                phase = node_info.get('current_phase', 'unknown')\n                elapsed = time.time() - node_info.get('start_time', time.time())\n                lines.append(f\"  \u2022 {node_name}: {phase} ({elapsed:.1f}s)\")\n\n        # Node execution flow\n        if system['node_flow']:\n            flow_display = \" \u2192 \".join(system['node_flow'][-5:])  # Last 5 nodes\n            lines.append(f\"\ud83d\udd17 Execution Flow: {flow_display}\")\n\n        # System health details\n        health = system['system_health']\n        if health['error_count'] &gt; 0:\n            lines.append(f\"\u26a0\ufe0f Errors: {health['error_count']}\")\n            if health['warnings']:\n                latest_warning = health['warnings'][-1]\n                warning_time = datetime.fromtimestamp(latest_warning['timestamp']).strftime(\"%H:%M:%S\")\n                lines.append(f\"   Latest: [{warning_time}] {latest_warning['error']}\")\n\n        return \"\\n\".join(lines) if lines else \"System state nominal\"\n\n    def _build_metrics_display(self, metrics: dict[str, Any]) -&gt; str:\n        \"\"\"Build performance metrics display\"\"\"\n        lines = []\n\n        lines.append(f\"\ud83d\udcca Total Events: {metrics['total_events']}\")\n        lines.append(f\"\u26a1 Processing Rate: {metrics['events_per_second']:.1f} events/sec\")\n        lines.append(f\"\u23f1\ufe0f Runtime: {metrics['elapsed_time']:.2f}s\")\n        lines.append(f\"\ud83c\udfe5 System Health: {metrics['system_health']}\")\n\n        if metrics['error_rate'] &gt; 0:\n            lines.append(f\"\u274c Error Rate: {metrics['error_rate']:.2%}\")\n\n        return \"\\n\".join(lines)\n\n    def _render_fallback_display(self, summary: dict[str, Any]) -&gt; str:\n        \"\"\"Fallback display without Rich\"\"\"\n        activity = summary['current_activity']\n        metrics = summary['execution_metrics']\n\n        print(f\"\\n{'=' * 60}\")\n        print(\"\ud83e\udd16 AGENT EXECUTION STATUS\")\n        print(f\"{'=' * 60}\")\n        print(f\"Phase: {activity['execution_phase'].title()}\")\n        if activity['total_outline_steps'] &gt; 0:\n            print(\n                f\"Progress: {activity['outline_completion_percent']:.1f}% (Step {activity['current_outline_step']}/{activity['total_outline_steps']})\")\n        print(f\"Health: {activity['system_health_status'].title()}\")\n        print(f\"Runtime: {metrics['elapsed_time']:.1f}s\")\n        print(f\"Events: {metrics['total_events']} ({metrics['events_per_second']:.1f}/sec)\")\n        if metrics['error_rate'] &gt; 0:\n            print(f\"Error Rate: {metrics['error_rate']:.1%}\")\n        print(f\"{'=' * 60}\")\n\n        return \"fallback_display_rendered\"\n</code></pre> <code>render_dual_track_display(processor)</code> \u00b6 <p>Main rendering method for dual-track display</p> Source code in <code>toolboxv2/mods/isaa/extras/terminal_progress.py</code> <pre><code>def render_dual_track_display(self, processor: DualTrackEventProcessor) -&gt; str:\n    \"\"\"Main rendering method for dual-track display\"\"\"\n    summary = processor.get_progress_summary()\n\n    if not self.use_rich:\n        return self._render_fallback_display(summary)\n\n    if self.mode == VerbosityMode.MINIMAL:\n        return self._render_minimal_display(summary)\n    elif self.mode == VerbosityMode.STANDARD:\n        return self._render_standard_display(summary)\n    elif self.mode == VerbosityMode.VERBOSE:\n        return self._render_verbose_display(summary)\n    elif self.mode == VerbosityMode.DEBUG:\n        return self._render_debug_display(summary)\n    elif self.mode == VerbosityMode.REALTIME:\n        return self._render_realtime_display(summary)\n\n    return \"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.terminal_progress.ProgressiveTreePrinter","title":"<code>ProgressiveTreePrinter</code>","text":"<p>Production-ready progressive tree printer with dual-track event processing</p> Source code in <code>toolboxv2/mods/isaa/extras/terminal_progress.py</code> <pre><code>class ProgressiveTreePrinter:\n    \"\"\"Production-ready progressive tree printer with dual-track event processing\"\"\"\n\n    def __init__(self, mode: VerbosityMode = VerbosityMode.STANDARD, use_rich: bool = True,\n                 auto_refresh: bool = True, max_history: int = 1000, **kwargs):\n        self.mode = mode\n        self.use_rich = use_rich and RICH_AVAILABLE\n        self.auto_refresh = auto_refresh\n        self.max_history = max_history\n\n        # Initialize dual-track processor\n        self.event_processor = DualTrackEventProcessor()\n        self.display_renderer = EnhancedDisplayRenderer(mode, use_rich)\n\n        # Display management\n        self._last_display_time = 0\n        self._display_interval = self._get_display_interval()\n        self._consecutive_errors = 0\n        self._error_threshold = 5\n\n        # Session tracking\n        self.agent_name = \"FlowAgent\"\n        self.session_id = None\n        self._print_counter = 0\n\n        # Accumulated runs tracking\n        self._accumulated_runs = []\n        self._current_run_id = 0\n        self._global_start_time = time.time()\n\n        # Rich console setup (if available)\n        if self.use_rich:\n            self.console = Console(record=True)\n\n    def flush(self, run_name: str = None) -&gt; dict[str, Any]:\n        \"\"\"Enhanced flush with dual-track state management\"\"\"\n        try:\n            current_time = time.time()\n            if run_name is None:\n                run_name = f\"run_{self._current_run_id + 1}\"\n\n            # Generate comprehensive run data using dual-track system\n            summary = self.event_processor.get_progress_summary()\n\n            # Create comprehensive run data\n            run_data = {\n                \"run_id\": self._current_run_id + 1,\n                \"run_name\": run_name,\n                \"flush_timestamp\": current_time,\n                \"dual_track_summary\": summary,\n                \"execution_events\": self.event_processor.event_history.copy(),\n                \"semantic_progress\": summary['dual_track_state']['semantic_progress'].copy(),\n                \"system_state\": summary['dual_track_state']['system_state'].copy(),\n                \"execution_metrics\": summary['execution_metrics'].copy(),\n                \"current_activity\": summary['current_activity'].copy(),\n                \"print_counter\": self._print_counter,\n                \"agent_name\": self.agent_name,\n                \"session_id\": self.session_id\n            }\n\n            # Add detailed execution flow analysis\n            run_data[\"execution_analysis\"] = {\n                \"outline_completion_rate\": summary['current_activity']['outline_completion_percent'] / 100,\n                \"reasoning_loops_count\": summary['current_activity']['active_reasoning_loop'],\n                \"system_node_count\": len(summary['dual_track_state']['system_state']['node_flow']),\n                \"error_density\": summary['execution_metrics']['error_rate'],\n                \"processing_efficiency\": summary['execution_metrics']['events_per_second']\n            }\n\n            # Store in accumulated runs\n            self._accumulated_runs.append(run_data)\n\n            # Reset for fresh execution\n            self._reset_for_fresh_execution()\n\n            if self.use_rich:\n                self.console.print(f\"\u2705 Run '{run_name}' flushed and stored\", style=\"green bold\")\n                self.console.print(f\"\ud83d\udcca Total accumulated runs: {len(self._accumulated_runs)}\", style=\"blue\")\n            else:\n                print(f\"\u2705 Run '{run_name}' flushed and stored\")\n                print(f\"\ud83d\udcca Total accumulated runs: {len(self._accumulated_runs)}\")\n\n            return run_data\n\n        except Exception as e:\n            error_msg = f\"\u274c Error during flush: {e}\"\n            if self.use_rich:\n                self.console.print(error_msg, style=\"red bold\")\n            else:\n                print(error_msg)\n\n            # Still try to reset for fresh execution\n            self._reset_for_fresh_execution()\n            return {\"error\": str(e), \"timestamp\": current_time}\n\n    def print_final_summary(self):\n        \"\"\"Print comprehensive final summary with dual-track analysis\"\"\"\n        try:\n            if not self.use_rich:\n                self._print_summary_fallback(self.event_processor.get_progress_summary())\n                return\n\n            summary = self.event_processor.get_progress_summary()\n\n            # Clear display and show completion\n            self.console.print()\n            self.console.print(\"\ud83c\udf89 [bold green]EXECUTION COMPLETED[/bold green] \ud83c\udf89\")\n\n            # Final dual-track display\n            self.display_renderer.render_dual_track_display(self.event_processor)\n\n            # Comprehensive summary table\n            self._print_comprehensive_final_table(summary)\n\n            # Performance analysis\n            if self.mode in [VerbosityMode.VERBOSE, VerbosityMode.DEBUG]:\n                self._print_dual_track_performance_analysis(summary)\n\n        except Exception as e:\n            print(f\"\u26a0\ufe0f Error printing final summary: {e}\")\n            self._print_summary_fallback(self.event_processor.get_progress_summary())\n\n    def get_accumulated_summary(self) -&gt; dict[str, Any]:\n        \"\"\"Get comprehensive summary of all accumulated runs with dual-track metrics\"\"\"\n        try:\n            if not self._accumulated_runs:\n                return {\n                    \"total_runs\": 0,\n                    \"message\": \"No runs have been flushed yet\"\n                }\n\n            # Calculate aggregate metrics\n            total_cost = 0.0\n            total_tokens = 0\n            total_events = 0\n            total_errors = 0\n            total_duration = 0.0\n            total_outline_steps = 0\n            total_reasoning_loops = 0\n\n            run_summaries = []\n\n            for run in self._accumulated_runs:\n                # Handle both old and new run data formats\n                if 'dual_track_summary' in run:\n                    # New dual-track format\n                    summary = run['dual_track_summary']\n                    semantic = summary['dual_track_state']['semantic_progress']\n                    metrics = summary['execution_metrics']\n\n                    total_cost += semantic['llm_interactions']['total_cost']\n                    total_tokens += semantic['llm_interactions']['total_tokens']\n                    total_events += metrics['total_events']\n                    total_errors += summary['dual_track_state']['system_state']['system_health']['error_count']\n                    total_duration += metrics['elapsed_time']\n                    total_outline_steps += semantic['outline_progress']['total_steps']\n                    total_reasoning_loops += semantic['current_reasoning_loop']\n\n                    run_summaries.append({\n                        \"run_id\": run[\"run_id\"],\n                        \"run_name\": run[\"run_name\"],\n                        \"duration\": metrics['elapsed_time'],\n                        \"events\": metrics['total_events'],\n                        \"cost\": semantic['llm_interactions']['total_cost'],\n                        \"tokens\": semantic['llm_interactions']['total_tokens'],\n                        \"errors\": summary['dual_track_state']['system_state']['system_health']['error_count'],\n                        \"outline_completion\": summary['current_activity']['outline_completion_percent'],\n                        \"reasoning_loops\": semantic['current_reasoning_loop'],\n                        \"system_health\": summary['current_activity']['system_health_status']\n                    })\n                else:\n                    # Fallback for old format\n                    exec_summary = run.get(\"execution_summary\", {})\n                    perf = exec_summary.get(\"performance_metrics\", {})\n                    timing = exec_summary.get(\"timing\", {})\n\n                    total_cost += perf.get(\"total_cost\", 0)\n                    total_tokens += perf.get(\"total_tokens\", 0)\n                    total_events += perf.get(\"total_events\", 0)\n                    total_errors += perf.get(\"error_count\", 0)\n                    total_duration += timing.get(\"elapsed\", 0)\n\n                    run_summaries.append({\n                        \"run_id\": run[\"run_id\"],\n                        \"run_name\": run[\"run_name\"],\n                        \"duration\": timing.get(\"elapsed\", 0),\n                        \"events\": perf.get(\"total_events\", 0),\n                        \"cost\": perf.get(\"total_cost\", 0),\n                        \"tokens\": perf.get(\"total_tokens\", 0),\n                        \"errors\": perf.get(\"error_count\", 0),\n                        \"outline_completion\": 0,  # Not available in old format\n                        \"reasoning_loops\": 0,  # Not available in old format\n                        \"system_health\": \"unknown\"\n                    })\n\n            # Calculate averages\n            num_runs = len(self._accumulated_runs)\n            avg_duration = total_duration / num_runs\n            avg_cost = total_cost / num_runs\n            avg_tokens = total_tokens / num_runs\n            avg_events = total_events / num_runs\n\n            return {\n                \"total_runs\": num_runs,\n                \"current_run_id\": self._current_run_id,\n                \"global_start_time\": self._global_start_time,\n                \"total_accumulated_time\": time.time() - self._global_start_time,\n\n                \"aggregate_metrics\": {\n                    \"total_cost\": total_cost,\n                    \"total_tokens\": total_tokens,\n                    \"total_events\": total_events,\n                    \"total_errors\": total_errors,\n                    \"total_duration\": total_duration,\n                    \"total_outline_steps\": total_outline_steps,\n                    \"total_reasoning_loops\": total_reasoning_loops,\n                },\n\n                \"average_metrics\": {\n                    \"avg_duration\": avg_duration,\n                    \"avg_cost\": avg_cost,\n                    \"avg_tokens\": avg_tokens,\n                    \"avg_events\": avg_events,\n                    \"avg_error_rate\": total_errors / max(total_events, 1),\n                    \"avg_outline_completion\": sum(r.get(\"outline_completion\", 0) for r in run_summaries) / num_runs,\n                    \"avg_reasoning_loops\": total_reasoning_loops / num_runs\n                },\n\n                \"run_summaries\": run_summaries,\n                \"performance_insights\": self._generate_accumulated_insights(run_summaries)\n            }\n\n        except Exception as e:\n            return {\"error\": f\"Error generating accumulated summary: {e}\"}\n\n    def export_accumulated_data(self, filepath: str = None, extra_data: dict[str, Any] = None) -&gt; str:\n        \"\"\"Export all accumulated run data to file with dual-track information\"\"\"\n        try:\n            if filepath is None:\n                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n                filepath = f\"accumulated_execution_data_{timestamp}.json\"\n\n            export_data = {\n                \"export_timestamp\": time.time(),\n                \"export_version\": \"2.0\",  # Updated version for dual-track\n                \"printer_config\": {\n                    \"mode\": self.mode.value,\n                    \"use_rich\": self.use_rich,\n                    \"agent_name\": self.agent_name\n                },\n                \"accumulated_summary\": self.get_accumulated_summary(),\n                \"all_runs\": self._accumulated_runs,\n                \"dual_track_metadata\": {\n                    \"total_semantic_events\": sum(\n                        len(run.get('execution_events', [])) for run in self._accumulated_runs\n                    ),\n                    \"total_system_nodes\": sum(\n                        len(run.get('system_state', {}).get('node_flow', [])) for run in self._accumulated_runs\n                    ),\n                    \"export_features\": [\"dual_track_processing\", \"semantic_progress\", \"system_state\"]\n                }\n            }\n\n            export_data.update(extra_data or {})\n\n            import json\n            with open(filepath, 'w') as f:\n                json.dump(export_data, f, indent=2, default=str)\n\n            if self.use_rich:\n                self.console.print(f\"\ud83d\udcc1 Accumulated data exported to: {filepath}\", style=\"green bold\")\n                self.console.print(f\"\ud83d\udcca Total runs exported: {len(self._accumulated_runs)}\", style=\"blue\")\n            else:\n                print(f\"\ud83d\udcc1 Accumulated data exported to: {filepath}\")\n                print(f\"\ud83d\udcca Total runs exported: {len(self._accumulated_runs)}\")\n\n            return filepath\n\n        except Exception as e:\n            error_msg = f\"\u274c Error exporting accumulated data: {e}\"\n            if self.use_rich:\n                self.console.print(error_msg, style=\"red bold\")\n            else:\n                print(error_msg)\n            return \"\"\n\n    def _format_cost(self, cost: float) -&gt; str:\n        \"\"\"Enhanced cost formatting with better precision\"\"\"\n        if cost &lt; 0.0001:\n            return f\"${cost * 1000000:.1f}\u03bc\"\n        elif cost &lt; 0.001:\n            return f\"${cost * 1000:.2f}m\"\n        elif cost &lt; 1:\n            return f\"${cost:.4f}\"\n        else:\n            return f\"${cost:.2f}\"\n\n    def reset_global_start_time(self):\n        \"\"\"Reset global start time for new session\"\"\"\n        self._global_start_time = time.time()\n\n    def _print_accumulated_summary_fallback(self, summary: dict[str, Any]):\n        \"\"\"Fallback accumulated summary without Rich\"\"\"\n        try:\n            print(f\"\\n{'=' * 80}\")\n            print(\"\ud83d\uddc2\ufe0f ACCUMULATED EXECUTION SUMMARY\")\n            print(f\"{'=' * 80}\")\n\n            agg = summary[\"aggregate_metrics\"]\n            avg = summary[\"average_metrics\"]\n\n            print(f\"Total Runs: {summary['total_runs']}\")\n            print(f\"Total Duration: {agg['total_duration']:.1f}s (avg: {avg['avg_duration']:.1f}s)\")\n            print(f\"Total Events: {agg['total_events']} (avg: {avg['avg_events']:.1f})\")\n\n            if agg[\"total_cost\"] &gt; 0:\n                print(f\"Total Cost: {self._format_cost(agg['total_cost'])} (avg: {self._format_cost(avg['avg_cost'])})\")\n\n            if agg[\"total_tokens\"] &gt; 0:\n                print(f\"Total Tokens: {agg['total_tokens']:,} (avg: {avg['avg_tokens']:,.0f})\")\n\n            # Dual-track specific metrics\n            if agg.get(\"total_outline_steps\", 0) &gt; 0:\n                print(f\"Total Outline Steps: {agg['total_outline_steps']}\")\n                print(f\"Avg Outline Completion: {avg['avg_outline_completion']:.1f}%\")\n\n            if agg.get(\"total_reasoning_loops\", 0) &gt; 0:\n                print(f\"Total Reasoning Loops: {agg['total_reasoning_loops']} (avg: {avg['avg_reasoning_loops']:.1f})\")\n\n            print(f\"Average Error Rate: {avg['avg_error_rate']:.1%}\")\n\n            print(f\"\\n{'=' * 80}\")\n            print(\"\ud83c\udfc3 INDIVIDUAL RUNS:\")\n            print(f\"{'=' * 80}\")\n\n            for run in summary[\"run_summaries\"]:\n                cost_str = self._format_cost(run[\"cost\"]) if run[\"cost\"] &gt; 0 else \"N/A\"\n                outline_str = f\"{run['outline_completion']:.0f}%\" if run.get('outline_completion') else \"N/A\"\n\n                print(f\"\u2022 {run['run_name']}: {run['duration']:.1f}s | \"\n                      f\"{run['events']} events | Cost: {cost_str} | \"\n                      f\"Outline: {outline_str} | Health: {run.get('system_health', 'unknown')}\")\n\n            # Insights\n            if summary.get(\"performance_insights\"):\n                print(\"\\n\ud83d\udd0d PERFORMANCE INSIGHTS:\")\n                print(f\"{'-' * 40}\")\n                for insight in summary[\"performance_insights\"]:\n                    print(f\"\u2022 {insight}\")\n\n            print(f\"{'=' * 80}\")\n\n        except Exception as e:\n            print(f\"\u274c Error printing fallback summary: {e}\")\n\n    def _generate_accumulated_insights(self, run_summaries: list[dict[str, Any]]) -&gt; list[str]:\n        \"\"\"Generate insights from accumulated run data with dual-track awareness\"\"\"\n        insights = []\n\n        if not run_summaries:\n            return insights\n\n        try:\n            num_runs = len(run_summaries)\n\n            # Performance trends\n            if num_runs &gt; 1:\n                recent_runs = run_summaries[-3:]  # Last 3 runs\n                older_runs = run_summaries[:-3] if len(run_summaries) &gt; 3 else []\n\n                if older_runs:\n                    recent_avg_duration = sum(r[\"duration\"] for r in recent_runs) / len(recent_runs)\n                    older_avg_duration = sum(r[\"duration\"] for r in older_runs) / len(older_runs)\n\n                    if recent_avg_duration &lt; older_avg_duration * 0.8:\n                        insights.append(\"\ud83d\ude80 Performance improving: Recent runs 20% faster\")\n                    elif recent_avg_duration &gt; older_avg_duration * 1.2:\n                        insights.append(\"\u26a0\ufe0f Performance degrading: Recent runs 20% slower\")\n\n            # Error patterns\n            error_counts = [r[\"errors\"] for r in run_summaries]\n            avg_errors = sum(error_counts) / len(error_counts)\n\n            if avg_errors == 0:\n                insights.append(\"\u2728 Perfect reliability: Zero errors across all runs\")\n            elif avg_errors &lt; 1:\n                insights.append(f\"\u2705 High reliability: {avg_errors:.1f} average errors per run\")\n            elif avg_errors &gt; 5:\n                insights.append(f\"\ud83d\udd27 Reliability concerns: {avg_errors:.1f} average errors per run\")\n\n            # Cost efficiency\n            costs = [r[\"cost\"] for r in run_summaries if r[\"cost\"] &gt; 0]\n            if costs:\n                avg_cost = sum(costs) / len(costs)\n                if avg_cost &lt; 0.01:\n                    insights.append(f\"\ud83d\udc9a Very cost efficient: {self._format_cost(avg_cost)} average per run\")\n                elif avg_cost &gt; 0.1:\n                    insights.append(f\"\ud83d\udcb8 High cost per run: {self._format_cost(avg_cost)} average\")\n\n            # Dual-track specific insights\n            outline_completions = [r.get(\"outline_completion\", 0) for r in run_summaries if r.get(\"outline_completion\")]\n            if outline_completions:\n                avg_completion = sum(outline_completions) / len(outline_completions)\n                if avg_completion &gt; 95:\n                    insights.append(f\"\ud83c\udfaf Excellent outline completion: {avg_completion:.1f}% average\")\n                elif avg_completion &lt; 80:\n                    insights.append(f\"\ud83d\udccb Low outline completion: {avg_completion:.1f}% - investigate planning\")\n\n            reasoning_loops = [r.get(\"reasoning_loops\", 0) for r in run_summaries if r.get(\"reasoning_loops\")]\n            if reasoning_loops:\n                avg_loops = sum(reasoning_loops) / len(reasoning_loops)\n                if avg_loops &gt; 10:\n                    insights.append(f\"\ud83e\udde0 High reasoning activity: {avg_loops:.1f} loops average\")\n                elif avg_loops &lt; 3:\n                    insights.append(f\"\u26a1 Efficient reasoning: {avg_loops:.1f} loops average\")\n\n            # System health patterns\n            health_statuses = [r.get(\"system_health\", \"unknown\") for r in run_summaries]\n            healthy_count = sum(1 for h in health_statuses if h == \"healthy\")\n            if healthy_count == len(health_statuses):\n                insights.append(\"\ud83d\udc9a Perfect system health across all runs\")\n            elif healthy_count / len(health_statuses) &lt; 0.8:\n                insights.append(\"\u26a0\ufe0f System health issues detected in multiple runs\")\n\n            # Consistency analysis\n            durations = [r[\"duration\"] for r in run_summaries]\n            if len(durations) &gt; 1:\n                import statistics\n                duration_std = statistics.stdev(durations)\n                duration_mean = statistics.mean(durations)\n                cv = duration_std / duration_mean if duration_mean &gt; 0 else 0\n\n                if cv &lt; 0.2:\n                    insights.append(\"\ud83c\udfaf Highly consistent execution times\")\n                elif cv &gt; 0.5:\n                    insights.append(\"\ud83d\udcca Variable execution times - investigate bottlenecks\")\n\n        except Exception as e:\n            insights.append(f\"\u26a0\ufe0f Error generating insights: {e}\")\n\n        return insights\n\n    def _reset_for_fresh_execution(self):\n        \"\"\"Reset internal state for a completely fresh execution\"\"\"\n        try:\n            # Increment run counter\n            self._current_run_id += 1\n\n            # Reset dual-track processor\n            self.event_processor = DualTrackEventProcessor()\n\n            # Reset display management\n            self._last_display_time = 0\n            self._print_counter = 0\n            self._consecutive_errors = 0\n\n            # Reset session info\n            self.session_id = None\n\n        except Exception as e:\n            print(f\"\u26a0\ufe0f Error during reset: {e}\")\n\n    def _print_comprehensive_final_table(self, summary: dict[str, Any]):\n        \"\"\"Print comprehensive final summary table with dual-track metrics\"\"\"\n        if not self.use_rich:\n            return\n\n        table = Table(title=\"\ud83d\udcca Final Execution Summary\", box=box.ROUNDED)\n        table.add_column(\"Category\", style=\"cyan\", min_width=15)\n        table.add_column(\"Metric\", style=\"white\", min_width=20)\n        table.add_column(\"Value\", style=\"green\", min_width=15)\n\n        # Session info\n        table.add_row(\"Session\", \"Agent Name\", self.agent_name)\n        table.add_row(\"\", \"Session ID\", str(self.session_id or \"N/A\"))\n        table.add_row(\"\", \"Total Runtime\", f\"{summary['execution_metrics']['elapsed_time']:.2f}s\")\n\n        # Progress track\n        semantic = summary['dual_track_state']['semantic_progress']\n        activity = summary['current_activity']\n\n        table.add_row(\"Progress\", \"Final Phase\", activity['execution_phase'].title())\n        table.add_row(\"\", \"Outline Completion\", f\"{activity['outline_completion_percent']:.1f}%\")\n        table.add_row(\"\", \"Reasoning Loops\", str(semantic['current_reasoning_loop']))\n\n        # System track\n        system = summary['dual_track_state']['system_state']\n        table.add_row(\"System\", \"Nodes Processed\", str(len(system['node_flow'])))\n        table.add_row(\"\", \"System Health\", system['system_health']['status'].title())\n        table.add_row(\"\", \"Error Count\", str(system['system_health']['error_count']))\n\n        # Performance\n        metrics = summary['execution_metrics']\n        table.add_row(\"Performance\", \"Total Events\", str(metrics['total_events']))\n        table.add_row(\"\", \"Processing Rate\", f\"{metrics['events_per_second']:.1f} events/sec\")\n        table.add_row(\"\", \"Error Rate\", f\"{metrics['error_rate']:.1%}\")\n\n        # LLM metrics\n        llm = semantic['llm_interactions']\n        if llm['total_calls'] &gt; 0:\n            table.add_row(\"LLM\", \"Total Calls\", str(llm['total_calls']))\n            if llm['total_cost'] &gt; 0:\n                table.add_row(\"\", \"Total Cost\", self._format_cost(llm['total_cost']))\n            if llm['total_tokens'] &gt; 0:\n                table.add_row(\"\", \"Total Tokens\", f\"{llm['total_tokens']:,}\")\n\n        self.console.print()\n        self.console.print(table)\n\n    def _print_dual_track_performance_analysis(self, summary: dict[str, Any]):\n        \"\"\"Print performance analysis with dual-track insights\"\"\"\n        if not self.use_rich:\n            return\n\n        insights = []\n\n        # Progress track analysis\n        activity = summary['current_activity']\n        semantic = summary['dual_track_state']['semantic_progress']\n\n        if activity['outline_completion_percent'] &gt; 95:\n            insights.append(\"\u2728 Excellent outline completion\")\n        elif activity['outline_completion_percent'] &lt; 80:\n            insights.append(\"\u26a0\ufe0f Low outline completion - planning may need improvement\")\n\n        if semantic['current_reasoning_loop'] &gt; 10:\n            insights.append(\"\ud83e\udde0 High reasoning activity - complex problem solving\")\n        elif semantic['current_reasoning_loop'] &lt; 3:\n            insights.append(\"\u26a1 Efficient reasoning - straightforward execution\")\n\n        # System track analysis\n        system = summary['dual_track_state']['system_state']\n        metrics = summary['execution_metrics']\n\n        if metrics['events_per_second'] &gt; 10:\n            insights.append(\"\ud83d\ude80 High processing efficiency\")\n        elif metrics['events_per_second'] &lt; 2:\n            insights.append(\"\ud83d\udc0c Low processing rate - possible bottlenecks\")\n\n        if system['system_health']['status'] == 'healthy':\n            insights.append(\"\ud83d\udc9a Perfect system health\")\n        else:\n            insights.append(\"\ud83d\udd27 System health issues detected\")\n\n        # Cross-track analysis\n        if (activity['outline_completion_percent'] &gt; 90 and\n            system['system_health']['status'] == 'healthy' and\n            metrics['error_rate'] &lt; 0.1):\n            insights.append(\"\ud83c\udfc6 Optimal execution across all tracks\")\n\n        if insights:\n            analysis_panel = Panel(\n                \"\\n\".join(f\"\u2022 {insight}\" for insight in insights),\n                title=\"\ud83d\udd0d Dual-Track Performance Analysis\",\n                style=\"yellow\"\n            )\n            self.console.print()\n            self.console.print(analysis_panel)\n\n    def print_accumulated_summary(self):\n        \"\"\"Print comprehensive summary of all accumulated runs\"\"\"\n        try:\n            summary = self.get_accumulated_summary()\n\n            if summary.get(\"total_runs\", 0) == 0:\n                if self.use_rich:\n                    self.console.print(\"\ud83d\udcca No accumulated runs to display\", style=\"yellow\")\n                else:\n                    print(\"\ud83d\udcca No accumulated runs to display\")\n                return\n\n            if not self.use_rich:\n                self._print_accumulated_summary_fallback(summary)\n                return\n\n            # Rich formatted output\n            self.console.print()\n            self.console.print(\"\ud83d\uddc2\ufe0f [bold cyan]ACCUMULATED EXECUTION SUMMARY[/bold cyan] \ud83d\uddc2\ufe0f\")\n\n            # Overview table with dual-track metrics\n            overview_table = Table(title=\"\ud83d\udcca Aggregate Overview\", box=box.ROUNDED)\n            overview_table.add_column(\"Metric\", style=\"cyan\", min_width=25)\n            overview_table.add_column(\"Total\", style=\"green\", min_width=15)\n            overview_table.add_column(\"Average\", style=\"blue\", min_width=15)\n\n            agg = summary[\"aggregate_metrics\"]\n            avg = summary[\"average_metrics\"]\n\n            overview_table.add_row(\"Runs\", str(summary[\"total_runs\"]), \"\")\n            overview_table.add_row(\"Duration\", f\"{agg['total_duration']:.1f}s\", f\"{avg['avg_duration']:.1f}s\")\n            overview_table.add_row(\"Events\", str(agg[\"total_events\"]), f\"{avg['avg_events']:.1f}\")\n\n            if agg[\"total_cost\"] &gt; 0:\n                overview_table.add_row(\"Cost\", self._format_cost(agg[\"total_cost\"]), self._format_cost(avg[\"avg_cost\"]))\n\n            if agg[\"total_tokens\"] &gt; 0:\n                overview_table.add_row(\"Tokens\", f\"{agg['total_tokens']:,}\", f\"{avg['avg_tokens']:,.0f}\")\n\n            # Dual-track specific metrics\n            if agg.get(\"total_outline_steps\", 0) &gt; 0:\n                overview_table.add_row(\"Outline Steps\", str(agg[\"total_outline_steps\"]), \"\")\n                overview_table.add_row(\"Outline Completion\", \"\", f\"{avg['avg_outline_completion']:.1f}%\")\n\n            if agg.get(\"total_reasoning_loops\", 0) &gt; 0:\n                overview_table.add_row(\"Reasoning Loops\", str(agg[\"total_reasoning_loops\"]),\n                                       f\"{avg['avg_reasoning_loops']:.1f}\")\n\n            overview_table.add_row(\"Error Rate\", \"\", f\"{avg['avg_error_rate']:.1%}\")\n\n            self.console.print(overview_table)\n\n            # Individual runs table\n            runs_table = Table(title=\"\ud83c\udfc3 Individual Runs\", box=box.ROUNDED)\n            runs_table.add_column(\"Run\", style=\"cyan\")\n            runs_table.add_column(\"Duration\", style=\"blue\")\n            runs_table.add_column(\"Events\", style=\"green\")\n            runs_table.add_column(\"Cost\", style=\"yellow\")\n            runs_table.add_column(\"Outline\", style=\"magenta\")\n            runs_table.add_column(\"Health\", style=\"white\")\n\n            for run in summary[\"run_summaries\"]:\n                cost_str = self._format_cost(run[\"cost\"]) if run[\"cost\"] &gt; 0 else \"-\"\n                outline_str = f\"{run.get('outline_completion', 0):.0f}%\" if run.get('outline_completion') else \"N/A\"\n                health_str = run.get('system_health', 'unknown')\n\n                runs_table.add_row(\n                    run[\"run_name\"],\n                    f\"{run['duration']:.1f}s\",\n                    str(run['events']),\n                    cost_str,\n                    outline_str,\n                    health_str\n                )\n\n            self.console.print(runs_table)\n\n            # Insights\n            if summary.get(\"performance_insights\"):\n                insights_panel = Panel(\n                    \"\\n\".join(f\"\u2022 {insight}\" for insight in summary[\"performance_insights\"]),\n                    title=\"\ud83d\udd0d Performance Insights\",\n                    style=\"yellow\"\n                )\n                self.console.print(insights_panel)\n\n        except Exception as e:\n            error_msg = f\"\u274c Error printing accumulated summary: {e}\"\n            if self.use_rich:\n                self.console.print(error_msg, style=\"red bold\")\n            else:\n                print(error_msg)\n\n    def _get_display_interval(self) -&gt; float:\n        \"\"\"Get appropriate display update interval based on mode\"\"\"\n        intervals = {\n            VerbosityMode.MINIMAL: 2.0,\n            VerbosityMode.STANDARD: 1.0,\n            VerbosityMode.VERBOSE: 0.5,\n            VerbosityMode.DEBUG: 0.1,\n            VerbosityMode.REALTIME: 0.2\n        }\n        return intervals.get(self.mode, 1.0)\n\n    async def progress_callback(self, event: ProgressEvent):\n        \"\"\"Enhanced progress callback with dual-track processing\"\"\"\n        try:\n            # Update agent info\n            if event.agent_name:\n                self.agent_name = event.agent_name\n            if event.session_id:\n                self.session_id = event.session_id\n\n            # Process through dual-track system\n            self.event_processor.process_event(event)\n\n            # Update display if enough time has passed or important event\n            should_update = (\n                time.time() - self._last_display_time &gt;= self._display_interval or\n                self._is_important_event(event)\n            )\n\n            if should_update and self.auto_refresh:\n                self._update_display()\n                self._last_display_time = time.time()\n\n        except Exception as e:\n            self._consecutive_errors += 1\n            if self._consecutive_errors &lt;= self._error_threshold:\n                print(f\"\u26a0\ufe0f Progress callback error #{self._consecutive_errors}: {e}\")\n            if self._consecutive_errors &gt; self._error_threshold:\n                print(\"\ud83d\udea8 Progress printing disabled due to excessive errors\")\n                self.progress_callback = self._noop_callback\n\n    def _is_important_event(self, event: ProgressEvent) -&gt; bool:\n        \"\"\"Determine if event requires immediate display update\"\"\"\n        important_events = {\n            'execution_start', 'execution_complete',\n            'outline_created', 'plan_created',\n            'error', 'task_error'\n        }\n        return event.event_type in important_events or event.success is False\n\n    def _update_display(self):\n        \"\"\"Update the display using dual-track renderer\"\"\"\n        try:\n            self._print_counter += 1\n            self.display_renderer.render_dual_track_display(self.event_processor)\n            self._consecutive_errors = 0  # Reset error counter on success\n\n        except Exception as e:\n            self._consecutive_errors += 1\n            print(f\"\u26a0\ufe0f Display update error: {e}\")\n\n    def print_execution_summary(self):\n        \"\"\"Print comprehensive execution summary\"\"\"\n        try:\n            summary = self.event_processor.get_progress_summary()\n\n            if not self.use_rich:\n                self._print_summary_fallback(summary)\n                return\n\n            self.display_renderer.console.print()\n            self.display_renderer.console.print(\"\ud83c\udf89 [bold green]EXECUTION SUMMARY[/bold green] \ud83c\udf89\")\n\n            # Final status display\n            self.display_renderer.render_dual_track_display(self.event_processor)\n\n            # Detailed metrics table\n            self._print_detailed_metrics_table(summary)\n\n        except Exception as e:\n            print(f\"\u26a0\ufe0f Error printing execution summary: {e}\")\n            self._print_summary_fallback(self.event_processor.get_progress_summary())\n\n    def _print_detailed_metrics_table(self, summary: dict[str, Any]):\n        \"\"\"Print detailed metrics table\"\"\"\n        if not self.use_rich:\n            return\n\n        table = Table(title=\"\ud83d\udcca Execution Metrics\", box=box.ROUNDED)\n        table.add_column(\"Category\", style=\"cyan\")\n        table.add_column(\"Metric\", style=\"white\")\n        table.add_column(\"Value\", style=\"green\")\n\n        # Progress track metrics\n        semantic = summary['dual_track_state']['semantic_progress']\n        table.add_row(\"Progress\", \"Execution Phase\", semantic['execution_phase'].title())\n        table.add_row(\"\", \"Outline Steps\",\n                      f\"{len(semantic['outline_progress']['completed_steps'])}/{semantic['outline_progress']['total_steps']}\")\n        table.add_row(\"\", \"Reasoning Loops\", str(semantic['current_reasoning_loop']))\n\n        # System track metrics\n        system = summary['dual_track_state']['system_state']\n        table.add_row(\"System\", \"Node Flow Length\", str(len(system['node_flow'])))\n        table.add_row(\"\", \"System Health\", system['system_health']['status'].title())\n        table.add_row(\"\", \"Error Count\", str(system['system_health']['error_count']))\n\n        # Execution metrics\n        metrics = summary['execution_metrics']\n        table.add_row(\"Performance\", \"Total Events\", str(metrics['total_events']))\n        table.add_row(\"\", \"Runtime\", f\"{metrics['elapsed_time']:.2f}s\")\n        table.add_row(\"\", \"Events/sec\", f\"{metrics['events_per_second']:.1f}\")\n\n        # LLM metrics\n        llm = semantic['llm_interactions']\n        if llm['total_calls'] &gt; 0:\n            table.add_row(\"LLM\", \"Total Calls\", str(llm['total_calls']))\n            if llm['total_cost'] &gt; 0:\n                table.add_row(\"\", \"Total Cost\", f\"${llm['total_cost']:.4f}\")\n            if llm['total_tokens'] &gt; 0:\n                table.add_row(\"\", \"Total Tokens\", f\"{llm['total_tokens']:,}\")\n\n        self.display_renderer.console.print()\n        self.display_renderer.console.print(table)\n\n    def _print_summary_fallback(self, summary: dict[str, Any]):\n        \"\"\"Fallback summary without Rich\"\"\"\n        activity = summary['current_activity']\n        metrics = summary['execution_metrics']\n        semantic = summary['dual_track_state']['semantic_progress']\n\n        print(f\"\\n{'=' * 60}\")\n        print(\"\ud83c\udf89 EXECUTION SUMMARY\")\n        print(f\"{'=' * 60}\")\n        print(f\"Agent: {self.agent_name}\")\n        print(f\"Session: {self.session_id or 'N/A'}\")\n        print(f\"Final Phase: {activity['execution_phase'].title()}\")\n\n        if semantic['outline_progress']['total_steps'] &gt; 0:\n            completed_steps = len(semantic['outline_progress']['completed_steps'])\n            total_steps = semantic['outline_progress']['total_steps']\n            print(\n                f\"Outline Progress: {completed_steps}/{total_steps} steps ({activity['outline_completion_percent']:.1f}%)\")\n\n        print(f\"Total Runtime: {metrics['elapsed_time']:.2f}s\")\n        print(f\"Total Events: {metrics['total_events']}\")\n        print(f\"Processing Rate: {metrics['events_per_second']:.1f} events/sec\")\n        print(f\"System Health: {activity['system_health_status'].title()}\")\n\n        if metrics['error_rate'] &gt; 0:\n            print(f\"Error Rate: {metrics['error_rate']:.2%}\")\n\n        llm = semantic['llm_interactions']\n        if llm['total_calls'] &gt; 0:\n            print(f\"LLM Calls: {llm['total_calls']}\")\n            if llm['total_cost'] &gt; 0:\n                print(f\"LLM Cost: ${llm['total_cost']:.4f}\")\n\n        print(f\"{'=' * 60}\")\n\n    # [Keep all the existing methods that were listed as \"methods to keep\"]\n    # flush, get_accumulated_summary, export_accumulated_data, etc.\n\n    async def _noop_callback(self, event: ProgressEvent):\n        \"\"\"No-op callback when printing is disabled\"\"\"\n        pass\n\n    def get_current_execution_state(self) -&gt; dict[str, Any]:\n        \"\"\"Get current execution state for external monitoring\"\"\"\n        return self.event_processor.get_progress_summary()\n\n    def force_display_update(self):\n        \"\"\"Force an immediate display update\"\"\"\n        self._update_display()\n\n    def set_display_mode(self, mode: VerbosityMode):\n        \"\"\"Change display mode at runtime\"\"\"\n        self.mode = mode\n        self.display_renderer = EnhancedDisplayRenderer(mode, self.use_rich)\n        self._display_interval = self._get_display_interval()\n</code></pre> <code>export_accumulated_data(filepath=None, extra_data=None)</code> \u00b6 <p>Export all accumulated run data to file with dual-track information</p> Source code in <code>toolboxv2/mods/isaa/extras/terminal_progress.py</code> <pre><code>def export_accumulated_data(self, filepath: str = None, extra_data: dict[str, Any] = None) -&gt; str:\n    \"\"\"Export all accumulated run data to file with dual-track information\"\"\"\n    try:\n        if filepath is None:\n            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n            filepath = f\"accumulated_execution_data_{timestamp}.json\"\n\n        export_data = {\n            \"export_timestamp\": time.time(),\n            \"export_version\": \"2.0\",  # Updated version for dual-track\n            \"printer_config\": {\n                \"mode\": self.mode.value,\n                \"use_rich\": self.use_rich,\n                \"agent_name\": self.agent_name\n            },\n            \"accumulated_summary\": self.get_accumulated_summary(),\n            \"all_runs\": self._accumulated_runs,\n            \"dual_track_metadata\": {\n                \"total_semantic_events\": sum(\n                    len(run.get('execution_events', [])) for run in self._accumulated_runs\n                ),\n                \"total_system_nodes\": sum(\n                    len(run.get('system_state', {}).get('node_flow', [])) for run in self._accumulated_runs\n                ),\n                \"export_features\": [\"dual_track_processing\", \"semantic_progress\", \"system_state\"]\n            }\n        }\n\n        export_data.update(extra_data or {})\n\n        import json\n        with open(filepath, 'w') as f:\n            json.dump(export_data, f, indent=2, default=str)\n\n        if self.use_rich:\n            self.console.print(f\"\ud83d\udcc1 Accumulated data exported to: {filepath}\", style=\"green bold\")\n            self.console.print(f\"\ud83d\udcca Total runs exported: {len(self._accumulated_runs)}\", style=\"blue\")\n        else:\n            print(f\"\ud83d\udcc1 Accumulated data exported to: {filepath}\")\n            print(f\"\ud83d\udcca Total runs exported: {len(self._accumulated_runs)}\")\n\n        return filepath\n\n    except Exception as e:\n        error_msg = f\"\u274c Error exporting accumulated data: {e}\"\n        if self.use_rich:\n            self.console.print(error_msg, style=\"red bold\")\n        else:\n            print(error_msg)\n        return \"\"\n</code></pre> <code>flush(run_name=None)</code> \u00b6 <p>Enhanced flush with dual-track state management</p> Source code in <code>toolboxv2/mods/isaa/extras/terminal_progress.py</code> <pre><code>def flush(self, run_name: str = None) -&gt; dict[str, Any]:\n    \"\"\"Enhanced flush with dual-track state management\"\"\"\n    try:\n        current_time = time.time()\n        if run_name is None:\n            run_name = f\"run_{self._current_run_id + 1}\"\n\n        # Generate comprehensive run data using dual-track system\n        summary = self.event_processor.get_progress_summary()\n\n        # Create comprehensive run data\n        run_data = {\n            \"run_id\": self._current_run_id + 1,\n            \"run_name\": run_name,\n            \"flush_timestamp\": current_time,\n            \"dual_track_summary\": summary,\n            \"execution_events\": self.event_processor.event_history.copy(),\n            \"semantic_progress\": summary['dual_track_state']['semantic_progress'].copy(),\n            \"system_state\": summary['dual_track_state']['system_state'].copy(),\n            \"execution_metrics\": summary['execution_metrics'].copy(),\n            \"current_activity\": summary['current_activity'].copy(),\n            \"print_counter\": self._print_counter,\n            \"agent_name\": self.agent_name,\n            \"session_id\": self.session_id\n        }\n\n        # Add detailed execution flow analysis\n        run_data[\"execution_analysis\"] = {\n            \"outline_completion_rate\": summary['current_activity']['outline_completion_percent'] / 100,\n            \"reasoning_loops_count\": summary['current_activity']['active_reasoning_loop'],\n            \"system_node_count\": len(summary['dual_track_state']['system_state']['node_flow']),\n            \"error_density\": summary['execution_metrics']['error_rate'],\n            \"processing_efficiency\": summary['execution_metrics']['events_per_second']\n        }\n\n        # Store in accumulated runs\n        self._accumulated_runs.append(run_data)\n\n        # Reset for fresh execution\n        self._reset_for_fresh_execution()\n\n        if self.use_rich:\n            self.console.print(f\"\u2705 Run '{run_name}' flushed and stored\", style=\"green bold\")\n            self.console.print(f\"\ud83d\udcca Total accumulated runs: {len(self._accumulated_runs)}\", style=\"blue\")\n        else:\n            print(f\"\u2705 Run '{run_name}' flushed and stored\")\n            print(f\"\ud83d\udcca Total accumulated runs: {len(self._accumulated_runs)}\")\n\n        return run_data\n\n    except Exception as e:\n        error_msg = f\"\u274c Error during flush: {e}\"\n        if self.use_rich:\n            self.console.print(error_msg, style=\"red bold\")\n        else:\n            print(error_msg)\n\n        # Still try to reset for fresh execution\n        self._reset_for_fresh_execution()\n        return {\"error\": str(e), \"timestamp\": current_time}\n</code></pre> <code>force_display_update()</code> \u00b6 <p>Force an immediate display update</p> Source code in <code>toolboxv2/mods/isaa/extras/terminal_progress.py</code> <pre><code>def force_display_update(self):\n    \"\"\"Force an immediate display update\"\"\"\n    self._update_display()\n</code></pre> <code>get_accumulated_summary()</code> \u00b6 <p>Get comprehensive summary of all accumulated runs with dual-track metrics</p> Source code in <code>toolboxv2/mods/isaa/extras/terminal_progress.py</code> <pre><code>def get_accumulated_summary(self) -&gt; dict[str, Any]:\n    \"\"\"Get comprehensive summary of all accumulated runs with dual-track metrics\"\"\"\n    try:\n        if not self._accumulated_runs:\n            return {\n                \"total_runs\": 0,\n                \"message\": \"No runs have been flushed yet\"\n            }\n\n        # Calculate aggregate metrics\n        total_cost = 0.0\n        total_tokens = 0\n        total_events = 0\n        total_errors = 0\n        total_duration = 0.0\n        total_outline_steps = 0\n        total_reasoning_loops = 0\n\n        run_summaries = []\n\n        for run in self._accumulated_runs:\n            # Handle both old and new run data formats\n            if 'dual_track_summary' in run:\n                # New dual-track format\n                summary = run['dual_track_summary']\n                semantic = summary['dual_track_state']['semantic_progress']\n                metrics = summary['execution_metrics']\n\n                total_cost += semantic['llm_interactions']['total_cost']\n                total_tokens += semantic['llm_interactions']['total_tokens']\n                total_events += metrics['total_events']\n                total_errors += summary['dual_track_state']['system_state']['system_health']['error_count']\n                total_duration += metrics['elapsed_time']\n                total_outline_steps += semantic['outline_progress']['total_steps']\n                total_reasoning_loops += semantic['current_reasoning_loop']\n\n                run_summaries.append({\n                    \"run_id\": run[\"run_id\"],\n                    \"run_name\": run[\"run_name\"],\n                    \"duration\": metrics['elapsed_time'],\n                    \"events\": metrics['total_events'],\n                    \"cost\": semantic['llm_interactions']['total_cost'],\n                    \"tokens\": semantic['llm_interactions']['total_tokens'],\n                    \"errors\": summary['dual_track_state']['system_state']['system_health']['error_count'],\n                    \"outline_completion\": summary['current_activity']['outline_completion_percent'],\n                    \"reasoning_loops\": semantic['current_reasoning_loop'],\n                    \"system_health\": summary['current_activity']['system_health_status']\n                })\n            else:\n                # Fallback for old format\n                exec_summary = run.get(\"execution_summary\", {})\n                perf = exec_summary.get(\"performance_metrics\", {})\n                timing = exec_summary.get(\"timing\", {})\n\n                total_cost += perf.get(\"total_cost\", 0)\n                total_tokens += perf.get(\"total_tokens\", 0)\n                total_events += perf.get(\"total_events\", 0)\n                total_errors += perf.get(\"error_count\", 0)\n                total_duration += timing.get(\"elapsed\", 0)\n\n                run_summaries.append({\n                    \"run_id\": run[\"run_id\"],\n                    \"run_name\": run[\"run_name\"],\n                    \"duration\": timing.get(\"elapsed\", 0),\n                    \"events\": perf.get(\"total_events\", 0),\n                    \"cost\": perf.get(\"total_cost\", 0),\n                    \"tokens\": perf.get(\"total_tokens\", 0),\n                    \"errors\": perf.get(\"error_count\", 0),\n                    \"outline_completion\": 0,  # Not available in old format\n                    \"reasoning_loops\": 0,  # Not available in old format\n                    \"system_health\": \"unknown\"\n                })\n\n        # Calculate averages\n        num_runs = len(self._accumulated_runs)\n        avg_duration = total_duration / num_runs\n        avg_cost = total_cost / num_runs\n        avg_tokens = total_tokens / num_runs\n        avg_events = total_events / num_runs\n\n        return {\n            \"total_runs\": num_runs,\n            \"current_run_id\": self._current_run_id,\n            \"global_start_time\": self._global_start_time,\n            \"total_accumulated_time\": time.time() - self._global_start_time,\n\n            \"aggregate_metrics\": {\n                \"total_cost\": total_cost,\n                \"total_tokens\": total_tokens,\n                \"total_events\": total_events,\n                \"total_errors\": total_errors,\n                \"total_duration\": total_duration,\n                \"total_outline_steps\": total_outline_steps,\n                \"total_reasoning_loops\": total_reasoning_loops,\n            },\n\n            \"average_metrics\": {\n                \"avg_duration\": avg_duration,\n                \"avg_cost\": avg_cost,\n                \"avg_tokens\": avg_tokens,\n                \"avg_events\": avg_events,\n                \"avg_error_rate\": total_errors / max(total_events, 1),\n                \"avg_outline_completion\": sum(r.get(\"outline_completion\", 0) for r in run_summaries) / num_runs,\n                \"avg_reasoning_loops\": total_reasoning_loops / num_runs\n            },\n\n            \"run_summaries\": run_summaries,\n            \"performance_insights\": self._generate_accumulated_insights(run_summaries)\n        }\n\n    except Exception as e:\n        return {\"error\": f\"Error generating accumulated summary: {e}\"}\n</code></pre> <code>get_current_execution_state()</code> \u00b6 <p>Get current execution state for external monitoring</p> Source code in <code>toolboxv2/mods/isaa/extras/terminal_progress.py</code> <pre><code>def get_current_execution_state(self) -&gt; dict[str, Any]:\n    \"\"\"Get current execution state for external monitoring\"\"\"\n    return self.event_processor.get_progress_summary()\n</code></pre> <code>print_accumulated_summary()</code> \u00b6 <p>Print comprehensive summary of all accumulated runs</p> Source code in <code>toolboxv2/mods/isaa/extras/terminal_progress.py</code> <pre><code>def print_accumulated_summary(self):\n    \"\"\"Print comprehensive summary of all accumulated runs\"\"\"\n    try:\n        summary = self.get_accumulated_summary()\n\n        if summary.get(\"total_runs\", 0) == 0:\n            if self.use_rich:\n                self.console.print(\"\ud83d\udcca No accumulated runs to display\", style=\"yellow\")\n            else:\n                print(\"\ud83d\udcca No accumulated runs to display\")\n            return\n\n        if not self.use_rich:\n            self._print_accumulated_summary_fallback(summary)\n            return\n\n        # Rich formatted output\n        self.console.print()\n        self.console.print(\"\ud83d\uddc2\ufe0f [bold cyan]ACCUMULATED EXECUTION SUMMARY[/bold cyan] \ud83d\uddc2\ufe0f\")\n\n        # Overview table with dual-track metrics\n        overview_table = Table(title=\"\ud83d\udcca Aggregate Overview\", box=box.ROUNDED)\n        overview_table.add_column(\"Metric\", style=\"cyan\", min_width=25)\n        overview_table.add_column(\"Total\", style=\"green\", min_width=15)\n        overview_table.add_column(\"Average\", style=\"blue\", min_width=15)\n\n        agg = summary[\"aggregate_metrics\"]\n        avg = summary[\"average_metrics\"]\n\n        overview_table.add_row(\"Runs\", str(summary[\"total_runs\"]), \"\")\n        overview_table.add_row(\"Duration\", f\"{agg['total_duration']:.1f}s\", f\"{avg['avg_duration']:.1f}s\")\n        overview_table.add_row(\"Events\", str(agg[\"total_events\"]), f\"{avg['avg_events']:.1f}\")\n\n        if agg[\"total_cost\"] &gt; 0:\n            overview_table.add_row(\"Cost\", self._format_cost(agg[\"total_cost\"]), self._format_cost(avg[\"avg_cost\"]))\n\n        if agg[\"total_tokens\"] &gt; 0:\n            overview_table.add_row(\"Tokens\", f\"{agg['total_tokens']:,}\", f\"{avg['avg_tokens']:,.0f}\")\n\n        # Dual-track specific metrics\n        if agg.get(\"total_outline_steps\", 0) &gt; 0:\n            overview_table.add_row(\"Outline Steps\", str(agg[\"total_outline_steps\"]), \"\")\n            overview_table.add_row(\"Outline Completion\", \"\", f\"{avg['avg_outline_completion']:.1f}%\")\n\n        if agg.get(\"total_reasoning_loops\", 0) &gt; 0:\n            overview_table.add_row(\"Reasoning Loops\", str(agg[\"total_reasoning_loops\"]),\n                                   f\"{avg['avg_reasoning_loops']:.1f}\")\n\n        overview_table.add_row(\"Error Rate\", \"\", f\"{avg['avg_error_rate']:.1%}\")\n\n        self.console.print(overview_table)\n\n        # Individual runs table\n        runs_table = Table(title=\"\ud83c\udfc3 Individual Runs\", box=box.ROUNDED)\n        runs_table.add_column(\"Run\", style=\"cyan\")\n        runs_table.add_column(\"Duration\", style=\"blue\")\n        runs_table.add_column(\"Events\", style=\"green\")\n        runs_table.add_column(\"Cost\", style=\"yellow\")\n        runs_table.add_column(\"Outline\", style=\"magenta\")\n        runs_table.add_column(\"Health\", style=\"white\")\n\n        for run in summary[\"run_summaries\"]:\n            cost_str = self._format_cost(run[\"cost\"]) if run[\"cost\"] &gt; 0 else \"-\"\n            outline_str = f\"{run.get('outline_completion', 0):.0f}%\" if run.get('outline_completion') else \"N/A\"\n            health_str = run.get('system_health', 'unknown')\n\n            runs_table.add_row(\n                run[\"run_name\"],\n                f\"{run['duration']:.1f}s\",\n                str(run['events']),\n                cost_str,\n                outline_str,\n                health_str\n            )\n\n        self.console.print(runs_table)\n\n        # Insights\n        if summary.get(\"performance_insights\"):\n            insights_panel = Panel(\n                \"\\n\".join(f\"\u2022 {insight}\" for insight in summary[\"performance_insights\"]),\n                title=\"\ud83d\udd0d Performance Insights\",\n                style=\"yellow\"\n            )\n            self.console.print(insights_panel)\n\n    except Exception as e:\n        error_msg = f\"\u274c Error printing accumulated summary: {e}\"\n        if self.use_rich:\n            self.console.print(error_msg, style=\"red bold\")\n        else:\n            print(error_msg)\n</code></pre> <code>print_execution_summary()</code> \u00b6 <p>Print comprehensive execution summary</p> Source code in <code>toolboxv2/mods/isaa/extras/terminal_progress.py</code> <pre><code>def print_execution_summary(self):\n    \"\"\"Print comprehensive execution summary\"\"\"\n    try:\n        summary = self.event_processor.get_progress_summary()\n\n        if not self.use_rich:\n            self._print_summary_fallback(summary)\n            return\n\n        self.display_renderer.console.print()\n        self.display_renderer.console.print(\"\ud83c\udf89 [bold green]EXECUTION SUMMARY[/bold green] \ud83c\udf89\")\n\n        # Final status display\n        self.display_renderer.render_dual_track_display(self.event_processor)\n\n        # Detailed metrics table\n        self._print_detailed_metrics_table(summary)\n\n    except Exception as e:\n        print(f\"\u26a0\ufe0f Error printing execution summary: {e}\")\n        self._print_summary_fallback(self.event_processor.get_progress_summary())\n</code></pre> <code>print_final_summary()</code> \u00b6 <p>Print comprehensive final summary with dual-track analysis</p> Source code in <code>toolboxv2/mods/isaa/extras/terminal_progress.py</code> <pre><code>def print_final_summary(self):\n    \"\"\"Print comprehensive final summary with dual-track analysis\"\"\"\n    try:\n        if not self.use_rich:\n            self._print_summary_fallback(self.event_processor.get_progress_summary())\n            return\n\n        summary = self.event_processor.get_progress_summary()\n\n        # Clear display and show completion\n        self.console.print()\n        self.console.print(\"\ud83c\udf89 [bold green]EXECUTION COMPLETED[/bold green] \ud83c\udf89\")\n\n        # Final dual-track display\n        self.display_renderer.render_dual_track_display(self.event_processor)\n\n        # Comprehensive summary table\n        self._print_comprehensive_final_table(summary)\n\n        # Performance analysis\n        if self.mode in [VerbosityMode.VERBOSE, VerbosityMode.DEBUG]:\n            self._print_dual_track_performance_analysis(summary)\n\n    except Exception as e:\n        print(f\"\u26a0\ufe0f Error printing final summary: {e}\")\n        self._print_summary_fallback(self.event_processor.get_progress_summary())\n</code></pre> <code>progress_callback(event)</code> <code>async</code> \u00b6 <p>Enhanced progress callback with dual-track processing</p> Source code in <code>toolboxv2/mods/isaa/extras/terminal_progress.py</code> <pre><code>async def progress_callback(self, event: ProgressEvent):\n    \"\"\"Enhanced progress callback with dual-track processing\"\"\"\n    try:\n        # Update agent info\n        if event.agent_name:\n            self.agent_name = event.agent_name\n        if event.session_id:\n            self.session_id = event.session_id\n\n        # Process through dual-track system\n        self.event_processor.process_event(event)\n\n        # Update display if enough time has passed or important event\n        should_update = (\n            time.time() - self._last_display_time &gt;= self._display_interval or\n            self._is_important_event(event)\n        )\n\n        if should_update and self.auto_refresh:\n            self._update_display()\n            self._last_display_time = time.time()\n\n    except Exception as e:\n        self._consecutive_errors += 1\n        if self._consecutive_errors &lt;= self._error_threshold:\n            print(f\"\u26a0\ufe0f Progress callback error #{self._consecutive_errors}: {e}\")\n        if self._consecutive_errors &gt; self._error_threshold:\n            print(\"\ud83d\udea8 Progress printing disabled due to excessive errors\")\n            self.progress_callback = self._noop_callback\n</code></pre> <code>reset_global_start_time()</code> \u00b6 <p>Reset global start time for new session</p> Source code in <code>toolboxv2/mods/isaa/extras/terminal_progress.py</code> <pre><code>def reset_global_start_time(self):\n    \"\"\"Reset global start time for new session\"\"\"\n    self._global_start_time = time.time()\n</code></pre> <code>set_display_mode(mode)</code> \u00b6 <p>Change display mode at runtime</p> Source code in <code>toolboxv2/mods/isaa/extras/terminal_progress.py</code> <pre><code>def set_display_mode(self, mode: VerbosityMode):\n    \"\"\"Change display mode at runtime\"\"\"\n    self.mode = mode\n    self.display_renderer = EnhancedDisplayRenderer(mode, self.use_rich)\n    self._display_interval = self._get_display_interval()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.terminal_progress.create_complex_scenario","title":"<code>create_complex_scenario()</code>  <code>async</code>","text":"<p>Create a complex scenario with multiple nodes and error recovery</p> Source code in <code>toolboxv2/mods/isaa/extras/terminal_progress.py</code> <pre><code>async def create_complex_scenario():\n    \"\"\"Create a complex scenario with multiple nodes and error recovery\"\"\"\n    base_time = time.time()\n    events = []\n\n    nodes = [\n        \"FlowAgent\",\n        \"StrategyOrchestratorNode\",\n        \"TaskPlannerFlow\",\n        \"ResearchNode\",\n        \"AnalysisNode\",\n        \"ValidationNode\",\n        \"ResponseGeneratorNode\"\n    ]\n\n    # Start execution\n    events.append(ProgressEvent(\n        event_type=\"execution_start\",\n        timestamp=base_time,\n        node_name=\"FlowAgent\",\n        session_id=f\"complex_session_{int(base_time)}\",\n        metadata={\"complexity\": \"high\", \"estimated_duration\": 25}\n    ))\n\n    current_time = base_time\n\n    for i, node in enumerate(nodes[1:], 1):\n        # Node entry\n        current_time += 0.5\n        events.append(ProgressEvent(\n            event_type=\"node_enter\",\n            timestamp=current_time,\n            node_name=node\n        ))\n\n        # Main operation (LLM or tool call)\n        current_time += 1.2\n        if i % 3 == 0:  # Tool call\n            success = i != 5  # Fail on ValidationNode\n            events.append(ProgressEvent(\n                event_type=\"tool_call\",\n                timestamp=current_time,\n                node_name=node,\n                tool_name=f\"tool_{i}\",\n                tool_duration=1.8,\n                tool_success=success,\n                tool_result=f\"Tool result {i}\" if success else None,\n                tool_error=f\"Tool error {i}\" if not success else None,\n                success=success,\n                metadata={\"error\": \"Validation failed\", \"error_type\": \"ValidationError\"} if not success else {}\n            ))\n\n            # Recovery if failed\n            if not success:\n                current_time += 2.0\n                events.append(ProgressEvent(\n                    event_type=\"tool_call\",\n                    timestamp=current_time,\n                    node_name=node,\n                    tool_name=\"recovery_tool\",\n                    tool_duration=1.5,\n                    tool_success=True,\n                    tool_result=\"Recovery successful\"\n                ))\n        else:  # LLM call\n            events.append(ProgressEvent(\n                event_type=\"llm_call\",\n                timestamp=current_time,\n                node_name=node,\n                llm_model=\"gpt-4\" if i % 2 == 0 else \"gpt-3.5-turbo\",\n                llm_total_tokens=1200 + i * 200,\n                llm_cost=0.024 + i * 0.005,\n                duration=1.5 + i * 0.3,\n                success=True\n            ))\n\n        # Node completion\n        current_time += 0.8\n        if node.endswith(\"Node\"):  # Simple nodes auto-complete\n            events.append(ProgressEvent(\n                event_type=\"node_phase\",\n                timestamp=current_time,\n                node_name=node,\n                success=True,\n                node_duration=current_time - (base_time + i * 2.5)\n            ))\n\n    # Final completion\n    events.append(ProgressEvent(\n        event_type=\"execution_complete\",\n        timestamp=current_time + 1.0,\n        node_name=\"FlowAgent\",\n        node_duration=current_time + 1.0 - base_time,\n        status=NodeStatus.COMPLETED,\n        success=True,\n        metadata={\"total_cost\": 0.156, \"total_tokens\": 12500}\n    ))\n\n    return events\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.terminal_progress.create_demo_scenario","title":"<code>create_demo_scenario(run_name='Demo Run', duration=10.0, cost=0.025, should_fail=False)</code>  <code>async</code>","text":"<p>Create a demo scenario with configurable parameters</p> Source code in <code>toolboxv2/mods/isaa/extras/terminal_progress.py</code> <pre><code>async def create_demo_scenario(run_name=\"Demo Run\", duration=10.0, cost=0.025, should_fail=False):\n    \"\"\"Create a demo scenario with configurable parameters\"\"\"\n    base_time = time.time()\n    events = []\n\n    # Execution start\n    events.append(ProgressEvent(\n        event_type=\"execution_start\",\n        timestamp=base_time,\n        node_name=\"FlowAgent\",\n        session_id=f\"demo_session_{int(base_time)}\",\n        metadata={\"query\": f\"Execute {run_name}\", \"user_id\": \"demo_user\"}\n    ))\n\n    # Strategy orchestrator\n    events.append(ProgressEvent(\n        event_type=\"node_enter\",\n        timestamp=base_time + 0.1,\n        node_name=\"StrategyOrchestratorNode\"\n    ))\n\n    events.append(ProgressEvent(\n        event_type=\"llm_call\",\n        timestamp=base_time + 1.2,\n        node_name=\"StrategyOrchestratorNode\",\n        llm_model=\"gpt-4\",\n        llm_total_tokens=1200,\n        llm_cost=cost * 0.4,\n        duration=1.1,\n        success=True,\n        metadata={\"strategy\": \"research_and_analyze\"}\n    ))\n\n    # Planning\n    events.append(ProgressEvent(\n        event_type=\"node_enter\",\n        timestamp=base_time + 2.5,\n        node_name=\"PlannerNode\"\n    ))\n\n    events.append(ProgressEvent(\n        event_type=\"llm_call\",\n        timestamp=base_time + 3.8,\n        node_name=\"PlannerNode\",\n        llm_model=\"gpt-3.5-turbo\",\n        llm_total_tokens=800,\n        llm_cost=cost * 0.2,\n        duration=1.3,\n        success=True\n    ))\n    # TaskPlan\n    events.append(ProgressEvent(\n        event_type=\"plan_created\",\n        timestamp=base_time + 4.0,\n        node_name=\"PlannerNode\",\n        status=NodeStatus.COMPLETED,\n        success=True,\n        metadata={\"plan_name\": \"Demo Plan\", \"task_count\": 3, \"full_plan\": TaskPlan(id='bf5053ad-1eae-4dd2-9c08-0c7fab49f80d', name='File Cleanup Task', description='Remove turtle_on_bike.py and execution_summary.json if they exist', tasks=[LLMTask(id='analyze_files', type='LLMTask', description='Analyze the current directory for turtle_on_bike.py and execution_summary.json', status='pending', priority=1, dependencies=[], subtasks=[], result=None, error=None, created_at=datetime(2025, 8, 13, 23, 51, 38, 726320), started_at=None, completed_at=None, metadata={}),ToolTask(id='remove_files', type='ToolTask', description='Delete turtle_on_bike.py and execution_summary.json using shell command', status='pending', priority=1, dependencies=[], subtasks=[], result=None, error=None, created_at=datetime(2025, 8, 13, 23, 51, 38, 726320), started_at=None, completed_at=None, metadata={}, retry_count=0, max_retries=3, critical=False, tool_name='shell', arguments={'command': \"Remove-Item -Path 'turtle_on_bike.py', 'execution_summary.json' -ErrorAction SilentlyContinue\"}, hypothesis='', validation_criteria='', expectation='')], status='created', created_at=datetime(2025, 8, 13, 23, 51, 38, 726320), metadata={}, execution_strategy='sequential')}\n    ))\n\n    # Execution with tools\n    events.append(ProgressEvent(\n        event_type=\"node_enter\",\n        timestamp=base_time + 5.0,\n        node_name=\"ExecutorNode\"\n    ))\n\n    events.append(ProgressEvent(\n        event_type=\"tool_call\",\n        timestamp=base_time + 6.2,\n        node_name=\"ExecutorNode\",\n        tool_name=\"web_search\",\n        duration=2.1,\n        success=not should_fail,\n        tool_result=\"Search completed\" if not should_fail else None,\n        tool_error=\"Search failed\" if should_fail else None,\n        metadata={\"error\": \"Search API timeout\"} if should_fail else {}\n    ))\n\n    if not should_fail:\n        # Analysis\n        events.append(ProgressEvent(\n            event_type=\"llm_call\",\n            timestamp=base_time + 8.5,\n            node_name=\"AnalysisNode\",\n            llm_model=\"gpt-4\",\n            llm_total_tokens=1500,\n            llm_cost=cost * 0.4,\n            duration=2.3,\n            success=True\n        ))\n\n        # Completion\n        events.append(ProgressEvent(\n            event_type=\"execution_complete\",\n            timestamp=base_time + duration,\n            node_name=\"FlowAgent\",\n            node_duration=duration,\n            status=NodeStatus.COMPLETED,\n            success=True,\n            metadata={\"result\": \"Successfully completed\"}\n        ))\n    else:\n        # Failed completion\n        events.append(ProgressEvent(\n            event_type=\"error\",\n            timestamp=base_time + duration * 0.7,\n            node_name=\"ExecutorNode\",\n            status=NodeStatus.FAILED,\n            success=False,\n            metadata={\n                \"error\": \"Execution failed due to tool error\",\n                \"error_type\": \"ToolError\"\n            }\n        ))\n\n    return events\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.terminal_progress.demo_accumulated_runs","title":"<code>demo_accumulated_runs()</code>  <code>async</code>","text":"<p>Demo accumulated runs functionality</p> Source code in <code>toolboxv2/mods/isaa/extras/terminal_progress.py</code> <pre><code>async def demo_accumulated_runs():\n    \"\"\"Demo accumulated runs functionality\"\"\"\n    print(\"\\n\ud83d\udcca ACCUMULATED RUNS DEMONSTRATION\")\n    print(\"=\" * 50)\n    print(\"This demo shows how multiple execution runs are accumulated and analyzed\")\n\n    printer = ProgressiveTreePrinter(mode=VerbosityMode.STANDARD)\n\n    # Simulate 3 different runs\n    runs = [\n        (\"Market Analysis\", \"research_and_analyze\", True, 12.5, 0.045),\n        (\"Content Creation\", \"creative_generation\", True, 8.2, 0.032),\n        (\"Problem Solving\", \"problem_solving\", False, 15.8, 0.067)  # This one fails\n    ]\n\n    for i, (run_name, strategy, success, duration, cost) in enumerate(runs):\n        print(f\"\\n\ud83c\udfc3 Running execution {i + 1}/3: {run_name}\")\n\n        # Strategy selection\n        printer.print_strategy_selection(strategy)\n        await asyncio.sleep(1)\n\n        # Quick execution simulation\n        events = await create_demo_scenario(\n            run_name=run_name,\n            duration=duration,\n            cost=cost,\n            should_fail=not success\n        )\n\n        for event in events:\n            await printer.progress_callback(event)\n            await asyncio.sleep(0.2)  # Fast execution\n\n        # Flush the run\n        printer.flush(run_name)\n        await asyncio.sleep(2)\n\n    # Show accumulated summary\n    print(\"\\n\ud83d\udcc8 ACCUMULATED SUMMARY:\")\n    printer.print_accumulated_summary()\n\n    # Export data\n    if input(\"\\n\ud83d\udcbe Export accumulated data? (y/n): \").lower().startswith('y'):\n        filepath = printer.export_accumulated_data()\n        print(f\"\u2705 Data exported to: {filepath}\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.terminal_progress.demo_all_modes","title":"<code>demo_all_modes()</code>  <code>async</code>","text":"<p>Demo all verbosity modes with the same scenario</p> Source code in <code>toolboxv2/mods/isaa/extras/terminal_progress.py</code> <pre><code>async def demo_all_modes():\n    \"\"\"Demo all verbosity modes with the same scenario\"\"\"\n    print(\"\\n\ud83c\udfad ALL MODES DEMONSTRATION\")\n    print(\"=\" * 50)\n    print(\"This demo will run the same scenario in all verbosity modes\")\n    print(\"to show the differences in output detail.\")\n\n    modes = [\n        (VerbosityMode.MINIMAL, \"MINIMAL - Only major updates\"),\n        (VerbosityMode.STANDARD, \"STANDARD - Regular updates with panels\"),\n        (VerbosityMode.VERBOSE, \"VERBOSE - Detailed information with metrics\"),\n        (VerbosityMode.DEBUG, \"DEBUG - Full debugging info with all details\"),\n        (VerbosityMode.REALTIME, \"REALTIME - Live updates (will show final tree)\")\n    ]\n\n    for mode, description in modes:\n        print(f\"\\n{'=' * 60}\")\n        print(f\"\ud83c\udfaf NOW DEMONSTRATING: {description}\")\n        print(f\"{'=' * 60}\")\n\n        await asyncio.sleep(2)\n\n        printer = ProgressiveTreePrinter(mode=mode, realtime_minimal=False)\n\n        await asyncio.sleep(1)\n\n        # Run scenario\n        events = await create_demo_scenario()\n\n        for event in events:\n            await printer.progress_callback(event)\n            if mode == VerbosityMode.REALTIME:\n                await asyncio.sleep(0.5)\n            else:\n                await asyncio.sleep(0.3)\n\n        # Final summary\n        printer.print_final_summary()\n\n        if mode != modes[-1][0]:  # Not the last mode\n            input(\"\\n\u23f8\ufe0f  Press Enter to continue to next mode...\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.terminal_progress.demo_complete_features","title":"<code>demo_complete_features()</code>  <code>async</code>","text":"<p>Complete feature demonstration</p> Source code in <code>toolboxv2/mods/isaa/extras/terminal_progress.py</code> <pre><code>async def demo_complete_features():\n    \"\"\"Complete feature demonstration\"\"\"\n    print(\"\\n\ud83d\ude80 COMPLETE FEATURE DEMONSTRATION\")\n    print(\"=\" * 50)\n    print(\"This demo showcases all features in a comprehensive scenario\")\n\n    # Start with verbose mode\n    printer = ProgressiveTreePrinter(mode=VerbosityMode.VERBOSE)\n\n    print(\"\\n1\ufe0f\u20e3 STRATEGY SELECTION SHOWCASE:\")\n    strategies = [\"direct_response\", \"research_and_analyze\", \"problem_solving\"]\n    for strategy in strategies:\n        printer.print_strategy_selection(strategy, context={\n            \"reasoning\": f\"Demonstrating {strategy} strategy selection\",\n            \"complexity_score\": 0.6,\n            \"estimated_steps\": 4\n        })\n        await asyncio.sleep(1)\n\n    print(\"\\n2\ufe0f\u20e3 COMPLEX EXECUTION WITH ERRORS:\")\n    # Complex scenario with multiple nodes, errors, and recovery\n    complex_events = await create_complex_scenario()\n\n    for event in complex_events:\n        await printer.progress_callback(event)\n        await asyncio.sleep(0.4)\n\n    printer.print_final_summary()\n\n    print(\"\\n3\ufe0f\u20e3 MODE COMPARISON:\")\n    print(\"Switching to REALTIME mode for live demo...\")\n    await asyncio.sleep(2)\n\n    # Switch to realtime mode\n    realtime_printer = ProgressiveTreePrinter(\n        mode=VerbosityMode.REALTIME,\n        realtime_minimal=True\n    )\n\n    print(\"Running same scenario in REALTIME minimal mode:\")\n    simple_events = await create_demo_scenario()\n\n    for event in simple_events:\n        await realtime_printer.progress_callback(event)\n        await asyncio.sleep(0.3)\n\n    print(\"\\n\\n4\ufe0f\u20e3 ACCUMULATED ANALYTICS:\")\n    # Flush both runs\n    printer.flush(\"Complex Execution\")\n    realtime_printer.flush(\"Realtime Execution\")\n\n    # Transfer accumulated data to one printer for summary\n    printer._accumulated_runs.extend(realtime_printer._accumulated_runs)\n    printer.print_accumulated_summary()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.terminal_progress.demo_enhanced_printer","title":"<code>demo_enhanced_printer()</code>  <code>async</code>","text":"<p>Comprehensive demo of the enhanced progress printer showcasing all modes</p> Source code in <code>toolboxv2/mods/isaa/extras/terminal_progress.py</code> <pre><code>async def demo_enhanced_printer():\n    \"\"\"Comprehensive demo of the enhanced progress printer showcasing all modes\"\"\"\n\n    print(\"\ud83d\ude80 Starting Enhanced Progress Printer Demo...\")\n    print(\"Choose demo type:\")\n    print(\"1. All Modes Demo - Show all verbosity modes with same scenario\")\n    print(\"2. Interactive Mode Selection - Choose specific mode\")\n    print(\"3. Strategy Selection Demo - Show strategy printing\")\n    print(\"4. Accumulated Runs Demo - Show multi-run accumulation\")\n    print(\"5. Complete Feature Demo - All features in sequence\")\n    print(\"6. Exit\")\n\n    try:\n        choice = input(\"Enter choice (1-6) [default: 1]: \").strip() or \"1\"\n    except:\n        choice = \"1\"\n\n    if choice == \"6\":\n        return\n    elif choice == \"1\":\n        await demo_all_modes()\n    elif choice == \"2\":\n        await demo_interactive_mode()\n    elif choice == \"3\":\n        await demo_strategy_selection()\n    elif choice == \"4\":\n        await demo_accumulated_runs()\n    elif choice == \"5\":\n        await demo_complete_features()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.terminal_progress.demo_interactive_mode","title":"<code>demo_interactive_mode()</code>  <code>async</code>","text":"<p>Interactive mode selection demo</p> Source code in <code>toolboxv2/mods/isaa/extras/terminal_progress.py</code> <pre><code>async def demo_interactive_mode():\n    \"\"\"Interactive mode selection demo\"\"\"\n    print(\"\\n\ud83c\udfae INTERACTIVE MODE SELECTION\")\n    print(\"Choose your preferred verbosity mode:\")\n    print(\"1. MINIMAL - Only major updates\")\n    print(\"2. STANDARD - Regular updates\")\n    print(\"3. VERBOSE - Detailed information\")\n    print(\"4. DEBUG - Full debugging info\")\n    print(\"5. REALTIME - Live updates\")\n\n    try:\n        choice = input(\"Enter choice (1-5) [default: 2]: \").strip() or \"2\"\n        modes = {\n            \"1\": VerbosityMode.MINIMAL,\n            \"2\": VerbosityMode.STANDARD,\n            \"3\": VerbosityMode.VERBOSE,\n            \"4\": VerbosityMode.DEBUG,\n            \"5\": VerbosityMode.REALTIME\n        }\n        mode = modes.get(choice, VerbosityMode.STANDARD)\n    except:\n        mode = VerbosityMode.STANDARD\n\n    printer = ProgressiveTreePrinter(mode=mode)\n    print(f\"\\n\ud83c\udfaf Running demo in {mode.value.upper()} mode...\")\n\n    # Strategy selection\n    printer.print_strategy_selection(\"slow_complex_planning\", context={\n        \"reasoning\": \"Task has multiple 'and' conditions requiring complex breakdown\",\n        \"complexity_score\": 0.9,\n        \"estimated_steps\": 8\n    })\n\n    await asyncio.sleep(1)\n\n    events = await create_demo_scenario()\n    for event in events:\n        await printer.progress_callback(event)\n        await asyncio.sleep(0.5 if mode == VerbosityMode.REALTIME else 0.8)\n\n    printer.print_final_summary()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.terminal_progress.demo_strategy_selection","title":"<code>demo_strategy_selection()</code>  <code>async</code>","text":"<p>Demo all strategy selection options</p> Source code in <code>toolboxv2/mods/isaa/extras/terminal_progress.py</code> <pre><code>async def demo_strategy_selection():\n    \"\"\"Demo all strategy selection options\"\"\"\n    print(\"\\n\ud83c\udfaf STRATEGY SELECTION DEMONSTRATION\")\n    print(\"=\" * 50)\n\n    strategies = [\n        (\"direct_response\", \"Simple question that needs direct answer\"),\n        (\"fast_simple_planning\", \"Task needs quick multi-step approach\"),\n        (\"slow_complex_planning\", \"Complex task with multiple 'and' conditions\"),\n        (\"research_and_analyze\", \"Needs information gathering and analysis\"),\n        (\"creative_generation\", \"Content creation with personalization\"),\n        (\"problem_solving\", \"Analysis with validation required\")\n    ]\n\n    for mode in [VerbosityMode.MINIMAL, VerbosityMode.STANDARD, VerbosityMode.VERBOSE]:\n        print(f\"\\n\ud83d\udd0d Strategy demo in {mode.value.upper()} mode:\")\n        print(\"-\" * 40)\n\n        printer = ProgressiveTreePrinter(mode=mode)\n\n        for strategy, reasoning in strategies:\n            complexity = 0.3 if \"simple\" in strategy else 0.7 if \"complex\" in strategy else 0.5\n\n            printer.print_strategy_selection(\n                strategy,\n                context={\n                    \"reasoning\": reasoning,\n                    \"complexity_score\": complexity,\n                    \"estimated_steps\": 1 if \"direct\" in strategy else 3 if \"fast\" in strategy else 6\n                }\n            )\n            await asyncio.sleep(0.8)\n\n        if mode != VerbosityMode.VERBOSE:\n            input(\"\\n\u23f8\ufe0f  Press Enter for next mode...\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.verbose_output","title":"<code>verbose_output</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.verbose_output.DynamicVerboseFormatter","title":"<code>DynamicVerboseFormatter</code>","text":"<p>Unified, dynamic formatter that adapts to screen size</p> Source code in <code>toolboxv2/mods/isaa/extras/verbose_output.py</code> <pre><code>class DynamicVerboseFormatter:\n    \"\"\"Unified, dynamic formatter that adapts to screen size\"\"\"\n\n    def __init__(self, print_func=None, min_width: int = 40, max_width: int = 240):\n        self.style = Style()\n        self.print = print_func or print\n        self.min_width = min_width\n        self.max_width = max_width\n        self._terminal_width = self._get_terminal_width()\n\n\n    def get_git_info(self):\n        \"\"\"Checks for a git repo and returns its name and branch, or None.\"\"\"\n        try:\n            # Check if we are in a git repository\n            subprocess.check_output(['git', 'rev-parse', '--is-inside-work-tree'], stderr=subprocess.DEVNULL)\n\n            # Get the repo name (root folder name)\n            repo_root = subprocess.check_output(['git', 'rev-parse', '--show-toplevel'],\n                                                stderr=subprocess.DEVNULL).strip().decode('utf-8')\n            repo_name = os.path.basename(repo_root)\n\n            # Get the current branch name\n            branch = subprocess.check_output(['git', 'rev-parse', '--abbrev-ref', 'HEAD'],\n                                             stderr=subprocess.DEVNULL).strip().decode('utf-8')\n\n            return repo_name, branch\n        except (subprocess.CalledProcessError, FileNotFoundError):\n            # This handles cases where 'git' is not installed or it's not a git repo\n            return None\n\n    def _get_terminal_width(self) -&gt; int:\n        \"\"\"Get current terminal width with fallback\"\"\"\n        try:\n            width = shutil.get_terminal_size().columns\n            return max(self.min_width, min(width - 2, self.max_width))\n        except (OSError, AttributeError):\n            return 80\n\n    def _wrap_text(self, text: str, width: int = None) -&gt; list[str]:\n        \"\"\"Wrap text to fit terminal width\"\"\"\n        if width is None:\n            width = self._terminal_width - 4  # Account for borders\n\n        words = text.split()\n        lines = []\n        current_line = []\n        current_length = 0\n\n        for word in words:\n            if current_length + len(word) + len(current_line) &lt;= width:\n                current_line.append(word)\n                current_length += len(word)\n            else:\n                if current_line:\n                    lines.append(' '.join(current_line))\n                current_line = [word]\n                current_length = len(word)\n\n        if current_line:\n            lines.append(' '.join(current_line))\n\n        return lines\n\n    def _create_border(self, char: str = \"\u2500\", width: int = None) -&gt; str:\n        \"\"\"Create a border line that fits the terminal\"\"\"\n        if width is None:\n            width = self._terminal_width\n        return char * width\n\n    def _center_text(self, text: str, width: int = None) -&gt; str:\n        \"\"\"Center text within the given width\"\"\"\n        if width is None:\n            width = self._terminal_width\n\n        # Remove ANSI codes for length calculation\n        clean_text = self._strip_ansi(text)\n        padding = max(0, (width - len(clean_text)) // 2)\n        return \" \" * padding + text\n\n    def _strip_ansi(self, text: str) -&gt; str:\n        \"\"\"Remove ANSI escape codes for length calculation\"\"\"\n        import re\n        ansi_escape = re.compile(r'\\x1B(?:[@-Z\\\\-_]|\\[[0-?]*[ -/]*[@-~])')\n        return ansi_escape.sub('', text)\n\n    def print_header(self, text: str):\n        \"\"\"Print a dynamic header that adapts to screen size\"\"\"\n        self._terminal_width = self._get_terminal_width()\n\n        if self._terminal_width &lt; 60:  # Tiny screen\n            self.print()\n            self.print(self.style.CYAN(\"=\" * self._terminal_width))\n            self.print(self.style.CYAN(self.style.Bold(text)))\n            self.print(self.style.CYAN(\"=\" * self._terminal_width))\n        else:  # Regular/large screen\n            border_width = min(len(text) + 2, self._terminal_width - 2)\n            border = \"\u2500\" * border_width\n\n            self.print()\n            self.print(self.style.CYAN(f\"\u250c{border}\u2510\"))\n            self.print(self.style.CYAN(f\"\u2502 {self.style.Bold(text).center(border_width - 2)} \u2502\"))\n            self.print(self.style.CYAN(f\"\u2514{border}\u2518\"))\n        self.print()\n\n    def print_section(self, title: str, content: str):\n        \"\"\"Print a clean section with adaptive formatting\"\"\"\n        self._terminal_width = self._get_terminal_width()\n\n        # Title\n        if self._terminal_width &lt; 60:\n            self.print(f\"\\n{self.style.BLUE('\u25cf')} {self.style.Bold(title)}\")\n        else:\n            self.print(f\"\\n{self.style.BLUE('\u25cf')} {self.style.Bold(self.style.BLUE(title))}\")\n\n        # Content with proper wrapping\n        for line in content.split('\\n'):\n            if line.strip():\n                wrapped_lines = self._wrap_text(line.strip())\n                for wrapped_line in wrapped_lines:\n                    if self._terminal_width &lt; 60:\n                        self.print(f\"  {wrapped_line}\")\n                    else:\n                        self.print(f\"  {self.style.GREY('\u2502')} {wrapped_line}\")\n        self.print()\n\n    def print_progress_bar(self, current: int, maximum: int, title: str = \"Progress\"):\n        \"\"\"Dynamic progress bar that adapts to screen size\"\"\"\n        self._terminal_width = self._get_terminal_width()\n\n        # Calculate bar width based on screen size\n        if self._terminal_width &lt; 60:\n            bar_width = 10\n            template = f\"\\r{title}: [{{}}] {current}/{maximum}\"\n        else:\n            bar_width = min(30, self._terminal_width - 30)\n            template = f\"\\r{self.style.CYAN(title)}: [{{}}] {current}/{maximum} ({current / maximum * 100:.1f}%)\"\n\n        progress = int((current / maximum) * bar_width)\n        bar = \"\u2588\" * progress + \"\u2591\" * (bar_width - progress)\n\n        self.print(template.format(bar), end='', flush=True)\n\n    def print_state(self, state: str, details: dict[str, Any] = None) -&gt; str:\n        \"\"\"Print current state with adaptive formatting\"\"\"\n        self._terminal_width = self._get_terminal_width()\n\n        state_colors = {\n            'ACTION': self.style.GREEN2,\n            'PROCESSING': self.style.YELLOW2,\n            'BRAKE': self.style.RED2,\n            'DONE': self.style.BLUE2,\n            'ERROR': self.style.RED,\n            'SUCCESS': self.style.GREEN,\n            'INFO': self.style.CYAN\n        }\n\n        color_func = state_colors.get(state.upper(), self.style.WHITE2)\n\n        if self._terminal_width &lt; 60:\n            # Compact format for small screens\n            self.print(f\"\\n[{color_func(state)}]\")\n            result = f\"\\n[{state}]\"\n        else:\n            # Full format for larger screens\n            self.print(f\"\\n{self.style.Bold('State:')} {color_func(state)}\")\n            result = f\"\\nState: {state}\"\n\n        if details:\n            for key, value in details.items():\n                # Truncate long values on small screens\n                if self._terminal_width &lt; 60 and len(str(value)) &gt; 30:\n                    display_value = str(value)[:27] + \"...\"\n                else:\n                    display_value = str(value)\n\n                if self._terminal_width &lt; 60:\n                    self.print(f\"  {key}: {display_value}\")\n                    result += f\"\\n  {key}: {display_value}\"\n                else:\n                    self.print(f\"  {self.style.GREY('\u251c\u2500')} {self.style.CYAN(key)}: {display_value}\")\n                    result += f\"\\n  \u251c\u2500 {key}: {display_value}\"\n\n        return result\n\n    def print_code_block(self, code: str, language: str = \"python\"):\n        \"\"\"Print code with syntax awareness and proper formatting\"\"\"\n        self._terminal_width = self._get_terminal_width()\n\n        if self._terminal_width &lt; 60:\n            # Simple format for small screens\n            self.print(f\"\\n{self.style.GREY('Code:')}\")\n            for line in code.split('\\n'):\n                self.print(f\"  {line}\")\n        else:\n            # Detailed format for larger screens\n            self.print(f\"\\n{self.style.BLUE('\u250c\u2500')} {self.style.YELLOW2(f'{language.upper()} Code')}\")\n\n            lines = code.split('\\n')\n            for i, line in enumerate(lines):\n                if i == len(lines) - 1 and not line.strip():\n                    continue\n\n                # Wrap long lines\n                if len(line) &gt; self._terminal_width - 6:\n                    wrapped = self._wrap_text(line, self._terminal_width - 6)\n                    for j, wrapped_line in enumerate(wrapped):\n                        prefix = \"\u2502\" if j == 0 else \"\u2502\"\n                        self.print(f\"{self.style.BLUE(prefix)} {wrapped_line}\")\n                else:\n                    self.print(f\"{self.style.BLUE('\u2502')} {line}\")\n\n            self.print(f\"{self.style.BLUE('\u2514\u2500')} {self.style.GREY('End of code block')}\")\n\n    def print_table(self, headers: list[str], rows: list[list[str]]):\n        \"\"\"Print a dynamic table that adapts to screen size\"\"\"\n        self._terminal_width = self._get_terminal_width()\n\n        if not rows:\n            return\n\n        # Calculate column widths\n        all_data = [headers] + rows\n        col_widths = []\n\n        for col in range(len(headers)):\n            max_width = max(len(str(row[col])) for row in all_data if col &lt; len(row))\n            col_widths.append(min(max_width, self._terminal_width // len(headers) - 2))\n\n        # Adjust if total width exceeds terminal\n        total_width = sum(col_widths) + len(headers) * 3 + 1\n        if total_width &gt; self._terminal_width:\n            # Proportionally reduce column widths\n            scale_factor = (self._terminal_width - len(headers) * 3 - 1) / sum(col_widths)\n            col_widths = [max(8, int(w * scale_factor)) for w in col_widths]\n\n        # Print table\n        self._print_table_row(headers, col_widths, is_header=True)\n        self._print_table_separator(col_widths)\n\n        for row in rows:\n            self._print_table_row(row, col_widths)\n\n    def _print_table_row(self, row: list[str], widths: list[int], is_header: bool = False):\n        \"\"\"Helper method to print a table row\"\"\"\n        formatted_cells = []\n        for _i, (cell, width) in enumerate(zip(row, widths, strict=False)):\n            cell_str = str(cell)\n            if len(cell_str) &gt; width:\n                cell_str = cell_str[:width - 3] + \"...\"\n\n            if is_header:\n                formatted_cells.append(self.style.Bold(self.style.CYAN(cell_str.ljust(width))))\n            else:\n                formatted_cells.append(cell_str.ljust(width))\n\n        self.print(f\"\u2502 {' \u2502 '.join(formatted_cells)} \u2502\")\n\n    def _print_table_separator(self, widths: list[int]):\n        \"\"\"Helper method to print table separator\"\"\"\n        parts = ['\u2500' * w for w in widths]\n        self.print(f\"\u251c\u2500{'\u2500\u253c\u2500'.join(parts)}\u2500\u2524\")\n\n    async def process_with_spinner(self, message: str, coroutine):\n        \"\"\"Execute coroutine with adaptive spinner\"\"\"\n        self._terminal_width = self._get_terminal_width()\n\n        if self._terminal_width &lt; 60:\n            # Simple spinner for small screens\n            spinner_symbols = \"\u280b\u2819\u2839\u2838\u283c\u2834\u2826\u2827\u2807\u280f\"\n        else:\n            # Detailed spinner for larger screens\n            spinner_symbols = \"\u280b\u2819\u2839\u2838\u283c\u2834\u2826\u2827\u2807\u280f\"\n\n        # Truncate message if too long\n        if len(message) &gt; self._terminal_width - 10:\n            display_message = message[:self._terminal_width - 13] + \"...\"\n        else:\n            display_message = message\n\n        with Spinner(f\"{self.style.CYAN('\u25cf')} {display_message}\", symbols=spinner_symbols):\n            return await coroutine\n\n    def print_git_info(self) -&gt; str | None:\n        \"\"\"Get current git branch with error handling\"\"\"\n        try:\n            result = subprocess.run(\n                ['git', 'rev-parse', '--abbrev-ref', 'HEAD'],\n                capture_output=True, text=True, timeout=2\n            )\n            if result.returncode == 0 and result.stdout.strip():\n                branch = result.stdout.strip()\n\n                # Check for uncommitted changes\n                status_result = subprocess.run(\n                    ['git', 'status', '--porcelain'],\n                    capture_output=True, text=True, timeout=1\n                )\n                dirty = \"*\" if status_result.stdout.strip() else \"\"\n\n                git_info = f\"{branch}{dirty}\"\n                self.print_info(f\"Git: {git_info}\")\n                return git_info\n        except (subprocess.TimeoutExpired, FileNotFoundError, subprocess.SubprocessError):\n            pass\n        return None\n\n    # Convenience methods with consistent styling\n    def print_error(self, message: str):\n        \"\"\"Print error message with consistent formatting\"\"\"\n        self.print(f\"{self.style.RED('\u2717')} {self.style.RED(message)}\")\n\n    def print_success(self, message: str):\n        \"\"\"Print success message with consistent formatting\"\"\"\n        self.print(f\"{self.style.GREEN('\u2713')} {self.style.GREEN(message)}\")\n\n    def print_warning(self, message: str):\n        \"\"\"Print warning message with consistent formatting\"\"\"\n        self.print(f\"{self.style.YELLOW('\u26a0')} {self.style.YELLOW(message)}\")\n\n    def print_info(self, message: str):\n        \"\"\"Print info message with consistent formatting\"\"\"\n        self.print(f\"{self.style.CYAN('\u2139')} {self.style.CYAN(message)}\")\n\n    def print_debug(self, message: str):\n        \"\"\"Print debug message with consistent formatting\"\"\"\n        self.print(f\"{self.style.GREY('\ud83d\udc1b')} {self.style.GREY(message)}\")\n</code></pre> <code>get_git_info()</code> \u00b6 <p>Checks for a git repo and returns its name and branch, or None.</p> Source code in <code>toolboxv2/mods/isaa/extras/verbose_output.py</code> <pre><code>def get_git_info(self):\n    \"\"\"Checks for a git repo and returns its name and branch, or None.\"\"\"\n    try:\n        # Check if we are in a git repository\n        subprocess.check_output(['git', 'rev-parse', '--is-inside-work-tree'], stderr=subprocess.DEVNULL)\n\n        # Get the repo name (root folder name)\n        repo_root = subprocess.check_output(['git', 'rev-parse', '--show-toplevel'],\n                                            stderr=subprocess.DEVNULL).strip().decode('utf-8')\n        repo_name = os.path.basename(repo_root)\n\n        # Get the current branch name\n        branch = subprocess.check_output(['git', 'rev-parse', '--abbrev-ref', 'HEAD'],\n                                         stderr=subprocess.DEVNULL).strip().decode('utf-8')\n\n        return repo_name, branch\n    except (subprocess.CalledProcessError, FileNotFoundError):\n        # This handles cases where 'git' is not installed or it's not a git repo\n        return None\n</code></pre> <code>print_code_block(code, language='python')</code> \u00b6 <p>Print code with syntax awareness and proper formatting</p> Source code in <code>toolboxv2/mods/isaa/extras/verbose_output.py</code> <pre><code>def print_code_block(self, code: str, language: str = \"python\"):\n    \"\"\"Print code with syntax awareness and proper formatting\"\"\"\n    self._terminal_width = self._get_terminal_width()\n\n    if self._terminal_width &lt; 60:\n        # Simple format for small screens\n        self.print(f\"\\n{self.style.GREY('Code:')}\")\n        for line in code.split('\\n'):\n            self.print(f\"  {line}\")\n    else:\n        # Detailed format for larger screens\n        self.print(f\"\\n{self.style.BLUE('\u250c\u2500')} {self.style.YELLOW2(f'{language.upper()} Code')}\")\n\n        lines = code.split('\\n')\n        for i, line in enumerate(lines):\n            if i == len(lines) - 1 and not line.strip():\n                continue\n\n            # Wrap long lines\n            if len(line) &gt; self._terminal_width - 6:\n                wrapped = self._wrap_text(line, self._terminal_width - 6)\n                for j, wrapped_line in enumerate(wrapped):\n                    prefix = \"\u2502\" if j == 0 else \"\u2502\"\n                    self.print(f\"{self.style.BLUE(prefix)} {wrapped_line}\")\n            else:\n                self.print(f\"{self.style.BLUE('\u2502')} {line}\")\n\n        self.print(f\"{self.style.BLUE('\u2514\u2500')} {self.style.GREY('End of code block')}\")\n</code></pre> <code>print_debug(message)</code> \u00b6 <p>Print debug message with consistent formatting</p> Source code in <code>toolboxv2/mods/isaa/extras/verbose_output.py</code> <pre><code>def print_debug(self, message: str):\n    \"\"\"Print debug message with consistent formatting\"\"\"\n    self.print(f\"{self.style.GREY('\ud83d\udc1b')} {self.style.GREY(message)}\")\n</code></pre> <code>print_error(message)</code> \u00b6 <p>Print error message with consistent formatting</p> Source code in <code>toolboxv2/mods/isaa/extras/verbose_output.py</code> <pre><code>def print_error(self, message: str):\n    \"\"\"Print error message with consistent formatting\"\"\"\n    self.print(f\"{self.style.RED('\u2717')} {self.style.RED(message)}\")\n</code></pre> <code>print_git_info()</code> \u00b6 <p>Get current git branch with error handling</p> Source code in <code>toolboxv2/mods/isaa/extras/verbose_output.py</code> <pre><code>def print_git_info(self) -&gt; str | None:\n    \"\"\"Get current git branch with error handling\"\"\"\n    try:\n        result = subprocess.run(\n            ['git', 'rev-parse', '--abbrev-ref', 'HEAD'],\n            capture_output=True, text=True, timeout=2\n        )\n        if result.returncode == 0 and result.stdout.strip():\n            branch = result.stdout.strip()\n\n            # Check for uncommitted changes\n            status_result = subprocess.run(\n                ['git', 'status', '--porcelain'],\n                capture_output=True, text=True, timeout=1\n            )\n            dirty = \"*\" if status_result.stdout.strip() else \"\"\n\n            git_info = f\"{branch}{dirty}\"\n            self.print_info(f\"Git: {git_info}\")\n            return git_info\n    except (subprocess.TimeoutExpired, FileNotFoundError, subprocess.SubprocessError):\n        pass\n    return None\n</code></pre> <code>print_header(text)</code> \u00b6 <p>Print a dynamic header that adapts to screen size</p> Source code in <code>toolboxv2/mods/isaa/extras/verbose_output.py</code> <pre><code>def print_header(self, text: str):\n    \"\"\"Print a dynamic header that adapts to screen size\"\"\"\n    self._terminal_width = self._get_terminal_width()\n\n    if self._terminal_width &lt; 60:  # Tiny screen\n        self.print()\n        self.print(self.style.CYAN(\"=\" * self._terminal_width))\n        self.print(self.style.CYAN(self.style.Bold(text)))\n        self.print(self.style.CYAN(\"=\" * self._terminal_width))\n    else:  # Regular/large screen\n        border_width = min(len(text) + 2, self._terminal_width - 2)\n        border = \"\u2500\" * border_width\n\n        self.print()\n        self.print(self.style.CYAN(f\"\u250c{border}\u2510\"))\n        self.print(self.style.CYAN(f\"\u2502 {self.style.Bold(text).center(border_width - 2)} \u2502\"))\n        self.print(self.style.CYAN(f\"\u2514{border}\u2518\"))\n    self.print()\n</code></pre> <code>print_info(message)</code> \u00b6 <p>Print info message with consistent formatting</p> Source code in <code>toolboxv2/mods/isaa/extras/verbose_output.py</code> <pre><code>def print_info(self, message: str):\n    \"\"\"Print info message with consistent formatting\"\"\"\n    self.print(f\"{self.style.CYAN('\u2139')} {self.style.CYAN(message)}\")\n</code></pre> <code>print_progress_bar(current, maximum, title='Progress')</code> \u00b6 <p>Dynamic progress bar that adapts to screen size</p> Source code in <code>toolboxv2/mods/isaa/extras/verbose_output.py</code> <pre><code>def print_progress_bar(self, current: int, maximum: int, title: str = \"Progress\"):\n    \"\"\"Dynamic progress bar that adapts to screen size\"\"\"\n    self._terminal_width = self._get_terminal_width()\n\n    # Calculate bar width based on screen size\n    if self._terminal_width &lt; 60:\n        bar_width = 10\n        template = f\"\\r{title}: [{{}}] {current}/{maximum}\"\n    else:\n        bar_width = min(30, self._terminal_width - 30)\n        template = f\"\\r{self.style.CYAN(title)}: [{{}}] {current}/{maximum} ({current / maximum * 100:.1f}%)\"\n\n    progress = int((current / maximum) * bar_width)\n    bar = \"\u2588\" * progress + \"\u2591\" * (bar_width - progress)\n\n    self.print(template.format(bar), end='', flush=True)\n</code></pre> <code>print_section(title, content)</code> \u00b6 <p>Print a clean section with adaptive formatting</p> Source code in <code>toolboxv2/mods/isaa/extras/verbose_output.py</code> <pre><code>def print_section(self, title: str, content: str):\n    \"\"\"Print a clean section with adaptive formatting\"\"\"\n    self._terminal_width = self._get_terminal_width()\n\n    # Title\n    if self._terminal_width &lt; 60:\n        self.print(f\"\\n{self.style.BLUE('\u25cf')} {self.style.Bold(title)}\")\n    else:\n        self.print(f\"\\n{self.style.BLUE('\u25cf')} {self.style.Bold(self.style.BLUE(title))}\")\n\n    # Content with proper wrapping\n    for line in content.split('\\n'):\n        if line.strip():\n            wrapped_lines = self._wrap_text(line.strip())\n            for wrapped_line in wrapped_lines:\n                if self._terminal_width &lt; 60:\n                    self.print(f\"  {wrapped_line}\")\n                else:\n                    self.print(f\"  {self.style.GREY('\u2502')} {wrapped_line}\")\n    self.print()\n</code></pre> <code>print_state(state, details=None)</code> \u00b6 <p>Print current state with adaptive formatting</p> Source code in <code>toolboxv2/mods/isaa/extras/verbose_output.py</code> <pre><code>def print_state(self, state: str, details: dict[str, Any] = None) -&gt; str:\n    \"\"\"Print current state with adaptive formatting\"\"\"\n    self._terminal_width = self._get_terminal_width()\n\n    state_colors = {\n        'ACTION': self.style.GREEN2,\n        'PROCESSING': self.style.YELLOW2,\n        'BRAKE': self.style.RED2,\n        'DONE': self.style.BLUE2,\n        'ERROR': self.style.RED,\n        'SUCCESS': self.style.GREEN,\n        'INFO': self.style.CYAN\n    }\n\n    color_func = state_colors.get(state.upper(), self.style.WHITE2)\n\n    if self._terminal_width &lt; 60:\n        # Compact format for small screens\n        self.print(f\"\\n[{color_func(state)}]\")\n        result = f\"\\n[{state}]\"\n    else:\n        # Full format for larger screens\n        self.print(f\"\\n{self.style.Bold('State:')} {color_func(state)}\")\n        result = f\"\\nState: {state}\"\n\n    if details:\n        for key, value in details.items():\n            # Truncate long values on small screens\n            if self._terminal_width &lt; 60 and len(str(value)) &gt; 30:\n                display_value = str(value)[:27] + \"...\"\n            else:\n                display_value = str(value)\n\n            if self._terminal_width &lt; 60:\n                self.print(f\"  {key}: {display_value}\")\n                result += f\"\\n  {key}: {display_value}\"\n            else:\n                self.print(f\"  {self.style.GREY('\u251c\u2500')} {self.style.CYAN(key)}: {display_value}\")\n                result += f\"\\n  \u251c\u2500 {key}: {display_value}\"\n\n    return result\n</code></pre> <code>print_success(message)</code> \u00b6 <p>Print success message with consistent formatting</p> Source code in <code>toolboxv2/mods/isaa/extras/verbose_output.py</code> <pre><code>def print_success(self, message: str):\n    \"\"\"Print success message with consistent formatting\"\"\"\n    self.print(f\"{self.style.GREEN('\u2713')} {self.style.GREEN(message)}\")\n</code></pre> <code>print_table(headers, rows)</code> \u00b6 <p>Print a dynamic table that adapts to screen size</p> Source code in <code>toolboxv2/mods/isaa/extras/verbose_output.py</code> <pre><code>def print_table(self, headers: list[str], rows: list[list[str]]):\n    \"\"\"Print a dynamic table that adapts to screen size\"\"\"\n    self._terminal_width = self._get_terminal_width()\n\n    if not rows:\n        return\n\n    # Calculate column widths\n    all_data = [headers] + rows\n    col_widths = []\n\n    for col in range(len(headers)):\n        max_width = max(len(str(row[col])) for row in all_data if col &lt; len(row))\n        col_widths.append(min(max_width, self._terminal_width // len(headers) - 2))\n\n    # Adjust if total width exceeds terminal\n    total_width = sum(col_widths) + len(headers) * 3 + 1\n    if total_width &gt; self._terminal_width:\n        # Proportionally reduce column widths\n        scale_factor = (self._terminal_width - len(headers) * 3 - 1) / sum(col_widths)\n        col_widths = [max(8, int(w * scale_factor)) for w in col_widths]\n\n    # Print table\n    self._print_table_row(headers, col_widths, is_header=True)\n    self._print_table_separator(col_widths)\n\n    for row in rows:\n        self._print_table_row(row, col_widths)\n</code></pre> <code>print_warning(message)</code> \u00b6 <p>Print warning message with consistent formatting</p> Source code in <code>toolboxv2/mods/isaa/extras/verbose_output.py</code> <pre><code>def print_warning(self, message: str):\n    \"\"\"Print warning message with consistent formatting\"\"\"\n    self.print(f\"{self.style.YELLOW('\u26a0')} {self.style.YELLOW(message)}\")\n</code></pre> <code>process_with_spinner(message, coroutine)</code> <code>async</code> \u00b6 <p>Execute coroutine with adaptive spinner</p> Source code in <code>toolboxv2/mods/isaa/extras/verbose_output.py</code> <pre><code>async def process_with_spinner(self, message: str, coroutine):\n    \"\"\"Execute coroutine with adaptive spinner\"\"\"\n    self._terminal_width = self._get_terminal_width()\n\n    if self._terminal_width &lt; 60:\n        # Simple spinner for small screens\n        spinner_symbols = \"\u280b\u2819\u2839\u2838\u283c\u2834\u2826\u2827\u2807\u280f\"\n    else:\n        # Detailed spinner for larger screens\n        spinner_symbols = \"\u280b\u2819\u2839\u2838\u283c\u2834\u2826\u2827\u2807\u280f\"\n\n    # Truncate message if too long\n    if len(message) &gt; self._terminal_width - 10:\n        display_message = message[:self._terminal_width - 13] + \"...\"\n    else:\n        display_message = message\n\n    with Spinner(f\"{self.style.CYAN('\u25cf')} {display_message}\", symbols=spinner_symbols):\n        return await coroutine\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.verbose_output.EnhancedVerboseOutput","title":"<code>EnhancedVerboseOutput</code>","text":"<p>Main interface for verbose output with full functionality</p> Source code in <code>toolboxv2/mods/isaa/extras/verbose_output.py</code> <pre><code>class EnhancedVerboseOutput:\n    \"\"\"Main interface for verbose output with full functionality\"\"\"\n\n    def __init__(self, verbose: bool = True, print_func=None, **formatter_kwargs):\n        self.verbose = verbose\n        self.print = print_func or print\n        self.formatter = DynamicVerboseFormatter(self.print, **formatter_kwargs)\n        self._start_time = time.time()\n\n    def __getattr__(self, name):\n        \"\"\"Delegate to formatter for convenience\"\"\"\n        return getattr(self.formatter, name)\n\n    async def print_agent_response(self, response: str):\n        await self.log_message(\"assistant\", response)\n\n    async def print_thought(self, thought: str):\n        await self.log_message(\"assistant\", f\"Thought: {thought}\")\n\n    async def log_message(self, role: str, content: str):\n        \"\"\"Log chat messages with role-based formatting\"\"\"\n        if not self.verbose:\n            return\n\n        role_formats = {\n            'user': (self.formatter.style.GREEN, \"\ud83d\udc64\"),\n            'assistant': (self.formatter.style.BLUE, \"\ud83e\udd16\"),\n            'system': (self.formatter.style.YELLOW, \"\u2699\ufe0f\"),\n            'error': (self.formatter.style.RED, \"\u274c\"),\n            'debug': (self.formatter.style.GREY, \"\ud83d\udc1b\")\n        }\n\n        color_func, icon = role_formats.get(role.lower(), (self.formatter.style.WHITE, \"\u2022\"))\n\n        if content.startswith(\"```\"):\n            self.formatter.print_code_block(content)\n            return\n\n        if content.startswith(\"{\") or content.startswith(\"[\") and content.endswith(\"}\") or content.endswith(\"]\"):\n            content = json.dumps(json.loads(content), indent=2)\n\n        # Adapt formatting based on screen size\n        if self.formatter._terminal_width &lt; 60:\n            self.print(f\"\\n{icon} [{role.upper()}]\")\n            # Wrap content for small screens\n            wrapped_content = self.formatter._wrap_text(content, self.formatter._terminal_width - 2)\n            for line in wrapped_content:\n                self.print(f\"  {line}\")\n        else:\n            self.print(f\"\\n{icon} {color_func(f'[{role.upper()}]')}\")\n            self.print(f\"{self.formatter.style.GREY('\u2514\u2500')} {content}\")\n        self.print()\n\n    async def log_process_result(self, result: dict[str, Any]):\n        \"\"\"Log processing results with structured formatting\"\"\"\n        if not self.verbose:\n            return\n\n        content_parts = []\n\n        if 'action' in result:\n            content_parts.append(f\"Action: {result['action']}\")\n        if 'is_completed' in result:\n            content_parts.append(f\"Completed: {result['is_completed']}\")\n        if 'effectiveness' in result:\n            content_parts.append(f\"Effectiveness: {result['effectiveness']}\")\n        if 'recommendations' in result:\n            content_parts.append(f\"Recommendations:\\n{result['recommendations']}\")\n        if 'workflow' in result:\n            content_parts.append(f\"Workflow:\\n{result['workflow']}\")\n        if 'errors' in result and result['errors']:\n            content_parts.append(f\"Errors: {result['errors']}\")\n        if 'content' in result:\n            content_parts.append(f\"Content:\\n{result['content']}\")\n\n        self.formatter.print_section(\"Process Result\", '\\n'.join(content_parts))\n\n    def log_header(self, text: str):\n        \"\"\"Log header with timing information\"\"\"\n        if not self.verbose:\n            return\n\n        elapsed = time.time() - self._start_time\n        timing = f\" ({elapsed / 60:.1f}m)\" if elapsed &gt; 60 else f\" ({elapsed:.1f}s)\"\n\n        self.formatter.print_header(f\"{text}{timing}\")\n\n    def log_state(self, state: str, user_ns: dict = None, override: bool = False):\n        \"\"\"Log state with optional override\"\"\"\n        if not self.verbose and not override:\n            return\n\n        return self.formatter.print_state(state, user_ns)\n\n    async def process(self, message: str, coroutine):\n        \"\"\"Process with optional spinner\"\"\"\n        if not self.verbose:\n            return await coroutine\n\n        if message.lower() in [\"code\", \"silent\"]:\n            return await coroutine\n\n        return await self.formatter.process_with_spinner(message, coroutine)\n\n    def print_tool_call(self, tool_name: str, tool_args: dict, result: str | None = None):\n        \"\"\"\n        Gibt Informationen zum Tool-Aufruf aus.\n        Versucht, das Ergebnis als JSON zu formatieren, wenn m\u00f6glich.\n        \"\"\"\n        if not self.verbose:\n            return\n\n        # Argumente wie zuvor formatieren\n        args_str = json.dumps(tool_args, indent=2, ensure_ascii=False) if tool_args else \"None\"\n        content = f\"Tool: {tool_name}\\nArguments:\\n{args_str}\"\n\n        if result:\n            result_output = \"\"\n            try:\n                # 1. Versuch, den String als JSON zu parsen\n                data = json.loads(result)\n\n                # 2. Pr\u00fcfen, ob das Ergebnis ein Dictionary ist (der h\u00e4ufigste Fall)\n                if isinstance(data, dict):\n                    # Eine Kopie f\u00fcr die Anzeige erstellen, um den 'output'-Wert zu ersetzen\n                    display_data = data.copy()\n                    output_preview = \"\"\n\n                    # Spezielle Handhabung f\u00fcr einen langen 'output'-String, falls vorhanden\n                    if 'output' in display_data and isinstance(display_data['output'], str):\n                        full_output = display_data['output']\n                        # Den langen String im JSON durch einen Platzhalter ersetzen\n                        display_data['output'] = \"&lt;-- [Inhalt wird separat formatiert]\"\n\n                        # Vorschau mit den ersten 3 Zeilen erstellen\n                        lines = full_output.strip().split('\\n')[:3]\n                        preview_text = '\\n'.join(lines)\n                        output_preview = f\"\\n\\n--- Vorschau f\u00fcr 'output' ---\\n\\x1b[90m{preview_text}\\n...\\x1b[0m\"  # Hellgrauer Text\n                        # display_data['output'] = output_preview\n                    # Das formatierte JSON (mit Platzhalter) zum Inhalt hinzuf\u00fcgen\n                    formatted_json = json.dumps(display_data, indent=2, ensure_ascii=False)\n                    result_output = f\"Geparstes Dictionary:\\n{formatted_json}{output_preview}\"\n\n                else:\n                    # Falls es valides JSON, aber kein Dictionary ist (z.B. eine Liste)\n                    result_output = f\"Gepastes JSON (kein Dictionary):\\n{json.dumps(data, indent=2, ensure_ascii=False)}\"\n\n            except json.JSONDecodeError:\n                # 3. Wenn Parsen fehlschl\u00e4gt, den String als Rohtext behandeln\n                result_output = f\"{result}\"\n\n            content += f\"\\nResult:\\n{result_output}\"\n\n        else:\n            # Fall, wenn der Task noch l\u00e4uft\n            content += \"\\nResult: In progress...\"\n\n        # Den gesamten Inhalt an den Formatter \u00fcbergeben\n        self.formatter.print_section(\"Tool Call\", content)\n\n    def print_event(self, event: dict):\n        \"\"\"Print event information\"\"\"\n        if not self.verbose:\n            return\n\n        if event.get(\"content\") and event[\"content\"].get(\"parts\"):\n            for part in event[\"content\"][\"parts\"]:\n                if part.get(\"text\"):\n                    self.formatter.print_info(f\"Thought: {part['text']}\")\n                if part.get(\"function_call\"):\n                    self.print_tool_call(\n                        part[\"function_call\"][\"name\"],\n                        part[\"function_call\"][\"args\"]\n                    )\n                if part.get(\"function_response\"):\n                    result = part[\"function_response\"][\"response\"].get(\"result\", \"\")\n                    self.print_tool_call(\n                        part[\"function_response\"][\"name\"],\n                        {},\n                        str(result)\n                    )\n\n        if event.get(\"usage_metadata\"):\n            self.formatter.print_info(f\"Token usage: {event['usage_metadata']}\")\n\n    @contextmanager\n    def section_context(self, title: str):\n        \"\"\"Context manager for sections\"\"\"\n        if self.verbose:\n            self.formatter.print_section(title, \"Starting...\")\n        try:\n            yield\n        finally:\n            if self.verbose:\n                self.formatter.print_success(f\"Completed: {title}\")\n\n    def clear_line(self):\n        \"\"\"Clear current line\"\"\"\n        self.print('\\r' + ' ' * self.formatter._terminal_width + '\\r', end='')\n\n    def print_separator(self, char: str = \"\u2500\"):\n        \"\"\"Print a separator line\"\"\"\n        self.print(self.formatter.style.GREY(char * self.formatter._terminal_width))\n\n    def print_warning(self, message: str):\n        \"\"\"Print a warning message with yellow style\"\"\"\n        if self.verbose:\n            self.print(self.formatter.style.YELLOW(f\"\u26a0\ufe0f  WARNING: {message}\"))\n\n    def print_error(self, message: str):\n        \"\"\"Print an error message with red style\"\"\"\n        if self.verbose:\n            self.print(self.formatter.style.RED(f\"\u274c ERROR: {message}\"))\n\n    def print_success(self, message: str):\n        \"\"\"Print a success message with green style\"\"\"\n        if self.verbose:\n            self.print(self.formatter.style.GREEN(f\"\u2705 SUCCESS: {message}\"))\n</code></pre> <code>__getattr__(name)</code> \u00b6 <p>Delegate to formatter for convenience</p> Source code in <code>toolboxv2/mods/isaa/extras/verbose_output.py</code> <pre><code>def __getattr__(self, name):\n    \"\"\"Delegate to formatter for convenience\"\"\"\n    return getattr(self.formatter, name)\n</code></pre> <code>clear_line()</code> \u00b6 <p>Clear current line</p> Source code in <code>toolboxv2/mods/isaa/extras/verbose_output.py</code> <pre><code>def clear_line(self):\n    \"\"\"Clear current line\"\"\"\n    self.print('\\r' + ' ' * self.formatter._terminal_width + '\\r', end='')\n</code></pre> <code>log_header(text)</code> \u00b6 <p>Log header with timing information</p> Source code in <code>toolboxv2/mods/isaa/extras/verbose_output.py</code> <pre><code>def log_header(self, text: str):\n    \"\"\"Log header with timing information\"\"\"\n    if not self.verbose:\n        return\n\n    elapsed = time.time() - self._start_time\n    timing = f\" ({elapsed / 60:.1f}m)\" if elapsed &gt; 60 else f\" ({elapsed:.1f}s)\"\n\n    self.formatter.print_header(f\"{text}{timing}\")\n</code></pre> <code>log_message(role, content)</code> <code>async</code> \u00b6 <p>Log chat messages with role-based formatting</p> Source code in <code>toolboxv2/mods/isaa/extras/verbose_output.py</code> <pre><code>async def log_message(self, role: str, content: str):\n    \"\"\"Log chat messages with role-based formatting\"\"\"\n    if not self.verbose:\n        return\n\n    role_formats = {\n        'user': (self.formatter.style.GREEN, \"\ud83d\udc64\"),\n        'assistant': (self.formatter.style.BLUE, \"\ud83e\udd16\"),\n        'system': (self.formatter.style.YELLOW, \"\u2699\ufe0f\"),\n        'error': (self.formatter.style.RED, \"\u274c\"),\n        'debug': (self.formatter.style.GREY, \"\ud83d\udc1b\")\n    }\n\n    color_func, icon = role_formats.get(role.lower(), (self.formatter.style.WHITE, \"\u2022\"))\n\n    if content.startswith(\"```\"):\n        self.formatter.print_code_block(content)\n        return\n\n    if content.startswith(\"{\") or content.startswith(\"[\") and content.endswith(\"}\") or content.endswith(\"]\"):\n        content = json.dumps(json.loads(content), indent=2)\n\n    # Adapt formatting based on screen size\n    if self.formatter._terminal_width &lt; 60:\n        self.print(f\"\\n{icon} [{role.upper()}]\")\n        # Wrap content for small screens\n        wrapped_content = self.formatter._wrap_text(content, self.formatter._terminal_width - 2)\n        for line in wrapped_content:\n            self.print(f\"  {line}\")\n    else:\n        self.print(f\"\\n{icon} {color_func(f'[{role.upper()}]')}\")\n        self.print(f\"{self.formatter.style.GREY('\u2514\u2500')} {content}\")\n    self.print()\n</code></pre> <code>log_process_result(result)</code> <code>async</code> \u00b6 <p>Log processing results with structured formatting</p> Source code in <code>toolboxv2/mods/isaa/extras/verbose_output.py</code> <pre><code>async def log_process_result(self, result: dict[str, Any]):\n    \"\"\"Log processing results with structured formatting\"\"\"\n    if not self.verbose:\n        return\n\n    content_parts = []\n\n    if 'action' in result:\n        content_parts.append(f\"Action: {result['action']}\")\n    if 'is_completed' in result:\n        content_parts.append(f\"Completed: {result['is_completed']}\")\n    if 'effectiveness' in result:\n        content_parts.append(f\"Effectiveness: {result['effectiveness']}\")\n    if 'recommendations' in result:\n        content_parts.append(f\"Recommendations:\\n{result['recommendations']}\")\n    if 'workflow' in result:\n        content_parts.append(f\"Workflow:\\n{result['workflow']}\")\n    if 'errors' in result and result['errors']:\n        content_parts.append(f\"Errors: {result['errors']}\")\n    if 'content' in result:\n        content_parts.append(f\"Content:\\n{result['content']}\")\n\n    self.formatter.print_section(\"Process Result\", '\\n'.join(content_parts))\n</code></pre> <code>log_state(state, user_ns=None, override=False)</code> \u00b6 <p>Log state with optional override</p> Source code in <code>toolboxv2/mods/isaa/extras/verbose_output.py</code> <pre><code>def log_state(self, state: str, user_ns: dict = None, override: bool = False):\n    \"\"\"Log state with optional override\"\"\"\n    if not self.verbose and not override:\n        return\n\n    return self.formatter.print_state(state, user_ns)\n</code></pre> <code>print_error(message)</code> \u00b6 <p>Print an error message with red style</p> Source code in <code>toolboxv2/mods/isaa/extras/verbose_output.py</code> <pre><code>def print_error(self, message: str):\n    \"\"\"Print an error message with red style\"\"\"\n    if self.verbose:\n        self.print(self.formatter.style.RED(f\"\u274c ERROR: {message}\"))\n</code></pre> <code>print_event(event)</code> \u00b6 <p>Print event information</p> Source code in <code>toolboxv2/mods/isaa/extras/verbose_output.py</code> <pre><code>def print_event(self, event: dict):\n    \"\"\"Print event information\"\"\"\n    if not self.verbose:\n        return\n\n    if event.get(\"content\") and event[\"content\"].get(\"parts\"):\n        for part in event[\"content\"][\"parts\"]:\n            if part.get(\"text\"):\n                self.formatter.print_info(f\"Thought: {part['text']}\")\n            if part.get(\"function_call\"):\n                self.print_tool_call(\n                    part[\"function_call\"][\"name\"],\n                    part[\"function_call\"][\"args\"]\n                )\n            if part.get(\"function_response\"):\n                result = part[\"function_response\"][\"response\"].get(\"result\", \"\")\n                self.print_tool_call(\n                    part[\"function_response\"][\"name\"],\n                    {},\n                    str(result)\n                )\n\n    if event.get(\"usage_metadata\"):\n        self.formatter.print_info(f\"Token usage: {event['usage_metadata']}\")\n</code></pre> <code>print_separator(char='\u2500')</code> \u00b6 <p>Print a separator line</p> Source code in <code>toolboxv2/mods/isaa/extras/verbose_output.py</code> <pre><code>def print_separator(self, char: str = \"\u2500\"):\n    \"\"\"Print a separator line\"\"\"\n    self.print(self.formatter.style.GREY(char * self.formatter._terminal_width))\n</code></pre> <code>print_success(message)</code> \u00b6 <p>Print a success message with green style</p> Source code in <code>toolboxv2/mods/isaa/extras/verbose_output.py</code> <pre><code>def print_success(self, message: str):\n    \"\"\"Print a success message with green style\"\"\"\n    if self.verbose:\n        self.print(self.formatter.style.GREEN(f\"\u2705 SUCCESS: {message}\"))\n</code></pre> <code>print_tool_call(tool_name, tool_args, result=None)</code> \u00b6 <p>Gibt Informationen zum Tool-Aufruf aus. Versucht, das Ergebnis als JSON zu formatieren, wenn m\u00f6glich.</p> Source code in <code>toolboxv2/mods/isaa/extras/verbose_output.py</code> <pre><code>def print_tool_call(self, tool_name: str, tool_args: dict, result: str | None = None):\n    \"\"\"\n    Gibt Informationen zum Tool-Aufruf aus.\n    Versucht, das Ergebnis als JSON zu formatieren, wenn m\u00f6glich.\n    \"\"\"\n    if not self.verbose:\n        return\n\n    # Argumente wie zuvor formatieren\n    args_str = json.dumps(tool_args, indent=2, ensure_ascii=False) if tool_args else \"None\"\n    content = f\"Tool: {tool_name}\\nArguments:\\n{args_str}\"\n\n    if result:\n        result_output = \"\"\n        try:\n            # 1. Versuch, den String als JSON zu parsen\n            data = json.loads(result)\n\n            # 2. Pr\u00fcfen, ob das Ergebnis ein Dictionary ist (der h\u00e4ufigste Fall)\n            if isinstance(data, dict):\n                # Eine Kopie f\u00fcr die Anzeige erstellen, um den 'output'-Wert zu ersetzen\n                display_data = data.copy()\n                output_preview = \"\"\n\n                # Spezielle Handhabung f\u00fcr einen langen 'output'-String, falls vorhanden\n                if 'output' in display_data and isinstance(display_data['output'], str):\n                    full_output = display_data['output']\n                    # Den langen String im JSON durch einen Platzhalter ersetzen\n                    display_data['output'] = \"&lt;-- [Inhalt wird separat formatiert]\"\n\n                    # Vorschau mit den ersten 3 Zeilen erstellen\n                    lines = full_output.strip().split('\\n')[:3]\n                    preview_text = '\\n'.join(lines)\n                    output_preview = f\"\\n\\n--- Vorschau f\u00fcr 'output' ---\\n\\x1b[90m{preview_text}\\n...\\x1b[0m\"  # Hellgrauer Text\n                    # display_data['output'] = output_preview\n                # Das formatierte JSON (mit Platzhalter) zum Inhalt hinzuf\u00fcgen\n                formatted_json = json.dumps(display_data, indent=2, ensure_ascii=False)\n                result_output = f\"Geparstes Dictionary:\\n{formatted_json}{output_preview}\"\n\n            else:\n                # Falls es valides JSON, aber kein Dictionary ist (z.B. eine Liste)\n                result_output = f\"Gepastes JSON (kein Dictionary):\\n{json.dumps(data, indent=2, ensure_ascii=False)}\"\n\n        except json.JSONDecodeError:\n            # 3. Wenn Parsen fehlschl\u00e4gt, den String als Rohtext behandeln\n            result_output = f\"{result}\"\n\n        content += f\"\\nResult:\\n{result_output}\"\n\n    else:\n        # Fall, wenn der Task noch l\u00e4uft\n        content += \"\\nResult: In progress...\"\n\n    # Den gesamten Inhalt an den Formatter \u00fcbergeben\n    self.formatter.print_section(\"Tool Call\", content)\n</code></pre> <code>print_warning(message)</code> \u00b6 <p>Print a warning message with yellow style</p> Source code in <code>toolboxv2/mods/isaa/extras/verbose_output.py</code> <pre><code>def print_warning(self, message: str):\n    \"\"\"Print a warning message with yellow style\"\"\"\n    if self.verbose:\n        self.print(self.formatter.style.YELLOW(f\"\u26a0\ufe0f  WARNING: {message}\"))\n</code></pre> <code>process(message, coroutine)</code> <code>async</code> \u00b6 <p>Process with optional spinner</p> Source code in <code>toolboxv2/mods/isaa/extras/verbose_output.py</code> <pre><code>async def process(self, message: str, coroutine):\n    \"\"\"Process with optional spinner\"\"\"\n    if not self.verbose:\n        return await coroutine\n\n    if message.lower() in [\"code\", \"silent\"]:\n        return await coroutine\n\n    return await self.formatter.process_with_spinner(message, coroutine)\n</code></pre> <code>section_context(title)</code> \u00b6 <p>Context manager for sections</p> Source code in <code>toolboxv2/mods/isaa/extras/verbose_output.py</code> <pre><code>@contextmanager\ndef section_context(self, title: str):\n    \"\"\"Context manager for sections\"\"\"\n    if self.verbose:\n        self.formatter.print_section(title, \"Starting...\")\n    try:\n        yield\n    finally:\n        if self.verbose:\n            self.formatter.print_success(f\"Completed: {title}\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.web_search","title":"<code>web_search</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.web_search.clean_markdown_robust","title":"<code>clean_markdown_robust(content)</code>","text":"<p>Robust markdown cleaning</p> Source code in <code>toolboxv2/mods/isaa/extras/web_search.py</code> <pre><code>def clean_markdown_robust(content: str) -&gt; str:\n    \"\"\"Robust markdown cleaning\"\"\"\n    if not content:\n        return \"\"\n\n    # Remove common encoding artifacts more aggressively\n    replacements = {\n        '\ufffd': '',\n        '\u00e2\u20ac\u2122': \"'\", '\u00e2\u20ac\u0153': '\"', '\u00e2\u20ac': '\"', '\u00e2\u20ac\u00a6': '...',\n        '\u00e2\u20ac\"': '-', '\u00e2\u20ac\"': '--', '\u00c2': ' ',\n        '\u00c3\u00a1': '\u00e1', '\u00c3\u00a9': '\u00e9', '\u00c3\u00ad': '\u00ed', '\u00c3\u00b3': '\u00f3', '\u00c3\u00ba': '\u00fa',\n        '\u00e2\u20ac\u00a2': '\u2022', '\u00c2\u00b7': '\u00b7', '\u00c2\u00ab': '\u00ab', '\u00c2\u00bb': '\u00bb'\n    }\n\n    for old, new in replacements.items():\n        content = content.replace(old, new)\n\n    # Remove lines with too many non-ASCII characters\n    lines = content.split('\\n')\n    cleaned_lines = []\n\n    for line in lines:\n        line = line.strip()\n        if not line:\n            cleaned_lines.append('')\n            continue\n\n        # Skip lines that are mostly garbled\n        ascii_chars = sum(1 for c in line if ord(c) &lt; 128)\n        if len(line) &gt; 10 and ascii_chars / len(line) &lt; 0.7:\n            continue\n\n        # Skip navigation/junk lines\n        if (len(line) &lt; 3 or\n            line.lower() in ['home', 'menu', 'search', 'login', 'register'] or\n            re.match(r'^[\\W\\s]*$', line)):\n            continue\n\n        cleaned_lines.append(line)\n\n    # Remove excessive empty lines\n    result = '\\n'.join(cleaned_lines)\n    result = re.sub(r'\\n{3,}', '\\n\\n', result)\n\n    return result.strip()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.web_search.convert_to_markdown","title":"<code>convert_to_markdown(element)</code>","text":"<p>Convert HTML element to markdown with fallbacks</p> Source code in <code>toolboxv2/mods/isaa/extras/web_search.py</code> <pre><code>def convert_to_markdown(element):\n    \"\"\"Convert HTML element to markdown with fallbacks\"\"\"\n\n    # Strategy 1: Use html2text\n    try:\n        import html2text\n        h = html2text.HTML2Text()\n        h.ignore_links = False\n        h.ignore_images = True\n        h.body_width = 0\n        h.unicode_snob = True\n        h.skip_internal_links = True\n        h.inline_links = False\n        h.decode_errors = 'ignore'\n\n        markdown = h.handle(str(element))\n        if markdown and len(markdown.strip()) &gt; 100:\n            return markdown\n    except:\n        pass\n\n    # Strategy 2: Extract text with basic formatting\n    try:\n        text_parts = []\n\n        for elem in element.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6']):\n            level = int(elem.name[1])\n            text_parts.append('#' * level + ' ' + elem.get_text(strip=True))\n            elem.replace_with('[HEADING_PLACEHOLDER]')\n\n        for elem in element.find_all('p'):\n            text = elem.get_text(strip=True)\n            if text:\n                text_parts.append(text)\n            elem.replace_with('[PARAGRAPH_PLACEHOLDER]')\n\n        # Get remaining text\n        remaining_text = element.get_text(separator='\\n', strip=True)\n\n        # Combine all text\n        all_text = '\\n\\n'.join(text_parts)\n        if remaining_text:\n            all_text += '\\n\\n' + remaining_text\n\n        return all_text\n\n    except:\n        pass\n\n    # Strategy 3: Simple text extraction\n    return element.get_text(separator='\\n', strip=True)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.web_search.find_main_content","title":"<code>find_main_content(soup)</code>","text":"<p>Find main content using multiple strategies</p> Source code in <code>toolboxv2/mods/isaa/extras/web_search.py</code> <pre><code>def find_main_content(soup):\n    \"\"\"Find main content using multiple strategies\"\"\"\n\n    # Strategy 1: Look for semantic HTML5 elements\n    for tag in ['main', 'article']:\n        element = soup.find(tag)\n        if element and len(element.get_text(strip=True)) &gt; 300:\n            return element\n\n    # Strategy 2: Look for common content containers\n    content_selectors = [\n        '[role=\"main\"]', '.main-content', '#main-content', '.content', '#content',\n        '.post-content', '.entry-content', '.article-content', '.blog-content',\n        '.story-body', '.article-body', '.post-body'\n    ]\n\n    for selector in content_selectors:\n        element = soup.select_one(selector)\n        if element and len(element.get_text(strip=True)) &gt; 300:\n            return element\n\n    # Strategy 3: Find the div with most text content\n    divs = soup.find_all('div')\n    if divs:\n        content_divs = [(div, len(div.get_text(strip=True))) for div in divs]\n        content_divs = [(div, length) for div, length in content_divs if length &gt; 300]\n\n        if content_divs:\n            content_divs.sort(key=lambda x: x[1], reverse=True)\n            return content_divs[0][0]\n\n    # Strategy 4: Use body as fallback\n    return soup.find('body')\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.web_search.is_content_parseable","title":"<code>is_content_parseable(content)</code>","text":"<p>Check if content is properly parsed and readable</p> Source code in <code>toolboxv2/mods/isaa/extras/web_search.py</code> <pre><code>def is_content_parseable(content: str) -&gt; bool:\n    \"\"\"\n    Check if content is properly parsed and readable\n    \"\"\"\n    if not content or len(content.strip()) &lt; 50:\n        return False\n\n    # Check for too many non-ASCII characters that look like encoding errors\n    total_chars = len(content)\n    if total_chars == 0:\n        return False\n\n    # Count problematic characters\n    problematic_chars = 0\n    replacement_chars = content.count('\ufffd')\n\n    # Check for sequences of garbled characters\n    garbled_patterns = [\n        r'[\u00c0\u00c1\u00c2\u00c3\u00c4\u00c5\u00c6\u00c7\u00c8\u00c9\u00ca\u00cb\u00cc\u00cd\u00ce\u00cf\u00d0\u00d1\u00d2\u00d3\u00d4\u00d5\u00d6\u00d8\u00d9\u00da\u00db\u00dc\u00dd\u00de\u00df\u00e0\u00e1\u00e2\u00e3\u00e4\u00e5\u00e6\u00e7\u00e8\u00e9\u00ea\u00eb\u00ec\u00ed\u00ee\u00ef\u00f0\u00f1\u00f2\u00f3\u00f4\u00f5\u00f6\u00f8\u00f9\u00fa\u00fb\u00fc\u00fd\u00fe\u00ff]{5,}',\n        r'[\u00c3\u00a2\u00c2\u20ac\u00c2\u2122\u00c3\u00a2\u00c2\u20ac\u00c2\u0153\u00c3\u00a2\u00c2\u20ac\u00c2\ufffd]{3,}',\n        r'[\\x80-\\xff]{4,}',  # High-byte sequences\n        r'[^\\x00-\\x7F\\s]{10,}'  # Too many non-ASCII chars in sequence\n    ]\n\n    for pattern in garbled_patterns:\n        matches = re.findall(pattern, content)\n        problematic_chars += sum(len(match) for match in matches)\n\n    # Calculate ratios\n    replacement_ratio = replacement_chars / total_chars\n    problematic_ratio = problematic_chars / total_chars\n\n    # Check for readable English content\n    english_words = re.findall(r'\\b[a-zA-Z]{3,}\\b', content)\n    english_ratio = len(' '.join(english_words)) / total_chars if english_words else 0\n\n    # Criteria for parseable content\n    is_parseable = (\n        replacement_ratio &lt; 0.05 and  # Less than 5% replacement chars\n        problematic_ratio &lt; 0.15 and  # Less than 15% garbled chars\n        english_ratio &gt; 0.3 and  # At least 30% English words\n        len(english_words) &gt; 10  # At least 10 English words\n    )\n\n    if not is_parseable:\n        print(\"Content failed parseability check:\")\n        print(f\"  Replacement ratio: {replacement_ratio:.1%}\")\n        print(f\"  Problematic ratio: {problematic_ratio:.1%}\")\n        print(f\"  English ratio: {english_ratio:.1%}\")\n        print(f\"  English words: {len(english_words)}\")\n\n    return is_parseable\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.web_search.is_mostly_readable","title":"<code>is_mostly_readable(text)</code>","text":"<p>Check if text is mostly readable ASCII/common unicode</p> Source code in <code>toolboxv2/mods/isaa/extras/web_search.py</code> <pre><code>def is_mostly_readable(text: str) -&gt; bool:\n    \"\"\"Check if text is mostly readable ASCII/common unicode\"\"\"\n    if not text:\n        return False\n\n    readable_chars = sum(1 for c in text if c.isprintable() or c.isspace())\n    return readable_chars / len(text) &gt; 0.8\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.web_search.robust_search","title":"<code>robust_search()</code>","text":"<p>Test the robust search functionality</p> Source code in <code>toolboxv2/mods/isaa/extras/web_search.py</code> <pre><code>def robust_search():\n    \"\"\"Test the robust search functionality\"\"\"\n    query = \"Python web scraping best practices\"\n    results = web_search(query, max_results=3)\n\n    print(f\"\\n{'=' * 60}\")\n    print(f\"FINAL RESULTS FOR: '{query}'\")\n    print(f\"{'=' * 60}\")\n\n    for i, result in enumerate(results, 1):\n        print(f\"\\n{i}. {result['title']}\")\n        print(f\"URL: {result['url']}\")\n        print(f\"Content length: {len(result['content'])} characters\")\n        print(f\"First 300 chars: {result['content'][:300]}...\")\n\n        # Show parseability stats\n        content = result['content']\n        ascii_ratio = sum(1 for c in content if ord(c) &lt; 128) / len(content)\n        print(f\"ASCII ratio: {ascii_ratio:.1%}\")\n        print(\"-\" * 80)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.web_search.url_to_markdown_robust","title":"<code>url_to_markdown_robust(url)</code>","text":"<p>Robust URL to markdown converter with multiple encoding strategies</p> Source code in <code>toolboxv2/mods/isaa/extras/web_search.py</code> <pre><code>def url_to_markdown_robust(url: str) -&gt; str | None:\n    \"\"\"\n    Robust URL to markdown converter with multiple encoding strategies\n    \"\"\"\n    try:\n        headers = {\n            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n            'Accept-Language': 'en-US,en;q=0.9',\n            'Accept-Charset': 'utf-8, iso-8859-1;q=0.5',\n            'Connection': 'keep-alive'\n        }\n\n        response = requests.get(url, headers=headers, timeout=20, allow_redirects=True)\n        response.raise_for_status()\n\n        # Quick content type check\n        content_type = response.headers.get('content-type', '').lower()\n        if not any(ct in content_type for ct in ['text/html', 'text/plain', 'application/xhtml']):\n            print(f\"Skipping non-HTML content: {content_type}\")\n            return None\n\n        # Get raw content\n        raw_content = response.content\n\n        # Strategy 1: Try response encoding first if it looks reliable\n        decoded_content = None\n        used_encoding = None\n\n        response_encoding = response.encoding\n        if response_encoding and response_encoding.lower() not in ['iso-8859-1', 'ascii']:\n            try:\n                decoded_content = response.text\n                used_encoding = response_encoding\n                # Quick test for encoding quality\n                if '\ufffd' in decoded_content or not is_mostly_readable(decoded_content[:1000]):\n                    decoded_content = None\n            except:\n                pass\n\n        # Strategy 2: Detect encoding from content\n        if not decoded_content:\n            try:\n                detected = chardet.detect(raw_content)\n                if detected and detected.get('confidence', 0) &gt; 0.8:\n                    decoded_content = raw_content.decode(detected['encoding'])\n                    used_encoding = detected['encoding']\n                    if '\ufffd' in decoded_content or not is_mostly_readable(decoded_content[:1000]):\n                        decoded_content = None\n            except:\n                pass\n\n        # Strategy 3: Extract encoding from HTML meta tags\n        if not decoded_content:\n            try:\n                # Try UTF-8 first to read meta tags\n                temp_content = raw_content.decode('utf-8', errors='ignore')[:2048]\n                charset_patterns = [\n                    r'&lt;meta[^&gt;]+charset[\"\\'\\s]*=[\"\\'\\s]*([^\"\\'&gt;\\s]+)',\n                    r'&lt;meta[^&gt;]+content[^&gt;]+charset=([^\"\\'&gt;\\s;]+)',\n                    r'&lt;\\?xml[^&gt;]+encoding[\"\\'\\s]*=[\"\\'\\s]*([^\"\\'&gt;\\s]+)'\n                ]\n\n                for pattern in charset_patterns:\n                    match = re.search(pattern, temp_content, re.I)\n                    if match:\n                        encoding = match.group(1).strip().lower()\n                        try:\n                            decoded_content = raw_content.decode(encoding)\n                            used_encoding = encoding\n                            if not ('\ufffd' in decoded_content or not is_mostly_readable(decoded_content[:1000])):\n                                break\n                        except:\n                            pass\n                        decoded_content = None\n            except:\n                pass\n\n        # Strategy 4: Try common encodings\n        if not decoded_content:\n            common_encodings = ['utf-8', 'utf-8-sig', 'latin1', 'cp1252', 'iso-8859-1']\n            for encoding in common_encodings:\n                try:\n                    test_content = raw_content.decode(encoding)\n                    if is_mostly_readable(test_content[:1000]) and '\ufffd' not in test_content[:1000]:\n                        decoded_content = test_content\n                        used_encoding = encoding\n                        break\n                except:\n                    continue\n\n        # Strategy 5: Last resort with error handling\n        if not decoded_content:\n            decoded_content = raw_content.decode('utf-8', errors='replace')\n            used_encoding = 'utf-8 (with errors)'\n\n        print(f\"Used encoding: {used_encoding}\")\n\n        # Parse with BeautifulSoup\n        soup = BeautifulSoup(decoded_content, 'html.parser')\n\n        # Remove all unwanted elements aggressively\n        unwanted_tags = ['script', 'style', 'nav', 'header', 'footer', 'aside', 'iframe',\n                         'form', 'button', 'input', 'noscript', 'meta', 'link', 'svg']\n        for tag in unwanted_tags:\n            for element in soup.find_all(tag):\n                element.decompose()\n\n        # Remove elements with unwanted classes/ids\n        unwanted_patterns = [\n            r'.*ad[s]?[-_].*', r'.*banner.*', r'.*popup.*', r'.*modal.*',\n            r'.*cookie.*', r'.*newsletter.*', r'.*social.*', r'.*share.*',\n            r'.*comment.*', r'.*sidebar.*', r'.*menu.*', r'.*navigation.*'\n        ]\n\n        for pattern in unwanted_patterns:\n            for attr in ['class', 'id']:\n                for element in soup.find_all(attrs={attr: re.compile(pattern, re.I)}):\n                    element.decompose()\n\n        # Find main content with multiple strategies\n        main_content = find_main_content(soup)\n\n        if not main_content:\n            print(\"No main content found\")\n            return None\n\n        # Convert to markdown using multiple strategies\n        markdown_content = convert_to_markdown(main_content)\n\n        if not markdown_content:\n            print(\"Markdown conversion failed\")\n            return None\n\n        # Clean and validate\n        cleaned_content = clean_markdown_robust(markdown_content)\n\n        # Final validation\n        if not is_content_parseable(cleaned_content):\n            print(\"Content failed parseability check\")\n            return None\n\n        return cleaned_content\n\n    except Exception as e:\n        print(f\"Error processing {url}: {e}\")\n        return None\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.web_search.web_search","title":"<code>web_search(query, max_results=5)</code>","text":"<p>Main search function with robust fallbacks</p> Source code in <code>toolboxv2/mods/isaa/extras/web_search.py</code> <pre><code>def web_search(query: str, max_results: int = 5) -&gt; list[dict[str, str]]:\n    \"\"\"\n    Main search function with robust fallbacks\n    \"\"\"\n    # Try API searches first if available\n    api_keys = {\n        'serpapi': os.getenv('SERPAPI_API_KEY'),\n        'bing': os.getenv('BING_API_KEY')\n    }\n    if isinstance(max_results, str):\n        if max_results.startswith('\"') and max_results.endswith('\"') or max_results.startswith(\"'\") and max_results.endswith(\"'\"):\n            max_results = max_results[1:-1]\n        max_results = int(max_results.strip())\n    if api_keys:\n        for api_name, api_key in api_keys.items():\n            if api_key:\n                try:\n                    print(f\"Trying {api_name.upper()} API...\")\n                    if api_name == 'serpapi':\n                        results = web_search_serpapi(query, max_results, api_key)\n                    elif api_name == 'bing':\n                        results = web_search_bing(query, max_results, api_key)\n                    else:\n                        continue\n\n                    if results and len(results) &gt;= max_results:\n                        return results\n                except Exception as e:\n                    print(f\"{api_name.upper()} API failed: {e}\")\n\n    # Use robust DuckDuckGo search\n    return web_search_robust(query, max_results)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.web_search.web_search_bing","title":"<code>web_search_bing(query, max_results=5, api_key=None)</code>","text":"<p>Web search using Bing Search API (free tier: 3,000 queries/month) Get your free API key at: https://azure.microsoft.com/en-us/services/cognitive-services/bing-web-search-api/</p> Source code in <code>toolboxv2/mods/isaa/extras/web_search.py</code> <pre><code>def web_search_bing(query: str, max_results: int = 5, api_key: str = None) -&gt; list[dict[str, str]]:\n    \"\"\"\n    Web search using Bing Search API (free tier: 3,000 queries/month)\n    Get your free API key at: https://azure.microsoft.com/en-us/services/cognitive-services/bing-web-search-api/\n    \"\"\"\n    if not api_key:\n        print(\"Please get a free API key from Azure Cognitive Services\")\n        return []\n\n    try:\n        url = \"https://api.bing.microsoft.com/v7.0/search\"\n        headers = {\n            \"Ocp-Apim-Subscription-Key\": api_key\n        }\n        params = {\n            \"q\": query,\n            \"count\": max_results,\n            \"textDecorations\": False,\n            \"textFormat\": \"HTML\"\n        }\n\n        response = requests.get(url, headers=headers, params=params)\n        response.raise_for_status()\n        data = response.json()\n\n        results = []\n        if \"webPages\" in data and \"value\" in data[\"webPages\"]:\n            for result in data[\"webPages\"][\"value\"][:max_results]:\n                url_link = result.get(\"url\", \"\")\n                title = result.get(\"name\", \"\")\n\n                print(f\"Processing: {title}\")\n                markdown_content = url_to_markdown_robust(url_link)\n\n                if markdown_content:\n                    results.append({\n                        'url': url_link,\n                        'title': title,\n                        'content': markdown_content\n                    })\n\n                # time.sleep(1)\n\n        return results\n\n    except Exception as e:\n        print(f\"Bing search error: {e}\")\n        return []\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.web_search.web_search_robust","title":"<code>web_search_robust(query, max_results=5, max_attempts=15)</code>","text":"<p>Robust search that keeps trying until it gets enough good results</p> Source code in <code>toolboxv2/mods/isaa/extras/web_search.py</code> <pre><code>def web_search_robust(query: str, max_results: int = 5, max_attempts: int = 15) -&gt; list[dict[str, str]]:\n    \"\"\"\n    Robust search that keeps trying until it gets enough good results\n    \"\"\"\n    if isinstance(max_results, str):\n        if max_results.startswith('\"') and max_results.endswith('\"') or max_results.startswith(\"'\") and max_results.endswith(\"'\"):\n            max_results = max_results[1:-1]\n        max_results = int(max_results.strip())\n    if isinstance(max_attempts, str):\n        if max_attempts.startswith('\"') and max_attempts.endswith('\"') or max_attempts.startswith(\"'\") and max_attempts.endswith(\"'\"):\n            max_attempts = max_attempts[1:-1]\n        max_attempts = int(max_attempts.strip())\n\n    def get_more_search_urls(search_query: str, num_urls: int = 15) -&gt; list[dict[str, str]]:\n        \"\"\"Get more URLs than needed so we can filter out bad ones\"\"\"\n        try:\n            headers = {\n                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',\n                'Accept': 'text/html,application/xhtml+xml',\n                'Accept-Language': 'en-US,en;q=0.9',\n            }\n\n            # Try DuckDuckGo lite\n            search_url = \"https://lite.duckduckgo.com/lite/\"\n            data = {'q': search_query}\n\n            response = requests.post(search_url, data=data, headers=headers, timeout=15)\n            response.raise_for_status()\n\n            soup = BeautifulSoup(response.content, 'html.parser')\n            results = []\n\n            for link in soup.find_all('a', href=True):\n                href = link.get('href', '')\n                text = link.get_text(strip=True)\n\n                if (href.startswith('http') and\n                    'duckduckgo.com' not in href and\n                    len(text) &gt; 5 and\n                    not any(skip in href.lower() for skip in ['ads', 'shopping', 'images'])):\n\n                    results.append({\n                        'url': href,\n                        'title': text[:150]\n                    })\n\n                    if len(results) &gt;= num_urls:\n                        break\n\n            return results\n\n        except Exception as e:\n            print(f\"Search error: {e}\")\n            return []\n\n    def get_fallback_urls(search_query: str) -&gt; list[dict[str, str]]:\n        \"\"\"Get fallback URLs from known good sites\"\"\"\n        encoded_query = quote_plus(search_query)\n        fallback_urls = [\n            f\"https://stackoverflow.com/search?q={encoded_query}\",\n            f\"https://www.reddit.com/search/?q={encoded_query}\",\n            f\"https://medium.com/search?q={encoded_query}\",\n            f\"https://dev.to/search?q={encoded_query}\",\n            f\"https://github.com/search?q={encoded_query}&amp;type=repositories\",\n            f\"https://docs.python.org/3/search.html?q={encoded_query}\",\n            f\"https://realpython.com/?s={encoded_query}\",\n            f\"https://towardsdatascience.com/search?q={encoded_query}\",\n            f\"https://www.geeksforgeeks.org/?s={encoded_query}\",\n            f\"https://hackernoon.com/search?query={encoded_query}\"\n        ]\n\n        return [\n            {'url': url, 'title': f\"Search results for '{search_query}'\"}\n            for url in fallback_urls\n        ]\n\n    print(f\"Searching for: '{query}' (need {max_results} good results)\")\n\n    # Get candidate URLs\n    candidate_urls = get_more_search_urls(query, max_attempts)\n\n    if not candidate_urls:\n        print(\"Primary search failed, using fallback URLs...\")\n        candidate_urls = get_fallback_urls(query)\n\n    print(f\"Found {len(candidate_urls)} candidate URLs\")\n\n    # Process URLs until we have enough good results\n    good_results = []\n    processed_count = 0\n\n    def task(candidate):\n        markdown_content = url_to_markdown_robust(candidate['url'])\n        if markdown_content:\n            return {\n                'url': candidate['url'],\n                'title': candidate['title'],\n                'content': markdown_content\n            }\n\n    # runn all tasks in parallel\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        results = list(executor.map(task, candidate_urls))\n        processed_count = len(candidate_urls)\n\n    good_results = [result for result in results if result]\n\n    #for candidate in candidate_urls:\n    #    if len(good_results) &gt;= max_results:\n    #        break\n\n    #    processed_count += 1\n    #    print(f\"\\n[{processed_count}/{len(candidate_urls)}] Processing: {candidate['title'][:80]}...\")\n\n    #    markdown_content = url_to_markdown_robust(candidate['url'])\n\n    #    if markdown_content:\n    #        good_results.append({\n    #            'url': candidate['url'],\n    #            'title': candidate['title'],\n    #            'content': markdown_content\n    #        })\n    #        print(f\"\u2705 Success! Got result {len(good_results)}/{max_results}\")\n    #    else:\n    #        print(\"\u274c Skipped (unparseable or low quality)\")\n\n    #    # Small delay to be respectful\n    #    time.sleep(1.5)\n\n    print(f\"\\n\ud83c\udf89 Final results: {len(good_results)} good results out of {processed_count} attempted\")\n    return good_results\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.extras.web_search.web_search_serpapi","title":"<code>web_search_serpapi(query, max_results=5, api_key=None)</code>","text":"<p>Web search using SerpAPI (free tier: 100 searches/month) Get your free API key at: https://serpapi.com/</p> Source code in <code>toolboxv2/mods/isaa/extras/web_search.py</code> <pre><code>def web_search_serpapi(query: str, max_results: int = 5, api_key: str = None) -&gt; list[dict[str, str]]:\n    \"\"\"\n    Web search using SerpAPI (free tier: 100 searches/month)\n    Get your free API key at: https://serpapi.com/\n    \"\"\"\n    if not api_key:\n        print(\"Please get a free API key from https://serpapi.com/\")\n        return []\n\n    try:\n        url = \"https://serpapi.com/search\"\n        params = {\n            \"engine\": \"google\",\n            \"q\": query,\n            \"api_key\": api_key,\n            \"num\": max_results\n        }\n\n        response = requests.get(url, params=params)\n        response.raise_for_status()\n        data = response.json()\n\n        results = []\n        if \"organic_results\" in data:\n            for result in data[\"organic_results\"][:max_results]:\n                url_link = result.get(\"link\", \"\")\n                title = result.get(\"title\", \"\")\n\n                print(f\"Processing: {title}\")\n                markdown_content = url_to_markdown_robust(url_link)\n\n                if markdown_content:\n                    results.append({\n                        'url': url_link,\n                        'title': title,\n                        'content': markdown_content\n                    })\n\n                #time.sleep(1)  # Be respectful\n\n        return results\n\n    except Exception as e:\n        print(f\"SerpAPI search error: {e}\")\n        return []\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.module","title":"<code>module</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.isaa.module.EnhancedAgentRequestHandler","title":"<code>EnhancedAgentRequestHandler</code>","text":"<p>               Bases: <code>BaseHTTPRequestHandler</code></p> <p>Enhanced HTTP request handler for standalone server with comprehensive UI support.</p> Source code in <code>toolboxv2/mods/isaa/module.py</code> <pre><code>class EnhancedAgentRequestHandler(BaseHTTPRequestHandler):\n    \"\"\"Enhanced HTTP request handler for standalone server with comprehensive UI support.\"\"\"\n\n    def __init__(self, isaa_mod, agent_id: str, agent, *args, **kwargs):\n        self.isaa_mod = isaa_mod\n        self.agent_id = agent_id\n        self.agent = agent\n        super().__init__(*args, **kwargs)\n\n    def do_GET(self):\n        \"\"\"Handle GET requests for enhanced UI and status.\"\"\"\n        parsed_path = urlparse(self.path)\n\n        if parsed_path.path in ['/', '/ui']:\n            self._serve_enhanced_ui()\n        elif parsed_path.path in ['/api/status', '/api/agent_ui/status', '/status']:\n            self._serve_status()\n        else:\n            self._send_404()\n\n    def do_POST(self):\n        \"\"\"Handle POST requests for enhanced API endpoints.\"\"\"\n        parsed_path = urlparse(self.path)\n\n        if parsed_path.path in ['/api/run', '/api/agent_ui/run_agent']:\n            self._handle_run_request()\n        elif parsed_path.path in ['/api/reset', '/api/agent_ui/reset_context']:\n            self._handle_reset_request()\n        else:\n            self._send_404()\n\n    def _serve_enhanced_ui(self):\n        \"\"\"Serve the enhanced UI HTML.\"\"\"\n        try:\n            html_content = get_agent_ui_html()\n\n            self.send_response(200)\n            self.send_header('Content-type', 'text/html')\n            self.send_header('Content-Length', str(len(html_content.encode('utf-8'))))\n            self.end_headers()\n            self.wfile.write(html_content.encode('utf-8'))\n\n        except Exception as e:\n            self._send_error_response(500, f\"Error serving UI: {str(e)}\")\n\n    def _serve_status(self):\n        \"\"\"Serve enhanced status information.\"\"\"\n        try:\n            status_info = {\n                'agent_id': self.agent_id,\n                'agent_name': getattr(self.agent, 'name', 'Unknown'),\n                'agent_type': self.agent.__class__.__name__,\n                'status': 'active',\n                'server_type': 'standalone',\n                'timestamp': time.time()\n            }\n\n            if hasattr(self.agent, 'status'):\n                try:\n                    agent_status = self.agent.status()\n                    if isinstance(agent_status, dict):\n                        status_info['agent_status'] = agent_status\n                except:\n                    pass\n\n            response_data = json.dumps(status_info).encode('utf-8')\n\n            self.send_response(200)\n            self.send_header('Content-type', 'application/json')\n            self.send_header('Content-Length', str(len(response_data)))\n            self.end_headers()\n            self.wfile.write(response_data)\n\n        except Exception as e:\n            self._send_error_response(500, f\"Error getting status: {str(e)}\")\n\n    def _handle_run_request(self):\n        \"\"\"Handle enhanced run requests with comprehensive progress tracking.\"\"\"\n        try:\n            content_length = int(self.headers['Content-Length'])\n            request_body = self.rfile.read(content_length)\n            request_data = json.loads(request_body.decode('utf-8'))\n\n            query = request_data.get('query', '')\n            session_id = request_data.get('session_id', f'standalone_{secrets.token_hex(8)}')\n            include_progress = request_data.get('include_progress', False)\n\n            if not query:\n                self._send_error_response(400, \"Missing 'query' field\")\n                return\n\n            # Run agent with enhanced progress tracking\n            loop = asyncio.new_event_loop()\n            asyncio.set_event_loop(loop)\n\n            try:\n                progress_tracker = EnhancedProgressTracker()\n                progress_events = []\n                enhanced_progress = {}\n\n                async def standalone_progress_callback(event: ProgressEvent):\n                    if include_progress:\n                        progress_data = progress_tracker.extract_progress_data(event)\n                        progress_events.append({\n                            'timestamp': event.timestamp,\n                            'event_type': event.event_type,\n                            'status': getattr(event, 'status', 'unknown').value if hasattr(event, 'status') and event.status else 'unknown',\n                            'data': event.to_dict()\n                        })\n                        enhanced_progress.update(progress_data)\n\n                # Set progress callback\n                original_callback = getattr(self.agent, 'progress_callback', None)\n\n                if hasattr(self.agent, 'set_progress_callback'):\n                    self.agent.set_progress_callback(standalone_progress_callback)\n                elif hasattr(self.agent, 'progress_callback'):\n                    self.agent.progress_callback = standalone_progress_callback\n\n                # Execute agent\n                result = loop.run_until_complete(\n                    self.agent.a_run(query=query, session_id=session_id)\n                )\n\n                # Restore callback\n                if hasattr(self.agent, 'set_progress_callback'):\n                    self.agent.set_progress_callback(original_callback)\n                elif hasattr(self.agent, 'progress_callback'):\n                    self.agent.progress_callback = original_callback\n\n                # Create enhanced response\n                response_data = {\n                    'success': True,\n                    'result': result,\n                    'session_id': session_id,\n                    'agent_id': self.agent_id,\n                    'server_type': 'standalone',\n                    'timestamp': time.time()\n                }\n\n                if include_progress:\n                    response_data.update({\n                        'progress_events': progress_events,\n                        'enhanced_progress': enhanced_progress,\n                        'final_summary': progress_tracker.get_final_summary()\n                    })\n                self._send_json_response(response_data)\n\n            finally:\n                loop.close()\n\n        except Exception as e:\n            self._send_error_response(500, f\"Execution error: {str(e)}\")\n            import traceback\n            print(traceback.format_exc())\n\n    def _handle_reset_request(self):\n        \"\"\"Handle enhanced reset requests.\"\"\"\n        try:\n            success = False\n            message = \"Reset not supported\"\n\n            if hasattr(self.agent, 'clear_context'):\n                self.agent.clear_context()\n                success = True\n                message = \"Context reset successfully\"\n            elif hasattr(self.agent, 'reset'):\n                self.agent.reset()\n                success = True\n                message = \"Agent reset successfully\"\n\n            response_data = {\n                'success': success,\n                'message': message,\n                'agent_id': self.agent_id,\n                'timestamp': time.time()\n            }\n\n            self._send_json_response(response_data)\n\n        except Exception as e:\n            self._send_error_response(500, f\"Reset error: {str(e)}\")\n\n    def _send_json_response(self, data: dict):\n        \"\"\"Send JSON response with CORS headers.\"\"\"\n        response_body = json.dumps(data, cls=CustomJSONEncoder).encode('utf-8')\n\n        self.send_response(200)\n        self.send_header('Content-type', 'application/json')\n        self.send_header('Content-Length', str(len(response_body)))\n        self.send_header('Access-Control-Allow-Origin', '*')\n        self.send_header('Access-Control-Allow-Methods', 'GET, POST, OPTIONS')\n        self.send_header('Access-Control-Allow-Headers', 'Content-Type')\n        self.end_headers()\n        self.wfile.write(response_body)\n\n    def _send_error_response(self, code: int, message: str):\n        \"\"\"Send error response.\"\"\"\n        error_data = {'success': False, 'error': message, 'code': code}\n        response_body = json.dumps(error_data).encode('utf-8')\n\n        self.send_response(code)\n        self.send_header('Content-type', 'application/json')\n        self.send_header('Content-Length', str(len(response_body)))\n        self.end_headers()\n        self.wfile.write(response_body)\n\n    def _send_404(self):\n        \"\"\"Send 404 response.\"\"\"\n        self._send_error_response(404, \"Not Found\")\n\n    def log_message(self, format, *args):\n        \"\"\"Override to reduce logging noise.\"\"\"\n        pass\n\n    def do_OPTIONS(self):\n        \"\"\"Handle preflight CORS requests.\"\"\"\n        self.send_response(200)\n        self.send_header('Access-Control-Allow-Origin', '*')\n        self.send_header('Access-Control-Allow-Methods', 'GET, POST, OPTIONS')\n        self.send_header('Access-Control-Allow-Headers', 'Content-Type')\n        self.end_headers()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.module.EnhancedAgentRequestHandler.do_GET","title":"<code>do_GET()</code>","text":"<p>Handle GET requests for enhanced UI and status.</p> Source code in <code>toolboxv2/mods/isaa/module.py</code> <pre><code>def do_GET(self):\n    \"\"\"Handle GET requests for enhanced UI and status.\"\"\"\n    parsed_path = urlparse(self.path)\n\n    if parsed_path.path in ['/', '/ui']:\n        self._serve_enhanced_ui()\n    elif parsed_path.path in ['/api/status', '/api/agent_ui/status', '/status']:\n        self._serve_status()\n    else:\n        self._send_404()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.module.EnhancedAgentRequestHandler.do_OPTIONS","title":"<code>do_OPTIONS()</code>","text":"<p>Handle preflight CORS requests.</p> Source code in <code>toolboxv2/mods/isaa/module.py</code> <pre><code>def do_OPTIONS(self):\n    \"\"\"Handle preflight CORS requests.\"\"\"\n    self.send_response(200)\n    self.send_header('Access-Control-Allow-Origin', '*')\n    self.send_header('Access-Control-Allow-Methods', 'GET, POST, OPTIONS')\n    self.send_header('Access-Control-Allow-Headers', 'Content-Type')\n    self.end_headers()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.module.EnhancedAgentRequestHandler.do_POST","title":"<code>do_POST()</code>","text":"<p>Handle POST requests for enhanced API endpoints.</p> Source code in <code>toolboxv2/mods/isaa/module.py</code> <pre><code>def do_POST(self):\n    \"\"\"Handle POST requests for enhanced API endpoints.\"\"\"\n    parsed_path = urlparse(self.path)\n\n    if parsed_path.path in ['/api/run', '/api/agent_ui/run_agent']:\n        self._handle_run_request()\n    elif parsed_path.path in ['/api/reset', '/api/agent_ui/reset_context']:\n        self._handle_reset_request()\n    else:\n        self._send_404()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.module.EnhancedAgentRequestHandler.log_message","title":"<code>log_message(format, *args)</code>","text":"<p>Override to reduce logging noise.</p> Source code in <code>toolboxv2/mods/isaa/module.py</code> <pre><code>def log_message(self, format, *args):\n    \"\"\"Override to reduce logging noise.\"\"\"\n    pass\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.module.EnhancedProgressTracker","title":"<code>EnhancedProgressTracker</code>","text":"<p>Enhanced progress tracker for detailed UI updates.</p> Source code in <code>toolboxv2/mods/isaa/module.py</code> <pre><code>class EnhancedProgressTracker:\n    \"\"\"Enhanced progress tracker for detailed UI updates.\"\"\"\n\n    def __init__(self):\n        self.session_state = {}\n        self.last_outline_update = None\n        self.last_activity_update = None\n\n    def extract_progress_data(self, event: ProgressEvent) -&gt; dict[str, Any]:\n        \"\"\"Extract comprehensive progress data from event.\"\"\"\n        progress_data = {}\n\n        # Outline progress\n        if hasattr(event, 'outline_data') or 'outline' in event.metadata:\n            outline_info = getattr(event, 'outline_data', event.metadata.get('outline', {}))\n            progress_data['outline'] = {\n                'current_step': outline_info.get('current_step', 'Unknown'),\n                'total_steps': outline_info.get('total_steps', 0),\n                'step_name': outline_info.get('step_name', 'Processing'),\n                'progress_percentage': outline_info.get('progress_percentage', 0),\n                'substeps': outline_info.get('substeps', []),\n                'estimated_completion': outline_info.get('estimated_completion')\n            }\n\n        # Activity information\n        if hasattr(event, 'activity_data') or 'activity' in event.metadata:\n            activity_info = getattr(event, 'activity_data', event.metadata.get('activity', {}))\n            progress_data['activity'] = {\n                'current_action': activity_info.get('current_action', 'Processing'),\n                'action_details': activity_info.get('action_details', ''),\n                'start_time': activity_info.get('start_time'),\n                'elapsed_time': activity_info.get('elapsed_time'),\n                'expected_duration': activity_info.get('expected_duration')\n            }\n\n        # Meta tool information\n        if hasattr(event, 'meta_tool_data') or 'meta_tool' in event.metadata:\n            meta_tool_info = getattr(event, 'meta_tool_data', event.metadata.get('meta_tool', {}))\n            progress_data['meta_tool'] = {\n                'tool_name': meta_tool_info.get('tool_name', 'Unknown'),\n                'tool_status': meta_tool_info.get('tool_status', 'active'),\n                'tool_input': meta_tool_info.get('tool_input', ''),\n                'tool_output': meta_tool_info.get('tool_output', ''),\n                'execution_time': meta_tool_info.get('execution_time')\n            }\n\n        # System status\n        if hasattr(event, 'system_data') or 'system' in event.metadata:\n            system_info = getattr(event, 'system_data', event.metadata.get('system', {}))\n            progress_data['system'] = {\n                'memory_usage': system_info.get('memory_usage', 0),\n                'cpu_usage': system_info.get('cpu_usage', 0),\n                'active_threads': system_info.get('active_threads', 1),\n                'queue_size': system_info.get('queue_size', 0)\n            }\n\n        # Graph/workflow information\n        if hasattr(event, 'graph_data') or 'graph' in event.metadata:\n            graph_info = getattr(event, 'graph_data', event.metadata.get('graph', {}))\n            progress_data['graph'] = {\n                'current_node': graph_info.get('current_node', 'Unknown'),\n                'completed_nodes': graph_info.get('completed_nodes', []),\n                'remaining_nodes': graph_info.get('remaining_nodes', []),\n                'node_connections': graph_info.get('node_connections', []),\n                'execution_path': graph_info.get('execution_path', [])\n            }\n\n        return progress_data\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.module.EnhancedProgressTracker.extract_progress_data","title":"<code>extract_progress_data(event)</code>","text":"<p>Extract comprehensive progress data from event.</p> Source code in <code>toolboxv2/mods/isaa/module.py</code> <pre><code>def extract_progress_data(self, event: ProgressEvent) -&gt; dict[str, Any]:\n    \"\"\"Extract comprehensive progress data from event.\"\"\"\n    progress_data = {}\n\n    # Outline progress\n    if hasattr(event, 'outline_data') or 'outline' in event.metadata:\n        outline_info = getattr(event, 'outline_data', event.metadata.get('outline', {}))\n        progress_data['outline'] = {\n            'current_step': outline_info.get('current_step', 'Unknown'),\n            'total_steps': outline_info.get('total_steps', 0),\n            'step_name': outline_info.get('step_name', 'Processing'),\n            'progress_percentage': outline_info.get('progress_percentage', 0),\n            'substeps': outline_info.get('substeps', []),\n            'estimated_completion': outline_info.get('estimated_completion')\n        }\n\n    # Activity information\n    if hasattr(event, 'activity_data') or 'activity' in event.metadata:\n        activity_info = getattr(event, 'activity_data', event.metadata.get('activity', {}))\n        progress_data['activity'] = {\n            'current_action': activity_info.get('current_action', 'Processing'),\n            'action_details': activity_info.get('action_details', ''),\n            'start_time': activity_info.get('start_time'),\n            'elapsed_time': activity_info.get('elapsed_time'),\n            'expected_duration': activity_info.get('expected_duration')\n        }\n\n    # Meta tool information\n    if hasattr(event, 'meta_tool_data') or 'meta_tool' in event.metadata:\n        meta_tool_info = getattr(event, 'meta_tool_data', event.metadata.get('meta_tool', {}))\n        progress_data['meta_tool'] = {\n            'tool_name': meta_tool_info.get('tool_name', 'Unknown'),\n            'tool_status': meta_tool_info.get('tool_status', 'active'),\n            'tool_input': meta_tool_info.get('tool_input', ''),\n            'tool_output': meta_tool_info.get('tool_output', ''),\n            'execution_time': meta_tool_info.get('execution_time')\n        }\n\n    # System status\n    if hasattr(event, 'system_data') or 'system' in event.metadata:\n        system_info = getattr(event, 'system_data', event.metadata.get('system', {}))\n        progress_data['system'] = {\n            'memory_usage': system_info.get('memory_usage', 0),\n            'cpu_usage': system_info.get('cpu_usage', 0),\n            'active_threads': system_info.get('active_threads', 1),\n            'queue_size': system_info.get('queue_size', 0)\n        }\n\n    # Graph/workflow information\n    if hasattr(event, 'graph_data') or 'graph' in event.metadata:\n        graph_info = getattr(event, 'graph_data', event.metadata.get('graph', {}))\n        progress_data['graph'] = {\n            'current_node': graph_info.get('current_node', 'Unknown'),\n            'completed_nodes': graph_info.get('completed_nodes', []),\n            'remaining_nodes': graph_info.get('remaining_nodes', []),\n            'node_connections': graph_info.get('node_connections', []),\n            'execution_path': graph_info.get('execution_path', [])\n        }\n\n    return progress_data\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.module.Tools","title":"<code>Tools</code>","text":"<p>               Bases: <code>MainTool</code>, <code>FileHandler</code></p> Source code in <code>toolboxv2/mods/isaa/module.py</code> <pre><code>class Tools(MainTool, FileHandler):\n\n    def __init__(self, app=None):\n\n        self.run_callback = None\n        # self.coding_projects: dict[str, ProjectManager] = {} # Assuming ProjectManager is defined elsewhere or removed\n        if app is None:\n            app = get_app(\"isaa-mod\")\n        self.version = version\n        self.name = \"isaa\"\n        self.Name = \"isaa\"\n        self.color = \"VIOLET2\"\n        self.config = {'controller-init': False,\n                       'agents-name-list': [], # TODO Remain ComplexModel FastModel BlitzModel, AudioModel, (ImageModel[i/o], VideoModel[i/o]), SummaryModel\n                       \"FASTMODEL\": os.getenv(\"FASTMODEL\", \"ollama/llama3.1\"),\n                       \"AUDIOMODEL\": os.getenv(\"AUDIOMODEL\", \"groq/whisper-large-v3-turbo\"),\n                       \"BLITZMODEL\": os.getenv(\"BLITZMODEL\", \"ollama/llama3.1\"),\n                       \"COMPLEXMODEL\": os.getenv(\"COMPLEXMODEL\", \"ollama/llama3.1\"),\n                       \"SUMMARYMODEL\": os.getenv(\"SUMMARYMODEL\", \"ollama/llama3.1\"),\n                       \"IMAGEMODEL\": os.getenv(\"IMAGEMODEL\", \"ollama/llama3.1\"),\n                       \"DEFAULTMODELEMBEDDING\": os.getenv(\"DEFAULTMODELEMBEDDING\", \"gemini/text-embedding-004\"),\n                       }\n        self.per_data = {}\n        self.agent_data: dict[str, dict] = {}  # Will store AgentConfig dicts\n        self.keys = {\n            \"KEY\": \"key~~~~~~~\",\n            \"Config\": \"config~~~~\"\n        }\n        self.initstate = {}\n\n        extra_path = \"\"\n        if self.toolID:  # MainTool attribute\n            extra_path = f\"/{self.toolID}\"\n        self.observation_term_mem_file = f\"{app.data_dir}/Memory{extra_path}/observationMemory/\"\n        self.config['controller_file'] = f\"{app.data_dir}{extra_path}/controller.json\"\n        self.mas_text_summaries_dict = FileCache(folder=f\"{app.data_dir}/Memory{extra_path}/summaries/\")\n        self.tools = {\n            \"name\": \"isaa\",\n            \"Version\": self.show_version,\n            \"mini_task_completion\": self.mini_task_completion,\n            \"run_agent\": self.run_agent,\n            \"save_to_mem\": self.save_to_mem_sync,\n            \"get_agent\": self.get_agent,\n            \"format_class\": self.format_class,  # Now async\n            \"get_memory\": self.get_memory,\n            \"rget_mode\": lambda mode: self.controller.rget(mode),\n        }\n        self.tools_interfaces: dict[str, ToolsInterface] = {}\n        self.working_directory = os.getenv('ISAA_WORKING_PATH', os.getcwd())\n        self.print_stream = stram_print\n        self.global_stream_override = False  # Handled by FlowAgentBuilder\n        self.lang_chain_tools_dict: dict[str, Any] = {}  # Store actual tool objects for wrapping\n\n        self.agent_memory: AISemanticMemory = f\"{app.id}{extra_path}/Memory\"  # Path for AISemanticMemory\n        self.controller = ControllerManager({})\n        self.summarization_mode = 1\n        self.summarization_limiter = 102000\n        self.speak = lambda x, *args, **kwargs: x  # Placeholder\n        self.scripts = Scripts(f\"{app.data_dir}{extra_path}/ScriptFile\")\n\n        self.default_setter = None  # For agent builder customization\n        self.initialized = False\n\n        FileHandler.__init__(self, f\"isaa{extra_path.replace('/', '-')}.config\", app.id if app else __name__)\n        MainTool.__init__(self, load=self.on_start, v=self.version, tool=self.tools,\n                          name=self.name, logs=None, color=self.color, on_exit=self.on_exit)\n        self.web_search = web_search\n        self.shell_tool_function = shell_tool_function\n        self.tools[\"shell\"] = shell_tool_function\n\n        self.print(f\"Start {self.spec}.isaa\")\n        with Spinner(message=\"Starting module\", symbols='c'):\n            self.load_file_handler()\n            config_fh = self.get_file_handler(self.keys[\"Config\"])\n            if config_fh is not None:\n                if isinstance(config_fh, str):\n                    try:\n                        config_fh = json.loads(config_fh)\n                    except json.JSONDecodeError:\n                        self.print(f\"Warning: Could not parse config from file handler: {config_fh[:100]}...\")\n                        config_fh = {}\n\n                if isinstance(config_fh, dict):\n                    # Merge, prioritizing existing self.config for defaults not in file\n                    loaded_config = config_fh\n                    for key, value in self.config.items():\n                        if key not in loaded_config:\n                            loaded_config[key] = value\n                    self.config = loaded_config\n\n            if self.spec == 'app':  # MainTool attribute\n                self.load_keys_from_env()\n\n            # Ensure directories exist\n            Path(f\"{get_app('isaa-initIsaa').data_dir}/Agents/\").mkdir(parents=True, exist_ok=True)\n            Path(f\"{get_app('isaa-initIsaa').data_dir}/Memory/\").mkdir(parents=True, exist_ok=True)\n\n        #initialize_isaa_webui_module(self.app, self)\n        #self.print(\"ISAA module started. fallback\")\n\n    def get_augment(self):\n        # This needs to be adapted. Serialization of FlowAgent is through AgentConfig.\n        return {\n            \"Agents\": self.serialize_all(),  # Returns dict of AgentConfig dicts\n            \"customFunctions\": json.dumps(self.scripts.scripts),  # Remains same\n        }\n\n    async def init_from_augment(self, augment, agent_name: str = 'self'):\n        \"\"\"Initialize from augmented data using new builder system\"\"\"\n\n        # Handle agent_name parameter\n        if isinstance(agent_name, str):\n            pass  # Use string name\n        elif hasattr(agent_name, 'config'):  # FlowAgentBuilder\n            agent_name = agent_name.config.name\n        else:\n            raise ValueError(f\"Invalid agent_name type: {type(agent_name)}\")\n\n        a_keys = augment.keys()\n\n        # Load agent configurations\n        if \"Agents\" in a_keys:\n            agents_configs_dict = augment['Agents']\n            self.deserialize_all(agents_configs_dict)\n            self.print(\"Agent configurations loaded.\")\n\n        # Load custom functions (scripts)\n        if \"customFunctions\" in a_keys:\n            custom_functions = augment['customFunctions']\n            if isinstance(custom_functions, str):\n                custom_functions = json.loads(custom_functions)\n            if custom_functions:\n                self.scripts.scripts = custom_functions\n                self.print(\"Custom functions loaded\")\n\n        # Tools are now handled by the builder system during agent creation\n        if \"tools\" in a_keys:\n            self.print(\"Tool configurations noted - will be applied during agent building\")\n\n    async def init_tools(self, tools_config: dict, agent_builder: FlowAgentBuilder):\n        # This function needs to be adapted to add tools to the FlowAgentBuilder\n        # For LangChain tools, they need to be wrapped as callables or ADK BaseTool instances.\n        lc_tools_names = tools_config.get('lagChinTools', [])\n        # hf_tools_names = tools_config.get('huggingTools', []) # HuggingFace tools are also LangChain tools\n        # plugin_urls = tools_config.get('Plugins', [])\n\n        all_lc_tool_names = list(set(lc_tools_names))  # + hf_tools_names\n\n        for tool_name in all_lc_tool_names:\n            try:\n                # Load tool instance (LangChain's load_tools might return a list)\n                loaded_tools = load_tools([tool_name], llm=None)  # LLM not always needed for tool definition\n                for lc_tool_instance in loaded_tools:\n                    # Wrap and add to builder\n                    # Simple case: wrap lc_tool_instance.run or lc_tool_instance._run\n                    if hasattr(lc_tool_instance, 'run') and callable(lc_tool_instance.run):\n                        # ADK FunctionTool needs a schema, or infers it.\n                        # We might need to manually create Pydantic models for args.\n                        # For simplicity, assume ADK can infer or the tool takes simple args.\n                        agent_builder.add_tool(lc_tool_instance.run, name=lc_tool_instance.name,\n                                                             description=lc_tool_instance.description)\n                        self.print(f\"Added LangChain tool '{lc_tool_instance.name}' to builder.\")\n                        self.lang_chain_tools_dict[lc_tool_instance.name] = lc_tool_instance  # Store for reference\n            except Exception as e:\n                self.print(f\"Failed to load/add LangChain tool '{tool_name}': {e}\")\n\n        # AIPluginTool needs more complex handling as it's a class\n        # for url in plugin_urls:\n        #     try:\n        #         plugin = AIPluginTool.from_plugin_url(url)\n        #         # Exposing AIPluginTool methods might require creating individual FunctionTools\n        #         # Or creating a custom ADK BaseTool wrapper for AIPluginTool\n        #         self.print(f\"AIPluginTool {plugin.name} loaded. Manual ADK wrapping needed.\")\n        #     except Exception as e:\n        #         self.print(f\"Failed to load AIPlugin from {url}: {e}\")\n\n    def serialize_all(self):\n        # Returns a copy of agent_data, which contains AgentConfig dicts\n        # The exclude logic might be different if it was excluding fields from old AgentBuilder\n        # For AgentConfig, exclusion happens during model_dump if needed.\n        return copy.deepcopy(self.agent_data)\n\n    def deserialize_all(self, data: dict[str, dict]):\n        # Data is a dict of {agent_name: builder_config_dict}\n        self.agent_data.update(data)\n        # Clear instances from self.config so they are rebuilt with new configs\n        for agent_name in data:\n            self.config.pop(f'agent-instance-{agent_name}', None)\n\n    async def init_isaa(self, name='self', build=False, **kwargs):\n        if self.initialized:\n            self.print(f\"Already initialized. Getting agent/builder: {name}\")\n            # build=True implies getting the builder, build=False (default) implies getting agent instance\n            return self.get_agent_builder(name) if build else await self.get_agent(name)\n\n        self.initialized = True\n        sys.setrecursionlimit(1500)\n        self.load_keys_from_env()\n\n        # Background loading\n        self.scripts.load_scripts()\n\n        with Spinner(message=\"Building Controller\", symbols='c'):\n            self.controller.init(self.config['controller_file'])\n        self.config[\"controller-init\"] = True\n\n\n        return self.get_agent_builder(name) if build else await self.get_agent(name)\n\n    def show_version(self):\n        self.print(\"Version: \", self.version)\n        return self.version\n\n    def on_start(self):\n\n        initialize_isaa_webui_module(self.app, self)\n\n        threading.Thread(target=self.load_to_mem_sync, daemon=True).start()\n        self.print(\"ISAA module started.\")\n\n    def load_keys_from_env(self):\n        # Update default model names from environment variables\n        for key in self.config:\n            if key.startswith(\"DEFAULTMODEL\"):\n                self.config[key] = os.getenv(key, self.config[key])\n        self.config['VAULTS'] = os.getenv(\"VAULTS\")\n\n    def on_exit(self):\n        self.app.run_bg_task_advanced(self.cleanup_tools_interfaces)\n        # Save agent configurations\n        for agent_name, agent_instance in self.config.items():\n            if agent_name.startswith('agent-instance-') and agent_instance and isinstance(agent_instance, list) and isinstance(agent_instance[0], FlowAgent):\n                self.app.run_bg_task_advanced(asyncio.gather(*[agent_instance.close() for agent_instance in agent_instance]))\n                # If agent instance has its own save logic (e.g. cost tracker)\n                # asyncio.run(agent_instance.close()) # This might block, consider task group\n                # The AgentConfig is already in self.agent_data, which should be saved.\n                pass  # Agent instances are not directly saved, their configs are.\n\n        self.scripts.save_scripts()\n        threading.Thread(target=self.save_to_mem_sync, daemon=True).start()  # Sync wrapper for save_to_mem\n\n        # Save controller if initialized\n        if self.config.get(\"controller-init\"):\n            self.controller.save(self.config['controller_file'])\n\n        # Clean up self.config for saving\n        clean_config = {}\n        for key, value in self.config.items():\n            if key.startswith('agent-instance-'): continue  # Don't save instances\n            if key.startswith('LLM-model-'): continue  # Don't save langchain models\n            clean_config[key] = value\n        self.add_to_save_file_handler(self.keys[\"Config\"], json.dumps(clean_config))\n\n        # Save other persistent data\n        self.save_file_handler()\n\n    def save_to_mem_sync(self):\n        # This used to call agent.save_memory(). FlowAgent does not have this.\n        # If AISemanticMemory needs global saving, it should be handled by AISemanticMemory itself.\n        # For now, this can be a no-op or save AISemanticMemory instances if managed by Tools.\n        memory_instance = self.get_memory()  # Assuming this returns AISemanticMemory\n        if hasattr(memory_instance, 'save_all_memories'):  # Hypothetical method\n            memory_instance.save_all_memories(f\"{get_app().data_dir}/Memory/\")\n        self.print(\"Memory saving process initiated\")\n\n    def load_to_mem_sync(self):\n        # This used to call agent.save_memory(). FlowAgent does not have this.\n        # If AISemanticMemory needs global saving, it should be handled by AISemanticMemory itself.\n        # For now, this can be a no-op or save AISemanticMemory instances if managed by Tools.\n        memory_instance = self.get_memory()  # Assuming this returns AISemanticMemory\n        if hasattr(memory_instance, 'load_all_memories'):  # Hypothetical method\n            memory_instance.load_all_memories(f\"{get_app().data_dir}/Memory/\")\n        self.print(\"Memory loading process initiated\")\n\n    def get_agent_builder(self, name=\"self\", extra_tools=None) -&gt; FlowAgentBuilder:\n        if name == 'None':\n            name = \"self\"\n\n        if extra_tools is None:\n            extra_tools = []\n\n        self.print(f\"Creating FlowAgentBuilder: {name}\")\n\n        # Create builder with agent-specific configuration\n        config = AgentConfig(\n            name=name,\n            fast_llm_model=self.config.get(f'{name.upper()}MODEL', self.config['FASTMODEL']),\n            complex_llm_model=self.config.get(f'{name.upper()}MODEL', self.config['COMPLEXMODEL']),\n            system_message=\"You are a production-ready autonomous agent.\",\n            temperature=0.7,\n            max_tokens_output=2048,\n            max_tokens_input=32768,\n            use_fast_response=True,\n            max_parallel_tasks=3,\n            verbose_logging=False\n        )\n\n        builder = FlowAgentBuilder(config=config)\n        builder._isaa_ref = self  # Store ISAA reference\n\n        # Load existing configuration if available\n        agent_config_path = Path(f\"{get_app().data_dir}/Agents/{name}/agent.json\")\n        if agent_config_path.exists():\n            try:\n                builder = FlowAgentBuilder.from_config_file(str(agent_config_path))\n                builder._isaa_ref = self\n                self.print(f\"Loaded existing configuration for builder {name}\")\n            except Exception as e:\n                self.print(f\"Failed to load config for {name}: {e}. Using defaults.\")\n\n        # Apply global settings\n        if self.global_stream_override:\n            builder.verbose(True)\n\n        # Apply custom setter if available\n        if self.default_setter:\n            builder = self.default_setter(builder, name)\n\n        # Initialize ToolsInterface for this agent\n        if not hasattr(self, 'tools_interfaces'):\n            self.tools_interfaces = {}\n\n        # Create or get existing ToolsInterface for this agent\n        if name not in self.tools_interfaces:\n            try:\n                # Initialize ToolsInterface\n                tools_interface = ToolsInterface(\n                    session_dir=str(Path(get_app().data_dir) / \"Agents\" / name / \"tools_session\"),\n                    auto_remove=False,  # Keep session data for agents\n                    variables={\n                        'agent_name': name,\n                        'isaa_instance': self\n                    },\n                    variable_manager=getattr(self, 'variable_manager', None),\n                )\n\n                self.tools_interfaces[name] = tools_interface\n                self.print(f\"Created ToolsInterface for agent: {name}\")\n\n            except Exception as e:\n                self.print(f\"Failed to create ToolsInterface for {name}: {e}\")\n                self.tools_interfaces[name] = None\n\n        tools_interface = self.tools_interfaces[name]\n\n        # Add ISAA core tools\n        async def run_isaa_agent_tool(target_agent_name: str, instructions: str, **kwargs_):\n            if not instructions:\n                return \"No instructions provided.\"\n            if target_agent_name.startswith('\"') and target_agent_name.endswith('\"') or target_agent_name.startswith(\n                \"'\") and target_agent_name.endswith(\"'\"):\n                target_agent_name = target_agent_name[1:-1]\n            return await self.run_agent(target_agent_name, text=instructions, **kwargs_)\n\n        async def memory_search_tool(\n            query: str,\n            search_mode: str | None = \"balanced\",\n            context_name: str | None = None\n        ) -&gt; str:\n            \"\"\"Memory search with configurable precision\"\"\"\n            mem_instance = self.get_memory()\n            memory_names_list = [name.strip() for name in context_name.split(',')] if context_name else None\n\n            search_params = {\n                \"wide\": {\"k\": 7, \"min_similarity\": 0.1, \"cross_ref_depth\": 3, \"max_cross_refs\": 4, \"max_sentences\": 8},\n                \"narrow\": {\"k\": 2, \"min_similarity\": 0.75, \"cross_ref_depth\": 1, \"max_cross_refs\": 1,\n                           \"max_sentences\": 3},\n                \"balanced\": {\"k\": 3, \"min_similarity\": 0.2, \"cross_ref_depth\": 2, \"max_cross_refs\": 2,\n                             \"max_sentences\": 5}\n            }.get(search_mode,\n                  {\"k\": 3, \"min_similarity\": 0.2, \"cross_ref_depth\": 2, \"max_cross_refs\": 2, \"max_sentences\": 5})\n\n            return await mem_instance.query(\n                query=query, memory_names=memory_names_list,\n                query_params=search_params, to_str=True\n            )\n\n        async def save_to_memory_tool(data_to_save: str, context_name: str = name):\n            mem_instance = self.get_memory()\n            result = await mem_instance.add_data(context_name, str(data_to_save), direct=True)\n            return 'Data added to memory.' if result else 'Error adding data to memory.'\n\n        # Add ISAA core tools\n        builder.add_tool(memory_search_tool, \"memorySearch\", \"Search ISAA's semantic memory\")\n        builder.add_tool(save_to_memory_tool, \"saveDataToMemory\", \"Save data to ISAA's semantic memory\")\n        builder.add_tool(self.web_search, \"searchWeb\", \"Search the web for information\")\n        builder.add_tool(self.shell_tool_function, \"shell\", f\"Run shell command in {detect_shell()}\")\n\n        # Scripting tools\n        # Enhanced tool descriptions for agent understanding\n        builder.add_tool(\n            self.scripts.run_script,\n            \"runScript\",\n            \"\"\"POWER TOOL: Execute saved scripts to perform complex operations beyond basic functions.\n\n            USE WHEN: You need file processing, data analysis, web scraping, API calls, system operations, mathematical computations, or any task requiring libraries/complex logic. or built-in tools not avalabel\n\n            DON'T USE: For simple text operations, basic math, or tasks you can do with built-in tools. or built-in tools avalabel\n\n            Args: name (required), args (optional - space-separated arguments for the script)\n            Example: runScript('web_scraper', 'https://example.com json')\"\"\"\n        )\n\n        builder.add_tool(\n            self.scripts.get_scripts_list,\n            \"listScripts\",\n            \"\"\"View your extended capabilities. Shows all available scripts that enhance your abilities beyond built-in functions. Use this to discover what powerful operations you can perform.\"\"\"\n        )\n\n        builder.add_tool(\n            self.scripts.create_script,\n            \"createScript\",\n            \"\"\"CAPABILITY ENHANCER: Create scripts to permanently extend your abilities.\n\n            Python scripts can use external libraries via 'uv' dependency management.\n            Shell scripts work cross-platform for system operations.\n\n            WHEN TO CREATE: When you need to repeat complex operations, use external libraries, or perform system-level tasks.\n\n            Args: name, description, content, script_type ('py' or 'sh'), dependencies (optional - for Python: 'requests pandas numpy' format)\n\n            Example: createScript('data_analyzer', 'Analyze CSV data', '...code...', 'py', 'pandas matplotlib')\"\"\"\n        )\n\n        builder.add_tool(\n            self.scripts.remove_script,\n            \"deleteScript\",\n            \"\"\"Remove a script capability. Use when a script is no longer needed or needs to be replaced. Args: name\"\"\"\n        )\n\n        # Add ToolsInterface tools dynamically\n        if tools_interface:\n            try:\n                # Get all tools from ToolsInterface\n                interface_tools = tools_interface.get_tools()\n\n                # Determine which tools to add based on agent name/type\n                tool_categories = {\n                    'code': ['execute_python', 'execute_rust', 'install_package'],\n                    'file': ['write_file', 'replace_in_file', 'read_file', 'list_directory', 'create_directory'],\n                    'session': ['get_execution_history', 'clear_session', 'get_variables'],\n                    'config': ['set_base_directory', 'set_current_file']\n                }\n\n                # Determine which categories to include\n                include_categories = set()\n                name_lower = name.lower()\n\n                # Code execution for development/coding agents\n                if any(keyword in name_lower for keyword in [\"dev\", \"code\", \"program\", \"script\", \"python\", \"rust\", \"worker\"]):\n                    include_categories.update(['code', 'file', 'session', 'config'])\n\n                # Web tools for web-focused agents\n                if any(keyword in name_lower for keyword in [\"web\", \"browser\", \"scrape\", \"crawl\", \"extract\"]):\n                    include_categories.update(['file', 'session'])\n\n                # File tools for file management agents\n                if any(keyword in name_lower for keyword in [\"file\", \"fs\", \"document\", \"write\", \"read\"]):\n                    include_categories.update(['file', 'session', 'config'])\n\n                # Default: add core tools for general agents\n                if not include_categories or name == \"self\":\n                    include_categories.update(['code', 'file', 'session', 'config'])\n\n                # Add selected tools\n                tools_added = 0\n                for tool_func, tool_name, tool_description in interface_tools:\n                    # Check if this tool should be included\n                    should_include = tool_name in extra_tools\n\n                    if not should_include:\n                        for category, tool_names in tool_categories.items():\n                            if category in include_categories and tool_name in tool_names:\n                                should_include = True\n                                break\n\n                    # Always include session management tools\n                    if tool_name in ['get_execution_history', 'get_variables']:\n                        should_include = True\n\n                    if should_include:\n                        try:\n                            builder.add_tool(tool_func, tool_name, tool_description)\n                            tools_added += 1\n                        except Exception as e:\n                            self.print(f\"Failed to add tool {tool_name}: {e}\")\n\n                self.print(f\"Added {tools_added} ToolsInterface tools to agent {name}\")\n\n            except Exception as e:\n                self.print(f\"Error adding ToolsInterface tools to {name}: {e}\")\n\n        # Configure cost tracking\n        builder.with_budget_manager(max_cost=100.0)\n\n        # Store agent configuration\n        try:\n            agent_dir = Path(f\"{get_app().data_dir}/Agents/{name}\")\n            agent_dir.mkdir(parents=True, exist_ok=True)\n\n            # Save agent metadata\n            metadata = {\n                'name': name,\n                'created_at': time.time(),\n                'tools_interface_available': tools_interface is not None,\n                'session_dir': str(agent_dir / \"tools_session\")\n            }\n\n            metadata_file = agent_dir / \"metadata.json\"\n            with open(metadata_file, 'w') as f:\n                json.dump(metadata, f, indent=2)\n\n        except Exception as e:\n            self.print(f\"Failed to save agent metadata for {name}: {e}\")\n\n        return builder\n\n\n    def get_tools_interface(self, agent_name: str = \"self\") -&gt; ToolsInterface | None:\n        \"\"\"\n        Get the ToolsInterface instance for a specific agent.\n\n        Args:\n            agent_name: Name of the agent\n\n        Returns:\n            ToolsInterface instance or None if not found\n        \"\"\"\n        if not hasattr(self, 'tools_interfaces'):\n            return None\n\n        return self.tools_interfaces.get(agent_name)\n\n    async def configure_tools_interface(self, agent_name: str, **kwargs) -&gt; bool:\n        \"\"\"\n        Configure the ToolsInterface for a specific agent.\n\n        Args:\n            agent_name: Name of the agent\n            **kwargs: Configuration parameters\n\n        Returns:\n            True if successful, False otherwise\n        \"\"\"\n        tools_interface = self.get_tools_interface(agent_name)\n        if not tools_interface:\n            self.print(f\"No ToolsInterface found for agent {agent_name}\")\n            return False\n\n        try:\n            # Configure based on provided parameters\n            if 'base_directory' in kwargs:\n                await tools_interface.set_base_directory(kwargs['base_directory'])\n\n            if 'current_file' in kwargs:\n                await tools_interface.set_current_file(kwargs['current_file'])\n\n            if 'variables' in kwargs:\n                tools_interface.ipython.user_ns.update(kwargs['variables'])\n\n            self.print(f\"Configured ToolsInterface for agent {agent_name}\")\n            return True\n\n        except Exception as e:\n            self.print(f\"Failed to configure ToolsInterface for {agent_name}: {e}\")\n            return False\n\n    async def cleanup_tools_interfaces(self):\n        \"\"\"\n        Cleanup all ToolsInterface instances.\n        \"\"\"\n        if not hasattr(self, 'tools_interfaces'):\n            return\n\n        async def cleanup_async():\n            for name, tools_interface in self.tools_interfaces.items():\n                if tools_interface:\n                    try:\n                        await tools_interface.__aexit__(None, None, None)\n                    except Exception as e:\n                        self.print(f\"Error cleaning up ToolsInterface for {name}: {e}\")\n\n        # Run cleanup\n        try:\n            await cleanup_async()\n            self.tools_interfaces.clear()\n            self.print(\"Cleaned up all ToolsInterface instances\")\n        except Exception as e:\n            self.print(f\"Error during ToolsInterface cleanup: {e}\")\n\n    async def register_agent(self, agent_builder: FlowAgentBuilder):\n        agent_name = agent_builder.config.name\n\n        if f'agent-instance-{agent_name}' in self.config:\n            self.print(f\"Agent '{agent_name}' instance already exists. Overwriting config and rebuilding on next get.\")\n            self.config.pop(f'agent-instance-{agent_name}', None)\n\n        # Save the builder's configuration\n        config_path = Path(f\"{get_app().data_dir}/Agents/{agent_name}/agent.json\")\n        agent_builder.save_config(str(config_path), format='json')\n        self.print(f\"Saved FlowAgentBuilder config for '{agent_name}' to {config_path}\")\n\n        # Store serializable config in agent_data\n        self.agent_data[agent_name] = agent_builder.config.model_dump()\n\n        if agent_name not in self.config.get(\"agents-name-list\", []):\n            if \"agents-name-list\" not in self.config:\n                self.config[\"agents-name-list\"] = []\n            self.config[\"agents-name-list\"].append(agent_name)\n\n        self.print(f\"FlowAgent '{agent_name}' configuration registered. Will be built on first use.\")\n        row_agent_builder_sto[agent_name] = agent_builder  # Cache builder\n\n    async def get_agent(self, agent_name=\"Normal\", model_override: str | None = None) -&gt; FlowAgent:\n        if \"agents-name-list\" not in self.config:\n            self.config[\"agents-name-list\"] = []\n\n        instance_key = f'agent-instance-{agent_name}'\n        if instance_key in self.config:\n            agent_instance = self.config[instance_key]\n            if model_override and agent_instance.amd.fast_llm_model != model_override:\n                self.print(f\"Model override for {agent_name}: {model_override}. Rebuilding.\")\n                self.config.pop(instance_key, None)\n            else:\n                self.print(f\"Returning existing FlowAgent instance: {agent_name}\")\n                return agent_instance\n\n        builder_to_use = None\n\n        # Try to get cached builder first\n        if agent_name in row_agent_builder_sto:\n            builder_to_use = row_agent_builder_sto[agent_name]\n            self.print(f\"Using cached builder for {agent_name}\")\n\n        # Try to load from stored config\n        elif agent_name in self.agent_data:\n            self.print(f\"Loading configuration for FlowAgent: {agent_name}\")\n            try:\n                config = AgentConfig(**self.agent_data[agent_name])\n                builder_to_use = FlowAgentBuilder(config=config)\n            except Exception as e:\n                self.print(f\"Error loading config for {agent_name}: {e}. Falling back to default.\")\n\n        # Create default builder if none found\n        if builder_to_use is None:\n            self.print(f\"No existing config for {agent_name}. Creating default builder.\")\n            builder_to_use = self.get_agent_builder(agent_name)\n\n        # Apply overrides and ensure correct name\n        builder_to_use._isaa_ref = self\n        if model_override:\n            builder_to_use.with_models(model_override, model_override)\n\n        if builder_to_use.config.name != agent_name:\n            builder_to_use.with_name(agent_name)\n\n        self.print(\n            f\"Building FlowAgent: {agent_name} with models {builder_to_use.config.fast_llm_model} - {builder_to_use.config.complex_llm_model}\")\n\n        # Build the agent\n        agent_instance: FlowAgent = await builder_to_use.build()\n\n        if agent_instance.amd.name == \"self\":\n            self.app.run_bg_task_advanced(agent_instance.initialize_context_awareness)\n\n        if interface := self.get_tools_interface(agent_name):\n            interface.variable_manager = agent_instance.variable_manager\n\n        # colletive cabability cahring for reduched reduanda analysis _tool_capabilities\n        agent_tool_nams = set(agent_instance.tool_registry.keys())\n\n        tools_data = {}\n        for _agent_name in self.config[\"agents-name-list\"]:\n            _instance_key = f'agent-instance-{_agent_name}'\n            if _instance_key not in self.config:\n                if agent_name != \"self\" and _agent_name == \"self\":\n                    await self.get_agent(\"self\")\n\n            if _instance_key not in self.config:\n                continue\n            _agent_instance = self.config[_instance_key]\n            _agent_tool_nams = set(_agent_instance._tool_capabilities.keys())\n            # extract the tool names that are in both agents_registry\n            overlap_tool_nams = agent_tool_nams.intersection(_agent_tool_nams)\n            _tc = _agent_instance._tool_capabilities\n            for tool_name in overlap_tool_nams:\n                if tool_name not in _tc:\n                    continue\n                tools_data[tool_name] = _tc[tool_name]\n\n        agent_instance._tool_capabilities.update(tools_data)\n        # Cache the instance and update tracking\n        self.config[instance_key] = agent_instance\n        if agent_name not in self.agent_data:\n            self.agent_data[agent_name] = builder_to_use.config.model_dump()\n        if agent_name not in self.config[\"agents-name-list\"]:\n            self.config[\"agents-name-list\"].append(agent_name)\n\n        self.print(f\"Built and cached FlowAgent instance: {agent_name}\")\n        return agent_instance\n\n    async def mini_task_completion(self, mini_task: str, user_task: str | None = None, mode: Any = None,  # LLMMode\n                                   max_tokens_override: int | None = None, task_from=\"system\",\n                                   stream_function: Callable | None = None, message_history: list | None = None, agent_name=\"TaskCompletion\"):\n        if mini_task is None: return None\n        if agent_name is None: return None\n        if mini_task == \"test\": return \"test\"\n        self.print(f\"Running mini task, volume {len(mini_task)}\")\n\n        agent = await self.get_agent(agent_name)  # Ensure agent is retrieved (and built if needed)\n\n        effective_system_message = agent.amd.system_message\n        if mode and hasattr(mode, 'system_msg') and mode.system_msg:\n            effective_system_message = mode.system_msg\n\n        messages = []\n        if effective_system_message:\n            messages.append({\"role\": \"system\", \"content\": effective_system_message})\n        if message_history:\n            messages.extend(message_history)\n\n        current_prompt = mini_task\n        if user_task:  # If user_task is provided, it becomes the main prompt, mini_task is context\n            messages.append({\"role\": task_from, \"content\": mini_task})  # mini_task as prior context\n            current_prompt = user_task  # user_task as the current prompt\n\n        messages.append({\"role\": \"user\", \"content\": current_prompt})\n\n        # Prepare params for a_run_llm_completion\n        llm_params = {\"model\": agent.amd.fast_llm_model if agent.amd.use_fast_response else agent.amd.complex_llm_model, \"messages\": messages}\n        if max_tokens_override:\n            llm_params['max_tokens'] = max_tokens_override\n        else:\n            llm_params['max_tokens'] = agent.amd.max_tokens\n\n        if stream_function:\n            llm_params['stream'] = True\n            # FlowAgent a_run_llm_completion handles stream_callback via agent.stream_callback\n            # For a one-off, we might need a temporary override or pass it if supported.\n            # For now, assume stream_callback is set on agent instance if needed globally.\n            # If stream_function is for this call only, agent.a_run_llm_completion needs modification\n            # or we use a temporary agent instance. This part is tricky.\n            # Let's assume for now that if stream_function is passed, it's a global override for this agent type.\n            original_stream_cb = agent.stream_callback\n            original_stream_val = agent.stream\n            agent.stream_callback = stream_function\n            agent.stream = True\n            try:\n                response_content = await agent.a_run_llm_completion(**llm_params)\n            finally:\n                agent.stream_callback = original_stream_cb\n                agent.stream = original_stream_val  # Reset to builder's config\n            return response_content  # Streaming output handled by callback\n\n        llm_params['stream'] = False\n        response_content = await agent.a_run_llm_completion(**llm_params)\n        return response_content\n\n    async def mini_task_completion_format(self, mini_task, format_schema: type[BaseModel],\n                                          max_tokens_override: int | None = None, agent_name=\"TaskCompletion\",\n                                          task_from=\"system\", mode_overload: Any = None, user_task: str | None = None, auto_context=False):\n        if mini_task is None: return None\n        self.print(f\"Running formatted mini task, volume {len(mini_task)}\")\n\n        agent = await self.get_agent(agent_name)\n\n        effective_system_message = None\n        if mode_overload and hasattr(mode_overload, 'system_msg') and mode_overload.system_msg:\n            effective_system_message = mode_overload.system_msg\n\n        message_context = []\n        if effective_system_message:\n            message_context.append({\"role\": \"system\", \"content\": effective_system_message})\n\n        current_prompt = mini_task\n        if user_task:\n            message_context.append({\"role\": task_from, \"content\": mini_task})\n            current_prompt = user_task\n\n        # Use agent.a_format_class\n        try:\n            result_dict = await agent.a_format_class(\n                pydantic_model=format_schema,\n                prompt=current_prompt,\n                message_context=message_context,\n                auto_context=auto_context\n                # max_tokens can be part of agent's model config or passed if a_format_class supports it\n            )\n            if format_schema == bool:  # Special handling for boolean schema\n                # a_format_class returns a dict, e.g. {\"value\": True}. Extract the bool.\n                # This depends on how bool schema is defined. A common way: class BoolResponse(BaseModel): value: bool\n                return result_dict.get(\"value\", False) if isinstance(result_dict, dict) else False\n            return result_dict\n        except Exception as e:\n            self.print(f\"Error in mini_task_completion_format: {e}\")\n            return None  # Or raise\n\n    async def format_class(self, format_schema: type[BaseModel], task: str, agent_name=\"TaskCompletion\", auto_context=False):\n        if format_schema is None or not task: return None\n\n        agent = None\n        if isinstance(agent_name, str):\n            agent = await self.get_agent(agent_name)\n        elif isinstance(agent_name, FlowAgent):\n            agent = agent_name\n        else:\n            raise TypeError(\"agent_name must be str or FlowAgent instance\")\n\n        return await agent.a_format_class(format_schema, task, auto_context=auto_context)\n\n    async def run_agent(self, name: str | FlowAgent,\n                        text: str,\n                        verbose: bool = False,  # Handled by agent's own config mostly\n                        session_id: str | None = None,\n                        progress_callback: Callable[[Any], None | Awaitable[None]] | None = None,\n                        **kwargs):  # Other kwargs for a_run\n        if text is None: return \"\"\n        if name is None: return \"\"\n        if text == \"test\": return \"\"\n\n        agent_instance = None\n        if isinstance(name, str):\n            agent_instance = await self.get_agent(name)\n        elif isinstance(name, FlowAgent):\n            agent_instance = name\n        else:\n            return self.return_result().default_internal_error(\n                f\"Invalid agent identifier type: {type(name)}\")\n\n        self.print(f\"Running agent {agent_instance.amd.name} for task: {text[:100]}...\")\n        save_p = None\n        if progress_callback:\n            save_p = agent_instance.progress_callback\n            agent_instance.progress_callback = progress_callback\n\n        if verbose:\n            agent_instance.verbose = True\n\n        # Call FlowAgent's a_run method\n        response = await agent_instance.a_run(\n            query=text,\n            session_id=session_id,\n            user_id=None,\n            stream_callback=None\n\n        )\n        if save_p:\n            agent_instance.progress_callback = save_p\n\n        return response\n\n    # mass_text_summaries and related methods remain complex and depend on AISemanticMemory\n    # and specific summarization strategies. For now, keeping their structure,\n    # but calls to self.format_class or self.mini_task_completion will become async.\n\n    async def mas_text_summaries(self, text, min_length=36000, ref=None):\n        len_text = len(text)\n        if len_text &lt; min_length: return text\n        key = self.one_way_hash(text, 'summaries', 'isaa')\n        value = self.mas_text_summaries_dict.get(key)\n        if value is not None: return value\n\n        # This part needs to become async due to format_class\n        # Simplified version:\n        summary = await self.mini_task_completion(\n            mini_task=f\"Summarize this text, focusing on aspects related to '{ref if ref else 'key details'}'. The text is: {text}\",\n            mode=self.controller.rget(SummarizationMode))\n\n        if summary is None or not isinstance(summary, str):\n            # Fallback or error handling\n            summary = text[:min_length] + \"... (summarization failed)\"\n\n        self.mas_text_summaries_dict.set(key, summary)\n        return summary\n\n    def get_memory(self, name: str | None = None) -&gt; AISemanticMemory:\n        # This method's logic seems okay, AISemanticMemory is a separate system.\n        logger_ = get_logger()  # Renamed to avoid conflict with self.logger\n        if isinstance(self.agent_memory, str):  # Path string\n            logger_.info(Style.GREYBG(\"AISemanticMemory Initialized from path\"))\n            self.agent_memory = AISemanticMemory(base_path=self.agent_memory)\n\n        cm = self.agent_memory\n        if name is not None:\n            # Assuming AISemanticMemory.get is synchronous or you handle async appropriately\n            # If AISemanticMemory methods become async, this needs adjustment\n            mem_kb = cm.get(name)  # This might return a list of KnowledgeBase or single one\n            return mem_kb\n        return cm\n\n    async def host_agent_ui(\n        self,\n        agent,\n        host: str = \"0.0.0.0\",\n        port: int | None = None,\n        access: str = 'local',\n        registry_server: str | None = None,\n        public_name: str | None = None,\n        description: str | None = None,\n        use_builtin_server: bool = None\n    ) -&gt; dict[str, str]:\n        \"\"\"\n        Unified agent hosting with WebSocket-enabled UI and optional registry publishing.\n\n        Args:\n            agent: Agent or Chain instance to host\n            host: Host address (default: 0.0.0.0 for remote access)\n            port: Port number (auto-assigned if None)\n            access: 'local', 'remote', or 'registry'\n            registry_server: Registry server URL for publishing (e.g., \"ws://localhost:8080/ws/registry/connect\")\n            public_name: Public name for registry publishing\n            description: Description for registry publishing\n            use_builtin_server: Use toolbox built-in server vs standalone Python server\n\n        Returns:\n            Dictionary with access URLs and configuration\n        \"\"\"\n        use_builtin_server = use_builtin_server or self.app.is_server\n        if not hasattr(self, '_hosted_agents'):\n            self._hosted_agents = {}\n\n        agent_id = f\"agent_{secrets.token_urlsafe(8)}\"\n\n        # Generate unique port if not specified\n        if not port:\n            port = 8765 + len(self._hosted_agents)\n\n        # Store agent reference\n        self._hosted_agents[agent_id] = {\n            'agent': agent,\n            'port': port,\n            'host': host,\n            'access': access,\n            'public_name': public_name or f\"Agent_{agent_id}\",\n            'description': description\n        }\n\n        result = {\n            'agent_id': agent_id,\n            'local_url': f\"http://{host}:{port}\",\n            'status': 'starting'\n        }\n\n        if use_builtin_server:\n            # Use toolbox built-in server\n            result.update(await self._setup_builtin_server_hosting(agent_id, agent, host, port))\n        else:\n            # Use standalone Python server\n            result.update(await self._setup_standalone_server_hosting(agent_id, agent, host, port))\n\n        # Handle registry publishing if requested\n        if access in ['remote', 'registry'] and registry_server:\n            if not public_name:\n                raise ValueError(\"public_name required for registry publishing\")\n\n            registry_result = await self._publish_to_registry(\n                agent=agent,\n                public_name=public_name,\n                registry_server=registry_server,\n                description=description,\n                agent_id=agent_id\n            )\n            result.update(registry_result)\n\n        self.app.print(f\"\ud83d\ude80 Agent '{result.get('public_name', agent_id)}' hosted successfully!\")\n        self.app.print(f\"   Local UI: {result['local_url']}\")\n        if 'public_url' in result:\n            self.app.print(f\"   Public URL: {result['public_url']}\")\n            self.app.print(f\"   API Key: {result.get('api_key', 'N/A')}\")\n\n        return result\n\n    # toolboxv2/mods/isaa/__init__.py - Missing Methods\n\n    import asyncio\n    import json\n    import secrets\n    import threading\n    import time\n    from concurrent.futures import ThreadPoolExecutor\n    from http.server import BaseHTTPRequestHandler, HTTPServer\n    from urllib.parse import parse_qs, urlparse\n\n\n    async def _handle_reset_context(self, agent_id: str, agent, conn_id: str):\n        \"\"\"Handle context reset requests from WebSocket UI.\"\"\"\n\n        try:\n            # Reset agent context if supported\n            if hasattr(agent, 'clear_context'):\n                agent.clear_context()\n                message = \"Context reset successfully\"\n                success = True\n            else:\n                message = \"Agent does not support context reset\"\n                success = False\n\n            # Send response back to UI\n            await self._broadcast_to_agent_ui(agent_id, {\n                'event': 'reset_response',\n                'data': {\n                    'success': success,\n                    'message': message,\n                    'timestamp': time.time()\n                }\n            })\n\n            self.app.print(f\"Context reset requested for agent {agent_id}: {message}\")\n\n        except Exception as e:\n            error_message = f\"Context reset failed: {str(e)}\"\n            self.app.print(f\"Context reset error for agent {agent_id}: {e}\")\n\n            await self._broadcast_to_agent_ui(agent_id, {\n                'event': 'error',\n                'data': {\n                    'error': error_message,\n                    'timestamp': time.time()\n                }\n            })\n\n    async def _handle_get_status(self, agent_id: str, agent, conn_id: str):\n        \"\"\"Handle status requests from WebSocket UI.\"\"\"\n\n        try:\n            # Collect agent status information\n            status_info = {\n                'agent_id': agent_id,\n                'agent_name': getattr(agent, 'name', 'Unknown'),\n                'agent_type': agent.__class__.__name__,\n                'status': 'active',\n                'timestamp': time.time(),\n                'server_type': 'builtin'\n            }\n\n            # Add additional status if available\n            if hasattr(agent, 'status'):\n                try:\n                    agent_status = agent.status()\n                    if isinstance(agent_status, dict):\n                        status_info.update(agent_status)\n                except:\n                    pass\n\n            # Add hosted agent info\n            if hasattr(self, '_hosted_agents') and agent_id in self._hosted_agents:\n                hosted_info = self._hosted_agents[agent_id]\n                status_info.update({\n                    'host': hosted_info.get('host'),\n                    'port': hosted_info.get('port'),\n                    'access': hosted_info.get('access'),\n                    'public_name': hosted_info.get('public_name')\n                })\n\n            # Send status back to UI\n            await self._broadcast_to_agent_ui(agent_id, {\n                'event': 'status_response',\n                'data': status_info\n            })\n\n            self.app.print(f\"Status requested for agent {agent_id}\")\n\n        except Exception as e:\n            error_message = f\"Status retrieval failed: {str(e)}\"\n            self.app.print(f\"Status error for agent {agent_id}: {e}\")\n\n            await self._broadcast_to_agent_ui(agent_id, {\n                'event': 'error',\n                'data': {\n                    'error': error_message,\n                    'timestamp': time.time()\n                }\n            })\n\n\n    async def stop_hosted_agent(self, agent_id: str = None, port: int = None):\n        \"\"\"Stop a hosted agent by agent_id or port.\"\"\"\n\n        if not hasattr(self, '_hosted_agents') and not hasattr(self, '_standalone_servers'):\n            self.app.print(\"No hosted agents found\")\n            return False\n\n        # Stop by agent_id\n        if agent_id:\n            if hasattr(self, '_hosted_agents') and agent_id in self._hosted_agents:\n                agent_info = self._hosted_agents[agent_id]\n                agent_port = agent_info.get('port')\n\n                # Stop standalone server if exists\n                if hasattr(self, '_standalone_servers') and agent_port in self._standalone_servers:\n                    server_info = self._standalone_servers[agent_port]\n                    try:\n                        server_info['server'].shutdown()\n                        self.app.print(f\"Stopped standalone server for agent {agent_id}\")\n                    except:\n                        pass\n\n                # Clean up hosted agent info\n                del self._hosted_agents[agent_id]\n                self.app.print(f\"Stopped hosted agent {agent_id}\")\n                return True\n\n        # Stop by port\n        if port:\n            if hasattr(self, '_standalone_servers') and port in self._standalone_servers:\n                server_info = self._standalone_servers[port]\n                try:\n                    server_info['server'].shutdown()\n                    self.app.print(f\"Stopped server on port {port}\")\n                    return True\n                except Exception as e:\n                    self.app.print(f\"Failed to stop server on port {port}: {e}\")\n                    return False\n\n        self.app.print(\"Agent or port not found\")\n        return False\n\n    async def list_hosted_agents(self) -&gt; dict[str, Any]:\n        \"\"\"List all currently hosted agents.\"\"\"\n\n        hosted_info = {\n            'builtin_agents': {},\n            'standalone_agents': {},\n            'total_count': 0\n        }\n\n        # Built-in server agents\n        if hasattr(self, '_hosted_agents'):\n            for agent_id, info in self._hosted_agents.items():\n                hosted_info['builtin_agents'][agent_id] = {\n                    'public_name': info.get('public_name'),\n                    'host': info.get('host'),\n                    'port': info.get('port'),\n                    'access': info.get('access'),\n                    'description': info.get('description')\n                }\n\n        # Standalone server agents\n        if hasattr(self, '_standalone_servers'):\n            for port, info in self._standalone_servers.items():\n                hosted_info['standalone_agents'][info['agent_id']] = {\n                    'port': port,\n                    'thread_alive': info['thread'].is_alive(),\n                    'server_type': 'standalone'\n                }\n\n        hosted_info['total_count'] = len(hosted_info['builtin_agents']) + len(hosted_info['standalone_agents'])\n\n        return hosted_info\n\n    def _create_agent_ws_connect_handler(self, agent_id: str):\n        \"\"\"Create WebSocket connect handler for specific agent.\"\"\"\n\n        async def on_connect(app, conn_id: str, session: dict):\n            if not hasattr(self, '_agent_connections'):\n                self._agent_connections = {}\n\n            if agent_id not in self._agent_connections:\n                self._agent_connections[agent_id] = set()\n\n            self._agent_connections[agent_id].add(conn_id)\n\n            # Send initial status\n            await app.ws_send(conn_id, {\n                'event': 'agent_connected',\n                'data': {\n                    'agent_id': agent_id,\n                    'status': 'ready',\n                    'capabilities': ['chat', 'progress_tracking', 'real_time_updates']\n                }\n            })\n\n            self.app.print(f\"UI client connected to agent {agent_id}: {conn_id}\")\n\n        return on_connect\n\n    def _create_agent_ws_message_handler(self, agent_id: str, agent):\n        \"\"\"Create WebSocket message handler for specific agent.\"\"\"\n\n        async def on_message(app, conn_id: str, session: dict, payload: dict):\n            event = payload.get('event')\n            data = payload.get('data', {})\n\n            if event == 'chat_message':\n                await self._handle_chat_message(agent_id, agent, conn_id, data)\n            elif event == 'reset_context':\n                await self._handle_reset_context(agent_id, agent, conn_id)\n            elif event == 'get_status':\n                await self._handle_get_status(agent_id, agent, conn_id)\n            else:\n                self.app.print(f\"Unknown event from UI: {event}\")\n\n        return on_message\n\n    def _create_agent_ws_disconnect_handler(self, agent_id: str):\n        \"\"\"Create WebSocket disconnect handler for specific agent.\"\"\"\n\n        async def on_disconnect(app, conn_id: str, session: dict = None):\n            if hasattr(self, '_agent_connections') and agent_id in self._agent_connections:\n                self._agent_connections[agent_id].discard(conn_id)\n\n            self.app.print(f\"UI client disconnected from agent {agent_id}: {conn_id}\")\n\n        return on_disconnect\n\n\n    async def _broadcast_to_agent_ui(self, agent_id: str, message: dict):\n        \"\"\"Broadcast message to all UI clients connected to specific agent.\"\"\"\n        if not hasattr(self, '_agent_connections') or agent_id not in self._agent_connections:\n            return\n\n        for conn_id in self._agent_connections[agent_id].copy():\n            try:\n                await self.app.ws_send(conn_id, message)\n            except Exception as e:\n                self.app.print(f\"Failed to send to UI client {conn_id}: {e}\")\n                self._agent_connections[agent_id].discard(conn_id)\n\n    async def _publish_to_registry(\n        self,\n        agent,\n        public_name: str,\n        registry_server: str,\n        description: str | None = None,\n        agent_id: str | None = None\n    ) -&gt; dict[str, str]:\n        \"\"\"Publish agent to registry server.\"\"\"\n        try:\n            # Import registry client dynamically to avoid circular imports\n            registry_client_module = __import__(\"toolboxv2.mods.registry.client\", fromlist=[\"get_registry_client\"])\n            get_registry_client = registry_client_module.get_registry_client\n\n            client = get_registry_client(self.app)\n\n            # Connect if not already connected\n            if not client.ws or not client.ws.open:\n                await client.connect(registry_server)\n\n            if not client.ws or not client.ws.open:\n                raise Exception(\"Failed to connect to registry server\")\n\n            # Register the agent\n            reg_info = await client.register(agent, public_name, description)\n\n            if reg_info:\n                return {\n                    'public_url': reg_info.public_url,\n                    'api_key': reg_info.public_api_key,\n                    'public_agent_id': reg_info.public_agent_id,\n                    'registry_status': 'published'\n                }\n            else:\n                raise Exception(\"Registration failed\")\n\n        except Exception as e:\n            self.app.print(f\"Registry publishing failed: {e}\")\n            return {'registry_status': 'failed', 'registry_error': str(e)}\n\n    def _get_enhanced_agent_ui_html(self, agent_id: str) -&gt; str:\n        \"\"\"Get production-ready enhanced UI HTML with comprehensive progress visualization.\"\"\"\n        agent_info = self._hosted_agents.get(agent_id, {})\n        server_info = {\n            'server_type': 'standalone' if not hasattr(self.app, 'tb') else 'builtin',\n            'agent_id': agent_id\n        }\n\n        # Update the JavaScript section in the HTML template:\n        js_config = f\"\"\"\n                window.SERVER_CONFIG = {json.dumps(server_info)};\n            \"\"\"\n        html_template = \"\"\"&lt;!DOCTYPE html&gt;\n    &lt;html lang=\"en\"&gt;\n    &lt;head&gt;\n        &lt;meta charset=\"UTF-8\"&gt;\n        &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;\n        &lt;title&gt;{agent_name}&lt;/title&gt;\n        &lt;script src=\"https://cdn.jsdelivr.net/npm/marked/marked.min.js\"&gt;&lt;/script&gt;\n        &lt;style&gt;\n            :root {\n                --bg-primary: #0d1117;\n                --bg-secondary: #161b22;\n                --bg-tertiary: #21262d;\n                --text-primary: #f0f6fc;\n                --text-secondary: #8b949e;\n                --text-muted: #6e7681;\n                --accent-blue: #58a6ff;\n                --accent-green: #3fb950;\n                --accent-red: #f85149;\n                --accent-orange: #d29922;\n                --accent-purple: #a5a5f5;\n                --accent-cyan: #39d0d8;\n                --border-color: #30363d;\n                --shadow: 0 2px 8px rgba(0, 0, 0, 0.3);\n            }\n\n            * { margin: 0; padding: 0; box-sizing: border-box; }\n\n            body {\n                font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;\n                background: var(--bg-primary);\n                color: var(--text-primary);\n                height: 100vh;\n                display: flex;\n                flex-direction: column;\n                overflow: hidden;\n            }\n\n            .header {\n                background: var(--bg-tertiary);\n                padding: 12px 20px;\n                border-bottom: 1px solid var(--border-color);\n                display: flex;\n                align-items: center;\n                justify-content: space-between;\n                box-shadow: var(--shadow);\n                z-index: 100;\n            }\n\n            .agent-info {\n                display: flex;\n                align-items: center;\n                gap: 16px;\n            }\n\n            .agent-title {\n                font-size: 18px;\n                font-weight: 600;\n                color: var(--accent-blue);\n            }\n\n            .agent-status {\n                display: flex;\n                align-items: center;\n                gap: 8px;\n                font-size: 14px;\n            }\n\n            .status-dot {\n                width: 10px;\n                height: 10px;\n                border-radius: 50%;\n                background: var(--accent-red);\n                animation: pulse 2s infinite;\n            }\n\n            .status-dot.connected {\n                background: var(--accent-green);\n                animation: none;\n            }\n\n            .status-dot.processing {\n                background: var(--accent-orange);\n                animation: pulse 1s infinite;\n            }\n\n            @keyframes pulse {\n                0%, 100% { opacity: 1; }\n                50% { opacity: 0.5; }\n            }\n\n            .main-container {\n                display: grid;\n                grid-template-columns: 2fr 1.5fr 1fr;\n                grid-template-rows: 1fr 1fr;\n                grid-template-areas:\n                    \"chat outline activity\"\n                    \"chat system graph\";\n                flex: 1;\n                gap: 1px;\n                background: var(--border-color);\n                overflow: hidden;\n            }\n\n            .panel {\n                background: var(--bg-secondary);\n                display: flex;\n                flex-direction: column;\n                overflow: hidden;\n            }\n\n            .chat-panel { grid-area: chat; }\n            .outline-panel { grid-area: outline; }\n            .activity-panel { grid-area: activity; }\n            .system-panel { grid-area: system; }\n            .graph-panel { grid-area: graph; }\n\n            .panel-header {\n                padding: 12px 16px;\n                background: var(--bg-tertiary);\n                border-bottom: 1px solid var(--border-color);\n                font-weight: 600;\n                font-size: 12px;\n                text-transform: uppercase;\n                letter-spacing: 0.5px;\n                display: flex;\n                align-items: center;\n                gap: 8px;\n            }\n\n            .panel-content {\n                flex: 1;\n                overflow-y: auto;\n                padding: 12px;\n            }\n\n            /* Chat Panel Styles */\n            .chat-messages {\n                flex: 1;\n                overflow-y: auto;\n                padding: 16px;\n                display: flex;\n                flex-direction: column;\n                gap: 16px;\n            }\n\n            .message {\n                display: flex;\n                align-items: flex-start;\n                gap: 12px;\n                max-width: 85%;\n            }\n\n            .message.user {\n                flex-direction: row-reverse;\n                margin-left: auto;\n            }\n\n            .message-avatar {\n                width: 32px;\n                height: 32px;\n                border-radius: 50%;\n                display: flex;\n                align-items: center;\n                justify-content: center;\n                font-size: 12px;\n                font-weight: 600;\n                flex-shrink: 0;\n            }\n\n            .message.user .message-avatar {\n                background: var(--accent-blue);\n            }\n\n            .message.agent .message-avatar {\n                background: var(--accent-green);\n            }\n\n            .message-content {\n                padding: 12px 16px;\n                border-radius: 12px;\n                line-height: 1.5;\n                font-size: 14px;\n            }\n\n            .message.user .message-content {\n                background: var(--accent-blue);\n                color: white;\n            }\n\n            .message.agent .message-content {\n                background: var(--bg-tertiary);\n                border: 1px solid var(--border-color);\n            }\n\n            .chat-input-area {\n                border-top: 1px solid var(--border-color);\n                padding: 16px;\n                display: flex;\n                gap: 12px;\n            }\n\n            .chat-input {\n                flex: 1;\n                background: var(--bg-primary);\n                border: 1px solid var(--border-color);\n                border-radius: 8px;\n                padding: 12px;\n                color: var(--text-primary);\n                font-size: 14px;\n            }\n\n            .chat-input:focus {\n                outline: none;\n                border-color: var(--accent-blue);\n            }\n\n            .send-button {\n                background: var(--accent-blue);\n                color: white;\n                border: none;\n                border-radius: 8px;\n                padding: 12px 20px;\n                cursor: pointer;\n                font-weight: 600;\n                transition: all 0.2s;\n            }\n\n            .send-button:hover:not(:disabled) {\n                background: #4493f8;\n                transform: translateY(-1px);\n            }\n\n            .send-button:disabled {\n                opacity: 0.5;\n                cursor: not-allowed;\n                transform: none;\n            }\n\n            /* Progress Indicator */\n            .progress-indicator {\n                display: none;\n                align-items: center;\n                gap: 12px;\n                padding: 12px 16px;\n                background: var(--bg-tertiary);\n                border-top: 1px solid var(--border-color);\n                font-size: 14px;\n            }\n\n            .progress-indicator.active { display: flex; }\n\n            .spinner {\n                width: 16px;\n                height: 16px;\n                border: 2px solid var(--border-color);\n                border-top: 2px solid var(--accent-blue);\n                border-radius: 50%;\n                animation: spin 1s linear infinite;\n            }\n\n            @keyframes spin {\n                0% { transform: rotate(0deg); }\n                100% { transform: rotate(360deg); }\n            }\n\n            /* Outline Panel Styles */\n            .outline-progress {\n                margin-bottom: 16px;\n            }\n\n            .outline-header {\n                display: flex;\n                align-items: center;\n                justify-content: space-between;\n                margin-bottom: 12px;\n            }\n\n            .outline-title {\n                font-weight: 600;\n                color: var(--accent-cyan);\n            }\n\n            .outline-stats {\n                font-size: 12px;\n                color: var(--text-muted);\n            }\n\n            .progress-bar {\n                width: 100%;\n                height: 6px;\n                background: var(--bg-primary);\n                border-radius: 3px;\n                overflow: hidden;\n                margin-bottom: 16px;\n            }\n\n            .progress-fill {\n                height: 100%;\n                background: linear-gradient(90deg, var(--accent-blue), var(--accent-cyan));\n                width: 0%;\n                transition: width 0.5s ease;\n            }\n\n            .outline-steps {\n                display: flex;\n                flex-direction: column;\n                gap: 8px;\n            }\n\n            .outline-step {\n                display: flex;\n                align-items: center;\n                gap: 10px;\n                padding: 8px 12px;\n                border-radius: 6px;\n                background: var(--bg-primary);\n                border-left: 3px solid var(--border-color);\n                transition: all 0.3s;\n            }\n\n            .outline-step.active {\n                border-left-color: var(--accent-orange);\n                background: rgba(217, 153, 34, 0.1);\n            }\n\n            .outline-step.completed {\n                border-left-color: var(--accent-green);\n                background: rgba(63, 185, 80, 0.1);\n            }\n\n            .step-icon {\n                font-size: 14px;\n                width: 16px;\n            }\n\n            .step-text {\n                flex: 1;\n                font-size: 13px;\n            }\n\n            .step-method {\n                font-size: 11px;\n                color: var(--text-muted);\n                background: var(--bg-tertiary);\n                padding: 2px 6px;\n                border-radius: 4px;\n            }\n\n            /* Activity Panel Styles */\n            .current-activity {\n                background: var(--bg-primary);\n                border: 1px solid var(--border-color);\n                border-radius: 6px;\n                padding: 12px;\n                margin-bottom: 12px;\n            }\n\n            .activity-header {\n                display: flex;\n                align-items: center;\n                gap: 8px;\n                margin-bottom: 8px;\n            }\n\n            .activity-title {\n                font-weight: 600;\n                color: var(--accent-orange);\n            }\n\n            .activity-duration {\n                font-size: 11px;\n                color: var(--text-muted);\n                background: var(--bg-tertiary);\n                padding: 2px 6px;\n                border-radius: 4px;\n            }\n\n            .activity-description {\n                font-size: 13px;\n                line-height: 1.4;\n                color: var(--text-secondary);\n            }\n\n            .meta-tools-list {\n                display: flex;\n                flex-direction: column;\n                gap: 6px;\n            }\n\n            .meta-tool {\n                display: flex;\n                align-items: center;\n                gap: 8px;\n                padding: 6px 10px;\n                background: var(--bg-primary);\n                border-radius: 4px;\n                font-size: 12px;\n            }\n\n            .tool-icon {\n                width: 12px;\n                text-align: center;\n            }\n\n            .tool-name {\n                flex: 1;\n                color: var(--text-secondary);\n            }\n\n            .tool-status {\n                font-size: 10px;\n                padding: 2px 6px;\n                border-radius: 3px;\n            }\n\n            .tool-status.running {\n                background: var(--accent-orange);\n                color: white;\n            }\n\n            .tool-status.completed {\n                background: var(--accent-green);\n                color: white;\n            }\n\n            .tool-status.error {\n                background: var(--accent-red);\n                color: white;\n            }\n\n            /* System Panel Styles */\n            .system-grid {\n                display: grid;\n                grid-template-columns: 1fr 2fr;\n                gap: 8px 12px;\n                font-size: 12px;\n            }\n\n            .system-key {\n                color: var(--text-muted);\n                font-weight: 500;\n            }\n\n            .system-value {\n                color: var(--text-primary);\n                font-family: 'SF Mono', Monaco, monospace;\n                word-break: break-word;\n            }\n\n            .current-node {\n                background: var(--bg-primary);\n                padding: 8px 10px;\n                border-radius: 6px;\n                margin-bottom: 12px;\n                border: 1px solid var(--border-color);\n            }\n\n            .node-name {\n                font-weight: 600;\n                color: var(--accent-purple);\n                margin-bottom: 4px;\n            }\n\n            .node-operation {\n                font-size: 11px;\n                color: var(--text-muted);\n            }\n\n            /* Graph Panel Styles */\n            .agent-graph {\n                display: flex;\n                flex-direction: column;\n                align-items: center;\n                gap: 8px;\n                padding: 8px;\n            }\n\n            .graph-node {\n                padding: 6px 12px;\n                background: var(--bg-primary);\n                border: 1px solid var(--border-color);\n                border-radius: 6px;\n                font-size: 11px;\n                text-align: center;\n                min-width: 80px;\n            }\n\n            .graph-node.active {\n                border-color: var(--accent-orange);\n                background: rgba(217, 153, 34, 0.1);\n            }\n\n            .graph-node.completed {\n                border-color: var(--accent-green);\n                background: rgba(63, 185, 80, 0.1);\n            }\n\n            .graph-arrow {\n                color: var(--text-muted);\n                font-size: 12px;\n            }\n\n            /* Connection Error Styles */\n            .connection-error {\n                background: var(--accent-red);\n                color: white;\n                padding: 8px 12px;\n                margin: 8px;\n                border-radius: 6px;\n                font-size: 12px;\n                text-align: center;\n            }\n\n            .fallback-mode {\n                background: var(--accent-orange);\n                color: white;\n                padding: 8px 12px;\n                margin: 8px;\n                border-radius: 6px;\n                font-size: 12px;\n                text-align: center;\n            }\n        &lt;/style&gt;\n    &lt;/head&gt;\n    &lt;body&gt;\n        &lt;div class=\"header\"&gt;\n            &lt;div class=\"agent-info\"&gt;\n                &lt;div class=\"agent-title\"&gt;{agent_name}&lt;/div&gt;\n                &lt;div class=\"text-secondary\"&gt;{agent_description}&lt;/div&gt;\n            &lt;/div&gt;\n            &lt;div class=\"agent-status\"&gt;\n                &lt;div class=\"status-dot\" id=\"status-dot\"&gt;&lt;/div&gt;\n                &lt;span id=\"status-text\"&gt;Initializing...&lt;/span&gt;\n            &lt;/div&gt;\n        &lt;/div&gt;\n\n        &lt;div class=\"main-container\"&gt;\n            &lt;!-- Chat Panel --&gt;\n            &lt;div class=\"panel chat-panel\"&gt;\n                &lt;div class=\"panel-header\"&gt;\ud83d\udcac Conversation&lt;/div&gt;\n                &lt;div class=\"chat-messages\" id=\"chat-messages\"&gt;\n                    &lt;div class=\"message agent\"&gt;\n                        &lt;div class=\"message-avatar\"&gt;AI&lt;/div&gt;\n                        &lt;div class=\"message-content\"&gt;Hello! I'm ready to help you. What would you like to know?&lt;/div&gt;\n                    &lt;/div&gt;\n                &lt;/div&gt;\n                &lt;div class=\"progress-indicator\" id=\"progress-indicator\"&gt;\n                    &lt;div class=\"spinner\"&gt;&lt;/div&gt;\n                    &lt;span id=\"progress-text\"&gt;Processing...&lt;/span&gt;\n                &lt;/div&gt;\n                &lt;div class=\"chat-input-area\"&gt;\n                    &lt;input type=\"text\" id=\"chat-input\" class=\"chat-input\" placeholder=\"Type your message...\"&gt;\n                    &lt;button id=\"send-button\" class=\"send-button\"&gt;Send&lt;/button&gt;\n                &lt;/div&gt;\n            &lt;/div&gt;\n\n            &lt;!-- Outline &amp; Progress Panel --&gt;\n            &lt;div class=\"panel outline-panel\"&gt;\n                &lt;div class=\"panel-header\"&gt;\ud83d\udccb Execution Outline&lt;/div&gt;\n                &lt;div class=\"panel-content\"&gt;\n                    &lt;div class=\"outline-progress\"&gt;\n                        &lt;div class=\"outline-header\"&gt;\n                            &lt;div class=\"outline-title\" id=\"outline-title\"&gt;Ready&lt;/div&gt;\n                            &lt;div class=\"outline-stats\" id=\"outline-stats\"&gt;0/0 steps&lt;/div&gt;\n                        &lt;/div&gt;\n                        &lt;div class=\"progress-bar\"&gt;\n                            &lt;div class=\"progress-fill\" id=\"outline-progress-fill\"&gt;&lt;/div&gt;\n                        &lt;/div&gt;\n                    &lt;/div&gt;\n                    &lt;div class=\"outline-steps\" id=\"outline-steps\"&gt;\n                        &lt;div class=\"outline-step\"&gt;\n                            &lt;div class=\"step-icon\"&gt;\u23f3&lt;/div&gt;\n                            &lt;div class=\"step-text\"&gt;Waiting for query...&lt;/div&gt;\n                        &lt;/div&gt;\n                    &lt;/div&gt;\n                    &lt;div class=\"current-activity\" id=\"current-activity\" style=\"display: none;\"&gt;\n                        &lt;div class=\"activity-header\"&gt;\n                            &lt;div class=\"activity-title\" id=\"activity-title\"&gt;Current Activity&lt;/div&gt;\n                            &lt;div class=\"activity-duration\" id=\"activity-duration\"&gt;0s&lt;/div&gt;\n                        &lt;/div&gt;\n                        &lt;div class=\"activity-description\" id=\"activity-description\"&gt;&lt;/div&gt;\n                    &lt;/div&gt;\n                &lt;/div&gt;\n            &lt;/div&gt;\n\n            &lt;!-- Activity &amp; Meta-Tools Panel --&gt;\n            &lt;div class=\"panel activity-panel\"&gt;\n                &lt;div class=\"panel-header\"&gt;\u2699\ufe0f Meta-Tool Activity&lt;/div&gt;\n                &lt;div class=\"panel-content\"&gt;\n                    &lt;div class=\"meta-tools-list\" id=\"meta-tools-list\"&gt;\n                        &lt;div style=\"color: var(--text-muted); font-size: 12px; text-align: center; padding: 20px;\"&gt;\n                            No activity yet\n                        &lt;/div&gt;\n                    &lt;/div&gt;\n                &lt;/div&gt;\n            &lt;/div&gt;\n\n            &lt;!-- System Status Panel --&gt;\n            &lt;div class=\"panel system-panel\"&gt;\n                &lt;div class=\"panel-header\"&gt;\ud83d\udd27 System Status&lt;/div&gt;\n                &lt;div class=\"panel-content\"&gt;\n                    &lt;div class=\"current-node\" id=\"current-node\"&gt;\n                        &lt;div class=\"node-name\" id=\"node-name\"&gt;System&lt;/div&gt;\n                        &lt;div class=\"node-operation\" id=\"node-operation\"&gt;Idle&lt;/div&gt;\n                    &lt;/div&gt;\n                    &lt;div class=\"system-grid\" id=\"system-grid\"&gt;\n                        &lt;div class=\"system-key\"&gt;Status&lt;/div&gt;\n                        &lt;div class=\"system-value\"&gt;Ready&lt;/div&gt;\n                        &lt;div class=\"system-key\"&gt;Runtime&lt;/div&gt;\n                        &lt;div class=\"system-value\"&gt;0s&lt;/div&gt;\n                        &lt;div class=\"system-key\"&gt;Events&lt;/div&gt;\n                        &lt;div class=\"system-value\"&gt;0&lt;/div&gt;\n                        &lt;div class=\"system-key\"&gt;Errors&lt;/div&gt;\n                        &lt;div class=\"system-value\"&gt;0&lt;/div&gt;\n                    &lt;/div&gt;\n                &lt;/div&gt;\n            &lt;/div&gt;\n\n            &lt;!-- Agent Graph Panel --&gt;\n            &lt;div class=\"panel graph-panel\"&gt;\n                &lt;div class=\"panel-header\"&gt;\ud83c\udf10 Agent Flow&lt;/div&gt;\n                &lt;div class=\"panel-content\"&gt;\n                    &lt;div class=\"agent-graph\" id=\"agent-graph\"&gt;\n                        &lt;div class=\"graph-node\"&gt;LLMReasonerNode&lt;/div&gt;\n                        &lt;div class=\"graph-arrow\"&gt;\u2193&lt;/div&gt;\n                        &lt;div class=\"graph-node\"&gt;Ready&lt;/div&gt;\n                    &lt;/div&gt;\n                &lt;/div&gt;\n            &lt;/div&gt;\n        &lt;/div&gt;\n\n        &lt;script unSave=\"true\"&gt;\n            __SERVER_CONFIG__\n            class ProductionAgentUI {\n                constructor() {\n                    this.ws = null;\n                    this.isProcessing = false;\n                    this.sessionId = 'ui_session_' + Math.random().toString(36).substr(2, 9);\n                    this.startTime = null;\n                    this.reconnectAttempts = 0;\n                    this.maxReconnectAttempts = 10;\n                    this.reconnectDelay = 1000;\n                    this.useWebSocket = true;\n                    this.fallbackMode = false;\n\n                    // Progress tracking\n                    this.currentOutline = null;\n                    this.currentActivity = null;\n                    this.metaTools = new Map();\n                    this.systemStatus = {};\n                    this.agentGraph = [];\n                    this.progressEvents = [];\n\n                    this.elements = {\n                        statusDot: document.getElementById('status-dot'),\n                        statusText: document.getElementById('status-text'),\n                        chatMessages: document.getElementById('chat-messages'),\n                        chatInput: document.getElementById('chat-input'),\n                        sendButton: document.getElementById('send-button'),\n                        progressIndicator: document.getElementById('progress-indicator'),\n                        progressText: document.getElementById('progress-text'),\n\n                        // Outline elements\n                        outlineTitle: document.getElementById('outline-title'),\n                        outlineStats: document.getElementById('outline-stats'),\n                        outlineProgressFill: document.getElementById('outline-progress-fill'),\n                        outlineSteps: document.getElementById('outline-steps'),\n                        currentActivity: document.getElementById('current-activity'),\n                        activityTitle: document.getElementById('activity-title'),\n                        activityDuration: document.getElementById('activity-duration'),\n                        activityDescription: document.getElementById('activity-description'),\n\n                        // Meta-tools elements\n                        metaToolsList: document.getElementById('meta-tools-list'),\n\n                        // System elements\n                        currentNode: document.getElementById('current-node'),\n                        nodeName: document.getElementById('node-name'),\n                        nodeOperation: document.getElementById('node-operation'),\n                        systemGrid: document.getElementById('system-grid'),\n\n                        // Graph elements\n                        agentGraph: document.getElementById('agent-graph')\n                    };\n                    this.init();\n                }\n\n\n                init() {\n\n                    this.configureAPIPaths();\n                    this.setupEventListeners();\n                    this.detectServerMode();\n                    this.startStatusUpdates();\n                }\n\n                configureAPIPaths() {\n                    const serverType = window.SERVER_CONFIG?.server_type || 'standalone';\n\n                    if (serverType === 'builtin') {\n                        this.apiPaths = {\n                            status: '/api/agent_ui/status',\n                            run: '/api/agent_ui/run_agent',\n                            reset: '/api/agent_ui/reset_context'\n                        };\n                        this.useWebSocket = true;\n                    } else {\n                        this.apiPaths = {\n                            status: '/api/status',\n                            run: '/api/run',\n                            reset: '/api/reset'\n                        };\n                        this.useWebSocket = false;\n                        this.enableFallbackMode();\n                    }\n                }\n\n                setupEventListeners() {\n                    this.elements.sendButton.addEventListener('click', () =&gt; this.sendMessage());\n                    this.elements.chatInput.addEventListener('keypress', (e) =&gt; {\n                        if (e.key === 'Enter' &amp;&amp; !this.isProcessing) {\n                            this.sendMessage();\n                        }\n                    });\n\n                    // Handle page visibility for reconnection\n                    document.addEventListener('visibilitychange', () =&gt; {\n                        if (!document.hidden &amp;&amp; (!this.ws || this.ws.readyState === WebSocket.CLOSED)) {\n                            this.connectWebSocket();\n                        }\n                    });\n                }\n\n                detectServerMode() {\n                    // Use configured paths instead of hardcoded ones\n                    fetch(this.apiPaths.status)\n                        .then(response =&gt; response.json())\n                        .then(data =&gt; {\n                            this.addLogEntry(`Server detected: ${data.server_type || 'standalone'}`, 'info');\n                            if (data.server_type === 'builtin' &amp;&amp; this.useWebSocket) {\n                                this.connectWebSocket();\n                            }\n                        })\n                        .catch(() =&gt; {\n                            this.addLogEntry('Server detection failed, using fallback mode', 'error');\n                            this.enableFallbackMode();\n                        });\n                }\n\n                connectWebSocket() {\n                    if (!this.useWebSocket) return;\n\n                    try {\n                        // Construct WebSocket URL more robustly\n                        const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';\n                        const wsUrl = `${protocol}//${window.location.host}/ws/agent_ui/connect`;\n\n                        this.addLogEntry(`Attempting WebSocket connection to: ${wsUrl}`);\n                        this.ws = new WebSocket(wsUrl);\n\n                        this.ws.onopen = () =&gt; {\n                            this.reconnectAttempts = 0;\n                            this.fallbackMode = false;\n                            this.setStatus('connected', 'Connected');\n                            this.addLogEntry('WebSocket connected successfully', 'success');\n                            this.removeFallbackIndicators();\n                        };\n\n                        this.ws.onmessage = (event) =&gt; {\n                            try {\n                                const message = JSON.parse(event.data);\n                                this.handleWebSocketMessage(message);\n                            } catch (error) {\n                                this.addLogEntry(`WebSocket message parse error: ${error.message}`, 'error');\n                            }\n                        };\n\n                        this.ws.onclose = (event) =&gt; {\n                            this.setStatus('disconnected', 'Disconnected');\n                            this.addLogEntry(`WebSocket disconnected (code: ${event.code})`, 'error');\n                            this.scheduleReconnection();\n                        };\n\n                        this.ws.onerror = (error) =&gt; {\n                            this.setStatus('error', 'Connection Error');\n                            this.addLogEntry('WebSocket connection error', 'error');\n                            this.scheduleReconnection();\n                        };\n\n                    } catch (error) {\n                        this.addLogEntry(`WebSocket setup error: ${error.message}`, 'error');\n                        this.enableFallbackMode();\n                    }\n                }\n\n                scheduleReconnection() {\n                    if (this.reconnectAttempts &gt;= this.maxReconnectAttempts) {\n                        this.addLogEntry('Max reconnection attempts reached, enabling fallback mode', 'error');\n                        this.enableFallbackMode();\n                        return;\n                    }\n\n                    this.reconnectAttempts++;\n                    const delay = Math.min(this.reconnectDelay * this.reconnectAttempts, 30000);\n\n                    this.setStatus('error', `Reconnecting in ${delay/1000}s (attempt ${this.reconnectAttempts})`);\n\n                    setTimeout(() =&gt; {\n                        if (!this.ws || this.ws.readyState === WebSocket.CLOSED) {\n                            this.connectWebSocket();\n                        }\n                    }, delay);\n                }\n\n                enableFallbackMode() {\n                    this.fallbackMode = true;\n                    this.useWebSocket = false;\n                    this.setStatus('disconnected', 'Fallback Mode (API Only)');\n                    this.showFallbackIndicator();\n                    this.addLogEntry('WebSocket unavailable - using API fallback mode', 'info');\n                }\n\n                showFallbackIndicator() {\n                    const indicator = document.createElement('div');\n                    indicator.className = 'fallback-mode';\n                    indicator.textContent = 'Using API fallback mode - limited real-time updates';\n                    indicator.id = 'fallback-indicator';\n                    document.body.appendChild(indicator);\n                }\n\n                removeFallbackIndicators() {\n                    const indicator = document.getElementById('fallback-indicator');\n                    if (indicator) {\n                        indicator.remove();\n                    }\n                }\n\n                handleWebSocketMessage(message) {\n                    try {\n                        switch (message.event) {\n                            case 'agent_connected':\n                                this.addLogEntry('Agent ready for interaction', 'success');\n                                this.updateSystemStatus({\n                                    status: 'Connected',\n                                    capabilities: message.data.capabilities\n                                });\n                                break;\n\n                            case 'processing_start':\n                                this.setProcessing(true);\n                                this.startTime = Date.now();\n                                this.addLogEntry(`Processing: ${message.data.query}`, 'progress');\n                                this.resetProgressTracking();\n                                break;\n\n                            case 'progress_update':\n                                this.handleProgressUpdate(message.data);\n                                break;\n\n                            case 'outline_update':\n                                this.handleOutlineUpdate(message.data);\n                                break;\n\n                            case 'meta_tool_update':\n                                this.handleMetaToolUpdate(message.data);\n                                break;\n\n                            case 'activity_update':\n                                this.handleActivityUpdate(message.data);\n                                break;\n\n                            case 'system_update':\n                                this.handleSystemUpdate(message.data);\n                                break;\n\n                            case 'graph_update':\n                                this.handleGraphUpdate(message.data);\n                                break;\n\n                            case 'chat_response':\n                                this.addMessage('agent', message.data.response);\n                                this.setProcessing(false);\n                                this.addLogEntry('Response completed', 'success');\n                                this.showFinalSummary(message.data);\n                                break;\n\n                            case 'error':\n                                this.addMessage('agent', `Error: ${message.data.error}`);\n                                this.setProcessing(false);\n                                this.addLogEntry(`Error: ${message.data.error}`, 'error');\n                                break;\n\n                            default:\n                                console.log('Unhandled WebSocket message:', message);\n                        }\n                    } catch (error) {\n                        this.addLogEntry(`Message handling error: ${error.message}`, 'error');\n                    }\n                }\n\n                handleProgressUpdate(data) {\n                    this.progressEvents.push(data);\n\n                    const progressText = `${data.event_type}: ${data.status || 'processing'}`;\n                    this.elements.progressText.textContent = progressText;\n\n                    // Update based on event type\n                    if (data.event_type === 'reasoning_loop') {\n                        this.addLogEntry(`\ud83e\udde0 Reasoning loop #${data.loop_number || '?'}`, 'reasoning');\n                        this.updateCurrentActivity({\n                            title: 'Reasoning',\n                            description: data.current_focus || 'Deep thinking in progress',\n                            duration: data.time_in_activity || 0\n                        });\n                    } else if (data.event_type === 'meta_tool_call') {\n                        this.addLogEntry(`\u2699\ufe0f Meta-tool: ${data.meta_tool_name || 'unknown'}`, 'meta-tool');\n                    } else {\n                        this.addLogEntry(`Progress - ${progressText}`, 'progress');\n                    }\n\n                    // Update system status\n                    this.updateSystemStatus({\n                        current_node: data.node_name,\n                        current_operation: data.event_type,\n                        runtime: this.getRuntime(),\n                        events: this.progressEvents.length\n                    });\n                }\n\n                handleOutlineUpdate(data) {\n                    this.currentOutline = data;\n\n                    if (data.outline_created &amp;&amp; data.steps) {\n                        this.elements.outlineTitle.textContent = 'Execution Outline';\n\n                        const completedCount = (data.completed_steps || []).length;\n                        const totalCount = data.total_steps || data.steps.length;\n\n                        this.elements.outlineStats.textContent = `${completedCount}/${totalCount} steps`;\n\n                        // Update progress bar\n                        const progress = totalCount &gt; 0 ? (completedCount / totalCount) * 100 : 0;\n                        this.elements.outlineProgressFill.style.width = `${progress}%`;\n\n                        // Update steps\n                        this.updateOutlineSteps(data.steps, data.current_step, data.completed_steps || []);\n\n                        this.addLogEntry(`Outline progress: ${completedCount}/${totalCount} steps completed`, 'outline');\n                    }\n                }\n\n                updateOutlineSteps(steps, currentStep, completedSteps) {\n                    this.elements.outlineSteps.innerHTML = '';\n\n                    steps.forEach((step, index) =&gt; {\n                        const stepEl = document.createElement('div');\n                        stepEl.className = 'outline-step';\n\n                        const stepId = step.id || (index + 1);\n                        let icon = '\u23f3';\n\n                        if (completedSteps.includes(stepId)) {\n                            stepEl.classList.add('completed');\n                            icon = '\u2705';\n                        } else if (stepId === currentStep) {\n                            stepEl.classList.add('active');\n                            icon = '\ud83d\udd04';\n                        }\n\n                        stepEl.innerHTML = `\n                            &lt;div class=\"step-icon\"&gt;${icon}&lt;/div&gt;\n                            &lt;div class=\"step-text\"&gt;${step.description || `Step ${stepId}`}&lt;/div&gt;\n                            &lt;div class=\"step-method\"&gt;${step.method || 'unknown'}&lt;/div&gt;\n                        `;\n\n                        this.elements.outlineSteps.appendChild(stepEl);\n                    });\n                }\n\n                handleMetaToolUpdate(data) {\n                    const toolId = `${data.meta_tool_name}_${Date.now()}`;\n                    const toolData = {\n                        name: data.meta_tool_name,\n                        status: data.status || 'running',\n                        timestamp: Date.now(),\n                        phase: data.execution_phase,\n                        data: data\n                    };\n\n                    this.metaTools.set(toolId, toolData);\n                    this.updateMetaToolsList();\n\n                    // Add to log with appropriate icon\n                    const statusIcon = data.status === 'completed' ? '\u2705' :\n                                     data.status === 'error' ? '\u274c' : '\u2699\ufe0f';\n                    this.addLogEntry(`${statusIcon} ${data.meta_tool_name}: ${data.status || 'running'}`, 'meta-tool');\n                }\n\n                updateMetaToolsList() {\n                    this.elements.metaToolsList.innerHTML = '';\n\n                    if (this.metaTools.size === 0) {\n                        this.elements.metaToolsList.innerHTML = `\n                            &lt;div style=\"color: var(--text-muted); font-size: 12px; text-align: center; padding: 20px;\"&gt;\n                                No meta-tool activity yet\n                            &lt;/div&gt;\n                        `;\n                        return;\n                    }\n\n                    // Show recent meta-tools (last 8)\n                    const recentTools = Array.from(this.metaTools.values())\n                        .sort((a, b) =&gt; b.timestamp - a.timestamp)\n                        .slice(0, 8);\n\n                    recentTools.forEach(tool =&gt; {\n                        const toolEl = document.createElement('div');\n                        toolEl.className = 'meta-tool';\n\n                        const icons = {\n                            internal_reasoning: '\ud83e\udde0',\n                            delegate_to_llm_tool_node: '\ud83c\udfaf',\n                            create_and_execute_plan: '\ud83d\udccb',\n                            manage_internal_task_stack: '\ud83d\udcda',\n                            advance_outline_step: '\u27a1\ufe0f',\n                            write_to_variables: '\ud83d\udcbe',\n                            read_from_variables: '\ud83d\udcd6',\n                            direct_response: '\u2728'\n                        };\n\n                        const icon = icons[tool.name] || '\u2699\ufe0f';\n                        const displayName = tool.name.replace(/_/g, ' ');\n                        const age = Math.floor((Date.now() - tool.timestamp) / 1000);\n\n                        toolEl.innerHTML = `\n                            &lt;div class=\"tool-icon\"&gt;${icon}&lt;/div&gt;\n                            &lt;div class=\"tool-name\"&gt;${displayName} (${age}s ago)&lt;/div&gt;\n                            &lt;div class=\"tool-status ${tool.status}\"&gt;${tool.status}&lt;/div&gt;\n                        `;\n\n                        this.elements.metaToolsList.appendChild(toolEl);\n                    });\n                }\n\n                handleActivityUpdate(data) {\n                    this.currentActivity = data;\n                    this.updateCurrentActivity(data);\n                }\n\n                updateCurrentActivity(data) {\n                    if (data.primary_activity &amp;&amp; data.primary_activity !== 'Unknown') {\n                        this.elements.currentActivity.style.display = 'block';\n                        this.elements.activityTitle.textContent = data.primary_activity || data.title;\n\n                        const duration = data.time_in_current_activity || data.duration || 0;\n                        if (duration &gt; 0) {\n                            this.elements.activityDuration.textContent = this.formatDuration(duration);\n                        }\n\n                        this.elements.activityDescription.textContent =\n                            data.detailed_description || data.description || '';\n                    } else {\n                        this.elements.currentActivity.style.display = 'none';\n                    }\n                }\n\n                handleSystemUpdate(data) {\n                    this.systemStatus = { ...this.systemStatus, ...data };\n                    this.updateSystemStatus(data);\n                }\n\n                updateSystemStatus(data) {\n                    // Update current node\n                    if (data.current_node) {\n                        this.elements.nodeName.textContent = data.current_node;\n                        this.elements.nodeOperation.textContent = data.current_operation || 'Processing';\n                    }\n\n                    // Update system grid\n                    const gridData = [\n                        ['Status', data.status || this.systemStatus.status || 'Running'],\n                        ['Runtime', this.formatDuration(data.runtime || this.getRuntime())],\n                        ['Events', data.events || this.progressEvents.length],\n                        ['Errors', data.error_count || this.systemStatus.error_count || 0],\n                        ['Node', data.current_node || this.systemStatus.current_node || 'Unknown']\n                    ];\n\n                    if (data.total_cost !== undefined) {\n                        gridData.push(['Cost', `$${data.total_cost.toFixed(4)}`]);\n                    }\n\n                    if (data.total_tokens !== undefined) {\n                        gridData.push(['Tokens', data.total_tokens.toLocaleString()]);\n                    }\n\n                    this.elements.systemGrid.innerHTML = '';\n                    gridData.forEach(([key, value]) =&gt; {\n                        this.elements.systemGrid.innerHTML += `\n                            &lt;div class=\"system-key\"&gt;${key}&lt;/div&gt;\n                            &lt;div class=\"system-value\"&gt;${value}&lt;/div&gt;\n                        `;\n                    });\n                }\n\n                handleGraphUpdate(data) {\n                    this.agentGraph = data.nodes || [];\n                    this.updateAgentGraph();\n                }\n\n                updateAgentGraph() {\n                    this.elements.agentGraph.innerHTML = '';\n\n                    if (this.agentGraph.length === 0) {\n                        const currentNode = this.systemStatus.current_node || 'LLMReasonerNode';\n                        this.elements.agentGraph.innerHTML = `\n                            &lt;div class=\"graph-node active\"&gt;${currentNode}&lt;/div&gt;\n                            &lt;div class=\"graph-arrow\"&gt;\u2193&lt;/div&gt;\n                            &lt;div class=\"graph-node\"&gt;Processing&lt;/div&gt;\n                        `;\n                        return;\n                    }\n\n                    this.agentGraph.forEach((node, index) =&gt; {\n                        const nodeEl = document.createElement('div');\n                        nodeEl.className = 'graph-node';\n\n                        if (node.active) nodeEl.classList.add('active');\n                        if (node.completed) nodeEl.classList.add('completed');\n\n                        nodeEl.textContent = node.name || `Node ${index + 1}`;\n                        this.elements.agentGraph.appendChild(nodeEl);\n\n                        if (index &lt; this.agentGraph.length - 1) {\n                            const arrow = document.createElement('div');\n                            arrow.className = 'graph-arrow';\n                            arrow.textContent = '\u2193';\n                            this.elements.agentGraph.appendChild(arrow);\n                        }\n                    });\n                }\n\n                async sendMessage() {\n                    const message = this.elements.chatInput.value.trim();\n                    if (!message || this.isProcessing) return;\n\n                    this.addMessage('user', message);\n                    this.elements.chatInput.value = '';\n\n                    if (this.useWebSocket &amp;&amp; this.ws &amp;&amp; this.ws.readyState === WebSocket.OPEN) {\n                        // Send via WebSocket\n                        this.ws.send(JSON.stringify({\n                            event: 'chat_message',\n                            data: {\n                                message: message,\n                                session_id: this.sessionId\n                            }\n                        }));\n                    } else {\n                        // Fallback to API\n                        await this.sendMessageViaAPI(message);\n                    }\n                }\n\n                async sendMessageViaAPI(message) {\n                    this.setProcessing(true);\n                    this.startTime = Date.now();\n                    this.resetProgressTracking();\n\n                    try {\n                        const response = await fetch(this.apiPaths.run, {\n                            method: 'POST',\n                            headers: {\n                                'Content-Type': 'application/json'\n                            },\n                            body: JSON.stringify({\n                                query: message,\n                                session_id: this.sessionId,\n                                include_progress: true\n                            })\n                        });\n\n                        const result = await response.json();\n\n                        if (result.success) {\n                            this.addMessage('agent', result.result);\n                            this.addLogEntry(`Request completed via API`, 'success');\n\n                            // Process progress events if available\n                            if (result.progress_events) {\n                                this.processAPIProgressEvents(result.progress_events);\n                            }\n\n                            // Process enhanced progress if available\n                            if (result.enhanced_progress) {\n                                this.processEnhancedProgress(result.enhanced_progress);\n                            }\n                        } else {\n                            this.addMessage('agent', `Error: ${result.error}`);\n                            this.addLogEntry(`API request failed: ${result.error}`, 'error');\n                        }\n\n                    } catch (error) {\n                        this.addMessage('agent', `Network error: ${error.message}`);\n                        this.addLogEntry(`Network error: ${error.message}`, 'error');\n                    } finally {\n                        this.setProcessing(false);\n                    }\n                }\n\n                processAPIProgressEvents(events) {\n                    events.forEach(event =&gt; {\n                        this.handleProgressUpdate(event);\n                    });\n                }\n\n                processEnhancedProgress(progress) {\n                    if (progress.outline) {\n                        this.handleOutlineUpdate(progress.outline);\n                    }\n                    if (progress.activity) {\n                        this.handleActivityUpdate(progress.activity);\n                    }\n                    if (progress.system) {\n                        this.handleSystemUpdate(progress.system);\n                    }\n                    if (progress.graph) {\n                        this.handleGraphUpdate(progress.graph);\n                    }\n                }\n\n                resetProgressTracking() {\n                    this.progressEvents = [];\n                    this.metaTools.clear();\n                    this.updateSystemStatus({ status: 'Processing', events: 0 });\n                }\n\n                showFinalSummary(data) {\n                    if (data.final_summary) {\n                        const summary = data.final_summary;\n                        this.addLogEntry(`Final Summary - Outline: ${summary.outline_completed ? 'Complete' : 'Partial'}, Meta-tools: ${summary.total_meta_tools}, Nodes: ${summary.total_nodes}`, 'success');\n                    }\n                }\n\n                addMessage(sender, content) {\n                    const messageEl = document.createElement('div');\n                    messageEl.classList.add('message', sender);\n\n                    const avatarEl = document.createElement('div');\n                    avatarEl.classList.add('message-avatar');\n                    avatarEl.textContent = sender === 'user' ? 'You' : 'AI';\n\n                    const contentEl = document.createElement('div');\n                    contentEl.classList.add('message-content');\n\n                    if (sender === 'agent' &amp;&amp; window.marked) {\n                        try {\n                            contentEl.innerHTML = marked.parse(content);\n                        } catch (error) {\n                            contentEl.textContent = content;\n                        }\n                    } else {\n                        contentEl.textContent = content;\n                    }\n\n                    messageEl.appendChild(avatarEl);\n                    messageEl.appendChild(contentEl);\n\n                    this.elements.chatMessages.appendChild(messageEl);\n                    this.elements.chatMessages.scrollTop = this.elements.chatMessages.scrollHeight;\n                }\n\n                addLogEntry(message, type = 'info') {\n                    // For debugging - could show in a log panel\n                    const timestamp = new Date().toLocaleTimeString();\n                    console.log(`[${timestamp}] [${type.toUpperCase()}] ${message}`);\n                }\n\n                setStatus(status, text) {\n                    this.elements.statusDot.className = `status-dot ${status}`;\n                    this.elements.statusText.textContent = text;\n                }\n\n                setProcessing(processing) {\n                    this.isProcessing = processing;\n                    this.elements.sendButton.disabled = processing;\n                    this.elements.chatInput.disabled = processing;\n\n                    if (processing) {\n                        this.elements.progressIndicator.classList.add('active');\n                        this.setStatus('processing', 'Processing');\n                    } else {\n                        this.elements.progressIndicator.classList.remove('active');\n                        this.setStatus(this.ws &amp;&amp; this.ws.readyState === WebSocket.OPEN ? 'connected' : 'disconnected',\n                                      this.ws &amp;&amp; this.ws.readyState === WebSocket.OPEN ? 'Connected' : 'Disconnected');\n                        this.startTime = null;\n                    }\n                }\n\n                formatDuration(seconds) {\n                    if (typeof seconds !== 'number') return '0s';\n                    if (seconds &lt; 60) return `${seconds.toFixed(1)}s`;\n                    if (seconds &lt; 3600) return `${Math.floor(seconds/60)}m${Math.floor(seconds%60)}s`;\n                    return `${Math.floor(seconds/3600)}h${Math.floor((seconds%3600)/60)}m`;\n                }\n\n                getRuntime() {\n                    return this.startTime ? (Date.now() - this.startTime) / 1000 : 0;\n                }\n\n                startStatusUpdates() {\n                    setInterval(() =&gt; {\n                        if (this.isProcessing) {\n                            this.updateSystemStatus({ runtime: this.getRuntime() });\n                        }\n                    }, 1000);\n                }\n            }\n\n            // Initialize the production UI\n            if (!window.TB) {\n\n                document.addEventListener('DOMContentLoaded', () =&gt; {\n                    window.agentUI = new ProductionAgentUI();\n                });\n            } else {\n                TB.once(() =&gt; {\n                    window.agentUI = new ProductionAgentUI();\n                });\n            }\n        &lt;/script&gt;\n    &lt;/body&gt;\n    &lt;/html&gt;\"\"\"\n\n        return (html_template.\n                replace(\"{agent_name}\", agent_info.get('public_name', 'Agent Interface')).\n                replace(\"{agent_description}\", agent_info.get('description', '')).\n                replace(\"__SERVER_CONFIG__\", js_config)\n                )\n\n    async def _handle_chat_message_with_progress_integration(self, agent_id: str, agent, conn_id: str, data: dict):\n        \"\"\"Enhanced chat message handler with ProgressiveTreePrinter integration.\"\"\"\n        query = data.get('message', '')\n        session_id = data.get('session_id', f\"ui_session_{conn_id}\")\n\n        if not query:\n            return\n\n        # Create ProgressiveTreePrinter for real-time UI updates\n        from toolboxv2.mods.isaa.extras.terminal_progress import (\n            ProgressiveTreePrinter,\n            VerbosityMode,\n        )\n        progress_printer = ProgressiveTreePrinter(\n            mode=VerbosityMode.STANDARD,\n            use_rich=False,\n            auto_refresh=False\n        )\n\n        # Enhanced progress callback that extracts all UI data\n        async def comprehensive_progress_callback(event):\n            try:\n                # Add event to progress printer for processing\n                progress_printer.tree_builder.add_event(event)\n\n                # Get comprehensive summary from the printer\n                summary = progress_printer.tree_builder.get_execution_summary()\n\n                # Extract outline information\n                outline_info = progress_printer._get_current_outline_info()\n\n                # Extract current activity\n                activity_info = progress_printer._get_detailed_current_activity()\n\n                # Extract tool usage\n                tool_usage = progress_printer._get_tool_usage_summary()\n\n                # Extract task progress\n                task_progress = progress_printer._get_task_executor_progress()\n\n                # Send basic progress update\n                await self._broadcast_to_agent_ui(agent_id, {\n                    'event': 'progress_update',\n                    'data': {\n                        'event_type': event.event_type,\n                        'status': getattr(event, 'status', 'processing').value if hasattr(event, 'status') and event.status else 'unknown',\n                        'node_name': getattr(event, 'node_name', 'Unknown'),\n                        'timestamp': event.timestamp,\n                        'loop_number': getattr(event.metadata, {}).get('reasoning_loop', 0),\n                        'meta_tool_name': getattr(event.metadata, {}).get('meta_tool_name'),\n                        'current_focus': getattr(event.metadata, {}).get('current_focus', ''),\n                        'time_in_activity': activity_info.get('time_in_current_activity', 0)\n                    }\n                })\n\n                # Send outline updates\n                if outline_info.get('outline_created'):\n                    await self._broadcast_to_agent_ui(agent_id, {\n                        'event': 'outline_update',\n                        'data': outline_info\n                    })\n\n                # Send meta-tool updates\n                if event.metadata and event.metadata.get('meta_tool_name'):\n                    await self._broadcast_to_agent_ui(agent_id, {\n                        'event': 'meta_tool_update',\n                        'data': {\n                            'meta_tool_name': event.metadata['meta_tool_name'],\n                            'status': 'completed' if event.success else (\n                                'error' if event.success is False else 'running'),\n                            'execution_phase': event.metadata.get('execution_phase', 'unknown'),\n                            'reasoning_loop': event.metadata.get('reasoning_loop', 0),\n                            'timestamp': event.timestamp\n                        }\n                    })\n\n                # Send activity updates\n                if activity_info['primary_activity'] != 'Unknown':\n                    await self._broadcast_to_agent_ui(agent_id, {\n                        'event': 'activity_update',\n                        'data': activity_info\n                    })\n\n                # Send system updates\n                await self._broadcast_to_agent_ui(agent_id, {\n                    'event': 'system_update',\n                    'data': {\n                        'current_node': summary['execution_flow']['current_node'],\n                        'current_operation': activity_info.get('primary_activity', 'Processing'),\n                        'status': 'Processing',\n                        'runtime': summary['timing']['elapsed'],\n                        'total_events': summary['performance_metrics']['total_events'],\n                        'error_count': summary['performance_metrics']['error_count'],\n                        'total_cost': summary['performance_metrics']['total_cost'],\n                        'total_tokens': summary['performance_metrics']['total_tokens'],\n                        'completed_nodes': summary['session_info']['completed_nodes'],\n                        'total_nodes': summary['session_info']['total_nodes'],\n                        'tool_usage': {\n                            'tools_used': list(tool_usage.get('tools_used', set())),\n                            'tools_active': list(tool_usage.get('tools_active', set())),\n                            'current_tool_operation': tool_usage.get('current_tool_operation')\n                        }\n                    }\n                })\n\n                # Send graph updates\n                flow_nodes = []\n                for node_name in summary['execution_flow']['flow']:\n                    if node_name in progress_printer.tree_builder.nodes:\n                        node = progress_printer.tree_builder.nodes[node_name]\n                        flow_nodes.append({\n                            'name': node_name,\n                            'active': node_name in summary['execution_flow']['active_nodes'],\n                            'completed': (node.status.value == 'completed') if node.status else False,\n                            'status': node.status.value if node.status else 'unknown'\n                        })\n\n                if flow_nodes:\n                    await self._broadcast_to_agent_ui(agent_id, {\n                        'event': 'graph_update',\n                        'data': {'nodes': flow_nodes}\n                    })\n\n            except Exception as e:\n                self.app.print(f\"Comprehensive progress callback error: {e}\")\n\n        # Set progress callback\n        original_callback = getattr(agent, 'progress_callback', None)\n\n        try:\n            if hasattr(agent, 'set_progress_callback'):\n                agent.set_progress_callback(comprehensive_progress_callback)\n            elif hasattr(agent, 'progress_callback'):\n                agent.progress_callback = comprehensive_progress_callback\n\n            # Send processing start notification\n            await self._broadcast_to_agent_ui(agent_id, {\n                'event': 'processing_start',\n                'data': {'query': query, 'session_id': session_id}\n            })\n\n            # Execute agent\n            result = await agent.a_run(query=query, session_id=session_id)\n\n            # Get final summary\n            final_summary = progress_printer.tree_builder.get_execution_summary()\n\n            # Extract outline information\n            outline_info = progress_printer._get_current_outline_info()\n\n            # Initialize outline_info if empty\n            if not outline_info or not outline_info.get('steps'):\n                outline_info = {\n                    'steps': [],\n                    'current_step': 1,\n                    'completed_steps': [],\n                    'total_steps': 0,\n                    'step_descriptions': {},\n                    'current_step_progress': \"\",\n                    'outline_raw_data': None,\n                    'outline_created': False,\n                    'actual_step_completions': []\n                }\n\n            # Try to infer outline from execution pattern if not found\n            if not outline_info.get('outline_created'):\n                outline_info = progress_printer._infer_outline_from_execution_pattern(outline_info)\n\n            # Send final result with summary\n            await self._broadcast_to_agent_ui(agent_id, {\n                'event': 'chat_response',\n                'data': {\n                    'response': result,\n                    'query': query,\n                    'session_id': session_id,\n                    'completed_at': asyncio.get_event_loop().time(),\n                    'final_summary': {\n                        'outline_completed': len(outline_info.get('completed_steps', [])) == outline_info.get(\n                            'total_steps', 0),\n                        'total_meta_tools': len([e for e in progress_printer.tree_builder.nodes.values()\n                                                 for event in e.llm_calls + e.sub_events\n                                                 if event.metadata and event.metadata.get('meta_tool_name')]),\n                        'total_nodes': final_summary['session_info']['total_nodes'],\n                        'execution_time': final_summary['timing']['elapsed'],\n                        'total_cost': final_summary['performance_metrics']['total_cost']\n                    }\n                }\n            })\n\n        except Exception as e:\n            await self._broadcast_to_agent_ui(agent_id, {\n                'event': 'error',\n                'data': {'error': str(e), 'query': query}\n            })\n        finally:\n            # Restore original callback\n            if hasattr(agent, 'set_progress_callback'):\n                agent.set_progress_callback(original_callback)\n            elif hasattr(agent, 'progress_callback'):\n                agent.progress_callback = original_callback\n\n    # Replace the existing method\n    async def _handle_chat_message(self, agent_id: str, agent, conn_id: str, data: dict):\n        \"\"\"Delegate to enhanced handler.\"\"\"\n        await self._handle_chat_message_with_progress_integration(agent_id, agent, conn_id, data)\n\n    # Unified publish and host method\n    # toolboxv2/mods/isaa/Tools.py\n\n    async def publish_and_host_agent(\n        self,\n        agent,\n        public_name: str,\n        registry_server: str = \"ws://localhost:8080/ws/registry/connect\",\n        description: str | None = None,\n        access_level: str = \"public\"\n    ) -&gt; dict[str, Any]:\n        \"\"\"FIXED: Mit Debug-Ausgaben f\u00fcr Troubleshooting.\"\"\"\n\n        if hasattr(agent, 'name') and not hasattr(agent, 'amd') and hasattr(agent, 'a_run'):\n            agent.amd = lambda :None\n            agent.amd.name = agent.name\n\n        try:\n            # Registry Client initialisieren\n            from toolboxv2.mods.registry.client import get_registry_client\n            registry_client = get_registry_client(self.app)\n\n            self.app.print(f\"Connecting to registry server: {registry_server}\")\n            await registry_client.connect(registry_server)\n\n            # Progress Callback f\u00fcr Live-Updates einrichten\n            callback_success = await self.setup_live_progress_callback(agent, registry_client, f\"agent_{agent.amd.name}\")\n            if not callback_success:\n                self.app.print(\"Warning: Progress callback setup failed\")\n            else:\n                self.app.print(\"\u2705 Progress callback setup successful\")\n\n            # Agent beim Registry registrieren\n            self.app.print(f\"Registering agent: {public_name}\")\n            registration_info = await registry_client.register(\n                agent_instance=agent,\n                public_name=public_name,\n                description=description or f\"Agent: {public_name}\"\n            )\n\n            if not registration_info:\n                return {\"error\": \"Registration failed\", \"success\": False}\n\n            self.app.print(f\"\u2705 Agent registration successful: {registration_info.public_agent_id}\")\n\n            result = {\n                \"success\": True,\n                \"agent_name\": public_name,\n                \"public_agent_id\": registration_info.public_agent_id,\n                \"public_api_key\": registration_info.public_api_key,\n                \"public_url\": registration_info.public_url,\n                \"registry_server\": registry_server,\n                \"access_level\": access_level,\n                \"ui_url\": registration_info.public_url.replace(\"/api/registry/run\", \"/api/registry/ui\"),\n                \"websocket_url\": registry_server.replace(\"/connect\", \"/ui_connect\"),\n                \"status\": \"registered\"\n            }\n\n            return result\n\n        except Exception as e:\n            self.app.print(f\"Failed to publish agent: {e}\")\n            return {\"error\": str(e), \"success\": False}\n\n    # toolboxv2/mods/isaa/Tools.py\n\n    async def setup_live_progress_callback(self, agent, registry_client, agent_id: str = None):\n        \"\"\"Enhanced setup for live progress callback with proper error handling.\"\"\"\n\n        if not registry_client:\n            self.app.print(\"Warning: No registry client provided for progress updates\")\n            return False\n\n        if not registry_client.is_connected:\n            self.app.print(\"Warning: Registry client is not connected\")\n            return False\n\n        progress_tracker = EnhancedProgressTracker()\n\n        # Generate agent ID if not provided\n        if not agent_id:\n            agent_id = getattr(agent, 'name', f'agent_{id(agent)}')\n\n        async def enhanced_live_progress_callback(event: ProgressEvent):\n            \"\"\"Enhanced progress callback with comprehensive data extraction.\"\"\"\n            try:\n                # Validate event\n                if not event:\n                    self.app.print(\"Warning: Received null progress event\")\n                    return\n\n                # Debug output for local development\n                event_type = getattr(event, 'event_type', 'unknown')\n                status = getattr(event, 'status', 'unknown')\n                agent_name = getattr(event, 'agent_name', 'Unknown Agent')\n\n                self.app.print(f\"\ud83d\udcca Progress Event: {event_type} | {status} | {agent_name}\")\n\n                # Extract comprehensive progress data\n                progress_data = progress_tracker.extract_progress_data(event)\n\n                # Prepare enhanced progress message\n                ui_progress_data = {\n                    \"agent_id\": agent_id,\n                    \"event_type\": event_type,\n                    \"status\": status.value if hasattr(status, 'value') else str(status),\n                    \"timestamp\": getattr(event, 'timestamp', asyncio.get_event_loop().time()),\n                    \"agent_name\": agent_name,\n                    \"node_name\": getattr(event, 'node_name', 'Unknown'),\n                    \"session_id\": getattr(event, 'session_id', None),\n\n                    # Core event metadata\n                    \"metadata\": {\n                        **getattr(event, 'metadata', {}),\n                        \"event_id\": getattr(event, 'event_id', f\"evt_{asyncio.get_event_loop().time()}\"),\n                        \"sequence_number\": getattr(event, 'sequence_number', 0),\n                        \"parent_event_id\": getattr(event, 'parent_event_id', None)\n                    },\n\n                    # Detailed progress data for UI panels\n                    \"progress_data\": progress_data,\n\n                    # UI-specific flags for selective updates\n                    \"ui_flags\": {\n                        \"should_update_outline\": bool(progress_data.get('outline')),\n                        \"should_update_activity\": bool(progress_data.get('activity')),\n                        \"should_update_meta_tools\": bool(progress_data.get('meta_tool')),\n                        \"should_update_system\": bool(progress_data.get('system')),\n                        \"should_update_graph\": bool(progress_data.get('graph')),\n                        \"is_error\": event_type.lower() in ['error', 'exception', 'failed'],\n                        \"is_completion\": event_type.lower() in ['complete', 'finished', 'success'],\n                        \"requires_user_input\": getattr(event, 'requires_user_input', False)\n                    },\n\n                    # Performance metrics\n                    \"performance\": {\n                        \"execution_time\": getattr(event, 'execution_time', None),\n                        \"memory_delta\": getattr(event, 'memory_delta', None),\n                        \"tokens_used\": getattr(event, 'tokens_used', None),\n                        \"api_calls_made\": getattr(event, 'api_calls_made', None)\n                    }\n                }\n\n                # Send live update to registry server\n                await registry_client.send_ui_progress(ui_progress_data)\n\n                # Also send agent status update if this is a significant event\n                if event_type in ['started', 'completed', 'error', 'paused', 'resumed']:\n                    agent_status = 'processing'\n                    if event_type == 'completed':\n                        agent_status = 'idle'\n                    elif event_type == 'error':\n                        agent_status = 'error'\n                    elif event_type == 'paused':\n                        agent_status = 'paused'\n\n                    await registry_client.send_agent_status(\n                        agent_id=agent_id,\n                        status=agent_status,\n                        details={\n                            \"last_event\": event_type,\n                            \"last_update\": ui_progress_data[\"timestamp\"],\n                            \"current_node\": progress_data.get('graph', {}).get('current_node', 'Unknown')\n                        }\n                    )\n\n                # Log successful progress update\n                self.app.print(f\"\u2705 Sent progress update: {event_type} -&gt; Registry Server\")\n\n            except Exception as e:\n                self.app.print(f\"\u274c Progress callback error: {e}\")\n                # Send error notification to UI\n                try:\n                    await registry_client.send_ui_progress({\n                        \"agent_id\": agent_id,\n                        \"event_type\": \"progress_callback_error\",\n                        \"status\": \"error\",\n                        \"timestamp\": asyncio.get_event_loop().time(),\n                        \"agent_name\": getattr(agent, 'name', 'Unknown'),\n                        \"metadata\": {\"error\": str(e)},\n                        \"ui_flags\": {\"is_error\": True}\n                    })\n                except Exception as nested_error:\n                    self.app.print(f\"Failed to send error notification: {nested_error}\")\n\n        # Set up progress callback with enhanced error handling\n        callback_set = False\n\n        if hasattr(agent, 'set_progress_callback'):\n            try:\n                self.app.print(f\"\ud83d\udd27 Setting progress callback via set_progress_callback for agent: {agent_id}\")\n                agent.set_progress_callback(enhanced_live_progress_callback)\n                callback_set = True\n            except Exception as e:\n                self.app.print(f\"Failed to set progress callback via set_progress_callback: {e}\")\n\n        if not callback_set and hasattr(agent, 'progress_callback'):\n            try:\n                self.app.print(f\"\ud83d\udd27 Setting progress callback via direct assignment for agent: {agent_id}\")\n                agent.progress_callback = enhanced_live_progress_callback\n                callback_set = True\n            except Exception as e:\n                self.app.print(f\"Failed to set progress callback via direct assignment: {e}\")\n\n        if not callback_set:\n            self.app.print(f\"\u26a0\ufe0f Warning: Agent {agent_id} doesn't support progress callbacks\")\n            return False\n\n        # Send initial agent status\n        try:\n            await registry_client.send_agent_status(\n                agent_id=agent_id,\n                status='online',\n                details={\n                    \"progress_callback_enabled\": True,\n                    \"callback_setup_time\": asyncio.get_event_loop().time(),\n                    \"agent_type\": type(agent).__name__\n                }\n            )\n            self.app.print(f\"\u2705 Progress callback successfully set up for agent: {agent_id}\")\n        except Exception as e:\n            self.app.print(f\"Failed to send initial agent status: {e}\")\n\n        return True\n\n\n    async def _setup_builtin_server_hosting(self, agent_id: str, agent, host, port) -&gt; dict[str, str]:\n        \"\"\"Setup agent hosting using toolbox built-in server with enhanced WebSocket support.\"\"\"\n\n        # Register WebSocket handlers for this agent\n        @self.app.tb(mod_name=\"agent_ui\", websocket_handler=\"connect\")\n        def register_agent_ws_handlers(_):\n            return {\n                \"on_connect\": self._create_agent_ws_connect_handler(agent_id),\n                \"on_message\": self._create_agent_ws_message_handler(agent_id, agent),\n                \"on_disconnect\": self._create_agent_ws_disconnect_handler(agent_id),\n            }\n\n        # Register UI endpoint - now uses enhanced UI\n        @self.app.tb(mod_name=\"agent_ui\", api=True, version=\"1\", api_methods=['GET'])\n        async def ui():\n            return Result.html(\n                self._get_enhanced_agent_ui_html(agent_id), row=True\n            )\n\n        # Register API endpoint for direct agent interaction\n        @self.app.tb(mod_name=\"agent_ui\", api=True, version=\"1\", request_as_kwarg=True, api_methods=['POST'])\n        async def run_agent(request: RequestData):\n            return await self._handle_direct_agent_run(agent_id, agent, request)\n\n        # Register additional API endpoints for enhanced features\n        @self.app.tb(mod_name=\"agent_ui\", api=True, version=\"1\", request_as_kwarg=True, api_methods=['POST'])\n        async def reset_context(request: RequestData):\n            return await self._handle_api_reset_context(agent_id, agent, request)\n\n        @self.app.tb(mod_name=\"agent_ui\", api=True, version=\"1\", request_as_kwarg=True, api_methods=['GET'])\n        async def status(request: RequestData):\n            return await self._handle_api_get_status(agent_id, agent, request)\n\n        # WebSocket endpoint URL\n        uri = f\"{host}:{port}\" if port else f\"{host}\"\n        ws_url = f\"ws://{uri}/ws/agent_ui/connect\"\n        ui_url = f\"http://{uri}/api/agent_ui/ui\"\n        api_url = f\"http://{uri}/api/agent_ui/run_agent\"\n\n        return {\n            'ui_url': ui_url,\n            'ws_url': ws_url,\n            'api_url': api_url,\n            'reset_url': f\"http://localhost:{self.app.args_sto.port}/api/agent_ui/reset_context\",\n            'status_url': f\"http://localhost:{self.app.args_sto.port}/api/agent_ui/status\",\n            'server_type': 'builtin',\n            'status': 'running'\n        }\n\n    async def _setup_standalone_server_hosting(self, agent_id: str, agent, host: str, port: int) -&gt; dict[str, str]:\n        \"\"\"Setup agent hosting using standalone Python HTTP server with enhanced UI support.\"\"\"\n\n        if not hasattr(self, '_standalone_servers'):\n            self._standalone_servers = {}\n\n        if port in self._standalone_servers:\n            self.app.print(f\"Port {port} is already in use by another agent\")\n            return {'status': 'error', 'error': f'Port {port} already in use'}\n\n        # Store server info for the handler\n        server_info = {\n            'agent_id': agent_id,\n            'server_type': 'standalone',\n            'api_paths': {\n                'ui': '/ui',\n                'status': '/api/status',\n                'run': '/api/run',\n                'reset': '/api/reset'\n            }\n        }\n\n        # Create handler factory with agent reference and server info\n        def handler_factory(*args, **kwargs):\n            handler = EnhancedAgentRequestHandler(self, agent_id, agent, *args, **kwargs)\n            handler.server_info = server_info\n            return handler\n\n        # Start HTTP server in separate thread\n        def run_server():\n            try:\n                httpd = HTTPServer((host, port), handler_factory)\n                self._standalone_servers[port] = {\n                    'server': httpd,\n                    'agent_id': agent_id,\n                    'thread': threading.current_thread(),\n                    'server_info': server_info\n                }\n\n                self.app.print(f\"Enhanced standalone server for agent '{agent_id}' running on http://{host}:{port}\")\n                self.app.print(f\"  UI: http://{host}:{port}/ui\")\n                self.app.print(f\"  API: http://{host}:{port}/api/run\")\n                self.app.print(f\"  Status: http://{host}:{port}/api/status\")\n\n                httpd.serve_forever()\n\n            except Exception as e:\n                self.app.print(f\"Standalone server failed: {e}\")\n            finally:\n                if port in self._standalone_servers:\n                    del self._standalone_servers[port]\n\n        # Start server in daemon thread\n        server_thread = threading.Thread(target=run_server, daemon=True)\n        server_thread.start()\n\n        # Wait a moment to ensure server starts\n        await asyncio.sleep(0.5)\n\n        return {\n            'server_type': 'standalone',\n            'local_url': f\"http://{host}:{port}\",\n            'ui_url': f\"http://{host}:{port}/ui\",\n            'api_url': f\"http://{host}:{port}/api/run\",\n            'reset_url': f\"http://{host}:{port}/api/reset\",\n            'status_url': f\"http://{host}:{port}/api/status\",\n            'status': 'running',\n            'port': port\n        }\n\n    async def _handle_direct_agent_run(self, agent_id: str, agent, request_data) -&gt; Result:\n        \"\"\"Handle direct agent API calls with enhanced progress tracking.\"\"\"\n\n        try:\n            # Parse request body\n            body = request_data.body if hasattr(request_data, 'body') else {}\n\n            if not isinstance(body, dict):\n                return Result.default_user_error(\"Request body must be JSON object\", exec_code=400)\n\n            query = body.get('query', '')\n            session_id = body.get('session_id', f'api_{secrets.token_hex(8)}')\n            kwargs = body.get('kwargs', {})\n            include_progress = body.get('include_progress', True)\n\n            if not query:\n                return Result.default_user_error(\"Missing 'query' field in request body\", exec_code=400)\n\n            # Enhanced progress tracking for API\n            progress_events = []\n            enhanced_progress = {}\n\n            async def enhanced_api_progress_callback(event):\n                if include_progress:\n                    progress_tracker = EnhancedProgressTracker()\n                    progress_data = progress_tracker.extract_progress_data(event)\n\n                    progress_events.append({\n                        'timestamp': event.timestamp,\n                        'event_type': event.event_type,\n                        'status': event.status.value if event.status else 'unknown',\n                        'agent_name': event.agent_name,\n                        'metadata': event.metadata\n                    })\n\n                    # Store enhanced progress data\n                    enhanced_progress.update(progress_data)\n\n            # Set progress callback\n            original_callback = getattr(agent, 'progress_callback', None)\n\n            try:\n                if hasattr(agent, 'set_progress_callback'):\n                    agent.set_progress_callback(enhanced_api_progress_callback)\n                elif hasattr(agent, 'progress_callback'):\n                    agent.progress_callback = enhanced_api_progress_callback\n\n                # Execute agent\n                result = await agent.a_run(query=query, session_id=session_id, **kwargs)\n\n                # Return enhanced structured response\n                response_data = {\n                    'success': True,\n                    'result': result,\n                    'session_id': session_id,\n                    'agent_id': agent_id,\n                    'execution_time': time.time()\n                }\n\n                if include_progress:\n                    response_data.update({\n                        'progress_events': progress_events,\n                        'enhanced_progress': enhanced_progress,\n                        'outline_info': enhanced_progress.get('outline', {}),\n                        'system_info': enhanced_progress.get('system', {}),\n                        'meta_tools_used': enhanced_progress.get('meta_tools', [])\n                    })\n\n                return Result.json(data=response_data)\n\n            except Exception as e:\n                self.app.print(f\"Agent execution error: {e}\")\n                return Result.default_internal_error(\n                    info=f\"Agent execution failed: {str(e)}\",\n                    exec_code=500\n                )\n            finally:\n                # Restore original callback\n                if hasattr(agent, 'set_progress_callback'):\n                    agent.set_progress_callback(original_callback)\n                elif hasattr(agent, 'progress_callback'):\n                    agent.progress_callback = original_callback\n\n        except Exception as e:\n            self.app.print(f\"Direct agent run error: {e}\")\n            return Result.default_internal_error(\n                info=f\"Request processing failed: {str(e)}\",\n                exec_code=500\n            )\n\n    async def _handle_api_reset_context(self, agent_id: str, agent, request_data) -&gt; Result:\n        \"\"\"Handle API context reset requests.\"\"\"\n        try:\n            if hasattr(agent, 'clear_context'):\n                agent.clear_context()\n                message = \"Context reset successfully\"\n                success = True\n            elif hasattr(agent, 'reset'):\n                agent.reset()\n                message = \"Agent reset successfully\"\n                success = True\n            else:\n                message = \"Agent does not support context reset\"\n                success = False\n\n            return Result.json(data={\n                'success': success,\n                'message': message,\n                'agent_id': agent_id,\n                'timestamp': time.time()\n            })\n\n        except Exception as e:\n            return Result.default_internal_error(\n                info=f\"Context reset failed: {str(e)}\",\n                exec_code=500\n            )\n\n    async def _handle_api_get_status(self, agent_id: str, agent, request_data) -&gt; Result:\n        \"\"\"Handle API status requests.\"\"\"\n        try:\n            # Collect comprehensive agent status\n            status_info = {\n                'agent_id': agent_id,\n                'agent_name': getattr(agent, 'name', 'Unknown'),\n                'agent_type': agent.__class__.__name__,\n                'status': 'active',\n                'timestamp': time.time(),\n                'server_type': 'api'\n            }\n\n            # Add agent-specific status\n            if hasattr(agent, 'status'):\n                try:\n                    agent_status = agent.status()\n                    if isinstance(agent_status, dict):\n                        status_info['agent_status'] = agent_status\n                except:\n                    pass\n\n            # Add hosted agent info\n            if hasattr(self, '_hosted_agents') and agent_id in self._hosted_agents:\n                hosted_info = self._hosted_agents[agent_id]\n                status_info.update({\n                    'host': hosted_info.get('host'),\n                    'port': hosted_info.get('port'),\n                    'access': hosted_info.get('access'),\n                    'public_name': hosted_info.get('public_name'),\n                    'description': hosted_info.get('description')\n                })\n\n            # Add connection info\n            connection_count = 0\n            if hasattr(self, '_agent_connections') and agent_id in self._agent_connections:\n                connection_count = len(self._agent_connections[agent_id])\n\n            status_info['active_connections'] = connection_count\n\n            return Result.json(data=status_info)\n\n        except Exception as e:\n            return Result.default_internal_error(\n                info=f\"Status retrieval failed: {str(e)}\",\n                exec_code=500\n            )\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.module.Tools.cleanup_tools_interfaces","title":"<code>cleanup_tools_interfaces()</code>  <code>async</code>","text":"<p>Cleanup all ToolsInterface instances.</p> Source code in <code>toolboxv2/mods/isaa/module.py</code> <pre><code>async def cleanup_tools_interfaces(self):\n    \"\"\"\n    Cleanup all ToolsInterface instances.\n    \"\"\"\n    if not hasattr(self, 'tools_interfaces'):\n        return\n\n    async def cleanup_async():\n        for name, tools_interface in self.tools_interfaces.items():\n            if tools_interface:\n                try:\n                    await tools_interface.__aexit__(None, None, None)\n                except Exception as e:\n                    self.print(f\"Error cleaning up ToolsInterface for {name}: {e}\")\n\n    # Run cleanup\n    try:\n        await cleanup_async()\n        self.tools_interfaces.clear()\n        self.print(\"Cleaned up all ToolsInterface instances\")\n    except Exception as e:\n        self.print(f\"Error during ToolsInterface cleanup: {e}\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.module.Tools.configure_tools_interface","title":"<code>configure_tools_interface(agent_name, **kwargs)</code>  <code>async</code>","text":"<p>Configure the ToolsInterface for a specific agent.</p> <p>Parameters:</p> Name Type Description Default <code>agent_name</code> <code>str</code> <p>Name of the agent</p> required <code>**kwargs</code> <p>Configuration parameters</p> <code>{}</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if successful, False otherwise</p> Source code in <code>toolboxv2/mods/isaa/module.py</code> <pre><code>async def configure_tools_interface(self, agent_name: str, **kwargs) -&gt; bool:\n    \"\"\"\n    Configure the ToolsInterface for a specific agent.\n\n    Args:\n        agent_name: Name of the agent\n        **kwargs: Configuration parameters\n\n    Returns:\n        True if successful, False otherwise\n    \"\"\"\n    tools_interface = self.get_tools_interface(agent_name)\n    if not tools_interface:\n        self.print(f\"No ToolsInterface found for agent {agent_name}\")\n        return False\n\n    try:\n        # Configure based on provided parameters\n        if 'base_directory' in kwargs:\n            await tools_interface.set_base_directory(kwargs['base_directory'])\n\n        if 'current_file' in kwargs:\n            await tools_interface.set_current_file(kwargs['current_file'])\n\n        if 'variables' in kwargs:\n            tools_interface.ipython.user_ns.update(kwargs['variables'])\n\n        self.print(f\"Configured ToolsInterface for agent {agent_name}\")\n        return True\n\n    except Exception as e:\n        self.print(f\"Failed to configure ToolsInterface for {agent_name}: {e}\")\n        return False\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.module.Tools.get_tools_interface","title":"<code>get_tools_interface(agent_name='self')</code>","text":"<p>Get the ToolsInterface instance for a specific agent.</p> <p>Parameters:</p> Name Type Description Default <code>agent_name</code> <code>str</code> <p>Name of the agent</p> <code>'self'</code> <p>Returns:</p> Type Description <code>ToolsInterface | None</code> <p>ToolsInterface instance or None if not found</p> Source code in <code>toolboxv2/mods/isaa/module.py</code> <pre><code>def get_tools_interface(self, agent_name: str = \"self\") -&gt; ToolsInterface | None:\n    \"\"\"\n    Get the ToolsInterface instance for a specific agent.\n\n    Args:\n        agent_name: Name of the agent\n\n    Returns:\n        ToolsInterface instance or None if not found\n    \"\"\"\n    if not hasattr(self, 'tools_interfaces'):\n        return None\n\n    return self.tools_interfaces.get(agent_name)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.module.Tools.host_agent_ui","title":"<code>host_agent_ui(agent, host='0.0.0.0', port=None, access='local', registry_server=None, public_name=None, description=None, use_builtin_server=None)</code>  <code>async</code>","text":"<p>Unified agent hosting with WebSocket-enabled UI and optional registry publishing.</p> <p>Parameters:</p> Name Type Description Default <code>agent</code> <p>Agent or Chain instance to host</p> required <code>host</code> <code>str</code> <p>Host address (default: 0.0.0.0 for remote access)</p> <code>'0.0.0.0'</code> <code>port</code> <code>int | None</code> <p>Port number (auto-assigned if None)</p> <code>None</code> <code>access</code> <code>str</code> <p>'local', 'remote', or 'registry'</p> <code>'local'</code> <code>registry_server</code> <code>str | None</code> <p>Registry server URL for publishing (e.g., \"ws://localhost:8080/ws/registry/connect\")</p> <code>None</code> <code>public_name</code> <code>str | None</code> <p>Public name for registry publishing</p> <code>None</code> <code>description</code> <code>str | None</code> <p>Description for registry publishing</p> <code>None</code> <code>use_builtin_server</code> <code>bool</code> <p>Use toolbox built-in server vs standalone Python server</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>Dictionary with access URLs and configuration</p> Source code in <code>toolboxv2/mods/isaa/module.py</code> <pre><code>async def host_agent_ui(\n    self,\n    agent,\n    host: str = \"0.0.0.0\",\n    port: int | None = None,\n    access: str = 'local',\n    registry_server: str | None = None,\n    public_name: str | None = None,\n    description: str | None = None,\n    use_builtin_server: bool = None\n) -&gt; dict[str, str]:\n    \"\"\"\n    Unified agent hosting with WebSocket-enabled UI and optional registry publishing.\n\n    Args:\n        agent: Agent or Chain instance to host\n        host: Host address (default: 0.0.0.0 for remote access)\n        port: Port number (auto-assigned if None)\n        access: 'local', 'remote', or 'registry'\n        registry_server: Registry server URL for publishing (e.g., \"ws://localhost:8080/ws/registry/connect\")\n        public_name: Public name for registry publishing\n        description: Description for registry publishing\n        use_builtin_server: Use toolbox built-in server vs standalone Python server\n\n    Returns:\n        Dictionary with access URLs and configuration\n    \"\"\"\n    use_builtin_server = use_builtin_server or self.app.is_server\n    if not hasattr(self, '_hosted_agents'):\n        self._hosted_agents = {}\n\n    agent_id = f\"agent_{secrets.token_urlsafe(8)}\"\n\n    # Generate unique port if not specified\n    if not port:\n        port = 8765 + len(self._hosted_agents)\n\n    # Store agent reference\n    self._hosted_agents[agent_id] = {\n        'agent': agent,\n        'port': port,\n        'host': host,\n        'access': access,\n        'public_name': public_name or f\"Agent_{agent_id}\",\n        'description': description\n    }\n\n    result = {\n        'agent_id': agent_id,\n        'local_url': f\"http://{host}:{port}\",\n        'status': 'starting'\n    }\n\n    if use_builtin_server:\n        # Use toolbox built-in server\n        result.update(await self._setup_builtin_server_hosting(agent_id, agent, host, port))\n    else:\n        # Use standalone Python server\n        result.update(await self._setup_standalone_server_hosting(agent_id, agent, host, port))\n\n    # Handle registry publishing if requested\n    if access in ['remote', 'registry'] and registry_server:\n        if not public_name:\n            raise ValueError(\"public_name required for registry publishing\")\n\n        registry_result = await self._publish_to_registry(\n            agent=agent,\n            public_name=public_name,\n            registry_server=registry_server,\n            description=description,\n            agent_id=agent_id\n        )\n        result.update(registry_result)\n\n    self.app.print(f\"\ud83d\ude80 Agent '{result.get('public_name', agent_id)}' hosted successfully!\")\n    self.app.print(f\"   Local UI: {result['local_url']}\")\n    if 'public_url' in result:\n        self.app.print(f\"   Public URL: {result['public_url']}\")\n        self.app.print(f\"   API Key: {result.get('api_key', 'N/A')}\")\n\n    return result\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.module.Tools.init_from_augment","title":"<code>init_from_augment(augment, agent_name='self')</code>  <code>async</code>","text":"<p>Initialize from augmented data using new builder system</p> Source code in <code>toolboxv2/mods/isaa/module.py</code> <pre><code>async def init_from_augment(self, augment, agent_name: str = 'self'):\n    \"\"\"Initialize from augmented data using new builder system\"\"\"\n\n    # Handle agent_name parameter\n    if isinstance(agent_name, str):\n        pass  # Use string name\n    elif hasattr(agent_name, 'config'):  # FlowAgentBuilder\n        agent_name = agent_name.config.name\n    else:\n        raise ValueError(f\"Invalid agent_name type: {type(agent_name)}\")\n\n    a_keys = augment.keys()\n\n    # Load agent configurations\n    if \"Agents\" in a_keys:\n        agents_configs_dict = augment['Agents']\n        self.deserialize_all(agents_configs_dict)\n        self.print(\"Agent configurations loaded.\")\n\n    # Load custom functions (scripts)\n    if \"customFunctions\" in a_keys:\n        custom_functions = augment['customFunctions']\n        if isinstance(custom_functions, str):\n            custom_functions = json.loads(custom_functions)\n        if custom_functions:\n            self.scripts.scripts = custom_functions\n            self.print(\"Custom functions loaded\")\n\n    # Tools are now handled by the builder system during agent creation\n    if \"tools\" in a_keys:\n        self.print(\"Tool configurations noted - will be applied during agent building\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.module.Tools.list_hosted_agents","title":"<code>list_hosted_agents()</code>  <code>async</code>","text":"<p>List all currently hosted agents.</p> Source code in <code>toolboxv2/mods/isaa/module.py</code> <pre><code>async def list_hosted_agents(self) -&gt; dict[str, Any]:\n    \"\"\"List all currently hosted agents.\"\"\"\n\n    hosted_info = {\n        'builtin_agents': {},\n        'standalone_agents': {},\n        'total_count': 0\n    }\n\n    # Built-in server agents\n    if hasattr(self, '_hosted_agents'):\n        for agent_id, info in self._hosted_agents.items():\n            hosted_info['builtin_agents'][agent_id] = {\n                'public_name': info.get('public_name'),\n                'host': info.get('host'),\n                'port': info.get('port'),\n                'access': info.get('access'),\n                'description': info.get('description')\n            }\n\n    # Standalone server agents\n    if hasattr(self, '_standalone_servers'):\n        for port, info in self._standalone_servers.items():\n            hosted_info['standalone_agents'][info['agent_id']] = {\n                'port': port,\n                'thread_alive': info['thread'].is_alive(),\n                'server_type': 'standalone'\n            }\n\n    hosted_info['total_count'] = len(hosted_info['builtin_agents']) + len(hosted_info['standalone_agents'])\n\n    return hosted_info\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.module.Tools.publish_and_host_agent","title":"<code>publish_and_host_agent(agent, public_name, registry_server='ws://localhost:8080/ws/registry/connect', description=None, access_level='public')</code>  <code>async</code>","text":"<p>FIXED: Mit Debug-Ausgaben f\u00fcr Troubleshooting.</p> Source code in <code>toolboxv2/mods/isaa/module.py</code> <pre><code>async def publish_and_host_agent(\n    self,\n    agent,\n    public_name: str,\n    registry_server: str = \"ws://localhost:8080/ws/registry/connect\",\n    description: str | None = None,\n    access_level: str = \"public\"\n) -&gt; dict[str, Any]:\n    \"\"\"FIXED: Mit Debug-Ausgaben f\u00fcr Troubleshooting.\"\"\"\n\n    if hasattr(agent, 'name') and not hasattr(agent, 'amd') and hasattr(agent, 'a_run'):\n        agent.amd = lambda :None\n        agent.amd.name = agent.name\n\n    try:\n        # Registry Client initialisieren\n        from toolboxv2.mods.registry.client import get_registry_client\n        registry_client = get_registry_client(self.app)\n\n        self.app.print(f\"Connecting to registry server: {registry_server}\")\n        await registry_client.connect(registry_server)\n\n        # Progress Callback f\u00fcr Live-Updates einrichten\n        callback_success = await self.setup_live_progress_callback(agent, registry_client, f\"agent_{agent.amd.name}\")\n        if not callback_success:\n            self.app.print(\"Warning: Progress callback setup failed\")\n        else:\n            self.app.print(\"\u2705 Progress callback setup successful\")\n\n        # Agent beim Registry registrieren\n        self.app.print(f\"Registering agent: {public_name}\")\n        registration_info = await registry_client.register(\n            agent_instance=agent,\n            public_name=public_name,\n            description=description or f\"Agent: {public_name}\"\n        )\n\n        if not registration_info:\n            return {\"error\": \"Registration failed\", \"success\": False}\n\n        self.app.print(f\"\u2705 Agent registration successful: {registration_info.public_agent_id}\")\n\n        result = {\n            \"success\": True,\n            \"agent_name\": public_name,\n            \"public_agent_id\": registration_info.public_agent_id,\n            \"public_api_key\": registration_info.public_api_key,\n            \"public_url\": registration_info.public_url,\n            \"registry_server\": registry_server,\n            \"access_level\": access_level,\n            \"ui_url\": registration_info.public_url.replace(\"/api/registry/run\", \"/api/registry/ui\"),\n            \"websocket_url\": registry_server.replace(\"/connect\", \"/ui_connect\"),\n            \"status\": \"registered\"\n        }\n\n        return result\n\n    except Exception as e:\n        self.app.print(f\"Failed to publish agent: {e}\")\n        return {\"error\": str(e), \"success\": False}\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.module.Tools.setup_live_progress_callback","title":"<code>setup_live_progress_callback(agent, registry_client, agent_id=None)</code>  <code>async</code>","text":"<p>Enhanced setup for live progress callback with proper error handling.</p> Source code in <code>toolboxv2/mods/isaa/module.py</code> <pre><code>async def setup_live_progress_callback(self, agent, registry_client, agent_id: str = None):\n    \"\"\"Enhanced setup for live progress callback with proper error handling.\"\"\"\n\n    if not registry_client:\n        self.app.print(\"Warning: No registry client provided for progress updates\")\n        return False\n\n    if not registry_client.is_connected:\n        self.app.print(\"Warning: Registry client is not connected\")\n        return False\n\n    progress_tracker = EnhancedProgressTracker()\n\n    # Generate agent ID if not provided\n    if not agent_id:\n        agent_id = getattr(agent, 'name', f'agent_{id(agent)}')\n\n    async def enhanced_live_progress_callback(event: ProgressEvent):\n        \"\"\"Enhanced progress callback with comprehensive data extraction.\"\"\"\n        try:\n            # Validate event\n            if not event:\n                self.app.print(\"Warning: Received null progress event\")\n                return\n\n            # Debug output for local development\n            event_type = getattr(event, 'event_type', 'unknown')\n            status = getattr(event, 'status', 'unknown')\n            agent_name = getattr(event, 'agent_name', 'Unknown Agent')\n\n            self.app.print(f\"\ud83d\udcca Progress Event: {event_type} | {status} | {agent_name}\")\n\n            # Extract comprehensive progress data\n            progress_data = progress_tracker.extract_progress_data(event)\n\n            # Prepare enhanced progress message\n            ui_progress_data = {\n                \"agent_id\": agent_id,\n                \"event_type\": event_type,\n                \"status\": status.value if hasattr(status, 'value') else str(status),\n                \"timestamp\": getattr(event, 'timestamp', asyncio.get_event_loop().time()),\n                \"agent_name\": agent_name,\n                \"node_name\": getattr(event, 'node_name', 'Unknown'),\n                \"session_id\": getattr(event, 'session_id', None),\n\n                # Core event metadata\n                \"metadata\": {\n                    **getattr(event, 'metadata', {}),\n                    \"event_id\": getattr(event, 'event_id', f\"evt_{asyncio.get_event_loop().time()}\"),\n                    \"sequence_number\": getattr(event, 'sequence_number', 0),\n                    \"parent_event_id\": getattr(event, 'parent_event_id', None)\n                },\n\n                # Detailed progress data for UI panels\n                \"progress_data\": progress_data,\n\n                # UI-specific flags for selective updates\n                \"ui_flags\": {\n                    \"should_update_outline\": bool(progress_data.get('outline')),\n                    \"should_update_activity\": bool(progress_data.get('activity')),\n                    \"should_update_meta_tools\": bool(progress_data.get('meta_tool')),\n                    \"should_update_system\": bool(progress_data.get('system')),\n                    \"should_update_graph\": bool(progress_data.get('graph')),\n                    \"is_error\": event_type.lower() in ['error', 'exception', 'failed'],\n                    \"is_completion\": event_type.lower() in ['complete', 'finished', 'success'],\n                    \"requires_user_input\": getattr(event, 'requires_user_input', False)\n                },\n\n                # Performance metrics\n                \"performance\": {\n                    \"execution_time\": getattr(event, 'execution_time', None),\n                    \"memory_delta\": getattr(event, 'memory_delta', None),\n                    \"tokens_used\": getattr(event, 'tokens_used', None),\n                    \"api_calls_made\": getattr(event, 'api_calls_made', None)\n                }\n            }\n\n            # Send live update to registry server\n            await registry_client.send_ui_progress(ui_progress_data)\n\n            # Also send agent status update if this is a significant event\n            if event_type in ['started', 'completed', 'error', 'paused', 'resumed']:\n                agent_status = 'processing'\n                if event_type == 'completed':\n                    agent_status = 'idle'\n                elif event_type == 'error':\n                    agent_status = 'error'\n                elif event_type == 'paused':\n                    agent_status = 'paused'\n\n                await registry_client.send_agent_status(\n                    agent_id=agent_id,\n                    status=agent_status,\n                    details={\n                        \"last_event\": event_type,\n                        \"last_update\": ui_progress_data[\"timestamp\"],\n                        \"current_node\": progress_data.get('graph', {}).get('current_node', 'Unknown')\n                    }\n                )\n\n            # Log successful progress update\n            self.app.print(f\"\u2705 Sent progress update: {event_type} -&gt; Registry Server\")\n\n        except Exception as e:\n            self.app.print(f\"\u274c Progress callback error: {e}\")\n            # Send error notification to UI\n            try:\n                await registry_client.send_ui_progress({\n                    \"agent_id\": agent_id,\n                    \"event_type\": \"progress_callback_error\",\n                    \"status\": \"error\",\n                    \"timestamp\": asyncio.get_event_loop().time(),\n                    \"agent_name\": getattr(agent, 'name', 'Unknown'),\n                    \"metadata\": {\"error\": str(e)},\n                    \"ui_flags\": {\"is_error\": True}\n                })\n            except Exception as nested_error:\n                self.app.print(f\"Failed to send error notification: {nested_error}\")\n\n    # Set up progress callback with enhanced error handling\n    callback_set = False\n\n    if hasattr(agent, 'set_progress_callback'):\n        try:\n            self.app.print(f\"\ud83d\udd27 Setting progress callback via set_progress_callback for agent: {agent_id}\")\n            agent.set_progress_callback(enhanced_live_progress_callback)\n            callback_set = True\n        except Exception as e:\n            self.app.print(f\"Failed to set progress callback via set_progress_callback: {e}\")\n\n    if not callback_set and hasattr(agent, 'progress_callback'):\n        try:\n            self.app.print(f\"\ud83d\udd27 Setting progress callback via direct assignment for agent: {agent_id}\")\n            agent.progress_callback = enhanced_live_progress_callback\n            callback_set = True\n        except Exception as e:\n            self.app.print(f\"Failed to set progress callback via direct assignment: {e}\")\n\n    if not callback_set:\n        self.app.print(f\"\u26a0\ufe0f Warning: Agent {agent_id} doesn't support progress callbacks\")\n        return False\n\n    # Send initial agent status\n    try:\n        await registry_client.send_agent_status(\n            agent_id=agent_id,\n            status='online',\n            details={\n                \"progress_callback_enabled\": True,\n                \"callback_setup_time\": asyncio.get_event_loop().time(),\n                \"agent_type\": type(agent).__name__\n            }\n        )\n        self.app.print(f\"\u2705 Progress callback successfully set up for agent: {agent_id}\")\n    except Exception as e:\n        self.app.print(f\"Failed to send initial agent status: {e}\")\n\n    return True\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.module.Tools.stop_hosted_agent","title":"<code>stop_hosted_agent(agent_id=None, port=None)</code>  <code>async</code>","text":"<p>Stop a hosted agent by agent_id or port.</p> Source code in <code>toolboxv2/mods/isaa/module.py</code> <pre><code>async def stop_hosted_agent(self, agent_id: str = None, port: int = None):\n    \"\"\"Stop a hosted agent by agent_id or port.\"\"\"\n\n    if not hasattr(self, '_hosted_agents') and not hasattr(self, '_standalone_servers'):\n        self.app.print(\"No hosted agents found\")\n        return False\n\n    # Stop by agent_id\n    if agent_id:\n        if hasattr(self, '_hosted_agents') and agent_id in self._hosted_agents:\n            agent_info = self._hosted_agents[agent_id]\n            agent_port = agent_info.get('port')\n\n            # Stop standalone server if exists\n            if hasattr(self, '_standalone_servers') and agent_port in self._standalone_servers:\n                server_info = self._standalone_servers[agent_port]\n                try:\n                    server_info['server'].shutdown()\n                    self.app.print(f\"Stopped standalone server for agent {agent_id}\")\n                except:\n                    pass\n\n            # Clean up hosted agent info\n            del self._hosted_agents[agent_id]\n            self.app.print(f\"Stopped hosted agent {agent_id}\")\n            return True\n\n    # Stop by port\n    if port:\n        if hasattr(self, '_standalone_servers') and port in self._standalone_servers:\n            server_info = self._standalone_servers[port]\n            try:\n                server_info['server'].shutdown()\n                self.app.print(f\"Stopped server on port {port}\")\n                return True\n            except Exception as e:\n                self.app.print(f\"Failed to stop server on port {port}: {e}\")\n                return False\n\n    self.app.print(\"Agent or port not found\")\n    return False\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.isaa.ui","title":"<code>ui</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.isaa.ui.get_agent_ui_html","title":"<code>get_agent_ui_html()</code>","text":"<p>Produktionsfertige UI mit Live-Progress-Tracking.</p> Source code in <code>toolboxv2/mods/isaa/ui.py</code> <pre><code>def get_agent_ui_html() -&gt; str:\n    \"\"\"Produktionsfertige UI mit Live-Progress-Tracking.\"\"\"\n\n    return \"\"\"&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\"&gt;\n&lt;head&gt;\n    &lt;meta charset=\"UTF-8\"&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;\n    &lt;title&gt;Agent Registry - Live Interface&lt;/title&gt;\n    &lt;script src=\"https://cdn.jsdelivr.net/npm/marked/marked.min.js\"&gt;&lt;/script&gt;\n    &lt;style&gt;\n        /* Modernes Dark Theme UI */\n        :root {\n            --bg-primary: #0d1117;\n            --bg-secondary: #161b22;\n            --bg-tertiary: #21262d;\n            --text-primary: #f0f6fc;\n            --text-secondary: #8b949e;\n            --text-muted: #6e7681;\n            --accent-blue: #58a6ff;\n            --accent-green: #3fb950;\n            --accent-red: #f85149;\n            --accent-orange: #d29922;\n            --accent-purple: #a5a5f5;\n            --accent-cyan: #39d0d8;\n            --border-color: #30363d;\n            --shadow: 0 2px 8px rgba(0, 0, 0, 0.3);\n\n            --sidebar-width: 300px;\n            --progress-width: 660px;\n            --sidebar-collapsed: 60px;\n            --progress-collapsed: 60px;\n        }\n        /* Enhanced Progress Panel Styles */\n        .progress-section {\n            margin-bottom: 16px;\n        }\n\n        /* ADD to existing CSS */\n        .event-status-badge {\n            padding: 2px 6px;\n            border-radius: 3px;\n            font-size: 10px;\n            font-weight: 500;\n        }\n\n        .event-status-badge.completed {\n            background: var(--accent-green);\n            color: white;\n        }\n\n        .event-status-badge.running {\n            background: var(--accent-orange);\n            color: white;\n        }\n\n        .event-status-badge.failed, .event-status-badge.error {\n            background: var(--accent-red);\n            color: white;\n        }\n\n        .event-status-badge.starting {\n            background: var(--accent-cyan);\n            color: white;\n        }\n\n        .progress-item.expandable[data-event-id*=\"tool_call\"] {\n            border-left-color: var(--accent-orange);\n        }\n\n        .progress-item.expandable[data-event-id*=\"llm_call\"] {\n            border-left-color: var(--accent-purple);\n        }\n\n        .progress-item.expandable[data-event-id*=\"meta_tool\"] {\n            border-left-color: var(--accent-cyan);\n        }\n\n        .progress-item.expandable[data-event-id*=\"error\"] {\n            border-left-color: var(--accent-red);\n            background: rgba(248, 81, 73, 0.02);\n        }\n\n        .section-title.expandable-section {\n            cursor: pointer;\n            display: flex;\n            justify-content: space-between;\n            align-items: center;\n            padding: 8px 12px;\n            background: var(--bg-primary);\n            border: 1px solid var(--border-color);\n            border-radius: 6px;\n            transition: all 0.2s;\n        }\n\n        .section-title.expandable-section:hover {\n            background: var(--bg-tertiary);\n        }\n\n        .section-toggle {\n            transition: transform 0.2s;\n            font-size: 12px;\n        }\n\n        .section-content {\n            max-height: 0;\n            overflow: hidden;\n            transition: max-height 0.3s ease-out;\n            background: var(--bg-primary);\n            border-radius: 0 0 6px 6px;\n        }\n\n        .section-content.expanded {\n            max-height: 900px;\n            padding: 12px;\n            border: 1px solid var(--border-color);\n            border-top: none;\n            overflow-y: auto;\n        }\n\n        .no-data {\n            color: var(--text-muted);\n            font-size: 12px;\n            text-align: center;\n            padding: 12px;\n            font-style: italic;\n        }\n\n        /* Expandable Progress Items */\n        .progress-item.expandable {\n            cursor: pointer;\n            transition: all 0.2s;\n            margin-bottom: 8px;\n        }\n\n        .progress-item.expandable:hover {\n            transform: translateY(-1px);\n            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);\n        }\n\n        .progress-item.expandable.expanded {\n            border-color: var(--accent-blue);\n        }\n\n        .progress-item.expandable.latest {\n            border-left: 3px solid var(--accent-green);\n            background: rgba(63, 185, 80, 0.05);\n        }\n\n        .progress-item-header {\n            display: flex;\n            align-items: center;\n            gap: 8px;\n            padding: 8px 12px;\n        }\n\n        .progress-meta {\n            margin-left: auto;\n            display: flex;\n            align-items: center;\n            gap: 8px;\n        }\n\n        .expand-indicator {\n            transition: transform 0.2s;\n            font-size: 12px;\n            color: var(--text-muted);\n        }\n\n        .progress-item.expanded .expand-indicator {\n            transform: rotate(180deg);\n        }\n\n        .progress-summary {\n            padding: 0 12px 8px 36px;\n            font-size: 11px;\n            color: var(--text-secondary);\n        }\n\n        .progress-item-expanded {\n            max-height: 0;\n            overflow: hidden;\n            transition: max-height 0.3s ease-out;\n            background: var(--bg-secondary);\n            border-top: 1px solid var(--border-color);\n        }\n\n        .progress-item-expanded.active {\n            max-height: 400px;\n            padding: 12px;\n            overflow-y: auto;\n        }\n\n        .expanded-section {\n            margin-bottom: 12px;\n        }\n\n        .expanded-section-title {\n            font-size: 12px;\n            font-weight: 600;\n            color: var(--accent-blue);\n            margin-bottom: 6px;\n            padding-bottom: 4px;\n            border-bottom: 1px solid var(--border-color);\n        }\n\n        .event-field {\n            display: flex;\n            justify-content: space-between;\n            align-items: flex-start;\n            padding: 4px 0;\n            font-size: 11px;\n        }\n\n        .event-field-label {\n            font-weight: 500;\n            color: var(--text-secondary);\n            min-width: 80px;\n        }\n\n        .event-field-value {\n            color: var(--text-primary);\n            text-align: right;\n            flex: 1;\n        }\n\n        .event-field-value.json {\n            background: var(--bg-primary);\n            border-radius: 4px;\n            padding: 6px;\n            font-family: monospace;\n            font-size: 10px;\n            text-align: left;\n            white-space: pre-wrap;\n            max-height: 100px;\n            overflow-y: auto;\n        }\n\n        /* ADD to existing CSS */\n.thinking-step.outline-step {\n    border-color: var(--accent-cyan);\n    background: rgba(57, 208, 216, 0.05);\n}\n\n.thinking-step.outline-step.completed {\n    border-color: var(--accent-green);\n    background: rgba(63, 185, 80, 0.05);\n}\n\n.thinking-step.outline-step.running {\n    border-color: var(--accent-orange);\n    background: rgba(210, 153, 34, 0.05);\n}\n\n.outline-progress {\n    margin: 8px 0;\n}\n\n.progress-info {\n    display: flex;\n    justify-content: space-between;\n    align-items: center;\n    margin-bottom: 6px;\n}\n\n.progress-text {\n    font-size: 11px;\n    color: var(--text-secondary);\n    font-weight: 500;\n}\n\n.progress-percentage {\n    font-size: 11px;\n    color: var(--accent-blue);\n    font-weight: 600;\n}\n\n.progress-bar-container {\n    margin-bottom: 8px;\n}\n\n.progress-bar {\n    height: 6px;\n    background: var(--bg-primary);\n    border-radius: 3px;\n    overflow: hidden;\n    border: 1px solid var(--border-color);\n}\n\n.progress-bar-fill {\n    height: 100%;\n    background: linear-gradient(90deg, var(--accent-cyan), var(--accent-blue));\n    transition: width 0.5s ease-out;\n    position: relative;\n}\n\n.progress-bar-fill::after {\n    content: '';\n    position: absolute;\n    top: 0;\n    left: 0;\n    right: 0;\n    bottom: 0;\n    background: linear-gradient(90deg, transparent, rgba(255,255,255,0.2), transparent);\n    animation: shimmer 2s infinite;\n}\n\n@keyframes shimmer {\n    0% { transform: translateX(-100%); }\n    100% { transform: translateX(100%); }\n}\n\n.step-completed {\n    color: var(--accent-green);\n    font-size: 10px;\n    text-align: center;\n    font-weight: 500;\n}\n\n.step-working {\n    color: var(--accent-orange);\n    font-size: 10px;\n    text-align: center;\n    font-style: italic;\n}\n\n.context-info {\n    display: flex;\n    justify-content: center;\n    gap: 12px;\n    margin-top: 8px;\n    padding-top: 8px;\n    border-top: 1px solid var(--border-color);\n}\n\n.context-item {\n    font-size: 10px;\n    color: var(--text-muted);\n    background: var(--bg-primary);\n    padding: 2px 6px;\n    border-radius: 3px;\n    border: 1px solid var(--border-color);\n}\n\n.thinking-step.plan-created {\n    border-color: var(--accent-blue);\n    background: rgba(88, 166, 255, 0.05);\n}\n\n.plan-details {\n    text-align: center;\n}\n\n.plan-info {\n    display: flex;\n    justify-content: center;\n    gap: 12px;\n    margin-bottom: 8px;\n}\n\n.plan-item {\n    font-size: 11px;\n    color: var(--text-secondary);\n    background: var(--bg-primary);\n    padding: 4px 8px;\n    border-radius: 4px;\n    border: 1px solid var(--border-color);\n}\n\n.plan-ready, .outline-ready {\n    margin-top: 8px;\n    color: var(--accent-green);\n    font-size: 10px;\n    text-align: center;\n}\n\n.step-status {\n    padding: 2px 6px;\n    border-radius: 3px;\n    font-size: 10px;\n    font-weight: 500;\n    margin-left: auto;\n}\n\n.step-status.completed {\n    background: var(--accent-green);\n    color: white;\n}\n\n.step-status.running {\n    background: var(--accent-orange);\n    color: white;\n}\n\n.step-status.ready {\n    background: var(--accent-blue);\n    color: white;\n}\n\n        /* Enhanced Chat Integration Styles */\n        .thinking-step {\n            background: var(--bg-secondary);\n            border: 1px solid var(--border-color);\n            border-radius: 8px;\n            padding: 10px 12px;\n            margin: 8px 0;\n            font-size: 13px;\n            transition: all 0.2s;\n        }\n\n        .thinking-step:hover {\n            transform: translateY(-1px);\n            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);\n        }\n\n        .thinking-step.reasoning-loop {\n            border-color: var(--accent-purple);\n            background: rgba(165, 165, 245, 0.05);\n        }\n\n        .thinking-step.outline-created {\n            border-color: var(--accent-cyan);\n            background: rgba(57, 208, 216, 0.05);\n        }\n\n        .thinking-step.task-progress.starting {\n            border-color: var(--accent-orange);\n            background: rgba(210, 153, 34, 0.05);\n        }\n\n        .thinking-step.task-progress.completed {\n            border-color: var(--accent-green);\n            background: rgba(63, 185, 80, 0.05);\n        }\n\n        .thinking-step.task-progress.error {\n            border-color: var(--accent-red);\n            background: rgba(248, 81, 73, 0.05);\n        }\n\n        .thinking-step-header {\n            display: flex;\n            align-items: center;\n            gap: 8px;\n            font-weight: 600;\n            margin-bottom: 8px;\n            color: var(--text-primary);\n        }\n\n        .step-progress, .step-info, .step-status {\n            margin-left: auto;\n            font-size: 10px;\n            font-weight: normal;\n            color: var(--text-muted);\n            background: var(--bg-primary);\n            padding: 2px 6px;\n            border-radius: 3px;\n        }\n\n        .priority-badge {\n            padding: 2px 6px;\n            border-radius: 3px;\n            font-size: 10px;\n            font-weight: 500;\n        }\n\n        .priority-badge.high {\n            background: var(--accent-red);\n            color: white;\n        }\n\n        .priority-badge.normal {\n            background: var(--accent-blue);\n            color: white;\n        }\n\n        .priority-badge.low {\n            background: var(--text-muted);\n            color: white;\n        }\n\n        /* Performance Metrics Grid */\n        .metrics-grid {\n            display: grid;\n            grid-template-columns: repeat(auto-fit, minmax(100px, 1fr));\n            gap: 8px;\n        }\n\n        .metric-card {\n            background: var(--bg-primary);\n            border: 1px solid var(--border-color);\n            border-radius: 6px;\n            padding: 8px;\n            text-align: center;\n        }\n\n        .metric-label {\n            font-size: 10px;\n            color: var(--text-muted);\n            margin-bottom: 4px;\n        }\n\n        .metric-value {\n            font-size: 14px;\n            font-weight: 600;\n            color: var(--accent-blue);\n        }\n\n        .reasoning-metrics .metric-grid {\n            display: grid;\n            grid-template-columns: repeat(3, 1fr);\n            gap: 8px;\n            margin-bottom: 8px;\n        }\n\n        .metric-item {\n            display: flex;\n            justify-content: space-between;\n            align-items: center;\n            font-size: 11px;\n        }\n\n        .metric-label {\n            color: var(--text-muted);\n        }\n\n        .metric-value {\n            color: var(--text-primary);\n            font-weight: 500;\n        }\n\n        /* Progress Bar */\n        .progress-bar-container {\n            margin: 8px 0;\n        }\n\n        .progress-bar-info {\n            display: flex;\n            justify-content: space-between;\n            font-size: 10px;\n            color: var(--text-muted);\n            margin-bottom: 4px;\n        }\n\n        .progress-bar {\n            height: 4px;\n            background: var(--bg-primary);\n            border-radius: 2px;\n            overflow: hidden;\n        }\n\n        .progress-bar-fill {\n            height: 100%;\n            background: var(--accent-blue);\n            transition: width 0.5s ease-out;\n        }\n\n        /* Outline Display */\n        .outline-steps {\n            margin: 8px 0;\n        }\n\n        .outline-step {\n            display: flex;\n            align-items: flex-start;\n            gap: 8px;\n            margin-bottom: 4px;\n            font-size: 11px;\n        }\n\n        .step-number {\n            color: var(--accent-blue);\n            font-weight: 600;\n            min-width: 20px;\n        }\n\n        .step-text {\n            color: var(--text-primary);\n            line-height: 1.3;\n        }\n\n        .context-metrics {\n            display: grid;\n            grid-template-columns: repeat(3, 1fr);\n            gap: 8px;\n            margin-bottom: 8px;\n        }\n\n        .context-metric {\n            display: flex;\n            flex-direction: column;\n            align-items: center;\n            font-size: 10px;\n            padding: 6px;\n            background: var(--bg-primary);\n            border-radius: 4px;\n        }\n\n        .context-label {\n            color: var(--text-muted);\n            margin-bottom: 2px;\n        }\n\n        .context-value {\n            color: var(--text-primary);\n            font-weight: 600;\n        }\n\n        .task-description {\n            margin-bottom: 6px;\n            font-weight: 500;\n        }\n\n        .task-timing {\n            font-size: 10px;\n            color: var(--accent-green);\n        }\n\n        .task-error {\n            font-size: 10px;\n            color: var(--accent-red);\n            background: rgba(248, 81, 73, 0.1);\n            padding: 4px;\n            border-radius: 3px;\n            margin-top: 4px;\n        }\n\n        .reasoning-insight {\n            margin-top: 8px;\n            font-size: 11px;\n            color: var(--accent-purple);\n            text-align: center;\n            font-style: italic;\n        }\n\n        .idle-status {\n            border-color: var(--accent-green);\n            background: rgba(63, 185, 80, 0.02);\n        }\n\n        @media (max-width: 1200px) {\n            :root {\n                --sidebar-width: 250px;\n                --progress-width: 580px;\n            }\n        }\n\n        @media (max-width: 1024px) {\n            :root {\n                --sidebar-width: 220px;\n                --progress-width: 460px;\n            }\n        }\n\n        .sidebar.collapsed::before {\n            content: '\ud83d\udccb';\n            font-size: 20px;\n            display: flex;\n            align-items: center;\n            justify-content: center;\n            padding: 20px 0;\n            border-bottom: 1px solid var(--border-color);\n        }\n\n        .progress-panel.collapsed::before {\n            content: '\ud83d\udcca';\n            font-size: 20px;\n            display: flex;\n            align-items: center;\n            justify-content: center;\n            padding: 20px 0;\n            border-bottom: 1px solid var(--border-color);\n            writing-mode: vertical-lr;\n        }\n\n        .sidebar, .progress-panel {\n            transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);\n        }\n\n        .main-container {\n            transition: grid-template-columns 0.3s cubic-bezier(0.4, 0, 0.2, 1);\n        }\n\n        * { margin: 0; padding: 0; box-sizing: border-box; }\n\n        body {\n            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;\n            background: var(--bg-primary);\n            color: var(--text-primary);\n            height: 100vh;\n            display: flex;\n            flex-direction: column;\n            overflow: hidden;\n        }\n\n        html, body {\n            height: 100%;\n            overflow: hidden;\n        }\n\n        .api-key-modal {\n            position: fixed;\n            top: 0;\n            left: 0;\n            right: 0;\n            bottom: 0;\n            background: rgba(0, 0, 0, 0.8);\n            display: flex;\n            align-items: center;\n            justify-content: center;\n            z-index: 1000;\n        }\n\n        .api-key-content {\n            background: var(--bg-secondary);\n            border: 1px solid var(--border-color);\n            border-radius: 12px;\n            padding: 24px;\n            max-width: 500px;\n            width: 90%;\n            text-align: center;\n        }\n\n        .api-key-title {\n            font-size: 20px;\n            font-weight: 600;\n            color: var(--accent-blue);\n            margin-bottom: 16px;\n        }\n\n        .api-key-description {\n            color: var(--text-secondary);\n            margin-bottom: 20px;\n            line-height: 1.5;\n        }\n\n        .api-key-input {\n            width: 100%;\n            background: var(--bg-primary);\n            border: 1px solid var(--border-color);\n            border-radius: 8px;\n            padding: 12px;\n            color: var(--text-primary);\n            font-size: 14px;\n            margin-bottom: 16px;\n        }\n\n        .api-key-button {\n            background: var(--accent-blue);\n            color: white;\n            border: none;\n            border-radius: 8px;\n            padding: 12px 24px;\n            cursor: pointer;\n            font-weight: 600;\n        }\n\n        /* Updated Header */\n        .header {\n            background: var(--bg-tertiary);\n            padding: 16px 24px;\n            border-bottom: 1px solid var(--border-color);\n            display: flex;\n            align-items: center;\n            justify-content: space-between;\n            box-shadow: var(--shadow);\n            flex-shrink: 0;\n        }\n\n        .header-controls {\n            display: flex;\n            align-items: center;\n            gap: 12px;\n        }\n\n        .panel-toggle {\n            background: var(--bg-secondary);\n            border: 1px solid var(--border-color);\n            color: var(--text-primary);\n            padding: 8px 12px;\n            border-radius: 6px;\n            cursor: pointer;\n            font-size: 12px;\n            transition: all 0.2s;\n        }\n\n        .panel-toggle:hover {\n            background: var(--bg-primary);\n        }\n\n        .panel-toggle.active {\n            background: var(--accent-blue);\n            color: white;\n        }\n\n        .logo {\n            display: flex;\n            align-items: center;\n            gap: 12px;\n            font-size: 20px;\n            font-weight: 700;\n            color: var(--accent-blue);\n        }\n\n        .connection-status {\n            display: flex;\n            align-items: center;\n            gap: 12px;\n        }\n\n        .status-indicator {\n            display: flex;\n            align-items: center;\n            gap: 8px;\n            padding: 8px 12px;\n            border-radius: 6px;\n            font-size: 14px;\n            font-weight: 500;\n        }\n\n        .status-indicator.connected {\n            background: rgba(63, 185, 80, 0.1);\n            color: var(--accent-green);\n            border: 1px solid var(--accent-green);\n        }\n\n        .status-indicator.disconnected {\n            background: rgba(248, 81, 73, 0.1);\n            color: var(--accent-red);\n            border: 1px solid var(--accent-red);\n        }\n\n        .status-dot {\n            width: 8px;\n            height: 8px;\n            border-radius: 50%;\n            background: currentColor;\n            animation: pulse 2s infinite;\n        }\n\n        .status-dot.connected { animation: none; }\n\n        @keyframes pulse {\n            0%, 100% { opacity: 1; }\n            50% { opacity: 0.4; }\n        }\n\n        /* FIXED: Better grid layout that properly handles collapsing */\n        .main-container {\n            display: grid;\n            grid-template-areas: \"sidebar chat progress\";\n            grid-template-columns: var(--sidebar-width) 1fr var(--progress-width);\n            flex: 1;\n            overflow: hidden;\n            min-height: 0;\n            height: 100%;\n        }\n\n        .main-container.sidebar-collapsed {\n            grid-template-columns: var(--sidebar-collapsed) 1fr var(--progress-width);\n        }\n\n        .main-container.progress-collapsed {\n            grid-template-columns: var(--sidebar-width) 1fr var(--progress-collapsed);\n        }\n\n        .main-container.both-collapsed {\n            grid-template-columns: var(--sidebar-collapsed) 1fr var(--progress-collapsed);\n        }\n\n        .sidebar {\n            grid-area: sidebar;\n            background: var(--bg-secondary);\n            border-right: 1px solid var(--border-color);\n            display: flex;\n            flex-direction: column;\n            overflow: hidden;\n            height: 100%;\n        }\n\n        .sidebar.collapsed .agents-list,\n        .sidebar.collapsed .system-info {\n            display: none;\n        }\n\n        .sidebar.collapsed .sidebar-header {\n            padding: 12px 8px;\n            justify-content: center;\n        }\n\n        .sidebar.collapsed .sidebar-title {\n            display: none;\n        }\n\n        .sidebar.collapsed .collapse-btn {\n            writing-mode: vertical-lr;\n            text-orientation: mixed;\n        }\n\n        .progress-panel.collapsed .collapse-btn {\n            writing-mode: vertical-lr;\n            text-orientation: mixed;\n            transform: rotate(180deg);\n        }\n\n        .sidebar-header {\n            padding: 12px 16px;\n            background: var(--bg-tertiary);\n            border-bottom: 1px solid var(--border-color);\n            display: flex;\n            align-items: center;\n            justify-content: space-between;\n            min-height: 48px;\n        }\n\n        .sidebar-title {\n            font-size: 14px;\n            font-weight: 600;\n            color: var(--text-secondary);\n            text-transform: uppercase;\n        }\n\n        .collapse-btn {\n            background: none;\n            border: none;\n            color: var(--text-muted);\n            cursor: pointer;\n            padding: 4px;\n            border-radius: 4px;\n            transition: all 0.2s;\n        }\n\n        .collapse-btn:hover {\n            background: var(--bg-primary);\n            color: var(--text-primary);\n        }\n\n        /* FIXED: Chat area properly uses grid area and expands */\n        .chat-area {\n            grid-area: chat;\n            display: flex;\n            flex-direction: column;\n            background: var(--bg-primary);\n            min-height: 0;\n            height: 100%;\n            overflow: hidden;\n        }\n\n        /* Updated Progress Panel */\n        .progress-panel {\n            grid-area: progress;\n            background: var(--bg-secondary);\n            border-left: 1px solid var(--border-color);\n            display: flex;\n            flex-direction: column;\n            overflow: hidden;\n            height: 100%;\n        }\n\n        .progress-panel.collapsed .panel-content {\n            display: none;\n        }\n\n        .progress-panel.collapsed .progress-header {\n            padding: 12px 8px;\n            justify-content: center;\n            writing-mode: vertical-lr;\n            text-orientation: mixed;\n        }\n\n        .progress-panel.collapsed .progress-header span {\n            transform: rotate(180deg);\n        }\n\n        .progress-header {\n            padding: 12px 16px;\n            background: var(--bg-tertiary);\n            border-bottom: 1px solid var(--border-color);\n            display: flex;\n            align-items: center;\n            justify-content: space-between;\n            font-weight: 600;\n            font-size: 14px;\n            min-height: 48px;\n        }\n\n        /* ADD to existing CSS */\n        .progress-item.llm_call {\n            border-left: 3px solid var(--accent-purple);\n        }\n\n        .progress-item.llm_call.latest {\n            border-left: 3px solid var(--accent-purple);\n            background: rgba(165, 165, 245, 0.03);\n        }\n\n        .progress-item.llm_call .progress-icon {\n            color: var(--accent-purple);\n        }\n\n        .progress-summary {\n            padding: 0 12px 8px 36px;\n            font-size: 10px;\n            color: var(--text-secondary);\n            line-height: 1.3;\n        }\n\n        .event-field-value.json {\n            background: var(--bg-primary);\n            border-radius: 4px;\n            padding: 8px;\n            font-family: 'Consolas', 'Monaco', monospace;\n            font-size: 10px;\n            text-align: left;\n            white-space: pre-wrap;\n            max-height: 300px;\n            overflow-y: auto;\n            border: 1px solid var(--border-color);\n            word-break: break-all;\n        }\n\n        .expanded-section {\n            margin-bottom: 12px;\n            border-bottom: 1px solid rgba(48, 54, 61, 0.3);\n            padding-bottom: 8px;\n        }\n\n        .expanded-section:last-child {\n            border-bottom: none;\n            margin-bottom: 0;\n        }\n\n        /* FIXED: Hide mobile tabs on desktop by default */\n        .mobile-tabs {\n            display: none;\n        }\n\n        /* Mobile Responsive */\n        @media (max-width: 768px) {\n            .main-container {\n                display: flex !important;\n                flex-direction: column;\n                height: 100%;\n                grid-template-areas: none;\n                grid-template-columns: none;\n            }\n\n            .mobile-tabs {\n                display: flex;\n                background: var(--bg-tertiary);\n                border-bottom: 1px solid var(--border-color);\n                flex-shrink: 0;\n            }\n\n            .header-controls {\n                display: none;\n            }\n\n            .mobile-tab {\n                flex: 1;\n                padding: 12px;\n                text-align: center;\n                background: var(--bg-secondary);\n                border-right: 1px solid var(--border-color);\n                cursor: pointer;\n                transition: all 0.2s;\n                font-size: 14px;\n            }\n\n            .mobile-tab:last-child {\n                border-right: none;\n            }\n\n            .mobile-tab.active {\n                background: var(--accent-blue);\n                color: white;\n            }\n\n            .sidebar,\n            .progress-panel {\n                flex: 1;\n                border-right: none;\n                border-left: none;\n                border-bottom: 1px solid var(--border-color);\n                min-height: 0;\n                max-height: none;\n            }\n\n            .chat-area {\n                flex: 1;\n                min-height: 0;\n            }\n\n            .sidebar,\n            .chat-area,\n            .progress-panel {\n                display: none;\n            }\n        }\n\n        @media (min-width: 769px) {\n            .main-container {\n                display: grid !important;\n            }\n\n            .sidebar,\n            .chat-area,\n            .progress-panel {\n                display: flex !important;\n                height: 100%;\n            }\n        }\n\n        .agents-list {\n            flex: 1;\n            overflow-y: auto;\n            padding: 16px;\n            min-height: 0;\n        }\n\n        .agents-header {\n            font-size: 14px;\n            font-weight: 600;\n            color: var(--text-secondary);\n            margin-bottom: 12px;\n            text-transform: uppercase;\n            letter-spacing: 0.5px;\n        }\n\n        .agent-item {\n            padding: 12px;\n            margin-bottom: 8px;\n            background: var(--bg-tertiary);\n            border: 1px solid var(--border-color);\n            border-radius: 8px;\n            cursor: pointer;\n            transition: all 0.2s;\n        }\n\n        .agent-item:hover {\n            border-color: var(--accent-blue);\n            transform: translateY(-1px);\n        }\n\n        .agent-item.active {\n            border-color: var(--accent-blue);\n            background: rgba(88, 166, 255, 0.1);\n        }\n\n        .agent-name {\n            font-weight: 600;\n            color: var(--text-primary);\n            margin-bottom: 4px;\n        }\n\n        .agent-description {\n            font-size: 12px;\n            color: var(--text-muted);\n            margin-bottom: 6px;\n        }\n\n        .agent-status {\n            display: flex;\n            align-items: center;\n            gap: 6px;\n            font-size: 11px;\n        }\n\n        .agent-status.online { color: var(--accent-green); }\n        .agent-status.offline { color: var(--accent-red); }\n\n        .chat-header {\n            padding: 16px 20px;\n            border-bottom: 1px solid var(--border-color);\n            background: var(--bg-tertiary);\n            flex-shrink: 0;\n        }\n\n        .chat-title {\n            font-size: 16px;\n            font-weight: 600;\n            color: var(--text-primary);\n            margin-bottom: 4px;\n        }\n\n        .chat-subtitle {\n            font-size: 12px;\n            color: var(--text-muted);\n        }\n\n        .messages-container {\n            flex: 1;\n            overflow-y: auto;\n            padding: 20px;\n            display: flex;\n            flex-direction: column;\n            gap: 16px;\n            min-height: 0;\n        }\n\n        .message {\n            display: flex;\n            gap: 12px;\n            max-width: 85%;\n        }\n\n        .message.user {\n            flex-direction: row-reverse;\n            margin-left: auto;\n        }\n\n        .message-avatar {\n            width: 36px;\n            height: 36px;\n            border-radius: 50%;\n            display: flex;\n            align-items: center;\n            justify-content: center;\n            font-size: 14px;\n            font-weight: 600;\n            flex-shrink: 0;\n        }\n\n        .message.user .message-avatar {\n            background: var(--accent-blue);\n            color: white;\n        }\n\n        .message.agent .message-avatar {\n            background: var(--accent-green);\n            color: white;\n        }\n\n        .message-content {\n            padding: 12px 16px;\n            border-radius: 16px;\n            line-height: 1.5;\n            font-size: 14px;\n        }\n\n        .message.user .message-content {\n            background: var(--accent-blue);\n            color: white;\n        }\n\n        .message.agent .message-content {\n            background: var(--bg-tertiary);\n            border: 1px solid var(--border-color);\n            color: var(--text-primary);\n        }\n\n        /* NEW: Thinking step styles */\n        .thinking-step {\n            background: var(--bg-secondary);\n            border: 1px solid var(--accent-purple);\n            border-radius: 12px;\n            padding: 12px 16px;\n            margin: 8px 0;\n            font-size: 13px;\n            color: var(--text-secondary);\n        }\n\n        .thinking-step.outline-step {\n            border-color: var(--accent-cyan);\n            background: rgba(57, 208, 216, 0.05);\n        }\n\n        .thinking-step-header {\n            display: flex;\n            align-items: center;\n            gap: 8px;\n            font-weight: 600;\n            margin-bottom: 6px;\n            color: var(--text-primary);\n        }\n\n        .thinking-step-content {\n            line-height: 1.4;\n        }\n\n        .message-input {\n            border-top: 1px solid var(--border-color);\n            padding: 16px 20px;\n            display: flex;\n            gap: 12px;\n            flex-shrink: 0;\n            background: var(--bg-secondary);\n        }\n\n        .input-field {\n            flex: 1;\n            background: var(--bg-primary);\n            border: 1px solid var(--border-color);\n            border-radius: 8px;\n            padding: 12px;\n            color: var(--text-primary);\n            font-size: 14px;\n        }\n\n        .input-field:focus {\n            outline: none;\n            border-color: var(--accent-blue);\n        }\n\n        .send-button {\n            background: var(--accent-blue);\n            color: white;\n            border: none;\n            border-radius: 8px;\n            padding: 12px 20px;\n            cursor: pointer;\n            font-weight: 600;\n            transition: all 0.2s;\n        }\n\n        .send-button:hover:not(:disabled) {\n            background: #4493f8;\n            transform: translateY(-1px);\n        }\n\n        .send-button:disabled {\n            opacity: 0.5;\n            cursor: not-allowed;\n            transform: none;\n        }\n\n        .panel-header {\n            padding: 16px;\n            background: var(--bg-tertiary);\n            border-bottom: 1px solid var(--border-color);\n            font-weight: 600;\n            font-size: 14px;\n        }\n\n        .panel-content {\n            flex: 1;\n            overflow-y: auto;\n            padding: 16px;\n            min-height: 0;\n        }\n\n        .progress-section {\n            margin-bottom: 20px;\n        }\n\n        .section-title {\n            font-size: 12px;\n            font-weight: 600;\n            color: var(--text-muted);\n            text-transform: uppercase;\n            margin-bottom: 8px;\n            letter-spacing: 0.5px;\n        }\n\n        /* NEW: Enhanced progress item styles */\n        .progress-item {\n            background: var(--bg-primary);\n            border: 1px solid var(--border-color);\n            border-radius: 8px;\n            padding: 12px;\n            margin-bottom: 8px;\n            font-size: 12px;\n            transition: all 0.2s;\n        }\n\n        .progress-item:hover {\n            border-color: var(--accent-blue);\n            transform: translateY(-1px);\n        }\n\n        .progress-item-header {\n            display: flex;\n            align-items: center;\n            gap: 8px;\n            margin-bottom: 6px;\n        }\n\n        .progress-icon {\n            width: 16px;\n            text-align: center;\n            font-size: 14px;\n        }\n\n        .progress-title {\n            font-weight: 500;\n            color: var(--text-primary);\n            flex: 1;\n        }\n\n        .progress-status {\n            padding: 2px 6px;\n            border-radius: 3px;\n            font-size: 10px;\n            font-weight: 500;\n        }\n\n        .progress-status.running {\n            background: var(--accent-orange);\n            color: white;\n        }\n\n        .progress-status.completed {\n            background: var(--accent-green);\n            color: white;\n        }\n\n        .progress-status.error {\n            background: var(--accent-red);\n            color: white;\n        }\n\n        .progress-status.starting {\n            background: var(--accent-cyan);\n            color: white;\n        }\n\n        .progress-details {\n            color: var(--text-secondary);\n            font-size: 11px;\n            line-height: 1.3;\n        }\n\n        .performance-metrics {\n            background: rgba(88, 166, 255, 0.05);\n            border: 1px solid rgba(88, 166, 255, 0.2);\n            border-radius: 6px;\n            padding: 8px;\n            margin-top: 6px;\n            font-size: 10px;\n        }\n\n        .performance-metrics .metric {\n            display: flex;\n            justify-content: space-between;\n            margin-bottom: 2px;\n        }\n\n        .no-agent-selected {\n            display: flex;\n            align-items: center;\n            justify-content: center;\n            flex-direction: column;\n            gap: 16px;\n            height: 100%;\n            color: var(--text-muted);\n            text-align: center;\n        }\n\n        .no-agent-selected .icon {\n            font-size: 48px;\n            opacity: 0.5;\n        }\n\n        .typing-indicator {\n            display: none;\n            align-items: center;\n            gap: 8px;\n            padding: 12px 16px;\n            background: var(--bg-tertiary);\n            margin: 12px 20px;\n            border-radius: 16px;\n            font-size: 14px;\n            color: var(--text-muted);\n            flex-shrink: 0;\n        }\n\n        .typing-indicator.active { display: flex; }\n\n        .typing-dots {\n            display: flex;\n            gap: 4px;\n        }\n\n        .typing-dot {\n            width: 6px;\n            height: 6px;\n            border-radius: 50%;\n            background: var(--text-muted);\n            animation: typing 1.4s infinite;\n        }\n\n        .typing-dot:nth-child(2) { animation-delay: 0.2s; }\n        .typing-dot:nth-child(3) { animation-delay: 0.4s; }\n\n        @keyframes typing {\n            0%, 60%, 100% { opacity: 0.3; }\n            30% { opacity: 1; }\n        }\n\n        .system-info {\n            margin-top: auto;\n            padding: 12px;\n            border-top: 1px solid var(--border-color);\n            font-size: 11px;\n            color: var(--text-muted);\n            flex-shrink: 0;\n        }\n\n        .error-message {\n            background: rgba(248, 81, 73, 0.1);\n            border: 1px solid var(--accent-red);\n            color: var(--accent-red);\n            padding: 12px;\n            border-radius: 6px;\n            margin: 12px;\n            font-size: 14px;\n            position: fixed;\n            bottom: 20px;\n            right: 20px;\n            z-index: 2000;\n            max-width: 300px;\n        }\n\n        .event-detail-modal {\n            position: fixed;\n            top: 0;\n            left: 0;\n            right: 0;\n            bottom: 0;\n            background: rgba(0, 0, 0, 0.8);\n            display: none;\n            align-items: center;\n            justify-content: center;\n            z-index: 2000;\n            padding: 20px;\n        }\n\n        .event-detail-modal.active {\n            display: flex;\n        }\n\n        .event-detail-content {\n            background: var(--bg-secondary);\n            border: 1px solid var(--border-color);\n            border-radius: 12px;\n            max-width: 800px;\n            max-height: 80vh;\n            width: 100%;\n            display: flex;\n            flex-direction: column;\n            overflow: hidden;\n            box-shadow: var(--shadow);\n        }\n\n        .event-detail-header {\n            padding: 20px 24px;\n            border-bottom: 1px solid var(--border-color);\n            background: var(--bg-tertiary);\n            display: flex;\n            align-items: center;\n            justify-content: space-between;\n            flex-shrink: 0;\n        }\n\n        .event-detail-title {\n            font-size: 18px;\n            font-weight: 600;\n            color: var(--text-primary);\n            display: flex;\n            align-items: center;\n            gap: 12px;\n        }\n\n        .event-detail-close {\n            background: none;\n            border: none;\n            color: var(--text-muted);\n            cursor: pointer;\n            padding: 8px;\n            border-radius: 6px;\n            font-size: 20px;\n            transition: all 0.2s;\n        }\n\n        .event-detail-close:hover {\n            background: var(--bg-primary);\n            color: var(--text-primary);\n        }\n\n        .event-detail-body {\n            flex: 1;\n            overflow-y: auto;\n            padding: 24px;\n            min-height: 0;\n        }\n\n        .event-section {\n            margin-bottom: 24px;\n        }\n\n        .event-section-title {\n            font-size: 14px;\n            font-weight: 600;\n            color: var(--accent-blue);\n            text-transform: uppercase;\n            letter-spacing: 0.5px;\n            margin-bottom: 12px;\n            padding-bottom: 6px;\n            border-bottom: 1px solid var(--border-color);\n        }\n\n        .event-field {\n            display: flex;\n            justify-content: space-between;\n            align-items: flex-start;\n            padding: 8px 0;\n            border-bottom: 1px solid rgba(48, 54, 61, 0.5);\n            font-size: 14px;\n        }\n\n        .event-field:last-child {\n            border-bottom: none;\n        }\n\n        .event-field-label {\n            font-weight: 500;\n            color: var(--text-secondary);\n            min-width: 140px;\n            flex-shrink: 0;\n        }\n\n        .event-field-value {\n            color: var(--text-primary);\n            flex: 1;\n            text-align: right;\n            word-break: break-word;\n        }\n\n        .event-field-value.json {\n            background: var(--bg-primary);\n            border-radius: 6px;\n            padding: 8px;\n            font-family: 'Consolas', 'Monaco', monospace;\n            font-size: 12px;\n            text-align: left;\n            white-space: pre-wrap;\n            max-height: 200px;\n            overflow-y: auto;\n        }\n\n        .event-status-badge {\n            padding: 4px 8px;\n            border-radius: 4px;\n            font-size: 12px;\n            font-weight: 500;\n        }\n\n        .event-status-badge.completed {\n            background: var(--accent-green);\n            color: white;\n        }\n\n        .event-status-badge.running {\n            background: var(--accent-orange);\n            color: white;\n        }\n\n        .event-status-badge.failed {\n            background: var(--accent-red);\n            color: white;\n        }\n\n        .progress-item {\n            cursor: pointer;\n            transition: all 0.2s;\n        }\n\n        .progress-item:hover {\n            transform: translateY(-2px);\n            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.2);\n        }\n\n        .thinking-step {\n            cursor: pointer;\n            transition: all 0.2s;\n        }\n\n        .thinking-step:hover {\n            transform: translateY(-1px);\n            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.15);\n        }\n    &lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n\n&lt;div class=\"api-key-modal\" id=\"api-key-modal\"&gt;\n    &lt;div class=\"api-key-content\"&gt;\n        &lt;div class=\"api-key-title\"&gt;\ud83d\udd10 Enter API Key&lt;/div&gt;\n        &lt;div class=\"api-key-description\"&gt;\n            Please enter your API key to access the agent. You can find this key in your agent registration details.\n        &lt;/div&gt;\n        &lt;input type=\"text\" class=\"api-key-input\" id=\"api-key-input\"\n               placeholder=\"tbk_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"&gt;\n        &lt;button class=\"api-key-button\" id=\"api-key-submit\"&gt;Connect&lt;/button&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div class=\"header\"&gt;\n    &lt;div class=\"logo\"&gt;\n        &lt;span&gt;\ud83e\udd16&lt;/span&gt;\n        &lt;span&gt;Agent Registry&lt;/span&gt;\n    &lt;/div&gt;\n    &lt;div class=\"header-controls\"&gt;\n        &lt;button class=\"panel-toggle active\" id=\"sidebar-toggle\"&gt;\ud83d\udccb Agents&lt;/button&gt;\n        &lt;button class=\"panel-toggle active\" id=\"progress-toggle\"&gt;\ud83d\udcca Progress&lt;/button&gt;\n        &lt;div class=\"status-indicator disconnected\" id=\"connection-status\"&gt;\n            &lt;div class=\"status-dot\"&gt;&lt;/div&gt;\n            &lt;span&gt;Connecting...&lt;/span&gt;\n        &lt;/div&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div class=\"mobile-tabs\"&gt;\n    &lt;div class=\"mobile-tab active\" data-tab=\"chat\"&gt;\ud83d\udcac Chat&lt;/div&gt;\n    &lt;div class=\"mobile-tab\" data-tab=\"agents\"&gt;\ud83d\udccb Agents&lt;/div&gt;\n    &lt;div class=\"mobile-tab\" data-tab=\"progress\"&gt;\ud83d\udcca Progress&lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div class=\"main-container\"&gt;\n    &lt;!-- Agents Sidebar --&gt;\n    &lt;div class=\"sidebar\" id=\"sidebar\"&gt;\n        &lt;div class=\"sidebar-header\"&gt;\n            &lt;div class=\"sidebar-title\"&gt;Available Agents&lt;/div&gt;\n            &lt;button class=\"collapse-btn\" id=\"sidebar-collapse\"&gt;\u25c0&lt;/button&gt;\n        &lt;/div&gt;\n        &lt;div class=\"agents-list\"&gt;\n            &lt;div id=\"agents-container\"&gt;\n                &lt;div style=\"color: var(--text-muted); font-size: 12px; text-align: center; padding: 20px;\"&gt;\n                    Loading agents...\n                &lt;/div&gt;\n            &lt;/div&gt;\n        &lt;/div&gt;\n        &lt;div class=\"system-info\"&gt;\n            &lt;div&gt;Registry Server&lt;/div&gt;\n            &lt;div id=\"server-info\"&gt;ws://localhost:8080&lt;/div&gt;\n        &lt;/div&gt;\n    &lt;/div&gt;\n\n    &lt;!-- Chat Area --&gt;\n    &lt;div class=\"chat-area\"&gt;\n        &lt;div class=\"chat-header\"&gt;\n            &lt;div class=\"chat-title\" id=\"chat-title\"&gt;Select an Agent&lt;/div&gt;\n            &lt;div class=\"chat-subtitle\" id=\"chat-subtitle\"&gt;Choose an agent from the sidebar to start chatting&lt;/div&gt;\n        &lt;/div&gt;\n\n        &lt;div class=\"messages-container\" id=\"messages-container\"&gt;\n            &lt;div class=\"no-agent-selected\"&gt;\n                &lt;div class=\"icon\"&gt;\ud83d\udcac&lt;/div&gt;\n                &lt;div&gt;Select an agent to start a conversation&lt;/div&gt;\n            &lt;/div&gt;\n        &lt;/div&gt;\n\n        &lt;div class=\"typing-indicator\" id=\"typing-indicator\"&gt;\n            &lt;span&gt;Agent is thinking&lt;/span&gt;\n            &lt;div class=\"typing-dots\"&gt;\n                &lt;div class=\"typing-dot\"&gt;&lt;/div&gt;\n                &lt;div class=\"typing-dot\"&gt;&lt;/div&gt;\n                &lt;div class=\"typing-dot\"&gt;&lt;/div&gt;\n            &lt;/div&gt;\n        &lt;/div&gt;\n\n        &lt;div class=\"message-input\"&gt;\n            &lt;input type=\"text\" class=\"input-field\" id=\"message-input\"\n                   placeholder=\"Type your message...\" disabled&gt;\n            &lt;button class=\"send-button\" id=\"send-button\" disabled&gt;Send&lt;/button&gt;\n        &lt;/div&gt;\n    &lt;/div&gt;\n    &lt;!-- Progress Panel --&gt;\n    &lt;div class=\"progress-panel\" id=\"progress-panel\"&gt;\n        &lt;div class=\"progress-header\"&gt;\n            &lt;span&gt;Live Progress&lt;/span&gt;\n            &lt;button class=\"collapse-btn\" id=\"progress-collapse\"&gt;\u25b6&lt;/button&gt;\n        &lt;/div&gt;\n        &lt;div class=\"panel-content\" id=\"progress-content\"&gt;\n            &lt;div class=\"progress-section\"&gt;\n                &lt;div class=\"section-title\"&gt;Current Status&lt;/div&gt;\n                &lt;div id=\"current-status\"&gt;\n                    &lt;div style=\"color: var(--text-muted); font-size: 12px; text-align: center; padding: 20px;\"&gt;\n                        No active execution\n                    &lt;/div&gt;\n                &lt;/div&gt;\n            &lt;/div&gt;\n\n            &lt;div class=\"progress-section\"&gt;\n                &lt;div class=\"section-title\"&gt;Performance Metrics&lt;/div&gt;\n                &lt;div id=\"performance-metrics\"&gt;\n                    &lt;div style=\"color: var(--text-muted); font-size: 12px; text-align: center; padding: 10px;\"&gt;\n                        No metrics available\n                    &lt;/div&gt;\n                &lt;/div&gt;\n            &lt;/div&gt;\n\n            &lt;div class=\"progress-section\"&gt;\n                &lt;div class=\"section-title\"&gt;Meta Tools History&lt;/div&gt;\n                &lt;div id=\"meta-tools-history\"&gt;\n                    &lt;div style=\"color: var(--text-muted); font-size: 12px; text-align: center; padding: 10px;\"&gt;\n                        No meta-tool activity\n                    &lt;/div&gt;\n                &lt;/div&gt;\n            &lt;/div&gt;\n\n            &lt;div class=\"progress-section\"&gt;\n                &lt;div class=\"section-title\"&gt;System Events&lt;/div&gt;\n                &lt;div id=\"system-events\"&gt;\n                    &lt;div style=\"color: var(--text-muted); font-size: 12px; text-align: center; padding: 10px;\"&gt;\n                        System idle\n                    &lt;/div&gt;\n                &lt;/div&gt;\n            &lt;/div&gt;\n        &lt;/div&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\n&lt;script unSave=\"true\"&gt;\n\n\n\n    class AgentRegistryUI {\n        constructor() {\n            this.ws = null;\n            this.currentAgent = null;\n            this.sessionId = 'ui_session_' + Math.random().toString(36).substr(2, 9);\n            this.isConnected = false;\n            this.reconnectAttempts = 0;\n            this.apiKey = null;\n            this.maxReconnectAttempts = 10;\n            this.reconnectDelay = 1000;\n\n            this.panelStates = {\n                sidebar: true,\n                progress: true,\n                mobile: 'chat'\n            };\n\n            this.agents = new Map();\n            this.currentExecution = null;\n\n            // NEW: Enhanced progress tracking\n            this.progressHistory = [];\n            this.maxProgressHistory = 200;\n            this.expandedProgressItem = null;\n            this.currentPerformanceMetrics = null;\n            this.currentOutline = null;\n\n            this.elements = {\n                connectionStatus: document.getElementById('connection-status'),\n                agentsContainer: document.getElementById('agents-container'),\n                chatTitle: document.getElementById('chat-title'),\n                chatSubtitle: document.getElementById('chat-subtitle'),\n                messagesContainer: document.getElementById('messages-container'),\n                messageInput: document.getElementById('message-input'),\n                sendButton: document.getElementById('send-button'),\n                typingIndicator: document.getElementById('typing-indicator'),\n                serverInfo: document.getElementById('server-info'),\n\n                // API Key elements\n                apiKeyModal: document.getElementById('api-key-modal'),\n                apiKeyInput: document.getElementById('api-key-input'),\n                apiKeySubmit: document.getElementById('api-key-submit'),\n\n                // Panel control elements\n                sidebarToggle: document.getElementById('sidebar-toggle'),\n                progressToggle: document.getElementById('progress-toggle'),\n                sidebarCollapse: document.getElementById('sidebar-collapse'),\n                progressCollapse: document.getElementById('progress-collapse'),\n                mainContainer: document.querySelector('.main-container'),\n                sidebar: document.getElementById('sidebar'),\n                progressPanel: document.getElementById('progress-panel'),\n                progressContent: document.getElementById('progress-content')\n            };\n\n            // Enhanced cleanup timer\n            setInterval(() =&gt; {\n                if (this.isTyping &amp;&amp; this.currentExecution) {\n                    const timeSinceLastUpdate = Date.now() - this.currentExecution.lastUpdate;\n                    if (timeSinceLastUpdate &gt; 30000) {\n                        console.log('\ud83e\uddf9 Cleanup: Hiding stuck typing indicator');\n                        this.showTypingIndicator(false);\n                        this.currentExecution = null;\n                        this.updateCurrentStatusToIdle();\n                    }\n                }\n            }, 5000);\n\n            this.init();\n        }\n\n        init() {\n            this.setupEventListeners();\n            this.setupPanelControls();\n            this.initializeProgressPanel();\n            this.showApiKeyModal();\n        }\n\n        // NEW: Initialize the refactored progress panel\n        initializeProgressPanel() {\n            if (this.elements.progressContent) {\n                this.elements.progressContent.innerHTML = `\n                &lt;div class=\"progress-section metrics-section\"&gt;\n                    &lt;div class=\"section-title expandable-section\" onclick=\"window.agentUI.toggleSection('metrics')\"&gt;\n                        &lt;span&gt;\ud83d\udcca Performance Metrics&lt;/span&gt;\n                        &lt;span class=\"section-toggle\"&gt;\u25bc&lt;/span&gt;\n                    &lt;/div&gt;\n                    &lt;div class=\"section-content\" id=\"performance-metrics\"&gt;\n                        &lt;div class=\"no-data\"&gt;No metrics available&lt;/div&gt;\n                    &lt;/div&gt;\n                &lt;/div&gt;\n\n                &lt;div class=\"progress-section outline-section\"&gt;\n                    &lt;div class=\"section-title expandable-section\" onclick=\"window.agentUI.toggleSection('outline')\"&gt;\n                        &lt;span&gt;\ud83d\uddfa\ufe0f Execution Outline &amp; Context&lt;/span&gt;\n                        &lt;span class=\"section-toggle\"&gt;\u25bc&lt;/span&gt;\n                    &lt;/div&gt;\n                    &lt;div class=\"section-content\" id=\"execution-outline\"&gt;\n                        &lt;div class=\"no-data\"&gt;No outline available&lt;/div&gt;\n                    &lt;/div&gt;\n                &lt;/div&gt;\n\n                &lt;div class=\"progress-section status-history-section\"&gt;\n                    &lt;div class=\"section-title expandable-section\" onclick=\"window.agentUI.toggleSection('status')\"&gt;\n                        &lt;span&gt;\u26a1 Status &amp; History&lt;/span&gt;\n                        &lt;span class=\"section-toggle\"&gt;\u25bc&lt;/span&gt;\n                    &lt;/div&gt;\n                    &lt;div class=\"section-content expanded\" id=\"status-history\"&gt;\n                        &lt;div class=\"no-data\"&gt;No active execution&lt;/div&gt;\n                    &lt;/div&gt;\n                &lt;/div&gt;\n            `;\n            }\n        }\n\n        // NEW: Toggle progress panel sections\n        toggleSection(sectionName) {\n            const section = document.querySelector(`.${sectionName}-section .section-content`);\n            const toggle = document.querySelector(`.${sectionName}-section .section-toggle`);\n\n            if (!section || !toggle) return;\n\n            const isExpanded = section.classList.contains('expanded');\n\n            if (isExpanded) {\n                section.classList.remove('expanded');\n                toggle.textContent = '\u25bc';\n            } else {\n                section.classList.add('expanded');\n                toggle.textContent = '\u25b2';\n            }\n        }\n\n        // REFACTORED: Main message handler with unified progress system\n        handleWebSocketMessage(data) {\n            console.log('WebSocket message received:', data);\n\n            if (data.event === 'execution_progress') {\n                const executionData = data.data;\n                if (executionData &amp;&amp; executionData.payload) {\n                    this.handleUnifiedProgressEvent(executionData);\n                }\n                return;\n            }\n\n            if (data.request_id &amp;&amp; data.payload) {\n                this.handleUnifiedProgressEvent(data);\n                return;\n            }\n\n            if (data.event) {\n                this.handleRegistryEvent(data);\n                return;\n            }\n\n            console.log('Unhandled message format:', data);\n        }\n\n        // NEW: Unified progress event handler\n        // REPLACE the existing handleUnifiedProgressEvent method\n        handleUnifiedProgressEvent(eventData) {\n            const payload = eventData.payload;\n            const eventType = payload.event_type;\n            const isFinal = eventData.is_final;\n            const requestId = eventData.request_id;\n\n            console.log(`\ud83c\udfaf Processing Event: ${eventType}`, payload);\n\n            // Handle final events\n            if (isFinal || eventType === 'execution_complete' || payload.status === 'completed') {\n                this.showTypingIndicator(false);\n\n                const result = payload.metadata?.result || payload.result || payload.response || payload.output;\n                if (result &amp;&amp; typeof result === 'string' &amp;&amp; result.trim()) {\n                    this.addMessage('agent', result);\n                }\n\n                this.currentExecution = null;\n                this.updateCurrentStatusToIdle();\n                return;\n            }\n\n            // Initialize execution tracking\n            if (!this.currentExecution) {\n                this.currentExecution = {\n                    requestId,\n                    startTime: Date.now(),\n                    events: [],\n                    lastUpdate: Date.now()\n                };\n                this.showTypingIndicator(true);\n            }\n\n            // ADD: Store ALL events in progress history\n            this.addToProgressHistory(payload);\n\n            // Handle chat integration for important events\n            this.handleChatIntegration(payload);\n\n            // Update performance metrics\n            this.updatePerformanceMetricsFromEvent(payload);\n\n            // Update execution outline\n            this.updateExecutionOutlineFromEvent(payload);\n\n            // Refresh status history (shows all events)\n            this.refreshStatusHistory();\n\n            // Update current execution\n            if (this.currentExecution) {\n                this.currentExecution.events.push({...payload, timestamp: Date.now()});\n                this.currentExecution.lastUpdate = Date.now();\n            }\n        }\n\n        // NEW: Add event to progress history\n        // UPDATE the addToProgressHistory method to ensure all events are captured\n        addToProgressHistory(payload) {\n        const irrelevantEventTypes = ['node_phase', 'node_enter']; // F\u00fcgen Sie hier weitere Typen hinzu, falls n\u00f6tig\n\n    // Pr\u00fcfen, ob der Event-Typ in der Liste der irrelevanten Typen ist\n    if (irrelevantEventTypes.includes(payload.event_type)) {\n        // Optional: Hier k\u00f6nnte man das Event kurz an anderer Stelle anzeigen,\n        // aber wir speichern es nicht im langfristigen Verlauf.\n        console.log(`\ud83d\udcdd Skipping storage for irrelevant event: ${payload.event_type}`);\n        return; // Die Funktion hier beenden, um das Speichern zu verhindern\n    }\n\n            // Generate consistent ID for events\n            const eventId = payload.event_id || `event_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;\n\n            const historyItem = {\n                ...payload,\n                timestamp: payload.timestamp || Date.now(),\n                id: eventId\n            };\n\n            // Remove any existing event with same ID to avoid duplicates\n            this.progressHistory = this.progressHistory.filter(item =&gt; item.id !== eventId);\n\n            this.progressHistory.unshift(historyItem);\n\n            if (this.progressHistory.length - 10 &gt; this.maxProgressHistory) {\n                this.progressHistory = this.progressHistory.slice(0, this.maxProgressHistory-50);\n            }\n\n            console.log(`\ud83d\udcdd Added to progress history: ${payload.event_type}`, historyItem);\n        }\n\n        // NEW: Refresh unified status history display\n        refreshStatusHistory() {\n            const container = document.getElementById('status-history');\n            if (!container) return;\n\n            if (this.progressHistory.length === 0) {\n                container.innerHTML = '&lt;div class=\"no-data\"&gt;No events recorded&lt;/div&gt;';\n                return;\n            }\n\n            container.innerHTML = '';\n\n            this.progressHistory.forEach((event, index) =&gt; {\n                const eventElement = this.createExpandableProgressItem(event, index === 0);\n                container.appendChild(eventElement);\n            });\n        }\n\n        // NEW: Create expandable progress item (only one expandable at a time)\n// UPDATE the createExpandableProgressItem method to show more LLM details\n        createExpandableProgressItem(event, isLatest = false) {\n            const div = document.createElement('div');\n            div.className = `progress-item expandable ${isLatest ? 'latest' : ''} ${event.event_type}`;\n            div.setAttribute('data-event-id', event.id);\n\n            const icon = this.getEventIcon(event.event_type, event.status);\n            const title = this.getDisplayAction(event.event_type, event);\n            const timestamp = new Date((event.timestamp || Date.now()) * (event.timestamp &gt; 10000000000 ? 1 : 1000)).toLocaleTimeString();\n            const status = event.status || 'unknown';\n\n            // ADD: Special summary for LLM calls\n            let summaryDetails = '';\n            if (event.node_name) summaryDetails += `${event.node_name} \u2022 `;\n            summaryDetails += timestamp;\n\n            if (event.event_type === 'llm_call') {\n                if (event.llm_temperature !== undefined) summaryDetails += ` \u2022 Temp: ${event.llm_temperature}`;\n                if (event.llm_total_tokens) summaryDetails += ` \u2022 ${event.llm_total_tokens} tokens`;\n                if (event.llm_cost) summaryDetails += ` \u2022 $${event.llm_cost.toFixed(4)}`;\n                if (event.duration) summaryDetails += ` \u2022 ${event.duration.toFixed(2)}s`;\n            } else {\n                if (event.duration) summaryDetails += ` \u2022 ${event.duration.toFixed(2)}s`;\n            }\n\n            div.innerHTML = `\n        &lt;div class=\"progress-item-header\" onclick=\"window.agentUI.toggleProgressItem('${event.id}')\"&gt;\n            &lt;div class=\"progress-icon\"&gt;${icon}&lt;/div&gt;\n            &lt;div class=\"progress-title\"&gt;${title}&lt;/div&gt;\n            &lt;div class=\"progress-meta\"&gt;\n                &lt;span class=\"progress-status ${status}\"&gt;${status}&lt;/span&gt;\n                &lt;span class=\"expand-indicator\"&gt;\u25bc&lt;/span&gt;\n            &lt;/div&gt;\n        &lt;/div&gt;\n        &lt;div class=\"progress-summary\"&gt;\n            ${summaryDetails}\n        &lt;/div&gt;\n        &lt;div class=\"progress-item-expanded\" id=\"expanded-${event.id}\"&gt;\n            ${this.createExpandedEventContent(event)}\n        &lt;/div&gt;\n    `;\n\n            return div;\n        }\n        // NEW: Toggle progress item (only one at a time)\n        toggleProgressItem(eventId) {\n            if (this.expandedProgressItem &amp;&amp; this.expandedProgressItem !== eventId) {\n                this.closeProgressItem(this.expandedProgressItem);\n            }\n\n            const expandedContent = document.getElementById(`expanded-${eventId}`);\n            const progressItem = document.querySelector(`[data-event-id=\"${eventId}\"]`);\n            const indicator = progressItem?.querySelector('.expand-indicator');\n\n            if (!expandedContent || !progressItem) return;\n\n            const isExpanded = expandedContent.classList.contains('active');\n\n            if (isExpanded) {\n                expandedContent.classList.remove('active');\n                progressItem.classList.remove('expanded');\n                if (indicator) indicator.textContent = '\u25bc';\n                this.expandedProgressItem = null;\n            } else {\n                expandedContent.classList.add('active');\n                progressItem.classList.add('expanded');\n                if (indicator) indicator.textContent = '\u25b2';\n                this.expandedProgressItem = eventId;\n            }\n        }\n\n        // NEW: Close progress item\n        closeProgressItem(eventId) {\n            const expandedContent = document.getElementById(`expanded-${eventId}`);\n            const progressItem = document.querySelector(`[data-event-id=\"${eventId}\"]`);\n            const indicator = progressItem?.querySelector('.expand-indicator');\n\n            if (expandedContent) expandedContent.classList.remove('active');\n            if (progressItem) progressItem.classList.remove('expanded');\n            if (indicator) indicator.textContent = '\u25bc';\n        }\n\n        // NEW: Create detailed expanded content\n// ADD this method to create comprehensive event details\n        createExpandedEventContent(event) {\n            const sections = [];\n\n            // Core Information\n            const coreInfo = this.extractCoreFields(event);\n            if (Object.keys(coreInfo).length &gt; 0) {\n                sections.push(this.createEventSection('Core Information', coreInfo));\n            }\n\n            // Timing Information\n            const timingInfo = this.extractTimingFields(event);\n            if (Object.keys(timingInfo).length &gt; 0) {\n                sections.push(this.createEventSection('Timing &amp; Status', timingInfo));\n            }\n\n            // LLM Information\n            const llmInfo = this.extractLLMFields(event);\n            if (Object.keys(llmInfo).length &gt; 0) {\n                sections.push(this.createEventSection('LLM Details', llmInfo));\n            }\n\n            // Tool Information\n            const toolInfo = this.extractToolFields(event);\n            if (Object.keys(toolInfo).length &gt; 0) {\n                sections.push(this.createEventSection('Tool Details', toolInfo));\n            }\n\n            // Performance Information\n            const perfInfo = this.extractPerformanceFields(event);\n            if (Object.keys(perfInfo).length &gt; 0) {\n                sections.push(this.createEventSection('Performance', perfInfo));\n            }\n\n            // Reasoning Context\n            const reasoningInfo = this.extractReasoningFields(event);\n            if (Object.keys(reasoningInfo).length &gt; 0) {\n                sections.push(this.createEventSection('Reasoning Context', reasoningInfo));\n            }\n\n            // Error Information\n            const errorInfo = this.extractErrorFields(event);\n            if (Object.keys(errorInfo).length &gt; 0) {\n                sections.push(this.createEventSection('Error Details', errorInfo));\n            }\n\n            // Raw Data\n            const rawData = this.extractRawDataFields(event);\n            if (Object.keys(rawData).length &gt; 0) {\n                sections.push(this.createEventSection('Raw Data', rawData));\n            }\n\n            return sections.join('') || '&lt;div class=\"no-expanded-data\"&gt;No detailed information available&lt;/div&gt;';\n        }\n\n        // NEW: Create event section for expanded view\n        createEventSection(title, fields) {\n            const fieldsHtml = Object.entries(fields)\n                .map(([key, value]) =&gt; {\n                    if (typeof value === 'object' &amp;&amp; value.type === 'json') {\n                        return `\n                        &lt;div class=\"event-field\"&gt;\n                            &lt;div class=\"event-field-label\"&gt;${key}:&lt;/div&gt;\n                            &lt;div class=\"event-field-value json\"&gt;${value.value}&lt;/div&gt;\n                        &lt;/div&gt;\n                    `;\n                    } else {\n                        return `\n                        &lt;div class=\"event-field\"&gt;\n                            &lt;div class=\"event-field-label\"&gt;${key}:&lt;/div&gt;\n                            &lt;div class=\"event-field-value\"&gt;${value}&lt;/div&gt;\n                        &lt;/div&gt;\n                    `;\n                    }\n                })\n                .join('');\n\n            return `\n            &lt;div class=\"expanded-section\"&gt;\n                &lt;div class=\"expanded-section-title\"&gt;${title}&lt;/div&gt;\n                ${fieldsHtml}\n            &lt;/div&gt;\n        `;\n        }\n\n        // ENHANCED: Chat integration for reasoning loops and task execution\n        handleChatIntegration(payload) {\n            const eventType = payload.event_type;\n            const metadata = payload.metadata || {};\n            switch (eventType) {\n                case 'reasoning_loop':\n                    if (metadata.outline_step &amp;&amp; metadata.outline_total) {\n                        this.handleOutlineStepInChat(payload);\n                    }\n                    break;\n                case 'outline_created':\n                    this.handleOutlineCreatedInChat(payload);\n                    break;\n                case 'task_start':\n                case 'task_complete':\n                case 'task_error':\n                    this.handleTaskProgressInChat(payload);\n                    break;\n                case 'plan_created':\n                    this.handlePlanCreatedInChat(payload);\n                    break;\n                case 'tool_call':\n                    // Only show important tool calls in chat\n                    if (payload.tool_name &amp;&amp; !payload.tool_name.includes('internal')) {\n                        this.handleToolCallInChat(payload);\n                    }\n                    break;\n            }\n        }\n\n        // ADD this method for plan creation\nhandlePlanCreatedInChat(payload) {\n    const metadata = payload.metadata || {};\n    const planName = metadata.plan_name || 'Execution Plan';\n    const taskCount = metadata.task_count || 0;\n    const strategy = metadata.strategy || 'sequential';\n\n    const planDiv = document.createElement('div');\n    planDiv.className = 'thinking-step plan-created';\n    planDiv.innerHTML = `\n        &lt;div class=\"thinking-step-header\"&gt;\n            &lt;span&gt;\ud83d\udccb&lt;/span&gt;\n            &lt;span&gt;${planName} Created&lt;/span&gt;\n            &lt;span class=\"step-status completed\"&gt;Ready&lt;/span&gt;\n        &lt;/div&gt;\n        &lt;div class=\"thinking-step-content\"&gt;\n            &lt;div class=\"plan-details\"&gt;\n                &lt;div class=\"plan-info\"&gt;\n                    &lt;span class=\"plan-item\"&gt;Tasks: ${taskCount}&lt;/span&gt;\n                    &lt;span class=\"plan-item\"&gt;Strategy: ${strategy}&lt;/span&gt;\n                &lt;/div&gt;\n                &lt;div class=\"plan-ready\"&gt;\n                    &lt;em&gt;\ud83d\ude80 Plan ready for execution&lt;/em&gt;\n                &lt;/div&gt;\n            &lt;/div&gt;\n        &lt;/div&gt;\n    `;\n\n    this.elements.messagesContainer.appendChild(planDiv);\n    this.scrollToBottom();\n}\n\n        // ADD this new method for outline step progress\nhandleOutlineStepInChat(payload) {\n    const metadata = payload.metadata || {};\n    const outlineStep = metadata.outline_step || 0;\n    const outlineTotal = metadata.outline_total || 0;\n    const loopNumber = metadata.loop_number || 0;\n    const status = payload.status || 'running';\n\n    if (outlineStep === 0 || outlineTotal === 0) return;\n\n    const progressPercentage = Math.round((outlineStep / outlineTotal) * 100);\n    const isCompleted = status === 'completed';\n\n    const stepDiv = document.createElement('div');\n    stepDiv.className = `thinking-step outline-step ${isCompleted ? 'completed' : 'running'}`;\n\n    let stepTitle = `Outline Step ${outlineStep} of ${outlineTotal}`;\n    let stepIcon = isCompleted ? '\u2705' : '\ud83d\uddfa\ufe0f';\n    let stepStatus = isCompleted ? 'Completed' : 'In Progress';\n\n    stepDiv.innerHTML = `\n        &lt;div class=\"thinking-step-header\"&gt;\n            &lt;span&gt;${stepIcon}&lt;/span&gt;\n            &lt;span&gt;${stepTitle}&lt;/span&gt;\n            &lt;span class=\"step-status ${status}\"&gt;${stepStatus}&lt;/span&gt;\n        &lt;/div&gt;\n        &lt;div class=\"thinking-step-content\"&gt;\n            &lt;div class=\"outline-progress\"&gt;\n                &lt;div class=\"progress-info\"&gt;\n                    &lt;span class=\"progress-text\"&gt;Execution Progress&lt;/span&gt;\n                    &lt;span class=\"progress-percentage\"&gt;${progressPercentage}%&lt;/span&gt;\n                &lt;/div&gt;\n                &lt;div class=\"progress-bar-container\"&gt;\n                    &lt;div class=\"progress-bar\"&gt;\n                        &lt;div class=\"progress-bar-fill\" style=\"width: ${progressPercentage}%\"&gt;&lt;/div&gt;\n                    &lt;/div&gt;\n                &lt;/div&gt;\n                ${isCompleted ?\n                    '&lt;div class=\"step-completed\"&gt;This execution step is now complete&lt;/div&gt;' :\n                    '&lt;div class=\"step-working\"&gt;Working on this step...&lt;/div&gt;'\n                }\n            &lt;/div&gt;\n\n            ${metadata.context_size || metadata.task_stack_size ? `\n                &lt;div class=\"context-info\"&gt;\n                    ${metadata.context_size ? `&lt;span class=\"context-item\"&gt;Context: ${metadata.context_size}&lt;/span&gt;` : ''}\n                    ${metadata.task_stack_size ? `&lt;span class=\"context-item\"&gt;Tasks: ${metadata.task_stack_size}&lt;/span&gt;` : ''}\n                &lt;/div&gt;\n            ` : ''}\n        &lt;/div&gt;\n    `;\n\n    this.elements.messagesContainer.appendChild(stepDiv);\n    this.scrollToBottom();\n}\n\n\n        // NEW: Handle outline creation with detailed information\n// REPLACE the existing handleOutlineCreatedInChat method\nhandleOutlineCreatedInChat(payload) {\n    const metadata = payload.metadata || {};\n    const outline = metadata.outline;\n\n    if (!outline) return;\n\n    const outlineDiv = document.createElement('div');\n    outlineDiv.className = 'thinking-step outline-created';\n    outlineDiv.innerHTML = `\n        &lt;div class=\"thinking-step-header\"&gt;\n            &lt;span&gt;\ud83d\udccb&lt;/span&gt;\n            &lt;span&gt;Execution Plan Created&lt;/span&gt;\n            &lt;span class=\"step-status completed\"&gt;Ready&lt;/span&gt;\n        &lt;/div&gt;\n        &lt;div class=\"thinking-step-content\"&gt;\n            &lt;div class=\"outline-content\"&gt;\n                ${this.formatOutlineForChat(outline)}\n            &lt;/div&gt;\n            &lt;div class=\"outline-ready\"&gt;\n                &lt;em&gt;\u2728 Ready to execute plan step by step&lt;/em&gt;\n            &lt;/div&gt;\n        &lt;/div&gt;\n    `;\n\n    this.elements.messagesContainer.appendChild(outlineDiv);\n    this.scrollToBottom();\n}\n\n        // NEW: Handle task execution progress cleanly\n        handleTaskProgressInChat(payload) {\n            const eventType = payload.event_type;\n            const taskId = payload.task_id;\n            const metadata = payload.metadata || {};\n            const description = metadata.description || 'Task execution';\n            const taskType = metadata.type || 'Task';\n            const priority = metadata.priority || 'normal';\n\n            let icon = '\ud83d\udccb';\n            let status = '';\n            let statusClass = 'running';\n\n            if (eventType === 'task_start') {\n                icon = '\u25b6\ufe0f';\n                status = 'Starting';\n                statusClass = 'starting';\n            } else if (eventType === 'task_complete') {\n                icon = '\u2705';\n                status = 'Completed';\n                statusClass = 'completed';\n            } else if (eventType === 'task_error') {\n                icon = '\u274c';\n                status = 'Failed';\n                statusClass = 'error';\n            }\n\n            const taskDiv = document.createElement('div');\n            taskDiv.className = `thinking-step task-progress ${statusClass}`;\n            taskDiv.innerHTML = `\n            &lt;div class=\"thinking-step-header\"&gt;\n                &lt;span&gt;${icon}&lt;/span&gt;\n                &lt;span&gt;${taskType} ${status}&lt;/span&gt;\n                &lt;span class=\"priority-badge ${priority}\"&gt;${priority}&lt;/span&gt;\n            &lt;/div&gt;\n            &lt;div class=\"thinking-step-content\"&gt;\n                &lt;div class=\"task-description\"&gt;${description}&lt;/div&gt;\n                ${payload.duration ? `&lt;div class=\"task-timing\"&gt;Duration: ${payload.duration.toFixed(2)}s&lt;/div&gt;` : ''}\n                ${eventType === 'task_error' &amp;&amp; payload.error_details?.message ?\n                `&lt;div class=\"task-error\"&gt;Error: ${payload.error_details.message}&lt;/div&gt;` : ''}\n            &lt;/div&gt;\n        `;\n\n            this.elements.messagesContainer.appendChild(taskDiv);\n            this.scrollToBottom();\n        }\n\n        // NEW: Handle tool calls in chat\n        handleToolCallInChat(payload) {\n            const toolName = payload.tool_name;\n            const status = payload.status;\n\n            if (status === 'running') return; // Only show completed tool calls\n\n            const toolDiv = document.createElement('div');\n            toolDiv.className = `thinking-step tool-call ${status}`;\n            toolDiv.innerHTML = `\n            &lt;div class=\"thinking-step-header\"&gt;\n                &lt;span&gt;\ud83d\udd27&lt;/span&gt;\n                &lt;span&gt;Used ${toolName}&lt;/span&gt;\n                &lt;span class=\"tool-status ${status}\"&gt;${status}&lt;/span&gt;\n            &lt;/div&gt;\n            &lt;div class=\"thinking-step-content\"&gt;\n                &lt;div class=\"tool-result\"&gt;\n                    ${status === 'completed' ? 'Tool executed successfully' : 'Tool execution failed'}\n                    ${payload.duration ? ` in ${payload.duration.toFixed(2)}s` : ''}\n                &lt;/div&gt;\n            &lt;/div&gt;\n        `;\n\n            this.elements.messagesContainer.appendChild(toolDiv);\n            this.scrollToBottom();\n        }\n\n        // NEW: Format outline for chat display\n        formatOutlineForChat(outline) {\n            if (typeof outline === 'string') {\n                return `&lt;div class=\"outline-text\"&gt;${outline}&lt;/div&gt;`;\n            }\n\n            if (Array.isArray(outline)) {\n                return `\n                &lt;div class=\"outline-steps\"&gt;\n                    ${outline.map((step, index) =&gt;\n                    `&lt;div class=\"outline-step\"&gt;\n                            &lt;span class=\"step-number\"&gt;${index + 1}.&lt;/span&gt;\n                            &lt;span class=\"step-text\"&gt;${step}&lt;/span&gt;\n                        &lt;/div&gt;`\n                ).join('')}\n                &lt;/div&gt;\n            `;\n            }\n\n            return '&lt;div class=\"outline-text\"&gt;Execution plan created&lt;/div&gt;';\n        }\n\n        // NEW: Create progress bar\n        createProgressBar(current, total) {\n            if (!total || total === 0) return '';\n\n            const percentage = Math.round((current / total) * 100);\n\n            return `\n            &lt;div class=\"progress-bar-container\"&gt;\n                &lt;div class=\"progress-bar-info\"&gt;\n                    &lt;span&gt;Progress&lt;/span&gt;\n                    &lt;span&gt;${percentage}%&lt;/span&gt;\n                &lt;/div&gt;\n                &lt;div class=\"progress-bar\"&gt;\n                    &lt;div class=\"progress-bar-fill\" style=\"width: ${percentage}%\"&gt;&lt;/div&gt;\n                &lt;/div&gt;\n            &lt;/div&gt;\n        `;\n        }\n\n        // ENHANCED: Update performance metrics\n        updatePerformanceMetricsFromEvent(payload) {\n            const metadata = payload.metadata || {};\n            const performance = metadata.performance_metrics;\n\n            if (performance &amp;&amp; Object.keys(performance).length &gt; 0) {\n                this.currentPerformanceMetrics = performance;\n                this.refreshPerformanceMetrics();\n            }\n        }\n\n        // NEW: Refresh performance metrics display\n        refreshPerformanceMetrics() {\n            const container = document.getElementById('performance-metrics');\n            if (!container || !this.currentPerformanceMetrics) return;\n\n            const metrics = {\n                'Action Efficiency': `${Math.round((this.currentPerformanceMetrics.action_efficiency || 0) * 100)}%`,\n                'Avg Loop Time': `${(this.currentPerformanceMetrics.avg_loop_time || 0).toFixed(1)}s`,\n                'Progress Rate': `${Math.round((this.currentPerformanceMetrics.progress_rate || 0) * 100)}%`,\n                'Total Loops': this.currentPerformanceMetrics.total_loops || 0,\n                'Progress Loops': this.currentPerformanceMetrics.progress_loops || 0\n            };\n\n            container.innerHTML = `\n            &lt;div class=\"metrics-grid\"&gt;\n                ${Object.entries(metrics).map(([key, value]) =&gt; `\n                    &lt;div class=\"metric-card\"&gt;\n                        &lt;div class=\"metric-label\"&gt;${key}&lt;/div&gt;\n                        &lt;div class=\"metric-value\"&gt;${value}&lt;/div&gt;\n                    &lt;/div&gt;\n                `).join('')}\n            &lt;/div&gt;\n        `;\n        }\n\n        // NEW: Update execution outline\n        updateExecutionOutlineFromEvent(payload) {\n            const eventType = payload.event_type;\n            const metadata = payload.metadata || {};\n\n            if (eventType === 'outline_created' || eventType === 'reasoning_loop') {\n                const outlineContainer = document.getElementById('execution-outline');\n                if (!outlineContainer) return;\n\n                const outline = metadata.outline;\n                const outlineStep = metadata.outline_step || 0;\n                const outlineTotal = metadata.outline_total || 0;\n                const contextSize = metadata.context_size || 0;\n                const taskStackSize = metadata.task_stack_size || 0;\n\n                outlineContainer.innerHTML = `\n                &lt;div class=\"outline-info\"&gt;\n                    &lt;div class=\"context-metrics\"&gt;\n                        &lt;div class=\"context-metric\"&gt;\n                            &lt;span class=\"context-label\"&gt;Context Size:&lt;/span&gt;\n                            &lt;span class=\"context-value\"&gt;${contextSize}&lt;/span&gt;\n                        &lt;/div&gt;\n                        &lt;div class=\"context-metric\"&gt;\n                            &lt;span class=\"context-label\"&gt;Task Stack:&lt;/span&gt;\n                            &lt;span class=\"context-value\"&gt;${taskStackSize}&lt;/span&gt;\n                        &lt;/div&gt;\n                        &lt;div class=\"context-metric\"&gt;\n                            &lt;span class=\"context-label\"&gt;Progress:&lt;/span&gt;\n                            &lt;span class=\"context-value\"&gt;${outlineStep}/${outlineTotal}&lt;/span&gt;\n                        &lt;/div&gt;\n                    &lt;/div&gt;\n\n                    ${outlineTotal &gt; 0 ? this.createProgressBar(outlineStep, outlineTotal) : ''}\n                &lt;/div&gt;\n\n                ${outline ? `\n                    &lt;div class=\"outline-details\"&gt;\n                        &lt;div class=\"outline-title\"&gt;Current Plan&lt;/div&gt;\n                        ${this.formatOutlineForChat(outline)}\n                    &lt;/div&gt;\n                ` : ''}\n            `;\n            }\n        }\n\n        // Helper methods for field extraction (using existing implementations)\n        extractCoreFields(event) {\n            const fields = {};\n            if (event.event_type) fields['Event Type'] = event.event_type.replace(/_/g, ' ').toUpperCase();\n            if (event.node_name) fields['Node'] = event.node_name;\n            if (event.agent_name) fields['Agent'] = event.agent_name;\n            if (event.task_id) fields['Task ID'] = event.task_id;\n            if (event.plan_id) fields['Plan ID'] = event.plan_id;\n            if (event.timestamp) fields['Timestamp'] = new Date((event.timestamp &gt; 10000000000 ? event.timestamp : event.timestamp * 1000)).toLocaleString();\n            return fields;\n        }\n\n// REPLACE the existing extractLLMFields method\n        extractLLMFields(event) {\n            const fields = {};\n            const metadata = event.metadata || {};\n\n            if (event.llm_model) fields['Model'] = event.llm_model;\n            if (event.llm_temperature !== undefined) fields['Temperature'] = event.llm_temperature;\n            if (event.llm_prompt_tokens) fields['Prompt Tokens'] = event.llm_prompt_tokens.toLocaleString();\n            if (event.llm_completion_tokens) fields['Completion Tokens'] = event.llm_completion_tokens.toLocaleString();\n            if (event.llm_total_tokens) fields['Total Tokens'] = event.llm_total_tokens.toLocaleString();\n            if (event.llm_cost) fields['Cost'] = `$${event.llm_cost.toFixed(4)}`;\n\n            // ADD: Model preferences and metadata\n            if (metadata.model_preference) fields['Model Preference'] = metadata.model_preference;\n\n            return fields;\n        }\n\n        extractToolFields(event) {\n            const fields = {};\n            const metadata = event.metadata || {};\n\n            if (event.tool_name) fields['Tool Name'] = event.tool_name;\n            if (metadata.meta_tool_name) fields['Meta Tool Name'] = metadata.meta_tool_name;\n\n            if (event.is_meta_tool !== null &amp;&amp; event.is_meta_tool !== undefined) {\n                fields['Is Meta Tool'] = event.is_meta_tool ? '\u2705 Yes' : '\u274c No';\n            }\n\n            // ADD: Tool execution details\n            if (metadata.execution_phase) fields['Execution Phase'] = metadata.execution_phase;\n            if (metadata.reasoning_loop) fields['Reasoning Loop'] = metadata.reasoning_loop;\n            if (metadata.parsed_args &amp;&amp; metadata.parsed_args.confidence_level) {\n                fields['Confidence Level'] = `${Math.round(metadata.parsed_args.confidence_level * 100)}%`;\n            }\n\n            return fields;\n        }\n\n// ADD these helper methods for comprehensive data extraction\n        extractTimingFields(event) {\n            const fields = {};\n\n            if (event.status) {\n                fields['Status'] = `&lt;span class=\"event-status-badge ${event.status}\"&gt;${event.status.toUpperCase()}&lt;/span&gt;`;\n            }\n            if (event.success !== null &amp;&amp; event.success !== undefined) {\n                fields['Success'] = event.success ? '\u2705 Yes' : '\u274c No';\n            }\n            if (event.timestamp) {\n                fields['Timestamp'] = new Date((event.timestamp &gt; 10000000000 ? event.timestamp : event.timestamp * 1000)).toLocaleString();\n            }\n            if (event.duration) {\n                fields['Duration'] = `${event.duration.toFixed(3)}s`;\n            }\n            if (event.node_duration) {\n                fields['Node Duration'] = `${event.node_duration.toFixed(3)}s`;\n            }\n            if (event.routing_decision) {\n                fields['Next Step'] = event.routing_decision;\n            }\n\n            return fields;\n        }\n\n        extractErrorFields(event) {\n            const fields = {};\n\n            if (event.error_details) {\n                const errorDetails = event.error_details;\n                if (errorDetails.message) fields['Error Message'] = errorDetails.message;\n                if (errorDetails.type) fields['Error Type'] = errorDetails.type;\n                if (errorDetails.traceback) {\n                    fields['Traceback'] = {\n                        type: 'json',\n                        value: errorDetails.traceback\n                    };\n                }\n            }\n\n            if (event.tool_error) {\n                fields['Tool Error'] = event.tool_error;\n            }\n\n            return fields;\n        }\n// REPLACE the existing extractRawDataFields method\n        extractRawDataFields(event) {\n            const fields = {};\n\n            // ADD: Full LLM Input/Output for LLM calls\n            if (event.event_type === 'llm_call') {\n                if (event.llm_input) {\n                    fields['LLM Input (Full Prompt)'] = {\n                        type: 'json',\n                        value: event.llm_input\n                    };\n                }\n\n                if (event.llm_output) {\n                    fields['LLM Output (Response)'] = {\n                        type: 'json',\n                        value: event.llm_output\n                    };\n                }\n            }\n\n            // Show other raw data for tool calls\n            if (event.tool_args &amp;&amp; typeof event.tool_args === 'object') {\n                fields['Tool Arguments'] = {\n                    type: 'json',\n                    value: JSON.stringify(event.tool_args, null, 2)\n                };\n            }\n\n            if (event.tool_result) {\n                const resultStr = typeof event.tool_result === 'string' ?\n                    event.tool_result :\n                    JSON.stringify(event.tool_result, null, 2);\n\n                fields['Tool Result'] = {\n                    type: 'json',\n                    value: resultStr.length &gt; 1000 ?\n                        resultStr.substring(0, 1000) + '\\\\n\\\\n... [truncated]' :\n                        resultStr\n                };\n            }\n\n            return fields;\n        }\n\n        extractPerformanceFields(event) {\n            const fields = {};\n            const metadata = event.metadata || {};\n            const performance = metadata.performance_metrics || {};\n\n            if (performance.action_efficiency) fields['Action Efficiency'] = `${Math.round(performance.action_efficiency * 100)}%`;\n            if (performance.avg_loop_time) fields['Avg Loop Time'] = `${performance.avg_loop_time.toFixed(2)}s`;\n            if (performance.progress_rate) fields['Progress Rate'] = `${Math.round(performance.progress_rate * 100)}%`;\n\n            return fields;\n        }\n\n        extractReasoningFields(event) {\n            const fields = {};\n            const metadata = event.metadata || {};\n\n            if (metadata.outline_step &amp;&amp; metadata.outline_total) {\n                fields['Outline Progress'] = `${metadata.outline_step}/${metadata.outline_total}`;\n            }\n            if (metadata.loop_number) fields['Loop Number'] = metadata.loop_number;\n            if (metadata.context_size) fields['Context Size'] = metadata.context_size.toLocaleString();\n            if (metadata.task_stack_size) fields['Task Stack Size'] = metadata.task_stack_size;\n\n            return fields;\n        }\n\n        extractMetadata(event) {\n            const fields = {};\n            const metadata = event.metadata || {};\n\n            // Show complex data as JSON\n            const complexFields = ['tool_args', 'tool_result', 'llm_input', 'llm_output', 'error_details'];\n\n            for (const field of complexFields) {\n                if (event[field] &amp;&amp; typeof event[field] === 'object') {\n                    fields[field.replace(/_/g, ' ').toUpperCase()] = {\n                        type: 'json',\n                        value: JSON.stringify(event[field], null, 2)\n                    };\n                }\n            }\n\n            return fields;\n        }\n\n        // Enhanced helper methods\n        // REPLACE the existing getDisplayAction method\n        getDisplayAction(eventType, payload) {\n            const metadata = payload.metadata || {};\n            switch (eventType) {\n                case 'reasoning_loop':\n                    const step = metadata.outline_step || 0;\n                    const total = metadata.outline_total || 0;\n                    return step &gt; 0 ? `Reasoning Step ${step}/${total}` : 'Deep Reasoning';\n                case 'task_start':\n                    return `Starting: ${metadata.description || 'Task'}`;\n                case 'task_complete':\n                    return `Completed: ${metadata.description || 'Task'}`;\n                case 'task_error':\n                    return `Failed: ${metadata.description || 'Task'}`;\n                case 'tool_call':\n                    const status = payload.status || 'running';\n                    const toolName = payload.tool_name || 'Unknown Tool';\n                    return `${status === 'running' ? 'Calling' : 'Called'} ${toolName}`;\n\n                case 'llm_call':\n                    const llmStatus = payload.status || 'running';\n                    const model = payload.llm_model || 'LLM';\n                    const taskId = payload.task_id || '';\n\n                    // Show more context for LLM calls\n                    let displayText = `${llmStatus === 'running' ? '\ud83d\udd04 Calling' : '\u2705 Called'} ${model}`;\n                    if (taskId &amp;&amp; taskId !== 'unknown') {\n                        displayText += ` (${taskId})`;\n                    }\n                    return displayText;\n                case 'plan_created':\n                    return `Plan: ${metadata.plan_name || 'Execution Plan'}`;\n                case 'outline_created':\n                    return 'Execution Outline Created';\n                case 'node_enter':\n                    return `Started: ${payload.node_name || 'Processing'}`;\n                case 'node_exit':\n                    return `Finished: ${payload.node_name || 'Processing'}`;\n                case 'node_phase':\n                    return `${payload.node_name || 'Node'}: ${payload.node_phase || 'Processing'}`;\n                case 'execution_start':\n                    return 'Execution Started';\n                case 'execution_complete':\n                    return 'Execution Complete';\n                // ADD: Meta tool events\n                case 'meta_tool_call':\n                    const metaToolName = metadata.meta_tool_name || payload.tool_name || 'Meta Tool';\n                    const metaStatus = payload.status || 'running';\n                    return `${metaStatus === 'running' ? 'Using' : 'Used'} ${metaToolName.replace(/_/g, ' ')}`;\n                // ADD: Error events\n                case 'error':\n                    return `Error in ${payload.node_name || 'System'}`;\n                default:\n                    return eventType.replace(/_/g, ' ').replace(/\\b\\w/g, l =&gt; l.toUpperCase());\n            }\n        }\n\n        // REPLACE the existing getEventIcon method\n        getEventIcon(eventType, status) {\n            if (status === 'error' || status === 'failed') return '\u274c';\n            if (status === 'completed') return '\u2705';\n\n            switch (eventType) {\n                case 'reasoning_loop': return '\ud83e\udde0';\n                case 'task_start': return '\u25b6\ufe0f';\n                case 'task_complete': return '\u2705';\n                case 'task_error': return '\u274c';\n                case 'tool_call': return '\ud83d\udd27';\n                case 'llm_call': return '\ud83d\udcad';\n                case 'plan_created': return '\ud83d\udccb';\n                case 'outline_created': return '\ud83d\uddfa\ufe0f';\n                case 'node_enter': return '\ud83d\ude80';\n                case 'node_exit': return '\ud83c\udfc1';\n                case 'node_phase': return '\u2699\ufe0f';\n                case 'execution_start': return '\ud83c\udfac';\n                case 'execution_complete': return '\ud83c\udf89';\n                case 'meta_tool_call': return '\ud83d\udee0\ufe0f';\n                case 'error': return '\ud83d\udea8';\n                default: return '\u26a1';\n            }\n        }\n\n        updateCurrentStatusToIdle() {\n            const container = document.getElementById('status-history');\n            if (container &amp;&amp; container.children.length === 0) {\n                container.innerHTML = `\n                &lt;div class=\"progress-item idle-status\"&gt;\n                    &lt;div class=\"progress-item-header\"&gt;\n                        &lt;div class=\"progress-icon\"&gt;\ud83d\udca4&lt;/div&gt;\n                        &lt;div class=\"progress-title\"&gt;Ready &amp; Waiting&lt;/div&gt;\n                        &lt;div class=\"progress-meta\"&gt;\n                            &lt;span class=\"progress-status idle\"&gt;idle&lt;/span&gt;\n                        &lt;/div&gt;\n                    &lt;/div&gt;\n                    &lt;div class=\"progress-summary\"&gt;\n                        Agent ready for next message \u2022 ${new Date().toLocaleTimeString()}\n                    &lt;/div&gt;\n                &lt;/div&gt;\n            `;\n            }\n        }\n\n        showTypingIndicator(show) {\n            console.log(`\ud83d\udcad ${show ? 'Showing' : 'Hiding'} typing indicator`);\n            this.elements.typingIndicator.classList.toggle('active', show);\n            if (show) {\n                this.elements.typingIndicator.scrollIntoView({ behavior: 'smooth', block: 'end' });\n            }\n            this.isTyping = show;\n        }\n\n        scrollToBottom() {\n            if (this.elements.messagesContainer) {\n                this.elements.messagesContainer.scrollTop = this.elements.messagesContainer.scrollHeight;\n            }\n        }\n\n        showApiKeyModal() {\n            const storedKey = localStorage.getItem('agent_registry_api_key');\n            if (storedKey) {\n                this.apiKey = storedKey;\n                this.elements.apiKeyModal.style.display = 'none';\n                this.connect();\n            } else {\n                this.elements.apiKeyModal.style.display = 'flex';\n            }\n        }\n\n        async validateAndStoreApiKey() {\n            const apiKey = this.elements.apiKeyInput.value.trim();\n            if (!apiKey) {\n                this.showError('Please enter an API key');\n                return;\n            }\n\n            if (!apiKey.startsWith('tbk_')) {\n                this.showError('Invalid API key format (should start with tbk_)');\n                return;\n            }\n\n            this.apiKey = apiKey;\n            this.elements.apiKeyModal.style.display = 'none';\n            this.connect();\n        }\n\n        setupPanelControls() {\n            this.elements.sidebarToggle?.addEventListener('click', () =&gt; this.togglePanel('sidebar'));\n            this.elements.progressToggle?.addEventListener('click', () =&gt; this.togglePanel('progress'));\n            this.elements.sidebarCollapse?.addEventListener('click', () =&gt; this.togglePanel('sidebar'));\n            this.elements.progressCollapse?.addEventListener('click', () =&gt; this.togglePanel('progress'));\n\n            const mobileTabs = document.querySelectorAll('.mobile-tab');\n            if (mobileTabs.length &gt; 0) {\n                mobileTabs.forEach(tab =&gt; {\n                    tab.addEventListener('click', () =&gt; this.switchMobileTab(tab.dataset.tab));\n                });\n            }\n\n            this.setupResponsiveHandlers();\n        }\n\n        togglePanel(panel) {\n            this.panelStates[panel] = !this.panelStates[panel];\n            this.updatePanelStates();\n        }\n\n        updatePanelStates() {\n            const { sidebar, progress } = this.panelStates;\n\n            if (this.elements.mainContainer) {\n                this.elements.mainContainer.classList.remove('sidebar-collapsed', 'progress-collapsed', 'both-collapsed');\n                if (!sidebar &amp;&amp; !progress) {\n                    this.elements.mainContainer.classList.add('both-collapsed');\n                } else if (!sidebar) {\n                    this.elements.mainContainer.classList.add('sidebar-collapsed');\n                } else if (!progress) {\n                    this.elements.mainContainer.classList.add('progress-collapsed');\n                }\n            }\n\n            if (this.elements.sidebar) this.elements.sidebar.classList.toggle('collapsed', !sidebar);\n            if (this.elements.progressPanel) this.elements.progressPanel.classList.toggle('collapsed', !progress);\n\n            if (this.elements.sidebarToggle) {\n                this.elements.sidebarToggle.classList.toggle('active', sidebar);\n                this.elements.sidebarToggle.textContent = sidebar ? '\ud83d\udccb Agents' : '\ud83d\udccb';\n            }\n\n            if (this.elements.progressToggle) {\n                this.elements.progressToggle.classList.toggle('active', progress);\n                this.elements.progressToggle.textContent = progress ? '\ud83d\udcca Progress' : '\ud83d\udcca';\n            }\n\n            if (this.elements.sidebarCollapse) this.elements.sidebarCollapse.textContent = sidebar ? '\u25c0' : '\u25b6';\n            if (this.elements.progressCollapse) this.elements.progressCollapse.textContent = progress ? '\u25b6' : '\u25c0';\n\n            if (this.elements.mainContainer) this.elements.mainContainer.offsetHeight;\n        }\n\n        handleWindowResize() {\n            const chatArea = document.querySelector('.chat-area');\n            const mainContainer = this.elements.mainContainer;\n\n            if (chatArea &amp;&amp; mainContainer) {\n                const currentDisplay = mainContainer.style.display;\n                mainContainer.style.display = 'none';\n                mainContainer.offsetHeight;\n                mainContainer.style.display = currentDisplay || '';\n            }\n        }\n\n        switchMobileTab(tab) {\n            this.panelStates.mobile = tab;\n\n            const mobileTabs = document.querySelectorAll('.mobile-tab');\n            if (mobileTabs.length &gt; 0) {\n                mobileTabs.forEach(t =&gt; t.classList.toggle('active', t.dataset.tab === tab));\n            }\n\n            const sidebarEl = document.querySelector('.sidebar');\n            const chatAreaEl = document.querySelector('.chat-area');\n            const progressPanelEl = document.querySelector('.progress-panel');\n\n            if (sidebarEl) sidebarEl.style.display = tab === 'agents' ? 'flex' : 'none';\n            if (chatAreaEl) chatAreaEl.style.display = tab === 'chat' ? 'flex' : 'none';\n            if (progressPanelEl) progressPanelEl.style.display = tab === 'progress' ? 'flex' : 'none';\n        }\n\n        setupResponsiveHandlers() {\n            const mediaQuery = window.matchMedia('(max-width: 768px)');\n            const handleResponsive = (e) =&gt; {\n                if (e.matches) {\n                    this.switchMobileTab(this.panelStates.mobile);\n                } else {\n                    const panels = document.querySelectorAll('.sidebar, .chat-area, .progress-panel');\n                    panels.forEach(panel =&gt; { if (panel) panel.style.display = ''; });\n                }\n            };\n\n            if (mediaQuery.addEventListener) {\n                mediaQuery.addEventListener('change', handleResponsive);\n            } else {\n                mediaQuery.addListener(handleResponsive);\n            }\n            handleResponsive(mediaQuery);\n        }\n\n        setupEventListeners() {\n            this.elements.apiKeySubmit?.addEventListener('click', () =&gt; this.validateAndStoreApiKey());\n            window.addEventListener('resize', () =&gt; this.handleWindowResize());\n            this.elements.apiKeyInput?.addEventListener('keypress', (e) =&gt; {\n                if (e.key === 'Enter') this.validateAndStoreApiKey();\n            });\n            this.elements.sendButton.addEventListener('click', () =&gt; this.sendMessage());\n            this.elements.messageInput.addEventListener('keypress', (e) =&gt; {\n                if (e.key === 'Enter' &amp;&amp; !e.shiftKey &amp;&amp; this.currentAgent) {\n                    e.preventDefault();\n                    this.sendMessage();\n                }\n            });\n\n            document.addEventListener('visibilitychange', () =&gt; {\n                if (!document.hidden &amp;&amp; (!this.ws || this.ws.readyState === WebSocket.CLOSED)) {\n                    this.connect();\n                }\n            });\n        }\n\n        connect() {\n            if (this.ws &amp;&amp; this.ws.readyState === WebSocket.OPEN) return;\n\n            this.updateConnectionStatus('connecting', 'Connecting...');\n\n            try {\n                const isLocal = window.location.hostname === 'localhost' || window.location.hostname === '127.0.0.1';\n                const wsProtocol = isLocal ? 'ws' : 'wss';\n                const wsUrl = `${wsProtocol}://${window.location.host}/ws/registry/ui_connect`;\n                this.ws = new WebSocket(wsUrl);\n\n                this.ws.onopen = () =&gt; {\n                    this.isConnected = true;\n                    this.reconnectAttempts = 0;\n                    this.updateConnectionStatus('connected', 'Connected');\n                    console.log('Connected to Registry Server');\n                };\n\n                this.ws.onmessage = (event) =&gt; {\n                    try {\n                        const data = JSON.parse(event.data);\n                        this.handleWebSocketMessage(data);\n                    } catch (error) {\n                        console.error('Message parse error:', error);\n                    }\n                };\n\n                this.ws.onclose = () =&gt; {\n                    this.isConnected = false;\n                    this.updateConnectionStatus('disconnected', 'Disconnected');\n                    this.scheduleReconnection();\n                };\n\n                this.ws.onerror = (error) =&gt; {\n                    console.error('WebSocket error:', error);\n                    this.updateConnectionStatus('error', 'Connection Error');\n                };\n\n            } catch (error) {\n                console.error('Connection error:', error);\n                this.updateConnectionStatus('error', 'Connection Failed');\n                this.scheduleReconnection();\n            }\n        }\n\n        scheduleReconnection() {\n            if (this.reconnectAttempts &gt;= this.maxReconnectAttempts) {\n                this.updateConnectionStatus('error', 'Connection Failed (Max attempts reached)');\n                return;\n            }\n\n            this.reconnectAttempts++;\n            const delay = Math.min(this.reconnectDelay * this.reconnectAttempts, 30000);\n\n            this.updateConnectionStatus('connecting', `Reconnecting in ${delay/1000}s (attempt ${this.reconnectAttempts})`);\n\n            setTimeout(() =&gt; {\n                if (!this.isConnected) this.connect();\n            }, delay);\n        }\n\n        updateConnectionStatus(status, text) {\n            this.elements.connectionStatus.className = `status-indicator ${status}`;\n            this.elements.connectionStatus.querySelector('span').textContent = text;\n        }\n\n        handleRegistryEvent(data) {\n            const event = data.event;\n            const payload = data.data || data;\n\n            console.log(`\ud83d\udccb Registry Event: ${event}`, payload);\n\n            switch (event) {\n                case 'api_key_validation':\n                    if (payload.valid) {\n                        console.log('\u2705 API key validated successfully');\n                    } else {\n                        this.showError('\u274c Invalid API key for this agent');\n                        this.currentAgent = null;\n                        this.elements.messageInput.disabled = true;\n                        this.elements.sendButton.disabled = true;\n                    }\n                    break;\n                case 'agents_list':\n                    console.log('\ud83d\udcdd Updating agents list:', payload.agents);\n                    this.updateAgentsList(payload.agents);\n                    break;\n                case 'agent_registered':\n                    console.log('\ud83c\udd95 Agent registered:', payload);\n                    this.addAgent(payload);\n                    break;\n                case 'error':\n                    console.error('\u274c WebSocket error:', payload);\n                    this.showError(payload.error || payload.message || 'Unknown error');\n                    break;\n                default:\n                    console.log('\u2753 Unhandled registry event:', event, payload);\n            }\n        }\n\n        updateAgentsList(agents) {\n            this.elements.agentsContainer.innerHTML = '';\n\n            if (!agents || agents.length === 0) {\n                this.elements.agentsContainer.innerHTML = '&lt;div style=\"color: var(--text-muted); font-size: 12px; text-align: center; padding: 20px;\"&gt;No agents available&lt;/div&gt;';\n                return;\n            }\n\n            agents.forEach(agent =&gt; {\n                this.agents.set(agent.public_agent_id, agent);\n                const agentEl = this.createAgentElement(agent);\n                this.elements.agentsContainer.appendChild(agentEl);\n            });\n        }\n\n        createAgentElement(agent) {\n            const div = document.createElement('div');\n            div.className = 'agent-item';\n            div.dataset.agentId = agent.public_agent_id;\n\n            div.innerHTML = `\n            &lt;div class=\"agent-name\"&gt;${agent.public_name}&lt;/div&gt;\n            &lt;div class=\"agent-description\"&gt;${agent.description || 'No description'}&lt;/div&gt;\n            &lt;div class=\"agent-status ${agent.status}\"&gt;\n                &lt;div class=\"status-dot\"&gt;&lt;/div&gt;\n                &lt;span&gt;${agent.status.toUpperCase()}&lt;/span&gt;\n            &lt;/div&gt;\n        `;\n\n            div.addEventListener('click', () =&gt; this.selectAgent(agent));\n            return div;\n        }\n\n        selectAgent(agent) {\n            if (!this.apiKey) {\n                this.showError('Please set your API key first');\n                return;\n            }\n\n            this.sendWebSocketMessage({\n                event: 'validate_api_key',\n                data: { public_agent_id: agent.public_agent_id, api_key: this.apiKey }\n            });\n\n            document.querySelectorAll('.agent-item').forEach(el =&gt; el.classList.remove('active'));\n            document.querySelector(`[data-agent-id=\"${agent.public_agent_id}\"]`)?.classList.add('active');\n\n            this.currentAgent = agent;\n            this.elements.chatTitle.textContent = agent.public_name;\n            this.elements.chatSubtitle.textContent = agent.description || 'Ready for conversation';\n\n            this.elements.messageInput.disabled = false;\n            this.elements.sendButton.disabled = false;\n\n            this.elements.messagesContainer.innerHTML = '';\n            this.addMessage('agent', `Hello! I'm ${agent.public_name}. How can I help you?`);\n\n            this.sendWebSocketMessage({\n                event: 'subscribe_agent',\n                data: { public_agent_id: agent.public_agent_id }\n            });\n\n            this.sendWebSocketMessage({\n                event: 'get_agent_status',\n                data: { public_agent_id: agent.public_agent_id }\n            });\n\n            // Reset progress panels\n            this.progressHistory = [];\n            this.refreshStatusHistory();\n            const metricsContainer = document.getElementById('performance-metrics');\n            if (metricsContainer) metricsContainer.innerHTML = '&lt;div class=\"no-data\"&gt;No metrics available&lt;/div&gt;';\n            const outlineContainer = document.getElementById('execution-outline');\n            if (outlineContainer) outlineContainer.innerHTML = '&lt;div class=\"no-data\"&gt;No outline available&lt;/div&gt;';\n        }\n\n        sendMessage() {\n            if (!this.currentAgent || !this.elements.messageInput.value.trim()) return;\n\n            const message = this.elements.messageInput.value.trim();\n            this.addMessage('user', message);\n\n            this.sendWebSocketMessage({\n                event: 'chat_message',\n                data: {\n                    public_agent_id: this.currentAgent.public_agent_id,\n                    message: message,\n                    session_id: this.sessionId,\n                    api_key: this.apiKey\n                }\n            });\n\n            this.elements.messageInput.value = '';\n\n            // Reset progress state\n            this.progressHistory = [];\n            this.expandedProgressItem = null;\n            this.refreshStatusHistory();\n\n            // Failsafe timeout\n            setTimeout(() =&gt; {\n                if (this.currentExecution) {\n                    console.log('\u23f0 Timeout: Hiding typing indicator and resetting execution state');\n                    this.showTypingIndicator(false);\n                    this.currentExecution = null;\n                    this.updateCurrentStatusToIdle();\n                    this.showError('Agent response timeout - please try again');\n                }\n            }, 60000);\n        }\n\n        addMessage(sender, content) {\n            const messageDiv = document.createElement('div');\n            messageDiv.classList.add('message', sender);\n\n            const avatar = document.createElement('div');\n            avatar.classList.add('message-avatar');\n            avatar.textContent = sender === 'user' ? 'U' : 'AI';\n\n            const contentDiv = document.createElement('div');\n            contentDiv.classList.add('message-content');\n\n            if (sender === 'agent' &amp;&amp; window.marked) {\n                try {\n                    contentDiv.innerHTML = marked.parse(content);\n                } catch (error) {\n                    contentDiv.textContent = content;\n                }\n            } else {\n                contentDiv.textContent = content;\n            }\n\n            messageDiv.appendChild(avatar);\n            messageDiv.appendChild(contentDiv);\n\n            this.elements.messagesContainer.appendChild(messageDiv);\n            this.elements.messagesContainer.scrollTop = this.elements.messagesContainer.scrollHeight;\n\n            if (sender === 'agent') {\n                this.showTypingIndicator(false);\n                setTimeout(() =&gt; {\n                    if (this.currentExecution) {\n                        this.currentExecution = null;\n                        this.updateCurrentStatusToIdle();\n                    }\n                }, 1000);\n            }\n        }\n\n        showError(message) {\n            const errorDiv = document.createElement('div');\n            errorDiv.className = 'error-message';\n            errorDiv.textContent = message;\n\n            document.body.appendChild(errorDiv);\n            setTimeout(() =&gt; {\n                if (errorDiv.parentNode) {\n                    errorDiv.parentNode.removeChild(errorDiv);\n                }\n            }, 5000);\n        }\n\n        sendWebSocketMessage(data) {\n            if (this.ws &amp;&amp; this.ws.readyState === WebSocket.OPEN) {\n                this.ws.send(JSON.stringify(data));\n            } else {\n                console.warn('WebSocket not connected, cannot send message');\n            }\n        }\n\n    }\n\n    // Initialize UI when DOM is ready\n    if (!window.TB) {\n        document.addEventListener('DOMContentLoaded', () =&gt; {\n            window.agentUI = new AgentRegistryUI();\n        });\n    } else {\n        TB.once(() =&gt; {\n            window.agentUI = new AgentRegistryUI();\n        });\n    }\n&lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\"\"\"\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry","title":"<code>registry</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.registry.client","title":"<code>client</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.registry.client.RegistryClient","title":"<code>RegistryClient</code>","text":"<p>Manages the client-side connection to the Registry Server with robust reconnection and long-running support.</p> Source code in <code>toolboxv2/mods/registry/client.py</code> <pre><code>class RegistryClient:\n    \"\"\"Manages the client-side connection to the Registry Server with robust reconnection and long-running support.\"\"\"\n\n    def __init__(self, app: App):\n        self.app = app\n\n        # WebSocket connection\n        self.ws: ws_client.WebSocketClientProtocol | None = None\n        self.server_url: str | None = None\n\n        # Task management\n        self.connection_task: asyncio.Task | None = None\n        self.ping_task: asyncio.Task | None = None\n        self.message_handler_tasks: set[asyncio.Task] = set()\n        self.progress_processor_task: asyncio.Task | None = None\n\n        # Connection state\n        self.is_connected = False\n        self.should_reconnect = True\n        self.reconnect_in_progress = False\n        self.reconnect_attempts = 0\n        self.max_reconnect_attempts = 10\n\n        # Agent management\n        self.local_agents: dict[str, Any] = {}\n        self.registered_info: dict[str, AgentRegistered] = {}\n        self.running_executions: dict[str, asyncio.Task] = {}\n        self.persistent_callbacks: dict[str, Callable] = {}\n\n        # Progress streaming (NO BATCHING - immediate streaming)\n        self.progress_queues: dict[str, asyncio.Queue] = {}\n        self.active_streams: set[str] = set()\n\n        # Event handling\n        self.custom_event_handlers: dict[str, Callable[[dict], Awaitable[None]]] = {}\n        self.pending_registrations: dict[str, asyncio.Future] = {}\n        self.registration_counter = 0\n\n    # Utility Methods\n    async def get_connection_status(self) -&gt; dict[str, Any]:\n        \"\"\"Get detailed connection status information.\"\"\"\n        try:\n            connection_status = {\n                \"is_connected\": self.is_connected,\n                \"server_url\": self.server_url,\n                \"reconnect_attempts\": self.reconnect_attempts,\n                \"max_reconnect_attempts\": self.max_reconnect_attempts,\n                \"should_reconnect\": self.should_reconnect,\n                \"reconnect_in_progress\": self.reconnect_in_progress,\n                \"websocket_state\": None,\n                \"websocket_open\": False,\n                \"tasks\": {\n                    \"connection_task_running\": self.connection_task and not self.connection_task.done(),\n                    \"ping_task_running\": self.ping_task and not self.ping_task.done(),\n                },\n                \"registered_agents_count\": len(self.local_agents),\n                \"running_executions_count\": len(self.running_executions),\n                \"pending_registrations_count\": len(self.pending_registrations),\n                \"persistent_callbacks_count\": len(self.persistent_callbacks),\n                \"last_ping_time\": getattr(self, 'last_ping_time', None),\n                \"connection_uptime\": None,\n                \"connection_established_at\": getattr(self, 'connection_established_at', None),\n            }\n\n            # WebSocket specific status\n            if self.ws:\n                connection_status.update({\n                    \"websocket_state\": str(self.ws.state.name) if hasattr(self.ws.state, 'name') else str(\n                        self.ws.state),\n                    \"websocket_open\": self.ws.open,\n                    \"websocket_closed\": self.ws.closed,\n                })\n\n            # Calculate uptime\n            if hasattr(self, 'connection_established_at') and self.connection_established_at:\n                connection_status[\n                    \"connection_uptime\"] = asyncio.get_event_loop().time() - self.connection_established_at\n\n            return connection_status\n\n        except Exception as e:\n            self.app.print(f\"Error getting connection status: {e}\")\n            return {\n                \"error\": str(e),\n                \"is_connected\": False,\n                \"server_url\": self.server_url,\n            }\n\n    async def get_registered_agents(self) -&gt; dict[str, AgentRegistered]:\n        \"\"\"Get all registered agents information.\"\"\"\n        try:\n            agents_info = {}\n\n            for agent_id, reg_info in self.registered_info.items():\n                # Get agent instance if available\n                agent_instance = self.local_agents.get(agent_id)\n\n                # Create enhanced agent info\n                agent_data = {\n                    \"registration_info\": reg_info,\n                    \"agent_available\": agent_instance is not None,\n                    \"agent_type\": type(agent_instance).__name__ if agent_instance else \"Unknown\",\n                    \"has_progress_callback\": hasattr(agent_instance, 'progress_callback') if agent_instance else False,\n                    \"supports_progress_callback\": hasattr(agent_instance,\n                                                          'set_progress_callback') if agent_instance else False,\n                    \"is_persistent_callback_active\": agent_id in self.persistent_callbacks,\n                    \"registration_timestamp\": getattr(reg_info, 'registration_timestamp', None),\n                }\n\n                # Add agent capabilities if available\n                if agent_instance and hasattr(agent_instance, 'get_capabilities'):\n                    try:\n                        agent_data[\"capabilities\"] = await agent_instance.get_capabilities()\n                    except Exception as e:\n                        agent_data[\"capabilities_error\"] = str(e)\n\n                agents_info[agent_id] = agent_data\n\n            return agents_info\n\n        except Exception as e:\n            self.app.print(f\"Error getting registered agents: {e}\")\n            return {}\n\n    async def get_running_executions(self) -&gt; dict[str, dict[str, Any]]:\n        \"\"\"Get information about currently running executions.\"\"\"\n        try:\n            executions_info = {}\n\n            for request_id, execution_task in self.running_executions.items():\n                execution_info = {\n                    \"request_id\": request_id,\n                    \"task_done\": execution_task.done(),\n                    \"task_cancelled\": execution_task.cancelled(),\n                    \"start_time\": getattr(execution_task, 'start_time', None),\n                    \"running_time\": None,\n                    \"task_exception\": None,\n                    \"task_result\": None,\n                }\n\n                # Calculate running time\n                if hasattr(execution_task, 'start_time') and execution_task.start_time:\n                    execution_info[\"running_time\"] = asyncio.get_event_loop().time() - execution_task.start_time\n\n                # Get task status details\n                if execution_task.done():\n                    try:\n                        if execution_task.exception():\n                            execution_info[\"task_exception\"] = str(execution_task.exception())\n                        else:\n                            execution_info[\"task_result\"] = \"completed_successfully\"\n                    except Exception as e:\n                        execution_info[\"task_status_error\"] = str(e)\n\n                executions_info[request_id] = execution_info\n\n            return executions_info\n\n        except Exception as e:\n            self.app.print(f\"Error getting running executions: {e}\")\n            return {}\n\n    async def cancel_execution(self, request_id: str) -&gt; bool:\n        \"\"\"Cancel a running execution.\"\"\"\n        try:\n            if request_id not in self.running_executions:\n                self.app.print(f\"\u274c Execution {request_id} not found\")\n                return False\n\n            execution_task = self.running_executions[request_id]\n\n            if execution_task.done():\n                self.app.print(f\"\u26a0\ufe0f  Execution {request_id} already completed\")\n                return True\n\n            # Cancel the task\n            execution_task.cancel()\n\n            try:\n                # Wait a moment for graceful cancellation\n                await asyncio.wait_for(execution_task, timeout=5.0)\n            except asyncio.CancelledError:\n                self.app.print(f\"\u2705 Execution {request_id} cancelled successfully\")\n            except asyncio.TimeoutError:\n                self.app.print(f\"\u26a0\ufe0f  Execution {request_id} cancellation timeout - may still be running\")\n            except Exception as e:\n                self.app.print(f\"\u26a0\ufe0f  Execution {request_id} cancellation resulted in exception: {e}\")\n\n            # Send cancellation notice to server\n            try:\n                if self.is_connected and self.ws and self.ws.open:\n                    cancellation_event = ProgressEvent(\n                        event_type=\"execution_cancelled\",\n                        node_name=\"RegistryClient\",\n                        success=False,\n                        metadata={\n                            \"request_id\": request_id,\n                            \"cancellation_reason\": \"client_requested\",\n                            \"timestamp\": asyncio.get_event_loop().time()\n                        }\n                    )\n\n                    cancellation_message = ExecutionResult(\n                        request_id=request_id,\n                        payload=cancellation_event.to_dict(),\n                        is_final=True\n                    )\n\n                    await self._send_message('execution_result', cancellation_message.model_dump())\n\n            except Exception as e:\n                self.app.print(f\"Failed to send cancellation notice to server: {e}\")\n\n            # Cleanup\n            self.running_executions.pop(request_id, None)\n\n            return True\n\n        except Exception as e:\n            self.app.print(f\"Error cancelling execution {request_id}: {e}\")\n            return False\n\n    async def health_check(self) -&gt; bool:\n        \"\"\"Perform a health check of the connection.\"\"\"\n        try:\n            # Basic connection checks\n            if not self.is_connected:\n                self.app.print(\"\ud83d\udd0d Health check: Not connected\")\n                return False\n\n            if not self.ws or not self.ws.open:\n                self.app.print(\"\ud83d\udd0d Health check: WebSocket not open\")\n                return False\n\n            # Ping test\n            try:\n                pong_waiter = await self.ws.ping()\n                await asyncio.wait_for(pong_waiter, timeout=10.0)\n\n                # Update last ping time\n                self.last_ping_time = asyncio.get_event_loop().time()\n\n                # Test message sending\n                test_message = WsMessage(\n                    event='health_check',\n                    data={\n                        \"timestamp\": self.last_ping_time,\n                        \"client_id\": getattr(self, 'client_id', 'unknown'),\n                        \"registered_agents\": list(self.local_agents.keys()),\n                        \"running_executions\": list(self.running_executions.keys())\n                    }\n                )\n\n                await self.ws.send(test_message.model_dump_json())\n\n                self.app.print(\"\u2705 Health check: Connection healthy\")\n                return True\n\n            except asyncio.TimeoutError:\n                self.app.print(\"\u274c Health check: Ping timeout\")\n                return False\n            except Exception as ping_error:\n                self.app.print(f\"\u274c Health check: Ping failed - {ping_error}\")\n                return False\n\n        except Exception as e:\n            self.app.print(f\"\u274c Health check: Error - {e}\")\n            return False\n\n    async def get_diagnostics(self) -&gt; dict[str, Any]:\n        \"\"\"Get comprehensive diagnostic information.\"\"\"\n        try:\n            diagnostics = {\n                \"connection_status\": await self.get_connection_status(),\n                \"registered_agents\": await self.get_registered_agents(),\n                \"running_executions\": await self.get_running_executions(),\n                \"health_status\": await self.health_check(),\n                \"system_info\": {\n                    \"python_version\": sys.version,\n                    \"asyncio_running\": True,\n                    \"event_loop\": str(asyncio.get_running_loop()),\n                    \"thread_name\": threading.current_thread().name,\n                },\n                \"performance_metrics\": {\n                    \"total_messages_sent\": getattr(self, 'total_messages_sent', 0),\n                    \"total_messages_received\": getattr(self, 'total_messages_received', 0),\n                    \"total_reconnections\": self.reconnect_attempts,\n                    \"total_registrations\": len(self.registered_info),\n                    \"memory_usage\": self._get_memory_usage(),\n                },\n                \"error_log\": getattr(self, 'recent_errors', []),\n            }\n\n            return diagnostics\n\n        except Exception as e:\n            return {\n                \"diagnostics_error\": str(e),\n                \"timestamp\": asyncio.get_event_loop().time()\n            }\n\n    def _get_memory_usage(self) -&gt; dict[str, Any]:\n        \"\"\"Get memory usage information.\"\"\"\n        try:\n            import psutil\n            import os\n\n            process = psutil.Process(os.getpid())\n            memory_info = process.memory_info()\n\n            return {\n                \"rss\": memory_info.rss,\n                \"vms\": memory_info.vms,\n                \"percent\": process.memory_percent(),\n                \"available\": psutil.virtual_memory().available,\n            }\n        except ImportError:\n            return {\"error\": \"psutil not available\"}\n        except Exception as e:\n            return {\"error\": str(e)}\n\n    async def cleanup_completed_executions(self):\n        \"\"\"Clean up completed execution tasks.\"\"\"\n        try:\n            completed_tasks = []\n\n            for request_id, task in self.running_executions.items():\n                if task.done():\n                    completed_tasks.append(request_id)\n\n            for request_id in completed_tasks:\n                self.running_executions.pop(request_id, None)\n                self.app.print(f\"\ud83e\uddf9 Cleaned up completed execution: {request_id}\")\n\n            return len(completed_tasks)\n\n        except Exception as e:\n            self.app.print(f\"Error during cleanup: {e}\")\n            return 0\n\n    async def connect(self, server_url: str, timeout: float = 30.0):\n        \"\"\"Connect and start all background tasks.\"\"\"\n        if not ws_client:\n            self.app.print(\"Websockets library not installed. Please run 'pip install websockets'\")\n            return False\n\n        if self.ws and self.ws.open:\n            self.app.print(\"Already connected to the registry server.\")\n            return True\n\n        self.server_url = server_url\n        self.should_reconnect = True\n        self.reconnect_in_progress = False\n\n        try:\n            self.app.print(f\"Connecting to Registry Server at {server_url}...\")\n            self.ws = await asyncio.wait_for(\n                ws_client.connect(server_url),\n                timeout=timeout\n            )\n\n            self.is_connected = True\n            self.reconnect_attempts = 0\n\n            # Start all background tasks\n            await self._start_all_background_tasks()\n\n            self.app.print(f\"\u2705 Successfully connected and started all tasks\")\n            return True\n\n        except asyncio.TimeoutError:\n            self.app.print(f\"\u274c Connection timeout after {timeout}s\")\n            return False\n        except Exception as e:\n            self.app.print(f\"\u274c Connection failed: {e}\")\n            return False\n\n    async def _start_all_background_tasks(self):\n        \"\"\"Start all background tasks needed for operation.\"\"\"\n        # Start connection listener\n        self.connection_task = asyncio.create_task(self._listen())\n\n        # Start ping task\n        self.ping_task = asyncio.create_task(self._ping_loop())\n\n        self.app.print(\"\ud83d\ude80 All background tasks started\")\n    async def _start_ping_task(self):\n        \"\"\"Start the ping/heartbeat task in the background.\"\"\"\n        if self.ping_task and not self.ping_task.done():\n            return  # Already running\n\n        self.ping_task = asyncio.create_task(self._ping_loop())\n\n    async def _ping_loop(self):\n        \"\"\"Dedicated ping task that never blocks and has highest priority.\"\"\"\n        ping_interval = 20  # Less aggressive than server's 5s interval\n        consecutive_failures = 0\n        max_failures = 2\n\n        while self.is_connected and self.should_reconnect:\n            try:\n                await asyncio.sleep(ping_interval)\n\n                # Double-check connection state\n                if not self.ws or not self.ws.open or self.ws.closed:\n                    self.app.print(\"Ping task detected closed connection\")\n                    break\n\n                try:\n                    # Send ping with short timeout\n                    pong_waiter = await self.ws.ping()\n                    await asyncio.wait_for(pong_waiter, timeout=8.0)  # Less than server's 10s timeout\n\n                    consecutive_failures = 0\n                    self.app.print(\"\ud83d\udce1 Heartbeat successful\")\n\n                except asyncio.TimeoutError:\n                    consecutive_failures += 1\n                    self.app.print(f\"\u26a0\ufe0f Ping timeout ({consecutive_failures}/{max_failures})\")\n\n                    if consecutive_failures &gt;= max_failures:\n                        self.app.print(\"\u274c Multiple ping timeouts - connection dead\")\n                        break\n\n                except Exception as ping_error:\n                    consecutive_failures += 1\n                    self.app.print(f\"\u274c Ping error ({consecutive_failures}/{max_failures}): {ping_error}\")\n\n                    if consecutive_failures &gt;= max_failures:\n                        break\n\n            except Exception as e:\n                self.app.print(f\"Ping loop error: {e}\")\n                break\n\n        self.app.print(\"Ping task stopped\")\n        # Trigger reconnect if we should still be connected\n        if self.should_reconnect and self.is_connected:\n            asyncio.create_task(self._trigger_reconnect())\n\n    async def _trigger_reconnect(self):\n        \"\"\"Trigger a reconnection attempt.\"\"\"\n        if self.reconnect_in_progress:\n            return\n\n        self.reconnect_in_progress = True\n        self.is_connected = False\n\n        try:\n            if self.ws:\n                with contextlib.suppress(Exception):\n                    await self.ws.close()\n                self.ws = None\n\n            # Stop current tasks\n            if self.connection_task and not self.connection_task.done():\n                self.connection_task.cancel()\n            if self.ping_task and not self.ping_task.done():\n                self.ping_task.cancel()\n\n            self.app.print(\"\ud83d\udd04 Attempting to reconnect...\")\n            await self._reconnect_with_backoff()\n\n        finally:\n            self.reconnect_in_progress = False\n\n    async def _reconnect_with_backoff(self):\n        \"\"\"Reconnect with exponential backoff.\"\"\"\n        max_attempts = 10\n        base_delay = 2\n        max_delay = 300  # 5 minutes max\n\n        for attempt in range(max_attempts):\n            if not self.should_reconnect:\n                break\n\n            delay = min(base_delay * (2 ** attempt), max_delay)\n            self.app.print(f\"\ud83d\udd04 Reconnect attempt {attempt + 1}/{max_attempts} in {delay}s...\")\n\n            await asyncio.sleep(delay)\n\n            try:\n                if self.server_url:\n                    self.ws = await ws_client.connect(self.server_url)\n                    self.is_connected = True\n                    self.reconnect_attempts = 0\n\n                    # Restart tasks\n                    self.connection_task = asyncio.create_task(self._listen())\n                    await self._start_ping_task()\n\n                    # Re-register agents\n                    await self._reregister_agents()\n\n                    self.app.print(\"\u2705 Reconnected successfully!\")\n                    return\n\n            except Exception as e:\n                self.app.print(f\"\u274c Reconnect attempt {attempt + 1} failed: {e}\")\n\n        self.app.print(\"\u274c All reconnection attempts failed\")\n        self.should_reconnect = False\n\n    async def _reregister_agents(self):\n        \"\"\"Re-register all local agents after reconnection.\"\"\"\n        if not self.registered_info:\n            self.app.print(\"No agents to re-register\")\n            return\n\n        self.app.print(f\"Re-registering {len(self.registered_info)} agents...\")\n\n        for agent_id, reg_info in list(self.registered_info.items()):\n            try:\n                agent_instance = self.local_agents.get(agent_id)\n                if not agent_instance:\n                    continue\n\n                # Create new registration (server will assign new IDs)\n                new_reg_info = await self.register(\n                    agent_instance,\n                    reg_info.public_name,\n                    self.local_agents.get(f\"{agent_id}_description\", \"Re-registered agent\")\n                )\n\n                if new_reg_info:\n                    # Update stored information\n                    old_agent_id = agent_id\n                    new_agent_id = new_reg_info.public_agent_id\n\n                    # Move agent to new ID\n                    self.local_agents[new_agent_id] = self.local_agents.pop(old_agent_id)\n                    self.registered_info[new_agent_id] = self.registered_info.pop(old_agent_id)\n\n                    self.app.print(f\"\u2705 Re-registered agent: {reg_info.public_name} (new ID: {new_agent_id})\")\n                else:\n                    self.app.print(f\"\u274c Failed to re-register agent: {reg_info.public_name}\")\n\n            except Exception as e:\n                self.app.print(f\"Error re-registering agent {reg_info.public_name}: {e}\")\n\n        self.app.print(\"Agent re-registration completed\")\n\n    async def _create_persistent_progress_callback(self, request_id: str, agent_id: str):\n        \"\"\"Create progress callback with offline queuing capability.\"\"\"\n        progress_queue = asyncio.Queue(maxsize=100)  # Buffer for offline messages\n\n        async def persistent_progress_callback(event: ProgressEvent):\n            try:\n                # Add to queue first\n                try:\n                    progress_queue.put_nowait((event, asyncio.get_event_loop().time()))\n                except asyncio.QueueFull:\n                    # Remove oldest item and add new one\n                    try:\n                        progress_queue.get_nowait()\n                        progress_queue.put_nowait((event, asyncio.get_event_loop().time()))\n                    except asyncio.QueueEmpty:\n                        pass\n\n                # Try to send immediately if connected\n                if await self._check_connection_health():\n                    try:\n                        result = ExecutionResult(\n                            request_id=request_id,\n                            payload=event.to_dict(),\n                            is_final=False\n                        )\n                        success = await self._send_message('execution_result', result.model_dump())\n                        if success:\n                            # Remove from queue since it was sent successfully\n                            try:\n                                progress_queue.get_nowait()\n                            except asyncio.QueueEmpty:\n                                pass\n                            return\n                    except Exception as e:\n                        self.app.print(f\"Progress send failed, queued: {e}\")\n\n                # If we get here, message is queued for later sending\n\n            except Exception as e:\n                self.app.print(f\"Progress callback error: {e}\")\n\n        # Store queue for later processing\n        self.progress_queues[request_id] = progress_queue\n        return persistent_progress_callback\n    async def _store_progress_callback_state(self, agent_id: str, callback_func):\n        \"\"\"Store progress callback for reconnection scenarios.\"\"\"\n        self.persistent_callbacks[agent_id] = callback_func\n\n    async def _restore_progress_callbacks(self):\n        \"\"\"Restore progress callbacks after reconnection.\"\"\"\n        for agent_id, callback_func in self.persistent_callbacks.items():\n            agent = self.local_agents.get(agent_id)\n            if agent and hasattr(agent, 'set_progress_callback'):\n                agent.set_progress_callback(callback_func)\n\n    def on(self, event_name: str, handler: Callable[[dict], Awaitable[None]]):\n        \"\"\"Register an async callback function to handle a custom event from the server.\"\"\"\n        self.app.print(f\"Handler for custom event '{event_name}' registered.\")\n        self.custom_event_handlers[event_name] = handler\n\n    async def send_custom_event(self, event_name: str, data: dict[str, Any]):\n        \"\"\"Send a custom event with a JSON payload to the server.\"\"\"\n        if not self.is_connected or not self.ws or not self.ws.open:\n            self.app.print(\"Cannot send custom event: Not connected.\")\n            return\n\n        try:\n            message = WsMessage(event=event_name, data=data)\n            await self.ws.send(message.model_dump_json())\n            self.app.print(f\"Sent custom event '{event_name}' to server.\")\n        except Exception as e:\n            self.app.print(f\"Failed to send custom event: {e}\")\n            await self._handle_connection_error()\n\n    async def _listen(self):\n        \"\"\"Robust message listening loop with immediate connection loss detection.\"\"\"\n        self.app.print(\"Registry client is now listening for incoming requests...\")\n\n        try:\n            while self.is_connected and self.ws and self.ws.open:\n                try:\n                    # Check connection state before each recv attempt\n                    if self.ws.closed:\n                        self.app.print(\"WebSocket is closed - triggering reconnect\")\n                        break\n\n                    message_raw = await asyncio.wait_for(self.ws.recv(), timeout=5.0)\n\n                    # Handle different message types immediately\n                    if isinstance(message_raw, bytes):\n                        # Server ping - respond immediately\n                        continue\n\n                    # Process text messages\n                    try:\n                        message = WsMessage.model_validate_json(message_raw)\n                        # Handle critical messages immediately, others in background\n                        if message.event in ['agent_registered']:\n                            await self._handle_message(message)\n                        else:\n                            # Handle non-critical messages in background to avoid blocking\n                            task = asyncio.create_task(self._handle_message(message))\n                            self.message_handler_tasks.add(task)\n                            # Clean completed tasks\n                            self.message_handler_tasks = {t for t in self.message_handler_tasks if not t.done()}\n\n                    except Exception as e:\n                        self.app.print(f\"Error processing message: {e} | Raw: {message_raw[:200]}\")\n\n                except asyncio.TimeoutError:\n                    # Normal timeout - check connection health\n                    if not self.ws or not self.ws.open or self.ws.closed:\n                        self.app.print(\"Connection health check failed during timeout\")\n                        break\n                    continue\n\n                except ConnectionClosed as e:\n                    self.app.print(f\"Connection closed by server: {e}\")\n                    break\n\n                except Exception as e:\n                    # Any other WebSocket error means connection is likely dead\n                    if \"ConnectionClosedError\" in str(type(e)) or \"IncompleteReadError\" in str(type(e)):\n                        self.app.print(f\"Connection lost: {e}\")\n                        break\n                    else:\n                        self.app.print(f\"Unexpected error in listen loop: {e}\")\n                        # Don't break on unexpected errors, but log them\n                        await asyncio.sleep(0.1)\n\n        except Exception as e:\n            self.app.print(f\"Fatal error in listen loop: {e}\")\n        finally:\n            # Always trigger reconnection attempt\n            if self.should_reconnect:\n                asyncio.create_task(self._trigger_reconnect())\n\n    async def _handle_message(self, message: WsMessage):\n        \"\"\"Handle incoming WebSocket messages with non-blocking execution.\"\"\"\n        try:\n            if message.event == 'agent_registered':\n                # Handle registration confirmation immediately\n                reg_info = AgentRegistered.model_validate(message.data)\n                reg_id = None\n                for rid, future in self.pending_registrations.items():\n                    if not future.done():\n                        reg_id = rid\n                        break\n\n                if reg_id and reg_id in self.pending_registrations:\n                    if not self.pending_registrations[reg_id].done():\n                        self.pending_registrations[reg_id].set_result(reg_info)\n                else:\n                    self.app.print(\"Received agent_registered but no pending registration found\")\n\n            elif message.event == 'run_request':\n                # Handle run requests in background - NEVER block here\n                run_data = RunRequest.model_validate(message.data)\n                asyncio.create_task(self._handle_run_request(run_data))\n\n            elif message.event in self.custom_event_handlers:\n                # Handle custom events in background\n                self.app.print(f\"Received custom event '{message.event}' from server.\")\n                handler = self.custom_event_handlers[message.event]\n                asyncio.create_task(handler(message.data))\n\n            else:\n                self.app.print(f\"Received unhandled event from server: '{message.event}'\")\n\n        except Exception as e:\n            self.app.print(f\"Error handling message: {e}\")\n            # Don't let message handling errors kill the connection\n\n    async def register(self, agent_instance: Any, public_name: str, description: str | None = None) -&gt; AgentRegistered | None:\n        \"\"\"Register an agent with the server.\"\"\"\n        if not self.is_connected or not self.ws:\n            self.app.print(\"Not connected. Cannot register agent.\")\n            return None\n\n        try:\n            # Create registration request\n            registration = AgentRegistration(public_name=public_name, description=description)\n            message = WsMessage(event='register', data=registration.model_dump())\n\n            # Create future for registration response\n            reg_id = f\"reg_{self.registration_counter}\"\n            self.registration_counter += 1\n            self.pending_registrations[reg_id] = asyncio.Future()\n\n            # Send registration request\n            await self.ws.send(message.model_dump_json())\n            self.app.print(f\"Sent registration request for agent '{public_name}'\")\n\n            # Wait for registration confirmation\n            try:\n                reg_info = await asyncio.wait_for(self.pending_registrations[reg_id], timeout=30.0)\n\n                # Store agent and registration info\n                self.local_agents[reg_info.public_agent_id] = agent_instance\n                self.registered_info[reg_info.public_agent_id] = reg_info\n\n                self.app.print(f\"Agent '{public_name}' registered successfully.\")\n                self.app.print(f\"  Public URL: {reg_info.public_url}\")\n                self.app.print(f\"  API Key: {reg_info.public_api_key}\")\n\n                return reg_info\n\n            except TimeoutError:\n                self.app.print(\"Timeout waiting for registration confirmation.\")\n                return None\n\n        except Exception as e:\n            self.app.print(f\"Error during registration: {e}\")\n            return None\n        finally:\n            # Cleanup pending registration\n            self.pending_registrations.pop(reg_id, None)\n\n    async def _handle_run_request(self, run_request: RunRequest):\n        \"\"\"Handle run request - start agent in completely separate task.\"\"\"\n        agent_id = run_request.public_agent_id\n        agent = self.local_agents.get(agent_id)\n\n        if not agent:\n            await self._stream_error(run_request.request_id, f\"Agent with ID {agent_id} not found\")\n            return\n\n        # Start agent execution in separate task - NEVER await here\n        execution_task = asyncio.create_task(\n            self._execute_agent_with_monitoring(agent, run_request)\n        )\n\n        # Store task but don't wait for it\n        self.running_executions[run_request.request_id] = execution_task\n\n        self.app.print(f\"\ud83d\ude80 Agent execution started in background: {run_request.request_id}\")\n        # This method returns immediately - agent runs in background\n    async def _execute_agent_with_monitoring(self, agent: Any, run_request: RunRequest):\n        \"\"\"Execute agent in completely separate task - never blocks main connection.\"\"\"\n        request_id = run_request.request_id\n        agent_id = run_request.public_agent_id\n\n        try:\n            # Create progress streaming callback\n            progress_callback = await self._create_streaming_progress_callback(request_id, agent_id)\n\n            # Store original callback\n            original_callback = getattr(agent, 'progress_callback', None)\n\n            # Set streaming progress callback\n            if hasattr(agent, 'set_progress_callback'):\n                agent.set_progress_callback(progress_callback)\n            elif hasattr(agent, 'progress_callback'):\n                agent.progress_callback = progress_callback\n\n            # Store for reconnection scenarios\n            self.persistent_callbacks[agent_id] = progress_callback\n            self.active_streams.add(request_id)\n\n            self.app.print(f\"\ud83d\ude80 Starting agent execution in separate task: {request_id}\")\n\n            # EXECUTE THE AGENT - this can run for hours/days\n            final_result = await agent.a_run(\n                query=run_request.query,\n                session_id=run_request.session_id,\n                **run_request.kwargs\n            )\n\n            # Send final result\n            await self._stream_final_result(request_id, final_result, agent_id, run_request.session_id)\n\n            self.app.print(f\"\u2705 Agent execution completed: {request_id}\")\n\n        except Exception as e:\n            self.app.print(f\"\u274c Agent execution failed: {e}\")\n            await self._stream_error(request_id, str(e))\n            import traceback\n            traceback.print_exc()\n\n        finally:\n            # Cleanup\n            await self.running_executions.pop(request_id, None)\n            self.persistent_callbacks.pop(agent_id, None)\n            self.active_streams.discard(request_id)\n\n            # Close progress queue\n            if request_id in self.progress_queues:\n                queue = self.progress_queues.pop(request_id)\n                # Signal queue processor to stop for this request\n                try:\n                    await queue.put(None)  # Sentinel value\n                except:\n                    pass\n\n            # Restore original callback\n            try:\n                if hasattr(agent, 'set_progress_callback'):\n                    agent.set_progress_callback(original_callback)\n                elif hasattr(agent, 'progress_callback'):\n                    agent.progress_callback = original_callback\n            except Exception as cleanup_error:\n                self.app.print(f\"Warning: Callback cleanup failed: {cleanup_error}\")\n\n    async def _stream_final_result(self, request_id: str, final_result: Any, agent_id: str, session_id: str):\n        \"\"\"Stream final result immediately.\"\"\"\n        final_event = ProgressEvent(\n            event_type=\"execution_complete\",\n            node_name=\"RegistryClient\",\n            success=True,\n            metadata={\n                \"result\": final_result,\n                \"agent_id\": agent_id,\n                \"session_id\": session_id\n            }\n        )\n\n        final_message = ExecutionResult(\n            request_id=request_id,\n            payload=final_event.to_dict(),\n            is_final=True\n        )\n\n        # Stream final result with high priority\n        max_attempts = 10\n        for attempt in range(max_attempts):\n            try:\n                if await self._check_connection_health():\n                    success = await self._send_message('execution_result', final_message.model_dump())\n                    if success:\n                        self.app.print(f\"\u2705 Final result streamed successfully\")\n                        return\n\n                await asyncio.sleep(1.0 * (attempt + 1))  # Longer delays for final result\n\n            except Exception as e:\n                self.app.print(f\"Final result stream attempt {attempt + 1} failed: {e}\")\n\n        self.app.print(f\"\u274c Failed to stream final result after {max_attempts} attempts\")\n\n    async def _stream_error(self, request_id: str, error_message: str):\n        \"\"\"Stream error immediately.\"\"\"\n        error_payload = ExecutionError(request_id=request_id, error=error_message)\n\n        for attempt in range(5):\n            try:\n                if await self._check_connection_health():\n                    success = await self._send_message('execution_error', error_payload.model_dump())\n                    if success:\n                        return\n                await asyncio.sleep(0.5 * (attempt + 1))\n            except Exception as e:\n                self.app.print(f\"Error stream attempt {attempt + 1} failed: {e}\")\n\n    async def _create_streaming_progress_callback(self, request_id: str, agent_id: str):\n        \"\"\"Create callback that streams progress immediately as it comes.\"\"\"\n        # Create queue for this specific request\n        progress_queue = asyncio.Queue()\n        self.progress_queues[request_id] = progress_queue\n\n        # Start dedicated processor for this request\n        processor_task = asyncio.create_task(\n            self._process_progress_stream(request_id, progress_queue)\n        )\n\n        async def streaming_progress_callback(event: ProgressEvent):\n            \"\"\"Stream progress immediately - no batching, no delays.\"\"\"\n            try:\n                if request_id in self.active_streams:\n                    # Put in queue for immediate processing\n                    await progress_queue.put(event)\n            except Exception as e:\n                self.app.print(f\"Progress streaming error: {e}\")\n\n        return streaming_progress_callback\n\n    async def _process_progress_stream(self, request_id: str, progress_queue: asyncio.Queue):\n        \"\"\"Process progress stream in real-time - separate task per request.\"\"\"\n        self.app.print(f\"\ud83d\udce1 Started progress streaming for request: {request_id}\")\n\n        while request_id in self.active_streams:\n            try:\n                # Get next progress event (blocking)\n                event = await progress_queue.get()\n\n                # Sentinel value to stop\n                if event is None:\n                    break\n\n                # Stream immediately - no batching\n                await self._stream_progress_immediately(request_id, event)\n\n            except Exception as e:\n                self.app.print(f\"Progress stream processing error: {e}\")\n                await asyncio.sleep(0.1)  # Brief pause on error\n\n        self.app.print(f\"\ud83d\udce1 Stopped progress streaming for request: {request_id}\")\n\n    async def _stream_progress_immediately(self, request_id: str, event: ProgressEvent):\n        \"\"\"Stream single progress event immediately.\"\"\"\n        max_attempts = 3\n\n        for attempt in range(max_attempts):\n            try:\n                if await self._check_connection_health():\n                    result = ExecutionResult(\n                        request_id=request_id,\n                        payload=event.to_dict(),\n                        is_final=False\n                    )\n\n                    success = await self._send_message('execution_result', result.model_dump())\n                    if success:\n                        return  # Successfully streamed\n\n                # Connection unhealthy - brief wait before retry\n                await asyncio.sleep(0.2 * (attempt + 1))\n\n            except Exception as e:\n                self.app.print(f\"Stream attempt {attempt + 1} failed: {e}\")\n                if attempt &lt; max_attempts - 1:\n                    await asyncio.sleep(0.2 * (attempt + 1))\n\n        # All attempts failed - but don't crash, just log\n        self.app.print(f\"\u26a0\ufe0f Failed to stream progress after {max_attempts} attempts\")\n\n\n    async def send_ui_progress(self, progress_data: dict[str, Any], retry_count: int = 3):\n        \"\"\"Enhanced UI progress sender with retry logic.\"\"\"\n        if not self.is_connected or not self.ws or not self.ws.open:\n            self.app.print(\"Registry client WebSocket not connected - queuing progress update\")\n            # Could implement a queue here for offline progress updates\n            return False\n\n        for attempt in range(retry_count):\n            try:\n                # Structure progress message for registry server\n                ui_message = {\n                    \"timestamp\": progress_data.get('timestamp', asyncio.get_event_loop().time()),\n                    \"agent_id\": progress_data.get('agent_id', 'unknown'),\n                    \"event_type\": progress_data.get('event_type', 'unknown'),\n                    \"status\": progress_data.get('status', 'processing'),\n                    \"agent_name\": progress_data.get('agent_name', 'Unknown'),\n                    \"node_name\": progress_data.get('node_name', 'Unknown'),\n                    \"session_id\": progress_data.get('session_id'),\n                    \"metadata\": progress_data.get('metadata', {}),\n\n                    # Enhanced progress data for UI panels\n                    \"outline_progress\": progress_data.get('progress_data', {}).get('outline', {}),\n                    \"activity_info\": progress_data.get('progress_data', {}).get('activity', {}),\n                    \"meta_tool_info\": progress_data.get('progress_data', {}).get('meta_tool', {}),\n                    \"system_status\": progress_data.get('progress_data', {}).get('system', {}),\n                    \"graph_info\": progress_data.get('progress_data', {}).get('graph', {}),\n\n                    # UI flags for selective updates\n                    \"ui_flags\": progress_data.get('ui_flags', {}),\n\n                    # Performance metrics\n                    \"performance\": progress_data.get('performance', {}),\n\n                    # Message metadata\n                    \"message_id\": f\"msg_{asyncio.get_event_loop().time()}_{attempt}\",\n                    \"retry_count\": attempt\n                }\n\n                # Send as WsMessage\n                message = WsMessage(event='ui_progress_update', data=ui_message)\n                await self.ws.send(message.model_dump_json())\n\n                # Success - break retry loop\n                self.app.print(\n                    f\"\ud83d\udce4 Sent UI progress: {progress_data.get('event_type')} | {progress_data.get('status')} (attempt {attempt + 1})\")\n                return True\n\n            except Exception as e:\n                self.app.print(f\"Failed to send UI progress (attempt {attempt + 1}/{retry_count}): {e}\")\n                if attempt &lt; retry_count - 1:\n                    await asyncio.sleep(0.5 * (attempt + 1))  # Exponential backoff\n                else:\n                    await self._handle_connection_error()\n                    return False\n\n        return False\n\n    async def send_agent_status(self, agent_id: str, status: str, details: dict[str, Any] = None):\n        \"\"\"Send agent status updates.\"\"\"\n        if not self.is_connected or not self.ws or not self.ws.open:\n            return\n\n        try:\n            status_message = {\n                \"agent_id\": agent_id,\n                \"status\": status,\n                \"details\": details or {},\n                \"timestamp\": asyncio.get_event_loop().time(),\n                \"capabilities\": [\"chat\", \"progress_tracking\", \"outline_visualization\", \"meta_tool_monitoring\"]\n            }\n\n            message = WsMessage(event='agent_status_update', data=status_message)\n            await self.ws.send(message.model_dump_json())\n\n        except Exception as e:\n            self.app.print(f\"Failed to send agent status: {e}\")\n            await self._handle_connection_error()\n\n    async def _send_error(self, request_id: str, error_message: str):\n        \"\"\"Send error message to server.\"\"\"\n        error_payload = ExecutionError(request_id=request_id, error=error_message)\n        await self._send_message('execution_error', error_payload.model_dump())\n\n    async def _check_connection_health(self) -&gt; bool:\n        \"\"\"Check if the WebSocket connection is actually healthy.\"\"\"\n        if not self.ws:\n            return False\n\n        try:\n            # Check basic connection state\n            if self.ws.closed or not self.ws.open:\n                return False\n\n            # Try a quick ping to verify connectivity\n            pong_waiter = await self.ws.ping()\n            await asyncio.wait_for(pong_waiter, timeout=3.0)\n            return True\n\n        except Exception as e:\n            self.app.print(f\"Connection health check failed: {e}\")\n            return False\n\n    async def _send_message(self, event: str, data: dict, max_retries: int = 3):\n        \"\"\"Enhanced message sending with connection health verification.\"\"\"\n        for attempt in range(max_retries):\n            # Check connection health before attempting to send\n            if not await self._check_connection_health():\n                self.app.print(f\"Connection unhealthy for message '{event}' (attempt {attempt + 1})\")\n\n                if attempt &lt; max_retries - 1:\n                    await asyncio.sleep(0.5 * (attempt + 1))\n                    continue\n                else:\n                    self.app.print(f\"Cannot send message '{event}': Connection permanently failed\")\n                    asyncio.create_task(self._trigger_reconnect())\n                    return False\n\n            try:\n                message = WsMessage(event=event, data=data)\n                await self.ws.send(message.model_dump_json())\n                return True\n\n            except Exception as e:\n                self.app.print(f\"Send attempt {attempt + 1} failed for '{event}': {e}\")\n\n                # Check if this is a connection-related error\n                error_str = str(e).lower()\n                if any(err in error_str for err in ['connectionclosed', 'incomplete', 'connection', 'closed']):\n                    self.app.print(\"Connection error detected - triggering reconnect\")\n                    asyncio.create_task(self._trigger_reconnect())\n                    return False\n\n                if attempt &lt; max_retries - 1:\n                    await asyncio.sleep(0.5 * (attempt + 1))\n\n        return False\n    async def _send_final_result_with_retry(self, request_id: str, final_result: Any, agent_id: str, session_id: str):\n        \"\"\"Send final result with robust retry logic.\"\"\"\n        final_event = ProgressEvent(\n            event_type=\"execution_complete\",\n            node_name=\"RegistryClient\",\n            success=True,\n            metadata={\n                \"result\": final_result,\n                \"agent_id\": agent_id,\n                \"session_id\": session_id\n            }\n        )\n\n        final_message = ExecutionResult(\n            request_id=request_id,\n            payload=final_event.to_dict(),\n            is_final=True\n        )\n\n        max_retries = 10\n        base_delay = 2\n\n        for attempt in range(max_retries):\n            try:\n                if not self.is_connected or not self.ws or not self.ws.open:\n                    self.app.print(f\"\u26a0\ufe0f  Connection lost - waiting for reconnection (attempt {attempt + 1})\")\n                    await asyncio.sleep(base_delay * (attempt + 1))\n                    continue\n\n                await self._send_message('execution_result', final_message.model_dump())\n                self.app.print(f\"\u2705 Final result sent successfully on attempt {attempt + 1}\")\n                return\n\n            except Exception as e:\n                delay = base_delay * (2 ** attempt)\n                self.app.print(f\"\u274c Failed to send final result (attempt {attempt + 1}): {e}\")\n                if attempt &lt; max_retries - 1:\n                    await asyncio.sleep(delay)\n\n        self.app.print(f\"\u274c Failed to send final result after {max_retries} attempts\")\n\n    async def _send_error_with_retry(self, request_id: str, error_message: str):\n        \"\"\"Send error message with retry logic.\"\"\"\n        max_retries = 5\n\n        for attempt in range(max_retries):\n            try:\n                if self.is_connected and self.ws and self.ws.open:\n                    await self._send_error(request_id, error_message)\n                    return\n                else:\n                    await asyncio.sleep(2 * (attempt + 1))\n            except Exception as e:\n                self.app.print(f\"Error sending error message (attempt {attempt + 1}): {e}\")\n                if attempt &lt; max_retries - 1:\n                    await asyncio.sleep(2 * (attempt + 1))\n\n    async def _handle_connection_error(self):\n        \"\"\"Handle connection errors and cleanup.\"\"\"\n        self.is_connected = False\n        if self.ws:\n            with contextlib.suppress(builtins.BaseException):\n                await self.ws.close()\n            self.ws = None\n\n    async def disconnect(self):\n        \"\"\"Enhanced disconnect with complete task cleanup.\"\"\"\n        self.app.print(\"Initiating clean shutdown...\")\n        self.is_connected = False\n        self.should_reconnect = False\n\n        # Cancel all background tasks\n        tasks_to_cancel = []\n\n        if self.connection_task and not self.connection_task.done():\n            tasks_to_cancel.append(self.connection_task)\n\n        if self.ping_task and not self.ping_task.done():\n            tasks_to_cancel.append(self.ping_task)\n\n        # Cancel message handler tasks\n        for task in list(self.message_handler_tasks):\n            if not task.done():\n                tasks_to_cancel.append(task)\n\n        # Cancel running executions\n        for task in list(self.running_executions.values()):\n            if not task.done():\n                tasks_to_cancel.append(task)\n\n        if tasks_to_cancel:\n            self.app.print(f\"Cancelling {len(tasks_to_cancel)} background tasks...\")\n            for task in tasks_to_cancel:\n                task.cancel()\n\n            # Wait for cancellation with timeout\n            try:\n                await asyncio.wait_for(\n                    asyncio.gather(*tasks_to_cancel, return_exceptions=True),\n                    timeout=5.0\n                )\n            except asyncio.TimeoutError:\n                self.app.print(\"Warning: Some tasks didn't cancel within timeout\")\n\n        # Close WebSocket connection\n        if self.ws:\n            with contextlib.suppress(Exception):\n                await self.ws.close()\n            self.ws = None\n\n        # Cancel pending registrations\n        for future in self.pending_registrations.values():\n            if not future.done():\n                future.cancel()\n        self.pending_registrations.clear()\n\n        # Clear state\n        self.message_handler_tasks.clear()\n        self.running_executions.clear()\n        self.persistent_callbacks.clear()\n\n        self.connection_task = None\n        self.ping_task = None\n\n        self.app.print(\"\u2705 Registry client shutdown completed\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.client.RegistryClient.cancel_execution","title":"<code>cancel_execution(request_id)</code>  <code>async</code>","text":"<p>Cancel a running execution.</p> Source code in <code>toolboxv2/mods/registry/client.py</code> <pre><code>async def cancel_execution(self, request_id: str) -&gt; bool:\n    \"\"\"Cancel a running execution.\"\"\"\n    try:\n        if request_id not in self.running_executions:\n            self.app.print(f\"\u274c Execution {request_id} not found\")\n            return False\n\n        execution_task = self.running_executions[request_id]\n\n        if execution_task.done():\n            self.app.print(f\"\u26a0\ufe0f  Execution {request_id} already completed\")\n            return True\n\n        # Cancel the task\n        execution_task.cancel()\n\n        try:\n            # Wait a moment for graceful cancellation\n            await asyncio.wait_for(execution_task, timeout=5.0)\n        except asyncio.CancelledError:\n            self.app.print(f\"\u2705 Execution {request_id} cancelled successfully\")\n        except asyncio.TimeoutError:\n            self.app.print(f\"\u26a0\ufe0f  Execution {request_id} cancellation timeout - may still be running\")\n        except Exception as e:\n            self.app.print(f\"\u26a0\ufe0f  Execution {request_id} cancellation resulted in exception: {e}\")\n\n        # Send cancellation notice to server\n        try:\n            if self.is_connected and self.ws and self.ws.open:\n                cancellation_event = ProgressEvent(\n                    event_type=\"execution_cancelled\",\n                    node_name=\"RegistryClient\",\n                    success=False,\n                    metadata={\n                        \"request_id\": request_id,\n                        \"cancellation_reason\": \"client_requested\",\n                        \"timestamp\": asyncio.get_event_loop().time()\n                    }\n                )\n\n                cancellation_message = ExecutionResult(\n                    request_id=request_id,\n                    payload=cancellation_event.to_dict(),\n                    is_final=True\n                )\n\n                await self._send_message('execution_result', cancellation_message.model_dump())\n\n        except Exception as e:\n            self.app.print(f\"Failed to send cancellation notice to server: {e}\")\n\n        # Cleanup\n        self.running_executions.pop(request_id, None)\n\n        return True\n\n    except Exception as e:\n        self.app.print(f\"Error cancelling execution {request_id}: {e}\")\n        return False\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.client.RegistryClient.cleanup_completed_executions","title":"<code>cleanup_completed_executions()</code>  <code>async</code>","text":"<p>Clean up completed execution tasks.</p> Source code in <code>toolboxv2/mods/registry/client.py</code> <pre><code>async def cleanup_completed_executions(self):\n    \"\"\"Clean up completed execution tasks.\"\"\"\n    try:\n        completed_tasks = []\n\n        for request_id, task in self.running_executions.items():\n            if task.done():\n                completed_tasks.append(request_id)\n\n        for request_id in completed_tasks:\n            self.running_executions.pop(request_id, None)\n            self.app.print(f\"\ud83e\uddf9 Cleaned up completed execution: {request_id}\")\n\n        return len(completed_tasks)\n\n    except Exception as e:\n        self.app.print(f\"Error during cleanup: {e}\")\n        return 0\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.client.RegistryClient.connect","title":"<code>connect(server_url, timeout=30.0)</code>  <code>async</code>","text":"<p>Connect and start all background tasks.</p> Source code in <code>toolboxv2/mods/registry/client.py</code> <pre><code>async def connect(self, server_url: str, timeout: float = 30.0):\n    \"\"\"Connect and start all background tasks.\"\"\"\n    if not ws_client:\n        self.app.print(\"Websockets library not installed. Please run 'pip install websockets'\")\n        return False\n\n    if self.ws and self.ws.open:\n        self.app.print(\"Already connected to the registry server.\")\n        return True\n\n    self.server_url = server_url\n    self.should_reconnect = True\n    self.reconnect_in_progress = False\n\n    try:\n        self.app.print(f\"Connecting to Registry Server at {server_url}...\")\n        self.ws = await asyncio.wait_for(\n            ws_client.connect(server_url),\n            timeout=timeout\n        )\n\n        self.is_connected = True\n        self.reconnect_attempts = 0\n\n        # Start all background tasks\n        await self._start_all_background_tasks()\n\n        self.app.print(f\"\u2705 Successfully connected and started all tasks\")\n        return True\n\n    except asyncio.TimeoutError:\n        self.app.print(f\"\u274c Connection timeout after {timeout}s\")\n        return False\n    except Exception as e:\n        self.app.print(f\"\u274c Connection failed: {e}\")\n        return False\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.client.RegistryClient.disconnect","title":"<code>disconnect()</code>  <code>async</code>","text":"<p>Enhanced disconnect with complete task cleanup.</p> Source code in <code>toolboxv2/mods/registry/client.py</code> <pre><code>async def disconnect(self):\n    \"\"\"Enhanced disconnect with complete task cleanup.\"\"\"\n    self.app.print(\"Initiating clean shutdown...\")\n    self.is_connected = False\n    self.should_reconnect = False\n\n    # Cancel all background tasks\n    tasks_to_cancel = []\n\n    if self.connection_task and not self.connection_task.done():\n        tasks_to_cancel.append(self.connection_task)\n\n    if self.ping_task and not self.ping_task.done():\n        tasks_to_cancel.append(self.ping_task)\n\n    # Cancel message handler tasks\n    for task in list(self.message_handler_tasks):\n        if not task.done():\n            tasks_to_cancel.append(task)\n\n    # Cancel running executions\n    for task in list(self.running_executions.values()):\n        if not task.done():\n            tasks_to_cancel.append(task)\n\n    if tasks_to_cancel:\n        self.app.print(f\"Cancelling {len(tasks_to_cancel)} background tasks...\")\n        for task in tasks_to_cancel:\n            task.cancel()\n\n        # Wait for cancellation with timeout\n        try:\n            await asyncio.wait_for(\n                asyncio.gather(*tasks_to_cancel, return_exceptions=True),\n                timeout=5.0\n            )\n        except asyncio.TimeoutError:\n            self.app.print(\"Warning: Some tasks didn't cancel within timeout\")\n\n    # Close WebSocket connection\n    if self.ws:\n        with contextlib.suppress(Exception):\n            await self.ws.close()\n        self.ws = None\n\n    # Cancel pending registrations\n    for future in self.pending_registrations.values():\n        if not future.done():\n            future.cancel()\n    self.pending_registrations.clear()\n\n    # Clear state\n    self.message_handler_tasks.clear()\n    self.running_executions.clear()\n    self.persistent_callbacks.clear()\n\n    self.connection_task = None\n    self.ping_task = None\n\n    self.app.print(\"\u2705 Registry client shutdown completed\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.client.RegistryClient.get_connection_status","title":"<code>get_connection_status()</code>  <code>async</code>","text":"<p>Get detailed connection status information.</p> Source code in <code>toolboxv2/mods/registry/client.py</code> <pre><code>async def get_connection_status(self) -&gt; dict[str, Any]:\n    \"\"\"Get detailed connection status information.\"\"\"\n    try:\n        connection_status = {\n            \"is_connected\": self.is_connected,\n            \"server_url\": self.server_url,\n            \"reconnect_attempts\": self.reconnect_attempts,\n            \"max_reconnect_attempts\": self.max_reconnect_attempts,\n            \"should_reconnect\": self.should_reconnect,\n            \"reconnect_in_progress\": self.reconnect_in_progress,\n            \"websocket_state\": None,\n            \"websocket_open\": False,\n            \"tasks\": {\n                \"connection_task_running\": self.connection_task and not self.connection_task.done(),\n                \"ping_task_running\": self.ping_task and not self.ping_task.done(),\n            },\n            \"registered_agents_count\": len(self.local_agents),\n            \"running_executions_count\": len(self.running_executions),\n            \"pending_registrations_count\": len(self.pending_registrations),\n            \"persistent_callbacks_count\": len(self.persistent_callbacks),\n            \"last_ping_time\": getattr(self, 'last_ping_time', None),\n            \"connection_uptime\": None,\n            \"connection_established_at\": getattr(self, 'connection_established_at', None),\n        }\n\n        # WebSocket specific status\n        if self.ws:\n            connection_status.update({\n                \"websocket_state\": str(self.ws.state.name) if hasattr(self.ws.state, 'name') else str(\n                    self.ws.state),\n                \"websocket_open\": self.ws.open,\n                \"websocket_closed\": self.ws.closed,\n            })\n\n        # Calculate uptime\n        if hasattr(self, 'connection_established_at') and self.connection_established_at:\n            connection_status[\n                \"connection_uptime\"] = asyncio.get_event_loop().time() - self.connection_established_at\n\n        return connection_status\n\n    except Exception as e:\n        self.app.print(f\"Error getting connection status: {e}\")\n        return {\n            \"error\": str(e),\n            \"is_connected\": False,\n            \"server_url\": self.server_url,\n        }\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.client.RegistryClient.get_diagnostics","title":"<code>get_diagnostics()</code>  <code>async</code>","text":"<p>Get comprehensive diagnostic information.</p> Source code in <code>toolboxv2/mods/registry/client.py</code> <pre><code>async def get_diagnostics(self) -&gt; dict[str, Any]:\n    \"\"\"Get comprehensive diagnostic information.\"\"\"\n    try:\n        diagnostics = {\n            \"connection_status\": await self.get_connection_status(),\n            \"registered_agents\": await self.get_registered_agents(),\n            \"running_executions\": await self.get_running_executions(),\n            \"health_status\": await self.health_check(),\n            \"system_info\": {\n                \"python_version\": sys.version,\n                \"asyncio_running\": True,\n                \"event_loop\": str(asyncio.get_running_loop()),\n                \"thread_name\": threading.current_thread().name,\n            },\n            \"performance_metrics\": {\n                \"total_messages_sent\": getattr(self, 'total_messages_sent', 0),\n                \"total_messages_received\": getattr(self, 'total_messages_received', 0),\n                \"total_reconnections\": self.reconnect_attempts,\n                \"total_registrations\": len(self.registered_info),\n                \"memory_usage\": self._get_memory_usage(),\n            },\n            \"error_log\": getattr(self, 'recent_errors', []),\n        }\n\n        return diagnostics\n\n    except Exception as e:\n        return {\n            \"diagnostics_error\": str(e),\n            \"timestamp\": asyncio.get_event_loop().time()\n        }\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.client.RegistryClient.get_registered_agents","title":"<code>get_registered_agents()</code>  <code>async</code>","text":"<p>Get all registered agents information.</p> Source code in <code>toolboxv2/mods/registry/client.py</code> <pre><code>async def get_registered_agents(self) -&gt; dict[str, AgentRegistered]:\n    \"\"\"Get all registered agents information.\"\"\"\n    try:\n        agents_info = {}\n\n        for agent_id, reg_info in self.registered_info.items():\n            # Get agent instance if available\n            agent_instance = self.local_agents.get(agent_id)\n\n            # Create enhanced agent info\n            agent_data = {\n                \"registration_info\": reg_info,\n                \"agent_available\": agent_instance is not None,\n                \"agent_type\": type(agent_instance).__name__ if agent_instance else \"Unknown\",\n                \"has_progress_callback\": hasattr(agent_instance, 'progress_callback') if agent_instance else False,\n                \"supports_progress_callback\": hasattr(agent_instance,\n                                                      'set_progress_callback') if agent_instance else False,\n                \"is_persistent_callback_active\": agent_id in self.persistent_callbacks,\n                \"registration_timestamp\": getattr(reg_info, 'registration_timestamp', None),\n            }\n\n            # Add agent capabilities if available\n            if agent_instance and hasattr(agent_instance, 'get_capabilities'):\n                try:\n                    agent_data[\"capabilities\"] = await agent_instance.get_capabilities()\n                except Exception as e:\n                    agent_data[\"capabilities_error\"] = str(e)\n\n            agents_info[agent_id] = agent_data\n\n        return agents_info\n\n    except Exception as e:\n        self.app.print(f\"Error getting registered agents: {e}\")\n        return {}\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.client.RegistryClient.get_running_executions","title":"<code>get_running_executions()</code>  <code>async</code>","text":"<p>Get information about currently running executions.</p> Source code in <code>toolboxv2/mods/registry/client.py</code> <pre><code>async def get_running_executions(self) -&gt; dict[str, dict[str, Any]]:\n    \"\"\"Get information about currently running executions.\"\"\"\n    try:\n        executions_info = {}\n\n        for request_id, execution_task in self.running_executions.items():\n            execution_info = {\n                \"request_id\": request_id,\n                \"task_done\": execution_task.done(),\n                \"task_cancelled\": execution_task.cancelled(),\n                \"start_time\": getattr(execution_task, 'start_time', None),\n                \"running_time\": None,\n                \"task_exception\": None,\n                \"task_result\": None,\n            }\n\n            # Calculate running time\n            if hasattr(execution_task, 'start_time') and execution_task.start_time:\n                execution_info[\"running_time\"] = asyncio.get_event_loop().time() - execution_task.start_time\n\n            # Get task status details\n            if execution_task.done():\n                try:\n                    if execution_task.exception():\n                        execution_info[\"task_exception\"] = str(execution_task.exception())\n                    else:\n                        execution_info[\"task_result\"] = \"completed_successfully\"\n                except Exception as e:\n                    execution_info[\"task_status_error\"] = str(e)\n\n            executions_info[request_id] = execution_info\n\n        return executions_info\n\n    except Exception as e:\n        self.app.print(f\"Error getting running executions: {e}\")\n        return {}\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.client.RegistryClient.health_check","title":"<code>health_check()</code>  <code>async</code>","text":"<p>Perform a health check of the connection.</p> Source code in <code>toolboxv2/mods/registry/client.py</code> <pre><code>async def health_check(self) -&gt; bool:\n    \"\"\"Perform a health check of the connection.\"\"\"\n    try:\n        # Basic connection checks\n        if not self.is_connected:\n            self.app.print(\"\ud83d\udd0d Health check: Not connected\")\n            return False\n\n        if not self.ws or not self.ws.open:\n            self.app.print(\"\ud83d\udd0d Health check: WebSocket not open\")\n            return False\n\n        # Ping test\n        try:\n            pong_waiter = await self.ws.ping()\n            await asyncio.wait_for(pong_waiter, timeout=10.0)\n\n            # Update last ping time\n            self.last_ping_time = asyncio.get_event_loop().time()\n\n            # Test message sending\n            test_message = WsMessage(\n                event='health_check',\n                data={\n                    \"timestamp\": self.last_ping_time,\n                    \"client_id\": getattr(self, 'client_id', 'unknown'),\n                    \"registered_agents\": list(self.local_agents.keys()),\n                    \"running_executions\": list(self.running_executions.keys())\n                }\n            )\n\n            await self.ws.send(test_message.model_dump_json())\n\n            self.app.print(\"\u2705 Health check: Connection healthy\")\n            return True\n\n        except asyncio.TimeoutError:\n            self.app.print(\"\u274c Health check: Ping timeout\")\n            return False\n        except Exception as ping_error:\n            self.app.print(f\"\u274c Health check: Ping failed - {ping_error}\")\n            return False\n\n    except Exception as e:\n        self.app.print(f\"\u274c Health check: Error - {e}\")\n        return False\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.client.RegistryClient.on","title":"<code>on(event_name, handler)</code>","text":"<p>Register an async callback function to handle a custom event from the server.</p> Source code in <code>toolboxv2/mods/registry/client.py</code> <pre><code>def on(self, event_name: str, handler: Callable[[dict], Awaitable[None]]):\n    \"\"\"Register an async callback function to handle a custom event from the server.\"\"\"\n    self.app.print(f\"Handler for custom event '{event_name}' registered.\")\n    self.custom_event_handlers[event_name] = handler\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.client.RegistryClient.register","title":"<code>register(agent_instance, public_name, description=None)</code>  <code>async</code>","text":"<p>Register an agent with the server.</p> Source code in <code>toolboxv2/mods/registry/client.py</code> <pre><code>async def register(self, agent_instance: Any, public_name: str, description: str | None = None) -&gt; AgentRegistered | None:\n    \"\"\"Register an agent with the server.\"\"\"\n    if not self.is_connected or not self.ws:\n        self.app.print(\"Not connected. Cannot register agent.\")\n        return None\n\n    try:\n        # Create registration request\n        registration = AgentRegistration(public_name=public_name, description=description)\n        message = WsMessage(event='register', data=registration.model_dump())\n\n        # Create future for registration response\n        reg_id = f\"reg_{self.registration_counter}\"\n        self.registration_counter += 1\n        self.pending_registrations[reg_id] = asyncio.Future()\n\n        # Send registration request\n        await self.ws.send(message.model_dump_json())\n        self.app.print(f\"Sent registration request for agent '{public_name}'\")\n\n        # Wait for registration confirmation\n        try:\n            reg_info = await asyncio.wait_for(self.pending_registrations[reg_id], timeout=30.0)\n\n            # Store agent and registration info\n            self.local_agents[reg_info.public_agent_id] = agent_instance\n            self.registered_info[reg_info.public_agent_id] = reg_info\n\n            self.app.print(f\"Agent '{public_name}' registered successfully.\")\n            self.app.print(f\"  Public URL: {reg_info.public_url}\")\n            self.app.print(f\"  API Key: {reg_info.public_api_key}\")\n\n            return reg_info\n\n        except TimeoutError:\n            self.app.print(\"Timeout waiting for registration confirmation.\")\n            return None\n\n    except Exception as e:\n        self.app.print(f\"Error during registration: {e}\")\n        return None\n    finally:\n        # Cleanup pending registration\n        self.pending_registrations.pop(reg_id, None)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.client.RegistryClient.send_agent_status","title":"<code>send_agent_status(agent_id, status, details=None)</code>  <code>async</code>","text":"<p>Send agent status updates.</p> Source code in <code>toolboxv2/mods/registry/client.py</code> <pre><code>async def send_agent_status(self, agent_id: str, status: str, details: dict[str, Any] = None):\n    \"\"\"Send agent status updates.\"\"\"\n    if not self.is_connected or not self.ws or not self.ws.open:\n        return\n\n    try:\n        status_message = {\n            \"agent_id\": agent_id,\n            \"status\": status,\n            \"details\": details or {},\n            \"timestamp\": asyncio.get_event_loop().time(),\n            \"capabilities\": [\"chat\", \"progress_tracking\", \"outline_visualization\", \"meta_tool_monitoring\"]\n        }\n\n        message = WsMessage(event='agent_status_update', data=status_message)\n        await self.ws.send(message.model_dump_json())\n\n    except Exception as e:\n        self.app.print(f\"Failed to send agent status: {e}\")\n        await self._handle_connection_error()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.client.RegistryClient.send_custom_event","title":"<code>send_custom_event(event_name, data)</code>  <code>async</code>","text":"<p>Send a custom event with a JSON payload to the server.</p> Source code in <code>toolboxv2/mods/registry/client.py</code> <pre><code>async def send_custom_event(self, event_name: str, data: dict[str, Any]):\n    \"\"\"Send a custom event with a JSON payload to the server.\"\"\"\n    if not self.is_connected or not self.ws or not self.ws.open:\n        self.app.print(\"Cannot send custom event: Not connected.\")\n        return\n\n    try:\n        message = WsMessage(event=event_name, data=data)\n        await self.ws.send(message.model_dump_json())\n        self.app.print(f\"Sent custom event '{event_name}' to server.\")\n    except Exception as e:\n        self.app.print(f\"Failed to send custom event: {e}\")\n        await self._handle_connection_error()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.client.RegistryClient.send_ui_progress","title":"<code>send_ui_progress(progress_data, retry_count=3)</code>  <code>async</code>","text":"<p>Enhanced UI progress sender with retry logic.</p> Source code in <code>toolboxv2/mods/registry/client.py</code> <pre><code>async def send_ui_progress(self, progress_data: dict[str, Any], retry_count: int = 3):\n    \"\"\"Enhanced UI progress sender with retry logic.\"\"\"\n    if not self.is_connected or not self.ws or not self.ws.open:\n        self.app.print(\"Registry client WebSocket not connected - queuing progress update\")\n        # Could implement a queue here for offline progress updates\n        return False\n\n    for attempt in range(retry_count):\n        try:\n            # Structure progress message for registry server\n            ui_message = {\n                \"timestamp\": progress_data.get('timestamp', asyncio.get_event_loop().time()),\n                \"agent_id\": progress_data.get('agent_id', 'unknown'),\n                \"event_type\": progress_data.get('event_type', 'unknown'),\n                \"status\": progress_data.get('status', 'processing'),\n                \"agent_name\": progress_data.get('agent_name', 'Unknown'),\n                \"node_name\": progress_data.get('node_name', 'Unknown'),\n                \"session_id\": progress_data.get('session_id'),\n                \"metadata\": progress_data.get('metadata', {}),\n\n                # Enhanced progress data for UI panels\n                \"outline_progress\": progress_data.get('progress_data', {}).get('outline', {}),\n                \"activity_info\": progress_data.get('progress_data', {}).get('activity', {}),\n                \"meta_tool_info\": progress_data.get('progress_data', {}).get('meta_tool', {}),\n                \"system_status\": progress_data.get('progress_data', {}).get('system', {}),\n                \"graph_info\": progress_data.get('progress_data', {}).get('graph', {}),\n\n                # UI flags for selective updates\n                \"ui_flags\": progress_data.get('ui_flags', {}),\n\n                # Performance metrics\n                \"performance\": progress_data.get('performance', {}),\n\n                # Message metadata\n                \"message_id\": f\"msg_{asyncio.get_event_loop().time()}_{attempt}\",\n                \"retry_count\": attempt\n            }\n\n            # Send as WsMessage\n            message = WsMessage(event='ui_progress_update', data=ui_message)\n            await self.ws.send(message.model_dump_json())\n\n            # Success - break retry loop\n            self.app.print(\n                f\"\ud83d\udce4 Sent UI progress: {progress_data.get('event_type')} | {progress_data.get('status')} (attempt {attempt + 1})\")\n            return True\n\n        except Exception as e:\n            self.app.print(f\"Failed to send UI progress (attempt {attempt + 1}/{retry_count}): {e}\")\n            if attempt &lt; retry_count - 1:\n                await asyncio.sleep(0.5 * (attempt + 1))  # Exponential backoff\n            else:\n                await self._handle_connection_error()\n                return False\n\n    return False\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.client.get_registry_client","title":"<code>get_registry_client(app)</code>","text":"<p>Factory function to get a singleton RegistryClient instance.</p> Source code in <code>toolboxv2/mods/registry/client.py</code> <pre><code>def get_registry_client(app: App) -&gt; RegistryClient:\n    \"\"\"Factory function to get a singleton RegistryClient instance.\"\"\"\n    app_id = app.id\n    if app_id not in registry_clients:\n        registry_clients[app_id] = RegistryClient(app)\n    return registry_clients[app_id]\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.demo_custom_messaging","title":"<code>demo_custom_messaging</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.registry.demo_custom_messaging.setup_chain_with_live_updates","title":"<code>setup_chain_with_live_updates()</code>  <code>async</code>","text":"<p>Example 3: Create agent chain with live progress broadcasting</p> Source code in <code>toolboxv2/mods/registry/demo_custom_messaging.py</code> <pre><code>async def setup_chain_with_live_updates():\n    \"\"\"Example 3: Create agent chain with live progress broadcasting\"\"\"\n    app = get_app(\"ChainLiveExample\")\n    isaa = app.get_mod(\"isaa\")\n\n    # Initialize ISAA\n    await isaa.init_isaa()\n\n    # Create and register specialized agents\n\n    # Research agent\n    researcher_builder = isaa.get_agent_builder(\"researcher_agent\")\n    researcher_builder.with_system_message(\n        \"You are a research specialist. Gather comprehensive information and provide detailed analysis. \"\n        \"Always report your progress clearly.\"\n    )\n    #researcher_builder.with_models(complex_llm_model=\"openrouter/openai/gpt-4o\")\n    await isaa.register_agent(researcher_builder)\n\n    # Writer agent\n    writer_builder = isaa.get_agent_builder(\"writer_agent\")\n    writer_builder.with_system_message(\n        \"You are a professional writer. Create well-structured, engaging content from research data. \"\n        \"Report your writing progress step by step.\"\n    )\n    #writer_builder.with_models(complex_llm_model=\"openrouter/openai/gpt-4o\")\n    await isaa.register_agent(writer_builder)\n\n    # Reviewer agent\n    reviewer_builder = isaa.get_agent_builder(\"reviewer_agent\")\n    reviewer_builder.with_system_message(\n        \"You are a quality reviewer. Check for accuracy, completeness, and suggest improvements. \"\n        \"Report your review progress clearly.\"\n    )\n    # reviewer_builder.with_models(fast_llm_model=\"openrouter/anthropic/claude-3-haiku\")\n    await isaa.register_agent(reviewer_builder)\n\n    # Get agent instances\n    researcher = await isaa.get_agent(\"researcher_agent\")\n    writer = await isaa.get_agent(\"writer_agent\")\n    reviewer = await isaa.get_agent(\"reviewer_agent\")\n\n    # Create chain using the &gt;&gt; operator for sequential execution\n    from pydantic import BaseModel\n    class Topick(BaseModel):\n        topic: str\n\n    class MiniBlog(BaseModel):\n        title: str\n        content: str\n\n    class Review(BaseModel):\n        feedback: str\n        better_title: str\n        better_content: str\n\n    chain = researcher &gt;&gt; CF(Topick) &gt;&gt; writer &gt;&gt; CF(MiniBlog) &gt;&gt; reviewer &gt;&gt; CF(Review)\n    chain.name = \"content_creation_chain\"\n\n    # Publish chain with live updates - Progress Callback wird automatisch eingerichtet\n    result = await isaa.publish_and_host_agent(\n        agent=chain,\n        public_name=\"Content Creation Pipeline\",\n        description=\"Multi-agent chain with live progress: Research \u2192 Write \u2192 Review\",\n        registry_server=\"ws://localhost:8080/ws/registry/connect\",\n    )\n\n    if result.get('public_url'):\n        app.print(\"\ud83d\udd17 Chain published successfully with Live Progress UI!\")\n        app.print(f\"   Local UI: {result['ui_url']}\")\n        app.print(f\"   WebSocket: {result.get('registry_server')}\")\n        app.print(f\"   WebSocket: {result.get('websocket_url')}\")\n        app.print(f\"   Public URL: {result.get('public_url')}\")\n        app.print(f\"   API Key: {result.get('public_api_key')}\")\n        print(result)\n\n        # Example usage - test the chain with live updates\n        #pp.print(\"\\n\ud83e\uddea Testing chain execution with live progress tracking:\")\n        #ry:\n        #   result_text = await chain.a_run(\n        #       query=\"Create a comprehensive article about renewable energy trends in 2024\",\n        #       session_id=\"demo-session\"\n        #   )\n        #   app.print(f\"\u2705 Chain completed successfully!\")\n        #   app.print(f\"   Result length: {len(result_text)} characters\")\n        #   app.print(\"   All progress was tracked live in the UI!\")\n        #xcept Exception as e:\n        #   app.print(f\"\u274c Chain execution failed: {e}\")\n\n        # Keep services running with live status\n        try:\n            while True:\n                await asyncio.sleep(30)\n                app.print(\"\ud83d\udc93 Chain services live - ready for requests\")\n        except KeyboardInterrupt:\n            app.print(\"Shutting down chain services...\")\n    else:\n        app.print(\"\u274c Failed to publish chain to registry\")\n\n    # Clean shutdown\n    await researcher.close()\n    await writer.close()\n    await reviewer.close()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.demo_custom_messaging.setup_complete_agent_system","title":"<code>setup_complete_agent_system(local=True)</code>  <code>async</code>","text":"<p>Vollst\u00e4ndiges Beispiel f\u00fcr Agent-System mit Live-Progress.</p> Source code in <code>toolboxv2/mods/registry/demo_custom_messaging.py</code> <pre><code>async def setup_complete_agent_system(local=True):\n    \"\"\"Vollst\u00e4ndiges Beispiel f\u00fcr Agent-System mit Live-Progress.\"\"\"\n\n    app = get_app(\"CompleteAgentSystem\")\n    isaa = app.get_mod(\"isaa\")\n\n    # ISAA initialisieren\n    await isaa.init_isaa()\n\n    # Erweiterten Agent erstellen\n    advanced_builder = isaa.get_agent_builder(\"production_assistant\")\n    advanced_builder.with_system_message(\"\"\"\n        Du bist ein produktions-fertiger AI-Assistent mit detailliertem Progress-Tracking.\n\n        Arbeitsweise:\n        1. Analysiere die Anfrage sorgf\u00e4ltig\n        2. Erstelle einen strukturierten Plan (Outline)\n        3. F\u00fchre jeden Schritt methodisch aus\n        4. Verwende Meta-Tools f\u00fcr komplexe Aufgaben\n        5. Berichte kontinuierlich \u00fcber deinen Fortschritt\n        6. Liefere umfassende, gut strukturierte Antworten\n\n        Zeige immer, welche Tools du verwendest und warum.\n        Erkl\u00e4re deine Reasoning-Loops transparent.\n        \"\"\")\n\n    # Agent registrieren\n    await isaa.register_agent(advanced_builder)\n    agent = await isaa.get_agent(\"production_assistant\")\n\n    # **Produktionsfertige Publish &amp; Host - Ein Aufruf macht alles**\n    result = await isaa.publish_and_host_agent(\n        agent=agent,\n        public_name=\"Production AI Assistant\",\n        registry_server=\"ws://localhost:8080/ws/registry/connect\" if local else \"wss://simplecore.app/ws/registry/connect\",\n        description=\"Production-ready AI assistant with comprehensive progress tracking, step-by-step reasoning, and meta-tool visualization. Supports real-time progress updates, outline tracking, and multi-user access.\",\n        access_level=\"public\"\n    )\n\n    if result.get('success'):\n        app.print(\"\ud83c\udf89 AGENT SYSTEM FULLY DEPLOYED!\")\n        app.print(\"\")\n        app.print(\"\ud83c\udf10 Public Access:\")\n        app.print(f\"   URL: {result['public_url']}\")\n        app.print(f\"   API Key: {result['public_api_key']}\")\n        app.print(\"\")\n        app.print(\"\ud83d\udda5\ufe0f  Live UI:\")\n        app.print(f\"   Registry UI: {result['ui_url']}\")\n        if result.get('local_ui'):\n            app.print(f\"   Local UI: {result['local_ui'].get('ui_url')}\")\n        app.print(\"\")\n        app.print(\"\ud83d\udd0c WebSocket:\")\n        app.print(f\"   Live Updates: {result['websocket_url']}\")\n        app.print(\"\")\n        app.print(\"\ud83d\udccb cURL Test:\")\n        app.print(f\"\"\"curl -X POST {result['public_url']} \\\\\n  -H \"Content-Type: application/json\" \\\\\n  -H \"Authorization: Bearer {result['public_api_key']}\" \\\\\n  -d '{{\"query\": \"Create a detailed analysis of quantum computing with step-by-step progress\", \"session_id\": \"test-session\"}}'\"\"\")\n\n        # Lokaler Test des Agents\n        app.print(\"\\n\ud83e\uddea Testing agent locally...\")\n        #await asyncio.sleep(5)\n        #test_result = await agent.a_run(\n        #    \"hey\",\n        #    session_id=\"local_test\"\n        #)\n        app.print(\"\u2705 Test completed successfully!\")\n\n        # Service am Leben halten\n        try:\n            while True:\n                await asyncio.sleep(30)\n                app.print(\"\ud83d\udc93 Agent services running - ready for requests\")\n        except KeyboardInterrupt:\n            app.print(\"\ud83d\uded1 Shutting down agent services...\")\n    else:\n        app.print(f\"\u274c Deployment failed: {result.get('error')}\")\n        print(result)\n\n    await agent.close()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.demo_custom_messaging.setup_multiple_live_agents","title":"<code>setup_multiple_live_agents()</code>  <code>async</code>","text":"<p>Example 4: Host multiple agents with individual live UIs</p> Source code in <code>toolboxv2/mods/registry/demo_custom_messaging.py</code> <pre><code>async def setup_multiple_live_agents():\n    \"\"\"Example 4: Host multiple agents with individual live UIs\"\"\"\n    app = get_app(\"MultiAgentLiveExample\")\n    isaa = app.get_mod(\"isaa\")\n\n    # Initialize ISAA\n    await isaa.init_isaa()\n\n    # Create different specialized agents\n    agents_config = [\n        {\n            \"name\": \"math_tutor\",\n            \"system\": \"You are a mathematics tutor. Explain concepts step-by-step with live progress updates.\",\n            \"public_name\": \"Live Math Tutor\",\n            \"port\": 8770\n        },\n        {\n            \"name\": \"code_helper\",\n            \"system\": \"You are a coding assistant. Help debug and explain code with detailed progress tracking.\",\n            \"public_name\": \"Live Code Assistant\",\n            \"port\": 8771\n        },\n        {\n            \"name\": \"creative_writer\",\n            \"system\": \"You are a creative writer. Generate stories and content with live creative process updates.\",\n            \"public_name\": \"Live Creative Writer\",\n            \"port\": 8772\n        }\n    ]\n\n    hosted_agents = []\n\n    # Create and host each agent\n    for config in agents_config:\n        # Create agent builder\n        builder = isaa.get_agent_builder(config[\"name\"])\n        builder.with_system_message(config[\"system\"])\n        # builder.with_models(complex_llm_model=\"openrouter/openai/gpt-4o\")\n\n        # Register agent\n        await isaa.register_agent(builder)\n\n        # Get agent instance\n        agent = await isaa.get_agent(config[\"name\"])\n\n        # Host with live UI - Progress wird automatisch eingerichtet\n        result = await isaa.publish_and_host_agent(\n            agent=agent,\n            public_name=config[\"public_name\"],\n            description=f\"Specialized agent: {config['public_name']} with live progress updates\",\n        )\n\n        hosted_agents.append({\n            'name': config[\"name\"],\n            'agent': agent,\n            'result': result\n        })\n\n        app.print(f\"\ud83d\ude80 {config['public_name']} live at: {result['ui_url']}\")\n\n    # Test all agents with live progress\n    app.print(\"\\n\ud83e\uddea Testing all agents with live progress:\")\n\n    test_queries = [\n        (\"math_tutor\", \"Explain how to solve quadratic equations step by step\"),\n        (\"code_helper\", \"Debug this Python function and explain the process\"),\n        (\"creative_writer\", \"Write a short story about AI and humans working together\")\n    ]\n\n    for agent_name, query in test_queries:\n        agent_info = next(a for a in hosted_agents if a['name'] == agent_name)\n        app.print(f\"Testing {agent_name} - watch live progress in UI...\")\n\n        try:\n            result = await agent_info['agent'].a_run(query, session_id=f\"test_{agent_name}\")\n            app.print(f\"\u2705 {agent_name} completed - live progress was shown!\")\n        except Exception as e:\n            app.print(f\"\u274c {agent_name} failed: {e}\")\n\n    # Keep all agents running\n    try:\n        while True:\n            await asyncio.sleep(60)\n            app.print(\"\ud83d\udc93 All agents live and ready\")\n            for agent_info in hosted_agents:\n                app.print(f\"   \u2022 {agent_info['name']}: {agent_info['result']['ui_url']}\")\n    except KeyboardInterrupt:\n        app.print(\"Shutting down all live agents...\")\n        for agent_info in hosted_agents:\n            await agent_info['agent'].close()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.demo_registry","title":"<code>demo_registry</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.registry.demo_registry.run_end_user_test","title":"<code>run_end_user_test()</code>  <code>async</code>","text":"<p>Simuliert einen externen Aufruf an die \u00f6ffentliche API des Registry Servers.</p> Source code in <code>toolboxv2/mods/registry/demo_registry.py</code> <pre><code>async def run_end_user_test():\n    \"\"\"Simuliert einen externen Aufruf an die \u00f6ffentliche API des Registry Servers.\"\"\"\n    print(\"--- [USER] Warte darauf, dass der Agent publiziert wird... ---\")\n    await published_event.wait()\n    print(\"--- [USER] Agent ist jetzt \u00f6ffentlich. Starte Testaufruf in 3 Sekunden... ---\")\n    await asyncio.sleep(3)\n\n    public_url = published_info.get(\"public_url\")\n    api_key = published_info.get(\"public_api_key\")\n\n    if not public_url or not api_key:\n        print(\"--- [USER] FEHLER: Keine \u00f6ffentlichen Agenten-Infos gefunden!\", file=sys.stderr)\n        return\n\n    print(f\"--- [USER] Sende POST-Anfrage an: {public_url} ---\")\n\n    request_payload = {\n        \"query\": \"Hallo, weitergeleitete Welt!\",\n        \"session_id\": \"ext-user-session-001\"\n    }\n\n    headers = {\n        \"Authorization\": f\"Bearer {api_key}\",\n        \"Content-Type\": \"application/json\"\n    }\n\n    async with aiohttp.ClientSession() as session:\n        try:\n            async with session.post(public_url, json=request_payload, headers=headers) as response:\n                print(f\"--- [USER] Antwort-Status: {response.status} ---\")\n\n                if response.status == 200:\n                    print(\"--- [USER] Beginne mit dem Streamen der Antwort-Events: ---\")\n                    # Die Antwort ist application/json-seq, also lesen wir zeilenweise\n                    async for line in response.content:\n                        if line:\n                            try:\n                                data = json.loads(line)\n                                event_type = data.get('event_type', 'unknown')\n                                status = data.get('status', '...')\n                                print(f\"  [STREAM] Event: {event_type:&lt;20} | Status: {status} {data}\")\n\n                                # Der finale Event enth\u00e4lt das Ergebnis\n                                if event_type == \"final_result\":\n                                    final_result = data.get('details', {}).get('result')\n                                    print(\"\\n--- [USER] Endg\u00fcltiges Ergebnis erhalten: ---\")\n                                    print(f\"  &gt;&gt;&gt; {final_result}\")\n\n                            except json.JSONDecodeError:\n                                print(f\"  [STREAM] Konnte Zeile nicht als JSON parsen: {line.decode()}\")\n                else:\n                    error_text = await response.text()\n                    print(f\"--- [USER] FEHLER vom Server: {error_text}\", file=sys.stderr)\n        except aiohttp.ClientConnectorError as e:\n            print(f\"--- [USER] VERBINDUNGSFEHLER: Konnte den Server nicht erreichen. L\u00e4uft er? Fehler: {e}\",\n                  file=sys.stderr)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.demo_registry.run_local_client","title":"<code>run_local_client()</code>  <code>async</code>","text":"<p>Startet die zweite toolboxv2-Instanz als lokalen Client, der einen Agenten hostet.</p> Source code in <code>toolboxv2/mods/registry/demo_registry.py</code> <pre><code>async def run_local_client():\n    \"\"\"Startet die zweite toolboxv2-Instanz als lokalen Client, der einen Agenten hostet.\"\"\"\n    print(\"--- [CLIENT] Initialisiere lokale Client Instanz ---\")\n    client_app = get_app(\"LocalClientInstance\")\n\n    # ISAA-Modul f\u00fcr diese Instanz holen und initialisieren\n    isaa: ISAA_Tools = client_app.get_mod(\"isaa\")\n    await isaa.init_isaa()\n    print(\"--- [CLIENT] ISAA initialisiert. ---\")\n\n    # --- Agenten erstellen ---\n    print(\"--- [CLIENT] Erstelle einen einfachen 'EchoAgent'... ---\")\n    builder = isaa.get_agent_builder(\"EchoAgent\")\n    builder.with_system_message(\"You are an echo agent. Repeat the user's query exactly, but prefix it with 'Echo: '.\")\n    await isaa.register_agent(builder)\n\n    # Agenten-Instanz holen (dieser Schritt ist nicht zwingend f\u00fcr das Publizieren per Name, aber gut zur Demo)\n    echo_agent = await isaa.get_agent(\"EchoAgent\")\n    print(f\"--- [CLIENT] 'EchoAgent' ({type(echo_agent).__name__}) erstellt. ---\")\n\n    # --- Agenten publizieren ---\n    # Warten, bis der Server sicher l\u00e4uft\n    await asyncio.sleep(2)\n\n    server_ws_url = \"ws://127.0.0.1:8080/ws/registry/connect\"\n    print(f\"--- [CLIENT] Publiziert 'EchoAgent' am Server: {server_ws_url} ---\")\n\n    # Die neue `publish_agent` Methode aufrufen\n    reg_info = await isaa.host_agent_ui(\n        agent=echo_agent,\n        public_name=\"Public Echo Service\",\n        server_url=server_ws_url,\n        description=\"A simple agent that echoes your input.\"\n    )\n\n    if reg_info:\n        print(\"--- [CLIENT] Agent erfolgreich publiziert! Details erhalten: ---\")\n        print(f\"  &gt; Public URL: {reg_info.public_url}\")\n        print(f\"  &gt; API Key: {reg_info.public_api_key}\")\n\n        # Speichere die Info und signalisiere dem Endbenutzer-Task, dass er starten kann\n        published_info.update(reg_info.model_dump())\n        published_event.set()\n    else:\n        print(\"--- [CLIENT] FEHLER: Agenten-Publizierung fehlgeschlagen. ---\", file=sys.stderr)\n\n    # H\u00e4lt diesen Task am Leben, um auf Weiterleitungsanfragen zu lauschen.\n    await asyncio.Future()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.demo_registry.run_registry_server","title":"<code>run_registry_server()</code>  <code>async</code>","text":"<p>Startet die erste toolboxv2-Instanz als unseren \u00f6ffentlichen Server.</p> Source code in <code>toolboxv2/mods/registry/demo_registry.py</code> <pre><code>async def run_registry_server():\n    \"\"\"Startet die erste toolboxv2-Instanz als unseren \u00f6ffentlichen Server.\"\"\"\n    print(\"--- [SERVER] Initialisiere Registry Server Instanz ---\")\n\n    # Holt sich eine App-Instanz. Das Laden des 'registry'-Moduls geschieht\n    # automatisch durch die __init__.py-Struktur von toolboxv2.\n    server_app = get_app(\"RegistryServerInstance\")\n\n    # Startet den actix-web Server auf Port 8080.\n    # `blocking=False` ist entscheidend, damit asyncio weiterlaufen kann.\n    server_app.start_server()\n\n    print(\"--- [SERVER] Registry Server l\u00e4uft auf http://127.0.0.1:8080 ---\")\n    print(\"--- [SERVER] Wartet auf eingehende Client-Verbindungen... ---\")\n\n    # H\u00e4lt diesen Task am Leben, um den Server laufen zu lassen.\n    await asyncio.Future()\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.server","title":"<code>server</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.registry.server.broadcast_to_ui_clients","title":"<code>broadcast_to_ui_clients(app, data)</code>  <code>async</code>","text":"<p>Broadcast updates to all connected UI clients.</p> Source code in <code>toolboxv2/mods/registry/server.py</code> <pre><code>async def broadcast_to_ui_clients(app: App, data: dict[str, Any]):\n    \"\"\"Broadcast updates to all connected UI clients.\"\"\"\n    if not STATE.ui_clients:\n        app.print(\"No active UI clients to broadcast to\")\n        return\n\n    app.print(f\"Broadcasting to {len(STATE.ui_clients)} UI clients: {data.get('event', 'unknown')}\")\n\n    dead_clients = set()\n    successful_broadcasts = 0\n\n    for ui_conn_id in STATE.ui_clients.copy():\n        try:\n            await app.ws_send(ui_conn_id, data)\n            successful_broadcasts += 1\n        except Exception as e:\n            app.print(f\"Failed to broadcast to UI client {ui_conn_id}: {e}\")\n            dead_clients.add(ui_conn_id)\n\n    # Clean up dead connections\n    for dead_client in dead_clients:\n        STATE.ui_clients.discard(dead_client)\n\n    app.print(f\"Broadcast completed: {successful_broadcasts} successful, {len(dead_clients)} failed\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.server.handle_agent_status_update","title":"<code>handle_agent_status_update(app, message)</code>  <code>async</code>","text":"<p>Handle agent status updates.</p> Source code in <code>toolboxv2/mods/registry/server.py</code> <pre><code>async def handle_agent_status_update(app: App, message: WsMessage):\n    \"\"\"Handle agent status updates.\"\"\"\n    try:\n        status_data = message.data\n        await broadcast_to_ui_clients(app, {\n            'event': 'agent_status_update',\n            'data': status_data\n        })\n\n    except Exception as e:\n        app.print(f\"Agent status update error: {e}\", error=True)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.server.handle_execution_error","title":"<code>handle_execution_error(app, message)</code>  <code>async</code>","text":"<p>Handle execution errors.</p> Source code in <code>toolboxv2/mods/registry/server.py</code> <pre><code>async def handle_execution_error(app: App, message: WsMessage):\n    \"\"\"Handle execution errors.\"\"\"\n    try:\n        error = ExecutionError.model_validate(message.data)\n\n        if error.request_id in STATE.pending_requests:\n            await STATE.pending_requests[error.request_id].put(error)\n\n        await broadcast_to_ui_clients(app, {\n            'event': 'execution_error',\n            'data': {\n                'request_id': error.request_id,\n                'error': error.error,\n                'timestamp': asyncio.get_event_loop().time()\n            }\n        })\n\n    except Exception as e:\n        app.print(f\"Execution error handling error: {e}\", error=True)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.server.handle_execution_result","title":"<code>handle_execution_result(app, message)</code>  <code>async</code>","text":"<p>Handle execution results.</p> Source code in <code>toolboxv2/mods/registry/server.py</code> <pre><code>async def handle_execution_result(app: App, message: WsMessage):\n    \"\"\"Handle execution results.\"\"\"\n    try:\n        result = ExecutionResult.model_validate(message.data)\n\n        if result.request_id in STATE.pending_requests:\n            await STATE.pending_requests[result.request_id].put(result)\n\n        # Broadcast to UI clients\n        await broadcast_to_ui_clients(app, {\n            'event': 'execution_progress',\n            'data': {\n                'request_id': result.request_id,\n                'payload': result.payload,\n                'is_final': result.is_final,\n                'timestamp': asyncio.get_event_loop().time()\n            }\n        })\n\n    except Exception as e:\n        app.print(f\"Execution result error: {e}\", error=True)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.server.handle_registration","title":"<code>handle_registration(app, conn_id, session, message)</code>  <code>async</code>","text":"<p>Handle agent registration.</p> Source code in <code>toolboxv2/mods/registry/server.py</code> <pre><code>async def handle_registration(app: App, conn_id: str, session: dict, message: WsMessage):\n    \"\"\"Handle agent registration.\"\"\"\n    try:\n        reg_data = AgentRegistration.model_validate(message.data)\n        agent_id = f\"agent_{secrets.token_urlsafe(16)}\"\n        api_key = f\"tbk_{secrets.token_urlsafe(32)}\"\n\n        STATE.client_agents.setdefault(conn_id, []).append(agent_id)\n        STATE.agent_to_client[agent_id] = conn_id\n        STATE.key_to_agent[api_key] = agent_id\n        STATE.agent_details[agent_id] = reg_data.model_dump()\n\n        base_url = os.getenv(\"APP_BASE_URL\", \"http://localhost:8080\") or session.get('host', 'localhost:8080')\n        if base_url == \"localhost\":\n            base_url = \"localhost:8080\"\n            app.print(\"APP_BASE_URL is localhost. Using default port 8080.\")\n        public_url = f\"{base_url}/api/registry/run?public_agent_id={agent_id}\"\n\n        if not public_url.startswith('http'):\n            public_url = f\"http://{public_url}\"\n\n        response = AgentRegistered(\n            public_name=reg_data.public_name,\n            public_agent_id=agent_id,\n            public_api_key=api_key,\n            public_url=public_url,\n        )\n\n        # Send registration confirmation\n        response_message = WsMessage(event='agent_registered', data=response.model_dump())\n        await app.ws_send(conn_id, response_message.model_dump())\n\n        # Notify UI clients\n        await broadcast_to_ui_clients(app, {\n            \"event\": \"agent_registered\",\n            \"data\": {\n                \"public_agent_id\": agent_id,\n                \"public_name\": reg_data.public_name,\n                \"description\": reg_data.description,\n                \"status\": \"online\"\n            }\n        })\n\n        app.print(f\"Agent '{reg_data.public_name}' registered with ID: {agent_id}\")\n\n    except Exception as e:\n        app.print(f\"Registration error: {e}\", error=True)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.server.handle_ui_progress_update","title":"<code>handle_ui_progress_update(app, message)</code>  <code>async</code>","text":"<p>Handle UI progress updates.</p> Source code in <code>toolboxv2/mods/registry/server.py</code> <pre><code>async def handle_ui_progress_update(app: App, message: WsMessage):\n    \"\"\"Handle UI progress updates.\"\"\"\n    try:\n        progress_data = message.data\n        agent_id = progress_data.get('agent_id', 'unknown')\n\n        # Store recent progress\n        if agent_id not in STATE.recent_progress:\n            STATE.recent_progress[agent_id] = []\n        STATE.recent_progress[agent_id].append(progress_data)\n\n        # Keep only last 50 events\n        STATE.recent_progress[agent_id] = STATE.recent_progress[agent_id][-50:]\n\n        # Broadcast to UI clients\n        await broadcast_to_ui_clients(app, {\n            \"event\": \"live_progress_update\",\n            \"data\": progress_data\n        })\n\n    except Exception as e:\n        app.print(f\"UI progress update error: {e}\", error=True)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.server.on_disconnect","title":"<code>on_disconnect(app, conn_id, session=None)</code>  <code>async</code>","text":"<p>Enhanced disconnect handler with comprehensive cleanup and UI notifications.</p> Source code in <code>toolboxv2/mods/registry/server.py</code> <pre><code>async def on_disconnect(app: App, conn_id: str, session: dict = None):\n    \"\"\"Enhanced disconnect handler with comprehensive cleanup and UI notifications.\"\"\"\n    app.print(f\"Registry client disconnected: {conn_id}\")\n\n    # Check if this is a UI client\n    if conn_id in STATE.ui_clients:\n        STATE.ui_clients.discard(conn_id)\n        app.print(f\"UI client {conn_id} removed from active clients\")\n        return\n\n    # Handle agent client disconnection\n    if conn_id in STATE.client_agents:\n        agent_ids_to_cleanup = STATE.client_agents[conn_id].copy()\n\n        for agent_id in agent_ids_to_cleanup:\n            try:\n                # Get agent details before removal for notification\n                agent_details = STATE.agent_details.get(agent_id, {})\n                agent_name = agent_details.get('public_name', 'Unknown')\n\n                # Remove from all state dictionaries\n                STATE.agent_to_client.pop(agent_id, None)\n                STATE.agent_details.pop(agent_id, None)\n\n                # Remove API key mapping\n                key_to_remove = next((k for k, v in STATE.key_to_agent.items() if v == agent_id), None)\n                if key_to_remove:\n                    STATE.key_to_agent.pop(key_to_remove, None)\n\n                # Clean up progress data\n                STATE.recent_progress.pop(agent_id, None)\n\n                # Clean up any pending requests for this agent by checking if queue exists and clearing it\n                requests_to_cleanup = []\n                for req_id in list(STATE.pending_requests.keys()):\n                    try:\n                        # Put error in queue to unblock any waiting requests\n                        error_result = ExecutionError(\n                            request_id=req_id,\n                            error=\"Agent disconnected unexpectedly\",\n                            public_agent_id=agent_id\n                        )\n                        await STATE.pending_requests[req_id].put(error_result)\n                        requests_to_cleanup.append(req_id)\n                    except Exception as e:\n                        app.print(f\"Error cleaning up pending request {req_id}: {e}\")\n\n                # Remove cleaned up requests\n                for req_id in requests_to_cleanup:\n                    STATE.pending_requests.pop(req_id, None)\n\n                # Notify UI clients about agent going offline (non-blocking)\n                if agent_details:\n                    asyncio.create_task(broadcast_to_ui_clients(app, {\n                        \"event\": \"agent_offline\",\n                        \"data\": {\n                            \"public_agent_id\": agent_id,\n                            \"public_name\": agent_name,\n                            \"status\": \"offline\",\n                            \"timestamp\": asyncio.get_event_loop().time()\n                        }\n                    }))\n\n                app.print(f\"Agent '{agent_name}' (ID: {agent_id}) unregistered and cleaned up\")\n\n            except Exception as e:\n                app.print(f\"Error during agent cleanup for {agent_id}: {e}\", error=True)\n\n        # Remove the client connection entry\n        STATE.client_agents.pop(conn_id, None)\n\n        app.print(f\"Client {conn_id} fully disconnected and cleaned up ({len(agent_ids_to_cleanup)} agents removed)\")\n    else:\n        app.print(f\"Unknown client {conn_id} disconnected (no agents to clean up)\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.server.on_message","title":"<code>on_message(app, conn_id, session, payload)</code>  <code>async</code>","text":"<p>Enhanced message handler with proper error handling.</p> Source code in <code>toolboxv2/mods/registry/server.py</code> <pre><code>async def on_message(app: App, conn_id: str, session: dict, payload: dict):\n    \"\"\"Enhanced message handler with proper error handling.\"\"\"\n    try:\n        # Ensure payload is a dict\n        if isinstance(payload, str):\n            payload = json.loads(payload)\n\n        message = WsMessage.model_validate(payload)\n        app.print(f\"Registry received event: {message.event} from {conn_id}\")\n\n        if message.event == 'register':\n            await handle_registration(app, conn_id, session, message)\n\n        elif message.event == 'ui_progress_update':\n            await handle_ui_progress_update(app, message)\n\n        elif message.event == 'execution_result':\n            await handle_execution_result(app, message)\n\n        elif message.event == 'execution_error':\n            await handle_execution_error(app, message)\n\n        elif message.event == 'agent_status_update':\n            await handle_agent_status_update(app, message)\n\n        else:\n            app.print(f\"Unhandled event '{message.event}' from client {conn_id}\")\n\n    except Exception as e:\n        app.print(f\"Error processing WebSocket message: {e}\", error=True)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.server.register_ui_ws_handlers","title":"<code>register_ui_ws_handlers(app)</code>","text":"<p>Register UI-specific WebSocket handlers.</p> Source code in <code>toolboxv2/mods/registry/server.py</code> <pre><code>@export(mod_name=Name, websocket_handler=\"ui_connect\")\ndef register_ui_ws_handlers(app: App):\n    \"\"\"Register UI-specific WebSocket handlers.\"\"\"\n    return {\n        \"on_connect\": ui_on_connect,\n        \"on_message\": ui_on_message,\n        \"on_disconnect\": ui_on_disconnect,\n    }\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.server.register_ws_handlers","title":"<code>register_ws_handlers(app)</code>","text":"<p>Register WebSocket handlers for the registry.</p> Source code in <code>toolboxv2/mods/registry/server.py</code> <pre><code>@export(mod_name=Name, websocket_handler=\"connect\")\ndef register_ws_handlers(app: App):\n    \"\"\"Register WebSocket handlers for the registry.\"\"\"\n    return {\n        \"on_connect\": on_connect,\n        \"on_message\": on_message,\n        \"on_disconnect\": on_disconnect,\n    }\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.server.run","title":"<code>run(app, public_agent_id, request)</code>  <code>async</code>","text":"<p>Public API endpoint to run agents.</p> Source code in <code>toolboxv2/mods/registry/server.py</code> <pre><code>@export(mod_name=Name, api=True, version=\"1\", request_as_kwarg=True, api_methods=['POST'])\nasync def run(app: App, public_agent_id: str, request: RequestData):\n    \"\"\"Public API endpoint to run agents.\"\"\"\n    if request is None:\n        return Result.default_user_error(info=\"Failed to run agent: No request provided.\")\n    if not request.headers:\n        return Result.default_user_error(info=\"Failed to run agent: No request headers provided.\")\n\n    auth_header = request.headers.authorization or request.headers.to_dict().get('authorization')\n\n    if not auth_header or not auth_header.startswith('Bearer '):\n        return Result.default_user_error(\"Authorization header missing or invalid.\", exec_code=401)\n\n    api_key = auth_header.split(' ')[1]\n\n    if STATE.key_to_agent.get(api_key) != public_agent_id:\n        return Result.default_user_error(\"Invalid API Key or Agent ID.\", exec_code=403)\n\n    conn_id = STATE.agent_to_client.get(public_agent_id)\n    if not conn_id:\n        return Result.default_internal_error(\"Agent is not currently connected/online.\", exec_code=503)\n\n    body = request.body\n    request_id = f\"req_{secrets.token_urlsafe(16)}\"\n\n    run_request = RunRequest(\n        request_id=request_id,\n        public_agent_id=public_agent_id,\n        query=body.get('query', ''),\n        session_id=body.get('session_id'),\n        kwargs=body.get('kwargs', {})\n    )\n\n    response_queue = asyncio.Queue()\n    STATE.pending_requests[request_id] = response_queue\n\n    # Send run request to the client\n    await app.ws_send(conn_id, WsMessage(event='run_request', data=run_request.model_dump()).model_dump())\n\n    try:\n        final_result = None\n        while True:\n            item = await asyncio.wait_for(response_queue.get(), timeout=120.0)\n\n            if isinstance(item, ExecutionError):\n                return Result.default_internal_error(\n                    info=f\"An error occurred during agent execution: {item.error}\",\n                    exec_code=500\n                )\n\n            if item.is_final:\n                final_result = item.payload.get(\"details\", {}).get(\"result\")\n                break\n\n        return Result.json(data={\"result\": final_result})\n\n    except TimeoutError:\n        return Result.default_internal_error(\n            info=\"The request timed out as the agent did not respond in time.\",\n            exec_code=504\n        )\n    finally:\n        STATE.pending_requests.pop(request_id, None)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.server.ui","title":"<code>ui(app, public_agent_id=None)</code>  <code>async</code>","text":"<p>Serve the interactive 3-panel agent UI.</p> Source code in <code>toolboxv2/mods/registry/server.py</code> <pre><code>@export(mod_name=Name, api=True, version=\"1\", api_methods=['GET'])\nasync def ui(app: App, public_agent_id: str = None):\n    \"\"\"Serve the interactive 3-panel agent UI.\"\"\"\n    from ..isaa.ui import get_agent_ui_html\n    html_content = get_agent_ui_html()\n    return Result.html(data=html_content, row=True)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.server.ui_on_connect","title":"<code>ui_on_connect(app, conn_id, session)</code>  <code>async</code>","text":"<p>UI Client connection.</p> Source code in <code>toolboxv2/mods/registry/server.py</code> <pre><code>async def ui_on_connect(app: App, conn_id: str, session: dict):\n    \"\"\"UI Client connection.\"\"\"\n    app.print(f\"UI Client connecting: {conn_id}\")\n    STATE.ui_clients.add(conn_id)\n    app.print(f\"UI Client connected: {conn_id} (Total: {len(STATE.ui_clients)})\")\n\n    # Send current agents list\n    available_agents = []\n    for agent_id, details in STATE.agent_details.items():\n        if agent_id in STATE.agent_to_client:\n            available_agents.append({\n                \"public_agent_id\": agent_id,\n                \"public_name\": details.get('public_name', 'Unknown'),\n                \"description\": details.get('description', ''),\n                \"status\": \"online\"\n            })\n\n    await app.ws_send(conn_id, {\n        \"event\": \"agents_list\",\n        \"data\": {\"agents\": available_agents}\n    })\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.server.ui_on_disconnect","title":"<code>ui_on_disconnect(app, conn_id, session=None)</code>  <code>async</code>","text":"<p>UI Client Disconnection.</p> Source code in <code>toolboxv2/mods/registry/server.py</code> <pre><code>async def ui_on_disconnect(app: App, conn_id: str, session: dict = None):\n    \"\"\"UI Client Disconnection.\"\"\"\n    app.print(f\"UI Client disconnected: {conn_id}\")\n    STATE.ui_clients.discard(conn_id)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.server.ui_on_message","title":"<code>ui_on_message(app, conn_id, session, payload)</code>  <code>async</code>","text":"<p>UI Client Message Handler.</p> Source code in <code>toolboxv2/mods/registry/server.py</code> <pre><code>async def ui_on_message(app: App, conn_id: str, session: dict, payload: dict):\n    \"\"\"UI Client Message Handler.\"\"\"\n    try:\n        # Ensure payload is a dict\n        if isinstance(payload, str):\n            payload = json.loads(payload)\n\n        event = payload.get('event')\n        data = payload.get('data', {})\n\n        if event == 'subscribe_agent':\n            agent_id = data.get('public_agent_id')\n            if agent_id in STATE.agent_details:\n                if agent_id in STATE.recent_progress:\n                    for progress_event in STATE.recent_progress[agent_id][-10:]:\n                        await app.ws_send(conn_id, {\n                            \"event\": \"historical_progress\",\n                            \"data\": progress_event\n                        })\n\n                await app.ws_send(conn_id, {\n                    \"event\": \"subscription_confirmed\",\n                    \"data\": {\"public_agent_id\": agent_id}\n                })\n\n        elif event == 'chat_message':\n            agent_id = data.get('public_agent_id')\n            message_text = data.get('message')\n            session_id = data.get('session_id', f'ui_{conn_id}')\n            api_key = data.get('api_key')\n\n            if not api_key or STATE.key_to_agent.get(api_key) != agent_id:\n                await app.ws_send(conn_id, {\n                    \"event\": \"error\",\n                    \"data\": {\"error\": \"Invalid or missing API Key\"}\n                })\n                return\n\n            if agent_id in STATE.agent_to_client:\n                agent_conn_id = STATE.agent_to_client[agent_id]\n                request_id = f\"ui_req_{secrets.token_urlsafe(16)}\"\n\n                run_request = RunRequest(\n                    request_id=request_id,\n                    public_agent_id=agent_id,\n                    query=message_text,\n                    session_id=session_id,\n                    kwargs={}\n                )\n\n                response_queue = asyncio.Queue()\n                STATE.pending_requests[request_id] = response_queue\n\n                await app.ws_send(agent_conn_id, WsMessage(\n                    event='run_request',\n                    data=run_request.model_dump()\n                ).model_dump())\n\n                await app.ws_send(conn_id, {\n                    \"event\": \"message_acknowledged\",\n                    \"data\": {\"request_id\": request_id, \"agent_id\": agent_id}\n                })\n\n    except Exception as e:\n        app.print(f\"UI message handling error: {e}\", error=True)\n        await app.ws_send(conn_id, {\n            \"event\": \"error\",\n            \"data\": {\"error\": str(e)}\n        })\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.types","title":"<code>types</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.registry.types.AgentRegistered","title":"<code>AgentRegistered</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Server -&gt; Client: Response after successful registration.</p> Source code in <code>toolboxv2/mods/registry/types.py</code> <pre><code>class AgentRegistered(BaseModel):\n    \"\"\"Server -&gt; Client: Response after successful registration.\"\"\"\n    public_name: str\n    public_agent_id: str = Field(..., description=\"The unique public ID for the agent.\")\n    public_api_key: str = Field(..., description=\"The secret API key for public access.\")\n    public_url: str = Field(..., description=\"The full public URL to run the agent.\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.types.AgentRegistration","title":"<code>AgentRegistration</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Client -&gt; Server: Payload to register a new agent.</p> Source code in <code>toolboxv2/mods/registry/types.py</code> <pre><code>class AgentRegistration(BaseModel):\n    \"\"\"Client -&gt; Server: Payload to register a new agent.\"\"\"\n    public_name: str = Field(..., description=\"A user-friendly name for the agent.\")\n    description: str | None = Field(None, description=\"Optional description of the agent's capabilities.\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.types.ExecutionError","title":"<code>ExecutionError</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Client -&gt; Server: Reports an error during execution.</p> Source code in <code>toolboxv2/mods/registry/types.py</code> <pre><code>class ExecutionError(BaseModel):\n    \"\"\"Client -&gt; Server: Reports an error during execution.\"\"\"\n    request_id: str\n    error: str\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.types.ExecutionResult","title":"<code>ExecutionResult</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Client -&gt; Server: A chunk of the execution result (for streaming).</p> Source code in <code>toolboxv2/mods/registry/types.py</code> <pre><code>class ExecutionResult(BaseModel):\n    \"\"\"Client -&gt; Server: A chunk of the execution result (for streaming).\"\"\"\n    request_id: str\n    payload: dict[str, Any] = Field(..., description=\"The ProgressEvent or final result as a dictionary.\")\n    is_final: bool = Field(False, description=\"True if this is the last message for this request.\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.types.RunRequest","title":"<code>RunRequest</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Server -&gt; Client: Request to execute an agent.</p> Source code in <code>toolboxv2/mods/registry/types.py</code> <pre><code>class RunRequest(BaseModel):\n    \"\"\"Server -&gt; Client: Request to execute an agent.\"\"\"\n    request_id: str = Field(..., description=\"A unique ID for this specific execution request.\")\n    public_agent_id: str = Field(..., description=\"The ID of the agent to run.\")\n    query: str = Field(..., description=\"The main input/query for the agent.\")\n    session_id: str | None = Field(None, description=\"Session ID for maintaining context.\")\n    kwargs: dict[str, Any] = Field({}, description=\"Additional keyword arguments for the a_run method.\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.registry.types.WsMessage","title":"<code>WsMessage</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A generic wrapper for all WebSocket messages.</p> Source code in <code>toolboxv2/mods/registry/types.py</code> <pre><code>class WsMessage(BaseModel):\n    \"\"\"A generic wrapper for all WebSocket messages.\"\"\"\n    event: str\n    data: dict[str, Any]\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.talk","title":"<code>talk</code>","text":""},{"location":"toolboxv2/#toolboxv2.mods.talk.TalkSession","title":"<code>TalkSession</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents the state of a single voice conversation session.</p> Source code in <code>toolboxv2/mods/talk.py</code> <pre><code>class TalkSession(BaseModel):\n    \"\"\"Represents the state of a single voice conversation session.\"\"\"\n    session_id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n    user_id: str\n    chat_session: ChatSession\n    event_queue: asyncio.Queue = Field(default_factory=asyncio.Queue, exclude=True)\n    # Task to track the running agent process, preventing concurrent requests\n    agent_task: asyncio.Task | None = Field(default=None, exclude=True)\n\n    class Config:\n        arbitrary_types_allowed = True\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.talk.Tools","title":"<code>Tools</code>","text":"<p>               Bases: <code>MainTool</code></p> <p>The main class for the Talk module, handling initialization, session management, and dependency loading.</p> Source code in <code>toolboxv2/mods/talk.py</code> <pre><code>class Tools(MainTool):\n    \"\"\"\n    The main class for the Talk module, handling initialization,\n    session management, and dependency loading.\n    \"\"\"\n\n    def __init__(self, app: App):\n        # Initialize the MainTool with module-specific information\n        self.version = VERSION\n        self.name = MOD_NAME\n        self.color = \"CYAN\"\n        self.sessions: dict[str, TalkSession] = {}\n        self.stt_func = None\n        self.tts_func = None\n        self.isaa_mod = None\n        super().__init__(load=self.on_start, v=VERSION, name=MOD_NAME, tool={}, on_exit=self.on_exit)\n\n    def on_start(self):\n        \"\"\"Initializes the Talk module, its dependencies (ISAA, AUDIO), and UI registration.\"\"\"\n        self.app.logger.info(f\"Starting {self.name} v{self.version}...\")\n\n        # Get the ISAA module instance, which is a critical dependency\n        self.isaa_mod = None#self.app.get_mod(\"isaa\")\n        if not self.isaa_mod:\n            self.app.logger.error(\n                f\"{self.name}: ISAA module not found or failed to load. Voice assistant will not be functional.\")\n            return\n\n        # Initialize STT and TTS services from the AUDIO module\n        if hasattr(TBEF, \"AUDIO\") and self.app.get_mod(\"AUDIO\"):\n            self.stt_func = self.app.run_any(TBEF.AUDIO.STT_GENERATE, model=\"openai/whisper-small\", row=True, device=0)\n            self.tts_func = self.app.get_function(TBEF.AUDIO.SPEECH, state=False)[0]\n\n            if self.stt_func and self.stt_func != \"404\":\n                self.app.logger.info(\"Talk STT (whisper-small) is Online.\")\n            else:\n                self.app.logger.warning(\"Talk STT function not available.\")\n                self.stt_func = None\n\n            if self.tts_func and self.tts_func != \"404\":\n                self.app.logger.info(\"Talk TTS function is Online.\")\n            else:\n                self.app.logger.warning(\"Talk TTS function not available.\")\n                self.tts_func = None\n        else:\n            self.app.logger.warning(\"Talk module: AUDIO module features are not available or the module is not loaded.\")\n\n        if not all([self.stt_func, self.tts_func]):\n            self.app.logger.error(\"Talk module cannot function without both STT and TTS services.\")\n\n        # Register the UI component with CloudM\n        self.app.run_any((\"CloudM\", \"add_ui\"),\n                         name=MOD_NAME, title=\"Voice Assistant\", path=f\"/api/{MOD_NAME}/ui\",\n                         description=\"Natural conversation with an AI assistant.\", auth=True)\n        self.app.logger.info(f\"{self.name} UI registered with CloudM.\")\n\n    def on_exit(self):\n        \"\"\"Clean up resources, especially cancelling any active agent tasks.\"\"\"\n        for session in self.sessions.values():\n            if session.agent_task and not session.agent_task.done():\n                session.agent_task.cancel()\n        self.app.logger.info(f\"Closing {self.name} and cleaning up sessions.\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.talk.Tools.on_exit","title":"<code>on_exit()</code>","text":"<p>Clean up resources, especially cancelling any active agent tasks.</p> Source code in <code>toolboxv2/mods/talk.py</code> <pre><code>def on_exit(self):\n    \"\"\"Clean up resources, especially cancelling any active agent tasks.\"\"\"\n    for session in self.sessions.values():\n        if session.agent_task and not session.agent_task.done():\n            session.agent_task.cancel()\n    self.app.logger.info(f\"Closing {self.name} and cleaning up sessions.\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.talk.Tools.on_start","title":"<code>on_start()</code>","text":"<p>Initializes the Talk module, its dependencies (ISAA, AUDIO), and UI registration.</p> Source code in <code>toolboxv2/mods/talk.py</code> <pre><code>def on_start(self):\n    \"\"\"Initializes the Talk module, its dependencies (ISAA, AUDIO), and UI registration.\"\"\"\n    self.app.logger.info(f\"Starting {self.name} v{self.version}...\")\n\n    # Get the ISAA module instance, which is a critical dependency\n    self.isaa_mod = None#self.app.get_mod(\"isaa\")\n    if not self.isaa_mod:\n        self.app.logger.error(\n            f\"{self.name}: ISAA module not found or failed to load. Voice assistant will not be functional.\")\n        return\n\n    # Initialize STT and TTS services from the AUDIO module\n    if hasattr(TBEF, \"AUDIO\") and self.app.get_mod(\"AUDIO\"):\n        self.stt_func = self.app.run_any(TBEF.AUDIO.STT_GENERATE, model=\"openai/whisper-small\", row=True, device=0)\n        self.tts_func = self.app.get_function(TBEF.AUDIO.SPEECH, state=False)[0]\n\n        if self.stt_func and self.stt_func != \"404\":\n            self.app.logger.info(\"Talk STT (whisper-small) is Online.\")\n        else:\n            self.app.logger.warning(\"Talk STT function not available.\")\n            self.stt_func = None\n\n        if self.tts_func and self.tts_func != \"404\":\n            self.app.logger.info(\"Talk TTS function is Online.\")\n        else:\n            self.app.logger.warning(\"Talk TTS function not available.\")\n            self.tts_func = None\n    else:\n        self.app.logger.warning(\"Talk module: AUDIO module features are not available or the module is not loaded.\")\n\n    if not all([self.stt_func, self.tts_func]):\n        self.app.logger.error(\"Talk module cannot function without both STT and TTS services.\")\n\n    # Register the UI component with CloudM\n    self.app.run_any((\"CloudM\", \"add_ui\"),\n                     name=MOD_NAME, title=\"Voice Assistant\", path=f\"/api/{MOD_NAME}/ui\",\n                     description=\"Natural conversation with an AI assistant.\", auth=True)\n    self.app.logger.info(f\"{self.name} UI registered with CloudM.\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.talk.api_open_stream","title":"<code>api_open_stream(self, request, session_id)</code>  <code>async</code>","text":"<p>Opens a Server-Sent Events (SSE) stream for a given session ID.</p> Source code in <code>toolboxv2/mods/talk.py</code> <pre><code>@export(mod_name=MOD_NAME, api=True, name=\"stream\", api_methods=['GET'], request_as_kwarg=True)\nasync def api_open_stream(self: Tools, request: RequestData, session_id: str) -&gt; Result:\n    \"\"\"Opens a Server-Sent Events (SSE) stream for a given session ID.\"\"\"\n    if not session_id or session_id not in self.sessions:\n        return Result.default_user_error(info=\"Invalid or expired session ID.\", exec_code=404)\n\n    session = self.sessions[session_id]\n    queue = session.event_queue\n\n    async def event_generator() -&gt; AsyncGenerator[dict[str, Any], None]:\n        self.app.logger.info(f\"SSE stream opened for session {session_id}\")\n        await queue.put({\"event\": \"connection_ready\", \"data\": \"Stream connected successfully.\"})\n        try:\n            while True:\n                event_data = await queue.get()\n                yield event_data\n                queue.task_done()\n        except asyncio.CancelledError:\n            self.app.logger.info(f\"SSE stream for session {session_id} cancelled by client.\")\n        finally:\n            if session_id in self.sessions:\n                if self.sessions[session_id].agent_task and not self.sessions[session_id].agent_task.done():\n                    self.sessions[session_id].agent_task.cancel()\n                del self.sessions[session_id]\n                self.app.logger.info(f\"Cleaned up and closed session {session_id}.\")\n\n    return Result.sse(stream_generator=event_generator())\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.talk.api_process_audio","title":"<code>api_process_audio(self, request, form_data)</code>  <code>async</code>","text":"<p>Receives audio, transcribes it, and starts the agent processing task.</p> Source code in <code>toolboxv2/mods/talk.py</code> <pre><code>@export(mod_name=MOD_NAME, api=True, name=\"process_audio\", api_methods=['POST'], request_as_kwarg=True)\nasync def api_process_audio(self: Tools, request: RequestData, form_data: dict) -&gt; Result:\n    \"\"\"Receives audio, transcribes it, and starts the agent processing task.\"\"\"\n    if not self.stt_func:\n        return Result.default_internal_error(info=\"Speech-to-text service is not available.\")\n\n    session_id = form_data.get('session_id')\n    audio_file_data = form_data.get('audio_blob')\n\n    if not session_id or session_id not in self.sessions:\n        return Result.default_user_error(info=\"Invalid or missing session_id.\", exec_code=400)\n\n    session = self.sessions[session_id]\n\n    if session.agent_task and not session.agent_task.done():\n        return Result.default_user_error(info=\"Already processing a previous request.\", exec_code=429)\n\n    if not audio_file_data or 'content_base64' not in audio_file_data:\n        return Result.default_user_error(info=\"Audio data is missing or in the wrong format.\", exec_code=400)\n\n    try:\n        audio_bytes = base64.b64decode(audio_file_data['content_base64'])\n        transcription_result = self.stt_func(audio_bytes)\n        transcribed_text = transcription_result.get('text', '').strip()\n\n        if not transcribed_text:\n            await session.event_queue.put({\"event\": \"error\", \"data\": \"Could not understand audio. Please try again.\"})\n            return Result.ok(data={\"message\": \"Transcription was empty.\"})\n\n        await session.event_queue.put({\"event\": \"transcription_update\", \"data\": transcribed_text})\n\n        voice_params = {\n            \"voice_index\": int(form_data.get('voice_index', '0')),\n            \"provider\": form_data.get('provider', 'piper'),\n            \"model_name\": form_data.get('model_name', 'ryan')\n        }\n\n        # Start the background task; the request returns immediately.\n        session.agent_task = asyncio.create_task(\n            _run_agent_and_respond(self, session, transcribed_text, voice_params)\n        )\n        return Result.ok(data={\"message\": \"Audio received and processing started.\"})\n\n    except Exception as e:\n        self.app.logger.error(f\"Error processing audio for session {session_id}: {e}\", exc_info=True)\n        return Result.default_internal_error(info=f\"Failed to process audio: {str(e)}\")\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.talk.api_start_session","title":"<code>api_start_session(self, request)</code>  <code>async</code>","text":"<p>Creates a new talk session for an authenticated user.</p> Source code in <code>toolboxv2/mods/talk.py</code> <pre><code>@export(mod_name=MOD_NAME, api=True, name=\"start_session\", api_methods=['POST'], request_as_kwarg=True)\nasync def api_start_session(self: Tools, request: RequestData) -&gt; Result:\n    \"\"\"Creates a new talk session for an authenticated user.\"\"\"\n    user_id = await _get_user_uid(self.app, request)\n    if not user_id:\n        return Result.default_user_error(info=\"User authentication required.\", exec_code=401)\n\n    if not self.isaa_mod:\n        return Result.default_internal_error(info=\"ISAA module is not available.\")\n\n    # Create a new ISAA ChatSession for conversation history\n    chat_session = ChatSession(mem=self.isaa_mod.get_memory())\n    session = TalkSession(user_id=user_id, chat_session=chat_session)\n    self.sessions[session.session_id] = session\n\n    self.app.logger.info(f\"Started new talk session {session.session_id} for user {user_id}\")\n    return Result.json(data={\"session_id\": session.session_id})\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.mods.talk.get_main_ui","title":"<code>get_main_ui(self, request)</code>","text":"<p>Serves the main HTML and JavaScript UI for the Talk widget.</p> Source code in <code>toolboxv2/mods/talk.py</code> <pre><code>@export(mod_name=MOD_NAME, name=\"ui\", api=True, api_methods=['GET'], request_as_kwarg=True)\ndef get_main_ui(self: Tools, request: RequestData) -&gt; Result:\n    \"\"\"Serves the main HTML and JavaScript UI for the Talk widget.\"\"\"\n    html_content = \"\"\"\n&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\" data-theme=\"light\"&gt;\n&lt;head&gt;\n    &lt;meta charset=\"UTF-8\"&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;\n    &lt;title&gt;ToolBoxV2 - Voice Assistant&lt;/title&gt;\n    &lt;link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200\" /&gt;\n    &lt;style&gt;\n        body { font-family: sans-serif; background-color: var(--theme-bg); color: var(--theme-text); display: flex; justify-content: center; align-items: center; min-height: 100vh; margin: 0; }\n        .container { display: flex; flex-direction: column; align-items: center; justify-content: center; width: 100%; max-width: 600px; padding: 20px; text-align: center; }\n        .visualizer { width: 250px; height: 250px; background-color: var(--glass-bg); border-radius: 50%; position: relative; overflow: hidden; border: 3px solid var(--theme-border); box-shadow: inset 0 0 15px rgba(0,0,0,0.2); transition: border-color 0.3s, box-shadow 0.3s; }\n        .visualizer.recording { border-color: #ef4444; }\n        .visualizer.thinking { border-color: #3b82f6; animation: pulse 2s infinite; }\n        .visualizer.speaking { border-color: #22c55e; }\n        .particle { position: absolute; width: 8px; height: 8px; background-color: var(--theme-primary); border-radius: 50%; pointer-events: none; transition: all 0.1s; }\n        #micButton { margin-top: 30px; width: 80px; height: 80px; border-radius: 50%; border: none; background-color: var(--theme-primary); color: white; cursor: pointer; display: flex; justify-content: center; align-items: center; box-shadow: 0 4px 10px rgba(0,0,0,0.2); transition: background-color 0.2s, transform 0.1s; }\n        #micButton:active { transform: scale(0.95); }\n        #micButton:disabled { background-color: #9ca3af; cursor: not-allowed; }\n        #micButton .material-symbols-outlined { font-size: 40px; }\n        #statusText { margin-top: 20px; min-height: 50px; font-size: 1.2em; color: var(--theme-text-muted); line-height: 1.5; }\n        @keyframes pulse { 0% { box-shadow: inset 0 0 15px rgba(0,0,0,0.2), 0 0 0 0 rgba(59, 130, 246, 0.7); } 70% { box-shadow: inset 0 0 15px rgba(0,0,0,0.2), 0 0 0 15px rgba(59, 130, 246, 0); } 100% { box-shadow: inset 0 0 15px rgba(0,0,0,0.2), 0 0 0 0 rgba(59, 130, 246, 0); } }\n    &lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;div class=\"container\"&gt;\n        &lt;div class=\"visualizer\" id=\"visualizer\"&gt;&lt;/div&gt;\n        &lt;p id=\"statusText\"&gt;Press the microphone to start&lt;/p&gt;\n        &lt;button id=\"micButton\"&gt;&lt;span class=\"material-symbols-outlined\"&gt;hourglass_empty&lt;/span&gt;&lt;/button&gt;\n        &lt;div class=\"options\" style=\"margin-top: 20px;\"&gt;\n            &lt;label for=\"voiceSelect\"&gt;Voice:&lt;/label&gt;\n            &lt;select id=\"voiceSelect\"&gt;\n                &lt;option value='{\"provider\": \"piper\", \"model_name\": \"ryan\", \"voice_index\": 0}'&gt;Ryan (EN)&lt;/option&gt;\n                &lt;option value='{\"provider\": \"piper\", \"model_name\": \"kathleen\", \"voice_index\": 0}'&gt;Kathleen (EN)&lt;/option&gt;\n                &lt;option value='{\"provider\": \"piper\", \"model_name\": \"karlsson\", \"voice_index\": 0}'&gt;Karlsson (DE)&lt;/option&gt;\n            &lt;/select&gt;\n        &lt;/div&gt;\n    &lt;/div&gt;\n    &lt;script unSave=\"true\"&gt;\n    function initTalk() {\n        const visualizer = document.getElementById('visualizer');\n        const micButton = document.getElementById('micButton');\n        const statusText = document.getElementById('statusText');\n        const voiceSelect = document.getElementById('voiceSelect');\n\n        const state = { sessionId: null, sseConnection: null, mediaRecorder: null, audioChunks: [], isRecording: false, isProcessing: false, currentAudio: null };\n        let audioContext, analyser, particles = [];\n\n        function setStatus(text, mode = 'idle') {\n            statusText.textContent = text;\n            visualizer.className = 'visualizer ' + mode;\n        }\n\n        function createParticles(num = 50) {\n            visualizer.innerHTML = ''; particles = [];\n            for (let i = 0; i &lt; num; i++) {\n                const p = document.createElement('div'); p.classList.add('particle');\n                visualizer.appendChild(p);\n                particles.push({ element: p, angle: Math.random() * Math.PI * 2, radius: 50 + Math.random() * 50, speed: 0.01 + Math.random() * 0.02 });\n            }\n        }\n\n        function animateVisualizer() {\n            if (analyser) {\n                const dataArray = new Uint8Array(analyser.frequencyBinCount);\n                analyser.getByteFrequencyData(dataArray);\n                let average = dataArray.reduce((a, b) =&gt; a + b, 0) / dataArray.length;\n                particles.forEach(p =&gt; {\n                    p.angle += p.speed;\n                    const scale = 1 + (average / 128);\n                    p.element.style.transform = `translate(${Math.cos(p.angle) * p.radius * scale}px, ${Math.sin(p.angle) * p.radius * scale}px)`;\n                });\n            }\n            requestAnimationFrame(animateVisualizer);\n        }\n\n        async function startSession() {\n            if (state.sessionId) return;\n            setStatus(\"Connecting...\", 'thinking');\n            micButton.disabled = true;\n            try {\n                const response = await TB.api.request('talk', 'start_session', {}, 'POST');\n                if (response.error === 'none' &amp;&amp; response.get()?.session_id) {\n                    state.sessionId = response.get().session_id;\n                    connectSse();\n                } else {\n                    setStatus(response.info?.help_text || \"Failed to start session.\", 'error');\n                }\n            } catch (e) {\n                setStatus(\"Connection error.\", 'error');\n            }\n        }\n\n        function connectSse() {\n            if (!state.sessionId) return;\n            state.sseConnection = TB.sse.connect(`/sse/talk/stream?session_id=${state.sessionId}`, {\n                onOpen: () =&gt; console.log(\"SSE Stream Open\"),\n                onError: () =&gt; setStatus(\"Connection lost.\", 'error'),\n                listeners: {\n                    'connection_ready': (data) =&gt; { setStatus(\"Press the microphone to start\"); micButton.disabled = false; micButton.innerHTML = '&lt;span class=\"material-symbols-outlined\"&gt;mic&lt;/span&gt;'; },\n                    'transcription_update': (data) =&gt; { setStatus(`\u201c${data}\u201d`, 'thinking'); state.isProcessing = true; },\n                    'agent_thought': (data) =&gt; setStatus(data, 'thinking'),\n                    'agent_response_chunk': (data) =&gt; { if (statusText.textContent.startsWith('\u201c')) statusText.textContent = \"\"; statusText.textContent += data; },\n                    'audio_playback': (data) =&gt; playAudio(data.content, data.format),\n                    'processing_complete': (data) =&gt; { state.isProcessing = false; setStatus(data); micButton.disabled = false; micButton.innerHTML = '&lt;span class=\"material-symbols-outlined\"&gt;mic&lt;/span&gt;'; },\n                    'error': (data) =&gt; { state.isProcessing = false; setStatus(data, 'error'); micButton.disabled = false; micButton.innerHTML = '&lt;span class=\"material-symbols-outlined\"&gt;mic&lt;/span&gt;'; }\n                }\n            });\n        }\n\n        async function playAudio(base64, format) {\n            setStatus(\"...\", 'speaking');\n            const blob = await (await fetch(`data:${format};base64,${base64}`)).blob();\n            const url = URL.createObjectURL(blob);\n            if (state.currentAudio) state.currentAudio.pause();\n            state.currentAudio = new Audio(url);\n\n            if (!audioContext) audioContext = new AudioContext();\n            const source = audioContext.createMediaElementSource(state.currentAudio);\n            if (!analyser) { analyser = audioContext.createAnalyser(); analyser.fftSize = 64; }\n            source.connect(analyser);\n            analyser.connect(audioContext.destination);\n\n            state.currentAudio.play();\n            state.currentAudio.onended = () =&gt; { setStatus(\"Finished speaking.\"); URL.revokeObjectURL(url); };\n        }\n\n        async function toggleRecording() {\n            if (state.isProcessing) return;\n            if (!state.sessionId) { await startSession(); return; }\n\n            if (state.isRecording) {\n                state.mediaRecorder.stop();\n                micButton.disabled = true;\n                micButton.innerHTML = '&lt;span class=\"material-symbols-outlined\"&gt;hourglass_top&lt;/span&gt;';\n                setStatus(\"Processing...\", 'thinking');\n            } else {\n                if (!state.mediaRecorder) {\n                    try {\n                        const stream = await navigator.mediaDevices.getUserMedia({ audio: { sampleRate: 16000, channelCount: 1 } });\n                        if (!audioContext) audioContext = new AudioContext();\n                        const source = audioContext.createMediaStreamSource(stream);\n                        if (!analyser) { analyser = audioContext.createAnalyser(); analyser.fftSize = 64; }\n                        source.connect(analyser);\n\n                        state.mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm;codecs=opus' });\n                        state.mediaRecorder.ondataavailable = e =&gt; state.audioChunks.push(e.data);\n                        state.mediaRecorder.onstop = uploadAudio;\n                    } catch (e) { setStatus(\"Could not access microphone.\", 'error'); return; }\n                }\n                state.audioChunks = []; state.mediaRecorder.start(); state.isRecording = true;\n                setStatus(\"Listening...\", 'recording');\n                micButton.innerHTML = '&lt;span class=\"material-symbols-outlined\"&gt;stop_circle&lt;/span&gt;';\n            }\n        }\n\n        async function uploadAudio() {\n            state.isRecording = false; state.isProcessing = true;\n            if (state.audioChunks.length === 0) { setStatus(\"No audio recorded.\"); state.isProcessing = false; micButton.disabled = false; micButton.innerHTML = '&lt;span class=\"material-symbols-outlined\"&gt;mic&lt;/span&gt;'; return; }\n            const audioBlob = new Blob(state.audioChunks, { type: 'audio/webm;codecs=opus' });\n\n            const formData = new FormData();\n            formData.append('session_id', state.sessionId);\n            formData.append('audio_blob', audioBlob, 'recording.webm');\n\n            const voiceParams = JSON.parse(voiceSelect.value);\n            for (const key in voiceParams) formData.append(key, voiceParams[key]);\n\n            try {\n                const response = await TB.api.request('talk', 'process_audio', formData, 'POST');\n                if (response.error !== 'none') {\n                    setStatus(response.info?.help_text || \"Failed to process audio.\", 'error');\n                    state.isProcessing = false; micButton.disabled = false; micButton.innerHTML = '&lt;span class=\"material-symbols-outlined\"&gt;mic&lt;/span&gt;';\n                }\n            } catch(e) {\n                 setStatus(\"Error sending audio.\", 'error'); state.isProcessing = false; micButton.disabled = false; micButton.innerHTML = '&lt;span class=\"material-symbols-outlined\"&gt;mic&lt;/span&gt;';\n            }\n        }\n\n        micButton.addEventListener('click', toggleRecording);\n        createParticles(); animateVisualizer();\n        if (window.TB.isInitialized) startSession(); else window.TB.events.on('tbjs:initialized', startSession, { once: true });\n    }\nif (window.TB?.events) {\n    if (window.TB.config?.get('appRootId')) { // A sign that TB.init might have run\n         initTalk();\n    } else {\n        window.TB.events.on('tbjs:initialized', initTalk, { once: true });\n    }\n} else {\n    // Fallback if TB is not even an object yet, very early load\n    document.addEventListener('tbjs:initialized', initTalk, { once: true }); // Custom event dispatch from TB.init\n}\n\n    &lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\"\"\"\n    return Result.html(data=html_content)\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.flows_dict","title":"<code>toolboxv2.flows_dict(s='.py', remote=False, dir_path=None, flows_dict_=None)</code>","text":"Source code in <code>toolboxv2/flows/__init__.py</code> <pre><code>def flows_dict(s='.py', remote=False, dir_path=None, flows_dict_=None):\n\n    if flows_dict_ is None:\n        flows_dict_ = {}\n    with Spinner(\"Loading flows\"):\n        # Erhalte den Pfad zum aktuellen Verzeichnis\n        if dir_path is None:\n            for ex_path in os.getenv(\"EXTERNAL_PATH_RUNNABELS\", '').split(','):\n                if not ex_path or len(ex_path) == 0:\n                    continue\n                flows_dict(s,remote,ex_path,flows_dict_)\n            dir_path = os.path.dirname(os.path.realpath(__file__))\n        to = time.perf_counter()\n        # Iteriere \u00fcber alle Dateien im Verzeichnis\n        files = os.listdir(dir_path)\n        l_files = len(files)\n        for i, file_name in enumerate(files):\n            with Spinner(f\"{file_name} {i}/{l_files}\"):\n                # \u00dcberpr\u00fcfe, ob die Datei eine Python-Datei ist\n                if file_name == \"__init__.py\":\n                    pass\n\n                elif remote and s in file_name and file_name.endswith('.gist'):\n                    # print(\"Loading from Gist :\", file_name)\n                    name_f = os.path.splitext(file_name)[0]\n                    name = name_f.split('.')[0]\n                    # publisher = name_f.split('.')[1]\n                    url = name_f.split('.')[-1]\n                    # print(\"Ent\", name)\n                    # Lade das Modul\n                    print(f\"Gist Name: {name}, URL: {url}\")\n                    try:\n                        module = GistLoader(f\"{name}/{url}\").load_module(name)\n                    #try:\n                    #    module = GistLoader(f\"{name}/{url}\")\n                    except Exception as e:\n                        print(f\"Error loading module {name} from github {url}\")\n                        print(e)\n                        continue\n\n                    # F\u00fcge das Modul der Dictionary hinzu\n                    print(f\"{hasattr(module, 'run')} and {callable(module.run)} and {hasattr(module, 'NAME')}\")\n                    if hasattr(module, 'run') and callable(module.run) and hasattr(module, 'NAME'):\n                        # print(\"Collecing :\", module.NAME)\n                        flows_dict_[module.NAME] = module.run\n                elif file_name.endswith('.py') and s in file_name:\n                    name = os.path.splitext(file_name)[0]\n                    # print(\"Loading :\", name)\n                    # Lade das Modul\n                    spec = importlib.util.spec_from_file_location(name, os.path.join(dir_path, file_name))\n                    module = importlib.util.module_from_spec(spec)\n                    try:\n                        spec.loader.exec_module(module)\n                    except Exception:\n                        print(\"Error loading module \", name)\n                        import traceback\n                        traceback.print_exc()\n                        continue\n\n                    # F\u00fcge das Modul der Dictionary hinzu\n                    if hasattr(module, 'run') and callable(module.run) and hasattr(module, 'NAME'):\n                        # print(\"Collecing :\", module.NAME)\n                        flows_dict_[module.NAME] = module.run\n\n        print(f\"Getting all flows took {time.perf_counter() - to:.2f} for {len(flows_dict_.keys())} elements\")\n        return flows_dict_\n</code></pre>"},{"location":"toolboxv2/#toolboxv2.TBEF","title":"<code>toolboxv2.TBEF</code>","text":"<p>Automatic generated by ToolBox v = 0.1.22</p>"},{"location":"toolboxv2/#other-exposed-items","title":"Other Exposed Items","text":""},{"location":"toolboxv2/#toolboxv2.ToolBox_over","title":"<code>toolboxv2.ToolBox_over = 'root'</code>  <code>module-attribute</code>","text":""},{"location":"usage/","title":"ToolBoxV2 Developer Guide","text":"<p>Based on the provided documentation, here's a comprehensive guide on how to use the ToolBoxV2 framework for building applications.</p>"},{"location":"usage/#introduction","title":"Introduction","text":"<p>ToolBoxV2 is a Python framework that provides a structured approach to building applications with standardized request handling and response formatting. It consists of two main components:</p> <ol> <li>RequestData Classes - For handling HTTP requests with strong typing</li> <li>Result Class - For standardized response handling and error management</li> </ol>"},{"location":"usage/#setting-up-your-application","title":"Setting Up Your Application","text":""},{"location":"usage/#creating-a-module","title":"Creating a Module","text":"<p>Start by initializing your application module:</p> <pre><code>from toolboxv2 import get_app, App, RequestData, Result\nfrom typing import Dict, Optional\n\n# Define your module\nMOD_NAME = \"YOUR_MODULE_NAME\"\nversion = \"1.0\"\nexport = get_app(\"{MODULE-NAME.SUB-MODULE}\").tb\n</code></pre>"},{"location":"usage/#registering-functions","title":"Registering Functions","text":"<p>Use the <code>@export</code> decorator to register functions within your module:</p> <pre><code>@export(mod_name=MOD_NAME, version=version)\ndef your_function():\n    # Function logic here\n    return Result.ok(data=\"Success\")\n</code></pre>"},{"location":"usage/#function-types","title":"Function Types","text":""},{"location":"usage/#standard-system-functions","title":"Standard System Functions","text":"<pre><code># Basic function with App parameter\n@export(mod_name=MOD_NAME, version=version, row=True)\ndef system_function(app: App):\n    # Implementation\n    return \"Raw return value\"  # Will be returned as-is because row=True\n\n# Function without App parameter\n@export(mod_name=MOD_NAME, version=version)\ndef function_without_app():\n    # Implementation\n    return Result.ok(data=\"Success\")\n\n# Function with arguments\n@export(mod_name=MOD_NAME, version=version)\ndef function_with_args(name: str) -&gt; Result:\n    # Implementation\n    return Result.ok(data=name)\n\n# Function returning raw data\n@export(mod_name=MOD_NAME, version=version, row=True)\ndef function_with_args_kwargs(name: str, nickname: Optional[str]=None) -&gt; str:\n    if nickname is None:\n        nickname = \"\"\n    return name + nickname  # Returned as raw string\n</code></pre>"},{"location":"usage/#async-functions","title":"Async Functions","text":"<pre><code>@export(mod_name=MOD_NAME, version=version, row=True)\nasync def async_function(app: App):\n    # Async implementation\n    result = await some_async_operation()\n    return result\n</code></pre>"},{"location":"usage/#api-endpoints","title":"API Endpoints","text":"<pre><code># API endpoint with request parameter\n@export(mod_name=MOD_NAME, api=True, version=\"1.0\", request_as_kwarg=True)\nasync def get_data(request: Optional[RequestData]=None):\n    if request:\n        query_params = request.query_params\n        # Process query parameters\n    return Result.json(data={\"status\": \"success\"})\n\n# API endpoint with App and Request parameters\n@export(mod_name=MOD_NAME, api=True, version=\"1.0\", request_as_kwarg=True)\nasync def get_user_data(app, request: Optional[RequestData]=None):\n    # Implementation using app and request\n    return Result.ok(data={\"user\": \"data\"})\n\n# API endpoint with specific HTTP methods\n@export(mod_name=MOD_NAME, api=True, version=\"1.0\", api_methods=['PUT', 'POST'])\nasync def update_data(app, data: Dict):\n    # Process the JSON data received in the request body\n    return Result.ok(data=data)\n\n# API endpoint handling form data\n@export(mod_name=MOD_NAME, api=True, version=\"1.0\", api_methods=['PUT', 'POST'])\nasync def submit_form(app, form_data: Dict):\n    # Process form data\n    return Result.ok(data=form_data)\n</code></pre>"},{"location":"usage/#working-with-request-data","title":"Working with Request Data","text":""},{"location":"usage/#accessing-request-information","title":"Accessing Request Information","text":"<pre><code>@export(mod_name=MOD_NAME, api=True, version=\"1.0\", request_as_kwarg=True)\nasync def process_request(request: Optional[RequestData]=None):\n    if request:\n        # Access method and path\n        method = request.method\n        path = request.path\n\n        # Access headers\n        user_agent = request.headers.user_agent\n        content_type = request.headers.content_type\n        custom_header = request.headers.extra_headers.get('x-custom-header')\n\n        # Access query parameters\n        query_params = request.query_params\n        search_term = query_params.get('search')\n\n        # Access form data or JSON body\n        if request.form_data:\n            form_values = request.form_data\n\n        if request.body and request.content_type == 'application/json':\n            json_data = request.body\n\n    return Result.ok(data=\"Request processed\")\n</code></pre>"},{"location":"usage/#accessing-session-information","title":"Accessing Session Information","text":"<pre><code>@export(mod_name=MOD_NAME, api=True, version=\"1.0\", request_as_kwarg=True)\nasync def get_user_session(request: Optional[RequestData]=None):\n    if request and hasattr(request, 'session'):\n        # Access session data\n        session_id = request.session.SiID\n        user_name = request.session.user_name\n        session_level = request.session.level\n\n        # Access custom session data\n        custom_data = request.session.extra_data.get('custom_key')\n\n    return Result.ok(data={\"user\": user_name})\n</code></pre>"},{"location":"usage/#working-with-results","title":"Working with Results","text":""},{"location":"usage/#creating-different-types-of-responses","title":"Creating Different Types of Responses","text":"<pre><code>@export(mod_name=MOD_NAME, api=True, version=\"1.0\")\nasync def response_examples(app):\n    # Choose the appropriate response type based on your needs\n\n    # 1. Standard success response\n    return Result.ok(\n        data={\"key\": \"value\"},\n        info=\"Operation completed successfully\"\n    )\n\n    # 2. JSON response\n    return Result.json(\n        data={\"status\": \"online\", \"version\": \"1.0\"},\n        info=\"API status retrieved\"\n    )\n\n    # 3. HTML response\n    return Result.html(\n        data=\"&lt;html&gt;&lt;body&gt;&lt;h1&gt;Welcome&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;\",\n        info=\"Page rendered\"\n    )\n\n    # 4. Text response\n    return Result.text(\n        text_data=\"Plain text content\",\n        content_type=\"text/plain\"\n    )\n\n    # 5. Binary file response\n    return Result.binary(\n        data=binary_data,\n        content_type=\"application/pdf\",\n        download_name=\"report.pdf\"\n    )\n\n    # 6. Redirect response\n    return Result.redirect(\n        url=\"/dashboard\",\n        status_code=302\n    )\n</code></pre>"},{"location":"usage/#error-handling","title":"Error Handling","text":"<pre><code>@export(mod_name=MOD_NAME, version=version)\ndef process_with_validation(user_input):\n    # Validate input\n    if not user_input:\n        return Result.default_user_error(\n            info=\"Empty input is not allowed\",\n            exec_code=400\n        )\n\n    # Process valid input\n    try:\n        processed_data = process_data(user_input)\n        return Result.ok(data=processed_data)\n    except Exception as e:\n        return Result.default_internal_error(\n            info=f\"Processing error: {str(e)}\",\n            exec_code=500\n        )\n</code></pre>"},{"location":"usage/#using-lazy_return-for-simplified-error-handling","title":"Using lazy_return for Simplified Error Handling","text":"<pre><code>@export(mod_name=MOD_NAME, version=version)\ndef validate_and_process(data):\n    # Validate data\n    validation_result = validate_data(data)\n\n    # If validation fails, return the error\n    # If validation succeeds, return the processed data\n    return validation_result.lazy_return(\n        'user',  # Use user error if validation fails\n        data={\"processed\": True, \"original\": data}  # Return this if successful\n    )\n</code></pre>"},{"location":"usage/#streaming-responses","title":"Streaming Responses","text":"<pre><code>@export(mod_name=MOD_NAME, api=True, version=\"1.0\")\nasync def stream_data():\n    async def generator():\n        for i in range(10):\n            yield {\"chunk\": i}\n            await asyncio.sleep(0.5)\n\n    async def cleanup():\n        # Cleanup resources when the stream closes\n        print(\"Stream closed, performing cleanup\")\n\n    return Result.stream(\n        stream_generator=generator(),\n        info=\"Streaming data chunks\",\n        cleanup_func=cleanup\n    )\n</code></pre>"},{"location":"usage/#advanced-features","title":"Advanced Features","text":""},{"location":"usage/#caching","title":"Caching","text":"<pre><code># Memory caching\n@export(mod_name=MOD_NAME, version=version, memory_cache=True,\n        memory_cache_max_size=100, memory_cache_ttl=300)\ndef cached_function(key):\n    # Expensive operation here\n    return Result.ok(data=compute_expensive_data(key))\n\n# File caching\n@export(mod_name=MOD_NAME, version=version, file_cache=True)\ndef file_cached_function(key):\n    # Expensive operation here\n    return Result.ok(data=compute_expensive_data(key))\n</code></pre>"},{"location":"usage/#background-functions","title":"Background Functions","text":"<pre><code># Memory caching\n@export(mod_name=MOD_NAME, version=version)\ndef function_with_log_running_bg_call():\n    # Expensive operation here\n    def sync_bg_function():\n        print(\"running in gb\")\n        compute_expensive_function()\n\n    return Result.ok(data=\"Starting processing\").task(sync_bg_function)\n\n# File caching\n@export(mod_name=MOD_NAME, version=version)\nasync def function_with_log_running_bg_call():\n    # Expensive operation here\n    async def bg_function():\n        print(\"running in gb\")\n        await compute_expensive_function()\n    return Result.ok(data=\"Starting processing\").task(bg_function())\n</code></pre>"},{"location":"usage/#lifecycle-management","title":"Lifecycle Management","text":"<pre><code># Initialization function\n@export(mod_name=MOD_NAME, version=version, initial=True)\ndef initialize_module(app: App):\n    # Called when the module is loaded\n    print(f\"Initializing {MOD_NAME} module\")\n    # Set up resources, connections, etc.\n    return Result.ok(info=\"Module initialized\")\n\n# Exit function\n@export(mod_name=MOD_NAME, version=version, exit_f=True)\ndef cleanup_module(app: App):\n    # Called when the application is shutting down\n    print(f\"Cleaning up {MOD_NAME} module\")\n    # Release resources, close connections, etc.\n    return Result.ok(info=\"Module cleaned up\")\n</code></pre>"},{"location":"usage/#prepost-compute-functions","title":"Pre/Post Compute Functions","text":"<pre><code>def log_before_execution(func, *args, **kwargs):\n    print(f\"Executing {func.__name__} with args: {args}, kwargs: {kwargs}\")\n    return args, kwargs\n\ndef log_after_execution(result, func, *args, **kwargs):\n    print(f\"Function {func.__name__} returned: {result}\")\n    return result\n\n@export(mod_name=MOD_NAME, version=version,\n        pre_compute=log_before_execution,\n        post_compute=log_after_execution)\ndef monitored_function(name):\n    # Function logic\n    return Result.ok(data=f\"Hello, {name}!\")\n</code></pre>"},{"location":"usage/#dokumentation-websocket-kommunikation","title":"Dokumentation: WebSocket-Kommunikation","text":"<p>Diese Dokumentation beschreibt, wie Sie die WebSocket-Funktionalit\u00e4t f\u00fcr bidirektionale Echtzeitkommunikation zwischen dem <code>tbjs</code>-Frontend und dem <code>toolboxv2</code>-Backend nutzen k\u00f6nnen.</p>"},{"location":"usage/#architekturubersicht","title":"Architektur\u00fcbersicht","text":"<p>Die WebSocket-Kommunikation wird durch einen zentralen Rust Actor auf dem <code>actix_web</code>-Server verwaltet. Dieser Actor agiert als intelligente Br\u00fccke, die Verbindungen von Clients entgegennimmt, Nachrichten an die entsprechenden Python-Handler weiterleitet und Push-Nachrichten vom Python-Backend an die Clients sendet.</p> <pre><code>sequenceDiagram\n    participant JS (TB.ws) as Frontend\n    participant Rust (actix-web) as WebSocket Actor\n    participant Python (toolboxv2) as Anwendungslogik\n\n    JS (TB.ws)-&gt;&gt;+Rust (actix-web): WebSocket-Verbindung aufbauen (/ws/...)\n    Rust (actix-web)-&gt;&gt;+Python (toolboxv2): Ruft Python `on_connect` Handler auf\n\n    loop Nachrichtenfluss\n        JS (TB.ws)-&gt;&gt;Rust (actix-web): Sendet Nachricht\n        Rust (actix-web)-&gt;&gt;Python (toolboxv2): Ruft Python `on_message` Handler auf\n\n        Python (toolboxv2)-)!-Rust (actix-web): Ruft `app.ws_broadcast()` oder `app.ws_send()` auf\n        Rust (actix-web)--&gt;&gt;JS (TB.ws): Leitet Nachricht an Clients weiter\n    end\n\n    JS (TB.ws)-xRust (actix-web): Verbindung wird getrennt\n    Rust (actix-web)-xPython (toolboxv2): Ruft Python `on_disconnect` Handler auf\n</code></pre>"},{"location":"usage/#teil-1-verwendung-in-javascript-tbjs","title":"Teil 1: Verwendung in JavaScript (<code>tbjs</code>)","text":"<p>Das <code>TB.ws</code>-Modul stellt eine einfache Schnittstelle zur Verwaltung von WebSocket-Verbindungen bereit.</p>"},{"location":"usage/#tbwsconnecturl-options","title":"<code>TB.ws.connect(url, options)</code>","text":"<p>Baut eine WebSocket-Verbindung zu einem bestimmten Endpunkt auf.</p> <ul> <li><code>url</code> (String): Der Pfad zum WebSocket-Endpunkt auf dem Server. Das Format ist <code>/ws/{Modulname}/{HandlerName}</code>, z. B. <code>/ws/ChatModule/public_room</code>.</li> <li><code>options</code> (Object, optional): Ein Objekt mit Callback-Funktionen:<ul> <li><code>onOpen(event)</code>: Wird aufgerufen, wenn die Verbindung erfolgreich hergestellt wurde.</li> <li><code>onMessage(data, event)</code>: Wird bei jeder eingehenden Nachricht aufgerufen. <code>data</code> enth\u00e4lt die bereits als JSON geparsten Daten.</li> <li><code>onClose(event)</code>: Wird aufgerufen, wenn die Verbindung geschlossen wird.</li> <li><code>onError(event)</code>: Wird aufgerufen, wenn ein Fehler auftritt.</li> </ul> </li> </ul>"},{"location":"usage/#tbwssendpayload","title":"<code>TB.ws.send(payload)</code>","text":"<p>Sendet Daten an den Server.</p> <ul> <li><code>payload</code> (Object): Ein JavaScript-Objekt, das als JSON-String an den Server gesendet wird.<ul> <li>Best Practice: Verwenden Sie ein konsistentes Format wie <code>{ \"event\": \"event_name\", \"data\": { ... } }</code>, um die Verarbeitung auf der Serverseite zu vereinfachen.</li> </ul> </li> </ul>"},{"location":"usage/#tbwsdisconnect","title":"<code>TB.ws.disconnect()</code>","text":"<p>Schlie\u00dft die aktive WebSocket-Verbindung manuell.</p>"},{"location":"usage/#event-basiertes-lauschen","title":"Event-basiertes Lauschen","text":"<p>Zus\u00e4tzlich zu den <code>onMessage</code>-Callbacks k\u00f6nnen Sie den globalen <code>TB.events</code>-Bus verwenden, um auf Nachrichten zu lauschen. Dies ist ideal f\u00fcr die Entkopplung Ihrer UI-Komponenten.</p> <ul> <li><code>TB.events.on('ws:message', ({ data, originEvent }) =&gt; { ... })</code>: Lauscht auf alle eingehenden WebSocket-Nachrichten.</li> <li><code>TB.events.on('ws:event:{event_name}', ({ data, originEvent }) =&gt; { ... })</code>: Wenn die eingehende Nachricht ein <code>{ \"event\": \"event_name\", ... }</code>-Format hat, wird dieses spezifische Event ausgel\u00f6st. Dies ist die empfohlene Methode.</li> </ul>"},{"location":"usage/#beispiel-ein-einfacher-chat-client","title":"Beispiel: Ein einfacher Chat-Client","text":"<pre><code>&lt;!-- UI f\u00fcr den Chat --&gt;\n&lt;div id=\"chat-log\" style=\"height: 200px; border: 1px solid #ccc; overflow-y: scroll; padding: 5px;\"&gt;&lt;/div&gt;\n&lt;input type=\"text\" id=\"chat-input\" placeholder=\"Nachricht eingeben...\" /&gt;\n&lt;button id=\"send-button\"&gt;Senden&lt;/button&gt;\n</code></pre> <pre><code>// JavaScript-Logik\nfunction initializeChat() {\n    const chatLog = document.getElementById('chat-log');\n    const chatInput = document.getElementById('chat-input');\n    const sendButton = document.getElementById('send-button');\n\n    // 1. Verbindung aufbauen\n    TB.ws.connect('/ws/ChatModule/public_room', {\n        onOpen: () =&gt; {\n            chatLog.innerHTML += '&lt;div&gt;&lt;em&gt;Verbindung zum Chat hergestellt.&lt;/em&gt;&lt;/div&gt;';\n        },\n        onClose: () =&gt; {\n            chatLog.innerHTML += '&lt;div&gt;&lt;em&gt;Verbindung zum Chat verloren.&lt;/em&gt;&lt;/div&gt;';\n        }\n    });\n\n    // 2. Auf neue Nachrichten vom Server lauschen (Best Practice)\n    TB.events.on('ws:event:new_message', ({ data }) =&gt; {\n        const message = data.data; // Die Struktur ist { event: '...', data: { user: '..', text: '..' } }\n        const messageDiv = document.createElement('div');\n        messageDiv.innerHTML = `&lt;strong&gt;${message.user}:&lt;/strong&gt; ${message.text}`;\n        chatLog.appendChild(messageDiv);\n        chatLog.scrollTop = chatLog.scrollHeight;\n    });\n\n    // Lauschen auf andere Events\n    TB.events.on('ws:event:user_joined', ({ data }) =&gt; {\n        chatLog.innerHTML += `&lt;div&gt;&lt;em&gt;${data.data}&lt;/em&gt;&lt;/div&gt;`;\n    });\n     TB.events.on('ws:event:user_left', ({ data }) =&gt; {\n        chatLog.innerHTML += `&lt;div&gt;&lt;em&gt;${data.data}&lt;/em&gt;&lt;/div&gt;`;\n    });\n\n\n    // 3. Nachricht senden, wenn der Button geklickt wird\n    sendButton.addEventListener('click', () =&gt; {\n        const messageText = chatInput.value;\n        if (messageText.trim() === '') return;\n\n        TB.ws.send({\n            event: \"chat_message\", // Entspricht dem Python-Handler\n            data: {\n                message: messageText\n            }\n        });\n\n        chatInput.value = '';\n    });\n}\n\n// Initialisiere den Chat, sobald tbjs bereit ist\nTB.events.on('tbjs:initialized', initializeChat, { once: true });\n</code></pre>"},{"location":"usage/#teil-2-implementierung-in-python-toolboxv2","title":"Teil 2: Implementierung in Python (<code>toolboxv2</code>)","text":"<p>Die serverseitige Logik wird durch einen speziellen <code>@export</code>-Decorator und <code>async</code>-Handler-Funktionen definiert.</p>"},{"location":"usage/#exportwebsocket_handlerhandler_name","title":"<code>@export(websocket_handler=\"handler_name\")</code>","text":"<p>Dieser Decorator registriert eine Initialisierungsfunktion f\u00fcr einen WebSocket-Endpunkt.</p> <ul> <li><code>websocket_handler</code> (String): Definiert den Namen des Handlers. Der vollst\u00e4ndige Endpunkt-Pfad f\u00fcr den Client lautet dann <code>/ws/{mod_name}/{handler_name}</code>.</li> <li>Die dekorierte Funktion muss ein Dictionary zur\u00fcckgeben, das die <code>async</code>-Funktionen f\u00fcr die WebSocket-Events (<code>on_connect</code>, <code>on_message</code>, <code>on_disconnect</code>) zuordnet.</li> </ul>"},{"location":"usage/#event-handler","title":"Event-Handler","text":"<p>Jeder Handler ist eine <code>async</code>-Funktion und erh\u00e4lt die folgenden Argumente:</p> <ul> <li><code>app: App</code>: Die globale <code>App</code>-Instanz.</li> <li><code>conn_id: str</code>: Eine eindeutige ID f\u00fcr die WebSocket-Verbindung des Clients.</li> <li><code>session: dict</code>: Die Sitzungsdaten des verbundenen Benutzers.</li> <li><code>payload: dict</code> (nur f\u00fcr <code>on_message</code>): Die vom Client gesendeten und als Dictionary geparsten JSON-Daten.</li> </ul>"},{"location":"usage/#server-push-funktionen","title":"Server-Push-Funktionen","text":"<p>Die <code>App</code>-Instanz bietet zwei <code>async</code>-Methoden, um Nachrichten proaktiv an Clients zu senden:</p> <ul> <li> <p><code>await app.ws_send(conn_id: str, payload: dict)</code>:</p> <ul> <li>Sendet eine Nachricht an eine einzelne, spezifische Verbindung (1-zu-1).</li> <li>Ideal f\u00fcr private Nachrichten oder Best\u00e4tigungen.</li> </ul> </li> <li> <p><code>await app.ws_broadcast(channel_id: str, payload: dict, source_conn_id: str = \"\")</code>:</p> <ul> <li>Sendet eine Nachricht an alle Clients, die mit einem bestimmten Kanal verbunden sind (1-zu-N).</li> <li><code>channel_id</code>: Muss dem <code>{mod_name}/{handler_name}</code> entsprechen.</li> <li><code>source_conn_id</code> (optional): Wenn angegeben, wird die Nachricht nicht an diesen Client zur\u00fcckgesendet (verhindert Echos).</li> </ul> </li> </ul>"},{"location":"usage/#beispiel-das-chat-modul-backend","title":"Beispiel: Das Chat-Modul-Backend","text":"<pre><code># toolboxv2/mods/chat_module.py\n\nfrom toolboxv2 import get_app, App\nfrom toolboxv2.utils.system.types import Result\n\napp = get_app(\"ChatModule\")\nexport = app.tb\nName = \"ChatModule\"\n\n# --- 1. Definiere die asynchronen Event-Handler ---\n\nasync def on_user_connect(app: App, conn_id: str, session: dict):\n    \"\"\"Wird aufgerufen, wenn ein neuer Client eine Verbindung herstellt.\"\"\"\n    username = session.get(\"user_name\", \"Anonymous\")\n    app.print(f\"WS CONNECT: User '{username}' connected with conn_id: {conn_id}\")\n\n    # Sende eine Willkommensnachricht nur an den neuen Benutzer\n    await app.ws_send(conn_id, {\"event\": \"welcome\", \"data\": f\"Welcome, {username}!\"})\n\n    # Informiere alle anderen im Raum \u00fcber den neuen Benutzer\n    await app.ws_broadcast(\n        channel_id=\"ChatModule/public_room\",\n        payload={\"event\": \"user_joined\", \"data\": f\"{username} has joined the chat.\"},\n        source_conn_id=conn_id  # Verhindert, dass der neue User seine eigene \"joined\"-Nachricht erh\u00e4lt\n    )\n\nasync def on_chat_message(app: App, conn_id: str, session: dict, payload: dict):\n    \"\"\"Wird aufgerufen, wenn eine Nachricht vom Client empfangen wird.\"\"\"\n    username = session.get(\"user_name\", \"Anonymous\")\n    # Der Payload vom Client hat die Struktur: { \"event\": \"chat_message\", \"data\": { \"message\": \"...\" } }\n    message_text = payload.get(\"data\", {}).get(\"message\", \"\").strip()\n\n    if not message_text:\n        return # Leere Nachrichten ignorieren\n\n    app.print(f\"WS MESSAGE from {username} ({conn_id}): {message_text}\")\n\n    # Sende die formatierte Nachricht an alle im Raum (inklusive Absender)\n    await app.ws_broadcast(\n        channel_id=\"ChatModule/public_room\",\n        payload={\"event\": \"new_message\", \"data\": {\"user\": username, \"text\": message_text}}\n    )\n\nasync def on_user_disconnect(app: App, conn_id: str, session: dict):\n    \"\"\"Wird aufgerufen, wenn ein Client die Verbindung trennt.\"\"\"\n    username = session.get(\"user_name\", \"Anonymous\")\n    app.print(f\"WS DISCONNECT: User '{username}' disconnected (conn_id: {conn_id})\")\n\n    # Informiere alle verbleibenden Benutzer\n    await app.ws_broadcast(\n        channel_id=\"ChatModule/public_room\",\n        payload={\"event\": \"user_left\", \"data\": f\"{username} has left the chat.\"}\n    )\n\n# --- 2. Registriere die Handler mit dem Decorator ---\n\n@export(mod_name=Name, websocket_handler=\"public_room\")\ndef register_chat_handlers(app: App):\n    \"\"\"\n    Diese Funktion wird beim Laden des Moduls aufgerufen.\n    Sie gibt ein Dictionary zur\u00fcck, das die Handler f\u00fcr die WebSocket-Events definiert.\n    \"\"\"\n    return {\n        \"on_connect\": on_user_connect,\n        \"on_message\": on_chat_message,\n        \"on_disconnect\": on_user_disconnect,\n    }\n</code></pre>"},{"location":"usage/#url-patterns-for-api-endpoints","title":"URL Patterns for API Endpoints","text":"<p>API endpoints are accessible using the following URL patterns:</p> <ul> <li>Regular API: <code>/api/MOD_NAME/{function_name}?param1=value1&amp;param2=value2</code></li> <li>Server-Sent Events (streaming): <code>/sse/MOD_NAME/{function_name}?param1=value1&amp;param2=value2</code></li> </ul>"},{"location":"utils/","title":"ToolBoxV2: The <code>App</code> Class","text":"<p>The <code>App</code> class is the central singleton instance in ToolBoxV2, responsible for managing the application's lifecycle, configuration, module loading, and core functionalities. It's typically accessed via the <code>get_app()</code> utility function.</p>"},{"location":"utils/#initialization","title":"Initialization","text":"<p>The <code>App</code> instance is initialized with a <code>prefix</code> and <code>AppArgs</code> (command-line arguments).</p> <pre><code>from toolboxv2 import App, AppArgs, get_app\n\n# Example: Initialize or get the App instance\n# The prefix helps differentiate multiple App instances if needed,\n# and is often used in directory naming.\nargs = AppArgs().default() # Or parsed from sys.argv in __main__.py\napp_instance = get_app(prefix=\"my_app_instance\", args=args)\n\n# Accessing key attributes:\nprint(f\"App ID: {app_instance.id}\")\nprint(f\"Version: {app_instance.version}\")\nprint(f\"Start Directory: {app_instance.start_dir}\")\nprint(f\"Data Directory: {app_instance.data_dir}\")\nprint(f\"Config Directory: {app_instance.config_dir}\")\nprint(f\"Debug Mode: {app_instance.debug}\")\n</code></pre>"},{"location":"utils/#key-initialization-steps","title":"Key Initialization Steps:","text":"<ol> <li> <p>System &amp; Paths:</p> <ul> <li>Determines the operating system (<code>system_flag</code>).</li> <li>Sets the <code>start_dir</code> to the application's root directory.</li> <li>Resolves the <code>prefix</code>:<ul> <li>If no prefix is provided, it attempts to load the last used prefix from <code>.data/last-app-prefix.txt</code>.</li> <li>If a prefix is provided, it's saved to this file for future use.</li> </ul> </li> <li>Constructs the <code>app_id</code> (e.g., <code>prefix-hostname</code>).</li> <li>Sets up <code>data_dir</code>, <code>config_dir</code>, and <code>info_dir</code> based on the <code>app_id</code> (e.g., <code>./.data/prefix-hostname/</code>).</li> <li>Sets up <code>appdata</code> directory (OS-specific application data folder).</li> </ul> </li> <li> <p>Logging:</p> <ul> <li>Initializes a logger (<code>app.logger</code>). The logging level and output (terminal/file) can vary based on the <code>prefix</code> (e.g., \"test\", \"live\", \"debug\") and the <code>--debug</code> CLI argument.</li> </ul> </li> <li> <p>Configuration:</p> <ul> <li>Loads application configuration using <code>FileHandler</code> from a file typically named <code>app_id.config</code> in the <code>config_dir</code>.</li> <li>Defines default configuration <code>keys</code> and <code>defaults</code> (e.g., for macros, helpers, debug status).</li> </ul> </li> <li> <p>Core Attributes:</p> <ul> <li><code>version</code>: ToolBoxV2 version, read from <code>pyproject.toml</code>.</li> <li><code>debug</code>: Boolean, controlled by CLI args and config.</li> <li><code>dev_modi</code>: Boolean, development mode status from config.</li> <li><code>functions</code>: A dictionary to store registered functions from modules.</li> <li><code>modules</code>: A dictionary to store loaded module objects.</li> <li><code>interface_type</code>: Default <code>ToolBoxInterfaces.native</code>.</li> <li><code>alive</code>: Boolean, controls the main application loop.</li> <li><code>args_sto</code>: Stores the parsed <code>AppArgs</code>.</li> <li><code>loop</code>: The asyncio event loop (initialized later or if already running).</li> <li><code>session</code>: A <code>Session</code> object for managing user/remote session state.</li> </ul> </li> <li> <p>Conditional Actions (based on <code>AppArgs</code>):</p> <ul> <li><code>args.init</code>: If true, adds <code>start_dir</code> to <code>sys.path</code>.</li> <li>The <code>__main__.py</code> script handles other arguments like <code>--update</code>, <code>--get-version</code>, etc., by calling <code>App</code> methods or other utilities.</li> </ul> </li> </ol>"},{"location":"utils/#core-functionalities","title":"Core Functionalities","text":""},{"location":"utils/#module-management","title":"Module Management","text":"<ul> <li> <p><code>load_mod(mod_name: str, spec='app', mlm='I', **kwargs)</code> / <code>save_load(modname, spec='app')</code>:</p> <ul> <li>Loads a module into the application.</li> <li><code>spec</code> (specification): Used to namespace or categorize the module instance (e.g., 'app' for general, or a specific session ID).</li> <li>Supports different loading mechanisms (<code>mlm</code>):<ul> <li><code>'I'</code>: In-place load (imports the Python module directly). This is the default.</li> <li><code>'C'</code>: Copies the module file to a runtime directory before loading (less common).</li> </ul> </li> <li>Handles <code>ModuleNotFoundError</code> by attempting to guide the user (e.g., install via <code>CloudM</code> or <code>pip</code>).</li> <li>Registers the module's exported functions and/or its <code>Tools</code> class instance.</li> <li>Can reload modules if they are already loaded. <pre><code># Load the 'MyModule'\nmy_module_instance = app_instance.load_mod(\"MyModule\")\n\n# Or if it's a Tool-based module:\n# my_tool_instance = app_instance.load_mod(\"MyToolModule\")\n</code></pre></li> </ul> </li> <li> <p><code>get_mod(name: str, spec='app') -&gt; ModuleType | MainToolType</code>:</p> <ul> <li>Retrieves a loaded module instance. If the module isn't loaded, it attempts to load it. <pre><code>db_mod = app_instance.get_mod(\"DB\")\nif db_mod:\n    db_mod.some_db_function()\n</code></pre></li> </ul> </li> <li> <p><code>remove_mod(mod_name: str, spec='app', delete=True)</code> / <code>a_remove_mod(...)</code> (async):</p> <ul> <li>Unloads a module, calling its <code>on_exit</code> functions if defined.</li> <li><code>delete=True</code> removes it completely from the <code>functions</code> registry.</li> </ul> </li> <li> <p><code>reload_mod(mod_name: str, spec='app', ...)</code>:</p> <ul> <li>Reloads an existing module. Useful for development.</li> </ul> </li> <li> <p><code>watch_mod(mod_name: str, ...)</code>:</p> <ul> <li>Monitors a module's source file(s) for changes and automatically reloads it. <pre><code># In development, watch 'MyDevModule' for changes\napp_instance.watch_mod(\"MyDevModule\")\n</code></pre></li> </ul> </li> <li> <p><code>load_all_mods_in_file(working_dir=\"mods\")</code> / <code>a_load_all_mods_in_file(...)</code> (async):</p> <ul> <li>Scans the specified directory (default <code>./mods/</code>) and loads all valid Python modules found.</li> </ul> </li> </ul>"},{"location":"utils/#function-registration-and-execution","title":"Function Registration and Execution","text":"<ul> <li> <p><code>@app.tb(...)</code> Decorator (via <code>_create_decorator</code>):</p> <ul> <li>The primary way functions are registered with ToolBoxV2. See <code>example_mod.md</code> for details on usage.</li> <li>This decorator populates the <code>app.functions</code> dictionary.</li> </ul> </li> <li> <p><code>get_function(name: Enum | tuple, metadata=False, state=True, specification='app', ...)</code>:</p> <ul> <li>Retrieves a registered function.</li> <li><code>name</code>: Can be an Enum (from <code>all_functions_enums.py</code>) or a <code>(module_name, function_name)</code> tuple.</li> <li><code>metadata=True</code>: Returns a tuple <code>(function_data_dict, callable_function)</code>.</li> <li><code>state=True</code>: Returns a stateful version of the function (bound to its module instance if applicable).</li> <li><code>state=False</code>: Returns the raw, stateless function.</li> <li><code>specification</code>: The context/instance spec to get the function for.</li> </ul> </li> <li> <p><code>run_any(mod_function_name, ..., get_results=False, **kwargs)</code> / <code>a_run_any(...)</code> (async):</p> <ul> <li>Executes a registered function by its name (Enum or tuple).</li> <li>Handles argument passing, stateful/stateless execution, and error wrapping into a <code>Result</code> object.</li> <li><code>get_results=True</code>: Returns the <code>Result</code> object itself.</li> <li><code>get_results=False</code> (default): Returns the <code>data</code> payload from the <code>Result</code> object if successful.</li> <li>Automatically handles running the function's pre/post compute hooks and caching if configured via <code>@app.tb</code>. <pre><code># Synchronous execution\nresult_data = app_instance.run_any((\"MyModule\", \"my_function\"), arg1=\"hello\")\nfull_result_obj = app_instance.run_any((\"MyModule\", \"my_function\"), arg1=\"hello\", get_results=True)\n\n# Asynchronous execution\nasync_result_data = await app_instance.a_run_any((\"MyAsyncModule\", \"my_async_function\"))\n</code></pre></li> </ul> </li> <li> <p><code>run_http(mod_function_name, function_name=None, method=\"GET\", ...)</code> (async):</p> <ul> <li>Executes a function on a remote ToolBoxV2 instance via HTTP, using the app's <code>session</code> object.</li> </ul> </li> </ul>"},{"location":"utils/#application-lifecycle","title":"Application Lifecycle","text":"<ul> <li><code>exit()</code> / <code>a_exit()</code> (async):<ul> <li>Gracefully shuts down the application.</li> <li>Calls <code>on_exit</code> functions for all loaded modules.</li> <li>Saves configuration.</li> <li>Stops the main application loop (<code>alive = False</code>).</li> <li>Cleans up threads and the event loop if applicable.</li> </ul> </li> </ul>"},{"location":"utils/#utilities","title":"Utilities","text":"<ul> <li><code>print(text, *args, **kwargs)</code> / <code>sprint(text, *args, **kwargs)</code>:<ul> <li>Styled print functions, prepending <code>System$[app_id]:</code>. <code>sprint</code> is often used for more verbose/system-level messages and can be silenced.</li> </ul> </li> <li><code>debug_rains(e: Exception)</code>: If <code>app.debug</code> is true, prints a full traceback and re-raises the exception.</li> <li><code>set_flows(r: dict)</code> / <code>run_flows(name: str, **kwargs)</code>: Manages and executes predefined application flows (sequences of operations).</li> <li><code>get_username()</code> / <code>set_username(username: str)</code>: Manages the application's user identity.</li> <li><code>save_autocompletion_dict()</code> / <code>get_autocompletion_dict()</code>: Saves/loads a dictionary of modules and their functions for autocompletion features.</li> <li><code>save_registry_as_enums(directory: str, filename: str)</code>: Generates an <code>all_functions_enums.py</code>-like file from the currently registered functions.</li> <li><code>execute_all_functions(...)</code> / <code>a_execute_all_functions(...)</code> (async):<ul> <li>Runs all registered testable functions (marked with <code>test=True</code> in <code>@app.tb</code> or having <code>samples</code>).</li> <li>Useful for integration testing and profiling.</li> <li>Can filter by module (<code>m_query</code>) and function (<code>f_query</code>).</li> <li>Supports profiling via <code>cProfile</code>.</li> </ul> </li> <li><code>run_bg_task(task: Callable)</code>:<ul> <li>Runs a synchronous or asynchronous task in a separate background thread with its own event loop. Ensures proper handling of nested asyncio operations within the task.</li> </ul> </li> </ul>"},{"location":"utils/#session-management-appsession","title":"Session Management (<code>app.session</code>)","text":"<p>The <code>app.session</code> attribute holds an instance of the <code>Session</code> class (from <code>toolboxv2.utils.system.session</code>). It's used for: *   Authenticating with a remote ToolBoxV2 service (e.g., SimpleCore Hub). *   Making authenticated HTTP requests (<code>session.fetch</code>, <code>session.upload_file</code>, <code>session.download_file</code>). *   Manages JWT claims and private key authentication.</p> <pre><code># Example: Making an authenticated API call\n# Assumes app.session is already authenticated\nresponse_data = await app_instance.session.fetch(\"/api/MyRemoteModule/get_info\")\njson_payload = await response_data.json()\n</code></pre> <pre><code>### 2. `cli.md` - Documenting the Command Line Interface\n\nThis should explain how to use the `tb` (or `python -m tb`) command-line tool, detailing its arguments and their effects.\n\n```markdown\n# ToolBoxV2: Command Line Interface (CLI)\n\nToolBoxV2 provides a command-line interface (CLI) for managing and running applications. It's typically invoked as `tb` (if installed globally or via an alias) or `python -m tb`.\n\n## General Usage\n\n```bash\npython -m tb [options] [sub-commands]\n# or\ntb [options] [sub-commands]\n</code></pre> <p>The CLI script (<code>__main__.py</code>) performs the following main steps: 1.  Parses command-line arguments. 2.  Initializes the <code>App</code> instance via <code>setup_app()</code> (which calls <code>get_app()</code>). 3.  Handles various options to:     *   Manage application data and configuration.     *   Control application modes (background, proxy, debug).     *   Load modules and manage their state.     *   Run tests or profilers.     *   Execute specific application flows or commands.</p>"},{"location":"utils/#key-cli-arguments","title":"Key CLI Arguments","text":"<p>The following are some of the primary arguments available. Use <code>tb -h</code> or <code>python -m tb -h</code> for a full list.</p> <ul> <li> <p>Instance and Mode:</p> <ul> <li><code>-init [name]</code>: Initializes ToolBoxV2 with a specific instance name (default: <code>main</code>).</li> <li><code>-n, --name &lt;name&gt;</code>: Specifies an ID for the ToolBox instance (default: <code>main</code>). This affects data/config directory names.</li> <li><code>-m, --modi &lt;mode&gt;</code>: Starts a ToolBoxV2 interface/flow (e.g., <code>cli</code>, <code>bg</code>, or custom flows). Default is usually \"cli\".</li> <li><code>--debug</code>: Starts the application in debug mode (more verbose logging, potentially different behavior).</li> <li><code>--remote</code>: Starts in remote mode, often for connecting to a proxy or another instance.</li> <li><code>-bg, --background-application</code>: Starts an interface in the background as a detached process.</li> <li><code>-bgr, --background-application-runner</code>: Runs the background application logic in the current terminal (for daemons).</li> <li><code>-fg, --live-application</code>: Starts a proxy interface, connecting to a background daemon.</li> <li><code>--kill</code>: Kills the currently running local ToolBoxV2 instance (matching the <code>-m &lt;mode&gt;</code> and <code>-n &lt;name&gt;</code>).</li> </ul> </li> <li> <p>Module and Version Management:</p> <ul> <li><code>-l, --load-all-mod-in-files</code>: Loads all modules found in the <code>mods/</code> directory on startup.</li> <li><code>-sfe, --save-function-enums-in-file</code>: Generates/updates the <code>all_functions_enums.py</code> file based on loaded modules. Often used with <code>-l</code>.</li> <li><code>-v, --get-version</code>: Prints the version of ToolBoxV2 and all loaded modules.</li> <li><code>-i, --install &lt;name&gt;</code>: Installs a module or interface (likely via <code>CloudM</code> module).</li> <li><code>-r, --remove &lt;name&gt;</code>: Uninstalls a module or interface.</li> <li><code>-u, --update &lt;name_or_main&gt;</code>: Updates a module/interface or the core ToolBoxV2 (<code>main</code>).</li> </ul> </li> <li> <p>Development and Testing:</p> <ul> <li><code>--test</code>: Runs all unit tests (typically discovers and runs tests in the <code>tests/</code> directory).</li> <li><code>--profiler</code>: Runs all registered testable functions and profiles their execution using <code>cProfile</code>.</li> <li><code>--ipy</code>: Starts an IPython session with the ToolBoxV2 app pre-loaded. Provides magic commands like <code>%tb save/loadX/load/open/inject</code>.</li> </ul> </li> <li> <p>Service Management (<code>--sm</code>):</p> <ul> <li>Provides a sub-menu for managing ToolBoxV2 as a system service (Linux/systemd or Windows Startup).</li> <li>Options: Init, Start/Stop/Restart, Status, Uninstall, Show/Hide console window (Windows).</li> </ul> </li> <li> <p>Log Management (<code>--lm</code>):</p> <ul> <li>Provides a sub-menu for managing log files (e.g., removing or unstyling logs by date/level).</li> </ul> </li> <li> <p>Data and Configuration Management:</p> <ul> <li><code>--delete-config-all</code>: Deletes all configuration files. Use with caution!</li> <li><code>--delete-data-all</code>: Deletes all data folders. Use with caution!</li> <li><code>--delete-config</code>: Deletes the configuration file for the named instance.</li> <li><code>--delete-data</code>: Deletes the data folder for the named instance.</li> </ul> </li> <li> <p>Network Configuration (for interfaces):</p> <ul> <li><code>-p, --port &lt;port&gt;</code>: Specifies the port for an interface (default: <code>5000</code> or <code>6587</code> for background).</li> <li><code>-w, --host &lt;host&gt;</code>: Specifies the host for an interface (default: <code>0.0.0.0</code>).</li> </ul> </li> <li> <p>Direct Command Execution:</p> <ul> <li><code>-c, --command &lt;module_name&gt; &lt;function_name&gt; [arg1 arg2 ...]</code> (can be repeated): Executes a specific function.</li> <li><code>--kwargs &lt;key=value&gt;</code> (can be repeated): Provides keyword arguments for commands specified with <code>-c</code>.</li> </ul> </li> <li> <p>Conda Integration:</p> <ul> <li><code>conda [conda_args...]</code>: Special argument to pass commands directly to a <code>conda_runner.py</code> script (e.g., <code>tb conda env list</code>).</li> </ul> </li> <li> <p>API Runner:</p> <ul> <li><code>api [api_args...]</code>: Special argument to invoke <code>cli_api_runner.py</code>, likely for direct API interactions or testing.</li> </ul> </li> <li> <p>GUI:</p> <ul> <li><code>gui</code>: Starts the GUI version of ToolBoxV2 (imports and runs <code>toolboxv2.__gui__.start</code>).</li> </ul> </li> </ul>"},{"location":"utils/#cli-execution-flow-__main__py","title":"CLI Execution Flow (<code>__main__.py</code>)","text":"<ol> <li>Argument Parsing: <code>parse_args()</code> uses <code>argparse</code> to define and parse all CLI arguments.</li> <li>App Setup (<code>setup_app()</code>):<ul> <li>Initializes the <code>App</code> instance using <code>get_app()</code> with the parsed arguments and name.</li> <li>Sets up PID file for the current process.</li> <li>Optionally silences <code>app.sprint</code> if not in debug/verbose mode.</li> <li>Loads all modules if <code>-l</code> is specified.</li> <li>Handles <code>--update</code> logic.</li> </ul> </li> <li>Background/Live Application Handling:<ul> <li>If <code>-bgr</code>: Initializes <code>DaemonApp</code>.</li> <li>If <code>-bg</code>: Starts the application as a detached background process using <code>subprocess.Popen</code>.</li> <li>If <code>-fg</code> (live-application): Attempts to connect to a background daemon using <code>ProxyApp</code>.</li> </ul> </li> <li>Action Dispatching: Based on the parsed arguments, it performs actions like:<ul> <li>Module installation (<code>--install</code>).</li> <li>Log management (<code>--lm</code>).</li> <li>Service management (<code>--sm</code>).</li> <li>Saving function enums (<code>-sfe</code>).</li> <li>Printing versions (<code>-v</code>).</li> <li>Running the profiler (<code>--profiler</code>).</li> <li>Running flows based on <code>--modi</code>.</li> <li>Handling Docker commands (<code>--docker</code>).</li> <li>Killing an existing instance (<code>--kill</code>).</li> <li>Executing direct commands (<code>-c</code>).</li> </ul> </li> <li>Cleanup: Removes the PID file and calls <code>app.a_exit()</code> before exiting.</li> </ol>"},{"location":"utils/#example-cli-usage","title":"Example CLI Usage","text":"<pre><code># Get version information\npython -m tb -v\n\n# Load all modules and save function enums\npython -m tb -l -sfe\n\n# Run a specific function in MyModule\npython -m tb -c MyModule my_function arg_value --kwargs param_name=kwarg_value\n\n# Start the application with a custom flow named 'web_server' in debug mode\npython -m tb -m web_server --debug -n my_web_instance\n\n# Start a background daemon for the 'bg_processing' flow\npython -m tb -m bg_processing -bg -n background_processor\n\n# Connect to the background daemon with a live proxy application\npython -m tb -m cli -fg -n background_processor\n\n# Kill the 'web_server' modi instance named 'my_web_instance'\npython -m tb -m web_server --kill -n my_web_instance\n</code></pre> <pre><code>### 3. `example_mod.md` - Documenting Module Creation\n\nThis needs to be updated to accurately reflect the `@app.tb(...)` decorator from `toolbox.py` and the `Result` and `RequestData` classes from `types.py`.\n\n```markdown\n# ToolBoxV2: Creating Modules\n\nToolBoxV2 modules are Python files or packages that extend the framework's functionality. They can define simple functions, stateful tools (classes inheriting from `MainTool`), or API endpoints.\n\n## Basic Module Structure\n\nA typical ToolBoxV2 module (`.py` file) includes:\n\n1.  **Imports:** Necessary libraries and ToolBoxV2 components.\n2.  **Module Metadata (Optional but Recommended):**\n    *   `Name` (or `name`): A string defining the module's canonical name.\n    *   `version`: A string for the module's version (e.g., \"1.0.0\").\n3.  **Function/Class Definitions:** The core logic of your module.\n4.  **Exporting Functions:** Functions are made available to ToolBoxV2 using the `@export` decorator (which is an alias for `app.tb`).\n\n## The `@export` Decorator (`app.tb`)\n\nThe `@export` decorator is the primary mechanism for registering functions and configuring their behavior within ToolBoxV2. It's obtained from an `App` instance.\n\n```python\nfrom toolboxv2 import get_app, App, Result, RequestData, MainTool\nfrom toolboxv2.utils.system.types import ToolBoxInterfaces # For specific interface types\nfrom typing import Optional, Dict, Any, List\nimport asyncio\n\n# Get the application instance (singleton)\n# The 'prefix' for get_app here is often the module's own name,\n# though the decorator will use its 'mod_name' parameter.\napp = get_app(\"MyModule\")\nexport = app.tb # Alias the decorator for convenience\n\n# --- Module Metadata (Best Practice) ---\nName = \"MyModule\"  # Used by the decorator if mod_name is not specified\nversion = \"1.0.1\"\n\n# --- Example Functions ---\n\n@export(mod_name=Name, version=version, helper=\"A simple greeting function.\")\ndef greet(name: str) -&gt; str:\n    \"\"\"Returns a greeting message.\"\"\"\n    return f\"Hello, {name} from MyModule!\"\n\n@export(mod_name=Name, version=version, row=True, helper=\"Returns raw data without Result wrapping.\")\ndef get_raw_data() -&gt; dict:\n    \"\"\"Demonstrates returning raw data.\"\"\"\n    return {\"key\": \"value\", \"number\": 123}\n\n@export(mod_name=Name, version=version, initial=True, helper=\"Runs when the module is first loaded.\")\ndef on_module_load():\n    \"\"\"Initialization logic for this module.\"\"\"\n    app.print(f\"{Name} module has been loaded and initialized!\")\n    # return Result.ok(info=\"MyModule initialized successfully\") # Optional: return a Result\n\n@export(mod_name=Name, version=version, exit_f=True, helper=\"Runs when the application is shutting down.\")\nasync def on_module_exit():\n    \"\"\"Cleanup logic for this module.\"\"\"\n    await asyncio.sleep(0.1) # Simulate async cleanup\n    app.print(f\"{Name} module is cleaning up.\")\n    # return Result.ok(info=\"MyModule cleaned up.\") # Optional\n\n@export(mod_name=Name, version=version, api=True, api_methods=['GET'], request_as_kwarg=True,\n        helper=\"An example API endpoint.\")\nasync def my_api_endpoint(request: Optional[RequestData] = None) -&gt; Result:\n    \"\"\"\n    Handles GET requests to /api/MyModule/my_api_endpoint.\n    Accesses request details if provided.\n    \"\"\"\n    if request:\n        app.print(f\"API request received: {request.request.method} {request.request.path}\")\n        app.print(f\"Query Params: {request.request.query_params}\")\n        app.print(f\"User from session: {request.session.user_name}\")\n    return Result.json(data={\"message\": \"API call successful!\", \"module_version\": version})\n\n@export(mod_name=Name, version=version, memory_cache=True, memory_cache_ttl=60)\ndef expensive_calculation(param: int) -&gt; int:\n    \"\"\"\n    An example of a function whose results will be cached in memory for 60 seconds.\n    \"\"\"\n    app.print(f\"Performing expensive calculation for {param}...\")\n    time.sleep(2) # Simulate work\n    return param * param\n\n# Example of a more complex function using App instance and returning a Result\n@export(mod_name=Name, version=version)\ndef process_data_with_app(app_instance: App, data_id: int) -&gt; Result:\n    \"\"\"\n    This function automatically receives the 'App' instance if its first parameter is type-hinted as 'App'.\n    This is determined by the 'state=True' logic in the decorator if 'app' is the first param.\n    Alternatively, use state=False for stateless functions.\n    \"\"\"\n    if not isinstance(app_instance, App): # Should always be App if first param is 'app'\n        return Result.default_internal_error(\"App instance not correctly passed.\")\n\n    # Use app_instance for logging, accessing config, other modules, etc.\n    app_instance.logger.info(f\"Processing data_id: {data_id} in {Name}\")\n    if data_id &lt; 0:\n        return Result.default_user_error(info=\"Data ID cannot be negative.\")\n    return Result.ok(data={\"processed_id\": data_id, \"status\": \"completed\"})\n</code></pre>"},{"location":"utils/#export-decorator-parameters","title":"<code>@export</code> Decorator Parameters:","text":"<ul> <li><code>name</code> (str, optional): The name to register the function under. Defaults to the function's actual name.</li> <li><code>mod_name</code> (str): The name of the module this function belongs to. If not provided, it tries to infer from <code>func.__module__</code> or a global <code>Name</code> in the module.</li> <li><code>version</code> (str, optional): Version string for this function/feature. Combined with the app's version.</li> <li><code>helper</code> (str, optional): A docstring or help text for the function.</li> <li><code>api</code> (bool, default <code>False</code>): If <code>True</code>, exposes this function as an HTTP API endpoint.<ul> <li>The URL pattern is typically <code>/api/&lt;mod_name&gt;/&lt;func_name&gt;</code>.</li> <li>For streaming, <code>/sse/&lt;mod_name&gt;/&lt;func_name&gt;</code>.</li> </ul> </li> <li><code>api_methods</code> (List[str], optional): Specifies allowed HTTP methods (e.g., <code>['GET', 'POST']</code>). Defaults to <code>['AUTO']</code> (GET if no body params, POST if body params).</li> <li><code>request_as_kwarg</code> (bool, default <code>False</code>): If <code>True</code> and <code>api=True</code>, the function will receive a <code>request: RequestData</code> keyword argument if it's defined in its signature.</li> <li><code>row</code> (bool, default <code>False</code>): If <code>True</code>, the function's raw return value is used directly. If <code>False</code> (default), the return value is automatically wrapped in a <code>Result.ok()</code> object if it's not already a <code>Result</code> or <code>ApiResult</code>.</li> <li><code>initial</code> (bool, default <code>False</code>): If <code>True</code>, this function is added to the module's \"on_start\" list and is called when the module is loaded by the <code>App</code> instance (if the module instance is a <code>MainTool</code> or similar, or if called directly).</li> <li><code>exit_f</code> (bool, default <code>False</code>): If <code>True</code>, this function is added to the module's \"on_exit\" list and is called when the <code>App</code> instance is shutting down or the module is removed.</li> <li><code>state</code> (bool, optional):<ul> <li>If <code>None</code> (default): Automatically determined. If the first parameter of the decorated function is named <code>self</code> or <code>app</code> (and type-hinted as <code>App</code>), <code>state</code> is considered <code>True</code>. Otherwise <code>False</code>.</li> <li>If <code>True</code>: The function is considered stateful. If its first parameter is <code>self</code>, it's assumed to be a method of a class instance (e.g., a <code>MainTool</code> subclass). If <code>app</code>, the <code>App</code> instance is passed.</li> <li>If <code>False</code>: The function is treated as stateless.</li> </ul> </li> <li><code>test</code> (bool, default <code>True</code>): Marks the function as testable. Used by <code>app.execute_all_functions()</code>.</li> <li><code>samples</code> (List[Dict[str, Any]], optional): A list of sample keyword arguments to be used when testing the function with <code>app.execute_all_functions()</code>.</li> <li><code>memory_cache</code> (bool, default <code>False</code>): Enables in-memory caching for the function's results.</li> <li><code>memory_cache_ttl</code> (int, default <code>300</code>): Time-to-live in seconds for memory cache entries.</li> <li><code>memory_cache_max_size</code> (int, default <code>100</code>): Max number of entries in the memory cache.</li> <li><code>file_cache</code> (bool, default <code>False</code>): Enables file-based caching for the function's results. (Stored in <code>app.data_dir/cache/...</code>).</li> <li><code>restrict_in_virtual_mode</code> (bool, default <code>False</code>): If <code>True</code>, restricts function in certain virtualized/proxied modes.</li> <li><code>level</code> (int, default <code>-1</code>): A general-purpose level or priority for the function.</li> <li><code>pre_compute</code> (Callable, optional): A function <code>(func, *args, **kwargs) -&gt; (args, kwargs)</code> called before the main function executes. It can modify args/kwargs.</li> <li><code>post_compute</code> (Callable, optional): A function <code>(result, func, *args, **kwargs) -&gt; result</code> called after the main function executes. It can modify the result.</li> <li><code>interface</code> (ToolBoxInterfaces | str, optional): Specifies the intended interface type (e.g., <code>ToolBoxInterfaces.cli</code>, <code>ToolBoxInterfaces.api</code>). Defaults to \"tb\".</li> </ul>"},{"location":"utils/#result-and-apiresult-objects","title":"<code>Result</code> and <code>ApiResult</code> Objects","text":"<ul> <li>Modules should typically return <code>Result</code> objects (or <code>ApiResult</code> for API endpoints) to provide standardized responses including success/error status, data payload, and informational messages.</li> <li>The <code>toolboxv2.utils.system.types.Result</code> class provides factory methods:<ul> <li><code>Result.ok(data=..., info=...)</code></li> <li><code>Result.json(data=..., info=...)</code> (for <code>api=True</code> functions)</li> <li><code>Result.html(data=..., info=...)</code></li> <li><code>Result.text(text_data=..., info=...)</code></li> <li><code>Result.binary(data=..., content_type=..., download_name=...)</code></li> <li><code>Result.redirect(url=..., status_code=...)</code></li> <li><code>Result.stream(stream_generator=..., info=..., cleanup_func=...)</code> (for SSE)</li> <li><code>Result.default_user_error(info=..., exec_code=...)</code></li> <li><code>Result.default_internal_error(info=..., exec_code=...)</code></li> <li><code>Result.custom_error(data=..., info=..., exec_code=...)</code></li> </ul> </li> <li>The <code>Result</code> object has a <code>task(background_task_callable)</code> method to schedule a background task to run after the main function returns.</li> </ul>"},{"location":"utils/#requestdata-object","title":"<code>RequestData</code> Object","text":"<ul> <li>For API functions (<code>api=True</code>) with <code>request_as_kwarg=True</code>, if the function signature includes <code>request: Optional[RequestData] = None</code>, it will receive an instance of <code>toolboxv2.utils.system.types.RequestData</code>.</li> <li><code>RequestData</code> provides access to:<ul> <li><code>request.method</code>, <code>request.path</code></li> <li><code>request.headers</code> (an instance of <code>Headers</code>, e.g., <code>request.headers.user_agent</code>, <code>request.headers.hx_request</code>)</li> <li><code>request.query_params</code> (dict)</li> <li><code>request.form_data</code> (dict, if applicable)</li> <li><code>request.body</code> (parsed JSON if <code>content_type</code> is <code>application/json</code>, otherwise raw bytes/str)</li> <li><code>session.SiID</code>, <code>session.user_name</code>, <code>session.level</code> (from the current user's session)</li> </ul> </li> </ul>"},{"location":"utils/#creating-a-maintool-based-module","title":"Creating a <code>MainTool</code>-based Module","text":"<p>For more complex, stateful modules, you can create a class that inherits from <code>toolboxv2.utils.system.main_tool.MainTool</code>.</p> <pre><code>from toolboxv2 import get_app, App, Result, MainTool\nfrom toolboxv2.utils.system.types import ToolBoxError\n\napp = get_app(\"MyToolModule\")\nexport = app.tb\n\nName = \"MyToolModule\"\nversion = \"0.5.0\"\n\nclass Tools(MainTool): # The class must be named 'Tools' for auto-detection by older App versions\n                      # or ensure your module file directly uses @export on methods if not named Tools.\n    # Or, you can export methods directly from any class:\n    # class MyCustomTool(MainTool):\n    #    @export(...)\n    #    def my_method(self, ...): ...\n\n    async def __ainit__(self): # Asynchronous initialization\n        # self.app is automatically available\n        # self.name, self.version, self.logger are set by MainTool's __await__\n        await super().__ainit__(name=Name, v=version, tool={\n            \"process_item\": self.process_item, # For older compatibility if functions were in 'tools' dict\n            \"get_status\": self.get_status\n        })\n        self.internal_state = \"initialized\"\n        self.app.print(f\"{self.name} (Tool) has been initialized with state: {self.internal_state}\")\n\n    @export(mod_name=Name, version=version) # Decorate methods to export them\n    def process_item(self, item_id: int, details: str) -&gt; Result:\n        # 'self' provides access to app, logger, name, version, config\n        self.app.logger.info(f\"{self.name} processing item: {item_id} - {details}\")\n        self.internal_state = f\"last_processed_{item_id}\"\n        if item_id == 0:\n            return self.return_result( # Helper from MainTool\n                error=ToolBoxError.input_error,\n                exec_code=1, # Custom error code\n                help_text=\"Item ID cannot be zero.\",\n                data_info=\"Validation failed\"\n            )\n        return Result.ok(data={\"item_id\": item_id, \"status\": \"processed by tool\"})\n\n    @export(mod_name=Name, version=version)\n    async def get_status(self) -&gt; str: # Example async method\n        await asyncio.sleep(0.01)\n        return f\"Tool {self.name} current state: {self.internal_state}\"\n\n    async def on_exit(self): # Not automatically called unless also decorated or part of a convention\n        self.app.print(f\"Tool {self.name} is shutting down its internal state.\")\n        # Perform cleanup\n\n# To ensure on_exit is called by the App framework:\n@export(mod_name=Name, version=version, exit_f=True)\nasync def custom_tool_exit_function(app_instance: App):\n    tool_instance = app_instance.get_mod(Name)\n    if tool_instance and hasattr(tool_instance, 'on_exit') and callable(tool_instance.on_exit):\n        await tool_instance.on_exit()\n</code></pre> <p>Key aspects of <code>MainTool</code>: *   Asynchronous Initialization: Use <code>async def __ainit__(self)</code> for setup. The <code>MainTool</code> itself is awaitable, and <code>__ainit__</code> is called when the instance is first awaited (e.g., by <code>app.load_mod</code> or <code>app.get_mod</code>). *   <code>self.app</code>: The <code>App</code> instance is available as <code>self.app</code>. *   <code>self.name</code>, <code>self.version</code>, <code>self.logger</code>: These are automatically set up. *   <code>self.return_result(...)</code>: A helper method for creating <code>Result</code> objects. *   Methods intended to be called via <code>app.run_any</code> should be decorated with <code>@export</code>.</p>"},{"location":"utils/#steps-to-create-a-valid-toolboxv2-module","title":"Steps to Create a Valid Toolboxv2 Module:","text":"<ol> <li>Define Module Structure: Organize your code with imports, metadata, and function/class definitions.</li> <li>Clarify Dependencies: Import necessary libraries. Handle missing optional dependencies gracefully if needed.</li> <li>Export Functions/Methods: Use the <code>@export(...)</code> decorator (e.g., <code>app.tb(...)</code>) to mark functions/methods that ToolBoxV2 should recognize.<ul> <li>Provide <code>mod_name</code> and <code>version</code>.</li> <li>Use other parameters (<code>api</code>, <code>row</code>, <code>initial</code>, <code>exit_f</code>, <code>memory_cache</code>, etc.) as needed.</li> <li>Ensure clear signatures and document parameters/return types (Python type hints are highly recommended).</li> </ul> </li> <li>Documentation and Versioning: Document your module and its functions. Use semantic versioning.</li> <li>Testing: Test your module thoroughly, including how it integrates with the ToolBoxV2 app (<code>app.run_any</code>, <code>app.get_mod</code>, etc.). Use the <code>test=True</code> and <code>samples</code> parameters in <code>@export</code> to facilitate automated testing via <code>app.execute_all_functions()</code>.</li> </ol>"},{"location":"utils/#to-isaa","title":"To isaa","text":""}]}